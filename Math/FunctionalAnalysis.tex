\input{../style.tex}

\title{Functional Analysis}
\author{Jacob Denson}

\begin{document}

\pagenumbering{gobble}
\maketitle
\tableofcontents
\pagenumbering{arabic}

\chapter{Introduction}

Functional analysis is the interlace of algebra and analysis, in which algebraic structures are endowed with topological structure. The approach's utility counts for the rapid growth of applications over the past century, be it in quantum mechanics, statistics, or computing science. Rarely are we concerned with a single object, like a function, a random variable, or a measure, but instead consider large classes of such objects. One technique for handling these classes is to add algebraic structure which elaborates on the natural relation between these objects. Functional analysis provides general tools for this methodology.

\begin{example}
    We rarely analyze a measurable function $f$ in isolation. Instead, we prove theorems about a class of measurable functions defined on the same measurable space. If $f$ and $g$ are measurable, then we may consider their addition $f + g$, their multiplication $fg$, and scaling $\lambda f$ (for $\lambda \in \mathbf{R}$), which are all measurable. Thus the space of measurable functions on a set is a vector space. Similarily, we may consider $C[0,1]$, the space of all continuous, real-valued functions on $[0,1]$.
\end{example}

Functional analysis mostly applies to functions between topological and algebraic structures, because we may add and scale things quite naturally, and we obtain topologies based on how functions converge. The power of functional analysis rests on how strongly the algebraic structure of a space connects to the topology. Stronger relations lead to stronger theorems. We shall begin with one of the strongest relations, a space with a well defined inner product.

Most properties of functional analysis work nicely with completeness. We therefore begin with real vector spaces. In fact, if we have a complete vector space over the rationals, then we can extend the scalar multiplication over the reals, so there is no way to succeed. From real spaces, we can't generalize much, apart from considering complex spaces. Thus, in this book, $\mathbf{F}$ will stand for $\mathbf{R}$ or $\mathbf{C}$. Real vector spaces are spaces which can be `scaled' in a nice way. Complex vector spaces can also be `twisted'. As an example, the space $C([0,1], \mathbf{R})$ of continuous, real valued functions is a real space, which can be scaled pointwise. On the other hand, if we take $C([0,1], \mathbf{C})$, then the space can be twisted. Each function in the space can be visualized as a corkscrew -- the domain is the length of the screw, the range is the extremities of the screw. Twisting a corkscrew is natural, so we have a complex vector space.

The nicest vector spaces are $\mathbf{R}^n$. It is here that we may measure angles, distances, and convergence. Recall that the inner product on $\mathbf{R}^n$ is naturally related to the measure of angles between vectors. Without an inner product, we can only talk about linear dependance, which is a binary relation. With an inner product, we obtain an abstract definition of angle, which is a degree of similarity between two vectors. The nicest spaces have angles defined upon them.

\begin{definition}
    An {\bf inner product space} is a pair $(V, \langle \cdot, \cdot \rangle)$, where $V$ is a real vector space, and $\langle \cdot, \cdot \rangle$ is a positive definite inner product. That is, for any $\lambda, \gamma \in \mathbf{R}$, $v,w, u \in V$,
    %
    \begin{equation} \langle \lambda v + \gamma w, u \rangle = \lambda \langle v, u \rangle + \gamma \langle w, u \rangle\ \ \ \ \ \langle u, \lambda v + \gamma w \rangle = \lambda \langle u, v \rangle + \gamma \langle u, w\rangle \end{equation}
    \begin{equation} \langle v, v \rangle \geq 0\ \ \ \ \ \ \ \langle v, v \rangle = 0\ \text{iff}\ v = 0 \end{equation}
\end{definition}

We would also like to consider complex inner product spaces, but we have a problem. If $\langle \cdot, \cdot \rangle$ is defined as in the real case, then we have
%
\[ 0 \leq \langle i v, i v \rangle = - \langle v, v \rangle \leq 0 \]
%
so $\langle v, v \rangle = 0$ for all $v$, hence $v = 0$. The problem results because we are restricted to considering real values of the product, yet we can vary $v$ by a complex coefficient.

How does a complex vector space come about. Let $V$ be a real vector space, and let $J$ be a linear map with $J^2 = -1$. Then $J$ is a way of `twisting' $V$, so we may make $V$ into a complex vector space by defining $(\lambda + \gamma i) v = \lambda v + \gamma J(v)$. Thus the twist is just multiplication by $i$. A choice of $J$ is obtained on any vector space, but it is only useful when found canonically. If we already have an inner product $\langle \cdot, \cdot \rangle$ based on the real structure of $V$, then $J$ should twist ninety degrees --  for any $v \in V$, $\langle v, Jv \rangle = 0$. We would also like this rotation to be uniform, so that $\langle Jv, Jw \rangle = \langle v, w \rangle$. Then $\langle Jv, w \rangle = \langle v, -Jw \rangle$, since $J^2 = -1$. We wish to extend $\langle \cdot, \cdot \rangle$ to a complex `form' $(\cdot, \cdot)$, in the sense that $\Re (\cdot, \cdot) = \langle \cdot, \cdot \rangle$. $(\cdot, \cdot)$ cannot be linear in each factor, since $\Re (v, iw) = \langle v, iw \rangle = \langle -iv, w \rangle$. The closest thing we could have is that $(\cdot, \cdot)$ is {\bf sequilinear}\footnote{sequi means `one and a half' in greek}, linear in the first factor, and `anti-linear' in the second factor, in the sense that
%
\[ (v, \lambda w + \gamma u) = \overline{\lambda} (v,w) + \overline{\gamma} (v,u) \]
%
And almost symmetric, in the sense that
%
\[ (v,w) = \overline{(w,v)} \]
%
Then
%
\[ \Im (v,w) = - \Re [i (v, w)] = - \Re (iv, w) = - \langle iv, w \rangle = \langle v, i w \rangle \]
%
So if we have any hope of extending $\langle \cdot, \cdot \rangle$, we must define
%
\[ (v,w) = \langle v, w \rangle + i \langle v, iw \rangle \]
%
And with the properties we have displayed, this map is a sesquilinear map, such that $(v,v) \geq 0$, and $(v,v) = 0$ if and only if $v = 0$. The real measures the ordinary angle between $v$ and $w$, the imaginary part measures a `rotational angle'.

\begin{definition}
    A {\bf Hermitian form} on a complex vector space $V$ is a sesquilinear map $\langle \cdot, \cdot \rangle$ such that $\langle v, v \rangle \geq 0$, and is equal to zero only when $v = 0$.
    
\end{definition}


\chapter{Hilbert Spaces}

A Hilbert space is a Banach space most similar to Euclidean space. They have an incredibly structure, and occur in wide applications of functional analysis to mathematics, physics, and computing science.

\begin{definition}
    A {\bf Hilbert space} is a complete inner product space -- That is, a vector space equiped with an inner (hermitian) product such that the corresponding metric structure is complete.
\end{definition}

In this chapter, we shall let $H$ denote a general Hilbert space, and $\langle \cdot, \cdot \rangle$ the inner product space with which the space is equipped.

\begin{theorem}[Cauchy-Schwarz inequality]
    $\langle x, y \rangle \leq \| x \| \| y \|$.
\end{theorem}

The main reason why the subject is called functional analysis is because most of the time we shall be analyzing functions from one space to another, which naturally have an additive and multiplicative structure obtained from the space these functions are defined on.

\begin{definition}
    A {\bf topological vector space} is a vector space over a field (here assumed to be $\mathbf{R}$ or $\mathbf{C}$), endowed with  topology which makes the operations of addition and multiplication continuous.
\end{definition}

Some immediate corollaries of the definition include that

\begin{prop}
    The translation $U + v$ of any open set $U$ by a vector $v$ is open.
\end{prop}
\begin{prop}
    When $v_\alpha \to v$, $w_\alpha \to w$, and $\lambda_\alpha \to \lambda$, $\lambda_\alpha (v_\alpha + w_\alpha) = \lambda ( v + w)$.
\end{prop}
\begin{prop}
    A translated local base at the origin by a vector $v$ is a local base at $v$.
\end{prop}
%
Proposition (1.2) and (1.3) give different characterizations of topological vector spaces. We can define topological vector spaces either in terms of neighbourhood bases at the origin, or in terms of convergent nets obeying the rule denoted in (1.2). A neighbourhood containing the origin will be hereafter known as a {\bf 0-neighbourhood}.
%
\begin{lemma}
    Every 0-neighbourhood $U$ contains a 0-neighbourhood $W$ for which $W + W \subset U$.
\end{lemma}
\begin{proof}
    Since addition is continuous, and $U$ is a 0-neighbourhood, there are neighbourhoods $W$ and $V$ for which $W + V \subset U$. Our problem is solved by picking $W \cap V$ as our neighbourhood.
\end{proof}

\begin{definition}
    A set $B$ is {\bf balanced} if $\lambda B \subset B$ for $|\lambda| < 1$.
\end{definition}

\begin{lemma}
    Every 0-neighbourhood can be shrunk to a balanced neighbourhood.
\end{lemma}
\begin{proof}
    Let $U$ be a neighbourhood of zero. Then there is a scalar neighbourhood $\Lambda$ of zero, and a neighbourhood $V$ of any vector $V$, for which $\Lambda V \subset U$. We may choose $\Lambda$ so it is balanced, and then $\Lambda V$ is balanced.
\end{proof}

\begin{prop}
    If $K$ and $C$ are disjoint subsets of a T1 vector space $V$, where $K$ is compact and $C$ is closed, then 0 has a neighbourhood $V$ such that $K + V$ and $C + V$ are disjoint.
\end{prop}
\begin{proof}
    Fix some point $k \in K$. It suffices to show that there is a neighbourhood $U_k$ for which $k + U_k$ is disjoint from $C + U_k$. If this is true, (1.4) tells us we may pick a subset $W_k$ of $U_k$ for which $W_k + W_k \subset U_k$. Then we may choose a finite subcover $k_1 + W_{k_1}, \dots, k_n + W_{k_n}$ of $K$. If we let $V = \bigcap_{i = 1}^n W_{k_i}$, then we find $K + V$ is disjoint from $C + V$.

    To find this neighbourhood of $k$, we know that we may first pick a neighbourhood $U$ containing $C$, disjoint from $k$. Without loss of generality, by translation, we may assume $U$ is a neighbourhood of 0. Then we may choose $W$ for which $W + W \subset U$ and $-W = W$. It then follows that $k + W$ is disjoint from $W + C$, since if $k + w = w' + c$, $k + w - w' = c$, the left side is contained within $U$.
\end{proof}

\begin{corollary}
    A T1 vector space is Hausdorff.
\end{corollary}

\begin{corollary}
    Every set in a neighbourhood base contains the closure of another neighbourhood.
\end{corollary}
\begin{proof}
    Let 
\end{proof}

\begin{corollary}
    The closure of a set $A$ is the intersection of all $A + V$, where $V$ is a 0-neighbourhood.
\end{corollary}
\begin{proof}

\end{proof}

\begin{prop}
    A locally bounded space is first-countable.
\end{prop}
\begin{proof}
    
\end{proof}

\begin{definition}
Vector spaces should be familiar, but we specify some basic properties which may have been missed in a basic course.
\begin{enumerate}
    \item A set $C$ is {\bf convex} if $tC + (1 - t)C \subset C$ for any $t \in [0,1]$.
    \item A set $B$ is {\bf balanced} if $\lambda B \subset B$ for $| \lambda | \leq 1$.
    \item a set $B$ is {\bf (Von-Neumann) bounded} if, for any neighbourhood $E$ of 0, there is a scalar $\lambda > 0$ such that $B \subset \gamma E$ for every $\gamma > \lambda$.
\end{enumerate}
\end{definition}

\begin{definition}
    There are many additional properties one can ascribe to a topological vector space.
    %
    \begin{enumerate}
        \item A topological vector space is {\bf locally convex} if there is a neighbourhood base of convex sets.
        \item A space is {\bf locally bounded} if there a neighbourhood base of bounded sets.
        \item An {\bf $\mathbf{F}$-space} is a vector space endowed with a complete, invariant metric ($d(v + u, w + u) = d(v,w)$ for any vectors $v,w,u$).
        \item A {\bf Fr\'{e}chet} space is a locally convex $F$-space.
        \item A {\bf normed space} is a vector space endowed with a norm function $\| \cdotp \|: V \to \mathbf{R}+$, such that
        %
        \begin{itemize}
            \item $\| v \| = 0$ if and only if $v = 0$.
            \item $\| v + w \| \leq \| v \| + \| w \|$.
            \item $\| \lambda v \| = | \lambda | \| v \|$.
        \end{itemize}
        %
        We can consider a norm space as an $F$-space by defining a distance function $d(v,w) = \| v - w \|$.
        \item A {\bf Banach space} is a complete normed space.
        \item A space is {\bf normable} if its topology can be induced by a norm.
        \item A space is {\bf Heine-Borel} if every closed-bounded set is compact.
    \end{enumerate}
\end{definition}

\begin{theorem}
    Every locally bounded space is first countable.
\end{theorem}
\begin{proof}
    
\end{proof}

We will be studying a specific subclass of topological vector space.

\begin{definition}
    A norm space is a vector space $V$ endowed with a norm function $\| \cdotp \|: \mathbf{R} \to \mathbf{R}^+$, such that
    %
    \begin{enumerate}
        \item $\| v \| = 0$ if and only if $v = 0$.
        \item $\| \lambda v \| = | \lambda | \| v \|$.
        \item $\| v + w \| \leq \| v \| + \| w \|$.
    \end{enumerate}
    %
    We obtain a distance function on a norm space by defining $d(v,w) = \| v - w \|$.
\end{definition}

\section{Convexity}

A function $f:(a,b) \to \mathbf{R}$ is convex when the line segment between $(a,f(a))$ and $(b,f(b))$ lies above the graph of $f$. The line segment connecting these two points is described by
%
\[ \{ (\lambda a + (1 - \lambda) b, \lambda f(a) + (1 - \lambda) f(b)) : 0 \leq \lambda \leq 1 \} \]
%
and we require that $(\lambda a + (1 - \lambda)b, f(\lambda a + (1 - \lambda)b)$ lies below the corresponding point on the line defined above. This is satisfied exactly when we have a certain inequality:

\begin{definition}
    A function $f:U \to \mathbf{R}$ is {\bf convex} on $(a,b)$ if, for any $a \leq x < y \leq b$, and $0 \leq \lambda \leq 1$, we have
    %
    \begin{equation} \label{convex1} f(\lambda x + (1 - \lambda) y) \leq \lambda f(x) + (1 - \lambda) f(y) \end{equation}
    %
    By rewording the definition, convexity is also satisfied when, for $a \leq x < y < z \leq b$,
    %
    \begin{equation} \label{convex2} \frac{f(y) - f(x)}{y - x} \leq \frac{f(z) - f(y)}{z - y} \end{equation}
    %
    Geometrically, this equation says that the slope of the tangent line from $(x, f(x))$ to $(y, f(y))$ is smaller than the tangent line from $(y, f(y))$ to $(z, f(z))$.
\end{definition}

\begin{lemma}
    A $C^1$ convex function's derivative is non-decreasing on $(a,b)$.
\end{lemma}
\begin{proof}
    Suppose $f$ is a $C^1$ function, and $f'$ is non-decreasing, then consider any $a \leq x < y < z \leq b$. Then $f'(x) \leq f'(y) \leq f'(z)$. Applying the mean value theorem, we conclude there is $t \in (x,y)$, and $u \in (y,z)$, for which
    %
    \begin{equation} \label{convexderivative} f'(t) = \frac{f(y) - f(x)}{y - x}\ \ \ \ \ f'(u) = \frac{f(z) - f(y)}{z - y} \end{equation}
    %
    And since $t < u$, (\ref{convexderivative}) implies $f'(t) \leq f'(u)$, i.e. (\ref{convex2}) is satisfied.

    If $f$ is $C^1$ and convex, then surely $f'$ is non-decreasing. Fix $a \leq x < y \leq b$. In (\ref{convex2})), letting $y$ converge to $x$, we obtain
    %
    \begin{equation} \label{yconvergeleft} f'(x) = \lim_{y \to x^+} \frac{f(y) - f(x)}{y - x} \leq \lim_{y \to x} \frac{f(z) - f(y)}{z - y} = \frac{f(z) - f(x)}{z - x} \end{equation}
    %
    Conversely, letting $y \to z$, we obtain
    %
    \begin{equation} \label{yconvergeright} f'(y) = \lim_{y \to z^-} \frac{f(z) - f(y)}{z - y} \geq \lim_{y \to z} \frac{f(y) - f(x)}{y - x} = \frac{f(z) - f(x)}{z - x} \end{equation}
    %
    And in tandem, (\ref{yconvergeleft}), (\ref{yconvergeright}) and (\ref{convex2}) imply that $f'(x) \leq f'(y)$.
\end{proof}

\begin{example}
    $\exp: \mathbf{R} \to \mathbf{R}$ is convex on $(-\infty, \infty)$, since $\exp'' = \exp > 0$.
\end{example}

\begin{lemma}
    A function is continuous on the open segments where it is convex.
\end{lemma}

The most important inequality in analysis is the triangle inequality, undershadowed by the Schwarz inequality. Almost as important is Jensen's inequality. Despite its importance, the proof is fairly simple and intuitive. Consider the center of mass of an object.  

\begin{theorem}[Jensen's Inequality]
    Let $(\Omega, \mathbf{P})$ be a probability space. If $X \in L^1(\mathbf{P})$, where $a < X< b$, and if $f$ is a real function, convex on $(a,b)$, then
    %
    \begin{equation} \label{jensen} f(\mathbf{E}[X]) \leq \mathbf{E}[f \circ X] \end{equation}
\end{theorem}
\begin{proof}
    Since $a < X < b$, $a < \mathbf{E}[X] < b$. Let
    %
    \[ \beta = \sup_{a < x < \mathbf{E}[X]} \frac{g(\mathbf{E}[X]) - g(x)}{\mathbf{E}[X] - x} \]
    %
    For any $a < x < y$, $g(x) + \beta(\mathbf{E}[X] - x) \geq g(y)$. But also, by the right side of $(\ref{convex2})$, for any $z > y$, $g(z) - \beta(z - \mathbf{E}[X]) \geq g(\mathbf{E}[X])$. For any $\omega \in \Omega$, we may restate these equations as as
    %
    \[ g(f(\omega)) - \beta(f(\omega) - y) \geq g(y) \]
    %
    But then taking expectations, we obtain (\ref{jensen}).
\end{proof}

Jensen's inequality is incredibly useful. To see this, consider some examples.

\begin{example}
    We have seen the exponential function is convex. Hence for any $L_1(\mathbf{P})$, where $\mathbf{P}$ is a probability measure, we have
    %
    \begin{equation} \label{harmonic} exp\left(\int f d\mathbf{P} \right) \leq \int e^f d\mathbf{P} \end{equation}
    %
    Let $\mathbf{P}$ be the uniform measure over a finite set $\{ x_1, x_2, \dots, x_n \}$. Then (\ref{harmonic})) tells us that
    %
    \[ e^{f(x_1)/n}e^{f(x_2)/n} \dots e^{f(x_n)/n} \leq \frac{\sum e^{f(x_i)}}{n} \]
    %
    If we let $x_i$ be real numbers, and $f(x_i) = \log(x_i)$, we conclude
    %
    \[ (x_1x_2 \dots x_n)^{1/n} \leq \frac{\sum x_i}{n} \]
    %
    In other words, the geometric mean is always smaller than the arithmetic mean.
\end{example}

Jensen's inequality implies so many other inequalities in analysis.

\begin{definition}
    Let $1 \leq p \leq \infty$. We say $1 \leq q \leq \infty$ is the {\bf conjugate} of $p$ if $p^{-1} + q^{-1} = 1$, and write $q = p'$.
\end{definition}

\begin{theorem}[H\"{o}lder]
    If $p' = q$, $(\Omega,\mu)$ is a measure space, and $f,g$ are positive measurable functions on $\Omega$, then
    %
    \begin{equation} \label{holder} \| fg \|_1 \leq \| f \|_p \| g \|_q \end{equation}
\end{theorem}
\begin{proof}
    Let $A,B$ be the values on the right hand side of (\ref{holder})). If $A = 0$, then $f = 0$ almost everywhere, so that the theorem is trivial. Symmetry shows that the same is true if $B = 0$, so assume $A, B \neq 0$. Define $F = f/A$, and $G = g/B$. Then
    %
    \[ \left( \int F^p d\mu \right)^{1/p} = A^{-1} \left( \int f^p d\mu \right)^{1/p} = 1\ \ \ \ \ \left( \int G^q d\mu \right)^{1/q} = B^{-1} \left( \int g^q d\mu \right)^{1/q} = 1 \]
    %
    For any $x$, there is a number $s$ such that $e^{s/p} = F(x)$, and $t$ such that $e^{t/q} = G(x)$. By the convexity of the exponential function, $e^{s/p + t/q} \leq e^s p^{-1} + e^t q^{-1}$. Thus $FG \leq p^{-1} F^p + q^{-1} G^q$, and thus by integrating,
    %
    \[ \int FG\ d\mu \leq p^{-1} + q^{-1} = 1 \]
\end{proof}

\begin{corollary}[Minkowski]
    For
    \[ \| f + g \|_p \leq \| f \|_p + \| g \|_p \]
\end{corollary}




\chapter{Operator Algebras}

In Linear algebra, one studies structure theorems for linear transformations from a finite dimensional vector space to itself. One shows that, in almost all cases, such a transformation can be `diagonalized': we are able to choose a basis of vectors which map into multiples of themselves under the linear transformation. We shall attempt to extend methods related to classification to infinite dimensional spaces.

\begin{definition}
    A {\bf compact operator} between two spaces $X$ and $Y$ maps bounded sets onto precompact sets. The set of all compact operators is denoted $K(X,Y)$.
\end{definition}

\begin{lemma}
    Every compact operator is bounded.
\end{lemma}
\begin{proof}
    The image of the unit ball is pre-compact, hence bounded.
\end{proof}

\begin{definition}
    A {\bf finite-rank operator}
\end{definition}




\chapter{Banach Algebras}

Recall that an algebra over a field $\mathbf{F}$ is an $\mathbf{F}$ vector-space equipped with an associative multiplicative structure which contains an identity. The set of all units (invertible elements) on such an algebra $A$ will be denoted $U(A)$. A consistant norm attached to an algebra is a nice situation to study characterization theorems, since all algebras can be identified with a set of linear maps over some vector space. We shall use capital letters, like $M$ and $N$, to denote abstract elements of a Banach algebra, and denote algebras by capital letters near the beginning of the alphabet, such as $A$ or $B$.

\begin{definition}
    A {\bf Banach Algebra} is a Banach space $A$ which is also an algebra, and satisfies $\| MN \| \leq \| M \| \| N \|$ for any $M,N \in A$, and $\| 1 \| = 1$.
\end{definition}

It is obvious that this makes multiplication (in addition to addition and scaling) a continuous operation on the space. It is interesting to note that this is really all you need to define a Banach algebra, provided it has an identity element.

\begin{theorem}
    Let $V$ be a Banach space upon which a continuous multiplication structure has been defined. Then there is an equivalent norm on $V$ which makes the space into a Banach algebra.
\end{theorem}
\begin{proof}
    Embed $V$ in $B(V)$ by defining $\Lambda_M(N) = MN$, for each $M \in V$ (since multiplication on the right is continuous, $\Lambda_M$ truly is in $B(V)$ rather than just being a linear map). This is an algebra isomorphism, which is also a Banach space isomorphism, provided  that the set of all $\Lambda_M$ is closed in $B(V)$, so we may apply the inverse function theorem. To see this, note two nice properties of the map. First,
    %
    \[ \| M \| = \| M \cdot 1 \| = \| \Lambda_{M}(1) \| \leq \| \Lambda_{M} \| \| 1 \|  \]
    %
    and second, $\Lambda_{M + N} = \Lambda_M + \Lambda_N$. Suppose $\Lambda_{M_i}$ is a Cauchy seqeunce. Then the $M_i$ are a Cauchy sequence, since
    %
    \[ \| M_i - M_j \| \leq \| \Lambda_{M_i - M_j} \| \| 1 \| = \| \Lambda_{M_i} - \Lambda_{M_j} \| \| 1 \| \]
    %
    and therefore they converge to an element $M$. By right continuity, $M_i N \to M N$ for all $N$, so by definition, $\Lambda_{M_i} \to \Lambda_M$. One may verify that the set $\{ \Lambda_m \}$ is a Banach algebra.
\end{proof}

\begin{example}
    Let $K$ be a compact space. Then the space $C(K)$ of $\mathbf{F}$-valued continuous functions is a Banach algebra over $\mathbf{F}$ under the norm $\| \cdot \|_\infty$ and with pointwise multiplication. If $K$ is finite, then $C(K) \cong \mathbf{F}^{|K|}$. More generally, we may consider the set of all essentially bounded functions on some measure space.
\end{example}

\begin{example}
    More generally, the space $C_b(X)$ of continuous, bounded $\mathbf{F}$-valued functions on any topological space $X$ is a Banach algebra. If $X$ is locally compact, then the space $C_0(X)$ of functions which vanish at infinity form a Banach algebra, except that the space does not always contain an identity. Normally, there exists a trick to add an identity to the space on any `Banach algebra without identity' -- in this case, we enlarge the space to consist of the space of functions which eventually become constant at infinity.
\end{example}

\begin{example}
    If $K$ is a compact neighbourhood in $\mathbf{C}$, then we define $A(K)$ to be the set of continuous functions defined on $K$ which are analytic in $K^\circ$. Since uniform convergence preserves holomorphicity, $A(K)$ is a closed subset of $C_0(K)$ and is therefore a Banach algebra. The algebra $A(\mathbf{D})$ is known as the disk algebra.
\end{example}

\begin{example}
    If $G$ is a group with measure $\mu$, $L_1(G, \mu)$ is a Banach algebra, where we define multiplication as convolution,
    %
    \[ (f * g)(x) = \int f(y) g(xy^{-1}) d\mu(y) \]
    %
    This algebra is commutative when $G$ is a commutative. It does not always possess a unit, unless we enlarge the space. We identify each $f$ with the measure $f \lambda$, where $(f \lambda) (E) = \int_E f d\lambda$. In other words, $f \lambda$ is the measure defined by the equation
    %
    \[ \frac{d(f \lambda)}{d \lambda} = f \]
    %
    Then the set of all measures of the form $f \lambda + \mu \delta$ where $\delta$ is the dirac function evaluated at the identity, and $\mu \in \mathbf{F}$ form a Banach algebra under the total variation norm, and multiplication is defined to be convolution of measures,
    %
    \[ (\nu * \eta)(E) = \int \chi_E (tu^{-1}) d \nu(t) d\eta(u) \]
\end{example}

All examples above have commutative algebra structures. One of the prime reasons to study Banach algebras is to study operators on a Banach space, which are almost always non-commutative. In fact, some folks call the study of operator algebras `non-commutative analysis'.

\begin{example}
    Let $E$ be a Banach space. The space $B(E)$ of all bounded linear operators from $E$ to itself is a Banach algebra with respect to the operator norm. Our theorem above essentially says every Banach algebra is a closed subalgebra of this kind of space. It is a unital algebra, since it possesses the identity operator. The subset $K(E)$ of compact linear operators is a closed (double-sided) ideal of $B(E)$, and so is also a Banach algebra. $K(E)$ is a unital algebra if and only if $E$ is finite dimensional.
\end{example}

The abstraction to Banach algebras is justified since we may talk about many classes of linear operators at once. Now to begin the Spectral theory. We shall restrict our attention almost everywhere to algebras over $\mathbf{C}$ because we may apply the deep and beautiful properties of holomorphic functions,

\begin{definition}
    The {\bf spectrum} and {\bf resolvent} of an element $M$ of a Banach algebra $A$ are defined respectively as
    %
    \[ \sigma_{A}(M) = \{ \lambda \in \mathbf{C} : \lambda - M \not \in U(A) \} \]
    %
    \[ \rho_{A}(M) = \{ \lambda \in \mathbf{C} : \lambda - M \in U(A) \} \]
    %
    The resolvent is the complement of the spectrum.
\end{definition}

\begin{example}
    Let $X$ be a space, and consider $f \in C_b(X)$. Then $\sigma_{C_b(X)}(f) = \overline{f(X)}$. If $\lambda \in \rho_{C_b(X)}(f)$, then
    %
    \[ (\lambda - f)^{-1}(x) = \frac{1}{\lambda - f(x)} \]
    %
    This continuous function is bounded if and only if $\lambda \not \in \overline{f(X)}$.
\end{example}

\begin{example}
    Consider a Banach space $E$. $T \in B(E)$ is invertible if and only if it is bijective, by the inverse mapping theorem. If $\dim(E) < \infty$, this is the set of injective operators. The spectrum is then exactly the set of eigenvalues of the operator. One can consider eigenvalues in the infinite operator, yet they are almost always a proper subset of the spectra.
\end{example}

\section{Spectral Theory}

\begin{definition}
    The {\bf point spectra} of an element $\Lambda \in B(V)$, where $V$ is an Banach algebra over $\mathbf{F}$, is
    %
    \[ \sigma_p(M) = \{ \lambda \in \mathbf{F} : \ker(\lambda I - M) \neq \{ 0 \} \} \]
    %
    If $\lambda \in \sigma_p(M)$, there is $v \in V$, $v \neq 0$, with $\Lambda v = \lambda v$. $v$ is known as an {\bf eigenvector}.
\end{definition}

\begin{lemma}[Neumann Series]
    If $M \in B_{A}$, then $1 - M \in U(A)$, and
    %
    \[ (1 - M)^{-1} = \sum_{k = 0}^\infty M^k \]
    %
    in the sense that the right hand side converges and satisfies the equality.
\end{lemma}
\begin{proof}
    The right side converges absolutely by the comparison test, since $\| M^k \| \leq \| M \|^k$. Since $A$ is Banach, the right side converges, and
    %
    \[ (1 - M) \sum_{k = 0}^\infty M^k = \sum_{k = 0}^\infty (1 - M)M^k = \sum_{k = 0}^\infty M^k - M^{k+1} = \lim_{n \to \infty} 1 - M^{n+1} \]
    %
    As $n \to \infty$, $M^{n+1} \to 0$, so the limit above tends to one. We may repeat this argument by multiplying on the right hand side, which shows the sum truly is the inverse.
\end{proof}

\begin{corollary}
    If $\| 1 - M \| < 1$, then $M \in U(A)$, and
    %
    \[ M^{-1} = \sum_{k = 0}^\infty (1 - M)^k \]
\end{corollary}
\begin{proof}
    Apply the theorem above, with $M$ replaced with $1 - M$.
\end{proof}

\begin{corollary}
    $U(A)$ is an open subset of $A$.
\end{corollary}
\begin{proof}
    If $M \in U(A)$, and if $\| M - N \| < 1/\| M^{-1} \|$, then 
    %
    \[ \| 1 - M^{-1}N \| \leq \| M^{-1} \| \| M - N \|  < 1 \]
    %
    so $M^{-1}N \in U(A)$, and thus $N \in U(A)$.
\end{proof}

\begin{corollary}
    $\sigma(M)$ is a closed subset of $\mathbf{F}$, and $\rho(M)$ is open.
\end{corollary}
\begin{proof}
    The map $f: \lambda \mapsto \lambda - M$ is a continuous operation, for
    %
    \[ \| (\lambda - M) - (\mu - M) \| = \| \lambda - \mu \| = | \lambda - \mu | \]
    %
    Since $U(A)$ is open, $f^{-1}(U(A)) = \rho(M)$ is open.
\end{proof}

\begin{theorem}
    $\sigma(M)$ is a compact subset of $A$.
\end{theorem}
\begin{proof}
    If $|\lambda| > \|M\|$, then $\| M/\lambda \| < 1$, so $(1 - M/\lambda) \in U(A)$, which means $\lambda - M$ is also invertible. Thus $\sigma(A)$ is closed and bounded, hence compact.
\end{proof}

We shall see that the spectra of a complex linear operator never has an empty spectra. This is why we mainly study $\mathbf{C}$-algebras, rather than $\mathbf{R}$-algebras -- there are even finite dimensional real operators with empty spectra (take a rotation matrix).

\begin{lemma}
    Inversion in an operator algebra $A$ is continuous.
\end{lemma}
\begin{proof}
    Let $(M_n)$ be a sequence in $U(A)$ converging to an invertible element $M$. Then, by continuity, $M_nM^{-1} \to 1$. If $\| 1 - M_n M^{-1} \| < 1/2$, then
    %
    \[ M_n^{-1} M = (M^{-1}M_n)^{-1} = \sum_{k = 0}^\infty (1 - M^{-1}M_n)^k \]
    %
    It follows that
    %
    \begin{align*}
        \| M_n^{-1} \| \leq \| M^{-1} \| \| M M_n^{-1} \| \leq \| M^{-1} \| &\sum_{k = 0}^\infty \| (1 - M_nM^{-1})^k \|\\
        &\leq \| M^{-1} \| \sum 2^{-k} = 2 \| M^{-1} \|
    \end{align*}
    %
    Finally, we obtain convergence of inverses,
    %
    \[ \| M_n^{-1} - M^{-1} \| = \| M_n^{-1} (M - M_n) M^{-1} \| \leq \overbrace{\| M_n^{-1} \|}^{\leq 2 \| M^{-1} \|} \overbrace{\| M - M_n \|}^{\to 0} \overbrace{\| M^{-1} \|}^{\text{constant}} \to 0 \]
    %
    so inversion is continuous.
\end{proof}

We can now prove the fundamental theorem of spectral theory, after a brief interlude with complex analysis.

\begin{definition}
    The resolvent of $M$, defined on $\rho(M)$, is the map
    %
    \[ R(z; M) = (A - zI)^{-1} \]
\end{definition}

\begin{lemma}
    $R$ is analytic, in that $\langle \phi, R(\cdot, M) \rangle$ is analytic for each $\phi \in A^*$.
\end{lemma}
\begin{proof}
    Let $f = \langle \phi, R(\cdot, M) \rangle$. Then
    %
    \begin{align*}
        \frac{f(\lambda + h) - f(\lambda)}{h} &= \frac{\langle \phi, (\lambda + h - a)^{-1} - (\lambda - a)^{-1} \rangle}{h}\\
        &= \frac{\langle \phi, (\lambda + h - a)^{-1} (\lambda - a)^{-1} [(\lambda - a) - (\lambda + h - a)] \rangle}{h}\\
        &= \langle \phi, -(\lambda + h - a)^{-1} (\lambda - a)^{-1} \rangle
    \end{align*}
    %
    As $h \to 0$, this tends to $\langle \phi, - (\lambda - a)^{-2} \rangle$, by continuity of inversion.
\end{proof}

In Banach theory, we call such a mapping {\bf weakly analytic}. A {\bf strongly analytic} function $f$ is then a mapping a subset of $\mathbf{C}$ to a Banach space such that the limit
%
\[ \lim_{h \to 0} \frac{f(z + h) - f(z)}{h} \]
%
exists at every point $z$ in the domain. By the chain rule, every strongly analytic function is weakly analytic. It is surprising that the converse also holds.

\begin{theorem}
    Every weakly analytic function $f$ into a Banach space $V$ is strongly analytic.
\end{theorem}
\begin{proof}
    Fix $\phi \in V^*$. Consider a particular contour winding counterclockwise around a point $w$ in the domain, which is at least a unit distance away from $w$ at any point on the contour. If $h,k \in \mathbf{C}$ are small enough that $w + h$ and $w + k$ are contained within the contour, then by the Cauchy integral theorem,
    %
    \begin{align*}
        \left\langle \phi, \frac{1}{h-k} \left[ \frac{f(w + h) - f(w)}{h} - \frac{f(w + k) - f(k)}{k} \right] \right\rangle\\
        = \frac{1}{2\pi i} \int_C \frac{\langle \phi, f(z) \rangle\ dz}{[z - (w + h)][z - (w + k)][z - w]}
    \end{align*}
    %
    Find $\delta$ such that if $\| h \| < \delta$, the distance between any point on $C$ and $w + h$ is greater than $1/2$. Then, if $M$ is the length of $C$, and $K$ is the supremum of $f$ on $C$, then
    %
    \[ \left| \frac{1}{2\pi i} \int_C \frac{\langle \phi, f(z) \rangle\ dz}{[z - (w + h)][z - (w + k)][z - w]}\right| \leq \frac{4MK}{2 \pi} \| \phi \| = \frac{2MK}{\pi} \| \phi \| \]
    %
    Applying the Banach Steinhaus theorem (on $X^*$, viewing elements of $X$ as elements of $X^{**}$), we conclude that for all $h,k$ sufficiently small, there exists $D$ such that
    %
    \[ \left| \frac{f(w + h) - f(w)}{h} - \frac{f(w + k) - f(k)}{k} \right| \leq D |h - k| \]
    %
    By the completeness of $V$, the quotients of $h$ and $k$ converge to a well defined quantity as $h - k$ converges to zero.
\end{proof}

There is a deep relationship between complex analysis and Banach algebras. We shall return to `holomorphic functional analysis' later.

\begin{theorem}
    Points of a complex Banach algebra has nonempty spectrum.
\end{theorem}
\begin{proof}
    Assume $\sigma(M)$ is empty. Then $\lambda - M$ is always invertible, for all $\lambda \in \mathbf{C}$. Fix an arbitrary $\phi \in A^*$. Then $f = \langle \phi, R(\cdot, M) \rangle$ is an entire function. What's more, $f$ is bounded, since, as $\lambda \to \infty$,
    %
    \[ | \langle \phi, (\lambda - M)^{-1} \rangle | \leq \| \phi \| \| (\lambda - M)^{-1} \| = \| \phi \| \left\| \sum_{k = 0}^\infty \frac{M^k}{\lambda^{k+1}} \right\| \to 0 \]
    %
    Which implies that $f$ is constant, and since it converges to zero at infinity, $f = 0$. In particular, this means that $\langle \phi, M^{-1} \rangle = 0$. But this contradicts the Hahn-Banach theorem, which says that for any non-zero element of a banach space there exists a bounded linear functional non-zero at the element. Hence $\sigma(M)$ must be non-empty.
\end{proof}

A cute little theorem results from this property of Banach algebras.

\begin{corollary}
    Every complex Banach division algebra is isometric to $\mathbf{C}$.
\end{corollary}
\begin{proof}
    Let $A$ be a complex division algebra, and fix $M \in A$. Pick some $\lambda \in \sigma(A)$. Then $\lambda - M \not \in U(A)$, hence $\lambda - M = 0$, i.e. $M = \lambda$. Thus $A = \mathbf{C} \cdot 1 \cong \mathbf{C}$.
\end{proof}

The real case is much more complicated. There are three real division algebras: $\mathbf{R}$, $\mathbf{C}$, and $\mathbf{Q}$ (the quaternions).

\begin{definition}
    The {\bf spectral radius} of an element $M \in A$ is defined to be
    %
    \[ r(M) = \sup \{ |\lambda| : \lambda \in \sigma(M) \} \]
\end{definition}

What is amazing is that we can define the spectral radius without any reference to the spectrum -- this is crazy, since if we enlarge our Banach algebra, more elements in the spectrum become invertible and are removed. Regardless, the supremum of the non-invertible elements will stay the same. To show this, we first prove a lemma

\begin{lemma}
    Let $M \in A$, $n \in \mathbf{N}$. Then, if $\lambda \in \sigma(M)$, $\lambda^n \in \sigma(M^n)$.
\end{lemma}
\begin{proof}
    Suppose $\lambda \in \sigma(M)$. Then
    %
    \[ \lambda^n - M^n = (\lambda - M) \left(\sum \lambda^{n-1-k} M^k \right) = \left(\sum \lambda^{n-1-k} M^k \right) (\lambda - M) \]
    %
    If $\lambda^n - M^n$ was invertible, then $\lambda - M$ would also be invertible.
\end{proof}

\begin{theorem}[Spectral Radius Theorem]
    \[ r(a) = \lim_{n \to \infty} \| a^n \|^{1/n} \]
\end{theorem}
\begin{proof}
    Let $\lambda \in \sigma(M)$. Then $\lambda^n \in \sigma(M^n)$. Thus $|\lambda|^n \leq \| M^n \|$, hence
    %
    \[ |\lambda| \leq \| M^n \|^{1/n} \]
    %
    Thus $r(M) \leq \| M^n \|^{1/n}$, so $r(M) \leq \liminf_{n \to \infty} \| M^n \|^{1/n}$.

    Set $R = 1/r(M)$ (which can be $\infty$, if $r(M) = 0$), and $r = 1/\|M\|$. Let $\lambda$ be a complex number with modulus less than $R$. Then $1/|\lambda| > r(M)$, so $1 - \lambda M \in U(A)$. If $\phi \in A^*$, define the function
    %
    \[ f: \lambda \mapsto \langle \phi, (1 - \lambda M)^{-1} \rangle \]
    %
    Then $f$ is holomorphic in the disk of radius $R$, as we have already verified. If $\lambda$ has radius less than $r$, then $\| \lambda M \| < 1$, $1 - \lambda M \in U(A)$, and
    %
    \[ \langle \phi, (1 - \lambda M)^{-1} \rangle = \sum_{k = 0}^\infty \langle \phi, M^k \rangle \lambda^k \]
    %
    %
    but power series expansions are unique, hence this expansion should work in the whole disk of radius $R$. But $\phi$ was arbitrary, so the sequence $\lambda^k M^k$ must be bounded. If $\lambda$ is fixed, then there is $C$ such that
    %
    \[ |\lambda^k| \|M^k\| \leq C \]
    %
    So
    %
    \[ \|M^k\|^{1/k} \leq \frac{C^{1/n}}{\lambda} \]
    %
    Hence $\limsup \|M^k\|^{1/k} \leq \frac{1}{\lambda}$. Letting $\lambda \to R$, we obtain that $\limsup \|M^k\|^{1/k} \leq r(a)$. We have shown $\liminf \|M^k\|^{1/k} = r(M) = \limsup \|M^k\|^{1/k}$, from which the theorem follows.
\end{proof}

\begin{corollary}
    If $A$ is an algebra, and $B$ a closed subalgebra both containing $M$, then $r_{A}(M) = r_B(a)$.
\end{corollary}

\begin{example}
    We can isometrically embed $A(\mathbf{D})$ in $C_0(\mathbf{T})$ via the map $f \mapsto f|_\mathbf{T}$. The fact that this is an isometry follows from the maximum modulus principle. Let $z: \mathbf{T} \to \mathbf{C}$ be the identity map. Then $\sigma_{A(\mathbf{D})}(z) = \mathbf{D} \supsetneqq \mathbf{T} = \sigma_{C_0(\mathbf{T})}(z|_\mathbf{T})$.
\end{example}

\begin{theorem}
    Let $A \subset B$ be Banach algebras, both containing an element $M$. Then $\sigma_B(M) \subset \sigma_B(M)$, and if $\lambda \in \sigma_A(M) \cap \rho_B(M)$, then the connected component of $\lambda$ in $\rho_B(M)$ is contained in $\sigma_A(M)$.
\end{theorem}
\begin{proof}
    Let $V$ be a component of $\rho_B(M)$. Obviously, $V \cap \rho_A(M)$ is open in $V$, since $\rho_A(M)$ is open. But $V \cap \rho_A(M)$ is also closed, for if $\lambda_n \in V \cap \rho_A(M)$ converges to $\lambda \in V$, then $\lambda_n - M \in U(A)$ converges to $\lambda - M \in U(B)$, then $\lambda - M \in U(A)$, since $A$ is a closed subalgebra, and $(\lambda_n - M)^{-1} \to (\lambda - M)^{-1}$. A non-empty open and closed subset of a connected space is either empty or the entire space. It follows that if $V \cap \sigma_A(M) \neq \emptyset$, then $V \subset \sigma_A(M)$.
\end{proof}

\begin{corollary}
    If $A \subset B$ are algebras, with $\sigma_B(M) \subset \mathbf{R}$, then $\sigma_A(M) = \sigma_A(M)$.
\end{corollary}
\begin{proof}
    If $\sigma_B(M)$ is a bounded subset of $\mathbf{R}$, so $\rho_B(M)$ is connected in $\mathbf{C}$. Hence $\sigma_A(M) = \sigma_B(M)$, since $\sigma_A(M) \neq \mathbf{C}$.
\end{proof}

\section{Gelfand Theory}

Gelfand realized that all commutative Banach algebras were really just spaces of continuous functions in disguise. This has incredibly important repurcussions which we will get to. The main part of Gelfand's theory is the connection between homomorphisms and maximal ideals -- an additive subgroup of the ring closed under multiplication by any element of the algebra, and under scalar multiplication by elements of a field. An arbitrary ideal of a algebra shall be denoted by gaudy letters near the beginning of the alphabet, like $\mathfrak{a}$ and $\mathfrak{b}$. We note that no proper ideal contains invertible elements in a ring, and that every ring possesses some maximal ideal (appealing to some method of transfinite induction). We first deal with some not-necessarily commutative theorems.

\begin{lemma}
    If $\| M \| \leq 1$, then $|f(M)| \leq 1$ for every (non necessarily) complex homomorphism $f: A \to \mathbf{C}$.
\end{lemma}
\begin{proof}
    The kernel of every homomorphism cannot be all of $A$, and it is certainly an ideal of $A$. Therefore the kernel cannot contain any invertible elements. If $f(M) = \lambda$, then $\lambda - M \in \ker(M)$, so that $\lambda - M$ is not invertible, which, from our discussion of the spectrum of $M$, we determine that $|\lambda| < 1$.
\end{proof}

\begin{corollary}
    Every algebraic functional (from $A$ to $\mathbf{C}$) is continuous.
\end{corollary}

\begin{lemma}
    Every maximal ideal of a Banach algebra is closed.
\end{lemma}
\begin{proof}
    Let $\mathfrak{a}$ be a maximal ideal of an algebra $A$. It is easy to show the closure of any ideal is an ideal. It follows that either $\overline{\mathfrak{a}} = \mathfrak{a}$ (so that $\mathfrak{a}$ is closed), or $\mathfrak{a}$ is dense in $A$. Suppose the second option holds. Let $a \in U(A)$ be chosen. Then there is $a_i \in \mathfrak{a}$ converging to $a$. But then the $a_i$ are eventually invertible, since $U(A)$ is open, from which we conclude $\mathfrak{a} = A$, a contradiction.
\end{proof}

Next, we consider the notion of a continuous homomorphism between two algebras $A$ and $B$, which is a map which is both linear and a ring homomorphism (we note that this means that no homomorphism can be zero). The first isomorphism theorem holds in such a space, and preserves completeness. If $f:A \to B$ is a continuous homomorphism from a Banach algebra $A$ to a normed algebra $B$, then $K$ is a closed ideal in $A$ contained within the kernel of $f$, so that $A/K$ is also a Banach space, then there is a continuous map $\overline{f}$ from $A/K$ to $B$ such that the standard diagram commutes. If $K = \ker(f)$, the map is injective, and therefore is an Banach algebra isomorphism if it is surjective.

\begin{lemma}
    Every maximal ideal of $A$ is the kernel of some complex homomorphism, and correspondingly, the kernel of every complex homomorphism is a maximal ideal.
\end{lemma}
\begin{proof}
    If $\mathfrak{a}$ is a maximal ideal, then $\mathfrak{a}$ is closed, so $A/\mathfrak{a}$ is a complex Banach algebra. But $A/\mathfrak{a}$ is also a division ring, so is really just $\mathbf{C}$ in disguise. The map $\phi: A \to A/\mathfrak{a} \cong \mathbf{C}$ is then a complex homomorphism we require. Conversely, let $\phi: A \to \mathbf{C}$ be a homomorphism. Then $\phi$ is surjective, for $\phi(\mathbf{C} \cdot 1) = \mathbf{C}$. Then if $K = \ker(f)$, $A/K \cong \mathbf{C}$, and thus $K$ is maximal.
\end{proof}

\begin{lemma}
    $M \in U(A)$ if and only if $\phi(M) \neq 0$ for all complex homomorphisms $\phi$.
\end{lemma}
\begin{proof}
    If $M \in U(A)$, we know $\phi(M) \neq 0$ for all $\phi \in \Phi_A$, for otherwise $\ker(\phi)$ would contain an invertible element. Conversely, if $M \not \in U(A)$, then $M$ is contained in a maximal ideal $\mathfrak{a}$, and the projection $\phi: A \to A/\mathfrak{a}$ is non-zero at $M$, and we have an algebra isomorphism from $A/\mathfrak{a}$ to $\mathbf{C}$ by Gelfand-Mazur, which does not enlarge the kernel.
\end{proof}

\begin{corollary} \label{spectralhomomorphism}
    In a commutative algebra, $\lambda \in \sigma(M)$ if and only if $\phi(M) = \lambda$ for some complex homomorphism $\phi$.
\end{corollary}

The key to Gelfand theory is noticing that homomorphisms of commutative Banach algebras naturally reflect the structure of the Banach algebra in question.

\begin{definition}
    For a commutative algebra $A$, the {\bf character space} $\Phi_A$ is the set of all maximal ideals of the algebra, or, correspondingly, as we shall see, the set of all algebraic functionals from $A$ to $\mathbf{C}$. We assign to each $M \in A$ the {\bf gelfand transform} $\widehat{M}: \Phi_A \to \mathbf{C}$, which is defined by $\widehat{M}(\phi) = \phi(M)$. The {\bf Gelfand topology} is the weakest topology which makes each $\widehat{M}$ continuous.
\end{definition}

\begin{lemma}
    The mat $M \mapsto \widehat{M}$ is an algebra homomorphism into $C(\Phi_A)$, whose kernel is the {\bf Jacobson radical}, the intersection of all maximal ideals. Thus the map is an isomorphism if and only if the algebra is semisimple. We have $\widehat{M}(\Phi_A) = \sigma(M)$.
\end{lemma}
\begin{proof}
    By direct calculation,
    %
    \[ \widehat{MN}(\phi) = \phi(MN) = \phi(M) \phi(N) = (\widehat{M} \widehat{N})(\phi) \]
    %
    If $\widehat{M} = 0$, then $\phi(M) = 0$ for all $\phi$. Thus $M$ is contained in every maximal ideal. The converse is equally trivial. That $\widehat{M}(\Phi_A) = \sigma(M)$ follows from Corollary \ref{spectralhomomorphism}.
\end{proof}

It was Gelfand's idea to surplant the character spaces with a topological structure. This is the Gelfand topology of the character space. We shall now deduce its structure.

\begin{theorem}
    The Gelfand topology makes $\Phi_A$ into a compact, Hausdorff space.
\end{theorem}
\begin{proof}
    The Gelfand topology has less open sets than the relatively induced weak * topology. This implies that it is compact, if it is compact in the weak * topology. We need only verify that $\Phi_A$ is weak * closed in $A^*$, since $\Phi_A$ is contained in the unit ball by the operator norm, which is weak * compact, by the Banach-Alaoglu theorem. Let $\Lambda$ be in the weak* closure of $\Phi_A$. We must show that it is a complex homomorphism. Fix $x,y \in A$, $\varepsilon > 0$. Consider
    %
    \[ W = \{ \psi \in A^* : | \psi - \Lambda | (z) < \varepsilon\ \text{for}\ z \in \{ 1, x, y, xy \} \} \]
    %
    Then $W$ is a weak* neighbourhood of $\Lambda$, and contains some $\phi \in \Phi_A$. Thus
    %
    \[ | 1 - \Lambda(1) | < \varepsilon \]
    %
    so that $\Lambda(1) = 1$, since $\varepsilon$ was arbitrary. Furthermore,
    %
    \begin{align*}
        \Lambda(xy) -   \Lambda(x) \Lambda(y) &= [\Lambda(xy) - \phi(xy)] + [\phi(x)\phi(y) - \Lambda(x)\Lambda(y)]\\
        &= [\Lambda(xy) - \phi(xy)] + [\phi(y) - \Lambda(y)] \phi(x)\\
        &\ \ \ + [\phi(x) - \Lambda(x)] \phi(y)
    \end{align*}
    %
    Hence, since $\phi$ is a complex homomorphism,
    %
    \[ | \Lambda(xy) -   \Lambda(x) \Lambda(y) | < (1 + |\phi(x)| + |\phi(y)|) \varepsilon \leq 3 \varepsilon \]
    %
    Letting $\varepsilon \to 0$, we obtain that $\Lambda$ is a complex homomorphism, and thus $\Phi_A$ is compact.
\end{proof}

The next lemma is part of classical harmonic analysis. It was proved in an extremely convoluted way by Norbert Weiner. With Gelfand's theory, the proof was shortened to a two-liner.

\begin{lemma}[Wiener's Lemma]
    Consider a function which admits a Fourier expansion
    %
    \[ f(z) = \sum_{n = -\infty}^\infty a_n z^n \]
    %
    If $\sum_{-\infty}^\infty |a_n| < \infty$, and if $f(z) \neq 0$ for all $z \in \mathbf{T}$, then $1/f$ also admits a Fourier expansion, and it coefficients converge absolutely.
\end{lemma}
\begin{proof}
    Let $A$ be the set of all functions with absolutely convergent Fourier expansions. If we define $\| f \| = \sum |a_i|$, then $A$ is a commutative Banach algebra, for if
    %
    \[ f(z) = \sum_{n = -\infty}^\infty a_n z^n\ \ \ \ \ g(z) = \sum_{n = -\infty}^\infty b_n z^n \]
    %
    Then
    %
    \[ (fg)(z) = \sum_{n = -\infty}^\infty \left ( \sum_{m = -\infty}^\infty a_m b_{n-m} \right) z^n \]
    %
    and
    %
    \begin{align*}
        \sum_{n = -\infty}^\infty \left| \sum_{m = -\infty}^\infty a_m b_{n-m} \right| &\leq \sum_{n,m = -\infty}^\infty |a_n b_m| = \left( \sum_{n = -\infty}^\infty |a_n| \right) \left( \sum_{m = -\infty}^\infty |b_m| \right)
    \end{align*}
    %
    The space is complete, since it is essentially just $l_1(\mathbf{Z})$.

    The map $f \mapsto f(w)$ is a complex homomorphism, for each $w \in \mathbf{T}$. We wish to show that these are the only such homomorphisms, so that $f$ is invertible if and only if it does not equal 0 at any point. If $z$ denotes the identity function, then it has norm 1, as does its inverse $1/z$. This implies that $|\phi(z)| \leq 1$ for any $\phi \in \Phi_A$, and that $|1/\phi(z)| = |\phi(1/z)| \leq 1$. Thus $\phi(z) = z(w) = w$, for some $w \in \mathbf{T}$. If $P = \sum_{k = -n}^m a_k z^k$ is a trigonometric polynomial function, it follows that $\phi(P) = P(w)$. But the trigonometric polynomials are dense in $A$, so we have proved what was needed to be shown.
\end{proof}

The next theorem applies ideal theory to complex analysis.

\begin{lemma}
    Let $f_1, \dots, f_n \in A(\mathbf{D})$, and suppose that for each $z \in \mathbf{D}$ at least one of the $f_i$ satisfy $f_i(z) \neq 0$. Then there are $g_1, \dots, g_n \in A(\mathbf{D})$ such that $\sum f_i g_i = 1$.
\end{lemma}
\begin{proof}
    In other words, $(f_1, \dots, f_n) = A(\mathbf{D})$. If $(f_1, \dots, f_n)$ is not $A(\mathbf{D})$, then $(f_1, \dots, f_n)$ is annihilated by some $\phi \in \Phi_{A(\mathbf{D})}$. We have $\phi(z) = w$, for some $w \in \mathbf{D}$. Then $\phi(P) = P(w)$, as in the last proof. Polynomials are dense in the set of holomorphic functions, so that $\phi(f) = f(w)$ for all $f \in A(\mathbf{D})$. But then $f(w) = 0$ for all $f \in (f_1, \dots, f_n)$, a contradiction which proves the theorem. Runge's theorem can be used to extend the theorem in question to general domains in $\mathbf{C}$, but we leave this to the reader.
\end{proof}

We have embedded each commutative banach algebra $A$ in a commutative banach algebra $C(\Phi_A)$. What happens if we start with $A = C(K)$? The answer is pleasant, for once.

\begin{theorem}
    Let $K$ be a compact space. Then $K$ is homeomorphic to $\Phi_{C(K)}$, by the map $x \mapsto \phi_x$, where $\phi_x(M) = M(x)$.
\end{theorem}
\begin{proof}
    Clearly the map is continuouse and injective, and will be a homeomorphism if it is verified surjective. Suppose it isn't surjective. Then there is a maximal ideal $M$ which isn't the kernel of any $\phi_x$. In particular, this implies that the kernel of $M$ cannot be contained in the kernel of any $\phi_x$. For each $x \in X$, there is $f_x \in M$ with $f_x(x) \neq 0$. Let $U_x = \{ y \in K : f_x(y) \neq 0 \}$. Then $U_x$ is an open cover of $K$. Then $K$ is compact, so there are $x_1, \dots, x_n$ with $K = \bigcup_{i = 1}^n U_{x_i}$. Let
    %
    \[ f = \sum |f_{x_i}| = \sum f_{x_i} \overline{f_{x_i}} \]
    %
    Then $f$ is invertible, yet is in $M$, a contradiction.
\end{proof}



\section{Holomorphic Functional Calculus}

We now have the ability to extend single variate complex analysis, and maps from $\mathbf{C}$ to complex Banach algebras. Complex analysis begins with an analysis of polynomials $P \in \mathbf{C}[X]$, mapping $M \in A$ to $P(M)$. We don't need anything topological here, and we may extend maps to general spaces. However, we do need topology to consider power series. For instance, we define the exponential of $M \in A$ by
%
\[ e^M = \sum_{k = 0}^\infty \frac{M^k}{k!} \]
%
We may define $\sin$ and $\cos$ similarily. More generally, for any power series $f = \sum_{k = 0}^\infty c_k (X - \alpha)^k$ with a radius of convergence $R$, we may define
%
\[ f(M) = \sum_{k = 0}^\infty c_k (M - \alpha)^k \]
%
And this function is defined for any $M$ satisfying $\|M - \alpha \| < R$. It is non-trivial to `overload' arbitrary analytic functions, which is the topic of this section.

We shall use the formulation of complex analysis in terms of chains, arbitrary finite `integer combinations' of differentiable curves $\gamma = \sum n_i \gamma_i$, where we let $- \gamma_i = \gamma_i^{-1}$ in the path homotopic sense (what we are really doing is considering the free abelian group $\mathbf{Z}\langle C^\infty(\mathbf{R}, \mathbf{C}) \rangle$, modulo the relation $- \gamma = \gamma^{-1}$). The trace of a curve will be its image,
%
\[ \text{tr}(\sum n_i \gamma_i) = \bigcup_{n_i \neq 0} \text{Im}(\gamma_i) \]
%
If $f$ is a function defined on $\text{tr}(\gamma)$, and $\gamma_i$ is defined on $[a_i, b_i]$ we define the integral
%
\[ \int_\gamma f(z) dz = \sum n_i \int_{\gamma_i} f(z) dz = \sum_i n_i \int_{a_i}^{b_i} (f \circ \gamma_i) \gamma_i' \]
%
The first property of importance to note is that Riemann integrals can be defined on functions from an interval to any Banach space. Provided the function is continuous, the integral will exist.

If $\gamma$ is a chain in $\mathbf{C}$, and $a \in E$ is given, then we define the {\bf index} of $\gamma$ with respect to $x$, denoted $\text{Ind}_a \gamma$, to be the value
%
\[ \frac{1}{2 \pi i} \int_\gamma \frac{dz}{z - a} \]
%
A chain $\gamma$ is {\bf positively oriented} if $\text{Ind}_a \gamma \in \{ 0, 1 \}$ for each $a \in \mathbf{C}$.

\begin{lemma} \label{banachcauchy}
    If $D$ is open, $f: D \to E$ is a holomorphic function into a Banach space, and $\gamma$ satisfies $\text{Ind}_z \gamma = 0$ for all $z \not\in D$, then $\int_\gamma f(z) dz = 0$.
\end{lemma}
\begin{proof}
    Take $\phi \in E^*$. The Riemann integral of a curve $\gamma: [a,b] \to E$ can be defined as the limit of the net
    %
    \[ \lim \sum_k \gamma(x_k) (x_k - x_{k-1}) \]
    %
    But since $\phi$ is continuous,
    %
    \begin{align*}
        \phi \left( \int_\gamma f(z) dz \right) &= \phi \left(\lim \sum_k \gamma(x_k) (x_k - x_{k-1}) \right) = \lim \sum_k \phi(\gamma(x_k)) (x_k - x_{k-1})\\
        &= \int (\phi \circ f)(z) dz
    \end{align*}
    %
    And this holds by linearity for arbitrary chains. Since $f$ is holomorphic in $D$, so is $\phi \circ f$. Applying Cauchy's theorem, we obtain that
    %
    \[ \phi \left( \int_\gamma f(z) dz \right) = 0 \]
    %
    Since $\phi$ was arbitrary, we must have
    %
    \[ \int_\gamma f(z) dz = 0 \]
    %
    By the Hahn-Banach theorem.
\end{proof}

We shall call a collection of chains $\{ \gamma_1, \dots, \gamma_n \}$ {\bf positively oriented} if the trace of $\gamma_i$ is disjoint from $\gamma_j$ for $i \neq j$, and if, letting $\gamma = \sum \gamma_i$, $\text{Ind}_w \gamma \in \{ 0,1 \}$ for all $w \in \mathbf{C}$. We shall let
%
\begin{align*}
    \text{Int}(\gamma) = \{ w \in \mathbf{C} : \text{Ind}_w \gamma = 1 \} \\
    \text{Ext}(\gamma) = \{ w \in \mathbf{C} : \text{Ind}_w \gamma = 0 \}
\end{align*}
%
Each is the union of connected components in $\mathbf{C} - \text{tr}(\gamma)$.

\begin{lemma}
    Let $D$ be an open set, and $K$ a compact subset. There is a positively oriented chain whose interior contains $D$, and whose exterior contains $D^c$.
\end{lemma}
\begin{proof}
    Split $D$ into its connected components. It suffices to prove the theorem assuming $D$ is a component. Let $\varepsilon = d(K,D^c)$. Then $\varepsilon > 0$, since $K$ is disjoint from $\varepsilon$. Let $G$ be a set of positively oriented squares (a chain consisting of the sum of four clockwise lines), whose interior lies in $D$, and whose vertices are elements of the product $\mathbf{Z}/n \times \mathbf{Z}/n$, where $n > \varepsilon / 2$. If we let $\gamma = \sum_{g \in G} g$, then by construction, $\text{Ind}_z \gamma = 0$ for all $z \in D^c$, and since the interiors of the squares are disjoint, the winding number around each point in $K$ is 1. By construction, we have found a required chain.
\end{proof}

We shall temporarily say that such a chain has the $(K,D)$ separation property. We can now extend holomorphic functions to arbitrary algebras, by artificially introducing the cauchy integral theorem into the algebra.

\begin{definition}
    Let $A$ be a Banach algebra, consider an element $M \in A$, $D$ an open set containing all of $\sigma(M)$, and $f:D \to A$ a holomorphic function. Let $\gamma$ be a positively oriented curve satisfying the $(\sigma(M), D)$ separation property, with $\sigma(M) \subset \text{Int}(\gamma)$. Define
    %
    \[ f(M) = \int_\gamma f(z) (z - M)^{-1} dz \]
    %
    Then the extension of $f$ is a well-defined holomorphic function.
\end{definition}

Of course, we cannot just say the definition is well defined

\begin{lemma}
    Let $D$ be an open set. If $f: D \to \mathbf{C}$ is holomorphic, and $\gamma, \lambda$ be two chains in $D$ satisfying the $(\sigma(M), D)$ separation property. When $f: D \to A$ is holomorphic, then
    %
    \[ \int_\gamma f(z) (z - M)^{-1} dz = \int_\lambda f(z) (z - M)^{-1} dz \]
\end{lemma}
\begin{proof}
    Then $\gamma - \lambda$ has winding number zero around any point in $\sigma(M)$ and $D^c$, and we have already verified this case in lemma \ref{banachcauchy}.
\end{proof}

We have laid the foundations for the holomorphic functional calculus.

\begin{theorem}
    The map $f \mapsto f(M)$ is an algebra homomorphism from $\mathcal{O}(D)$ into $A$, which is really just evaluation for polynomials, and is continuous in the locally uniform topology.
\end{theorem}
\begin{proof}
    It can easily be verified (plagiarized from the proof in the real case) that uniform convergence preserves convergence of integration. The evaluation map is obviously linear, so we need only show the polynomial evaluation property for monomials $P = X^n$. Select a $(\sigma(M), D)$ chain $\gamma$ far away enough from the origin that we may express inverses in Neumann series. Then
    %
    \begin{align*}
        P(M) &= \frac{1}{2 \pi i} \int_\gamma z^n (z - M)^{-1} dz = \frac{1}{2 \pi i} \int_\gamma z^{n-1} \sum_{k = 0}^\infty \frac{M^k}{z^k} dz\\
        &= \frac{1}{2 \pi i} \sum_{k = 0}^\infty M^k \int_\gamma z^{n - 1 - k} dz = M^n
    \end{align*}
    %
    since $\int_\gamma z^{n-1-k} dz \neq 0$ only when $n - 1 - k = -1$ ($n = k$).

    Now we need to show the multiplicity of the evaluation map. This is done by brute calculation. Let $f,g \in \mathcal{O}(D)$ be given. Pick $\gamma$ be as required, and consider another $\tilde{\gamma}$ satisfying $\text{Int}\ \tilde{\gamma} \supset \overline{\text{Int}\ \gamma}$, $\mathbf{C} - D \subset \text{ext}\ \tilde{\gamma}$. Then
    %
    \begin{align*}
        f(M) g(M) &= \frac{-1}{4 \pi^2} \left( \int_\gamma f(z) (z - M)^{-1} dz \right) \left( \int_{\tilde{\gamma}} g(w) (w - M)^{-1} \right)\\
        &= \frac{-1}{4 \pi^2} \int_\gamma \int_{\tilde{\gamma}} f(z) g(w) (z - M)^{-1} (w - M)^{-1} dw\ dz\\
        &= \frac{-1}{4 \pi^2} \int_\gamma \int_{\tilde{\gamma}} f(z) g(w) \left( \frac{1}{w - z} \left((z - M)^{-1} - (w - M)^{-1} \right) \right) dw\ dz\\
        &= \frac{-1}{4 \pi^2} \int_\gamma f(z) \left( \int_{\tilde{\gamma}} \frac{g(w)}{w - z} dw \right) (z - M)^{-1} dz\\
        &\ \ \ + \frac{1}{4 \pi^2} \int_{\tilde{\gamma}} g(w) \left( \int_\gamma \frac{f(z)}{w - z} dz \right) (w - M)^{-1} dw\\
        &= \frac{1}{2 \pi i} \int_\gamma f(z) \left( \frac{1}{2 \pi i} \int_{\tilde{\gamma}} \frac{g(w)}{w - z} dw \right) (z - M)^{-1} dz\\
        &= \frac{1}{2 \pi i} \int_\gamma f(z) g(z) (z - M)^{-1} dz\\
        &= (fg)(M)
    \end{align*}
    %
    and thus we have an algebra homomorphism.
\end{proof}

In fact, we will show that this homomorphism is the unique one satisfying the properties. This would be trivial if $D = \mathbf{C}$, since we could expand all functions as limits of polynomials via their power series. To prove the theorem in general, we need an advanced theorem in complex analysis, Runge's theorem, which states that any function holomorphic in an open set $D$ is locally uniformly approximated by rational functions whose poles lay outside of $D$.

Now if $r_i$ is rational, and $\Lambda$ is a homomorphism such that $\Lambda P = P(M)$, then
%
\[ \Lambda (P/Q) = \Lambda(P) \Lambda(1/Q) = \Lambda(P) \Lambda(Q)^{-1} = P(M) Q(M)^{-1} = (P/Q)(M) \]
%
The homorphism is then uniquely defined, since the $r_i$ are dense in the set of all holomorphic functions.

\begin{example}
    Let $K$ be compact, and let $f \in C(K)$. Let $D$ be an open neighbourhood of $\sigma(f) = f(K)$. Consider the map from $\mathcal{O}(D) \to C(K)$ mapping $g$ to $g \circ f$. This map satisfies the properties of the holomorphic functional calculus, so it really is the holomorphic calculus in disguise.
\end{example}

\begin{theorem}
    Let $f:A \to B$ be a homomorphism between two Banach algebras, $M \in A$. Then $\sigma(f(M)) \subset \sigma(M)$, and if $g$ is holomorphic in a neighbourhood of $\sigma(M)$, then $(g \circ f)(M) = (f \circ g)(M)$.
\end{theorem}
\begin{proof}
    That $\sigma(f(M)) \subset \sigma(M)$ is trivial. If $g$ is a polynomial, then the theorem follows from the multiplicative property. But then the theorem is true for limits of polynomials, and hence for all $g$.
\end{proof}

\begin{corollary}
    If $D$ is a neighbourhood of $\sigma(M)$, and $f \in \mathcal{O}(f)$, then it follows that $\widehat{f}(M) = f \circ \widehat{M}$.
\end{corollary}

The ultimatum of the holomorphic functional calculus is the proof of the spectral mapping theorem, that asserts that the `operation' of the spectrum commutes with holomorphic functions. To extend this theorem to non-commutative algebras, we need an algebraic trick. We introduce the center $Z(A)$ of an algebra, which is defined exactly how it is defined in all other algebraic structures. It is a closed subalgebra of $A$, for if $M_i \to M$, and each $M_i \in A$, then
%
\[ MN = \lim M_iN = \lim NM_i = NM \]
%
If $S$ is a subset of $A$, then we may consider
%
\[ Z(S) = \{ M \in A : MN = NM \forall N \in S \} \]
%
which is also a closed subset of $A$. If $S$ is commutative, then $Z(Z(S))$ is commutative, for if $M$ and $N$ commutes with all elements in $Z(S)$, they certainly commute with all elements in $S$, so that $M,N \in S$, and $MN = NM$. Consider $Z(Z(\{ M \}))$. If $\lambda - M$ is invertible in $A$, there is $N = (\lambda - M)^{-1}$. But then if $K \in Z(\{ M \})$, then $K$ commutes with $\lambda - M$, and
%
\[ KN = N(\lambda - M) K N = (\lambda - M)^{-1} K (\lambda - M) N = NK \]
%
which implies that $\lambda - M$ is invertible in $Z(Z(\{M\}))$, so $\sigma_A(M) = \sigma_{Z(Z(\{M\}))}(M)$.

\begin{theorem}[Spectral Mapping Theorem]
    If $\sigma(M) \subset D$, with $D$ open, and $f \in \mathcal{O}(D)$, then $\sigma(f(M)) = f(\sigma(M))$.
\end{theorem}
\begin{proof}
    First, suppose $A$ is commutative. By Gelfand theory,
    %
    \[ \sigma(f(M)) = \widehat{f}(M) = f(\hat{M}) = f(\sigma(M)) \]
    %
    If $A$ is not commutative, consider $Z(Z(\{M\}))$. Then $\sigma(M) \subset Z(Z(\{M\}))$, and we may apply the thorem in the commutative case.
\end{proof}





\section{Banach Algebras Without Identity}

We shall now treat Banach algebras without identities. The reason for this is that such objects naturally appear in analysis. If $X$ is not compact, then $C_0(X)$ does not contain an identity. Though we have noted that there is almost always a natural trick for adding an identity, it is psychologically relieving to treat the case separately.

There is always a trick to add an identity to a banach algebra $A$, though it is abstract, since it applies to all algebras. We consider $A \ltimes \mathbf{C}$, with a multiplicative structure
%
\[ (M + \lambda)(N + \gamma) = MN + \lambda N + \gamma M + \lambda \gamma \]
%
Then we have an identity $0 + 1$, and the space considered still satisfies the properties that make it a Banach algebra if we surplant a norm
%
\[ \| M + \lambda \| = \| M \| + |\lambda| \]
%
If $M_i + \lambda_i$ is a cauchy sequence, then $M_i$ and $\lambda_i$ are both separately cauchy sequences, and therefore converge to a well defined quantity, which also converges in the abstract norm. We may then define $\sigma_A(M) = \sigma_{A \ltimes \mathbf{C}}(M)$. The fundamental theorem of spectral theory still applies, as does the spectral radius formula.

In the Gelfand theory, we have a little trouble defining ideals. We can an ideal $\mathfrak{a}$ (an additive subgroup closed under multiplication) for a commutative algebra without identity $A$ {\bf modular} if there is $N \in A$ such that $MN - M \in \mathfrak{a}$ for all $M \in A$. Equivalently, this follows if $A/\mathfrak{a}$ contains an identity. We may consider maximal modular ideals as well. We need to edit the proof which shows a maximal ideal is closed, which again relies on an algebraic trick.

\begin{lemma}
    A maximal modular ideal in an algebra $A$ is closed.
\end{lemma}
\begin{proof}
    If a maximal ideal $\mathfrak{a}$ was not closed, then we would have $\overline{\mathfrak{a}} = A$. Let $N$ be a right identity for $\mathfrak{a}$. Then there is $M$ with $\| M - N \| < 1$. Then
    %
    \begin{align*}
        N &= (N - M) + M = \sum_{k = 1}^\infty (N - M)^k - \sum_{k = 2}^\infty (N - M)^k + M\\
        &= \sum_{k = 1}^\infty (N - M)^k - \left[ \sum_{k = 1}^\infty (N - M)^k \right] (N - M) + M\\
        &= \underbrace{\left[ \left( \sum_{k = 1}^\infty (N - M)^k \right) M + M \right]}_{\in \mathfrak{a}} - \underbrace{\left[ \left( \sum_{k = 1}^\infty (N - M)^k \right) N - \left( \sum_{k = 1}^\infty (N - M)^k \right) \right]}_{\in \mathfrak{a}}
    \end{align*}
    %
    which is clearly a contradiction of the maximality of $\mathfrak{a}$.
\end{proof}

The kernel of any {\it nonzero} algebra homomorphism from $A$ to $\mathbf{C}$ is a maximal modular ideal, and any maximal modular ideal is the kernel of some algebra homomorphism.  We may therefore consider the gelfand transform of a commutative algebra without identity.

\begin{lemma}
    If $A$ is an algebra without identity, and $\phi$ is a homomorphism to $\mathbf{C}$, then there is a unique non-zero algebra functional $A \ltimes \mathbf{C}$ which extends $\phi$.
\end{lemma}
\begin{proof}
    Define $\tilde{\phi}(M + \lambda) = \phi(M) + \lambda$. Then $\tilde{\phi}$ is linear, $\tilde{\phi}(1) = 1$, and
    %
    \begin{align*}
        \tilde{\phi}(M + \lambda) \tilde{\phi}(N + \gamma) &= [\phi(M) + \lambda][\phi(N) + \gamma]\\
        &= \phi(MN) + \phi(\lambda N) + \phi(\gamma M) + \lambda \gamma\\
        &= \tilde{\phi}((M + \lambda)(N + \gamma))
    \end{align*}
    %
    The uniqueness of the extension follows from the fact any maximal modular ideal of $A$ can be uniquely extended to a maximal ideal on $A \ltimes \mathbf{C}$, for the projection $M + \lambda \mapsto M$ maps ideals to ideals by the vector space property. and the only ideals of $\mathbf{C}$ are $(0)$ and $(1)$.
\end{proof}

\begin{corollary}
    The Gelfand space extension $\Phi_{A \ltimes \mathbf{C}} = \Phi_A \cup \{ \phi_\infty \}$, where $\phi_\infty(M + \lambda) = \lambda$, and $\sigma(M) = \widehat{M}(\Phi_{A}) \cup \{ 0 \}$.
\end{corollary}

We may still apply the Gelfand topology to $A$, but it is no longer compact.

\begin{theorem}
    The Gelfand topology on $\Phi_A$ is locally compact when $A$ does not possess an identity.
\end{theorem}

\section{Bounded Approximate Identities}

We may not have an identity in a general Banach algebra, but we may be able to `approximate' an identity in some sense.

\begin{definition}
    A {\bf bounded left approximate identity} (or {\bf BLAI}) for an algebra $A$ is a net $\{ M_\alpha \}$ for which, for any $N \in A$, $\lim M_\alpha N = N$. One may similarily define {\bf bounded right} ({\bf BRAI}) and {\bf two sided} ({\bf AI}) identities.
\end{definition}

\begin{example}
    Let $X$ be locally compact and Hausdorff. The set of all compact subsets is a directed, exhausting set. Using Urysohn's lemma, find $f_K$, for each compact $K$, such that $f_K |_K = 1$, and $\| f_K \|_\infty \leq 1$. Fix $g \in C_0(X)$. Pick $K$ such that $|g| \leq \varepsilon$ outside of $K$. Then, in $K$, $|f_K g - g| = 0$, and outside of $K$, $|f_K g - g| < 2 \varepsilon$. Thus $\| f_K g - g \|_\infty < 2 \varepsilon$. $\{ f_K \}$ is not cauchy, for if $|f_K| < \varepsilon$ outside of $K'$, then $\| f_K - f_{K'} \|_\infty < 1 - \varepsilon$.
\end{example}

Advanced Banach space theory makes use of a large amount of bounded left approximate identities.

\begin{definition}
    A Banach space $E$ has the {\bf approximation property} if there is a net $\{ T_\alpha \}$ of finite rank operators which tend to $\text{id}_E$ uniformly on compact subsets. The space has the {\bf bounded approximation property} if $\| T_\alpha \|$ is bounded.
\end{definition}

Uniform convergence on compact sets is equivalent to pointwise convergence for bounded operators. Choose some compact $K$, fix $\varepsilon > 0$, and pick $x_1, \dots, x_n$ for which $\{ B(x_i, \varepsilon) \}$ is a cover of $K$. Then, if $x \in K$, there is $x_j$ with $\| x - x_j \| < \varepsilon$, and then
%
\begin{align*}
    \| T_\alpha x - x \| &\leq \| T_\alpha x - T_\alpha x_j \| + \| T_\alpha x_j - x_j \| + \| x_j - x \|\\
    &\leq \varepsilon \sup \|T_\alpha\| + \| T_\alpha x_j - x_j \| + \varepsilon
\end{align*}
%
If we choose $\alpha$ big enough, then this is guaranteed to be less than $3 \varepsilon$.

\begin{example}
    All Hilbert space have the bounded approximation property, as do the classical sequence spaces $c_0$ and $l_p$. Finding a space without the approximation property was an open problem for more than 40 years. Proposed as a challenge by Stanislaw Mazur in 1936, the solver of this problem was promised a live goose. In 1972, the goose was granted to the swedish mathematician Per Enflo.
\end{example}

For any Banach space $E$, we denote by $A(E)$ the closure of all finite rank operators in $B(E)$. It is clear than $A(E) \subset K(E)$. The problem of whether $A(E) = K(E)$ is much more subtle.

\begin{example}
    Let $E$ have the bounded approximation property. Let $\{ T_\alpha \}$ be such a bounded net. If $S$ is compact, then $S\overline{B_E}$ is precompact, and
    %
    \[ \| T_\alpha S - S \| \leq \sup \{ \| T_\alpha - Sx \| : x \in B_x \} \]
    %
    The right side is precompact, and since $\{ T_\alpha \}$ uniformly tends to the identity on compact sets, we must have $\| T_\alpha S - S \| \to 0$. This shows $\{ T_\alpha \}$ is a bounded left approximate identity, and that $A(E) = K(E)$.

    Now suppose $A(E)$ has a bounded left approximate identity $\{ T_\alpha \}$. Without loss of generality, we may assume each $T_\alpha$ is of finite rank. For $x \in E$, $\phi \in E^*$, let $x \otimes \phi : E \to E$ be defined by $(x \otimes \phi)(y) = \phi(y) x$. Then $x \otimes \phi$ obviously has finite rank. Pick $y$ for which $\langle \phi, y \rangle = 1$. Then
    %
    \[ \| T_\alpha x - x \| = \| T_\alpha (x \otimes \phi)(y) - (x \otimes \phi)(y) \| \leq \| y \| \| T_\alpha (x \otimes \phi) - (x \otimes \phi) \| \to 0 \]
    %
    So the nets converge pointwise, which implies convergence on compact sets. To summarize, $E$ has the bounded approximxation property if and only if $A(E)$ has a bounded left approximate identity if and only if $K(E)$ has a bounded left approximate identity belonging to $A(E)$.
\end{example}

It can be proven (though we won't prove it here) that

\begin{theorem}[Lewis, Goldbeck]
    In a Banach space, TFAE:
    %
    \begin{enumerate}
        \item $E^*$ has the bounded approximation property.
        \item $A(E)$ has the bounded right approximation property.
        \item $A(E)$ has the bounded approximation property.
    \end{enumerate}
\end{theorem}

\begin{lemma}
    If a space has the bounded left and right approximation properties then it has the two sided approximation property.
\end{lemma}
\begin{proof}
    Let $\{ M_\alpha \}$ be a left approximation identity, and $\{ N_\beta \}$ a right approximation identity. We contend $\{ M_\alpha + N_\beta - M_\alpha N_\beta \}$ is a two sided approximator. The limits below certainly converge, and the iterated limits must therefore equal the convergent factor, which is
    %
    \[ \lim_\alpha \lim_\beta L(M_\alpha + N_\beta - M_\alpha N_\beta) = \lim_\alpha LM_\alpha + L - LM_\alpha = L \]
    %
    \[ \lim_\beta \lim_\alpha (M_\alpha + N_\beta - M_\alpha N_\beta)L = \lim_\beta L + N_\beta L - N_\beta L = L \]
    %
    So twe have a two sided approximator.
\end{proof}

Before the logician Paul Cohen got into logic, he was a functional analyst who contributed to the theory of approximation identities. We shall prove the theorem he contributed to the field, generalized to work over arbitrary modules.

\begin{definition}
    Let $A$ be a Banach algebra. A left banach $A$-module is a Banach space $E$, which is a module of $A$, with a constant $C > 0$ for which for any $M \in A$, $x \in E$,
    %
    \[ \| Mx \| \leq C \| M \| \| x \| \]
    %
    This makes the module operations continuous.
\end{definition}

\begin{theorem}[Cohen's Factorization Theorem]
    Let $A$ be a Banach algebra with BLAI $\{ x_i \}$, bounded by $K$. If $E$ is a banach $A$ module, let $x \in \overline{AE}$, and let $\varepsilon > 0$. Then there are $M \in A$, $y \in \overline{AE}$ with
    %
    \begin{enumerate}
        \item $\| M \| \leq K$
        \item $\| y - x \| < \varepsilon$
        \item $x = My$
    \end{enumerate}
\end{theorem}
\begin{proof}
    If $A$ has an identity, then the proof is trivial. Since $\overline{AE}$ is a closed subset of $E$, we might as well assume $\overline{AE} = E$. We may extend $E$ to be an module of $A \ltimes \mathbf{C}$, with
    %
    \[ (M + \lambda) x = Mx + \lambda x \]
    %
    Pick $\lambda \in \mathbf{C}$ with
    %
    \[ 0 < K < \frac{1 - \lambda}{\lambda} \]
    %
    Consider a particular BLAI $\{ N_\alpha \}$ with $\sup \| N_\alpha \| \leq K$. Define a net $\{ M_\alpha \}$ in $A \ltimes \mathbf{C}$ by letting
    %
    \[ M_\alpha = \lambda N_\alpha + (1 - \lambda) \]
    %
    Then $M_\alpha L \to L$ for all $L \in E$, and each $M_\alpha$ is invertible in $A \ltimes \mathbf{C}$ by the choice of $\lambda$, and
    %
    \[ M_\alpha^{-1} = \frac{1}{1 - \lambda} \sum_{k = 0}^\infty \left(- \frac{\lambda N_\alpha}{1 - \lambda} \right)^k \]
    %
    which implies
    %
    \begin{align*}
        \| M_\alpha^{-1} N - N \| &= \| M_\alpha^{-1} N - M_\alpha^{-1} M N \| \leq \| M_\alpha^{-1} \| \| N - M N \|\\
        &\leq \left( \frac{1}{1 - \lambda} \sum_{k = 0}^\infty \left( \frac{\lambda K}{1 - \lambda} \right)^k \right) \| N - M_\alpha N \| \to 0
    \end{align*}
    %
    Therefore $M_\alpha^{-1}$ is also a BLAI. Fix $x \in E$, and let $\delta < 1, \frac{\varepsilon}{2 + \|x\|}$. We will inductively construct a sequence $\alpha_n$ of indices such that the sequence $E_{\alpha_1} \dots E_{\alpha_n}$ and $E_{\alpha_1}^{-1} \dots E_{\alpha_n}^{-1}$ converge. Choce $\alpha_1$ such that
    %
    \[ \| E_{\alpha_1}^{-1} x - x \| < \delta/2 \]
    %
    If $\alpha_1, \dots, \alpha_n$ has been chosen. There is a unique element $L_n \in A$ such that
    %
    \[  E_{\alpha_n} \dots E_{\alpha_1} = (1 - \lambda)^n + L_n \]
    %
    Pick $\alpha_{n+1}$ such that
    %
    \[ \| E_{\alpha_{n+1}} L_n - L_n \| < \frac{\delta}{(C + 1)\| E_{\alpha_1}^{-1} \dots E_{\alpha_n}^{-1} \| 2^{n+1}} \]
    %
    where $C$ is the module constant. Then
    %
    \[ E_{\alpha_1}^{-1} \dots E_{\alpha_n}^{-1} E_{\alpha_{n+1}}^{-1} x - E_{\alpha_1}^{-1} \dots E_{\alpha_n}^{-1} x \| \leq C \| E_{\alpha_1}^{-1} \dots E_{\alpha_n}^{-1} \| \| x - E_{\alpha_{n+1}}^{-1} x \| < \frac{\delta}{2^{n+1}} \]
\end{proof}

\end{document}