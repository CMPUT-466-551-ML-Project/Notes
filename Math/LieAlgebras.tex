\input{../style.tex}

\title{The Representation Theory of Lie Algebras}
\author{Jacob Denson}

\begin{document}

\pagenumbering{gobble}

\maketitle

\tableofcontents

\pagenumbering{arabic}

\chapter{Basic Definitions}

If $K$ is a field, then a Lie algebra over $K$ is a $K$ vector-space $\mathfrak{g}$ equipped with an alternating, bilinear form $[\cdot, \cdot]$, known as the {\bf Lie bracket}, satisfying the Jacobi identity
%
\[ [X,[Y,Z]] + [Y,[Z,X]] + [Z,[X,Y]] = 0 \]
%
for any $X,Y,Z \in \mathfrak{g}$. Note that the bracket operation need not be associative. That is, it is entirely possible for $[X,[Y,Z]] \neq [[X,Y],Z]$. The majority of Lie algebras emerge in geometry (normally where $K = \mathbf{R}$ or $K = \mathbf{C}$), and some parts of number theory, where a Lie group $G$ gives rise to a natural Lie algebra structure on the space $\mathfrak{g}$ of tangent vectors at the origin (There is a natural theory of `lie groups' for fields other than the real and complex numbers, though we won't discuss them here). We normally denote this structure by the `frakturized' name of $G$.

\begin{example}
    The Lie algebra $\mathfrak{gl}_n(K)$ is the set of matrices in $M_n(K)$, under the Lie bracket $[X,Y] = XY - YX$. The Jacobi identity follows by a thorough calculation, and shows that the commutator operation forms a Lie bracket on any algebra over $K$. Geometrically, $\mathfrak{gl}_n(K)$ corresponds to the Lie group $GL_n(K)$. In general, if $A$ is any associative algebra over $K$, then the commutator $[X,Y] = XY - YX$ gives a Lie algebra structure on $A$, providing a measure of commutativity.
\end{example}

\begin{example}
    If $\mathfrak{g}$ is any vector space, then the trivial bracket $[X,Y] = 0$ gives $\mathfrak{g}$ a Lie algebra structure. $\mathfrak{g}$ is known as a commutative Lie algebra, because then $[X,Y] = [Y,X]$. Since this implies that every vector space has a Lie algebra structure, we should not expect to learn much about the vector space structure of a Lie algebra from properties of the Lie algebra structure.
\end{example}

\begin{example}
    On any field $K$, the space of linear endomorphisms on $K[X]$ forms an associative algebra over $K$ under composition. Of particular interest are the operators
    %
    \[ f(X) \mapsto g(X) f(X) \]
    %
    for $g \in K[X]$, which we shall identify with $g$, and the differentiation operators
    %
    \[ f(X) \mapsto f'(X) \]
    %
    which we denote $\partial_X$. If we consider the space of `differential operators with polynomial coefficients', operators which can be written in the form
    %
    \[ \sum_{k = 0}^N g_k(X) \partial_X^k \]
    %
    with $g_k(X) \in K[X]$, for some $N$, then we find these form a subalgebra of the space of endomorphisms, since we have the identity
    %
    \[ (\partial_X X)(f) = X \partial_X(f) + f \partial_X(X) = X \partial_X(f) + f \]
    %
    so that $\partial_X X = X \partial_X + 1$, and we may use this identity to rearrange the product of any two differential operators to coincide with an operator of the form above. As an algebra, the space of differential operators has essentially no more relations. If
    %
    \[ \sum_{k = 0}^N g_k(X) \partial_X^k = 0 \]
    %
    Then successively applying the operator to the monomials $X^m$ gives
    %
    \[ g_0(X) = g_1(X) = \dots = g_N(X) = 0 \]
    %
    provided we are working over a field of characteristic 0, in which case we have an isomorphism of the ring of operators with $K \langle X, Y \rangle / (YX - XY - 1)$. If a field has finite characteristic $p$,  this method only allows us to determine that
    %
    \[ g_0(X) = g_1(X) = \dots = g_{p-1}(X) = 0 \]
    %
    but $\partial_X^p = 0$ in this case, so if we add this additional relation $Y^p = 0$, we obtain another isomorphism with a quotient of $K \langle X, Y \rangle$. In general, the ring of differential operators in $n$ variables is called the $n$'th Weyl algebra. It is obtained from $K\langle X_1, \dots, X_n, Y_1, \dots, Y_n \rangle$ modulo the relations $Y_i X_j - X_j Y_i = \delta_{ij}$ and $Y_i^p = 0$, which makes sense if we view $Y_i$ as the operator which is partial differentiation in the $i$'th variable. The commutator on these algebras gives a particularly interesting Lie algebra structure.
\end{example}

\begin{example}
    If $A$ is an associative algebra over $K$, then $M_n(A)$ is an algebra over $K$, and therefore a Lie algebra, denoted $\mathfrak{gl}_n(A)$. A particularly interesting example occurs if $A = \mathbf{C}[X,X^{-1}]$, in which case we call $\mathfrak{gl}_n(A)$ a Loop Lie algebra.
\end{example}

\begin{example}
    Given a (possibly non associative) algebra $A$, a derivation on $A$ is a linear map $d: A \to A$ satisfying $d(xy) = xd(y) + d(x)y$. Given two derivations $d$ and $d'$, $d \circ d'$ may not be a derivation, but the commutator $[d_1, d_2] = d_1 \circ d_2 - d_2 \circ d_1$ is always a derivation, because
    %
    \begin{align*}
        (d_1 \circ d_2 - &d_2 \circ d_1)(fg) = d_1(f d_2(g) + d_2(f) g) - d_2(d_1(f) g + f d_1(g))\\
        &= [d_1(f) d_2(g) + f (d_1 \circ d_2)(g) + d_2(f) d_1(g) + (d_1 \circ d_2)(f) g]\\
        &\ - [(d_2 \circ d_1)(f) g + d_1(f) d_2(g) + d_2(f) d_1(g) + f (d_2 \circ d_1)(g)]\\
        &= f(d_1 \circ d_2 - d_2 \circ d_1)(g) - (d_1 \circ d_2 - d_2 \circ d_1)(f) g
    \end{align*}
    %
    Thus the set of derivations on $A$, denoted $\text{der}(A)$, forms a Lie algebra.

    We should expect the space of derivations to play a fundamental role in the study of Lie algebras, because if $X,Y,Z$ are elements of any Lie algebra, then the Jacobi identity tells us that
    %
    \[ [X,[Y,Z]] = - [Y,[Z,X]] - [Z,[X,Y]] = [Y,[X,Z]] + [[X,Y],Z] \]
    %
    Introducing the {\bf adjoint map} $\text{adj}_X$ defined by $\text{adj}_X(Y) = [X,Y]$, we can restate the equation above as
    %
    \[ \text{adj}_X[Y,Z] = [Y, \text{adj}_X(Z)] + [\text{adj}_X(Y), Z] \]
    %
    so that $\text{adj}_X$ is actually a derivation on $\mathfrak{g}$. The map $X \mapsto \text{adj}_X$ is a representation of $\mathfrak{g}$ on $\text{der}(\mathfrak{g})$, because
    %
    \begin{align*}
        [\text{adj}_X, \text{adj}_Y](Z) &= [\text{adj}_X \text{adj}_Y - \text{adj}_Y \text{adj}_X](Z)\\
        &= [X,[Y,Z]] - [Y,[X,Z]]\\
        &= [X,[Y,Z]] + [Y,[Z,X]]\\
        &= -[Z,[X,Y]]\\
        &= [[X,Y],Z]\\
        &= \text{adj}_{[X,Y]}(Z)
    \end{align*}
    %
    The kernel of this homomorphism being the centre of $\mathfrak{g}$, denoted $Z(\mathfrak{g})$, which is the set of $X$ such that $[X,Y] = 0$ for all $Y$. In general, a bilinear skew-symmetric map is a Lie bracket if and only if the corresponding adjoint maps are all derivations -- the derivation equation is exactly the Jacobi identity in disguise.
\end{example}

\begin{example}
    The Lie algebra $\mathfrak{sl}_n(K)$ consists of the elements $X$ of $\mathfrak{gl}_n(K)$ whose trace is zero. This is a Lie subalgebra of $\mathfrak{gl}_n(K)$, because of the formula
    %
    \[ \text{tr}(XY) = \text{tr}(YX) \]
    %
    which is easily verified because
    %
    \[ \text{tr}(XY) = \sum_{i = 1}^n (XY)_{ii} = \sum_{i = 1}^n \sum_{j = 1}^n X_{ij} Y_{ji} = \sum_{i = 1}^n \sum_{j = 1}^n X_{ji} Y_{ij} = \text{tr}(YX) \]
    %
    and so
    %
    \[ \text{tr}(XY - YX) = \text{tr}(XY) - \text{tr}(YX) = 0 \]
    %
    The Lie group corresponding to $\mathfrak{sl}_n(K)$ is $SL_n(K)$.
\end{example}

\begin{example}
    The Special Orthogonal Lie Algebra $\mathfrak{so}_n(K)$ is the subalgebra of $\mathfrak{sl}_n(K)$ consisting of skew symmetric matrices $X$ such that $X^t = -X$, because if $X,Y \in \mathfrak{so}_n(K)$, then
    %
    \[ (XY - YX)^t = Y^tX^t - X^tY^t = YX - XY = -(XY - YX) \]
    %
    so the Lie bracket is well defined. The Lie algebra corresponds to the Lie group $SO_n(K)$, and in fact also the Lie group $O_n(K)$.
\end{example}

\begin{example}
    If $n$ is even, $n = 2m$, define the matrix $J \in M_n(K)$ by
    %
    \[ J = \begin{pmatrix} 0 & I_m \\ -I_m & 0 \end{pmatrix} \]
    %
    and then define $\mathfrak{sp}_n(K)$ to be the matrices $X \in \mathfrak{sl}_n$ satisfying $X^tJ + JX = 0$. If we write
    %
    \[ X = \begin{pmatrix} A & B \\ C & D \end{pmatrix} \]
    %
    Then
    %
    \[ X^tJ = \begin{pmatrix} -C^t & A^t \\ -D^t & B^t \end{pmatrix}\ \ \ \ \ JX = \begin{pmatrix} C & D \\ -A & -B \end{pmatrix} \]
    %
    giving us a simpler series of equations on the blocks of $X$ which define $\mathfrak{sp}_n(K)$.
    %
    \[ C^t = C\ \ \ \ \ A^t = D\ \ \ \ \ B^t = B \]
    %
    This Lie algebra corresponds to the Symplectic Lie group $SP_n(K)$.
\end{example}

\begin{example}
    The Heisenberg group $H_n(K)$ is the Lie group of matrices of the form
    %
    \[ \begin{pmatrix} 1 & a & c \\ 0 & I_n & b \\ 0 & 0 & 1 \end{pmatrix} \]
    %
    where $a \in K^n$ is a row vector, $c \in K$, and $b \in K^n$ is a column vector. It's corresponding Lie algebra $\mathfrak{h}_n(K)$ consists of vectors of the form
    %
    \[ \begin{pmatrix} 0 & a & c \\ 0 & 0 & b \\ 0 & 0 & 0 \end{pmatrix} \]
    %
    which is flat, since the Heisenberg group is essentially flat.
\end{example}

A homomorphism $f$ of Lie algebras is, of course, a linear map preserving the Lie bracket operation. We can consider the kernel, which will always form a (two-sided) ideal of the algebra, in the sense that if $f(X) = 0$, then $f[Y,X] = f[X,Y] = 0$ for all elements $Y$ in the algebra. In general, given a two-sided ideal $\mathfrak{a}$ of $\mathfrak{g}$, we may consider the standard equivalence relation on $\mathfrak{g}$ to form the quotient space $\mathfrak{g}/\mathfrak{a}$, and if $X - X' \in \mathfrak{a}$, $Y - Y' \in \mathfrak{a}$, then
%
\[ [X,Y] - [X',Y'] = [X-X',Y] + [X',Y-Y'] \in \mathfrak{a} \]
%
so the bracket is well defined on the quotient of the space, and we have quotient Lie algebras. We have a version of all three of the standard isomorphism theorems on the class of Lie algebras, which we leave the reader to specify explicitly. In addition, we note that we can apply algebraic formation rules for ideals -- if $\mathfrak{a}$ and $\mathfrak{b}$ are ideals, then
%
\[ \mathfrak{a} + \mathfrak{b} = \{ X + Y : X \in \mathfrak{a}, Y \in \mathfrak{b} \} \]
\[ [\mathfrak{a}, \mathfrak{b}] = \text{span} \{ [X,Y] : X \in \mathfrak{a}, \mathfrak{b} \} \]
%
where we need to take the span in $[\mathfrak{a}, \mathfrak{b}]$ so the result will be a subspace of the algebra. Of particular importance to the theory is the {\bf derived subalgebra} $\mathfrak{g}' = [\mathfrak{g}, \mathfrak{g}]$ of $\mathfrak{g}$, which is the set of all elements of $\mathfrak{g}$ which can be written $[X,Y]$, for $X,Y \in \mathfrak{g}$.

\begin{example}
    Consider the homomorphism $f: \mathfrak{gl}_n(K) \to K$ obtained by taking the trace of the matrix, which is a homomorphism because
    %
    \[ \text{tr}([x,y]) = \text{tr}(xy - yx) = 0 = [\text{tr}(x), \text{tr}(y)] \]
    %
    The kernel is the special linear group, and is thus verified to be proper ideal of the general linear group. Thus the general linear group is not simple, it breaks down into the direct sum
    %
    \[ \mathfrak{gl}_n(K) = \mathfrak{sl}_n(K) \oplus \mathbf{C} \cdot I \]
    %
    In the sense of the direct sum of Lie algebras, because if $X,X' \in \mathfrak{sl}_n(K)$, $\lambda, \gamma \in \mathbf{C}$, then
    %
    \begin{align*}
        [X + \lambda, X' + \gamma] &= (X + \lambda)(X' + \gamma) - (X' + \gamma)(X + \lambda)\\
        &= XX' + \lambda X' + \gamma X + \lambda \gamma - X'X - \gamma X - \lambda X' - \lambda \gamma\\
        &= [X,X'] + [\lambda, \gamma]
    \end{align*}
    %
    This is the bracket structure which we can use to define the abstract direct sum of any two Lie algebras $\mathfrak{g}$ and $\mathfrak{h}$, denoted $\mathfrak{g} \oplus \mathfrak{h}$.
\end{example}

It is difficult to classify all Lie algebras, but we can classify the simple Lie algebras (those without a non-zero proper ideal), which will occupy us through the course. It turns out that the only simple Lie algebras are
%
\[ \mathfrak{sl}_n, \mathfrak{so}_n, \mathfrak{sp}_n \]
%
and some `eccentric' algebras $\mathfrak{e}_6, \mathfrak{e}_7, \mathfrak{e}_8, \mathfrak{e}_4$, and $\mathfrak{g}_2$. In order to do this, we will need to harness the powerful tools of representation theory, which we will develop along the way.

\section{Low Dimensional Classifications}

Given a Lie algebra $\mathfrak{g}$, we may fix a basis $E_1, \dots, E_n$, thereby finding constants $a_{ij}^k \in K$ such that
%
\[ [E_i,E_j] = \sum a_{ij}^k E_k \]
%
The Lie algebra property guarantees that $a_{ij}^k = -a_{ji}^k$, so that for a fixed $k$, the matrix $(a_{ij}^k)$ is skew-symmetric, and the Jacobi identity takes the form
%
\[ \sum a_{jk}^l a_{il}^m + a_{ki}^l a_{jl}^m + a_{ij}^l a_{kl}^m = 0 \]
%
for every $i,j,k,m$. Conversely, given $a_{ij}$ over some vector space satisfying these equations, the corresponds bilinear map is a Lie bracket, because if $X = \sum a^i e_i$, $Y = \sum b^i e_i$, and $Z = \sum c^i e_i$, then
%
\begin{align*}
    [X,[Y,Z]] + &[Y,[Z,X]] + [Z,[X,Y]]\\
    &= \sum_{i,j,l} a^i b^j c^l \left( [e_i,[e_j,e_l]] + [e_j,[e_l,e_i]] + [e_l,[e_i,e_j]] \right)\\
    &= 0
\end{align*}
%
This coordinatization is particular applicable in low dimensions, where the calculations are relatively trivial, and allows us to classify the algebras up to isomorphism, because two algebras $\mathfrak{g}$ and $\mathfrak{h}$ are isomorphic if and only if we can specify a basis in such a way that the structure constants obtained are the same. In the one dimensional case, the only skew symmetric matrix is trivial, so that every one dimensional Lie algebra is abelian. The calculation of the two and three dimensional cases gets progressively more and more involved.

\begin{theorem}
    There is a single nonabelian two dimensional Lie algebra.
\end{theorem}
\begin{proof}
    If $\mathfrak{g}$ is a two dimensional Lie algebra, and if $(X,Y)$ is a basis, then $[X,Y]$ spans the derived subalgebra, hence the derived subalgebra is one dimensional if the space is nonabelian. Fix a non-zero $X$ in the derived subalgebra, and extend $X$ to a basis $(X,Y)$. Then $[X,Y] \neq 0$, for otherwise the bracket is abelian. Write $[X,Y] = \lambda X$. By scaling $Y$, we may actually assume $[X,Y] = X$. This shows that there can be at most one non-abelian Lie algebra, because we have found a basis with a particular set of structural constants, and provided these constants specify a Lie algebra, we have determined that there is a single two dimensional Lie algebra. The bracket $[X,Y] = X$ does actually give a Lie algebra structure, since
    %
    \begin{align*}
        [aX + &bY, [mX + nY, qX + rY]] + [mX + nY, [qX + rY, aX + bY]]\\
        &+ [qX + rY, [aX + bY, mX + nY]]\\
        &= [aX + bY, (mr - nq)X] + [mX + nY, (qb - ra)X] + [qX + rY, (an - bm)X]\\
        &= [b(nq - mr) + n(ra - qb) + r(bm - an)]X = 0
    \end{align*}
    %
    Hence a two-dimensional non-abelian Lie algebra exists.
\end{proof}

The three dimensional case is more involved. We split our discussion into three cases, where the derived subalgebra has dimension 0,1,2, and 3. The zero dimensional case is obviously the abelian Lie algebra, and needs no further discussion.

\begin{theorem}
    The Heisenberg Lie algebra is the unique three dimensional Lie algebra whose derived subalgebra is one dimensional, and contained within the center of the algebra.
\end{theorem}
\begin{proof}
    Given such a Lie algebra $\mathfrak{g}$, take $X$ and $Y$ such that $[X,Y] = Z \neq 0$. Then $X$, $Y$, and $Z$ are linearly independant, for if $aX + bY + cZ = 0$, then
    %
    \[ [aX + bY + cZ, X] = b[Y,X] = -bZ = 0\ \ \ \ \ [aX + bY + cZ, Y] = aZ = 0 \]
    %
    implying $a = b = 0$, hence $c = 0$. Thus $X,Y$, and $Z$ are a basis of the Lie algebra. The structural constants of this Lie algebra are identical to the structural constants of the Heisenberg Lie algebra, where $X = E_{12}$, $Y = E_{23}$, and $Z = E_{33}$.
\end{proof}

The remaining dimension 1 case occurs when the derived subalgebra is not contained within the center. If we consider the direct product the nonabelian two-dimensional Lie algebra $\mathfrak{g}$ with the field $K$, denoted $\mathfrak{g} \oplus K$, then the derived subalgebra of this Lie algebra is not contained within the centre, because
%
\[ (\mathfrak{g} \oplus K)' = KX \oplus (0) \]
\[ Z(\mathfrak{g} \oplus K) = (0) \oplus K \]
%
We shall now prove that this is the defining three dimensional Lie algebra whose derived subalgebra is one-dimensional, and is not contained within the centre.

\begin{theorem}
    There is a unique three dimensional Lie algebra with one dimensional derived subalgebra not contained within the center of the algebra.
\end{theorem}
\begin{proof}
    Let $\mathfrak{h}$ be such an algebra. Pick $X \neq 0$ spanning the derived $\mathfrak{h}'$, then pick $Y$ with $[X,Y] = X$. Then $X$ and $Y$ are linearly independant, and we may consider some basis $\{ X, Y, Z \}$. There must $a$ and $b$ such that $[X,Z] = aX$, $[Y,Z] = bX$. If we consider the equations
    %
    \begin{align*}
        (\lambda X + \gamma Y + \eta Z, X) &= -(\gamma + \eta a) X\\
        (\lambda X + \gamma Y + \eta Z, Y) &= (\lambda - \eta b) X\\
        (\lambda X + \gamma Y + \eta Z, Z) &= (a \lambda + b \gamma) X
    \end{align*}
    %
    And if we consider the matrix
    %
    \[ \begin{pmatrix} 0 & -1 & -a \\ 1 & 0 & -b \\ a & b & 0 \end{pmatrix} \]
    %
    we notice the determinant is $0$, hence the matrix is non-invertible, and the nullspace must contain some non-zero $(\lambda, \gamma, \eta)$, i.e. $Z(\mathfrak{g})$ is non trivial, and contains some non-zero $\lambda X + \gamma Y + \eta Z$. If $\eta = 0$, then the equations above would imply $\gamma = \lambda = 0$, which is impossible, hence $\eta \neq 0$, and we have found a nonzero $w \in Z(\mathfrak{h})$ not contained in the span of $x$ or $y$, hence we have the decomposition
    %
    \[ \mathfrak{h} = \langle x, y \rangle \oplus Kw \cong \mathfrak{g} \oplus K \]
    %
    Hence $\mathfrak{g} \oplus K$ is a Lie algebra.
\end{proof}

There is actually an infinite family of non-isomorphic Lie algebras whose derived algebra is two-dimensional, but we have a nice classification of this family. In the two dimensional case, we take a basis $(Y,Z)$ of the derived subalgebra, and complete it to a basis $(X,Y,Z)$ of the entire algebra. We claim that the derived subalgebra is always abelian. To prove this, it suffices to show $[Y,Z] = 0$. Consider the adjoint map $\text{adj}_Y$, which can be written in matrix form with respect to the basis given as
%
\[ \begin{pmatrix} 0 & 0 & 0 \\ * & 0 & \alpha \\ * & 0 & \beta \end{pmatrix} \]
%
for some constants $\alpha$ and $\beta$. We claim that the trace of any adjoint operator is zero, so that $\beta = 0$. By consider the adjoint map $\text{adj}_Z$, we conclude that $\alpha = 0$. Thus the derived subalgebra is abelian.

\begin{lemma}
    For any Lie algebra $\mathfrak{g}$, and $X \in \mathfrak{g}'$, $\text{tr}(\text{adj}_X) = 0$.
\end{lemma}
\begin{proof}
    If $X = [Y,Z]$, then
    %
    \[ \text{adj}_{[Y,Z]} = [\text{adj}_Y, \text{adj}_Z] \in \mathfrak{gl}(\mathfrak{g})' = \mathfrak{sl}(\mathfrak{g}) \]
    %
    Hence the trace the adjoint is zero.
\end{proof}

In fact, $\text{adj}_X$ is an isomorphism of $\mathfrak{g}'$, because $[X,Y]$ and $[X,Z]$ span the derived subalgebra, hence the map is surjective, and therefore an isomorphism. In fact, by linearity, $\text{adj}_M$ is an isomorphism for any $M = \alpha X + \beta Y + \gamma Z$, where $\alpha \neq 0$. If we can find an $M$ such that $\text{adj}_M: \mathfrak{g}' \to \mathfrak{g}'$ is diagonalizable, then the map has two non-zero eigenvectors $Y$ and $Z$, such that $[M,Y] = \lambda Y$, $[M,Z] = \gamma Z$ (the eigenvalue must be additive inverses because the trace of the matrix is zero).




\section{Root Systems}

A useful (and standard) basis for $\mathfrak{gl}_n(K)$ are the matrices $E_{ij}$, which are only non-zero on row $i$ and column $j$, where the matrix coefficient has value 1. We note that
%
\[ [E_{ij}, E_{kl}] = \delta_j^k E_{il} + \delta_i^l E_{kj} \]
%
If we define $H_k = E_{kk} - E_{k+1\ k+1}$, then the $H_k$, together with the $E_{ij}$ for $i \neq j$, span $\mathfrak{sl}_n$, and
%
\[ [H_k, E_{ij}] = [E_{kk}, E_{ij}] - [E_{k+1\ k+1}, E_{ij}] = (\delta_k^i + \delta_k^j - \delta_{k+1}^i - \delta_{k+1}^j) E_{ij} \]
%
\[ [H_i, H_j] = [H_i, E_{jj}] - [H_i, E_{j+1\ j+1}] = 2(\delta_i^{j+1} - \delta_{i+1}^j) E_{jj} \]
%
Thus $E_{ij}$ is an eigenvector for the {\bf adjoint} map $\text{adj}(X)$

So $E_{ij}$ is an eigenvector for the {\bf adjoint} map $\text{adj}(X)$, defined by $\text{adj}(X)(Y) = [X,Y]$, where $X = H_k$.

\end{document}