\documentclass[dvipsnames,letterpaper,12pt]{article}

\usepackage[margin = 1.0in]{geometry}
\usepackage{amsmath,amssymb,graphicx,mathabx,accents, enumitem}

\setlist[enumerate]{label*={\normalfont(\Alph*)},ref=(\Alph*)}

\numberwithin{equation}{section}

\usepackage{tikz, tkz-berge, tkz-graph}
\usetikzlibrary{patterns,arrows,decorations.pathreplacing}

\usepackage{color,xcolor}
\definecolor{crimsonred}{RGB}{132,22,23}
\definecolor{darkblue}{RGB}{72,61,139}

\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem*{example}{Example}
\newtheorem*{remark}{Remark}

\DeclareMathOperator{\minkdim}{\dim_{\mathbf{M}}}
\DeclareMathOperator{\hausdim}{\dim_{\mathbf{H}}}
\DeclareMathOperator{\lowminkdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\upminkdim}{\overline{\dim}_{\mathbf{M}}}

\DeclareMathOperator{\lhdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\lmbdim}{\underline{\dim}_{\mathbf{MB}}}

\DeclareMathOperator{\RR}{\mathbf{R}}
\DeclareMathOperator{\ZZ}{\mathbf{Z}}
\DeclareMathOperator{\QQ}{\mathbf{Q}}
\DeclareMathOperator{\Prob}{\mathbf{P}}
\DeclareMathOperator{\Expect}{\mathbf{E}}

\DeclareMathOperator{\B}{\mathcal{B}}









\title{Large Sets Avoiding Rough Patterns}
\author{Jacob Denson\thanks{University of British Columbia, Vancouver BC, \{denson, malabika, jzahl\}@math.ubc.ca.} \and Malabika Pramanik\footnotemark[1] \and Joshua Zahl\footnotemark[1]}

\begin{document}

\maketitle

\begin{abstract}
	The pattern avoidance problem seeks to construct a set $X\subset \RR^d$ with large dimension that avoids a prescribed pattern such as three term arithmetic progressions, or more general patterns such as avoiding points $x_1, \dots, x_n$ such that $f(x_1, \dots, x_n) = 0$ (three term arithmetic progressions are specified by the pattern $x_1 - 2x_2 + x_3 = 0$). Previous work on the subject has considered patterns described by polynomials, or by functions $f$ satisfying certain regularity conditions. We consider the case of `rough patterns.
	% DISCUSS: SHOULD WE INCLUDE THE FACT THAT WE USE HAUSDORFF DIMENSION?
	There are several problems that fit into the framework of rough pattern avoidance. As a first application, if $Y \subset [0,1]$ is a set with Minkowski dimension $\alpha$, we construct a set $X \subset [0,1]$ with Hausdorff dimension $1-\alpha$ so that $X+X$ is disjoint from $Y$. As a second application, given a set $Y$ of dimension close to one, we can construct a subset $X \subset Y$ of dimension $1/2$ that avoids isosceles triangles. [{\bf{TODO:}} I'd like to replace this with a rectifiability statement]
\end{abstract}









% DISCUSS: Typography: You shouldn't use \ell unless you have script characters for r and s, i.e. scripts for other lengths.

% DISCUSS: Typography: It's bad style to use Math Bolded font and Math blackboard font simultaneously in a paper. We need to decide whether we want to use one or the other, and stick with it.

% DISCUSS: Why discuss additive combinatorics if we are publishing an article in a harmonic analysis journal, and it is never used or mentioned again?

% DISCUSS: The geometry in Maga's theorem is more easy to understand than Keleti's theorem. Easing the reader into the problem is more important than assigning credit?

A major question in modern geometric measure theory is whether sets with sufficiently large Hausdorff dimension necessarily contain copies of certain patterns. For example, the main result of \cite{Maga} constructs a set $X \subset \RR^2$ with full Hausdorff dimension such that no four points in $X$ form the vertices of a parallelogram. On the other hand, Theorem 6.8 of \cite{Matilla} shows that each set $X \subset \RR^d$ with Hausdorff dimension exceeding one must contain three colinear points. There is currently no comprehensive theorem  for these types of problems, and the threshold dimension at which patterns are guaranteed can vary for different patterns, or not even exist at all. In this paper, we provide lower bounds for the threshold by solving the pattern avoidance problem; constructing sets with large dimension avoiding patterns.

One natural way to approach the pattern avoidance problem is to find general methods for constructing pattern avoiding sets by exploiting a particular geometric feature of the pattern. In \cite{Mathe}, M\'{a}th\'{e} shows that, given a pattern specified by a countable union of rational coefficient bounded degree polynomials $f_1, f_2, \dots$ in $nd$ variables, one can construct a set $X \subset \RR^d$ such that for every collection of distinct points $x_1, \dots, x_n$, and each index $k$, $f_k(x_1, \dots, x_n) \neq 0$. In \cite{MalabikaRob}, Fraser and the second author consider a related problem where the functions $f_k$ are placed with $C^1$ functions satisfying a mild degeneracy condition.

% DISCUSS: Why discuss the intersection with equal points if this isn't part of the problem statement. If you feel this is a useful perspective, move this to the discussion in Section 6.

% DISCUSS: SAY "WE SAY THIS AVOIDS THIS PATTERN IF..."

Rather than avoiding the zeroes of a function, in this paper, we fix $Z \subset \RR^{dn}$, and construct sets $X$ such that for each distinct $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in Z$. We then say $X$ avoids the pattern specified by $Z$. For instance, if $Z = \{ (x_1,x_2,x_3) \in (\RR^d)^3 : (x_1,x_2,x_3)\ \text{are colinear} \}$, then $X \subset \RR^d$ avoids the pattern specified by $Z$ precisely when $X$ does not contain three colinear points. Our problem generalizes the problem statements considered in \cite{Mathe} and \cite{MalabikaRob} if we set $Z = \bigcup_{k = 1}^\infty f_k^{-1}(0)$. From this perspective, M\'{a}th\'{e} constructs sets avoiding a set $Z$ formed from a countable union of algebraic varieties, while Fraser and the second author construct sets avoiding a set $Z$ formed from the countable union of $C^1$ manifolds.

The advantage of the formulation of pattern avoidance we consider is that it is now natural to consider `rough' sets $Z \subset \RR^{dn}$ which are not naturally specified as the zero set of a function. In particular, in this paper we consider $Z$ formed from the countable union of sets, each with lower Minkowski dimension bounded above by some $\alpha$. In contrast with previous work, no further assumptions are made on $Z$. The dimension of the avoiding set $X$ we will eventually construct depends only on the codimension $nd - \alpha$ of the set $Z$, and the number of variables $n$.

\begin{theorem}\label{mainTheorem}
	Let $Z$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$, with $d \leq \alpha < dn$. Then there exists a set $X \subset [0,1)^d$ with Hausdorff dimension at least $(nd - \alpha)/(n-1)$ such that whenever $x_1, \dots, x_n \in X$ are distinct, then $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

\begin{remark}
	When $\alpha < d$, the pattern avoidance problem is trivial, since $X = [0,1)^d - \pi(Z)$ is full dimensional and solves the pattern avoidance problem, where $\pi \colon \RR^{dn} \to \RR^d$ is the projection map onto the first coordinate. The case $\alpha = dn$ is trivial as well, since we can set $X = \emptyset$.

	%And given only a lower Minkowski dimension bound on the sets which form $Z$, we cannot do any better than a zero dimensional set since it is possible for $Z$ to be $\RR^{dn}$, in which case solutions to the pattern avoidance problem can consist of at most $n-1$ points.
\end{remark}

% DISCUSS: Without mentioning why this result can only be developed because our method can be applied to very rough sets, the application doesn't seem exciting at all.

When $Z$ is a countable union of smooth manifolds, Theorem \ref{mainTheorem} generalizes Theorem 1.1 and 1.2 from \cite{MalabikaRob}. Section \ref{futureWorkSection} is devoted to a comparison of our methods with \cite{MalabikaRob}, as well as other general pattern avoidance methods. But our result is more interesting when it can be applied to truly `rough' sets. One surprising application to our method is obtained by considering a `rough' set $Y$ in addition to a set $Z$, and finding a set $X \subset Y$ of large dimension avoiding $Z$. Previous methods in the literature fundamentally exploit the ability to select points on the entirety of Euclidean space, and so it remains unlikely that we can obtain any result of this form using their methods, unless $Y$ is suitably flat, i.e. a smooth surface. To contrast this, our result even applies for certain sets $Y$ which are of Cantor type. We discuss applications of our result in Section 5.

% DISCUSS: Our method isn't randomized.

Theorem \ref{mainTheorem} is proved using a Cantor-type construction, a common theme in the surrounding literature, described explicitly in Section \ref{discretizationsection}. For a sequence of decreasing lengths $\{ l_n \}$ with $l_n \to 0$, the construction specifies a selection mechanism for a nested family of sets $X_n \to X$, with $X_n$ a union of sidelength $l_n$ cubes and avoiding $Z$ at scales close to $l_n$. Our {\it key} contribution to this process is using the probabilistic method to guarantee the existence of efficient selections at each scale, described in Section 2. This selection also assigns mass uniformly on intermediate scales, akin to \cite{MalabikaRob}, ensuring that the selection procedure at a single scale is the sole reason for the Hausdorff dimension we calculate in Section 4. Furthermore, the randomization allows us to avoid the complicated queueing techniques in \cite{KeletiDimOneSet} and \cite{MalabikaRob}, which has the additional benefit that we can confront the entire behaviour of $Z$ at scales close to $l_n$ simultaneously during the $n$th step of the construction.










\section{Frequently Used Notation and Terminology}\label{notationSection}

Our argument heavily depends upon discretizing sets into unions of cubes. Throughout our argument, we use the following notation:

% DISCUSS: DOES THE SECTION PARTITIONING HELP?
% DISCUSS: DOES THE UPPER CASE LOWER CASE HELP?

\begin{enumerate}%[label=\Alph*]
	\item A {\it dyadic scale} is a length $l$ equal to $2^{-k}$ for some non-negative integer $k$.

	\item Given a length $l > 0$, we let $\B^d_l$  denote the family of all half open cubes in $\RR^d$ with sidelength $l$ and corners on the lattice $(l \cdot \ZZ)^d$. That is,
	%
	\[ \B^d_l = \{ [a_1, a_1 + l] \times \cdots \times [a_d, a_d+l] : a_k \in l \cdot \ZZ \}. \]
	%
	If $E \subset \RR^d$, $\B^d_l(E)$ is the family of cubes in $\B^d_l$ intersecting $E$, i.e.
	%
	\[ \B^d_l(E) = \{ I \in \B^d_l: I \cap E = \emptyset \}. \]

	\item The {\it lower Minkowski dimension} of a compact set $Z \subset \RR^d$ are defined as
	%
	\begin{equation} \label{minkdimdef}
		\lowminkdim(Z) = \liminf_{l \to 0} \frac{\log(\# \B^d_l(Z))}{\log(1/l)}.
	\end{equation}

	\item If $0\leq\alpha\leq d$ and $\delta>0$, we define the dyadic Hausdorff content of a set $E\subset\RR^d$ as 
		%
	\[ H^\alpha_\delta(E) = \inf \left\{ \sum_{k = 1}^m l_k^\alpha : E \subset \bigcup_{k = 1}^m I_k\ \text{and}\ I_k \in \B^d_{l_k}, l_k \leq \delta\ \text{for all $k$} \right\}. \]
	%


	The $\alpha$ dimensional dyadic Hausdorff measure $H^\alpha$ on $\RR^d$ is $H^\alpha(E) = \lim_{\delta \to 0} H_\delta^\alpha(E)$. 
	The {\it Hausdorff dimension} of a set $E$ is $\hausdim(E) = \inf \{ \alpha \geq 0 : H^\alpha(E) = 0 \}$.
% \end{enumerate}

% In Section 2, we solve a discrete version of Theorem \ref{mainTheorem}. Non-diagonal cubes will play an important role in this process. 

% \begin{enumerate}
	\item \label{stronglyNonDiagonalDef}Given $I \in \B^{dn}_l$, we can decompose $I$ as $I_1 \times \cdots \times I_n$ for unique cubes $I_1, \dots, I_n \in \B_l^d$. We say $I$ is {\it strongly non-diagonal} if the cubes $I_1, \dots, I_n$ are distinct. Strongly non-diagonal cubes will play an important role in Section \ref{discretesection}, when we solve a discrete version of Theorem \ref{mainTheorem}. 
% \end{enumerate}

% In Section 3, we discretize the set $Z$ in the hypothesis of Theorem \ref{mainTheorem} into a union of boxes. Our argument is aided by the following definitions:

% \begin{enumerate}
	\item\label{strongCoverDefn} Adopting the terminology of \cite{KatzTao}, we say a collection of sets $U_1, \dots, U_n$ is a {\it strong cover} of a set $E$ if $E \subset \limsup U_k$, which means every element of $E$ is contained in infinitely many of the sets $U_k$. This idea will be useful in Section \ref{discretizationsection}.  
% \end{enumerate}

% Once $X$ has been constructed, in Section 4 we show it has the Hausdorff dimension required by Theorem \ref{mainTheorem}. Here we use a Frostman's lemma type approach.

% \begin{enumerate}
	\item\label{frostmanItem} A {\it Frostman measure} of dimension $\alpha$ is a non-zero compactly supported probability measure $\mu$ on $\RR^d$ such that for every cube $I$ of sidelength $l$, we have
	\begin{equation}\label{muICondition}
	\mu(I) \lesssim l^\alpha.
	\end{equation}
	Note that a measure $\mu$ satisfies \eqref{muICondition} for every cube $I$ if and only if it satisfies \eqref{muICondition} for cubes whose sidelengths are dyadic scales.  

	 {\it Frostman's lemma} says that
	%
	\[ \hausdim(E) = \sup \left\{ \alpha: \begin{array}{c} \text{there is an}\ \alpha\ \text{dimensional Frostman}\\
	\text{measure supported on $E$} \end{array} \right\}. \]
\end{enumerate}









\section{Avoidance at Discrete Scales}\label{discretesection}

% DISCUSS: Z_s doesn't cover Z, just a segment of it.

In this section we describe a method for avoiding $Z$ at a single scale. This will be applied in Section \ref{discretizationsection} at many scales to construct a set $X$ avoiding $Z$ at all scales. The single scale technique is the core part of our construction, and the efficiency with which we can avoid $Z$ at a single scale has direct consequences on the Hausdorff dimension of the set $X$ that we construct.

At a single scale, we solve a discretized version of the problem, where all sets are unions of cubes at two dyadic scales $l \geq s$. In the discrete setting, $Z$ is replaced by a union of cubes in $\B^{dn}_s$, denoted by $Z_s$. Given a set $E$, which is a union of cubes in $\B_l^d$, our goal is to construct a union of cubes in $\B_s^d(E)$, denoted $F$, such that $F^n$ is disjoint from the strongly non-diagonal cubes of $Z_s$ (see Definition \ref{stronglyNonDiagonalDef}).

In order to ensure the final set $X$ obtained in Theorem \ref{mainTheorem} has large Hausdorff dimension regardless of the rapid decay of scales used in the construction of $X$, it is crucial that $F$ is spread uniformly over $E$. We achieve this by decomposing $E$ into sub-cubes in $\B_r^d$ for some intermediate scale $r \in (s,l)$, and distributing $F$ evenly among as many of these intermediate sub-cubes as possible. The following lemma shows this is possible provided we have an upper bound on the volume of $Z_s$.

% DISCUSS: Sure we can assume that r^{dn} (# B_r^d(E)) > |Z_s|, but we never actually use this in our proof, so this seems an inappropriate use of this grammar.

\begin{lemma} \label{discretelemma}
	Fix three dyadic scales $l \geq r \geq s$. Let $E$ be a union of cubes in $\B^d_l$, and let $Z_s$ be a union of cubes in $\B^d_s$ such that $|Z_s| \leq l^d r^{d(n-1)}/2$. Then there exists a set $F \subset E$, which is a union of cubes in $\B^d_s$, satisfying the following three properties:
	%
	\begin{enumerate}
		\item\label{avoidanceItem} \emph{Avoidance}: For any distinct $J_1, \dots, J_n \in \B^d_s(F)$, we have $J_1 \times \dots \times J_n \not \in \B_s^{dn}(Z_s)$.
		\item\label{nonConcentrationItem} \emph{Non-Concentration}: For each $I \in \B_r^d(E)$, there is at most one $J \in \B_s^d(F)$ with $J \subset I$.
		\item\label{largeSizeItem} \emph{Large Size}: For any $I \in \B^d_l(E)$, $\# \B^d_s(F \cap I) \geq \# \B^d_r(I) / 2 = (l/r)^d / 2$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	For each $I \in B_r^d(E)$, let $J_I$ be a random element of $\B^d_s(I)$ chosen independently with uniform probability. Define a random set
	%
	\begin{equation} \label{Udefinition}
		U = \bigcup \{ J_I : I \in \B^d_s(I) \}.
	\end{equation}
	%
	By construction, for each $I \in B^d_s(I)$, $U$ contains exactly one subcube $J \in \B_s^d$ with $J \subset I$, so $U$ satisfies Property \ref{nonConcentrationItem}. Our construction also implies $\# \B_s^d(U \cap I) = \# \B_r^d(I)$ for each $I$, 
	% DISCUSS: WHY MAKE THE READER HAVE TO THINK HERE? THE THIRD EQUALITY WOULD HELP?
	so $U$ satisfies Property \ref{largeSizeItem}. Unfortunately, $U$ might not satisfy Property \ref{avoidanceItem}. %We will address this problem next. %We will show that with non-zero probability, we can remove at most $|Z_s| r^{-dn}$ cubes from $U$ to obtain Property \ref{avoidanceItem}, so that Property \ref{nonConcentrationItem} and \ref{largeSizeItem} remain to be true.
	% DISCUSS: OF COURSE WE'LL ADRESS THIS QUESTION NEXT, THE PROOF IS SO TINY?

	For each cube $J \in \B_s^d(E)$, there is a unique `parent' cube $I \in \B_r^d(E)$ such that $J \subset I$. Since $I$ contains $(r/s)^d$ elements of $\B^d_s(E)$, and $J_I$ is chosen uniformly at random, we find
	%
	\begin{equation} \label{singleCubeProb}
		\Prob(J \subset U) = \Prob(J_I = J) = (s/r)^d.
	\end{equation}
	%
	Here the probability measure $\Prob(\cdot)$ is taken with respect to the randomly chosen set $U$ defined in \eqref{Udefinition}. Since the cubes $J_I$ are chosen independantly, if $J_1, \dots, J_k$ are distinct cubes in $\B^d_s(E)$, then \eqref{singleCubeProb} combined with Property \ref{nonConcentrationItem} shows
	%
	\begin{equation}\label{jointprob}
		\Prob(J_1, \dots, J_k \in U) = \begin{cases} (s/r)^{dk} &: \text{if $J_1, \dots, J_k$ have distinct parents} \\ 0 &: \text{otherwise} \end{cases}.
	\end{equation}
	%
	Let $K = J_1 \times \dots \times J_n \in \B^{dn}_s(Z_s)$ be a strongly non-diagonal cube. Since the cubes $J_1, \dots, J_n$ are distinct, we can apply \eqref{jointprob} to conclude
	%
	\begin{equation}\label{probaKSubsetUn}
		\Prob(K \subset U^n) = \Prob(J_1, \dots, J_k \in U) \leq (s/r)^{dn}.
	\end{equation}
	%
	Define a random collection of cubes
	%
	\begin{equation}\label{KUDef}
		\mathcal{K}(U)=\{ K \in \B_s^{dn}(Z_s) \colon U\in U^n,\ K\ \textrm{strongly non-diagonal}  \}.
	\end{equation}
	%
	By \eqref{probaKSubsetUn} and linearity of expectation,
	%
	\begin{equation}\label{expectedNumberOfCubes}
		\Expect(\# \mathcal{K}(U)) = \sum_K \Prob(K \subset U^n) \leq \# \B_s^{dn}(Z_s) \cdot (s/r)^{dn} = |Z_s| r^{-dn},
	\end{equation}
	%
	where $K$ ranges over strongly non-diagonal cubes in $\B^{dn}_s(Z_s)$. In particular, \eqref{expectedNumberOfCubes} implies that there exists at least one (non-random) set $U_0$ such that
	%
	\begin{equation}\label{KU0Small}
		\# \mathcal{K}(U_0) \leq \Expect(\# \mathcal{K}(U)) \leq |Z_s| r^{-dn} \leq (l/r)^d/2.
	\end{equation}
	%
	In the last inequality, we applied the assumption that $|Z_s| \leq l^d r^{d(n-1)}/2$.

	We define
	%
	\begin{equation}\label{defnOfF}
		F = U_0 - \{ \pi(K)\colon K\in \mathcal{K}(U_0),\ K\ \textrm{strongly non-diagonal} \},
	\end{equation} 
	%
	where $\pi\colon \B_s^{dn}\to \B_s^d$ projects a set $J_1\times\cdots\times J_n \in \B_s^{dn}$ to $J_1 \in \B_s^d$. It now suffices to verify that $F$ satisfies each of the properties required:
	%
	\begin{itemize}
		\item Given any strongly non-diagonal cube $J_1 \times \cdots \times J_n \in \B_s^{dn}(Z_s)$, either $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(U_0^n)$, or $J_1 \times \cdots \times J_n \in \B_s^{dn}(U_0^n)$. If the former occurs then $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(F^n)$ since $F\subset U_0$, while if the latter occurs then $K \in \mathcal{K}(U_0)$, so $J_1 \not \in \B_s^d(F)$. In either case, $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(F^n)$, so $F$ satisfies Property \ref{avoidanceItem}.

		\item Since $F\subset U_0$, and $U_0$ satisfies Property \ref{nonConcentrationItem}, $F$ also satisfies Property \ref{nonConcentrationItem}.

		\item We note that $\B^d_s(U_0) = \B^d_r(E) = \B^d_l(E) (l/r)^d$. Combined with \eqref{KU0Small}, this implies
		%
		\begin{equation} \label{FLowerBound}
		\begin{split}
			\B^d_s(F) = \B^d_s(U_0) - \mathcal{K}(U_0) &\geq \B^d_r(E) - (l/r)^d/2 = \B^d_l(E) (l/r)^d - (l/r)^d/2.
		\end{split}
		\end{equation}
		%
		Let $I_1, \dots, I_N$ enumerate all cubes in $\B^d_l(E)$, so $N = \B^d_l(E)$. Then we know
		%
		\begin{equation} \label{BdFDecomposition}
			\# \B^d_s(F) = \# \B^d_s(F \cap I_1) + \dots + \# \B^d_s(F \cap I_N).
		\end{equation}
		%
		Property \ref{nonConcentrationItem} implies that for each index $i$,
		%
		\begin{equation} \label{maxLocalBound}
			\# \B^d_s(F \cap I_i) \leq \B^d_r(I_i) = (l/r)^d
		\end{equation}
		%
		If there is an index $i$ for which $\# \B^d_s(F \cap I_i) < (l/r)^d/2$, then \eqref{BdFDecomposition} and \eqref{maxLocalBound} imply
		%
		\begin{align*}
			\# \B^d_s(F) \leq (l/r)^d/2 + (N - 1)(l/r)^d = (l/r)^d(N - 1/2) = (l/r)^d(\B^d_l(E) - 1/2)
		\end{align*}
		%
		Applying the assumption that $|Z_s| < l^d r^{d(n-1)} / 2$, we continue the calculation, concluding
		%
		\[ \# \B^d_s(F) \leq (l/r)^d \B^d_l(E) - (l/r)^d/2 < (l/r)^d \B^d_l(E) - |Z_s| r^{-dn} \]
		%
		This contradicts \eqref{FLowerBound}, so for any index $i$, we must have $\# \B^d_s(F \cap I_i) \geq (l/r)^d/2$. Thus the set $F$ satisfies Property \ref{largeSizeItem}.
	\end{itemize}
	%
	Thus we have shown $F$ satisfies all requirements of the Lemma.
\end{proof}

\begin{remark}
	While the existence of the set $F$ in Lemma \ref{discretelemma} was obtained by probabilistic techniques, we emphasize that it's existence is a purely deterministic statement. One can find a candidate $F$ constructively by checking all of the finitely many possible choice of $U$ to find one particular choice $U_0$ which satisfies $\eqref{KU0Small}$, and then defining $F$ by \eqref{defnOfF}.
	%The advantage of the probabilistic argument is that we are able to find an explicit bound for the minimal cardinality of $\mathcal{K}(U)$. 
	Thus the set we obtain in Theorem \ref{mainTheorem} exists by purely constructive means.
\end{remark}

% DISCUSS: THIS PARAGRAPH IS IMPORTANT, BECAUSE IT SHOWS WHY THE LEMMA IS THE MOST IMPORTANT ASPECT TO OBTAINING THE DIMENSION BOUND.
Our inability to select almost every cube in Lemma \ref{discretelemma} means that repeated applications of the result will lead to a loss in Hausdorff dimension. In fact, in the worst case, applying the lemma causes us to lose as much Hausdorff dimension as is permitted by Theorem 1. To see why, we will later see that if $Z$ is the countable union of sets with lower Minkowski dimension $\alpha$, the scale $s$ discretization $Z_s$ satisfies $|Z_s| \leq s^{dn - \alpha - \varepsilon}$, for some small positive $\varepsilon$ converging to zero as $s \to 0$. In the worst case, however, it is certainly possible that
%
\begin{equation}\label{ZsBadBound}
	|Z_s| \geq s^{dn - \alpha}.
\end{equation}
%
In this situation, we can only apply Lemma \ref{discretelemma} if $s^{dn - \alpha} \leq l^d r^{d(n-1)}/2$, which implies
%
\begin{equation} \label{rConstraint}
	r \geq s^{(dn - \alpha)/d(n-1)},
\end{equation}
%
If we combine \eqref{rConstraint} with Property \ref{nonConcentrationItem} of Lemma \ref{discretelemma}, we conclude
%
\begin{equation} \label{boxCountingBound}
	\frac{\log \# \B^d_s(F)}{\log(1/s)} \leq \frac{\log \# \B^d_r(E)}{\log(1/s)} = \frac{\log |E| r^{-d}}{\log(1/s)} = \frac{d \log(1/r) - \log |E|^{-1}}{\log(1/s)} \leq \frac{dn - \alpha}{n - 1}
\end{equation}
%
Given a set $F = \bigcap F_k$, where $\{ F_k \}$ are infinitely many sets obtained from an application of Lemma \ref{discretelemma} at a sequence of scales $\{ s_k \}$ with $s_k \to 0$ as $k \to \infty$, then \eqref{boxCountingBound} can be easily used to show
%
\begin{equation} \label{badDimension}
	\hausdim(F) \leq \frac{dn - \alpha}{n-1}.
\end{equation}
%
Comparing \eqref{badDimension} to the Hausdorff dimension of the set $X$ obtained in Theorem \ref{mainTheorem}, we see that we must be very careful to ensure applications of the discrete lemma are the only place in our proof where dimension is lost.

\begin{remark}
	Lemma \ref{discretelemma} is the core of our avoidance technique. The remaining argument is fairly modular. If, for a special case of $Z$, one can improve Lemma \ref{discretelemma} using a different proof technique so that a better bound can be placed on the number of cubes discarded, then the remaining parts of our paper can be applied near verbatim to yield a set $X$ with larger Hausdorff dimension to Theorem \ref{mainTheorem}. The dimension this new technique yields can then be found by an analogous calculation to the last pragraph.
\end{remark}










\section{Fractal Discretization}\label{discretizationsection}
In this section we will construct the set $X$ by applying Lemma \ref{discretelemma} at many scales. Since $Z$ is a countable union of compact sets with Minkowski dimension at most $\alpha$, there exists a strong cover (see Definition \ref{strongCoverDefn}) of $Z$ by cubes restricted to a sequence of dyadic scales $\{ l_k \}$. We will select this strong cover so that the scales $l_k$ converge to 0 very quickly.

\begin{lemma} \label{coveringlemma}
	Let $Z \subset \RR^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Let $\{ \varepsilon_k \}$ be a sequence of positive numbers and let $\{ f_k \}$ be a sequence of functions from $(0,\infty)$ to $(0,\infty)$. Then there exists a sequence of dyadic lengths $\{ l_k \}$ and compact sets $\{ Z_k \}$ such that
	%
	\begin{enumerate}
		\item For each index $k \geq 2$, $l_k \leq f_{k-1}(l_{k-1})$.
		\item For each index $k$, $Z_k$ is a union of cubes in $\B^{dn}_{l_k}$.
		\item $Z$ is strongly covered by the sets $\{ Z_k \}$.
		\item For each index $k$, $\# \B^{dn}_{l_k}(Z_k) \leq 1/l_k^{\alpha + \varepsilon_k}$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	Let $Z$ be the union of sets $\{ Y_k \}$ with $\lowminkdim(Y_k) \leq \alpha$ for each $k$. Let $m_1, m_2, \dots$ be a sequence of integers that repeats each integer infinitely often. For each positive integer $k$, since $\lowminkdim(Y_{m_k}) \leq \alpha$, \eqref{minkdimdef} implies that there exists arbitrarily small lengths $l$ which satisfy $\# \B_l^{dn}(Y_{m_k}) \leq 1/l^{\alpha + (\varepsilon_k/2)}$. Replacing $l$ with a dyadic scale at most twice the size of $l$, there are infinitely many {\it dyadic} scales $l$ with
	%
	\begin{equation} \label{minkdimimplication}
		\# \B^{dn}_l(Y_{m_k}) \leq \frac{1}{(l/2)^{\alpha + \varepsilon_k}} \leq \frac{2^{dn}}{l^{\alpha + (\varepsilon_k/2)}} = \frac{\left( 2^{dn} l^{\varepsilon_k/2} \right)}{l^{\alpha + \varepsilon_k}}.
	\end{equation}
	%
	In particular, we may select a dyadic length $l$ such that $2^{dn} l^{\varepsilon_k/2} \leq 1$, and, if $k \geq 2$, also satisfying $l \leq f_{k-1}(l_{k-1})$. The first constraint together with \eqref{minkdimimplication} implies $\# \B^{dn}_l(Y_{m_k}) \leq 1/l^{\alpha + \varepsilon_k}$. We then set $l_k = l$, and define $Z_k$ to be the union of all cubes in $\B_{l_k}^{dn}(Y_{m_k})$.
\end{proof}

We now construct $X$ by avoiding the various discretizations of $Z$ at each scale. The aim is to find a nested decreasing family of discretized sets $\{ X_k \}$ with $X = \bigcap X_k$. One condition guaranteeing that $X$ avoids $Z$ is that $X_k^n$ is disjoint from {\it strongly non-diagonal} cubes in $Z_k$.

\begin{lemma} \label{stronglydiagonal}
	Let $Z \subset \RR^{dn}$ and let $\{ l_k \}$ be a sequence of lengths converging to zero. For each index $k$, let $Z_k$ be a union of cubes in $\B^{dn}_{l_k}$, and suppose the sets $\{ Z_k \}$ strongly cover $Z$. For each index $k$, let $X_k$ be a union of cubes in $\B^d_{l_k}$. Suppose that for each $k$, $X_k^n$ avoids strongly non-diagonal cubes in $Z_k$. If $X = \bigcap X_k$, then $(x_1, \dots, x_n) \not \in Z$ for each distinct $x_1, \dots, x_n \in X$.
\end{lemma}
\begin{proof}
	Let $z \in Z$ be a point with distinct coordinates $z_1, \dots, z_n$. Set
	%
	\[ \Delta = \{ (w_1, \dots, w_n) \in \RR^{dn}: \text{there exists $i \neq j$ such that $w_i = w_j$} \}. \]
	%
	Then $d(\Delta,z) > 0$, where $d$ is the Hausdorff distance between $\Delta$ and $z$. Since $\{ Z_k \}$ strongly covers $Z$, there is a subsequence $\{ k_m \}$ such that $z \in Z_{k_m}$ for each index $m$. For suitably large $m$, the sidelength $l_k$ cube $I$ in $Z_{k_m}$ containing $z$ is disjoint from $\Delta$. But this means $I$ is strongly non-diagonal, and so $z \not \in X_{k_m}^n$. In particular, $z$ is not an element of $X^n$.
\end{proof}

% DISCUSS: Technically we are proving Theorem 1 for the whole paper, and we don't finish the proof here?

We are now ready to construct the set $X$ in Theorem \ref{mainTheorem}. Let $l_0 = 1$ and $X_0 = [0,1)^d$. For each $k \geq 1$, define $\varepsilon_k = c/k$, where we view $c = (dn - \alpha)/4$ as a irrelevant constant small enough that $dn - \alpha - 2\varepsilon_k > 0$ for each $k$. We set
%
\begin{equation}\label{defnFK}
	f_k(x) = \min \left( (x^d/2)^{1/\varepsilon_{k+1}}, x^{k^2} \right)
%	f_k(x)=\min \left( x^{k^2}, (x^d4^{-k-1})^{\frac{1}{\varepsilon_{k+1}d(n-1)}} \right).
\end{equation}
%
Apply Lemma \ref{coveringlemma} to $Z$ with this choice of $\{\varepsilon_k\}$ and $\{f_k\}$; let $\{l_k\}$ be the resulting sequence of length scales and let $\{Z_k\}$ be the resulting strong cover of $Z$. Observe that \eqref{defnFK} implies that for each index $k$,
%
\begin{equation} \label{boundOnLk}
	l_{k+1}^{\varepsilon_{k+1}} \leq l_k^d/2 \quad \text{and} \quad l_{k+1} \leq l_k^{k^2}
\end{equation}
%
For each index $k \geq 1$, define $l = l_k$, $s = l_{k+1}$, and $r = l_{k+1}^{(dn - \alpha - 2\varepsilon_{k+1})/d(n-1)}$. Observe that $X_k$ is a non-empty union of cubes in $\B^d_l$; that $Z_{k+1}$ is a union of cubes in $\B^{dn}_s$; and that
%
\[ |Z_{k+1}| \leq s^{dn - \alpha - \varepsilon_{k+1}} = r^{d(n-1)} s^{\varepsilon_{k+1}} \leq l^d r^{d(n-1)}/2 \]
%
Setting $Z_s = Z_{k+1}$, we are therefore justified in applying Lemma \ref{discretelemma} with the choices of $l$, $r$, and $s$ described above, and with $\varepsilon = \varepsilon_{k+1}$. We obtain a set $F \subset X_k$ which is a union of cubes in $\B^d_s(E)$ satisfying Properties \ref{avoidanceItem}, \ref{nonConcentrationItem}, and \ref{largeSizeItem} from the lemma, and we define $X_{k+1} = F$. Property \ref{avoidanceItem} implies $X_{k+1}$ avoids strongly non-diagonal cubes in $Z_{k+1}$, so if we define $X = \bigcap X_k$, then Lemma \ref{stronglydiagonal} implies $(x_1, \dots, x_n) \not \in Z$ for each distinct $x_1, \dots, x_n \in X$.









\section{Dimension Bounds}\label{dimensionsection}

To complete the proof of Theorem \ref{mainTheorem}, we must show that $\dim_{\mathbf{H}}(X) \geq \beta$, where
%
\[ \beta = \frac{dn - \alpha}{n - 1} \]
%
This section gives a proof of this claim. We begin with a rough outline of our proof strategy. Recall that from the previous section, we have a decreasing sequence of lengths $\{ l_k \}$. At the discrete scale $l_k$, we will find that $X$ looks like a set with dimension $\beta - O(1/k)$. As $k \to \infty$, $\beta - O(1/k) \to \beta$, so $X$ looks $\beta$ dimensional at the discrete scales. To obtain the complete dimension bound, it then suffices to interpolate to get a $\beta$ dimensional behaviour at all intermediate scales. In this construction, as in \cite{MalabikaRob}, the rapid decay of the lengths $\{ l_k \}$ means interpolating poses a significant difficulty. We avoid this difficulty because of the uniform way that we have selected cubes in consecutive scales. This will imply that between the scales $l_k$ and $r_{k+1}$, $X$ behaves like a full dimensional set.

The most convenient way to examine the dimension of $X$ at various scales is to use Frostman's lemma. We construct a probability measure $\mu$ supported on $X$ such that for all $\varepsilon > 0$, for all lengths $l$, and for all $I \in \B^d_l$, $\mu(I) \lesssim_\varepsilon l^{\beta - \varepsilon}$. For each $\varepsilon > 0$, the measure $\mu$ is a Frostman measure with dimension at least $\beta - \varepsilon$ (see Definition \ref{frostmanItem}). This implies that $\hausdim(X) \geq \beta$. The advantage of this approach is that once a natural choice of $\mu$ is fixed, it is easy to understand the behaviour of $X$ at a scale $l$ by looking at the behaviour of $\mu$ restricted to cubes at the scale $l$.

Let's construct the measure $\mu$. First, we define a function $p$ recursively on $\bigcup_{i = 1}^\infty \B^d_{l_i}$. We initially set $p([0,1)^d) = 1$. Given $I \in \B^d_{l_{k+1}}$, we find a parent cube $I' \in \B^d_{l_k}$ with $I \subset I'$. If $I \subset X_{k+1}$, then we set
%
\[ p(I) = \frac{p(I')}{\# \B^d_{l_k}(X_{k+1} \cap I')} \]
%
Otherwise, if $I \not \subset X_{k+1}$, we set $p(I) = 0$. We construct $\mu$ as an exterior measure by setting
%
\[ \mu(E) = \inf \left\{ \sum_{i = 1}^\infty p(I_i): E \subset \bigcup_{i = 1}^\infty I_i\ \text{and}\ I_i \subset \bigcup_{j = 1}^\infty \B^d_{l_j}\ \text{for each $i$}  \right\} \]
%
It is easy to see that $p$ is finitely additive. This means that we have a cover of some set $E$ by some cubes $\{ I_i \}$, then for each $\varepsilon$, we can refine each $I_i$ with sidelength greater than $\varepsilon$ into finitely many smaller cubes with sidelength smaller than $t$, obtaining a cover of $E$ by cubes $\{ J_i \}$, such that the sidelength of each $J_i$ is smaller than $\varepsilon$, and $\sum p(J_i) = \sum p(I_i)$. This can be easily used to show $\mu$ is a metric outer measure, and hence is measurable on all Borel sets. The fact that $\mu(I) \leq p(I)$ for each $I \in \bigcup_{i = 1}^\infty \B^d_{l_i}$ will be very useful for passing from discrete bounds to continuous bounds. Since $p(I) = 0$ for any cube $I$ in $\B^d_{l_i}$ not contained in $X_i$, $\mu$ is supported on $X_k$ for each $k$, and in particular, $\mu$ is supported on $X$. The remainder of this section is then devoted to showing that $\mu$ is a Frostman measure of dimension $\beta - \varepsilon$ for each $\varepsilon > 0$.

\begin{lemma} \label{mubound}
	If $I \in \B^d_{l_k}$, then
	%
	\begin{equation}
		\mu(I) \leq p(I) \leq 2^k \left[ \frac{r_k \dots r_1}{l_{k-1} \dots l_1} \right]^d.
	\end{equation}
\end{lemma}
\begin{proof}
	Consider $I \in \B^d_{l_{i+1}}$, together with a parent cube $I' \in \B^d_{l_i}$ with $I \subset I'$. If $p(I) > 0$, $I \subset X_{i+1}$, so $I' \subset X_i$. Because $X_{i+1}$ was obtained from $X_i$ via an application of Lemma 1, Property \ref{largeSizeItem} of that lemma states that $\# \B^d_{l_{i+1}}(X_{i+1} \cap I) \geq (l/r)^d/2$, so
	%
	\begin{equation} \label{oneStepBound}
		p(I) = \frac{p(I')}{\# \B^d_{l_{i+1}}(X_{i+1} \cap I)} \leq \frac{2 p(I')}{(l_i/r_{i+1})^d}
	\end{equation}
	%
	Expanding \eqref{oneStepBound} recursively completes the proof, using the base case that $p([0,1]^d) = 1$.
\end{proof}

Treating all parameters in \eqref{mubound} which depend on indices smaller than $k$ as essentially constant, we `conclude' that $p(I) \lesssim r_k^d \lesssim l_k^{\beta - 2d \cdot \varepsilon_{k+1}}$. The bound $l_{k+1} \leq l_k^{k^2}$ from \eqref{boundOnLk} implies $l_k$ decays very rapidly, which enables us to ignore quantities depending on previous indices, and obtain a true inequality.

\begin{corollary}
	For all $I \in \B^d_{l_k}$, $\mu(I) \leq p(I) \lesssim l_k^{\beta - O(1/k)}$.
\end{corollary}
\begin{proof}
	Given $\varepsilon > 0$, Lemma \ref{mubound}, the inequality $l_k \leq l_{k-1}^{(k-1)^2}$ from \eqref{boundOnLk}, and the fact that $\varepsilon_{k+1} = O(1/k)$ imply
	%
	\begin{align*}
		p(I) &\leq 2^k \left[ \frac{r_k \dots r_1}{l_{k-1} \dots l_1} \right]^d \leq \left( \frac{2^k}{l_{k-1}^d \dots l_1^d} \right) l_k^{\beta - O(1/k)}\\
		&= \left( \frac{2^k l_k^{2d/k}}{l_{k-1}^{d(k-1)}} \right) l_k^{\beta - O(1/k) - 2d/k} \leq \left( 2^k l_{k-1}^{(2d/k)(k-1)^2 - d(k-1)} \right) l_k^{\beta - O(1/k)} = o(l_k^{\beta - O(1/k)}). \tag*{\qedhere}
	\end{align*}
\end{proof}

Corollary 3 gives a clean expression of the $\beta$ dimensional behaviour of $\mu$ at discrete scales. To obtain a Frostman measure bound at {\it all} scales, we need to apply a covering argument. This is where the uniform mass assignment technique comes into play. Because $\mu$ behaves like a full dimensional set between the scales $l_k$ and $r_{k+1}$, we won't be penalized for making the gap between $l_k$ and $r_{k+1}$ arbitrarily large. This is essential to our argument, because $l_k$ decays faster than $2^{-k^m}$ for each $m > 0$.

\begin{lemma} \label{frostmanBound}
	If $l$ is dyadic and $I \in \B_l^d$, then $\mu(I) \lesssim l^{\beta - \varepsilon}$ for all $\varepsilon > 0$.
\end{lemma}
\begin{proof}
	We begin by assume $l \leq l_k$ for some $k$, and prove $\mu(I) \lesssim l^{\beta - O(1/k)}$. To do this, we apply a covering argument, which breaks into cases depending on the size of $l$ in proportion to the scales $l_k$ and $r_k$:
	%
	\begin{itemize}
		\item If $r_{k+1} \leq l \leq l_k$, we can cover $I$ by $(l/r_{k+1})^d$ cubes in $\B^d_{r_{k+1}}$. Because of the non-concentration and breadth properties of our construction, we therefore know that the mass of each cube in $\B^d_{r_{k+1}}$ is bounded by at most $2 (r_{k+1}/l_{k+1})^d$ times the mass of a cube in $\B_{l_k}^d$. Thus
		%
		\[ \mu(I) \lesssim (l/r_{k+1})^d (2(r_{k+1}/l_k)^d) l_k^{\beta - O(1/k)} \leq 2l^d/l_k^{d - \beta + O(1/k)} \leq 2l^{\beta - O(1/k)}, \]
		%
		where we used the fact that $d - \beta + O(1/k) \geq 0$, so $l_k^{d - \beta + O(1/k)} \geq l^{d - \beta + O(1/k)}$.

		\item If $l_{k+1} \leq l \leq r_{k+1}$, we can cover $I$ by a single cube in $\B^d_{r_{k+1}}$. Each cube in $\B^d_{r_{k+1}}$ contains at most one cube of $\B^d_{l_{k+1}}$ also contained in $X_{k+1}$, so $\mu(I) \lesssim l_{k+1}^{\beta - O(1/k)} \leq l^{\beta - O(1/k)}$.

		\item If $l \leq l_{k+1}$, there certainly exists $m$ such that $l_{m+1} \leq l \leq l_m$, and one of the previous cases yields that $\mu(I) \lesssim l^{\beta - O(1/m)} \leq l^{\beta - O(1/k)}$.
	\end{itemize}
	%
	If $l \geq l_k$, then $\mu(I) \leq 1 \lesssim_k l_k^{\beta - O(1/k)} \leq l^{\beta - O(1/k)}$, so we obtain $\mu(I) \lesssim_k l^{\beta - O(1/k)}$ for arbitrary dyadic $l$. Since $k$ is arbitrary, this proves the claim.
\end{proof}

Applying Frostman's lemma to Lemma \ref{frostmanBound} gives $\hausdim(X) \geq \beta$. This concludes the proof of Theorem \ref{mainTheorem}.









\section{Applications}\label{applications}

As discussed in the introduction, Theorem 1 generalizes Theorems 1.1 and 1.2 from \cite{MalabikaRob}. In this section, we present two applications of Theorem \ref{mainTheorem} in settings where previous methods cannot obtain any results.

\begin{theorem}[Sum-sets avoiding specified sets]
	Let $Y \subset \RR^d$ be a countable union of sets of Minkowski dimension at most $\alpha$. Then there exists a set $X \subset \RR^d$ with Hausdorff dimension $1 - \alpha$ such that $X + X$ is disjoint from $Y$.
\end{theorem}
\begin{proof}
	Define $Z = Z_1 \cup Z_2$, where
	%
	\[ Z_1 = \{ (x,y) : x + y \in Y \} \quad \text{and} \quad Z_2 = \{ (x,y): y \in Y/2 \}. \]
	%
	Since $Y$ is a countable union of sets of Minkowski dimension at most $\alpha$, $Z$ is a countable union of sets with lower Minkowski dimension at most $1 + \alpha$. Applying Theorem \ref{mainTheorem} with $d = 1$, $n = 2$, giving a set $X \subset \RR^d$ with Hausdorff dimension $1 - \alpha$ avoiding $Z$. Since $X$ avoids $Z_1$, whenever $x,y \in X$ are distinct, $x + y \not \in Y$. Since $X$ avoids $Z_2$, $X \cap (Y/2) = \emptyset$, and thus for each $x \in X$, $x + x \not \in Y$. Thus $X + X$ is disjoint from $Y$.
\end{proof}

\begin{remark}
	One weakness of our result is that as the number of variables $n$ increases, the dimension of $X$ tends to zero. If we try and make the $n$-fold sum $X + \cdots + X$ disjoint from $Y$, current techniques only yield a set of dimension $(1 - \alpha)/(n-1)$. We have ideas on how to improve our main result when $Z$ is `flat', in addition to being low dimension, which will enable us to remove the dependence of $\hausdim(X)$ on $n$. In particular, we expect to be able to construct a set $X$ of dimension $1 - \alpha$, such that $X$ is disjoint from $Y$, and $X$ is closed under addition, and multiplication by rational numbers. In particular, given a $\QQ$ subspace $V$ of $\RR^d$ with dimension $\alpha$, we can always find a `complementary' $\QQ$ vector space $W$ with complementary fractional dimension $d - \alpha$ such that $V \cap W = (0)$.
\end{remark}

In \cite{MalabikaRob}, Fraser and the second author show that if $\gamma$ is a $C^2$ curve with non-vanishing curvature, then there exists a set $E \subset \gamma$ of Hausdorff dimension $1/2$ that does not contain isoceles triangles. Our method extends this result from the case of curves to more general plane sets.

\begin{theorem}[Restricted sets avoiding isoceles triangles]
	Let $Y \subset \RR^2$ and let $\pi: \RR^2 \to \RR$ be an orthogonal projection such that $\pi(Y)$ has non-empty interior. Let $d$ be an arbitrary metric on $\RR^2$. Suppose that
	%
	\[ Z_0 = \{ (y_1, y_2, y_3) \in Y^3: d(y_1,y_2) = d(y_1,y_3) \} \]
	%
	is the countable union of sets with lower Minkowski dimension at most $2 + \varepsilon$, for $\varepsilon \geq 0$. Then there exists a set $X \subset Y$ with dimension $1/2 - O(\varepsilon)$ so that no triple of points $(x_1, x_2, x_3) \in X^3$ form the vertices of an isoceles triangle.
\end{theorem}
\begin{proof}
	Without loss of generality, by translation and rescaling, assuming $\pi(Y)$ contains $[0,1]$. Form the set
	%
	\[ Z = \pi(Z_0) = \{ (\pi(y_1), \pi(y_2), \pi(y_3)) : y \in Z_0 \} \]
	%
	Then $Z$ is the projection of a $2 + t$ dimensional set, and therefore has dimension at most $2 + t$. Applying Theorem \ref{mainTheorem} with $d = 1$ and $n = 3$, we construct a Hausdorff dimension $1/2 - \varepsilon/2$ set $X_0 \subset [0,1]$ such that for each distinct $x_1,x_2,x_3 \in X_0$, $(x_1,x_2,x_3) \not \in Z$. Thus if we form a set $X$ by picking, from each $x \in X_0$, a single element of $\pi^{-1}(x)$, then $X$ avoids isoceles triangles, and has Hausdorff dimension at least as large as $X_0$.
\end{proof}

To see that Theorem 3 indeed generalizes the result of Fraser and the second author, observe that if $d$ is the Euclidean metric, then for every pair of points $x,y \in \RR^2$, the set
%
\[ \{ z \in \RR^2: d(x,z) = d(y,z) \} \]
%
is the perpendicular bisector $B_{xy}$ of $x$ and $y$. If $\gamma$ is a compact portion of a smooth curve with non-vanishing curvature, then the number of points in $\gamma \cap B_{xy}$ is bounded independantly of $x$ and $y$. Thus $Z_0$ in the statement of Theorem 3 has Minkowski dimension at most 2.

Results about slice of measures, e.g. those detailed in Chapter 6 of \cite{Matilla} show that for each one dimensional set $Y$, for almost every line $L$, $L \cap Y$ consists of a finite collection of points. This suggests that if $Y$ is any set with fractional dimension one, then $Z_0$ has dimension at most 2. We are unsure if this is true for every set with dimension one, but we provide two separate results which suggest that the result is true for a generic set. The first result shows that for an infinite family of Cantor-type sets with dimension $1 + \varepsilon$, $Z_0$ has dimension at most $3 - \varepsilon$. Thus Theorem 3 can be applied in settings where $Y$ is incredibly `rough', i.e. totally disconnected.

The probabilistic model we study is obtained by considering a nested family of random discretized sets $C_0,C_1, \dots$ with $C_k$ a union of sidelength $1/2^k$ squares. First, we fix $p \in [0,1]$. Then we set $C_0 = [0,1]^2$. To construct $C_{k+1}$, we split $C_k$ into sidelength $1/2^{k+1}$ squares, and keep each square in $C_{k+1}$ with probability $p$. Then every sidelength $1/2^k$ cube is contained in $C_k$ with probability $p^k$, and so $C_k$ contains, on average, $(4p)^k$ sidelength $1/2^k$ cubes. We now show that if $p > 1/4$, $C$ almost surely has Minkowski dimension $2 - \log_2(1/p)$.

\begin{lemma} \label{randomdimension}
	If $p > 1/4$, then almost surely, $C = \emptyset$, or has Minkowski dimension $2 - \log_2(1/p)$, and this second case occurs with non-zero probability.% If $p \leq 1/4$, $C$ is almost surely empty.
\end{lemma}
\begin{proof}
	Let $p > 1/4$. For each $k$, let $Z_k$ denote the number of sidelength $1/2^k$ cubes in $[0,1]^2$. Then $\Expect[Z_{k+1}|Z_k] = (4p) Z_k$, so by induction we can verify that $\Expect[Z_k] = (4p)^k$. The sequence $\{ Z_k \}$ is a branching process, where each cube can produce between zero and four subcubes. The Kesten-Stigum theorem (the main result of \cite{KestenStigum}) implies that almost surely, there exists a random constant $A_0$ such that $Z_k \sim A_0 (4p)^k$, $\Expect(A_0) = 1$, and $A_0 = 0$ if and only if it is eventually true that $Z_k = 0$ for sufficiently large $k$, so $C_k = \emptyset$ eventually. Whenever $A_0$ is non-zero, we find
	%
	\[ \minkdim(C) = \lim_{k \to \infty} \frac{\log Z_k}{k \log 2} = \lim_{k \to \infty} \frac{\log(Z_k/A_0 (4p)^k) + \log A_0 (4p)^k}{k \log 2} = 2 - \log_2(1/p) \]
	%
	Since $\Expect(A_0) \neq 0$, $A_0$ is non-zero with positive probability. %If $p \leq 1/4$, the basic theory of extinction probabilities for branching processes (e.g. Chapter 1, Section 5 of \cite{AthreyaTextbook}) shows that almost surely, $Z_k$ is eventually equal to $0$ for large enough $k$, which implies $C = \emptyset$ almost surely.
\end{proof}

We now show similar theory shows that the resulting set $Z_0$ associated with $C$ almost surely has Minkowski dimension $3 - \alpha$. To do this, we must first prove a lemma about branching processes.

\begin{lemma}\label{branchingtrick}
	Let $Z_0, Z_1, Z_2, \dots$ be a supercritical branching process generated by an offspring law $p_0, \dots, p_N$, with $\sum_{k = 0}^N k p_k = E > 1$. Then there exists a random constant $A$, and a universal constant $c$ such that
	%
	\[ \Prob(Z_k \geq A (p_0 + E)^k) \lesssim \exp(-c E^k) \]
\end{lemma}
\begin{proof}
	Without loss of generality, we may assume the existence of a grid of independant, identically distributed discrete random variables $X_{ij}$ with $\Prob(X_{ij} = k) = p_k$ such that
	%
	\[ Z_{k+1} = \sum_{j = 1}^{Z_k} X_{ij}. \]
	%
	Now consider the branching process $\{ \tilde{Z}_k \}$ defined by setting $\tilde{Z}_0 = 1$, and
	%
	\[ \tilde{Z}_{k+1} = \sum_{j = 1}^{\tilde{Z}_k} \max(X_{ij}, 1). \]
	%
	Then $Z_k \leq \tilde{Z}_k$, and $\Expect(\tilde{Z}_{k+1}|\tilde{Z}_k) = p_0 + \sum_{k = 1}^N k p_k = p_0 + E$. Applying Theorem 5 of \cite{Athreya} implies that if $A_0$ is the random constant obtained as in Lemma \ref{randomdimension}, then there exists a small constant $c$ such that
	%
	\begin{align*}
		\Prob(Z_k \geq (A_0+1) (p_0 + E)^k) &\leq \Prob(\tilde{Z}_k \geq (A_0+1) (p_0 + E)^k)\\
		&\lesssim \exp(-c (p_0 + E)^k ) \leq \exp(-c E^k). \qedhere
	\end{align*}
\end{proof}

We are now able to obtain bounds on the intersection of $C$ with lines in the plane by proceeding along similar lines to the previous argument, together with a chaining argument which enables one to place probability bounds on the intersection properties of $C$ with the infinite set of lines in the plane.

\begin{lemma}
	If $p > 1/2$, then almost surely, $Z_0$ associated with $C$ has lower Minkowski dimension at most $3 - O(\log_2(1/p))$.
\end{lemma}
\begin{proof}
	Fix $N$, and for each index $k$ let $\delta_k = 1/2^{Nk}$. Given a line $L$, let $I$ be a sidelength $\delta_k$ square $I$ intersecting the $\delta_k$ thickened line $L_{\delta_k}$. Then $L$ passes from one side of the box to the other, and so if we split $I$ into $4^N$ sidelength $\delta_{k+1}$ squares, then $L_{\delta_{k+1}}$ intersects at most $10 \cdot 2^N$ of these boxes. Conditioned on $I$ being contained in $C_k$, each of these subboxes occurs in $C_{k+N}$ with probability $p^N$. We let $Z_k(L)$ denote the number of sidelength $1/2^{Nk}$ boxes in $C_{Nk}$ intersecting $L_{\delta_k}$. Let $N > 3$, so that $10 \cdot 2^N < 4^N$. If we let $\tilde{Z_k}(L)$ denote the number of sidelength $1/2^{Nk}$ boxes in $C_{Nk}$, but augmented so exactly $10 \cdot 2^N$ subboxes are added at each stage, then $\tilde{Z_k}(L)$ is a branching process with $Z_k(L) \leq \tilde{Z_k}(L)$ and $\Expect[\tilde{Z}_{k+1}(L)|\tilde{Z}_k(L)] = 10 \cdot (2p)^N \tilde{Z_k}(L)$. The offspring law for this branching process is such that a cube produces no subcubes with probability $(1 - p^N)^{10 \cdot 2^N}$, which converges to zero as $N \to \infty$ since $p > 1/2$. Applying Lemma \ref{branchingtrick}, we conclude that there is a random constant $A$ and a small constant $c$ such that
	%
	\[ \Prob(Z_k(L) \geq A (o(1) + M)^k) \lesssim \exp(-c (2p)^{kN}) \]
	%
	Now the main result of BIGGINS AND BINGHAM show there are two universal constants $c$ and $\lambda > 1$ such that
	%
	\[ \Prob(A \geq t) \leq \exp(-c t^\lambda) \]
	%
	In particular, $\Prob(A \geq k) \leq \exp(-ck^\lambda)$. Putting these two inequalities together gives
	%
	\[ \Prob(Z_k(L) \geq k(o(1) + 10 (2p)^N)^k) \lesssim \exp(-c (2p)^{kN}) + \exp(-c k^\lambda) \lesssim \exp(-c k^\lambda) \]
	%
	For each $k$, we now find lines $L_{k,1}, \dots, L_{k,M}$ such that for any line $L$, there exists $i$ such that $[0,1]^d \cap L_{\delta_k/2} \subset (L_{k,i})_{\delta_k}$. If we do this efficiently, if $B$ is a sufficiently large universal constant, we can guarantee that $M \leq B \cdot 4^{kN}$. Applying a union bound, we find that
	%
	\[ \Prob \left( \text{there is $i$ such that}\ Z_k(L_{k,i}) \geq k(o(1) + 10 (2p)^N)^k \right) \lesssim B \cdot 4^{kN} \exp(-c k^\lambda) \]
	%
	Since $\lambda > 1$, we have
	%
	\[ \sum_{k = 1}^\infty \Prob \left( \text{there is $i$ such that}\ Z_k(L_{k,i}) \geq k(o(1) + 10 (2p)^N)^k \right) < \infty \]
	%
	Applying Borel-Cantelli, we conclude that almost surely, it is eventually true for sufficiently large $k$ that $Z_k(L_{k,i}) \leq k(o(1) + 10 (2p)^N)^k$ for all $i$. In particular, the number of cubes intersecting $L_{\delta_k/2}$ for any line $L$ is bounded by $k(o(1) + 10 (2p)^N)^k = O((100 \cdot (2p)^N)^k)$. Taking $N \to \infty$ `should' prove the claim.

%	Since $C$ almost surely has Minkowski dimension $2 - \log_2(1/p)$, there is a large constant $B'$ such that we can cover $C$ by cubes $I_1, \dots, I_N$ with $N \leq B' (1/\delta_k)^{2 - \log_2(1/p)}$ sidelength $\delta_k/2$ cubes. For each pair of distinct cubes $I_i$ and $I_j$, the set of lines $L_{x_i x_j}$ is contained in a single $\delta_k/2$ thickened line.
\end{proof}











\section{Relation to Literature, and Future Work}\label{futureWorkSection}

Our result is part of a growing body of work finding general methods to find sets avoiding patterns. The main focus of this section is comparing our method to the two other major results in the literature. \cite{MalabikaRob} constructs sets with dimension $k/(n-1)$ avoiding the zero sets of rank $k$ $C^1$ functions. In \cite{Mathe}, sets of dimension $d/l$ are constructed avoiding a degree $l$ algebraic hypersurface specified by a polynomial with rational coefficients.

We can view our result as a robust version of Pramanik and Fraser's result. Indeed, if we try and avoid the zero set of a $C^1$ rank $k$ function, then we are really avoiding a dimension $dn - k$ dimensional manifold. Our method gives a dimension
%
\[ \frac{dn - (dn - k)}{n - 1} = \frac{k}{n - 1} \]
%
set, which is exactly the result obtained in \cite{MalabikaRob}.

That our result generalizes \cite{MalabikaRob} should be expected because the technical skeleton of our construction is heavily modeled after their construction technique. Their result also reduces the problem to a discrete avoidance problem. But they {\it deterministically} select a particular side length $S$ cube in every side length $R$ cube. For arbitrary $Z$, this selection procedure can easily be exploited for a particularly nasty $Z$, so their method must rely on smoothness in order to ensure some cubes are selected at each stage. Our discrete avoidance technique was motivated by other combinatorial optimization problems, where adding a random quantity prevents inefficient selections from being made in expectation. This allows us to rely purely on combinatorial calculations, rather than employing smoothness, and greatly increases the applicability of the sets $Z$ we can apply our method to. Furthermore, it shows that the underlying problem is robust to changes in dimension; slightly `thickening' $Z$ only slightly perturbs the dimension of $X$.

One useful technique in \cite{MalabikaRob}, and its predecessor \cite{KeletiDimOneSet}, is the use of a Cantor set construction `with memory'; a queue in the construction algorithm for their sets allows storage of particular discrete versions of the problem to be stored, and then retrieved at a much later stage of the construction process. This enables them to `separate' variables in the discrete version of the problem, i.e. instead of forming a single set $F$ from a set $E$, they from $n$ sets $F_1, \dots, F_n$ from disjoint sets $E_1, \dots, E_n$. The fact that our result is more general, yet does not rely on this technique is an interesting anomaly. An obvious advantage is that the description of the technique is much more simple. But an additional advantage is that we can attack `one scale' of the problem at a time, rather than having to rely on stored memory from a vast number of steps before the current one. We believe that we can exploit the single scale approach to the problem to generalize our theorem to a much wider family of `dimension $\alpha$' sets $Z$, which we plan to discuss in a later paper.

As a generalization of the result in \cite{MalabikaRob}, our result has the same issues when compared to the result of \cite{Mathe}. When the parameter $n$ is large, the dimension of our result suffers greatly, as with the $n$ fold sum application in the last section. Furthermore, our result can't even beat trivial results if $Z$ is almost full dimensional, as the next example shows.

\begin{example}
	Consider an $\alpha$ dimensional set of angles $Y$, and try and find $X \subset \RR^2$ such that the angle formed from any collection of three points in $X$ avoids $Y$. If we form the set
	%
	\[ Z = \left\{ (x,y,z): \text{There is $\theta \in Y$}\ \text{such that}\ \frac{(x - y) \cdot (x - z)}{|x - y||x - z|} = \cos \theta \right\} \]
	%
	Then we can find $X$ avoiding $Z$. But one calculates that $Z$ has dimension $3d + \alpha - 1$, which means $X$ has dimension $(1 - \alpha) / 2$. Provided the set of angles does not contain $\pi$, the trivial example of a straight line beats our result.
\end{example}

Nonetheless, we still believe our method is a useful inspiration for new techniques in the `high dimensional' setting. Most prior literature studies sets $Z$ only implicitly as zero sets of some regular function $f$. The features of the function $f$ imply geometric features of $Z$, which are exploited by these results. But some geometric features are not obvious from the functional perspective; in particular, the fractional dimension of the zero set of $f$ is not an obvious property to study. We believe obtaining methods by looking at the explicit geometric structure of $Z$ should lead to new techniques in the field, and we already have several ideas in mind when $Z$ has geometric structure in addition to a dimension bound, which we plan to publish in a later paper.

We can compare our randomized selection technique to a discrete phenomenon that has been recently noticed, for instance in \cite{BaloghMorrisSamotij}. There, certain combinatorial problems can be rephrased as abstract problems on hypergraphs, and one can then generalize the solutions of these problems using some strategy to improve the result where the hypergraph is sparse. Our result is a continuous analogue of this phenomenon, where sparsity is represented by the dimension of the set $Z$ we are trying to avoid. One can even view Lemma 1 as a solution to a problem about independent sets in hypergraphs. In particular, we can form a hypergraph by taking the cubes $\B^d_s(E)$ as vertices, and adding an edge $(I_1, \dots, I_n)$ between $n$ distinct cubes $I_k \in \B^d_s(E)$ if $I_1 \times \dots \times I_n$ intersects $Z_s$. An independent set of cubes in this hypergraph corresponds precisely to a set $F$ with $F^n$ disjoint except on a discretization of the diagonal. And so Lemma 1 really just finds a `uniformly chosen' independent set in a sparse graph. Thus we really just applied the discrete phenomenon at many scales to obtain a continuous version of the phenomenon.








\bibliographystyle{amsplain}
\bibliography{FractalsAvoidingFractalSetsPaper}

\end{document}