\documentclass[12pt,reqno]{article}

%\documentclass[dvipsnames,letterpaper,12pt]{article}

\usepackage[margin = 1in]{geometry}
\usepackage{amsmath,amssymb,graphicx,mathabx,accents}
\usepackage{enumerate,mdwlist}

%\setlist[enumerate]{label*={\normalfont(\Alph*)},ref=(\Alph*)}

\numberwithin{equation}{section}

\usepackage{amsthm}

\usepackage{hyperref}

\usepackage{verbatim}

\usepackage{nag}

\DeclareMathOperator{\minkdim}{\dim_{\mathbf{M}}}
\DeclareMathOperator{\hausdim}{\dim_{\mathbf{H}}}
\DeclareMathOperator{\lowminkdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\upminkdim}{\overline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\fordim}{\dim_{\mathbf{F}}}

\DeclareMathOperator{\lhdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\lmbdim}{\underline{\dim}_{\mathbf{MB}}}

\DeclareMathOperator{\RR}{\mathbf{R}}
\DeclareMathOperator{\ZZ}{\mathbf{Z}}
\DeclareMathOperator{\QQ}{\mathbf{Q}}
\DeclareMathOperator{\TT}{\mathbf{T}}
\DeclareMathOperator{\CC}{\mathbf{C}}

\DeclareMathOperator{\B}{\mathcal{B}}

\newtheorem{theorem}{Theorem}
%\newtheorem{lemma}{Lemma}
%\newtheorem{corollary}{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{prop}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
%\newtheorem*{concludingremarks}{Concluding Remarks}
\numberwithin{theorem}{section}

\DeclareMathOperator{\EE}{\mathbf{E}}
\DeclareMathOperator{\PP}{\mathbf{P}}

\DeclareMathOperator{\DQ}{\mathcal{Q}}
\DeclareMathOperator{\DR}{\mathcal{R}}

\newcommand{\psitwo}[1]{\| {#1} \|_{\psi_2(L)}}
\newcommand{\TV}[2]{\| {#1} \|_{\text{TV}({#2})}}








\title{Large Salem Sets Avoiding Configurations}
\author{Jacob Denson}

\begin{document}

\maketitle

\section{Introduction}

Geometric measure theory explores the relationship between the geometry of subsets of Euclidean spaces, and regularity properties of the family of Borel measures supported on those subsets. From the perspective of harmonic analysis, it is interesting to explore what structural information can be gathered from the Fourier analytic properties of measures supported on a particular subset of Euclidean space. In this paper, we focus on the relationship between the Fourier analytic properties of a set and the existence of patterns on the set. In particular, given a pattern, we construct a family of sets which generically avoids this pattern, and which supports measures with fast Fourier decay.

A useful statistic associated with any Borel set $E \subset \RR^d$ is it's \emph{Fourier dimension}; given a finite Borel measure $\mu$ on $\RR^d$, it's Fourier dimension, $\fordim(\mu)$, is the supremum of all $s \in [0,d]$ such that
%
\begin{equation} \label{fordim}
    \sup \left\{ |\widehat{\mu}(\xi)| |\xi|^{s/2} : \xi \in \RR^d \right\} < \infty.
\end{equation}
%
The Fourier dimension of a Borel set $E \subset \RR^d$, denoted $\fordim(E)$, is then the supremum of $\fordim(\mu)$, over all Borel probability measures $\mu$ supported on $E$. A particularly tractable family of sets in this scheme are \emph{Salem sets}, those sets whose Fourier dimension agrees with their Hausdorff dimension. Most pattern avoiding sets constructed in the literature are not Salem, often having Fourier dimension zero. Nonetheless, the sets we construct in this paper are Salem. We prove two results, one avoiding `rough' patterns, in the sense of \cite{OurPaper}, and the second avoiding patterns formed by a family of smooth surfaces.

\begin{theorem} \label{maintheorem}
    Let $0 \leq \alpha < dn$, and let $Z \subset \RR^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Then there exists a compact Salem set $E \subset [0,1]^d$ with dimension
    %
    \[ \beta = \min \left( \frac{nd - \alpha}{n-1/2}, d \right) \]
    %
    such that for any distinct points $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

\begin{remark}
    Theorem \ref{maintheorem} is an attempt to strengthen the main result of \cite{OurPaper} to construct a set with a Fourier dimension bound rather than a Hausdorff dimension bound, albeit under a weaker dimension bound than that obtained in \cite{OurPaper}. Unlike in \cite{OurPaper}, the case of Theorem \ref{maintheorem} when $0 \leq \alpha < d$ is still interesting, since the trivial construction $[0,1]^d - \pi(Z)$ is not necessarily a Salem set, where $\pi(x_1, \dots, x_n) = x_1$ is projection onto the first coordinate. For instance, in Example 8 of \cite{Ekstrom2014} it is shown that there exists a compact set $E \subset [0,1]$ such that $\minkdim(E) < 1$ and $\fordim([0,1] - E) < 1$. Setting $Z = E \times \{ 0 \} \cup \{ 0 \} \times E$ shows that neither subtracting projections onto the first nor the second coordinate gives the required Fourier dimension bounds.
\end{remark}

\begin{comment}
A well-known result in this pattern avoidance setting is that sets with large Fourier dimension satisfy many algebraic relations. More precisely, if integer coefficients $m_1, \dots, m_n \in \ZZ$ are fixed, and we consider a compact set $X \subset \RR$ with $\fordim(X) > 2/n$, then the sum set $m_1 X + \dots + m_n X$ contains an open interval. It follows by a slight modification of these coefficients that if $X \subset \RR$ and $\fordim(X) > 2/n$, then there exists $m_1, \dots, m_n \in \ZZ$, distinct points $x_1, \dots, x_n \in X$, and an additional integer $a \in \ZZ$, such that
%
\begin{equation} \label{intequation}
    m_1 x_1 + \dots + m_n x_n = a.
\end{equation}
%
It is an interesting to determine how tight this result is. In \cite{Korner2}, T.W. K\"{o}rner constructs a Salem set $X$ with Fourier dimension $1/(n-1)$ such that for non-zero $m \in \ZZ^n$, and $a \in \ZZ$, $X$ does not contain distinct points $x_1, \dots, x_n$ solving \eqref{intequation}. If, for each nonzero $m \in \ZZ^n$ and $a \in \ZZ$, we consider the set
%
\[ Z_{m,a} = \left\{ (x_1, \dots, x_n) \in [0,1]^n : m_1x_1 + \dots + m_n x_n = a \right\}, \]
%
then $Z_{m,a}$ is a subset of an $n-1$ dimensional hyperplane, and thus can be easily seen to have Minkowski dimension $n-1$. It follows that we can apply Theorem \ref{maintheorem} to $Z = \bigcup \{ Z_{m,a} : m \neq 0, a \in \ZZ \}$ to obtain a Salem set $X \subset [0,1]$ with dimension
%
\[ \frac{n - (n-1)}{n - 1} = \frac{1}{n-1}, \]
%
such that $(x_1, \dots, x_n) \not \in Z$ for each distinct $x_1, \dots, x_n \in X$. This means precisely that $X$ avoids solutions to $\eqref{intequation}$ for all nonzero $m \in \ZZ^n$ and $a \in \ZZ$. Thus we see Theorem \ref{maintheorem} generalizes K\"{o}rner's result, and thus shows the result depends little on the arithmetic properties of the pattern K\"{o}rner avoids, but rather, depends only on the `thickness' of the family of tuples $(x_1, \dots, x_n)$ satisfying the pattern. Since we expect Theorem \ref{maintheorem} to be tight for general sets, an improvement to K\"{o}rner's construction must rely more heavily on the algebraic properties of the pattern involved.
\end{comment}

In the case $d = 1$, under the stronger assumption that $Z$ is a countable union of smooth hypersurfaces which are either curved, or satisfy a kind of finite-type condition (in the manner of \cite{Stein}, though slightly different from the definition there), we are able to fully recover the dimension bound originally proved in the Hausdorff dimension setting in \cite{PramanikFraser} in the Fourier dimension instead.
%If $W \subset \RR^{dn}$, we say $W$ is a manifold of \emph{finite-type} if it has dimension $dn - d$, and around any point $x = (x_1,\dots,x_n) \in W$, there is $i \in \{ 1, \dots, n \}$, a neighbourhood $U$ of $x_i$, a neighbourhood $V$ of $(x_1,\dots,x_{i-1},x_{i+1},\dots,x_n)$, and a smooth map $f: V \to \RR^d$ such that if $y \in \RR^d$, with $y_i \in U$ and $(y_1,\dots,y_{i-1},y_{i+1},\dots,y_n) \in V$, then $y \in W$ if and only if $y_i = f(y_1,\dots,y_{i-1},y_{i+1},\dots,y_n)$, and for each $y \in V$, there exists a multi-index $\alpha$ such that $\partial_\alpha f_j(y) \neq 0$ for each $j \in \{ 1, \dots, i - 1 , i + 1, \dots, n \}$.

\begin{theorem} \label{theoremJOICVIOJVI122}
    Suppose $Z \subset \RR^{dn}$ is a countable union of sets of the form
    %
    \[ \{ x \in U \times V : x_1 = f(x_2,\dots,x_d) \} \]
    %
    where $U$ is an open set of $\RR^d$, $V$ is an open set of $\RR^{d(n-1)}$, and $f: V \to \RR^d$ is a smooth map such that for each unit vector $\eta \in \RR^d$, either $\nabla(f \cdot \eta)(x) \neq 0$, or there exists $|\alpha| \leq 2(n-1)/d$ with $\partial^\alpha(f \cdot \eta)(x) \neq 0$. Then there exists a compact Salem set $E \subset [0,1]$ with dimension
    %
    \[ \beta = \frac{1}{n-1} \]
    %
    such that for any distinct points $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

\begin{remark}
    If $d = 1$, the conditions of this theorem are satisfied if $Z$ is the countable union of manifolds which are projected submersively onto at least two coordinate axis, or have finite-type (as in \cite{Stein}) of order at most $2(n-1)$.
\end{remark}

In \cite{Korner2}, it is shown that for each $n > 0$, there exists a set $E \subset \RR^{dn}$ with Fourier dimension $1/(n-1)$ such that for any $x_1,\dots,x_n \in E$ and any integers $m_1,\dots,m_n \in \ZZ$, not all zero, $m_1x_1 + \dots + m_nx_n \neq 0$. We note that for the set
%
\begin{equation} \label{equationCIOSCJSIOJIO}
    Z = \{ (x_1,\dots,x_n) \in \RR^d: m_1x_1 + \dots + m_n = 0\ \text{for some nonzero $m \in \ZZ^n$} \}
\end{equation}
%
is a countable union of hyperplanes in $\RR^n$. Theorem \ref{theoremJOICVIOJVI122} applies to the set
%
\[ Z' = \left\{ (x_1,\dots,x_n) \in \RR^d: \begin{array}{c}
            \text{there are integers $m_1,\dots,m_n \in \ZZ$, at least two of}\\
            \text{which nonzero, such that $m_1x_1 + \dots + m_nx_n = 0$.}
        \end{array} \right\}. \]
%
Thus we can find a set $E$ avoiding $Z'$.
%
\[ Z - Z' = \{ x \in \RR^d: x_i = 0\ \text{for some $i$} \} \]
%
the set $E - \{ 0 \}$ avoids $Z$ and has the same Fourier dimension as $E$. Our arguments are heavily inspired by the techniques of \cite{Korner2}, but augmented with novel applications of probabilistic concentration inequalities, which enables us to push the results of \cite{Korner2} to a much more general setting. In particular, our arguments show that the results of that paper do not depend on the rich arithmetic structure of the pattern $Z$ in \eqref{equationCIOSCJSIOJIO}, but rather on the dimension of the hypersurfaces of which $Z$ is composed.

There are two key features of the patterns $Z$ satisfying the hypothesis of Theorem \ref{theoremJOICVIOJVI122} that enable us to obtain our result; firstly, they have thin projections onto a single `coordinate' which enables us to obtain a concentration inequality, and secondly, they obey a nondegeneracy condition which enables us to obtain an appropriate decay on their Fourier transform. Though convienient to express in the terms of smooth surfaces, the techniques in the proof of Theorem \ref{theoremJOICVIOJVI122} can be applied to more `rough' situations which still exhibit the same properties required of the surfaces studied.

\begin{theorem}
    There exists a compact Salem set $E \subset [0,1]$ of dimension $1$ such that for each non-zero $x \in E - E$ and each $\alpha > 0$, there are at most finitely many rational numbers $p/q \in \mathbf{Q}$ such that $|x - p/q| \leq q^{-(2 + \alpha)}$.
\end{theorem}

Because we are working with \emph{compact} sets avoiding patterns, working in the domain $\RR^d$ is not significantly different from working in a periodic domain $\TT^d = \RR^d / \ZZ^d$, and working in $\TT^d$ has several technical advantages over $\RR^d$. For a finite Borel measure $\mu$ on $\TT^d$, we can define it's Fourier dimension $\fordim(\mu)$ as the supremum of all $0 \leq s \leq d$ such that
%
\begin{equation}
    \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{s/2} < \infty.
\end{equation}
%
We can then define the Fourier dimension $\fordim(E)$ of any Borel set $E \subset \TT^d$ as the supremum of $\fordim(\mu)$, over all Borel measures $\mu$ supported on $E$. Since $\TT^d$ has a natural metric space structure, we can also define the Hausdorff dimension of measures and sets on $\TT^d$. It is a simple consequence of the Poisson summation formula that if $\mu$ is a compactly supported measure on $\RR^d$, then \eqref{fordim} is equivalent to the more discrete condition
%
\begin{equation} \label{discretefordim}
    \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{s/2} < \infty.
\end{equation}
%
A proof is given in Lemma 39 of \cite{myThesis}. In particular, if $\mu^*$ is the \emph{periodization} of $\mu$, i.e. the measure on $\TT^d$ such that for any $f \in C(\TT^d)$,
%
\begin{equation}
    \int_{\TT^d} f(x)\; d\mu^*(x) = \int_{\RR^d} f(x)\; d\mu(x),
\end{equation}
%
then by Poisson summation and \eqref{discretefordim} we see that $\fordim(\mu^*) = \fordim(\mu)$. Since $\mu$ is compactly supported, it is also simple to see that $\hausdim(\mu^*) = \hausdim(\mu)$ (for instance, by equating Frostman measure conditions). Thus Theorem \ref{maintheorem} is clearly equivalent to Theorem \ref{periodictheorem}, which is it's periodic variant.

\begin{theorem} \label{periodictheorem}
    Let $0 \leq \alpha < dn$, and let $Z \subset \TT^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Then there exists a compact Salem set $E \subset \TT^d$ with dimension
    %
    \[ \beta = \min \left( \frac{dn - \alpha}{n-1/2}, d \right) \]
    %
    such that for any distinct points $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

Noting that the periodization of any manifold is a countable union of manifolds with the same local properties as the original manifold, Theorem \ref{TheoremGGHSDIOCJOIJ} also is equivalent to a periodic version.

\begin{theorem} \label{TheoremGGHSDIOCJOIJ}
    Suppose $Z \subset \TT^{dn}$ is a countable union of $C^\infty$ surfaces of dimension $dn - d$, each of which having either non-vanishing curvature, or have finite type at most $2(n-1)/d$ at each point. Then there exists a compact Salem set $E \subset \TT^d$ with dimension
    %
    \[ \beta = \frac{d}{n-1} \]
    %
    such that for any distinct points $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

We construct the sets $E$ in Theorems \ref{periodictheorem} and \ref{TheoremGGHSDIOCJOIJ} by relying on a Baire-category type approach. Thus we consider a complete metric space $\mathcal{X}_\beta$, whose elements consist of pairs $(E,\mu)$, where $E$ is a subset of $\TT^d$, and $\mu$ is a probability measure supported on $E$. We then show that for \emph{quasi-all} elements $(E,\mu) \in \mathcal{X}_\beta$, $E$ is a Salem set of dimension $\beta$, and for distinct $x_1,\dots,x_n \in E$, $(x_1,\dots,x_n) \not \in Z$. %in the sense that the set of pairs $(E,\mu)$ which do not satisfy these properties is a set of first category in $\mathcal{X}_\beta$.
It thus follows that the consequences of Theorem \ref{periodictheorem} holds in a `generic' sense for elements of $\mathcal{X}_\beta$.

Once we have setup the appropriate metric space $\mathcal{X}_\beta$, our approach is quite similar to the construction in \cite{OurPaper}, relying on a random selection procedure, which is now exploited to give high probability bounds on the Fourier transform of the measures we study. The use of the Baire category approach in this paper, rather than an algorithmic, `nested set' approach as used in \cite{OurPaper}, is mostly of an aesthetic nature, avoiding the complex queuing method and dyadic decomposition strategy required in the nested set approach; our approach can, with some care, be converted into a queuing procedure like in \cite{OurPaper}. But the Baire category argument makes our proof much simpler to read, and has the advantage that it indicates that Salem sets of a specified dimension `generically' avoid a given rough pattern.% Moreover, the proof of the Baire category theorem is in some senses, `hidden' in the queuing method, so the two methods are, aside from small technical differences, equivalent to one another.

\section{Notation} \label{notationSection}

\begin{itemize}
%    \item For a positive integer $N$, we let $[N] = \{ 1, \dots, N \}$.

    \item Given a metric space $X$, $x \in X$, and $\varepsilon > 0$, we shall let $B_\varepsilon(x)$ denote the open ball of radius $\varepsilon$ around $x$. We let $\delta_x$ denote the Dirac delta measure at $x$. For a given set $E \subset \Omega$ and $\varepsilon > 0$, we let
    %
    \[ E_\varepsilon = \bigcup_{x \in E} B_\varepsilon(x), \]
    %
    denote the \emph{$\varepsilon$-thickening} of the set $E$. A subset of $X$ is of \emph{first category} in $X$ if it is the countable union of closed sets with empty interior. We say a property holds \emph{quasi-always}, or a property is \emph{generic} in $X$ if the set of points in $X$ failing to satisfy that property form a set of first category.

    \item We let $\TT^d = \RR^d/\ZZ^d$. Given $x \in \TT$, we let
    %
    \[ |x| = \min \{ |x + n| : n \in \ZZ \}, \]
    %
    and for $x \in \TT^d$, we let
    %
    \[ |x| = \sqrt{|x_1|^2 + \dots + |x_d|^2}. \]
    %
    The canonical metric on $\TT^d$ is then given by $d(x,y) = |x - y|$, for $x,y \in \TT^d$. For an axis-oriented cube $Q$ in $\TT^d$, we let $2Q$ be the cube in $\TT^d$ with the same centre and twice the sidelength.

    \item Suppose $\mathbf{E} = \TT^d$ or $\mathbf{E} = \RR^d$. For $\alpha \in [0,d]$ and $\delta > 0$, we define the Hausdorff content of a Borel set $E \subset \mathbf{E}$ as
    %
    \[ H^\alpha_\delta(E) = \inf \left\{ \sum_{i = 1}^\infty \varepsilon_i^\alpha : E \subset \bigcup_{i = 1}^\infty B_{\varepsilon_i}(x_i)\ \text{and $0 < \varepsilon_i \leq \delta$ for all $i \geq 1$} \right\}. \]
    %
    The $\alpha$ dimensional Hausdorff measure of $E$ is equal to
    %
    \[ H^\alpha(E) = \lim_{\delta \to 0} H^\alpha_\delta(E). \]
    %
    The Hausdorff dimension $\hausdim(E)$ of a Borel set $E$ is then the infinum over all $s \in [0,d]$ such that $H^s(E) = \infty$, or alternatively, the supremum over all $s \in [0,d]$ such that $H^s(E) = 0$. Frostman's lemma says that if we define the Hausdorff dimension $\hausdim(\mu)$ of a finite Borel measure $\mu$ as the supremum of all $s \in [0,d]$ such that
    %
    \begin{equation} \label{hausdim}
        \sup \left\{ \mu(B_\varepsilon(x)) \cdot \varepsilon^{-\alpha} : x \in \mathbf{E}, \varepsilon > 0 \right\} < \infty,
    \end{equation}
    %
    then $\hausdim(E)$ is the supremum of $\hausdim(\mu)$, over all Borel probability measures $\mu$ supported on $E$. This is analogous to the definition of the Fourier dimension of a set $E$ given in the introduction.

    For a measurable set $E \subset \mathbf{E}$, we let $|E|$ denote it's Lebesgue measure. We define the lower Minkowski dimension of a compact Borel set $E \subset \mathbf{E}$ as
    %
    \[ \lowminkdim(E) = \liminf_{r \to 0} d - \log_r|E_r|. \]
    %
    Thus $\lowminkdim(E)$ is the largest number such that for $\alpha < \lowminkdim(E)$, there exists a decreasing sequence $\{ r_i \}$ with $\lim_{i \to \infty} r_i = 0$ and $|E_{r_i}| \leq r_i^{d - \alpha}$ for each $i$.

    \item In this paper we will need to employ probabilistic concentration bounds several times. In particular, we use \emph{McDiarmid's inequality}, trivially modified from the standard theorem to work with complex-valued functions. Let $\mathbf{E} = \TT^d$ or $\mathbf{E} = \RR^d$. Let $\{ X_1, \dots, X_N \}$ be an independant family of random variables, and consider a function $f: \mathbf{E}^N \to \CC$. Suppose that for each $i \in \{ 1, \dots, N \}$, there exists a constant $A_i > 0$ such that for any $x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_N \in \mathbf{E}$, and for each $x_i, x_i' \in \mathbf{E}$,
    %
    \[ |f(x_1, \dots, x_i, \dots, x_N) - f(x_1, \dots, x_i', \dots, x_N)| \leq A_i. \]
    %
    Then McDiarmid's inequality guarantees that for all $t \geq 0$,
    %
    \[ \PP \left( |f(X_1, \dots, X_N) - \EE(f(X_1, \dots, X_N))| \geq t \right) \leq 4 \exp \left( \frac{-2t^2}{A_1^2 + \dots + A_N^2} \right). \]
    %
    The complex-valued extension we have just stated is proved easily from the real-valued case by taking a union bound to the inequality for the real and imaginary values of $f$. Proofs of McDiarmid's inequality are given in many probability texts, for instance, in Theorem 3.11 of \cite{VanHandel}.

    A special case of McDiarmid's inequality is \emph{Hoeffding's Inequality}. The version of Hoeffding's inequality we use states that if $\{ X_1, \dots, X_N \}$ is a family of independant random variables, such that for each $i$, there exists a constant $A_i \geq 0$ such that $|X_i| \leq A_i$ almost surely, then for each $t \geq 0$,
    %
    \[ \PP \left( |X_1 + \dots + X_N - \EE(X_1 + \dots + X_N)| \geq t \right) \leq 4 \exp \left(\frac{-t^2/2}{A_1^2 + \dots + A_N^2} \right). \]
    %

    \begin{comment}

    \item Our random construction involves a probabilistic concentration of measure argument. Define a convex function $\psi_2: [0,\infty) \to [0,\infty)$ by setting
    %
    \[ \psi_2(t) = e^{t^2} - 1, \]
    %
    The function $\psi_2$ induces an Orlicz norm on the family of scalar valued random variables over a probability space by setting, for each random variable $X$,
    %
    \[ \psitwo{X} = \inf \left\{ A \in (0,\infty) : \EE(\psi_2(|X|/A)) \leq 1 \right\}. \]
    %
    The family of random variables with $\psitwo{X} < \infty$ are known as \emph{subgaussian random variables}. Here are the important properties of subgaussian random variables which we use in this paper:
    %
    \begin{itemize}
        \item If $\psitwo{X} \leq A$, then for each $t \geq 0$,
        %
        \[ \PP \left( |X| \geq t \right) \leq 10 \exp \left( -t^2/10A^2 \right). \]
        %
        Thus Subgaussian random variables have Gaussian tails.

        \item If $|X| \leq A$ almost surely, then $\psitwo{X} \leq 10 A$. Thus bounded random variables are subgaussian.

    %\item (Centering) For any random variable $X$,
    %
    %\[ \psitwo{X - \EE(X)} \lesssim \psitwo{X}. \]

    %\item (Union Bound) If $X_1, \dots, X_N$ are random variables, then
    %
    %\[ \psitwo{X_1 + \dots + X_N} \leq \psitwo{X_1} + \dots + \psitwo{X_N}. \]

        \item If $X_1, \dots, X_N$ are \emph{independent}, then
        %
        \[ \psitwo{X_1 + \dots + X_N} \leq 10 \left( \psitwo{X_1}^2 + \dots + \psitwo{X_N}^2 \right)^{1/2}. \]
        %
        This is an equivalent way to state \emph{Hoeffding's Inequality}, and we refer to an application of this inequality as an application of Hoeffding's inequality.
    \end{itemize}
    %
    Roughly speaking, if $X$ is a random variable with $\psitwo{X} \leq A$, we can think of $X$ as being sharply concentrated in the region $[-A,A]$. The Orlicz norm thus provides a convenient way to quantify concentration phenomena.
    %
    \begin{remark}
        The constants involved in these statements are suboptimal, but will suffice for our purposes. Proofs can be found in Chapter 2 of \cite{Vershynin}.
    \end{remark}

    \end{comment}

%    \item Let $X$ and $Y$ be metric spaces. For a given $f: X \to Y$, we let
    %
%    \[ \| f \|_{\text{Lip}(X)} = \sup \left\{ \frac{d(f(x_1),f(x_2))}{d(x_1,x_2)} : x_1,x_2 \in X \right\} \]
    %
%    denote the optimal Lipschitz constant for $f$.

    \item Throughout this paper, we will need to consider a standard mollifier. So we fix a smooth, non-negative function $\phi \in C^\infty(\TT^d)$ such that $\phi(x) = 0$ for $|x| \geq 2/5$ and
%
\[ \int_{\TT^d} \phi(x)\; dx = 1. \]
%
\begin{comment}
\begin{theorem} \label{equationASFGCISIX}
    There exists a smooth probability density $\phi \in C^\infty(\TT^d)$ such that $\phi(x) = 0$ for $|x| \geq 2/5$, and such that for each $x \in \TT^d$
    %
    \[ \sum_{k \in \{ 0, 1 \}^d} \phi(x + k/2) = 2^d. \]
\end{theorem}
\begin{proof}
    Let $\psi$ be a non-negative smooth function on $\TT$ such that $\psi(x) = \psi(- x)$ for all $x \in \TT$, $\psi(x) = 1$ for $|x| \leq 1/10$, $\psi(x) = 0$ for $|x| \geq 2/10$, and $0 \leq \psi(x) \leq 1$ for all $x \in \TT$. Then define $\eta$ to be the non-negative, $C^\infty$ function
    %
    \[ \eta(x) = \frac{1}{2} - \frac{\psi(x) + \psi(x + 1/2)}{2}. \]
    %
    If we define
    %
    \[ \phi_0(x) = 2(\psi(x) + \eta(x)), \]
    %
    then $\phi_0(x) + \phi_0(x + 1/2) = 2$ for all $x \in \TT$. Moreover, if $|x| \geq 2/5$, then $\psi(x) = 0$, and since this implies $|x + 1/2| \leq 1/10$, we find $\eta(x) = 0$. Thus $\phi_0(x) = 0$ for $|x| \geq 2/5$. But the condition $\phi_0(x) + \phi_0(x + 1/2) = 2$ implies that $\phi_0$ is a probability density function. Thus it suffices to define
    %
    \[ \phi(x_1, \dots, x_d) = \phi_0(x_1) \dots \phi_0(x_d). \qedhere \]
\end{proof}
\end{comment}
%
For each $r \in (0,1)$, we can then define $\phi_r \in C^\infty(\TT^d)$ by writing
%
\[ \phi_r(x) = \begin{cases} r^{-d} \phi(x/r) &: |x| < r, \\ 0 &: \text{otherwise}. \end{cases} \]
%
The following standard properties hold:
%
\begin{enumerate}
    \item[(1)] For each $r \in (0,1)$, $\phi_r$ is a non-negative smooth function with
    %
    \begin{equation}
        \int_{\TT^d} \phi_r(x)\; dx = 1,
    \end{equation}
    %
    and $\phi_r(x) = 0$ for $|x| \geq r$.

    \item[(2)] For any $r \in (0,1)$,
    %
    \begin{equation} \label{equationDIOJAOIJVIV23242}
        \| \widehat{\phi_r} \|_{L^\infty(\ZZ^d)} \leq 1.
    \end{equation}

%    \item For any positive integer $N$, if $\varepsilon = 1/N$ and $x \in \TT^d$,
    %
%    \begin{equation} \label{equation5550002352124124512}
%        \sum_{k \in [2N]^d} \phi_{1/N}(x + k/2N) = (2N)^d.
%    \end{equation}

    \item[(3)] For each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{approximationtoidentitypointwiseconvergence}
        \lim_{r \to 0} \widehat{\phi_r}(\xi) = 1.
    \end{equation}

    \item[(4)] For each $T > 0$, and for all $r > 0$ and any non-zero $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{molificationdecaybound}
        |\widehat{\phi_r}(\xi)| \lesssim_T r^{-T} |\xi|^{-T}.
    \end{equation}
\end{enumerate}
\end{itemize}

\section{A Metric Space Controlling Fourier Dimension}

In order to work with a Baire category type argument, we must construct an appropriate metric space appropriate for our task and establish a set of tools for obtaining convergence in this metric space. In later sections we will fix a specific choice of $\beta$ to avoid a particular pattern. But in this section we let $\beta$ be an arbitrary element of $(0,d]$. Our approach in this section is heavily influenced by \cite{Korner2}. However, we employ a Frech\'{e}t space construction instead of the Banach space used in \cite{Korner2}, which enables us to use softer estimates in our arguments:
%
\begin{itemize}
    \item We let $\mathcal{E}$ denote the family of all compact subsets of $\TT^d$. If, for two compact sets $E,F \in \mathcal{E}$, we consider their Hausdorff distance
    %
    \[ d_\mathbf{H}(E,F) = \inf \{ \varepsilon > 0 : E \subset F_\varepsilon\ \text{and}\ F \subset E_\varepsilon \}, \]
    %
    then $(\mathcal{E},d_\mathbf{H})$ forms a complete metric space. %We note that if a sequence $\{ E_k \}$ converges to a set $E$ in the Hausdorff distance, then $E$ is the collection of all values $\lim_{k \to \infty} x_k$, where $\{ x_k \}$ is a convergent sequence with $x_k \in E_k$ for each $k$.

    \item We let $M(\beta/2)$ consist of the class of all finite Borel measures $\mu$ on $\TT^d$ such that for each $\varepsilon \in (0,\beta/2]$, the quantity
    %
    \[ \| \mu \|_{M(\beta/2 - \varepsilon)} = \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{\beta/2 - \varepsilon} \]
    %
    is finite. Then $\| \cdot \|_{M(\beta/2 - \varepsilon)}$ is a seminorm on $M(\beta/2)$, and the collection of all such seminorms for $\varepsilon \in (0,\beta/2]$ gives $M(\beta/2)$ the structure of a Frech\'{e}t space. Under this topology, a sequence of probability measures $\{ \mu_k \}$ converges to a probability measure $\mu$ in $M(\beta/2)$ if and only if for any $\varepsilon > 0$, $\lim_{k \to \infty} \| \mu_k - \mu \|_{M(\beta/2 - \varepsilon)} = 0$.
\end{itemize}

\begin{comment}
\begin{theorem}
    $M(\beta)$ is a Frech\'{e}t space.
\end{theorem}
\begin{proof}
    Let $\{ \mu_k \}$ be a Cauchy sequence in $M(\beta)$. By the Banach-Alaoglu theorem, we can find a finite Borel measure $\mu$ such that some subsequence $\{ \mu_{k_i} \}$ of the sequence $\{ \mu_k \}$ converges weakly to $\mu$. Then for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationAAGDDTYY8}
        \lim_{i \to \infty} \widehat{\mu_{k_i}}(\xi) = \widehat{\mu}(\xi).
    \end{equation}
    %
    Since $\{ \mu_k \}$ is Cauchy, for each $\varepsilon > 0$ there exists a constant $M_\varepsilon > 0$ such that for each $k$,
    %
    \begin{equation} \label{equationGFDSCCSI9}
        \| \mu_k \|_{M(\beta,\varepsilon)} \leq M_\varepsilon.
    \end{equation}
    %
    But combining \eqref{equationAAGDDTYY8} with \eqref{equationGFDSCCSI9} shows that for each $\varepsilon > 0$,
    %
    \begin{equation} \label{equationFGSCIS991}
        \| \mu \|_{M(\beta,\varepsilon)} \leq M_\varepsilon < \infty.
    \end{equation}
    %
    In particular, $\mu \in M(\beta)$. Now fix $r > 0$ and $\varepsilon > 0$. Because $\{ \mu_k \}$ is Cauchy, there exists $k_0$ such that for $k_1,k_2 \geq k_0$,
    %
    \begin{equation} \label{equationGGSIC8823}
        \| \mu_{k_1} - \mu_{k_2} \|_{M(\beta,r)} \leq \varepsilon.
    \end{equation}
    %
    But then combining \eqref{equationAAGDDTYY8} and\eqref{equationGGSIC8823} shows that for $k \geq k_0$,
    %
    \begin{equation} \label{equationGGSCSXXX}
        \| \mu - \mu_k \|_{M(\beta,r)} \leq \varepsilon.
    \end{equation}
    %
    Since $r$ and $\varepsilon$ were arbitrary, \eqref{equationGGSCSXXX} shows that $\mu_k$ converges to $\mu$ in the topology determined by the seminorms of $M(\beta)$. If we consider a decreasing family $\{ \varepsilon_k \}$ such that $\varepsilon_k \to 0$, then $M(\beta)$ is clearly topologized by the subfamily of seminorms $\{ \| \cdot \|_{M(\beta,\varepsilon_k)} \}$, so $M(\beta)$ is metrizable. Thus we conclude that $M(\beta)$ is a Frech\"{e}t space.
\end{proof}
\end{comment}

We now let $\mathcal{X}_\beta$ be the collection of all pairs $(E,\mu) \in \mathcal{E} \times M(\beta/2)$, where $\mu$ is a probability measure such that $\text{supp}(\mu) \subset E$. Then $\mathcal{X}_\beta$ is a closed subset of $\mathcal{E} \times M(\beta/2)$ under the product metric, and thus a complete metrizable space. We remark that for any $\varepsilon > 0$ and $(E,\mu) \in \mathcal{X}_\beta$,
%
\begin{equation} \label{equationGFSCSC4}
    \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = 0,
\end{equation}
%
which follows because $\| \mu \|_{M(\beta/2 - \varepsilon/2)}$ is finite. Thus $\fordim(\mu) \geq \beta$ for each $(E,\mu) \in \mathcal{X}_\beta$.
\begin{comment}
\begin{theorem}
    $\mathcal{X}$ is a closed subset of $\mathcal{E} \times M(\beta)$.
\end{theorem}
\begin{proof}
    Suppose $\{ (E_k,\mu_k) \}$ is a sequence of elements of $\mathcal{X}$ converging to some tuple $(E,\mu) \in \mathcal{E} \times M(\beta)$. Fix $\varepsilon > 0$. Since $E_k \to E$ in the Hausdorff dimension, there exists $k_0$ such that for $k \geq k_0$, $E_k \subset E(\varepsilon)$. Since $\mu_k \to \mu$ weakly, this implies that $\mu$ is a probability measure, and that $\text{supp}(\mu) \subset E(\varepsilon)$. Taking $\varepsilon \to 0$ shows that $\text{supp}(\mu) \subset E$. Again for a fixed $\varepsilon > 0$, applying the triangle inequality and the reverse triangle inequality combined with \eqref{equationGFSCSC4} applied to $\mu_k$, we conclude
    %
    \[ \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi) - \widehat{\mu_k}(\xi)| \leq \| \mu - \mu_k \|_{M(\beta,\varepsilon)}. \]
    %
    Taking $k \to \infty$ shows that
    %
    \[ \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = 0, \]
    %
    which completes the proof.
\end{proof}
\end{comment}

\begin{lemma} \label{smoothdensitylemma}
    The set of all $(E,\mu)$ with $\mu \in C^\infty(\TT^d)$ is dense in $\mathcal{X}_\beta$.
\end{lemma}
\begin{proof}
    Consider $(E,\mu) \in \mathcal{X}_\beta$. For each $r \in (0,1)$, consider the convolved measure $\mu_r = \mu * \phi_r$. Then $\mu_r \in C^\infty(\TT^d)$. We claim that $\lim_{r \to 0} (E_r,\mu_r) = (E,\mu)$. Since $\text{supp}(\mu_r) \subset E_r$, we find that $d_{\mathbf{H}}(E,E_r) \leq r$, and so $\lim_{r \to 0} E_r = E$. Now fix $\varepsilon_1 \in (0,\beta/2]$ and $\varepsilon > 0$. For each $\xi \in \ZZ^d$, $|\widehat{\mu_r}(\xi)| = |\widehat{\phi_r}(\xi)| |\widehat{\mu}(\xi)|$, so
    %
    \begin{equation} \label{equationFFSCI}
        |\xi|^{\beta/2 - \varepsilon_1} |\mu_r(\xi) - \mu(\xi)| = |\xi|^{\beta/2 - \varepsilon_1} |\widehat{\phi_r}(\xi) - 1| |\widehat{\mu}(\xi)|.
    \end{equation}
    %
    We control \eqref{equationFFSCI} over large frequencies using the term $|\widehat{\mu}(\xi)|$, and by small frequencies using the term $|\widehat{\phi_r}(\xi) - 1|$. Since $(E,\mu) \in \mathcal{X}_\beta$, we can apply \eqref{equationGFSCSC4} to find $R > 0$ such that for $|\xi| \geq R$,
    %
    \begin{equation} \label{equationDIICSIC}
        |\xi|^{\beta/2 - \varepsilon_1} |\widehat{\mu}(\xi)| \leq \varepsilon.
    \end{equation}
    %
    Combining \eqref{equationFFSCI}, \eqref{equationDIICSIC}, and \eqref{equationDIOJAOIJVIV23242}, for $|\xi| \geq R$ we find that
    %
    \begin{equation} \label{equationDSCISIIXX}
        |\xi|^{\beta/2 - \varepsilon_1} |\mu_r(\xi) - \mu(\xi)| \leq 2 \varepsilon.
    \end{equation}
    %
    On the other hand, \eqref{approximationtoidentitypointwiseconvergence} shows that there exists $r_0 > 0$ such that for $r \leq r_0$ and $|\xi| \leq R$,
    %
    \begin{equation} \label{equationDISCIIS}
        |\xi|^{\beta/2 - \varepsilon} |\widehat{\phi_r}(\xi) - 1| \leq \varepsilon.
    \end{equation}
    %
    The $(L^1,L^\infty)$ bound for the Fourier transform implies that $|\widehat{\mu}(\xi)| \leq \mu(\TT^d) = 1$, which combined with \eqref{equationDISCIIS} gives that for $r \leq r_0$ and $|\xi| \leq R$,
    %
    \begin{equation} \label{equatioNFISISCISI}
        |\xi|^{\beta/2 - \varepsilon_1} |\mu_r(\xi) - \mu(\xi)| \leq \varepsilon.
    \end{equation}
    %
    Putting together \eqref{equationDSCISIIXX} and \eqref{equatioNFISISCISI}, shows that for $r \leq r_0$, $\| \mu_r - \mu \|_{M(\beta/2 - \varepsilon_1)} \leq 2\varepsilon$. Since $\varepsilon$ and $\varepsilon_1$ were arbitrary, $\lim_{r \to 0} \mu_r = \mu$, completing the proof.
\end{proof}

\begin{remark} \label{remarkDOIWJDIOWJ2}
    Let
    %
    \[ \tilde{\mathcal{X}_\beta} = \{ (E,\mu) \in \mathcal{X}_\beta : \text{supp}(\mu) = E \}. \]
    %
    Suppose $(E_0,\mu_0) \in \tilde{\mathcal{X}_\beta}$. Then, in the proof above, one may let $E_r$ be equal to $\text{supp}(\mu_r)$, since it follows from this that $d_\mathbf{H}(E_0,E_r) \leq r$. This means that the set of pairs $(E,\mu) \in \tilde{\mathcal{X}_\beta}$ with $\mu \in C^\infty(\TT^d)$ are dense in $\tilde{\mathcal{X}_\beta}$.
\end{remark}

The reason we work with $\mathcal{X}_\beta$ instead of the smaller space $\tilde{\mathcal{X}_\beta} \subset \mathcal{X}_\beta$ in this paper is that $\tilde{\mathcal{X}_\beta}$ is not a closed subset of $\mathcal{X}_\beta$, and so is not a complete metric space. However, as a consolation, quasi-all elements of $\mathcal{X}_\beta$ belong to $\tilde{\mathcal{X}_\beta}$, so that one can think of $\mathcal{X}_\beta$ and $\tilde{\mathcal{X}_\beta}$ as being equal `generically'.

\begin{lemma} \label{lemmaOIJAWDIOJW23232}
    For quasi-all $(E,\mu) \in \mathcal{X}_\beta$, $\text{supp}(\mu) = E$.
\end{lemma}
\begin{proof}
    For each closed cube $Q \subset \TT^d$, let
    %
    \[ A(Q) = \{ (E,\mu) \in \TT^d: (E \cap Q) = \emptyset\ \text{or}\ \mu(Q) > 0 \}. \]
    %
    Then $A(Q)$ is an open set. If $\{ Q_k \}$ is a sequence enumerating all cubes with rational corners in $\TT^d$, then
    %
    \[ \bigcap_{k = 1}^\infty A(Q_k) = \{ (E,\mu) \in \mathcal{X}_\beta : \text{supp}(\mu) = E \}. \]
    %
    Thus it suffices to show that $A(Q)$ is dense in $\mathcal{X}_\beta$ for each closed cube $Q$. Thus we fix $(E_0,\mu_0) \in \mathcal{X}_\beta - A(Q)$, $\varepsilon_1 \in (0,\beta/2]$, and $\varepsilon > 0$, and try and find $(E,\mu) \in A(Q)$ with $d_\mathbf{H}(E,E_0) \leq \varepsilon$ and $\| \mu_0 - \mu \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$. Applying Lemma \ref{smoothdensitylemma}, we may assume without loss of generality that $\mu_0 \in C^\infty(\TT^d)$.

    Because $(E_0,\mu_0) \in \mathcal{X}_\beta - A(Q)$, we know $E \cap Q \neq \emptyset$ and $\mu(Q) = 0$. Find a smooth probability measure $\nu$ supported on $E_\varepsilon \cap Q$ and, for $t \in (0,1)$, define $\mu_t = (1 - t) \mu_0 + t \nu$. Then $\text{supp}(\mu_t) \subset E_\varepsilon$, so if we let $E = \text{supp}(\nu) \cup \text{supp}(\mu)$, then $d_\mathbf{H}(E,E_0) \leq \varepsilon$. Clearly $(E,\mu_t) \in A(Q)$ for $t > 0$. And
    %
    \[ \| \mu_t - \mu_0 \|_{M(\beta/2 - \varepsilon)} \leq t \left( \| \mu_0 \|_{M(\beta/2 - \varepsilon)} + \| \nu \|_{M(\beta/2 - \varepsilon)} \right), \]
    %
    so if we choose $t \leq \varepsilon (\| \mu \|_{M(\beta/2 - \varepsilon)} + \| \nu \|_{M(\beta/2 - \varepsilon)})^{-1}$ we find $\| \mu_t - \mu \|_{M(\beta/2 - \varepsilon)} \leq \varepsilon$. Since $\varepsilon$ was arbitrary, we conclude $A(Q)$ is dense in $\mathcal{X}_\beta$.
\end{proof}

Combining Lemma \ref{lemmaOIJAWDIOJW23232} with Remark \ref{remarkDOIWJDIOWJ2} gives the following simple corollary.

\begin{corollary} \label{corollaryOIDJOWIJD2212}
    The family of $(E,\mu)$ with $\text{supp}(\mu) = E$ and $\mu \in C^\infty(\TT^d)$ is dense in $\mathcal{X}_\beta$.
\end{corollary}

Our main way of constructing approximations to $(E_0,\mu_0) \in \mathcal{X}_\beta$ is to multiply $\mu_0$ by a smooth function $f \in C^\infty(\TT^d)$. For instance, we might choose $f$ in such a way as to remove certain points from the support of $\mu_0$ which contribute to the formation of a pattern we are trying to avoid. As long as the Fourier transform of $f$ decays appropriately quickly, the next lemma shows that $f \mu_0 \approx \mu_0$.

\begin{lemma} \label{LemmaTTSICICS}
    Consider a smooth finite measure $\mu_0$ on $\TT^d$, as well as a smooth probability density function $f \in C^\infty(\TT^d)$. If we define $\mu = f \mu_0$, then
    %
    \[ \| \mu - \mu_0 \|_{M(\beta/2)} \lesssim_{d,\mu_0} \| f \|_{M(\beta/2)}. \]
\end{lemma}
\begin{proof}
    Since $\widehat{\mu} = \widehat{f} * \widehat{\mu_0}$, and $\widehat{f}(0) = 1$, for each $\xi \in \ZZ^d$ we have
    %
    \begin{equation} \label{equationPPYTUECUUCS}
    \begin{split}
        |\xi|^{\beta/2} |\widehat{\mu}(\xi) - \widehat{\mu_0}(\xi)| &= |\xi|^{\beta/2} \left| \sum_{\eta \neq \xi} \widehat{f}(\xi - \eta) \widehat{\mu_0}(\eta) \right|.
    \end{split}
    \end{equation}
    %
    If $|\eta| \leq |\xi|/2$, then $|\xi|/2 \leq |\xi - \eta| \leq 2 |\xi|$, so
    %
    \begin{equation} \label{equationPPDOSO}
        |\xi|^{\beta/2} |\widehat{f}(\xi - \eta)| \leq \| f \|_{M(\beta/2)} |\xi|^{\beta/2} |\xi-\eta|^{-\beta} \leq 2^{\beta/2} \| f \|_{M(\beta/2)} \lesssim_d \| f \|_{M(\beta/2)}.
    \end{equation}
    %
    Since $\mu_0$ is smooth, for any $T \geq 0$ and $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationGGIDISCXJIX}
        |\xi|^T |\widehat{\mu_0}(\xi)| \lesssim_{T,\mu_0} 1.
    \end{equation}
    %
    Thus we can combine the bounds \eqref{equationPPDOSO} and \eqref{equationGGIDISCXJIX}, with $T = d+1$, to conclude that
    %
    \begin{equation} \label{equationGGPSOVVCSI}
    \begin{split}
        |\xi|^{\beta/2} \left| \sum_{0 \leq |\eta| \leq |\xi|/2} \widehat{f}(\eta) \widehat{\mu_0}(\xi - \eta) \right| &\lesssim_{\mu_0,d} \left( 1 + \sum_{0 < |\eta| \leq |\xi|/2} \frac{1}{|\eta|^{d+1}} \right) \| f \|_{M(\beta)} \lesssim_d \| f \|_{M(\beta)}.
    \end{split}
    \end{equation}
    %
    On the other hand, for all $\eta \neq \xi$,
    %
    \begin{equation} \label{equationGGDPSOX}
    \begin{split}
        |\widehat{f}(\xi - \eta)| \leq  \| f \|_{M(\beta/2)} |\xi - \eta|^{-\beta} \leq \| f \|_{M(\beta/2)}.
    \end{split}
    \end{equation}
    %
    Thus applying \eqref{equationGGIDISCXJIX} and \eqref{equationGGDPSOX}, with $T = 3d/2$, we conclude that
    %
    \begin{equation} \label{equationGGHOODPPS}
    \begin{split}
        |\xi|^{\beta/2} \left| \sum_{\substack{|\eta| > |\xi|/2\\ \eta \neq \xi}} \widehat{f}(\xi - \eta) \widehat{\mu_0}(\eta) \right| &\lesssim_{d,\mu_0} |\xi|^{\beta/2} \sum_{|\eta| > |\xi|/2} \frac{\| f \|_{M(\beta/2)}}{|\eta|^{3d/2}} \lesssim_d \| f \|_{M(\beta/2)}.
    \end{split}
    \end{equation}
    %
    Combining \eqref{equationPPYTUECUUCS}, \eqref{equationGGPSOVVCSI} and \eqref{equationGGHOODPPS} completes the proof.
\end{proof}

\begin{remark} \label{remarkFOIJIOSJCIOSJ}
    In particular, we note that this lemma implies that $1 - \mu(\TT^d) \lesssim_{d,\mu_0} \| f \|_{M(0)}$.
\end{remark}

The bound in Lemma \ref{LemmaTTSICICS}, if $\| f \|_{M(\beta/2)}$ is taken appropriately small, also implies that the Hausdorff distance between the supports of $\mu$ and $\mu_0$ is small.

\begin{lemma} \label{LemmaTAOIAWOIDJ12301}
    Fix a probability measure $\mu_0 \in C^\infty(\TT^d)$. For any $\varepsilon > 0$, there exists $\delta > 0$ depending on $\mu_0$ and $\varepsilon$, such that if $\mu \in C^\infty(\TT^d)$, $\text{supp}(\mu) \subset \text{supp}(\mu_0)$, and $\| \mu_0 - \mu \|_{M(\beta/2)} \leq \delta$, then $d_\mathbf{H}(\text{supp}(\mu),\text{supp}(\mu_0)) \leq \varepsilon$.
\end{lemma}
\begin{proof}
    Consider any cover of $\text{supp}(\mu_0)$ by a family of radius $\varepsilon/3$ balls $\{ B_1,\dots,B_N \}$, and for each $i \in \{ 1, \dots, N \}$, consider a smooth function $f_i \in C_c^\infty(B_i)$ such that there is $s > 0$ with
    %
    \begin{equation} \label{equationCIJCIJCIJ}
        \int f_i(x) d\mu_0(x) \geq s.
    \end{equation}
    %
    for each $i \in \{ 1, \dots, N \}$. Fix $A > 0$ with
    %
    \begin{equation} \label{equationvVVIJIJX}
        \sum_{\xi \neq 0} |\widehat{f_i}(\xi)| \leq A
    \end{equation}
    %
    for all $i \in \{ 1, \dots, N \}$ as well. Set $\delta = s/2A$. If $\| \mu_0 - \mu \|_{M(\beta/2)} \leq \delta$, we apply Plancherel's inequality together with \eqref{equationCIJCIJCIJ} and \eqref{equationvVVIJIJX} to conclude that
    %
    \begin{equation} \label{equationIVIJVIVJIVJ}
    \begin{split}
        \left| \int f_i(x) d\mu(x)\; dx - \int f_i(x) d\mu_0(x) \right| &= \left| \sum_{\xi \in \ZZ^d} \widehat{f_i}(\xi) \left( \widehat{\mu}(\xi) - \widehat{\mu_0}(\xi) \right) \right|\\
        &\leq A \| \mu_0 - \mu \|_{M(\beta/2)} \leq s/2.
    \end{split}
    \end{equation}
    %
    Thus we conclude from \eqref{equationCIJCIJCIJ} and \eqref{equationIVIJVIVJIVJ} that
    %
    \begin{equation} \label{equationVIOJVIOSJCICJXXXXX}
        \int f_i(x) d\mu(x)\; dx \geq \int f_i(x) d\mu_0(x) - s/2 \geq s/2 > 0.
    \end{equation}
    %
    Since equation \eqref{equationVIOJVIOSJCICJXXXXX} holds for each $i \in \{ 1,\dots, N \}$, the support of $\mu$ intersects every ball in $\{ B_1, \dots, B_N \}$. Combined with the assumption that $\text{supp}(\mu) \subset \text{supp}(\mu_0)$, this implies that $d_\mathbf{H}(\mu_0,\mu) \leq \varepsilon$.
\end{proof}

To obtain the smooth function $f$ to which we can apply Lemmas \ref{LemmaTTSICICS} and \ref{LemmaTAOIAWOIDJ12301}, we take a measure $\eta$, which is a linear combination of Dirac deltas, and let $f = \eta * \phi_r$. To obtain the appropriate control on $\widehat{f}$, it suffices to have a decay bound for $\widehat{\eta}$ for $|\xi| \leq 1/r$, and a weaker bound for $|\xi|$ slightly bigger than $1/r$, which is required before we can take complete advantage of the Fourier decay of the mollifier $\phi_r$ for $|\xi| \geq 1/r$.

\begin{comment}

\begin{lemma} \label{Lemma65493}
    Fix $C > 0$, $r,\varepsilon_1 > 0$, and $\beta \in (0,d/2]$. Consider $K$ points $x_1, \dots, x_K \in \TT^d$ such that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq 1/r^{1+\varepsilon_1}$,
    %
    \begin{equation} \label{equationOIJDOIJIO}
        \left| \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i x_i \cdot \xi} \right| \leq C |\xi|^{-\beta}.
    \end{equation}
    %
    Then if we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{r}(x - x_i), \]
    %
    then $\| f \|_{M(\beta-\varepsilon_1)} \lesssim_{d,\varepsilon_1} C$.
\end{lemma}
\begin{proof}
    Set
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then \eqref{equationOIJDOIJIO} is equivalent to the property that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq 1/r^{1 + \varepsilon_1}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C |\xi|^{-\beta}.
    \end{equation}
    %
    Noting that $f = D * \phi_{r}$, we conclude that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_{r}}|.
    \end{equation}
    %
    For $0 < |\xi| \leq 1/r^{1 + \varepsilon_1}$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationDIOJAOIJVIV23242} to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
        |\widehat{f}(\xi)| \leq C |\xi|^{-\beta} \leq C |\xi|^{\varepsilon_1 - \beta}.
    \end{equation}
    %
    For $|\xi| \geq 1/r^{1 + \varepsilon_1}$, we note that \eqref{molificationdecaybound} implies $\widehat{\phi_{r}}(\xi) \lesssim_T r^{-T} |\xi|^{-T}$, and so if $T \geq \beta$,
    %
    \begin{equation} \label{equationDIICCCJSXVVM21}
        |\widehat{f}(\xi)| \lesssim_T [r^{-T} |\xi|^{\beta-T}] |\xi|^{-\beta} \leq [r^{-T} r^{-(1+\varepsilon_1)(\beta-T)}] |\xi|^{-\beta} \leq r^{-(1+\varepsilon_1) \beta + \varepsilon_1 T} |\xi|^{-\beta}.
    \end{equation}
    %
    Setting $T = (1 + 1/\varepsilon_1) \cdot \beta$ gives $|\widehat{f}(\xi)| \lesssim_{\varepsilon_1,d} |\xi|^{-\beta}$.
\end{proof}

\end{comment}

\begin{lemma} \label{Lemma65493}
    Fix $C > 0$ and $\varepsilon,\varepsilon_1,\varepsilon_2 > 0$, with $\varepsilon_2 \leq \beta/2$. Then there exists $r_0 > 0$ depending on all these quantities, such that if $0 < r \leq r_0$, then for any Borel probability measure $\eta$ on $\TT^d$ satisfying
    %
    \begin{equation} \label{equationOIJDOIJIO}
        \left| \widehat{\eta}(\xi) \right| \leq \varepsilon \cdot |\xi|^{\varepsilon_2-\beta/2}\quad\quad\text{for $0 < |\xi| \leq (1/r)$}
    \end{equation}
    %
    and
    %
    \begin{equation} \label{equationOIJDOIJIO2}
        \left| \widehat{\eta}(\xi) \right| \leq C \cdot r^{\beta/2} \log(1/r)^{1/2} \quad\quad\text{for $(1/r) \leq |\xi| \leq (1/r)^{1 + \varepsilon_1}$},
    \end{equation}
    %
    if we define $f(x) = (\eta * \phi_r)(x)$, then $\| f \|_{M(\beta/2 - \varepsilon_2)} \leq 2\varepsilon$.
\end{lemma}
\begin{proof}
    For each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equation6666GGCIS}
        \widehat{f}(\xi) = \widehat{\eta}(\xi) \widehat{\phi_r}(\xi).
    \end{equation}
    %
    For $|\xi| \leq 1/r$ we combine \eqref{equationOIJDOIJIO}, \eqref{equation6666GGCIS} and \eqref{equationDIOJAOIJVIV23242} to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
    \begin{split}
        |\widehat{f}(\xi)| &\leq \varepsilon \cdot |\xi|^{\varepsilon_2 - \beta/2}.
    \end{split}
    \end{equation}
    %
    If $(1/r) \leq |\xi| \leq (1/r)^{1+\varepsilon_1}$, \eqref{molificationdecaybound} implies $|\widehat{\phi_{r}}(\xi)| \lesssim_\beta r^{-\beta/2} |\xi|^{-\beta/2}$, which together with \eqref{equationOIJDOIJIO2}, \eqref{equation6666GGCIS}, and \eqref{equationDIOJAOIJVIV23242}, show that for $r \leq r_1$,
    %
    \begin{equation} \label{equationGGOOSC66341}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_\beta \left( C r^{\beta/2} \log(1/r)^{1/2} \right) \left( r^{-\beta/2} |\xi|^{-\beta/2} \right)\\
        &\leq C \log(1/r)^{1/2} \cdot |\xi|^{-\beta/2}\\
        &\leq C r^{\varepsilon_2} \log(1/r)^{1/2} \cdot |\xi|^{\varepsilon_2-\beta/2}.
    \end{split}
    \end{equation}
    %
    Since $C r^{\varepsilon_2} \log(1/r)^{1/2} \to 0$ as $r \to 0$, so we conclude from \eqref{equationGGOOSC66341} that there exists $r_1 > 0$ such that for $r \leq r_1$ and $(1/r) \leq |\xi| \leq (1/r)^{1 + \varepsilon_1}$
    %
    \begin{equation} \label{equationUUUDDDCII777}
        |\widehat{f}(\xi)| \leq \varepsilon \cdot |\xi|^{\varepsilon_2-\beta/2}.
    \end{equation}
    %
    If $|\xi| \geq (1/r)^{1 + \varepsilon_1}$, we apply \eqref{molificationdecaybound} for $T \geq \beta/2$ to conclude
    %
    \begin{equation} \label{equationGGUSCCCYVSSXX998723}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_T r^{-T} |\xi|^{-T}\\
        &= r^{-T} |\xi|^{\beta/2 - T} \cdot |\xi|^{-\beta/2}\\
        &\leq r^{-T} (1/r)^{(\beta/2 - T)(1 + \varepsilon_1)} \cdot |\xi|^{-\beta/2}\\
        &= r^{\varepsilon_1 T - (\beta/2)(1 + \varepsilon_1)} \cdot |\xi|^{-\beta/2}.
    \end{split}
    \end{equation}
    %
    If we choose $T > (\beta/2)(1 + 1/\varepsilon_1)$, then as $r \to 0$, $r^{\varepsilon_1 T - (\beta/2)(1 + \varepsilon_1)} \to 0$. Thus we conclude from \eqref{equationGGUSCCCYVSSXX998723} that there exists $r_2 > 0$ satisfying such that for $0 < r \leq r_2$ and $|\xi| \geq (1/r)^{1+\varepsilon_1}$,
    %
    \begin{equation} \label{equationBBCDSGDCC77}
        |\widehat{f}(\xi)| \leq \varepsilon \cdot |\xi|^{-\beta/2} \leq \varepsilon \cdot |\xi|^{\varepsilon_2-\beta/2}.
    \end{equation}
    %
    All that remains is to combine \eqref{equationGGIOHISI99234}, \eqref{equationUUUDDDCII777}, and \eqref{equationBBCDSGDCC77}, defining $r_0 = \min(r_1,r_2)$.
\end{proof}

\begin{comment}

\begin{proof}
    Set
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then \eqref{equationOIJDOIJIO} is equivalent to the property that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C |\xi|^{-\beta/2}.
    \end{equation}
    %
    Noting that $f = D * \phi_{\varepsilon_0}$, we conclude that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_{\varepsilon_0}}|.
    \end{equation}
    %
    For $0 < |\xi| \leq 1/\varepsilon_0^{1 + \varepsilon_2}$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationDIOJAOIJVIV23242} to conclude
    %
    \begin{equation} \label{equationWOIDJAOIDJOISCJOICJCCCCCC}
        |\widehat{f}(\xi)| \leq C |\xi|^{-\beta/2} \leq C |\xi|^{\varepsilon_1 - \beta/2}.
    \end{equation}
    %
    For $|\xi| \geq 1/\varepsilon_0^{1 + \varepsilon_2}$, we note that \eqref{molificationdecaybound} implies $\widehat{\phi_{\varepsilon_0}}(\xi) \lesssim_T \varepsilon_0^{-T} |\xi|^{-T}$, and so if $T \geq \beta/2$,
    %
    \begin{align} \label{equationDIOJIOCJCCCXXXSDDQW}
        |\widehat{f}(\xi)| &\lesssim_T [\varepsilon_0^{-T} |\xi|^{T-\beta/2}] |\xi|^{-\beta/2}\\
        &\leq [\varepsilon_0^{-T} \varepsilon_0^{-(1 + \varepsilon_2)(T - \beta/2)}] |\xi|^{-\beta/2}\\
        &= \varepsilon_0^{(1 + \varepsilon_2)(\beta/2) - T(2 + \varepsilon_2)}
    \end{align}
\end{proof}

\begin{lemma} \label{Lemma65493}
    Fix $C > 0$, $\varepsilon_1, \varepsilon_2 > 0$, and $\varepsilon > 0$. Consider $K$ points $x_1, \dots, x_K \in \TT^d$ such that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationOIJDOIJIO}
        \left| \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i x_i \cdot \xi} \right| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Then there exists a large integer $K_0$ depending on $C$,$\beta$,$\varepsilon_1$,$\varepsilon_2$, and $\varepsilon$, such that if $K \geq K_0$, $r \geq C^{-1} K^{-1/\beta}$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{r}(x - x_i), \]
    %
    then $\| f \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$.
\end{lemma}
\begin{proof}
    Set
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then \eqref{equationOIJDOIJIO} is equivalent to the property that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Noting that $f = D * \phi_{r}$, we conclude that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_{r}}|.
    \end{equation}
    %
    For $0 < |\xi| \leq K^{1/\beta}$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationDIOJAOIJVIV23242} to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
        |\widehat{f}(\xi)| \leq \left[ C K^{-\varepsilon_1/\beta} \log(K)^{1/2} \right] |\xi|^{\varepsilon_1 - \beta/2}.
    \end{equation}
    %
    As $K \to \infty$, $K^{-\varepsilon_1/\beta} \log(K)^{1/2} \to 0$, so we conclude from \eqref{equationGGIOHISI99234} there exists a large integer $K_1(C,\beta,\varepsilon_1,\varepsilon)$ such that for $K \geq K_1(C,\beta,\varepsilon_1,\varepsilon)$,
    %
    \begin{equation} \label{equation663sdDDDCC}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_1-\beta/2}.
    \end{equation}
    %
    If $K^{1/\beta} \leq |\xi| \leq K^{1/\beta + \varepsilon_2}$, we note that \eqref{molificationdecaybound} implies $\widehat{\phi_{r}}(\xi) \lesssim_d r^{-\beta/2} |\xi|^{-\beta/2}$, which together with \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS}, and the bound $r \geq C^{-1} K^{-1/\beta}$, imply
    %
    \begin{equation} \label{equationGGOOSC66341}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_d \left( C K^{-1/2} r^{-\beta/2} K^{-\varepsilon_1/\beta} \log(K)^{1/2} \right) |\xi|^{\varepsilon_1-\beta/2}\\
        &\leq \left( C^{1 + \beta/2} K^{-\varepsilon_1/\beta} \log(K)^{1/2} \right) |\xi|^{\varepsilon_1 - \beta/2}.
    \end{split}
    \end{equation}
    %
    Again, we find that as $K \to \infty$, $K^{-\varepsilon_1/\beta} \log(K)^{1/2} \to 0$, so we conclude from \eqref{equationGGOOSC66341} that there exists $K_2(C,\beta,\varepsilon_1,\varepsilon)$ such that if $K \geq K_2(C,\beta,\varepsilon_1,\varepsilon)$, then
    %
    \begin{equation} \label{equationUUUDDDCII777}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_1-\beta/2}.
    \end{equation}
    %
    If $|\xi| \geq K^{1/\beta + \varepsilon_2}$, we apply \eqref{molificationdecaybound} for $T \geq \beta/2$ together with the bound $r \geq C^{-1} K^{-1/\beta}$ to conclude
    %
    \begin{equation} \label{equationGGUSCCCYVSSXX998723}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_T r^{-T} |\xi|^{-T}\\
        &\leq \left[ C^T K^{T/\beta} |\xi|^{\beta/2 - T} \right] |\xi|^{-\beta/2}\\
        &\leq \left[ C^T K^{1/2 + (\beta/2 - T) \varepsilon_2} \right] |\xi|^{-\beta/2}.
    \end{split}
    \end{equation}
    %
    If we choose $T > \beta/2 + 1/2 \varepsilon_2$, then as $K \to \infty$, $K^{1/2 + (\beta/2 - T) \varepsilon_1} \to 0$. Thus we conclude from \eqref{equationGGUSCCCYVSSXX998723} that there exists a large integer $K_3(C,\beta,\varepsilon_2,\varepsilon)$ such that for $K \geq K_3(C,\beta,\varepsilon_2,\varepsilon)$ and $|\xi| \geq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationBBCDSGDCC77}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{-\beta/2}.
    \end{equation}
    %
    All that remains is to combine \eqref{equation663sdDDDCC}, \eqref{equationUUUDDDCII777}, and \eqref{equationBBCDSGDCC77}, defining $K_0 = \max(K_1,K_2,K_3)$.
\end{proof}

\end{comment}

\begin{corollary} \label{lemmaIOJDD23124}
    Fix $C > 0$ and $\varepsilon,\varepsilon_1,\varepsilon_2 > 0$ with $\varepsilon_2 \leq \beta/2$. Then there exists $r_0 > 0$ and $\delta > 0$ depending on these quantities, such that if $0 < r \leq r_0$, then for any Borel probability measure $\eta$ on $\TT^d$ satisfying
    %
    \begin{equation} \label{equationADOIJWAOIDJAD}
        \left| \widehat{\eta}(\xi) \right| \leq \delta \cdot |\xi|^{\varepsilon_2-\beta/2}\quad\quad\text{for $0 < |\xi| \leq (1/r)$}
    \end{equation}
    %
    and
    %
    \begin{equation} \label{equationIAOIDJAOICJOIBJOIEVJ2}
        \left| \widehat{\eta}(\xi) \right| \leq C \cdot r^{\beta/2} \log(1/r)^{1/2} \quad\quad\text{for $(1/r) \leq |\xi| \leq (1/r)^{1 + \varepsilon_1}$},
    \end{equation}
    %
    if we define $f(x) = (\eta * \phi_r)(x)$, and a probability measure
    %
    \[ \mu = \frac{f \mu_0}{(f \mu_0)(\TT^d)} \]
    %
    then $\| \mu - \mu_0 \|_{M(\beta/2-\varepsilon_2)} \leq \varepsilon$.
\end{corollary}
\begin{proof}
    Let
    %
    \[ \delta = \min \left( \frac{\varepsilon}{2}, \frac{1}{2}, \frac{\varepsilon}{4 \| \mu_0 \|_{M(\beta/2-\varepsilon_2)}} \right). \]
    %
    Thus if we apply Lemmas \ref{LemmaTTSICICS} and \ref{Lemma65493}, we conclude there exists $r_0$ such that for $r \leq r_0$,
    %
    \begin{equation} \label{equationDIOJAWDOIJAWIOJ212412}
        \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon_2)} \leq \varepsilon/2,
    \end{equation}
    %
    and
    %
    \begin{equation} \label{equationOIJOIJWOIDJWOIDJ3424526342412}
        \| f \mu_0 - \mu_0 \|_{M(0)} \leq \min \left( \frac{1}{2}, \frac{\varepsilon}{4 \| \mu_0 \|_{M(\beta/2 - \varepsilon_2)}} \right).
    \end{equation}
    %
    Equation \eqref{equationOIJOIJWOIDJWOIDJ3424526342412} implies that
    %
    \begin{equation} \label{equationIOAWJDOIJWDIOWJDIOW2414521}
        1 - \min \left( \frac{1}{2}, \frac{\varepsilon}{4 \| \mu_0 \|_{M(\beta/2 - \varepsilon_2)}} \right) \leq (f\mu_0)(\TT^d) \leq 1.
    \end{equation}
    %
    But now \eqref{equationDIOJAWDOIJAWIOJ212412} and \eqref{equationIOAWJDOIJWDIOWJDIOW2414521} show that
    %
    \begin{align*}
        \| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_2)} &\leq \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon)} + \| \mu - f \mu_0 \|_{M(\beta/2 - \varepsilon)}\\
        &\leq (\varepsilon/2) + \left( 1 - \frac{1}{(f \mu_0)(\TT^d)} \right) \| \mu_0 \|_{M(\beta/2 - \varepsilon)}\\
        &\leq (\varepsilon/2) + (\varepsilon/2) \leq \varepsilon. \qedhere
    \end{align*}
\end{proof}

\begin{comment}
\begin{lemma} \label{lemmaIOJDD23124}
    Consider a smooth finite measure $\mu_0$ on $\TT^d$. Fix $C > 0$, $r, \varepsilon_1, \varepsilon_2 > 0$, and $\varepsilon > 0$. Consider $K$ points $x_1, \dots, x_K \in \TT^d$ such that if
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationBBBBODDUH}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Then there exists a large integer $K_0(C,d,\beta,\mu_0,\varepsilon_1,\varepsilon_2,\varepsilon)$, such that if $K \geq K_0$ and $r \geq C^{-1} K^{-1/\beta}$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{r}(x - x_i), \]
    %
    and a smooth probability measure
    %
    \[ \mu = \frac{f \mu_0}{(f \mu_0)(\TT^d)}, \]
    %
    then $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$.
\end{lemma}
\begin{proof}
    It suffices to combine Lemmas \ref{LemmaTTSICICS} and \ref{Lemma65493} to show that there exists $K_0(C,d,\beta,\mu_0,\varepsilon_1,\varepsilon_2,\varepsilon)$ such that
    %
    \begin{equation} \label{equationDIOJAWDOIJAWIOJ212412}
        \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon/10,
    \end{equation}
    %
    and
    %
    \begin{equation} \label{equationOIJOIJWOIDJWOIDJ3424526342412}
        \| f \mu_0 - \mu_0 \|_{M(0)} \leq \min \left( \frac{1}{2}, \frac{\varepsilon}{4 \| \mu_0 \|_{M(\beta/2 - \varepsilon)}} \right).
    \end{equation}
    %
    As mentioned in Remark \ref{remarkFOIJIOSJCIOSJ}, \eqref{equationOIJOIJWOIDJWOIDJ3424526342412} implies that
    %
    \begin{equation} \label{equationIOAWJDOIJWDIOWJDIOW2414521}
        1 - \min \left( 1/2, (\varepsilon/4) \| \mu \|_{M(\beta/2-\varepsilon)} \right) \leq (f\mu_0)(\TT^d) \leq 1.
    \end{equation}
    %
    But now \eqref{equationDIOJAWDOIJAWIOJ212412} and \eqref{equationIOAWJDOIJWDIOWJDIOW2414521} show that
    %
    \begin{align*}
        \| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} &\leq \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon)} + \| \mu - f \mu_0 \|_{M(\beta/2 - \varepsilon)}\\
        &\leq (\varepsilon/2) + \left( 1 - \frac{1}{(f \mu_0)(\TT^d)} \right) \| \mu_0 \|_{M(\beta/2 - \varepsilon)} \leq \varepsilon. \qedhere
    \end{align*}
\end{proof}
\end{comment}

A useful technique to find functions with small Fourier coefficients is to apply some random techniques. This is because the `average' function has small Fourier coefficients.

\begin{lemma} \label{LemmaGISCICS1}
    Fix a positive integer $K$. Let $X_1, \dots, X_K$ be independant random variables on $\TT^d$, such that for each nonzero $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equatioNVVVVSXXJVU1132}
        \sum_{k = 1}^K \EE \left( e^{2 \pi i \xi \cdot X_k} \right) = 0.
    \end{equation}
    %
    Set
    %
    \[ \eta(x) = \frac{1}{K} \sum_{k = 1}^K \delta_{X_k}(x) \]
    %
    and
    %
    \[ B = \{ \xi \in \ZZ^d: 0 < |\xi| \leq K^{100/\beta} \}. \]
    %
    Then there exists a constant $C$ depending on $\beta$ and $d$, such that% depending on $\beta$ and $d$, such that
    %
    \[ \PP \left( \| \widehat{\eta} \|_{L^\infty(B)} \geq C K^{-1/2} \log(K)^{1/2} \right) \leq 1/10. \]
\end{lemma}

\begin{remark}
    In particular, \eqref{equatioNVVVVSXXJVU1132} holds if the $\{ X_i \}$ are uniformly distributed on $\TT^d$.
\end{remark}

\begin{proof}
    For each $\xi \in \ZZ^d$ and $k \in \{ 1, \dots, K \}$, consider the random variable
    %
    \begin{equation}
        Y(\xi,k) = K^{-1} e^{2 \pi i (\xi \cdot X_k)}.
    \end{equation}
    %
    Then for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationPPDOCS999223}
        \sum_{k = 1}^K Y(\xi,k) = \widehat{\eta}(\xi).
    \end{equation}
    %
    We also note that for each $\xi \in \ZZ^d$ and $k \in \{ 1, \dots, K \}$,
    %
    \begin{equation} \label{equationGFDSCSXAOOO99}
        |Y(\xi,k)| = K^{-1}.
    \end{equation}
    %
    Moreover,
    %
    \begin{equation} \label{equationDOIJWIJCCCCC5555322}
    \begin{split}
        \sum_{k = 1}^K \EE(Y(\xi,k)) = 0.
    \end{split}
    \end{equation}
    %
    Since the family of random variables $\{ Y(\xi,k) \}$ is independent for a fixed $\xi$, we can apply Hoeffding's inequality together with \eqref{equationPPDOCS999223} and \eqref{equationGFDSCSXAOOO99} to conclude that for all $t \geq 0$,
    %
    \begin{equation} \label{equationDDISCCOXOSPP998323}
        \PP \left( |\widehat{\eta}(\xi)| \geq t \right) \leq 2 e^{-Kt^2/2}.
    \end{equation}
    %
    A union bound obtained by applying \eqref{equationDDISCCOXOSPP998323} over all $|\xi| \leq K^{100/\beta}$ shows that there exists a constant $C \geq 1$ depending on $d$ and $\beta$ such that %depending on $d$ and $\beta$ such that
    %
    \begin{equation} \label{equationPPDOCS2424}
        \PP \left( \| \widehat{\eta} \|_{L^\infty(B)} \geq t \right) \leq \exp \left( C \log(K) - \frac{5K t^2}{C} \right).
    \end{equation}
    %
    But then, setting $t = CK^{-1/2} \log(K)^{1/2}$ in \eqref{equationPPDOCS2424} completes the proof.
\end{proof}

Let us now consider the consequences of the square-root cancellation bound in Lemma \ref{LemmaGISCICS1}. Given $\eta$ as in Lemma \ref{LemmaGISCICS1}, consider the smooth function $f = \eta * \phi_r$. The support of $f$ consists of $K$ radius $r$ balls. Provided $K \approx r^{-\beta}$, the support therefore behaves like an $r$-thickening of a set with Minkowski dimension $\beta$. If
%
\begin{equation}
    \| \widehat{\eta} \|_{L^\infty(B)} \leq C K^{-1/2} \log(K)^{1/2},
\end{equation}
%
as is guaranteed with high probability in Lemma \ref{LemmaGISCICS1}, we actually find that the support of $f$ also behaves like an $r$-thickening of a set with \emph{Fourier dimension} $\beta$ as well. This is one reason why constructions involving some kind of square-root cancellation are often a viable tactic to construct Salem sets, with random examples being an important example of such a construction.

\begin{lemma} \label{remarkGGIVJIS}
    Fix $\varepsilon,\varepsilon_1 > 0$ and $C > 0$ with $\varepsilon_1 \leq \beta/2$. Then there exists $r_0 > 0$ and $C' > 0$ depending on these quantities such that for $r \leq r_0$, if $K \geq (1/C) r^{-\beta}$ and $\eta$ is a Borel probability measure with
    %
    \[ \| \widehat{\eta} \|_{L^\infty(B)} \leq C K^{-1/2} \log(K)^{1/2}, \]
    %
    then
    %
    \[ |\widehat{\eta}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_1 - \beta/2} \quad\quad \text{for $|\xi| \leq (1/r)$} \]
    %
    and
    %
    \[ |\widehat{\eta}(\xi)| \leq C' r^{\beta/2} \log(1/r)^{1/2} \quad\quad \text{for $(1/r) \leq |\xi| \leq (1/r)^{2}$}. \]
\end{lemma}
\begin{proof}
    The function $x \mapsto x^{-1/2} \log(x)^{1/2}$ is decreasing for sufficiently large $x$. Thus if $r_0$ is chosen appropriately small, then for $|\xi| \leq (1/r)$ we find
    %
    \begin{equation} \label{equationCIJICJSICJSI}
        |\widehat{\eta}(\xi)| \leq C K^{-1/2} \log(K)^{1/2} \leq C r^{\varepsilon_2} \log((1/C) r^{-\beta})^{1/2} \cdot |\xi|^{\varepsilon_2 - \beta/2} \leq \varepsilon \cdot |\xi|^{\varepsilon_2 - \beta/2}.
    \end{equation}
    %
    If $r_0$ is appropriately small, then
    %
    \[ (1/r)^2 \leq C^{2/\beta} K^{2/\beta} \leq K^{100/\beta} \]
    %
    Thus for $(1/r) \leq |\xi| \leq (1/r)^2$, $\xi \in B$, and so we find there is $C' > 0$ such that
    %
    \begin{equation} \label{equationJVOIJICKCCO23}
        |\widehat{\eta}(\xi)| \leq C K^{-1/2} \log(K)^{1/2} \leq C r^{\beta/2} \log((1/C) r^{-\beta})^{1/2} \leq C' r^{\beta/2} \log(1/r)^{1/2}.
    \end{equation}
    %
    Together, \eqref{equationCIJICJSICJSI} and \eqref{equationJVOIJICKCCO23} give what was required.
\end{proof}

It is a general heuristic that quasi-all sets are as `thin as possible' with respect to the Hausdorff metric. In particular, we should expect the Hausdorff dimension and Fourier dimension of a generic element of $\mathcal{X}_\beta$ to be as low as possible. For each $(E,\mu) \in \mathcal{X}_\beta$, the condition that $\mu \in M(\beta/2)$ implies that $\fordim(\mu) \geq \beta$, so $\fordim(E) \geq \beta$. Thus it is natural to expect that for quasi-all $(E,\mu) \in M(\beta/2)$, the set $E$ has both Hausdorff dimension and Fourier dimension equal to $\beta$.

\begin{lemma}
    For quasi-all $(E,\mu) \in \mathcal{X}_\beta$, $E$ is a Salem set of dimension $\beta$.
\end{lemma}
\begin{proof}
    We shall assume $\beta < d$ in the proof, since when $\beta = d$, $E$ is a Salem set for any $(E,\mu) \in \mathcal{X}_\beta$, and thus the result is trivial. Since the Hausdorff dimension of a measure is an upper bound for the Fourier dimension, it suffices to show that for quasi-all $(E,\mu) \in \mathcal{X}_\beta$, $E$ has Hausdorff dimension at most $\beta$. For each $\alpha > \beta$ and $\delta, s > 0$, and let $A(\alpha,\delta,s) = \{ (E,\mu) \in \mathcal{X}: H^\alpha_\delta(E) < s \}$. Then $A(\alpha,\delta,s)$ is an open subset of $\mathcal{X}_\beta$, and
    %
    \[ \bigcap_{n = 1}^\infty \bigcap_{m = 1}^\infty \bigcap_{k = 1}^\infty A(\beta + 1/n, 1/m, 1/k) \]
    %
    is precisely the family of $(E,\mu) \in \mathcal{X}_\beta$ such that $E$ has Hausdorff dimension at $\beta$.
%
    %Certainly any $E$ in this family must have $H^\alpha(E) = 0$ for all $\alpha > \beta$, so $\hausdim(E) \leq \beta$. But the condition that $\mu \in M(A)$ implies $\fordim(\mu) \geq \beta$. Thus
    %
    %\[ \beta \leq \fordim(\mu) \leq \fordim(E) \leq \hausdim(E) \leq \beta, \]
    %
    %hence all these quantities are equal to $\beta$.
    Thus it suffices to show that $A(\alpha,\delta,s)$ is dense in $\mathcal{X}_\beta$ for $\alpha \in (\beta,d)$ and $\delta, s > 0$. Fix $(E_0,\mu_0) \in \mathcal{X}_\beta$, $\alpha \in (\beta,d)$, $\delta > 0$, $s > 0$, and $\varepsilon_1 > 0$. We aim to show that for each $\varepsilon > 0$, there exists $(E,\mu) \in A(\alpha,\delta,s)$ such that $d_\mathbf{H}(E,E_0) \leq \varepsilon$ and $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$. Without loss of generality, in light of Lemma \ref{smoothdensitylemma}, we may assume that $\mu_0 \in C^\infty(\TT^d)$.

    Fix a small value $r$, and then find an integer $K$ such that $r^{-\beta} \leq K \leq r^{-\beta} + 1$. Lemma \ref{LemmaGISCICS1} shows that there exists a constant $C$ depending on $\beta$ and $d$, as well as $K$ points $x_1, \dots, x_K \in \TT^d$ such that if
    %
    \[ \eta(x) = \frac{1}{K} \sum_{k = 1}^K \delta_{X_k}(x), \]
    %
    then for each $|\xi| \leq (1/r)^{1 + 1/\beta} \leq K^{1/\beta + 1}$,
    %
    \begin{equation} \label{equationDDVVIXXSX23}
        |\widehat{\eta}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Equation \eqref{equationDDVVIXXSX23} shows $\eta$ satisfies the hypotheses of Lemma \ref{remarkGGIVJIS}, and the result of Lemma \ref{remarkGGIVJIS} can then be fed into Corollary \ref{lemmaIOJDD23124} to conclude that for any $\delta > 0$, there exists $r_1 > 0$ such that if $r \leq r_1$, if
    %
    \[ \mu_1(x) = \frac{1}{K} \left( \sum_{k = 1}^K \phi_{r}(x - x_k) \right) \mu_0(x), \]
    %
    and if
    %
    \[ \mu = \mu_1 / \mu_1(\TT^d), \]
    %
    then
    %
    \begin{equation} \label{equationYYUDUSC4434}
        \| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \min(\delta,\varepsilon).
    \end{equation}
    %
    If $\delta$ is chosen appropriately, Lemma \ref{LemmaTAOIAWOIDJ12301} implies
    %
    \begin{equation}
        d_{\mathbf{H}}(\text{supp}(\mu),\text{supp}(\mu_0)) \leq \varepsilon.
    \end{equation}
    %
    Note that $\mu$ is supported on $K$ balls of radius $r$. Thus for $r \leq \delta$,
    %
    \begin{equation} \label{equationGGSCPXX22}
        H^\alpha_\delta(\text{supp}(\mu)) \leq K r^\alpha \leq (r^{-\beta} + 1) r^\alpha = r^{\alpha - \beta} + r^\alpha.
    \end{equation}
    %
    Since $\alpha > \beta$, \eqref{equationGGSCPXX22} implies that there is $r_2 > 0$ depending on $\alpha$, $\beta$, and $s$ such that for $r \leq r_2$, $H^\alpha_\delta(\text{supp}(\mu)) \leq s$. This means $(\text{supp}(\mu),\mu) \in A(\alpha,\delta,s)$, and since $\varepsilon > 0$ was arbitrary, we see that we have proved what was required.
\end{proof}

This concludes the setup to the proof of Theorems \ref{periodictheorem} and \ref{TheoremGGHSDIOCJOIJ}. All that remains is to show that quasi-all elements of $\mathcal{X}_\beta$ avoid the given set $Z$; just as with some of the proofs we have given in this section, the advantage of the Baire category approach is that we can reduce our calculations to discussing only a couple scales at once, which allows us to focus solely on the discrete, quantitative question at the heart of the problem.

\section{Random Avoiding Sets for Rough Patterns}

We begin by proving Theorem \ref{periodictheorem}, which requires simpler calculations than Theorem \ref{TheoremGGHSDIOCJOIJ}. In the last section, our results held for an arbitrary $\beta \in (0,d]$. But in this section, we assume
%
\[ \beta = \min \left( d, \frac{dn - \alpha}{n - 1/2} \right), \]
%
which will enable us to generically avoid the pattern $Z$ described in Theorem \ref{periodictheorem}. The construction here is very similar to the construction in \cite{OurPaper}, albeit in a Baire category setting and with modified parameters to ensure a Fourier dimension bound rather than just a Hausdorff dimension bound.

\begin{lemma} \label{LemmaVIVIJCIJSIJ}
    Suppose $Z \subset \TT^{dn}$ is a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Then for quasi-all $(E,\mu) \in \mathcal{X}_\beta$, for any distinct points $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$.
\end{lemma}
\begin{proof}
    The set $Z \subset \RR^{dn}$ is the countable union of sets with lower Minkowski dimension at most $\alpha$. For a closed set $W \subset \TT^{dn}$ with lower Minkowski dimension at most $\alpha$, and $s > 0$, consider the set
    %
    \[ B(W,s) = \left\{ (E,\mu) \in \mathcal{X}_\beta: \begin{array}{c}
            \text{for all $x_1, \dots, x_n \in E$ such that}\\
            \text{$|x_i - x_j| \geq s$ for $i \neq j$, $(x_1, \dots, x_n) \not \in W$}
        \end{array} \right\}. \]
    %
    If $(E_0,\mu_0) \in B(W,s)$, then because $E_0$ is compact, so too is the set
    %
    \[ F = \{ (x_1,\dots,x_n) \in E_0^n : |x_i - x_j| \geq s\ \text{for $i \neq j$} \} \]
    %
    Since $W$ is also closed, hence compact, there exists $\varepsilon > 0$ such that if $(x_1,\dots,x_n) \in F$, then $d((x_1,\dots,x_n),W) > \varepsilon$. It follows that if $d_\mathbf{H}(E_0,E) \leq \varepsilon$, then for any measure $\mu$ supported on $E$, $(E,\mu) \in B(W,s)$. Thus $B(W,s)$ is an open subset of $\mathcal{X}_\beta$. If $Z$ is a countable union of closed sets $\{ Z_k \}$ with lower Minkowski at most $\alpha$, then clearly the set
    %
    \[ \bigcup_{k = 1}^\infty \bigcup_{n = 1}^\infty B(Z_k,1/n) \]
    %
    consists of the family of sets $(E,\mu)$ such that for distinct $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$. Thus it suffices to show that $B(W,s)$ is dense in $\mathcal{X}_\beta$ for any $s > 0$, and any closed set $W$ with lower Minkowski dimension at most $\alpha$.

    Let us begin by fixing a set $W \subset \TT^{dn}$ and a pair $(E_0,\mu_0) \in \mathcal{X}_\beta$. We will show that for any $\varepsilon_1 \in (0,\beta/100]$ and $\varepsilon > 0$, we can find $(E,\mu) \in B(W,s)$ with $d_\mathbf{H}(E,E_0) \leq \varepsilon$ and $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$. We may assume by Corollary \ref{corollaryOIDJOWIJD2212} that $\text{supp}(\mu_0) = E$ and $\mu_0 \in C^\infty(\TT^d)$. Since $W$ has lower Minkowski dimension at most $\alpha$, we can find arbitrarily small $r \in (0,1)$ such that
    %
    \begin{equation} \label{equationGGSCSAS}
        |W_r| \leq r^{dn - \alpha - \varepsilon_1/4}.
    \end{equation}
    %
    Assume also that $r$ is small enough that we can find an integer $K \geq 10$ with
    %
    \begin{equation} \label{equationICCISAXAX122412}
        r^{-(\beta - \varepsilon_1/2)} \leq K \leq r^{-(\beta - \varepsilon_1/2)} + 1.
    \end{equation}
    %
    Let $X_1, \dots, X_K$ be independent and uniformly distributed on $\TT^d$. For each distinct set of indices $k_1, \dots, k_n \in \{ 1, \dots, K \}$, the random vector $X_k = (X_{k_1}, \dots, X_{k_n})$ is uniformly distributed on $\TT^{nd}$, and so \eqref{equationGGSCSAS} and \eqref{equationICCISAXAX122412} imply that
    % \psi_1 = \varepsilon \beta
    % \varepsilon \leq n - 1/2
    % \psi_2 \leq \beta/2
    % \psi_2 = 2 \varepsilon \beta
    \begin{equation} \label{equationGGASDCJWIJSFGGGG}
        \PP(d(X_k,W) \leq r) \leq |W_r| \leq r^{dn - \alpha - \varepsilon_1/4} \lesssim_{d,n,\beta} K^{\frac{-(dn - \alpha - \varepsilon_1/4)}{\beta - \varepsilon_1/2}} \leq K^{-(n-1/2)},
    \end{equation}
    %
    where we used the calculation
    %
    \begin{equation}
    \begin{split}
        \frac{dn - \alpha - \varepsilon_1/4}{\beta - \varepsilon_1/2} &= \frac{dn-\alpha}{\beta} + \frac{[(dn - \alpha)/\beta](\varepsilon_1/2) - \varepsilon_1/4}{\beta - \varepsilon_1/2}\\
        &\geq \frac{dn - \alpha}{\beta} + \frac{(n-1/2)(\varepsilon_1/2) - \varepsilon_1/4}{\beta - \varepsilon_1/2}\\
        &\geq \frac{dn - \alpha}{\beta} \geq n - 1/2.
    \end{split}
    \end{equation}
    %
    If $M_0$ denotes the number of indices $i$ such that $d(X_i,W) \leq r$, then by linearity of expectation we conclude from \eqref{equationGGASDCJWIJSFGGGG} that there is a constant $C$ depending only on $d$, $n$, and $\beta$ such that
    %
    \begin{equation} \label{equationDDASGVV}
        \EE(M_0) \leq (C/10) K^{1/2}.
    \end{equation}
    %
    Applying Markov's inequality to \eqref{equationDDASGVV}, we conclude that
    %
    \begin{equation} \label{equationFGGGSC}
        \PP(M_0 \geq C K^{1/2}) \leq 1/10.
    \end{equation}
    %
    %For each cube $I$ with sides parallel to the axis of $\TT^d$, and with sidelength $K^{-1/4d}$, we find
    %
%    \begin{equation} \label{equationDIOJOIDJSOIJ2222312414}
%    \begin{split}
%        \PP \left( \text{there is $i \in \{ 1, \dots, K \}$ such that $X_i \in I$} \right) &= 1 - (1 - K^{-1/4})^K \geq 1 - K^{-3/4}.
%    \end{split}
%    \end{equation}
    %
%    Now $\TT^d$ is covered by a family of at most $K^{1/4}$ such cubes $I$. If $F = \{ X_1, \dots, X_K \}$, then a union bound applying \eqref{equationDIOJOIDJSOIJ2222312414} repeatedly shows
    %
%    \begin{equation} \label{equationOIJIOWJDIOWJ23122142}
%        \PP \left( d_H(F,\TT^d) \leq d^{1/2} K^{-1/4d} \right) \geq 1 - K^{-1/2}.
%    \end{equation}
    %
%    In particular, we conclude from \eqref{equationOIJIOWJDIOWJ23122142} that there is $K_0$ depending only on $d$ and $\varepsilon$ such that if $K \geq K_0$, then
    %
%    \begin{equation} \label{equationOIWJOIAWJDOIWJ}
%         \PP \left( d_H(F,\TT^d) \leq d^{1/2} K^{-1/4d} \right) \leq 1/10.
%    \end{equation}
    %
    Taking a union bound to \eqref{equationFGGGSC} %\eqref{equationOIWJOIAWJDOIWJ}
    and the results of Lemma \ref{LemmaGISCICS1}, we conclude that there exists $K$ points $x_1, \dots, x_K \in \TT^d$ and a constant $C$ depending only on $d$, $n$, and $\beta$ such that the following two statements hold:
    %
    \begin{itemize}
        \item[(1)] Let $S$ be the set of indices $k_1 \in \{ 1, \dots, K \}$ with the property that we can find distinct indices $k_2, \dots, k_n \in \{ 1, \dots, K \}$ such that if $X = (X_{k_1}, \dots, X_{k_n})$, then $d(X, W) \leq r$. Then
        %
        \begin{equation} \label{equationGGSC99124}
            \#(S) \leq C K^{1/2}.
        \end{equation}

        \item[(2)] If we define
        %
        \[ \eta_0(x) = \frac{1}{K} \sum_{k = 1}^K \delta_{x_k}(x) \]
        %
        then for $0 < |\xi| \leq K^{100/\beta}$,
        %
        \begin{equation} \label{equationGGGISCI11242}
            |\widehat{\eta_0}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
        \end{equation}
    \end{itemize}
    %
    Thus \eqref{equationGGSC99124} and \eqref{equationGGGISCI11242} imply that if
    %
    \[ \eta_1(x) = \sum_{k \not \in S} \delta_{x_k}(x), \]
    %
    then for each $|\xi| \leq K^{1/\beta_0 + 1}$,
    %
    \begin{equation} \label{equationGGSCSIAXAXXXSFGG}
        |\widehat{\eta_1}(\xi)| \leq 2C K^{-1/2} \log(K).
    \end{equation}
    %
    Since $K \geq r^{\varepsilon_1/2 - \beta}$, we can apply Lemma \ref{remarkGGIVJIS} to $\eta_1$, and then apply Corollary \ref{lemmaIOJDD23124} to the result of Lemma \ref{remarkGGIVJIS} to conclude that for any $\delta > 0$, there is $r_0 > 0$ % depending only on $d$, $q$, $n$, $\beta$, $\mu_0$, $\varepsilon$, $\delta$, and $\varepsilon_1$
    such that if $r \leq r_0$ and we define
    %
    \[ \mu'(x) = \left( \sum_{k \not \in S} \phi_{(r/2n^{1/2})}(x - X_k) \right) \mu_0(x), \]
    %
    and then set $\mu = \mu' / \mu'(\TT^d)$, then
    %
    \begin{equation} \label{equationvVVV323285853S}
        \| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \min(\delta,\varepsilon).
    \end{equation}
    %
    Choosing $\delta$ in accordance with Lemma \ref{LemmaTAOIAWOIDJ12301}, \eqref{equationvVVV323285853S} also implies that $d_\mathbf{H}(\text{supp}(\mu), \text{supp}(\mu_0)) \leq \varepsilon$. Since $\varepsilon$ and $\varepsilon_1$ are arbitrary, our proof would therefore be complete if we could show that $(\text{supp}(\mu),\mu) \in B(W,s)$.

    Consider $n$ points $y_1, \dots, y_n \in \text{supp}(\mu)$, with $|y_i - y_j| \geq r$ for any two indices $i \neq j$. We can therefore find distinct indices $k_1, \dots, k_n \in \{ 1, \dots, K \}$ such that for each $i \in \{ 1, \dots, n \}$, $|x_{k_i} - y_i| \leq (n^{-1/2}/2) \cdot r$, which means if we set $x = (x_{k_1}, \dots, x_{k_n})$ and $y = (y_1, \dots, y_n)$, then
    %
    \begin{equation} \label{equationFISICISCI232222452}
        |x - y| \leq (r/2).
    \end{equation}
    %
    Since $i_1 \not \in S$, $d(x,W) \geq r$, which combined with \eqref{equationFISICISCI232222452} implies
    %
    \begin{equation} \label{equationSICSICI}
        d(y,W) \geq d(x,W) - |x - y| \geq r/2.
    \end{equation}
    %
    Thus in particular we conclude $y \not \in W$, which shows $(E,\mu) \in B(W,s)$.
\end{proof}

The Baire category theorem, applied to Lemma \ref{LemmaVIVIJCIJSIJ} implies Theorem \ref{periodictheorem}, and thus concludes the proof of Theorem \ref{maintheorem}. Before we move onto the next proof, let us discuss where the loss in Theorem \ref{maintheorem} occurs in our proof, as compared to the Hausdorff dimension bound of \cite{OurPaper}. In the proof of Lemma \ref{LemmaVIVIJCIJSIJ}, in order to obtain the bound \eqref{equationGGSCSIAXAXXXSFGG}, we were forced to choose the parameter $r$ such that $\#(S) \leq K^{1/2}$, so that the trivial bound
%
\begin{equation}
    \left| \sum_{k \in S} e^{2 \pi i (\xi \cdot X_k)} \right| \leq \#(S)
\end{equation}
%
obtained by the triangle inequality is viable to obtain a Fourier dimension bound. On the other hand, if we were able to justify that with high probability, we could obtain a square root cancellation bound
%
\begin{equation}
    \left| \sum_{k \in S} e^{2 \pi i (\xi \cdot X_k)} \right| \lesssim \#(S)^{1/2},
\end{equation}
%
then we would only need to choose the parameter $r$ such that $\#(S) \lesssim K$, which leads to a set with larger Fourier dimension, matching with the Hausdorff dimension bound obtained in \cite{OurPaper}. Under stronger assumptions on the pattern we are trying to avoid (the hypothesis of Theorem \ref{TheoremGGHSDIOCJOIJ}, we are roughly able to obtain such a result in the next section (though with an additional oscillatory term which decays fast as $\xi \to \infty$), enabling us to obtain this improved dimension bound.

\section{Avoiding Surfaces}

In this section we prove Theorem \ref{TheoremGGHSDIOCJOIJ} using some more robust probability concentration calculations. We set
%
\[ \beta = \frac{d}{n-1}. \]
%
For this value we will be able to generically avoid the pattern $Z$ described in Theorem \ref{TheoremGGHSDIOCJOIJ}.

\begin{lemma}
    Let $Z \subset \TT^{dn}$ satisfy the hypothesis of Theorem \ref{TheoremGGHSDIOCJOIJ}. Then for quasi-all $(E,\mu) \in \chi_\beta$, and for any distinct points $x_1,\dots,x_n \in E$, $(x_1,\dots,x_n) \not \in Z$.
\end{lemma}
\begin{proof}
    Fix a manifold $W \subset \TT^{dn}$ with finite type. Given any family of disjoint, sidelength $s$ closed cubes $R_1,\dots,R_n \subset \TT^d$ such that $d(R_i,R_j) \geq 10s$ and $R_1 \times \dots \times R_n \cap W$ is a closed set, we let
    %
    \begin{equation}
        H(W;R_1,\dots,R_n) = \left\{ (E,\mu) \in \mathcal{X}_\beta: (R_1 \times \dots \times R_n) \cap E^n \cap W = \emptyset \right\}.
    \end{equation}
    %
    Then $H(W;R_1,\dots,R_n)$ is an open subset of $\mathcal{X}_\beta$. For the purpose of a Baire category argument, our result will follow by showing $H(W;R_1,\dots,R_n)$ is dense in $\mathcal{X}_\beta$ for any family of cubes $\{ R_1,\dots, R_n \}$. Without loss of generality, possibly permuting coordinates if necessary we may assume that $1/s$ is an integer, and that for the family of cubes $\{ R_1,\dots, R_n \}$, if $Q_1 = 2R_1,\dots, Q_n = 2R_n$, then there exists a $C^\infty$ function $f: Q_2 \times \dots \times Q_n \to \RR^d$ such that
    %
    \begin{equation}
        W \cap (Q_1 \times \dots \times Q_n) = \{ (x_1,\dots,x_d) \in Q_1 \times \dots \times Q_n : x_1 = f(x_2,\dots,x_d) \}
    \end{equation}
    %
    and such that some higher order derivative of $f$ vanishes, as in the definition of a manifold of finite type. To begin with, for simplicity, let us assume that there is $l \in \{ 2, \dots, n \}$ such that $\partial f_j / \partial x^l$ is nonvanishing on $Q_2 \times \dots \times Q_n$ for each $j \in \{ 1, \dots, d \}$. Fix a constant $L \geq 0$ such that for any $x,x' \in Q_2 \times \dots \times Q_n$,
    %
    \begin{equation}
        |f(x) - f(x')| \leq L |x - x'|.
    \end{equation}
    %
    As with the previous proof, we fix $(E_0,\mu_0) \in \mathcal{X}_\beta$ with $\text{supp}(\mu_0) = E_0$ and $\mu_0 \in C^\infty(\TT^d)$, and show that for any $\varepsilon_1 \in (0,\beta/100]$ and $\varepsilon > 0$, there is $(E,\mu) \in H(W;Q_1,\dots,Q_n)$ with $\| \mu - \mu_0 \|_{M(\beta/2-\varepsilon_1)} \leq \varepsilon$.

    Fix a family of non-negative bump functions $\psi_0,\psi_1,\dots,\psi_n \in C^\infty(\TT^d)$, such that for $i \in \{ 1,\dots,n \}$, $\psi_i(x) = 1$ for $x \in R_i$, $\psi_i(x) = 0$ for $x \not \in Q_i$, and $\psi_0(x) + \dots + \psi_n(x) = 1$ for $x \in \TT^d$. Let $A_0,\dots,A_n$ denote the total mass of $\psi_0,\dots,\psi_n$ respectively. Now consider a family of independant random variables $\{ X_i(k) : 0 \leq i \leq n, 1 \leq k \leq K \}$, where the random variable $X_i(k)$ is continuous with distribution function $A_i^{-1} \psi_i$. Let $r = K^{\varepsilon_1/2 - 1/\beta}$
    % 2(n-1)/d \leq k
    and then set $S$ to be the set of indices $k_1 \in \{ 1, \dots, K \}$ such that there are indices $k_2,\dots,k_n \in \{ 1,\dots,K \}$ with the property that
    % r <= log(K)^{1/d} K^{(1-n)/d}
    % r^d = log(K) K^{\varepsilon_1 - (n - 1)}
    % Then we get a deviation of K^{1/2} log(K) instead which is prefectly fine!!!!!
    % On the other hand, we get that the expected value has very good decay bounds.
    \begin{equation} \label{equationDDIVJIVCJIJSDDKODKI23125}
        |X_1(k_1) - f(X_2(k_2),\dots,X_n(k_n))| \leq (L+1)r.
    \end{equation}
    %
    A simple argument following from \eqref{equationDDIVJIVCJIJSDDKODKI23125} shows that if $k_1 \not \in S$, then for any $k_2,\dots,k_n \in \{ 1, \dots, K \}$, if $X = (X_1(k_1),\dots,X_n(k_n))$, then $d(X,W) \geq r$. Thus if we define
    %
    \[ \eta = \sum_{i \in \{ 0, 2, \dots, n \}} A_i \sum_{k = 1}^K \delta_{X_i(k)} + A_1 \sum_{k \not \in S} \delta_{X_1(k)}, \]
    %
    if we define $\mu' = \eta * \phi_{(r/2n^{1/2})}$, and then set $\mu = \mu'/\mu'(\TT^d)$, $E = \text{supp}(\mu)$, then $(E,\mu) \in H(W;R_1,\dots,R_n)$. The remainder of our argument consists of obtaining control on the exponential sum
    %
    \begin{equation}
        U(\xi) = \widehat{\eta}(-\xi) = \sum_{i \in \{ 0, 2, \dots, n \}} A_i \sum_{k = 1}^K e^{2 \pi i \xi \cdot X_i(k)} + A_1 \sum_{k \not \in S} e^{2 \pi i \xi \cdot X_1(k)}.
    \end{equation}
    %
    so that we may apply Corollary \ref{lemmaIOJDD23124}.%to conclude that $\| \mu - \mu_0 \|_{M(\beta/2-\varepsilon_1)} \leq \varepsilon$ when $K$ is sufficiently large.

    For $\xi \in \ZZ^d$, set
    %
    \begin{equation}
        V(\xi) = \frac{1}{K} \sum_{i = 0}^n A_i \sum_{k = 1}^K e^{2 \pi i \xi \cdot X_i(k)}.
    \end{equation}
    %
    Then for non-zero $\xi \in \ZZ^d$,
    %
    \begin{equation}
        \EE(V(\xi)) = \sum_{i = 0}^n \int \psi_i(x) e^{2 \pi i \xi \cdot x}\; dx = K \int_{\TT^d} e^{2 \pi i \xi \cdot x}\; dx = 0.
    \end{equation}
    %
    Applying Lemma \ref{LemmaGISCICS1}, we conclude that if $B = \{ \xi \in \ZZ^d: 0 < |\xi| < K^{100/\beta} \}$, then there is $C > 0$ such that
    %
    \begin{equation} \label{equationCOIACOIAJCPPPPP}
        \PP \left( \| V \|_{L^\infty(B)} \geq C K^{-1/2} \log(K)^{1/2} \right) \leq 1/10.
    \end{equation}
    %
    It remains to analyze
    %
    \begin{equation}
        Y(\xi) = V(\xi) - U(\xi) = \frac{A_1}{K} \sum_{k \in S} e^{2 \pi i \xi \cdot X_k}.
    \end{equation}
    %
    Let us briefly discuss our strategy to obtain a concentration bound for $Y(\xi)$. The random quantity $Y(\xi)$ is a function of the independant random quantities $\{ X_i(k) \}$, and so we would like to apply McDiarmid's inequality to understand the concentration properties of $Y(\xi)$ about it's mean. However, a naive application of McDiarmid's inequality fails here, because changing a single random variable $X_i(k)$ for $i \geq 2$ can change the quantity $Y(\xi)$ by $\Omega(1)$, which is far too much square root cancellation (TODO: Diagram). On the other hand, it is highly unlikely that the random variables $\{ X_1(k) \}$ are arranged in such a way that $X_i(k)$ can change $Y(\xi)$ by $\Omega(1)$, so we should expect that adjusting a single random variable $X_i(k)$ does not influence the value of $Y(\xi)$ very much if the quantity $Y(\xi)$ is \emph{averaged} over the possible choices of $\{ X_1(k) \}$.

    Consider the random set $\Omega \subset Q_1$, which is the set of values $x \in Q_1$ such that there are $k_2,\dots,k_n \in \{ 1,\dots,K \}$ with
    %
    \begin{equation}
        |x - f(X_2(k_2),\dots,X_n(k_n))| \leq r.
    \end{equation}
    %
    Then
    %
    \begin{equation}
        Y(\xi) = \frac{1}{K} \sum_{k = 1}^K Z_k.
    \end{equation}
    %
    where
    %
    \begin{equation}
        Z(k) = \begin{cases} e^{2 \pi i \xi \cdot X_1(k)} &: X_1(k) \in \Omega, \\ 0 &: X_1(k) \not \in \Omega \end{cases}.
    \end{equation}
    %
    If $\Sigma$ is the $\sigma$ algebra generated by the random variables $\{ X_i(k) : i \geq 2, k \in \{ 1, \dots, K \} \}$, then the random variables $\{ Z(k) \}$ are \emph{conditionally independant} (and identically distributed) given $\Sigma$. Since we have $|Z(k)| \leq 1$ almost surely, Hoeffding's inequality thus implies that for all $t \geq 0$,
    %
    \begin{equation} \label{equationCOIJCOIJX1232312}
        \PP \left( \left| Y(\xi) - \EE(Y(\xi)|\Sigma) \right| \geq t \right) \leq 4 \exp \left( \frac{-K t^2}{2} \right).
    \end{equation}
    %
    It is simple to see that
    %
    \begin{equation}
        \EE(Y(\xi) | \Sigma) = \int_\Omega \psi_1(x) e^{2 \pi i \xi \cdot x}\; dx.
    \end{equation}
    %
    Since
    %
    \begin{equation}
        \Omega = \bigcup \left\{ B_r(f(X_2(k_2),\dots,X_n(k_n))) : 1 \leq k_2,\dots,k_n \leq K \right\}.
    \end{equation}
    % K^{n-1} = r^{(n-1) \varepsilon_1/2 - d}
    we see that varying each random variable $X_i(k)$ adjusts at most $K^{n-2}$ of the balls forming $\Omega$, and thus varying $X_i(k)$ independantly of the other random variables changes $\EE(Y(\xi)|\Sigma)$ by at most
    %
    \begin{equation}
        2 \cdot (2r)^d \cdot K^{n-2} = 2^{d+1} \cdot r^d \cdot K^{n-2} = \frac{2^{d+1} \cdot r^{(n-1) \varepsilon_1/2}}{K} \leq \frac{2^{d+1}}{K}.
    \end{equation}
    % K^{-(n-1)} = r^d
    % 
    Thus McDiarmid's inequality shows that for any $t \geq 0$,
    %
    \begin{equation} \label{equationCIJCIJIVJIO}
        \PP \left( |\EE(Y(\xi)|\Sigma) - \EE(Y(\xi))| \geq t \right) \leq 4 \exp \left( \frac{-K t^2}{2^{2d+1}} \right).
    \end{equation}
    %
    Combining \eqref{equationCOIJCOIJX1232312} and \eqref{equationCIJCIJIVJIO}, we conclude that for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationCNCIJIJOJOPPPPOPODAW}
        \PP \left( | Y(\xi) - \EE(Y(\xi)) | \geq t  \right) \leq 8 \exp \left( \frac{-K t^2}{2^{2d + 1}} \right).
    \end{equation}
    %
    Applying a union bound to \eqref{equationCNCIJIJOJOPPPPOPODAW} over all $\xi \in B$ shows that there exists a constant $C > 0$ such that
    %
    \begin{equation} \label{equationCOIJCIOJCOISJCI2312412}
        \PP \left( \| Y - \EE(Y) \|_{L^\infty(B)} \geq C K^{-1/2} \log(K)^{1/2} \right) \leq 1/10.
    \end{equation}
    %
    Combining \eqref{equationCOIACOIAJCPPPPP} and \eqref{equationCOIJCIOJCOISJCI2312412}, we conclude that there exists a constant $C > 0$ such that
    %
    \begin{equation} \label{equationOCIJCIOCJIO}
        \PP \left( \| U - \EE(Y) \|_{L^\infty(B)} \geq C K^{-1/2} \log(K)^{1/2} \right) \leq 1/2.
    \end{equation}
    %
    Our calculation will therefore be complete if we can bound the quantity $\EE(Y)$.

    For each non-zero $\xi \in \ZZ^d$, let $\eta_W$ be the surface measure on $W$ obtained from the pullback of the Lebesgue measure via the projection onto $(x_2,\dots,x_d)$, let $\sigma_r$ be the measure of the ball of radius $r$ in $\TT^d \times \{ 0 \}^{n-1}$, and let $\psi = \psi_1 \otimes \dots \otimes \psi_n$. Now since the random variables $X = (X_1(k_1),\dots,X_n(k_n))$ are uniformly distributed for $1 \leq k_1,\dots,k_n \leq K$, so
    %
    \begin{equation}
    \begin{split}
        \EE(Y(\xi)) &= K^n \cdot \EE \left( \frac{1}{K} \cdot \mathbf{I} \left( |X_1 - f(X_2,\dots,X_n)| \leq (L+1)r \right) e^{2 \pi i \xi \cdot X_1} \right)\\
        &= \frac{K^{n-1}}{A_1 \cdots A_n} \int_W \int_{B_{(L+1)r}(0)} \psi(x_1 + y,x_2,\dots,x_n) e^{2 \pi i \xi \cdot (x_1 + y)}\; dy\; dx\\
        &= \frac{K^{n-1}}{A_1 \cdots A_n} \left( \left( \psi \cdot \eta_W \right) * \sigma_{(L+1)r} \right)^{\wedge}(-\xi,0,\dots,0)\\
        &= \frac{K^{n-1}}{A_1 \dots A_n} \widehat{\psi \cdot \eta_W}(-\xi,0,\dots,0) \cdot \widehat{\sigma_{(L+1)r}}(-\xi,0,\dots,0)\\
        &= \frac{(L+1)^d}{A_1 \dots A_n} \cdot r^d K^{n-1} \cdot \widehat{\psi \cdot \eta_W}(-\xi,0,\dots,0) \cdot \widehat{\sigma_1}(-(L+1)r\xi,0,\dots,0)\\
        &= \frac{(L+1)^d}{A_1 \dots A_n} \cdot r^{(n-1) \varepsilon_1/2} \cdot \widehat{\psi \cdot \eta_W}(-\xi,0,\dots,0) \cdot \widehat{\sigma_1}(-(L+1)r\xi,0,\dots,0).
    \end{split}
    \end{equation}
    %
    Since $\sigma_1(\TT^d) = O_d(1)$, $\| \widehat{\sigma_1} \|_{L^\infty(\ZZ^d)} \lesssim_d 1$ (this is the best bound possible for $|\xi| \leq 1/r$). If we define $\tilde{\psi}(x_2,\dots,x_n) = \psi(f(x_2,\dots,x_n),x_2,\dots,x_n)$, then
    %
    \[ \widehat{\psi \cdot \eta_W}(-\xi,0,\dots,0) = \int_W \tilde{\psi}(x_2,\dots,x_n) e^{2 \pi i \xi \cdot f(x_2,\dots,x_n)}\; dx_2 \dots dx_n \]
    %
    The conditions we placed on the surface $W$ (proved, for instance, in \cite{Stein}) imply that
    %
    \begin{equation}
        |\widehat{\psi \cdot \eta_W}(-\xi,0,\dots,0)| \lesssim |\xi|^{-\beta/2}.
    \end{equation}
    %
    Thus for any $\delta > 0$, there exists $r_1$ such that for any $r \leq r_1$, and for any nonzero $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationOIJOJDOIJD}
        |\EE(Y(\xi))| \leq \delta |\xi|^{-\beta/2}.
    \end{equation}
    %
    From \eqref{equationOCIJCIOCJIO} and \eqref{equationOIJOJDOIJD}, we conclude there exists a choice of values $\{ X_i(k) \}$ such that for any $\xi \in B$,
    %
    \begin{equation}
        |\widehat{\eta}(\xi)| = |U(-\xi)| \leq C K^{-1/2} \log(K)^{1/2} + \delta |\xi|^{-\beta/2}.
    \end{equation}
    %
    Applying Lemma \ref{remarkGGIVJIS} and then Corollary \ref{lemmaIOJDD23124}, we conclude that if $\delta$ is chosen appropriately, then $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$, which completes the proof.
\end{proof}


\section{Salem Sets with non-approximable difference Sets}

Analyzing the last proof, you may have noticed that to 




\begin{comment}

\begin{lemma} \label{equationDIOJDOIJCIJ}
    Let $S$ be the set of indices $k_1 \in \{ 1, \dots, K \}$ such that there are indices $k_2,\dots,k_n \in \{ 1,\dots,K \}$ with the property that
    %
    \[ |X_1(k_1) - f(X_2(k_2),\dots,X_n(k_n))| \leq (L+1)r. \]
    %
    Then if $k_1 \not \in S$ and $k_2,\dots,k_n \in \{ 1,\dots,K \}$, if $X = (X_{k_1}^1,\dots,X_{k_n}^n)$, then $d(X,W) \geq r$.
\end{lemma}
\begin{proof}
    It follows by definition that
    %
    \[ |X_1(k_1) - f(X_2(k_2),\dots,X_n(k_n))| \geq (L+1)r. \]
    %
    If $Y = (Y_1,\dots,Y_n) \in W \cap (Q_1 \times \dots \times Q_n)$, then
    %
    \begin{align*}
        (L+1)r &\leq |X_1(k_1) - f(X_2(k_2),\dots,X_n(k_n))|\\
        &\leq |X_1(k_1) - Y_1| + |Y_1 - f(X_2(k_2),\dots,X_n(k_n)|\\
        &= |X_1(k_1) - Y_1| + |f(Y_2,\dots,Y_n) - f(X_2(k_2),\dots,X_n(k_n)|\\
        &\leq |X_1(k_1) - Y_1| + L|(Y_2,\dots,Y_n) - (X_2(k_2),\dots,X_n(k_n))\\
        &\leq (L+1) |X - Y|,
    \end{align*}
    %
    so $|X-Y| \geq r$.
\end{proof}

\end{comment}

\begin{comment}
Suppose we can show that for any $\xi \neq 0$,
%
\[ |\widehat{Y_1}(\xi) + \dots + \widehat{Y_N}(\xi)| \lesssim C \left( \| \widehat{Y_1} \|_{L^\infty(\RR^d)}^2 + \dots + \| \widehat{Y_N} \|_{L^\infty(\ZZ^d)}^2 \right)^{1/2}. \]
%
In the example we consider, this would then imply
%
\[ |Y_1(\xi) + \dots + Y_N(\xi)| \lesssim N^{1/2}. \]
%
Thus in the last theorem we can take $N = K$,
%
\[ N \leq K^{1 - (2d/\beta)(1 - 1/p)} \]
%
If we can set $p \geq 1$,
\end{comment}

\begin{comment}

\section{Techniques for Avoiding Hyperplanes}

Let $y = f(x)$ be a curve in $\TT^2$ defining a curve $S$, where $f$ is an analytic function (except perhaps at finitely many points?). Given $\varepsilon > 0$, we want to determine the differentiability of the map
%
\[ A(x) = H^1(S_\varepsilon \cap \{ x \times \TT \}). \]
%
We wish to show $A$ is a smooth function. The tangent to $S$ at a point $(x,f(x))$ is given by $(1,f'(x))$, and so the unit normal vector is
%
\[ N(x) = \frac{(f'(x),-1)}{\sqrt{1 + f'(x)^2}}. \]
%
Suppose that $x_0 \in \TT$ is fixed, and let $x \in \TT$ and $|\delta| \leq \varepsilon$ be given such that
%
\[ (x_0,y_0) = (x,f(x)) + \delta N(x) = \left( x + \frac{\delta f'(x)}{\sqrt{1+ f'(x)^2}}, f(x) - \frac{\delta}{\sqrt{1 + f'(x)^2}} \right) \]
%
Thus
%
\[ x_0 = x + \frac{\delta f'(x)}{\sqrt{1 + f'(x)^2}} \]
%
and
%
\[ y_0 = f(x) - \frac{\delta}{\sqrt{1 + f'(x)^2}}. \]
%
Now the first equation tells us that
%
\[ \delta = - (x - x_0) \frac{\sqrt{1 + f'(x)^2}}{f'(x)}. \]
%
Thus if we define
%
\[ g(x,x_0) = \begin{cases} f(x) + \frac{x - x_0}{f'(x)} &: f'(x) \neq 0 \\ BLAH &: BLAH, \end{cases} \]
%
then $y_0 = g(x,x_0)$. Thus we ask ourselves what is the value of
%
\[ A(x_0) = \max \left\{ f(x) + \frac{x - x_0}{f'(x)} : |x - x_0| \leq \frac{\varepsilon |f'(x)|}{\sqrt{1 + f'(x)^2}} \right\}. \]
%
Now $g(x,x_0)$ is a smooth function except where $f'(x) = 0$. In particular, if $f'(x_0) \neq 0$, then the constraint region defining $A(x_0)$ is a finite union of closed intervals. And $f'(x_0) = 0$ only at finitely many points, and if we make $\varepsilon$ small enough we can make $A(x_0) = f(x_0) + \varepsilon$ at these points.

so this causes us no problems since we only care about whether $A$ is differentiable except at finitely many points. To analyze $A(x_0)$ when $f'(x_0) = 0$, we note that a solution that gives the maximum either satisfies
%
\[ f'(x)(f'(x)^2 + 1) + (x - x_0) f''(x) = 0 \]
%
or
%
\[ x - x_0 = \frac{\varepsilon f'(x)}{\sqrt{1 + f'(x)^2}} \]
%
or
%
\[ x - x_0 = \frac{-\varepsilon f'(x)}{\sqrt{1 + f'(x)^2}}. \]
%
If $\varepsilon$ is small enough, then the implicit function theorem implies that the second and third equations have finitely many solutions for each $x_0$, which are locally smoothly parameterized. Since $f'(x_0) \neq 0$, the first equation does not even have any solutions if $\varepsilon \lesssim 1$. Thus we conclude that if $\varepsilon$ is small enough, there exists a function $x(x_0)$ which is smooth, except at finitely many points, such that
%
\[ g(x_0) = f(x) + \frac{x - x_0}{f'(x)}. \]
%
Thus at any $x_0$ where $x$ is smooth, we conclude
%
\[ g'(x_0) = f'(x) \cdot x' + \frac{x' - 1}{f'(x)} - \frac{x - x_0}{f'(x)^2} f''(x) x'. \]

\end{comment}

\begin{thebibliography}{9}

\bibitem{OurPaper}
    Jacob Denson, Malabika Pramanik, Joshua Zahl,
    \textit{Large sets avoiding rough patterns}.

\bibitem{myThesis}
    Jacob Denson,
    \textit{Cartesian products avoiding patterns}.

\bibitem{Ekstrom2014}
    Fredrik Ekstr\"{o}m, Tomas Persson J\"{o}rg Schmeling,
    \textit{On the Fourier dimension and a modification},
    2015.

\bibitem{PramanikFraser}
    Robert Fraser, Malabika Pramanik,
    \textit{Large Sets Avoiding Patterns},
    2016.

\bibitem{Stein}
    Elias Stein,
    \textit{Harmonic Analysis: Real-Variable Methods, Orthogonality, and Oscillatory Integrals},
    1993.

\bibitem{VanHandel}
    Ramon van Handel
    \textit{Probability in High Dimensions},
    2016.

%\bibitem{Korner1}
%    T.W. K\"{o}rner,
%    \textit{Measures on Independent Sets, A Quantitative Version of Rudin's Theorem}.

\bibitem{Korner2}
    T.W. K\"{o}rner,
    \textit{Fourier transforms of measures and algebraic relations on their supports}.

%\bibitem{Vershynin}
%    Roman Vershynin,
%    \textit{High dimensional probability},
%    Cambridge Series in Statistical and Probabilistic Mathematics,
%    2018.

\end{thebibliography}

\end{document}
