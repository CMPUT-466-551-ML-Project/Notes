\input{../../style.tex}

\title{Geometric Measure Theory}
\author{Jacob Denson}

\begin{document}

\pagenumbering{gobble}

\maketitle

\tableofcontents

\pagenumbering{arabic}

\chapter{Fractal Dimensions}

The expression of geometric properties of subsets of $\mathbf{R}^d$ requires more than can be expressed using the Lebesgue measure. For instance, curves and surfaces all have measure zero in two and three dimensions respectively, and thus we cannot distinguish them by the Lebesgue measure from any of the other nasty Lebesgue measurable subsets of measure zero. Hausdorff showed that there is a notion of `dimension' of measure zero subsets of $\mathbf{R}^d$ which matches the dimension of corresponding curves and surfaces. Even more interestingly, Hausdorff's theory of dimension gives certain fractal subsets non-integer dimension. It is very useful when studying non-smooth shapes, like fractals, and in many quantitative questions in harmonic analysis.

%Here is the general idea. If $X = [0,1)$ is a unit interval, then $nX = [0,n)$ is the union of $n$ disjoint translates of $[0,1)$. If we instead consider the unit square $X = [0,1) \times [0,1)$, then $nX = [0,n) \times [0,n)$ is the union of $n^2$ disjoint translates of $[0,1)$. If $X$ is a unit cube, the $nX$ is the union of $n^3$ disjoint translates of $[0,1)$, and so on and so forth. Thus, it makes sense to define the dimension of $X$ to be the value $\alpha$ such that $nX$ is the union of $n^\alpha$ disjoint copies of $X$. Note that if $X$ is the Cantor set, then $3X$ is the union of two translates of $X$, so our previous intuition would be willing to say that the Cantor set has `dimension' $\log_3 2 = 0.6309\dots$.

\section{Minkowski Dimension}

The easiest fractal dimension to introduce is Minkowski dimension. If $E$ is a bounded set in $\mathbf{R}^n$, then we can consider the open set $E_\delta$, which is an `$\delta$ thickening' of $E$. We define the \emph{lower} and \emph{upper} Minkowski dimension as
%
\[ \lowminkdim(E) = \liminf_{\delta \to 0} \left( n - \frac{\log|E_\delta|}{\log \delta} \right) \]
%
and
%
\[ \upminkdim(E) = \limsup_{\delta \to 0} \left( n - \frac{\log|E_\delta|}{\log \delta} \right). \]
%
If $\upminkdim(E) = \lowminkdim(E)$, then we refer to this common quantity as the Minkowski dimension $\minkdim(E)$. One can interpret that if $\minkdim(E) = \alpha$, then $|E_\delta| = \delta^{n - \alpha + o(1)}$. This means that for sufficiently small $\delta$, if $\dim_M(E) = \alpha$, then $|E_\delta| = \delta^{n - \alpha + o(1)}$. These notions can also be extended to unbounded sets by considering the supremum over all bounded subsets. For a set $E$, we define
%
\[ \upminkdim(E) = \limsup_{r \to \infty} \left[ \upminkdim(E \cap B(0,r)) \right] \]
%
and
%
\[ \lowminkdim(E) &= \liminf_{r \to \infty} \left[ \lowminkdim(E \cap B(0,r)) \right]. \]
%
The Minkowski dimension $\minkdim(E)$ is defined as the common value of these two functions, if they agree.

\begin{example}
	If $E = B^k \times \{ 0 \}^{n-k}$, where $B^k$ is the $k$ dimensional unit ball, then
	%
	\[ B^k \times \delta B^{n-k} \subset E_\delta \subset (1 + \delta)B^k \times \delta B^{n-k} \]
	%
	which shows that
	%
	\[ \delta^{n-k} \lesssim |E_\delta| \lesssim (1 + \delta)^k \delta^{n-k} \]
	%
	Thus $\minkdim(E) = k$. In particular, $\minkdim(r E) = k$ for all $r > 0$, and so taking $r \to \infty$ shows $\minkdim(\RR^k \times 0^{n-k}) = k$.
\end{example}

\begin{example}
	Let
	%
	\[ C = \left\{ \sum_{i = 1}^\infty a_i/4^i : a_i \in \{ 0, 3 \} \right\} \]
	%
	be a Cantor set. If $1/4^{N+1} \leq \delta \leq 1/4^N$, then
	%
	\[ \left\{ \sum_{i = 1}^\infty a_i/4^i : a_1, \dots, a_{N+1} \in \{ 0, 3 \} \right\} \subset C_\delta \subset \left\{ \sum_{i = 1}^\infty a_i/4^i : a_1, \dots, a_N \in \{ 0, 3 \} \right\}. \]
	%
	The latter set has volume $2^N/4^N = 1/2^N \leq (2\delta)^{1/2}$. The initial set has volume $2^{N+1}/4^{N+1} = 1/2^{N+1} \geq \delta^{1/2}$. Thus $\log |C_\delta| = \log(\delta) / 2 + O(1)$, and so $C$ has Minkowski dimension $1/2$.
\end{example}

\begin{example}
	We can modify the last example slightly, considering
	%
	\[ C = \left\{ \sum_{i = 1}^\infty a_i/4^i : a_i \in \{ 0, 3 \}\ \text{if there is $k$ s.t.}\ (2k)! \leq i \leq (2k+1)! \right\}. \]
	%
	Then $C$ has lower Minkowski dimension $1/2$ and upper Minkowski dimension 1. If one looks at the iterated construction of $C$, one sees that we only dissect $C$ at an incredibly sparse range of scales.
\end{example}

\begin{example}
	Let $S = \{ (x,\sin(1/x)) : 0 < x \leq 1 \}$. Then $S$ has Minkowski dimension $3/2$. Consider a fixed scale $\delta$. For any $x \in (0,1)$, Let $f(x) = \sin(1/x)$. Then $|f'(x)| \leq 1/x^2$, so for any fixed $x_0$, the length of the vertical segment $S_\delta \cap \{ x = x_0 \}$ is at most $2\delta / (x_0 - \delta)^2$. In particular, we may cover $S_\delta \cap [0,1] \times [-1,1]$ by an initial cube $[0, \delta^\alpha] \times [-1,1]$ for $\alpha < 1$, and then an integral over the bound obtained for the lengths of the vertical segments. Thus
	%
	\[ |S_\delta \cap [0,1] \times [-1,1]| \leq 2\delta^\alpha + \int_{\delta^\alpha}^1 \frac{2\delta}{(x_0 - \delta)^2} \lesssim \delta^\alpha + \delta^{1-\alpha}. \]
	%
	Choosing $\alpha = 1/2$ gives $|S_\delta| \lesssim \delta^{1/2}$. But $S_\delta$ certainly contains $[0,\delta^{1/2}] \times [-1,1]$, which gives $|S_\delta| \gtrsim \delta^{1/2}$. In particular, taking limits shows this estimate is enough to conclude $S$ has Minkowski dimension $3/2$.
\end{example}

Many fractals display self similarity properties. For instance, if $C$ is the classical Cantor set, then $3C$ is the union of two translates of $C$. The next lemma thus implies the Minkowski dimension of the Cantor set is $\log_3(2)$.

\begin{theorem}
	If $E$ is compact, $r > 1$, and there is $r$ such that $rE$ is the union of $k$ disjoint translates of $E$, then $\dim_M(E) = \log_r k$.
\end{theorem}
\begin{proof}
	For small $\delta$, $(rE)_\delta$ is the union of $k$ disjoint translates of $E_\delta$, so
	%
	\[ r^d |E_{\delta/r}| = |(rE)_\delta| = k |E_\delta|. \]
	%
	In particular, this means that $|E_{1/r^N}|$ is proportional to $(k/r^d)^N$. But this means that for any $1/r^{N+1} \leq \delta \leq 1/r^N$,
	%
	\[ |E_\delta| \sim (k/r^d)^N \sim (k/r^d)^{-\log_r \delta} = \delta^{d - \log_r k}. \]
	%
	Thus $\dim_M(E) = \log_r k$.
\end{proof}

There are several alternate definitions of Minkowski dimension. Given a bounded set $E$, and $\delta > 0$, we let
%
\begin{itemize}
	\item $N^\text{Ext}_\delta(E)$ denote the minimum number of $\delta$ balls required to cover $E$.
	\item $N^\text{Int}_\delta(E)$ denotes the minimum number of $\delta$ balls with centers in $E$ required to cover $E$.
	\item $N^\text{Pack}_\delta(E)$ is the largest number of disjoint open balls of radius $\delta$ with centers in $E$.
\end{itemize}
%
Given a cover of $E$ by $N$ balls of radius $\delta$, by doubling the radius of the balls, we can cover $E$ by $N$ balls of radius $2\delta$ with centers of $E$. Thus $N^\text{Int}_{2\delta}(E) \leq N^\text{Ext}_\delta(E) \leq N^{\text{Int}}_\delta(E)$. Conversely, if we have a maximal packing by $N$ radius $\delta$ balls, then we can cover $E$ by $N$ radius $2\delta$ balls. Thus $N^\text{Int}_{2\delta}(E) \leq N^\text{Pack}_\delta(E)$. On the other hand, $N^\text{Pack}_\delta(E) \leq |E_\delta|/|\delta B^n| \leq N_\delta^\text{Ext}(E)$, because a packing of balls inside $E$ provides a disjoint subset of balls in $E_\delta$, and if we cover $E$ by $\delta$ balls, then $E_\delta$ is covered by the radius $2\delta$ balls with the same centres. In particular, we have shown that as $\delta \to 0$, all the quantities $\log_{1/\delta} N^*_\delta(E)$ are comparable to one another. Since
%
\[ \delta^n |N_\delta^{\text{Pack}}(E)| \lesssim |E_\delta| \lesssim \delta^n |N_\delta^{\text{Ext}}(E)| \]
%
We find that
%
\[ \underline{\dim}_M(E) = \liminf_{\delta \to 0} \frac{\log N_\delta^*(E)}{\log(1/\delta)}\ \ \ \ \overline{\dim}_M(E) = \limsup_{\delta \to 0} \frac{\log N_\delta^*(E)}{\log(1/\delta)}. \]
%
These definitions are quite useful, because they can be defined for subsets of an arbitrary metric space.

\section{Hausdorff Dimension}

Hausdorff dimension is a more stable version of fractal dimension which is obtained by finding a canonical `$s$ dimensional measure' $H^s$ on $\mathbf{R}^n$ for each $s$, and then setting the dimension of $E$ to be the supremum of $s$ such that $H^s(E) < \infty$. A naive way to construct is to assign a mass $r^s$ to each radius $r$ ball in $\mathbf{R}^n$, and then define
%
\[ H^s_\infty(E) = \inf \left\{ \sum r_k^s : E \subset \bigcup B(x_k,r_k) \right\} \]
%
This is an outer measure, and so Caratheodory's extension theorem gives a $\sigma$ algebra of measurable sets. Unfortunately, not even intervals are measurable with respect to this $\sigma$ algebra, for non-integer values of $s$.

\begin{example}
	Let $s = 1/2$, and let $E = (a,b)$. On one hand, $H^s_\infty(E) \leq [(b-a)/2]^{1/2}$. On the other hand, if $(a,b)$ is covered by balls $B(x_k,r_k)$, then $\sum 2r_k \geq b - a$, so applying the concavity of $x \mapsto x^{1/2}$, we conclude
	%
	\[ \sum r_k^{1/2} \geq \left( \sum r_k \right)^{1/2} \geq \left( \frac{b - a}{2} \right)^{1/2} \]
	%
	Thus $H^s_\infty(E) = [(b-a)/2]^{1/2}$. But now we see that the additivity property begins to breakdown, since $H^{1/2,\infty}[0,1] = 2^{-1/2}$, whereas $H^{1/2,\infty}[0,1/2] = H^{1/2,\infty}[1/2,1] = 1/2$, and so $H^{1/2,\infty}[0,1] < H^{1/2,\infty}[0,1/2] + H^{1/2,\infty}[1/2,1]$.
\end{example}

The reason why intervals fail to be measurable is that $[0,1]$ is most efficiently coverable by a single large ball, rather than covering the set by the two intervals $[0,1/2]$ and $[1/2,1]$. We can fix this by limiting the Hausdorff measure to be the value of the most efficient cover by arbitrarily small balls.

For a subset $E$ of Euclidean space, we define
%
\[ H_\delta^s(E) = \inf \left\{ \sum_{n = 1}^\infty \text{diam}(B_n)^s : E \subset \bigcup_{n = 1}^\infty B_n, \text{diam}(B_n) \leq \delta \right\} \]
%
We then define $H^s(E) = \lim_{\delta \to 0} H_\delta^s(E)$. Then $H^s$ is an exterior measure, and $H^s(E \cup F) = H^s(E) + H^s(F)$ if $d(E,F) > 0$. Thus all Borel sets are measurable with respect to $H^s$, which is certainly more satisfactory than the last definition.

\begin{remark}
	Though not all sets are measurable with respect to $H^s_\infty$. Nonetheless, since the values $H^s_\delta(E)$ increase to the value $H^s(E)$, if $H^s(E) = 0$, then $H^s_\delta(E) = 0$ for all $\delta > 0$. Thus $H^s_\infty(E) = 0$. Conversely, if $H^s_\infty(E) = 0$, and $E$ is compact, then $H^s_\delta(E) = 0$ for all $\delta > 0$. To fix the compactness condition, we known $H^s_\infty(E \cap [-R,R]) = 0$ for all $R$, so $H^s(E \cap [-R,R]) = 0$, and then
	%
	\[ H^s(E) = \lim_{R \to \infty} H^s(E \cap [-R,R]) = 0. \]
	%
	Thus though the $\sigma$ algebra of measurable sets with respect to $H^s$ and $H^s_\infty$ may disagree, the null sets do agree.
\end{remark}

\begin{example}
	Let $s = 0$. Then $H_\delta^0(E) = N_\delta^{\text{Ext}}(E)$, which tends to $\infty$ as $\delta \to 0$ unless $E$ is finite, and then $H_\delta^0(E) \to \# E$. Thus $H^0$ is just the counting measure.
\end{example}

\begin{example}
	Let $s = n$. If $E$ has Lebesgue measure zero, then for any $\varepsilon > 0$, there exists countable many balls $B(x_k,r_k)$ covering $E$ with $\sum r_k^n < \varepsilon$. Then $r_k < \varepsilon^{1/n}$, so $H^n_{\varepsilon^{1/n}}(E) < \varepsilon$. Letting $\varepsilon \to 0$, we conclude $H^n(E) = 0$. Thus $H^n$ is absolutely continuous with respect to the Lebesgue measure. The measure $H^n$ is translation invariant, so $H^n$ is actually a constant multiple of the Lebesgue measure. We let the constant multiple be defined $1/\omega_n$. The value $\omega_n$ can be defined as the volume of a unit ball in $\mathbf{R}^n$, since $H^n(B) = 1$ if $B$ is a unit ball.
\end{example}

The same argument shows that if $V$ is an $m$ dimensional subspace of $\mathbf{R}^n$, then $H^m$, restricted to subsets of $V$, is a constant multiple of the $m$ dimensional Lebesgue measure on $V$. More generally, $H^m$ measures the $m$ dimensional surface area of smooth, $m$ dimensional submanifolds of $\mathbf{R}^n$.

\begin{theorem}
	Let $U$ be an open subset of $\mathbf{R}^d$, and let $\phi: U \to \mathbf{R}^n$ be a smooth immersion. Then for any compact set $E$,
	%
	\[ H^d(\phi(E)) \propto \frac{1}{\omega_d} \int_E J(x)\; dx \]
	%
	where $J(x)$ is the square root of the sums of squares of the $d \times d$ minors of $D\phi(x)$.
\end{theorem}
\begin{proof}
	We may cover $E$ by finitely many open sets $U_1, \dots, U_N$, together with coordinate charts $y_1, \dots, y_N$ such that $(y_k \circ \phi)(x) = (x,f_k(x))$ for some smooth $f_k$, and fix $J_k$ such that for any $x \in U_k$, $|J(x) - J_k| < \varepsilon$. TODO: PROVE REST OF THEOREM.
\end{proof}

\begin{lemma}
	If $t < s$ and $H^t(E) < \infty$, $H^s(E) = 0$, and if $H^s(E) = \infty$, $H^t(E) = \infty$.
\end{lemma}
\begin{proof}
	If, for any cover of $E$ by balls $B(x_k,r_k)$, $\sum r_k^t \leq A$, and $r_k \leq \delta$, then $\sum r_k^s \leq \sum r_k^{s-t} r_k^t \leq \delta^{s-t} A$. Thus $H^s_\delta(E) \leq \delta^{s-t} A $, and taking $\delta \to 0$, we conclude $H^s(E) = 0$. The latter point is just proved by taking contrapositives.
\end{proof}

Thus given any Borel set $E$, there is $s$ such that $H^{s_0}(E) = 0$ for $s_0 < s$, and $H^{s_1}(E) = \infty$ for $s_1 > s$. We refer to $s$ as the Hausdorff dimension of $E$, denoted $\dim_H(E)$.

\begin{example}
	Consider $S = \{ (x,\sin(1/x)) : 0 < x \leq 1 \}$. Then for each $\delta > 0$, the set $S \cap [\delta,1] \times \mathbf{R}$ is the image of a smooth curve, and therefore has Hausdorff dimension $1$. Thus for any $\varepsilon > 0$, $H^{1 + \varepsilon}(S \cap [\delta,1] \times \mathbf{R}) = 0$. But then taking limits as $\delta \to 0$, we conclude $H^{1+\varepsilon}(S) = 0$. Since $H^1(S) > 0$, this shows $S$ has Hausdorff dimension 1. Compare this to the Minkowski dimension $3/2$ result we obtained previously.
\end{example}

An easy way to compare the approaches to fractal dimension given by Minkowski and Hausdorff dimension is that Minkowski dimension measures the efficiency of covers of a set at a fixed scale, whereas Hausdorff dimension measures the efficiency of covers of a set at various, small scales.

\section{Energy Integrals and Frostman's Lemma}

By taking particular covers of a set, it is easy to upper bound the Hausdorff dimension of a set. On the other hand, finding a lower bound is a little more tricky. One method to finding to lower bound is constructing a measure on our set with a certain `measure' property. We say a finite Borel measure $\mu$ is a Frostman measure with dimension $\alpha$ if $\mu(B(x,r)) \lesssim r^\alpha$. For a set $E$, we let $M(E)$ denote all Borel measures supported on $E$.

\begin{theorem}[Frostman's Lemma]
	Let $0 \leq s \leq n$. For a compact set $E$, the Hausdorff dimension $H^\alpha(E) > 0$ if and only if there is an $\alpha$ dimensional Frostman measure supported on $E$. In particular
	%
	\[ \hausdim(E) = \sup \{ \alpha \geq 0: \text{there is an $\alpha$ dimensional measure}\ \mu \in M(E) \} \]
\end{theorem}
\begin{proof}
	Suppose $H^s(E) > 0$. Without loss of generality, assume $E \subset [0,1)^n$. We work dyadically. For each $k$, let $\mathcal{Q}_k$ denote the set of all cubes of the form $[a,a+1/2^k]$, with $a \in \mathbf{Z}/2^k$. A cube in $\bigcup \mathcal{Q}_k$ is known as a dyadic cube. We can define the $s$ dimensional dyadic Hausdorff exterior measure $H^s_{\Delta,\delta}$ as the exterior measure obtained by restricting to coverings by Dyadic cubes with sidelength bounded by $\delta$, and a cube in $\mathcal{Q}_k$ is assigned mass $1/2^{sk}$. The measure $H^s_\Delta$ is then obtained by taking limits. It is not difficult to show that there are universal constants such that $H^s_\Delta$ is comparable to $H^s$ for all $s$. We now construct a subadditive premeasure $\mu^+$ by defining $\mu^+(Q) = H^s_{\Delta,2^{-k}}(E \cap Q)$ for each dyadic $Q$. Then $\mu^+([0,1)^n) \geq H^s_\Delta(E) > 0$, and we can apply the Caratheodory extension theorem to extend the measure to all Borel sets (since all open sets are the countable union of dyadic cubes). Note that if $Q \in \mathcal{Q}_k$, then covering $E \cap Q$ by $Q$ gives $\mu^+(Q) \leq 1/2^{-sk}$. But we can find an additive measure $\mu$ on dyadic cubes such that $\mu([0,1)^n) = \mu^+([0,1)^n)$, and $\mu(Q) = \sum_{Q' \subset Q} \mu(Q')$ whenever $Q$ is dyadic, and $Q'$ ranges over dyadic cubes with half the sidelength of $Q$. This can be done by working downward `greedily'. And the Caratheodory extension theorem then gives that $\mu$ is the required Frostman lemma.

	Conversely, if an $s$ dimensional measure $\mu$ exists supported on $E$, then $\mu$ is absolutely continuous with respect to $H^s$, and therefore there is a locally integrable $f$ such that
	%
	\[ \mu(E) = \int f(x)\; dH^s(x) \]
\end{proof}

A fundamental concept in the lower bounding of dimensions is the $\alpha$ energy of a Borel measure $\mu$, which is
%
\[ I_\alpha(\mu) = \int \int |x-y|^{-\alpha}\; d\mu(x) d\mu(y) = \int k_s * \mu\; d\mu \]
%
where $k_s(x) = |x|^{-\alpha}$, for $x \in \mathbf{R}^d$. If $0 < \beta < \alpha$, and $\mu$ has compact support. Integrating Frostman's lemma gives that for a Borel $E$,
%
\[ \hausdim(E) = \sup \{ \alpha: \text{there is}\ \mu \in M(A)\ \text{such that}\ I_\alpha(\mu) < \infty \} \]
%
The $\alpha$ dimensional energy then
%
\[ I_\alpha(\mu) \propto_{n,\alpha} \int_{\mathbf{R}^d} |\widehat{\mu}(\xi)|^2 |\xi|^{\alpha-d}\; d\xi \]
%
Thus
%
\[ \hausdim(E) = \sup \left\{ \text{there is}\ \mu \in M(A)\ \text{such that}\ \int |\widehat{\mu}(x)|^2 |x|^{\alpha-d}\; dx < \infty \right\} \]

\section{Projection Theorems}

Recall that the Grassmanian manifold $G(n,m)$ is a space parameterizing the family of $m$ dimensional hyperplanes in $\mathbf{R}^n$. The orthogonal group $O(n)$ acts on $G(n,m)$, and we let $\gamma_{nm}$ denote the resultant Borel probablity measure. We then have Marstrand's projection theorem

\begin{theorem}[Marstrand]
	s
\end{theorem}






\chapter{Fourier Dimension}

The {\bf Fourier dimension} of a Borel set $E$ is
%
\[ \dim_{\mathbf{F}}(E) = \sup \{s : \text{there is}\ \mu \in M(E)\ \text{s.t.}\ |\widehat{\mu}(\xi)| \leq |\xi|^{-s/2}  \} \]
%
This implies the energy integrals of the right dimension to converge, implying $\dim_{\mathbf{F}}(E) \leq \hausdim(E)$. A set is {\bf Salem} if $\hausdim(E) = \dim_{\mathbf{F}}(E)$.

\section{Dimensions of Brownian Motion}

Consider a one dimensional Brownian motion $W$. Then almost surely, for each $0 < \alpha < 1/2$, $W$ is locally $\alpha$ H\"{o}lder continuous. For a fixed Borel set $E$, The bound
%
\[ \hausdim(W(E)) \leq \frac{1}{\alpha} \hausdim(E) \]
%
then holds for almost every path of the motion. Taking $\alpha \uparrow 1/2$, we find the $\hausdim(W(E)) \leq 2 \hausdim(E)$. In this lecture we focus on a converse.

\begin{theorem}[Mckean, 1955]
	Let $A \subset [0,\infty)$ be Borel. Then $\hausdim(W(E)) = 2\hausdim(E) \wedge 1$ almost surely.
\end{theorem}

More generally,

\begin{theorem}[Kaufman's Dimension Doubling Theorem]
	Let $B$ be a Brownian motion in $\mathbf{R}^d$, for $d \geq 2$, then almost surely, for every Borel set $E$,
	%
	\[\hausdim(B(E)) = 2\hausdim(E) \]
\end{theorem}

Note that the almost surely condition is now independent of $E$, so we can apply this theorem to random sets. If $Z = \{ t \geq 0: B_t = 0 \}$ is the random zero set of a path of Brownian motion, and $d \geq 2$, then almost surely we find $\hausdim(E) = 0$. For $d = 1$, the zero may not even be zero dimensional, so we know that Mckean's theorem cannot take out the almost surely over all subsets. We will follow Kahane's 1966 proof of Mckean's result. Consider the following lemma.

\begin{lemma}
	If $\mu$ is an $s$ dimensional measure supported on $[0,\infty)$, then almost surely, for all $|\xi| > 2$,
	%
	\[ |\widehat{\mu_W}(\xi)| \lesssim \frac{(\log |\xi|)^{1/2}}{|\xi|^{-s}} \]
	%
	where $\mu_W$ is the random pushforward measure of $\mu$ by the random path $W$, and the constant in the inequality is random.
\end{lemma}
\begin{proof}
	
\end{proof}

If $E$ was $s$ dimensional, we could find an $s$ dimensional probability measure on $E$. Then by Kahane's lemma, we compute, almost surely, that
%
\[ I_s(\mu_W) \lesssim O(1) + \int_{|\xi| > 2} |\widehat{\mu_W}(\xi)|^2 |\xi|^{s-1} \lesssim O(1) + \int_{-\infty}^\infty \frac{\log |x|}{|x|^{-1-s}} < \infty \]
%
so $\mu_W$ is $s$ dimensional, and so $\hausdim(W(E)) \geq s$. Note that we actually proved something even stronger. The inequality above implies that $\dim_{\mathbf{F}}(W(E)) \geq s$ almost surely, so $W(E)$ is a Salem set almost surely. In particular, Salem sets exist. An alternate proof is to calculate, using Fubini's theorem, we calculate that if $Z \sim N(0,1)$, then provided $r < 2s < 1$,
	%
	\[ \mathbf{E}[I_r(\mu_W)] = \int_{-\infty}^\infty \mathbf{E} \left( \frac{1}{|W_t - W_s|^r} \right)\; dr = \left( \int_{-\infty}^\infty \frac{dt\; ds}{|t-s|^{r/2}} \right) \mathbf{E} \left( \frac{1}{|Z|^r} \right) < \infty \]
	%
	This doesn't require the $K$ lemma at all.

\chapter{Properties of Generic Sets}

In modern analysis, a popular technique is to establish certain properties that hold for a `generic point' lying in some space. For instance, if $X$ is a measure space, we can think of a property holding `generically' if the set of points $x$ upon which that property holds forms a set of measure zero. However, it is often the case that one wants to study the generic behaviour of spaces which have no natural measure theoretic structure. These spaces do have a natural metric space structure, however, and so it suffices to establish a suitably notice of a property holding `generically' in a topological space. This is provided by considering a property to hold `generically' if its holds except on a set of points which are of `first category'.

If $X$ is a topological space, we say $E \subset X$ is \emph{nowhere dense} if $\overline{E}$ has non-empty interior. We say $E \subset X$ is of \emph{first category} if it is the countable union of nowhere dense sets. A set $E$ is of \emph{second category} if it is not of first category, and a property on $X$ holds \emph{quasi-always} if is true except on a set of first category. We recall that the \emph{Baire category theorem} says that, in a complete metric space, or a locally compact topological space, the complement of sets of first category are dense, which supports our notion that such sets are generic.

Now let $X$ be a metric space. For $E \subset X$, and $\varepsilon > 0$, we let
%
\[ E_\varepsilon = \{ x \in E: \text{there is $y \in E$ such that $d(x,y) < \varepsilon$} \}. \]
%
Now let $\mathcal{E}$, or $\mathcal{E}(X)$, be the family of all compact subsets of $X$. Given two compact sets $E, F \in \mathcal{E}$, we can define the \emph{Hausdorff distance}
%
\[ d_H(E,F) = \inf \{ \varepsilon > 0: E \subset F_\varepsilon\ \text{and}\ F \subset E_\varepsilon \}. \]
%
It is easy to see that since $E$ and $F$ are compact, $d_H(E,F) < \infty$. Moreover, since $\overline{E} = \bigcap_{\varepsilon > 0} E_\varepsilon$, and the fact that $E$ and $F$ are closed sets, $d_H(E,F) = 0$ if and only if $E = F$. If $E \subset F_\varepsilon$, and $F \subset G_\delta$, then $E \subset G_{\varepsilon + \delta}$, which is a manifestation of the triangle inequality for the Hausdorff distance. Thus $\mathcal{E}$ has the natural structure of a metric space.

\begin{theorem}
	If $X$ is complete, $\mathcal{E}$ is complete.
\end{theorem}
\begin{proof}
	Note that if $E = \lim_{i \to \infty} E_i$, and if $\{ x_i \}$ is a sequence of points with $x_i \in E_i$ for each $i$, and $\lim x_i = x$ for some $x \in X$, then we actually have $x \in E$. This is because we can find points $\{ y_i \} \in E$ with $d(x_i,y_i) \leq d(E,E_i)$, hence $d(y_i,x) \leq d(y_i,x_i) + d(x_i,x) \to 0$, so $y_i \to x$, and hence $x \in E$ since $E$ is closed. It will be a consequence of this theorem that $E$ consists of \emph{precisely} the limit points of the form above.

	If $\{ E_i \}$ is a Cauchy sequence in $\mathcal{E}$, we let $E$ denote the family of limits of Cauchy sequences $\{ x_i \}$ with $x_i \in E_i$ for each $i$. If $\{ x_{i_j} \}$ is a Cauchy subsequence with $x_{i_j} \in E_{i_j}$ for each $j$, then we can extend it to a Cauchy sequence $\{ x_i \}$ with $x_i \in E_i$ for each $i$, so without loss of generality, we may assume by thinning to a subsequence such that $d_H(E_i,E_{i+1}) < 1/2^{i+1}$. In this case, it is easy to see that $E = \bigcap_{i = 1}^\infty (E_i)_{1/2^i}$. It is certainly true that $\bigcap_{i = 1}^\infty (E_i)^{1/2^i} \subset E$. Conversely, if $\{ x_i \}$ is a Cauchy sequence with $x_i \in E_i$ for each $i$, and if $x = \lim_{i \to \infty} x_i$, then for each $i$, there is $\varepsilon_i > 0$, such that $d_H(E_i,E_{i+j}) + \varepsilon_i < 1/2^i$. If we fix $j > i$ large enough that $d(x_j,x) < \varepsilon_i$, then we can find $y_i \in E_i$ with $d(y_i,x_j) < 1/2^i - \varepsilon_i$, hence $d(y_i,x) < 1/2^i$. Since $i$ was arbitrary, $x \in \bigcap_{i = 1}^\infty (E_i)_{1/2^i}$. The family of sets $\{ (E_i)_{1/2^i} \}$ is nested. Moreover, if $x_i \in E_i$, then a sequence $\{ x_j \}$ extending $x_i$ with $x_j \in E_j$ for each $j$, and $d(x_j,x_{j+1}) < 1/2^{j+1}$, which is therefore Cauchy, and if $x = \lim x_i$ is in $E$, $d(x,x_i) < 1/2^i$. Thus $E_i \subset E_{1/2^i}$, and since $E$ is obviously a subset of $E_{1/2^i}$, $E_{1/2^i} \subset (E_i)_{1/2^i}$. Thus $d_H(E,E_i) \leq 1/2^i$. Our proof will be finished if we show $E$ is a compact set. Let us now show $E$ is a compact set. Let $A \subset E$ be an infinite subset of $E$. We define a nested family of infinite sets $\{ A_i \}$ inductively. by first defining $A_i = A_0$. Then, given $A_i$, there are finitely many balls $\{ B(x_1,1/2^{i+1}), \dots, B(x_N,1/2^{i+1})$ which cover $E_{i+1}$, and then $\{ B(x_1,1/2^i), \dots, B(x_N,1/2^i) \}$ is a cover of $(E_{i+1})_{1/2^{i+1}}$, and therefore a cover of $A_i$. Thus there is some $j$ such that $B(x_j,1/2^i) \cap A_i$ contains infinitely many points, and we set $A_{i+1} = B(x_j,1/2^i) \cap A_i$. Clearly this family of sets has a limit point, so $A$ has a limit point. This shows $E$ is compact.
\end{proof}

The proof of this theorem gives the following corollary.

\begin{corollary}
	If $\{ E_i \}$ converges to $E$ in the Hausdorff distance, then
	%
	\[ E = \{ x \in X : \text{there are}\ x_i \in E_i\ \text{s.t.}\ x = \lim x_i \}. \]
\end{corollary}

Since we have assigned a complete metric space structure to the family of compact sets in a metric space, it is now natural to discuss whether a property holds for `quasi-all' compact subsets of a space.

\begin{remark}
	There is an alternate family of sets which can be used with Baire category techniques. If $X$ is a measure space, let $\mathcal{E}$ denote the family of all finite measure subsets of $X$. We could define a metric, by letting the distance between two sets $E,F \in \mathcal{E}$ by equal to
	%
	\[ d(E,F) = |E \bigtriangleup F| = |E - F| + |F - E|. \]
	%
	Then $d(E,F) = 0$ if and only if $E$ and $F$ differ by a set of measure zero. The map $E \mapsto \mathbf{I}_E$ embeds $\mathcal{E}$ in $L^1(X)$. If $\mathcal{I}_{E_i}$ is a sequence of sets and $\| \mathbf{I}_{E_i} - f \|_{L^1(X)} \to 0$, then a simple approximation argument can show $\{ x \in X: f(x) \not \in \{ 0, 1 \} \}$ is a set of measure zero, so there exists a finite measure set $F$ such that $\mathbf{I}_F$ equals $f$ almost everywhere. Thus $\mathcal{E}$ is a complete metric space. However, most properties of sets which can be tested generically in $\mathcal{E}$ also tend to extend to generic properties in $L^1(X)$, and Baire-category arguments tend to be extendable to $L^1(X)$ in such a way that we can apply one of the three main principles of functional analysis may be applied.
\end{remark}

We begin with a basic, natural example, which shows that if $X$ is a metric space with no isolated points, then quasi-all compact subsets of $X$ have no isolated points.

\begin{lemma}
	Fix $\delta > 0$ and $0 < \varepsilon < \delta/3$. If $E,F \in \mathcal{E}$, $d_H(E,F) < \varepsilon$, and there is $x \in E$ such that $B(x,\delta) \cap E = \{ x \}$, then there is $y \in F$ such that $d(x,y) < \varepsilon$, and moreover, for any such $y$,
	%
	\[ B(y,\delta - 3\varepsilon) \cap F \subset B(x,\varepsilon) \subset B(y,2\varepsilon). \]
\end{lemma}
\begin{proof}
	There must certainly exists $y \in F$ with $d(x,y) < \varepsilon$. If $y' \in F$ satisfies $d(y,y') < \delta - 3\varepsilon$, then because $d_H(E,F) < \varepsilon$, there must be $x' \in E$ such that $d(x',y') < \varepsilon$. But the triangle inequality implies that $d(x,x') < 2\varepsilon < \delta$, so $x = x'$, and thus $d(y,y') < 2\varepsilon$.
\end{proof}

\begin{theorem}
	Let $X$ be a metric space with no isolated points. Then quasi-all compact subsets of $X$ have no isolated points.
\end{theorem}
\begin{proof}
	For each $\delta > 0$, let $A_\delta = \{ E \in \mathcal{E}: \text{there is $x \in E$ such that}\ B(x,\delta) \cap E = \{ x \} \}$. Our goal is to show $A_\delta$ is closed and nowhere dense. First, we show $A_\delta$ is closed. If $\{ E_i \}$ is a sequence in $A_\delta$ converging to some $E \in \mathcal{E}$. Pick $x_i \in E_i$ for each $i$ such that $B(x_i,\delta) \cap E_i = \{ x_i \}$. Without loss of generality, assume that $d(E_i, E) < \delta / 3$, and we can choose a decreasing sequence $\varepsilon_i < \delta / 3$ such that $d_H(E_i,E) < \varepsilon_i$. Then for each $i$, we can find $y_i \in E$ such that $d(x_i,y_i) < \varepsilon_i$ and $B(y_i,\delta - 3 \varepsilon_i) \cap F \subset B(y_i,2\varepsilon_i)$. Since $F$ is compact, we can assume $\{ y_i \}$ converges to some point $y$. But if $d(y_i,y) < \varepsilon'$ and $B(y_i,\delta - 3\varepsilon) \cap F \subset B(y_i,2\varepsilon)$, then $B(y,\delta-3\varepsilon - \varepsilon') \subset B(y,2\varepsilon + \varepsilon')$. Taking $i \to \infty$, and thus $\varepsilon, \varepsilon' \to 0$, we conclude that $B(y,\delta) = \{ y \}$. Thus $E \in A_\delta$. It is easy to show $A_\delta$ is nowhere dense. If $E \in A_\delta$, it can only have finitely many elements satsifying the property above by compactness, and we can always add a single point within a $\varepsilon$ neighbourhood of each such point to find $F \not \in A_\delta$ with $d_H(E,F) < \varepsilon$. Thus $\bigcup_{\delta > 0} A_\delta = \bigcup_{n = 1}^\infty A_{1/n}$ is a set of first category, and it's complement is the set of all compact sets with no isolated points.
\end{proof}

\section{Kronecker Sets}

Let us now also discuss an application to harmonic analysis on $\mathbf{T} = \mathbf{R}/\mathbf{Z}$. Recall that distinct values $x_1, \dots, x_n \in \mathbf{T}$ are \emph{independent} if for any $m_1, \dots, m_n \in \ZZ$, $m_1 x_1 + \dots + m_n x_n = 0$ only if $m_1, \dots, m_n = 0$. It is a consequence of the classical theorem of Kronecker and Weyl that if $x_1, \dots, x_n \in \mathbf{T}$ are independant, then for any values $a_1, \dots, a_n \in \CC$ with $|a_i| = 1$ for all $i$, and for any $\varepsilon > 0$, there exists an integer $N$ such that $|\exp(2 \pi Nix_i) - a_i| < \varepsilon$ for all $i \in \{ 1, \dots, n \}$. We wish to try and understand this result for infinite families of sets. So we define $E \subset \mathbf{T}$ to be \emph{independent} if all finite subsets of $E$ are independent, and \emph{Kronecker} if for any $f \in C(\mathbf{T})$ with $|f(x)| = 1$ for all $x \in \mathbf{T}$, and for any $\varepsilon > 0$, there exists $N$ such that $|\exp(2 \pi Nix) - f(x)| < \varepsilon$ for all $x \in E$.

\begin{lemma}
	If $E$ is a Kronecker set, then $E$ is independant.
\end{lemma}
\begin{proof}
	If $m_1 x_1 + \dots + m_n x_n = 0$, for distinct $x_i$, then for any $N$,
	%
	\[ \exp(2\pi m_1 N x_1) \dots \exp(2\pi m_n N x_n) = 1. \]
	%
	If $|m_1| + \dots + |m_n| = M$, and if we choose $f \in C(\mathbf{T})$ such that $f(x_k) = \exp(i \pi / m_k n)$ for each $k$, and if $N$ is chosen such that $|f(x_k) - \exp(2 \pi N i x_i)| < 1/M$, then
	%
	\begin{align*}
		2 &= |1 - (-1)|\\
		&= \left| \prod_{k = 1}^n \exp(2 \pi N i x_k)^{m_k} - \prod_{k = 1}^n \exp(i \pi / m_k n)^{m_k} \right|\\
		&\leq \sum_{k = 1}^n |m_k| |\exp(2 \pi N i x_k) - \exp(i \pi / m_k n)| \leq 1,
	\end{align*}
	%
	which gives a contradiction.
\end{proof}

\begin{remark}
	The converse, unfortunately, is not true. There are independant sets which are not Kronecker.
\end{remark}

It is a general heuristic that a generic compact subset of a metric space is as `thin as possible'. Kronecker sets are very thin from the perspective of harmonic analysis, and so we expect quasi-all compact subsets of $\TT$ are Kronecker sets. To prove this statement, we note that the family of all functions $f \in C(\TT)$ with $|f(x)| = 1$ for all $x \in \TT$ is separable, and if $\{ f_i \}$ is a countable dense set, then $E$ is Kronecker if and only if each of the functions $f_i$ is arbitrarily approximable by a character on $\TT$.

\begin{theorem}
	Quasi-all compact subsets of $\mathbf{T}$ are Kronecker.
\end{theorem}
\begin{proof}
	For each function $f \in C(\mathbf{T})$ with $|f(x)| = 1$ for all $x \in \mathbf{T}$, let $A(f,\varepsilon)$ be the family of all sets $E$ such that there exists an integer $N$ such that $|f(x) - \exp(2 \pi i N x)| < \varepsilon$ for each $x \in E$. We claim $A(f,\varepsilon)$ is a dense, open subset of $\mathcal{E}$. If $E$ is fixed, since $E$ is compact and $f$ is continuous, there is $\delta > 0$ such that $|f(x) - \exp(2 \pi i N x)| < \varepsilon$ for each $x \in E_\delta$. But this implies that $F \in A(f,\varepsilon)$ for each $F$ with $d_H(E,F) < \delta$. Thus $A(f,\varepsilon)$ is open. If $\{ f_i \}$ is a dense family of continuous functions in the $L^\infty$ norm, then $\bigcap_{i = 1}^\infty \bigcap_{n = 1}^\infty A(f_i,1/n)$ is the family of all Kronecker sets. Hence to complete our proof it suffices to show $A(f,\varepsilon)$ is open and dense for any $f \in C(\mathbf{T})$ and $\varepsilon > 0$.

	To show density, let $E$ be an arbitrary set. Since $f$ is continuous, it is actually uniformly continuous, so we can find $\delta$ such that if $|x - y| < \delta$, then $|f(x) - f(y)| < \sqrt{2}$. This forces the values of $f$ to lie on a particular half of the circle over any $\delta$ interval. Thus if $N$ is a large integer such that $2/N < \delta$, then $\{ x \in \mathbf{T}: \exp(2 \pi i N x) = f(x) \}$ contains a point in any length $2/N$ interval of $\mathbf{T}$. In particular, this means that if
	%
	\[ F = \{ x \in E_{2/N} : \exp(2 \pi i N x) = f(x) \}, \]
	%
	then $d_H(F,E) < 2/N$ and $F \in A(f,\varepsilon)$ for all $\varepsilon > 0$. Since $N$ is arbitrary, $A(f,\varepsilon)$ is dense.
\end{proof}

This theorem also even holds under more algebraically restricted circumstances. We note that
%
\[ \{ (E_1,E_2) \in \mathcal{E}^2: E_1 + E_2 = \mathbf{T} \} \]
%
is a closed subset of $\mathcal{E}^2$, and is therefore complete. We shall show that quasi-all elements of this set are pairs of Kronecker sets.

\begin{theorem}
	Quasi-all $(E_1,E_2) \in \mathcal{E}^2$ with $E_1 + E_2 = \mathbf{T}$ are Kronecker sets.
\end{theorem}
\begin{proof}
	For each $f$, $\varepsilon > 0$, and $i \in \{ 0, 1 \}$, let $A(f,\varepsilon,i)$ be the family of all pairs of sets $(E_1, E_2)$ with $E_1 + E_2 = \mathbf{T}$ for which there exists an integer $N$ such that for each  $x \in E_i$, $|f(x) - \exp(2 \pi i N x)| < \varepsilon$. Then
	%
	\[ \bigcap_{i \in \{ 0, 1 \}} \bigcap_{j = 1}^\infty \bigcap_{k = 1}^\infty A(f_j,1/k,i) \]
	%
	is the family of all pairs $(E_1,E_2)$ where $E_1 + E_2 = \mathbf{T}$ and $E_1$ and $E_2$ are Kronecker. Thus it suffices to show $A(f,\varepsilon,i)$ is open and dense for each $f$, $i$, and $\varepsilon > 0$. It is easy to see that $A(f,\varepsilon,i)$ is open, as in the last proof. Without loss of generality, we can assume $i = 1$. So fix $\delta > 0$, and consider the sets $\widetilde{E_i} = (E_i)_{\delta/2}$. Then if $d(E_1,F) < \delta/4$, $F + \tilde{E_2} = \mathbf{T}$. Thus choosing $F$ as in the last theorem gives a pair $(F,\tilde{E_2})$ within a $\delta$ neighbourhood of $(E_1,E_2)$. Thus $A(f,\varepsilon,i)$ is open and dense, which proves the theorem.
\end{proof}

\section{Besicovitch Sets}

We can also use Baire category techniques to study the generic behaviour of Besicovitch sets, subsets of the plane containing a unit line segments in each direction. For each $a,b \in [-2,2]$, we let $l_{ab}$ be the line segment connecting $(a,0)$ to $(b,1)$. We let $\mathcal{F}$ consist of the family of all compact subsets $E$ of $[-2,2] \times [0,1]$ which are a union of line segments of the form $l_{ab}$, and such that for each $\nu \in [-1,1]$, there exists $a \in [-2,2]$ such that $l_{a(a+\nu)} \subset \mathcal{F}$. Such a set contains a unit line segment from any angle in a 45 degree arc, and so two copies of such a set form a Besicovitch set.

\begin{lemma}
	$\mathcal{F}$ is a closed subset of the family $\mathcal{E}$ of all compact subsets of $[-2,2] \times [0,1]$.
\end{lemma}
\begin{proof}
	Suppose $E = \lim_{i \to \infty} E_i$, with $E_i \in \mathcal{F}$ for all $i$. We begin by showing $E$ is a union of line segments. Suppose that $x \in E$. Then there are points $x_i \in E_i$ for each $i$ such that $x = \lim x_i$. Moreover, we can find pairs $a_i$ and $b_i$ such that $x_i \in l_{a_ib_i}$. Since $[-2,2]$ is compact, we can assume without loss of generality that $a_i$ and $b_i$ are convergent sequences to values $a$ and $b$. But this means that $l_{a_ib_i}$ converges in the Hausdorff metric to $l_{ab}$, and thus $x \in l_{ab}$. Moreover, $l_{ab} \subset E$. Thus $E$ is a union of lines. Similar techniques can be used to show $E$ contains a line segment corresponding to each $\nu \in [-1,1]$.
 \end{proof}

\begin{theorem}
	$\mathcal{F}$ is a closed subset of the family $\mathcal{E}$ of all compact subsets of $[-2,2] \times [0,1]$, and quasi-all elements of $\mathcal{F}$ have Lebesgue measure zero.
\end{theorem}
\begin{proof}
	We show the stronger statement that quasi-all elements $E$ of $\mathcal{F}$ are such that, for all $y \in [0,1]$, $E \cap (\RR \times \{ y \})$ has length zero (with respect to the Hausdorff measure), from which the general statement follows by Fubini's theorem. For each interval $I \subset [0,1]$ with length $\varepsilon$, we set $A(I)$ to be the set of all compact sets $E \in \mathcal{F}$ such that, for each $y \in I$, $E \cap [-2,2] \times \{ y \}$ has length less than $100 \varepsilon$. The set
	%
	\[ \bigcap_{n = 1}^\infty \bigcap_{k = 0}^{n-1} A([k/n,(k+1)/n]) \]
	%
	is the class of sets whose slices have length zero, so it suffices to show $A(I)$ is open and dense for each interval $I$. It is obvious that the family of such sets is open, since if $E \in A(I)$, there exists a sufficiently small $\delta$ such that $E_\delta \in A(I)$, and so if $d_H(E,F) < \delta$, $F \in A(I)$. Thus we must concentrate on showing $A(I)$ is dense in $\mathcal{F}$. So consider a set $E \in \mathcal{F}$, and fix a large integer $N > 4$, defining $\delta = 1/N$. If $E = \bigcup_\alpha l_{a_\alpha b_\alpha}$, and we define $x_\alpha = a_\alpha + 2\delta$ and $y_\alpha = b_\alpha + 2\delta$ if $a_\alpha \leq -1/2$, and $x_\alpha = a_\alpha - 2\delta$ and $y_\alpha = b_\alpha - 2\delta$ if $a_\alpha > -1/2$. Then $E' = \bigcup_\alpha l_{x_\alpha y_\alpha}$ is an element of $\mathcal{F}$, a subset of $[-2+\delta,2-\delta] \times \{ y \}$, and $d(E,E') \leq 2\delta$. Thus to prove density, it suffices to show that given $E \in \mathcal{F}$ which is also a subset of $[-2+2\delta,2-2\delta] \times \{ y \}$, we can find $F \in A(I)$ with $d_H(E,F) \lesssim \delta$. We begin by finding $\{ a_1, \dots, a_N \}$ such that $l_{a_k(a_k + k/N)}$ for each $k \in \{ -N, \dots, N \}$. Fix a point $u_k \in l_{a_k(a_k + k/N)} \cap ([-2,2] \times I)$, and consider the family of all lines through $u_k$ which lie in a $\delta$ thickening of $l_{a_k(a_k + k/N)}$. This set has length at most $\delta$ on each slice of $[-2,2] \times I$, and contains a line $l_{x(x + \nu)}$ for each $\nu \in [(k-1)/N,(k+1)/N]$. The union $G$ of such lines lies in $\mathcal{F}$, and is a subset of the $\delta$ thickening of $E$. If we consider a finite union of lines $H$ such that $d_H(H,E) < \delta$, then $G \cup H \in A(I)$ and $d(H,E) < \delta$.
\end{proof}

\section{Independent Sets With Sharp Fourier Decay}

We recall that if $E \subset \TT$ has Fourier dimension exceeding $2/n$, and we consider $n$ integers $m_1, \dots, m_n \in \ZZ$, then $m_1 E + \dots + m_n E$ contains a non-empty interval. It follows that by a slight modification of these integers, one can find $m_1, \dots, m_n \in \ZZ$ and distinct $x_1, \dots, x_n \in E$ such that
%
\begin{equation} \label{linearEquation}
	m_1 x_1 + \dots + m_N x_N = 0.
\end{equation}
%
In particular, this implies that if $\mu$ is supported on an independent set, then for any $\alpha > 0$,
%
\[ \sup_{n \neq 0} \widehat{\mu}(n) |n|^\alpha = \infty. \]
%
In this section, we address the tightness of this result. In particular, we prove the following results:
%
\begin{itemize}
	\item We use Baire category methods to construct probability measures $\mu$ with Fourier dimension $1/n$ supported on sets containing no solutions to \eqref{linearEquation} for any $m_1, \dots, m_n \in \ZZ$. A slightly more complicated argument constructs measures with Fourier dimension $1/(n-1)$. This result is far from tight, and improving this bound remains an open question.

	\item Let $\{ A(k) : k \neq 0 \}$ be any sequence of positive scalars such that for each $\alpha > 0$,
	%
	\[ \lim_{|k| \to \infty} |A(k)| |k|^\alpha = \infty. \]
	%
	Then there exists a probability measure $\mu$ with independent support, but for each nonzero $k \in \ZZ$, $|\widehat{\mu}(k)| \leq A(k)$.
\end{itemize}

Since we employ Baire category methods, our theorem involves finding an appropriate complete metric space on which to study generic behaviour. Given a particular sequence $\{ A(k) : k \neq 0 \}$, we extend the definition by setting $A(0) = 1$. We then let $M(A)$ be the family of all finite measures $\mu \in M(\TT)$ such that
%
\[ \| \mu \|_A = \sup_{n \neq 0} \frac{|\widehat{\mu}(n)|}{|A(n)|} < \infty. \]
%
The family of all such measures forms a vector space, and in particular, a Banach space under the norm $\| \cdot \|_A$. To see this, we note that if $\{ \mu_i \}$ is a sequence in this space, then $\mu_i(\TT) = \widehat{\mu_i}(0)$ is uniformly bounded, so by thinning the seqence, there exists a finite measure $\mu \in M(\TT)$ such that $\{ \mu_i \}$ converges weakly to $\mu$. Thus the Fourier coefficients of the sequence $\{ \mu_i \}$ converge pointwise to $\mu$, and since $\mu_i$ is Cauchy in the norm on $M(A)$, this implies that $\mu \in M(A)$, and $\| \mu_i - \mu \|_A \to 0$.

\begin{remark}
	We have shown that if $\mu_i \to \mu$ in $M(A)$, then $\mu_i$ converges weakly to $\mu$. In particular, this means the set $P(A)$ of finite probability measures in $M(A)$ is a closed, convex subset of $M(A)$, since $P(A)$ can be described as the family of all measures $\mu$ such that
	%
	\[ \int_{\mathbf{T}} d\mu = 1, \]
	%
	and for any non-negative $f \in C(\TT)$, $\int f d\mu \geq 0$.
\end{remark}

\begin{remark}
	The above definition works for any sequence $\{ A(k) \}$. Nonetheless, we will often assume in the following discussion that there exists $\alpha > 0$ such that
	%
	\[ A(k) \gtrsim |k|^{-\alpha}, \]
	%
	so that $C^\infty(\TT) \subset M(A)$, since such functions have rapid Fourier decay.
\end{remark}

Convergence of measures in $M(A)$ does not imply enough information about how similar the supports of these measures are. Since we would like to use Baire category arguments to infer information about the supports of measures, the norm on $M(A)$ therefore must be augmented. We might want to define a metric on $M(A)$ by setting
%
\[ d(\mu,\nu) = \| \mu - \nu \|_A + d_H(\text{supp}(\mu), \text{supp}(\nu)), \]
%
so that we may control both Fourier coefficients and geometric information about the support of a measure. But unfortunately, this metric is not necessarily complete.

\begin{example}
	Fix an interval $I \subset \TT$, and pick non-negative functions $\phi, \eta \in C^\infty(\TT)$ such that $\text{supp}(\phi) \cap I = \emptyset$, and $I \subset \text{supp}(\eta)$, then the sequence $\psi_n = (1/n) \phi + (1 - 1/n) \eta$ has support $\text{supp}(\phi) \cup \text{supp}(\eta)$ for all $n$, and if $n,m > 0$,
	%
	\[ \| \psi_{n + m} - \psi_n \|_A = \frac{m}{n(n+m)} \left\| \eta - \phi \right\|_A \lesssim 1/n, \]
	%
	so $\{ \psi_n \}$ is a Cauchy sequence under the metric $d$ just defined. However, $\psi_n$ converges to $\eta$ in $M(A)$, which must be the limit under the metric $d$, if such a limit exists. But $d_H(\text{supp}(\psi_n, \eta) \gtrsim |I| > 0$ for each $n$, so $\psi_n$ does not converge to $\eta$ under the metric $d$, and so this metric is not complete.
\end{example}

Fortunately, quasi-all elements of the completion of $M(A)$ under this metric belong to $M(A)$, as we see below, so we can `essentially' treat $M(A)$ as a complete metric space. Since the space $\mathcal{E}$ of compact subsets of $\TT$ is complete under the Hausdorff metric, so too is the space $\mathcal{E} \times M(A)$ under the product metric. The subset
%
\[ \mathcal{G} = \{ (E,\mu) \in \mathcal{E} \times P(A): \text{supp}(\mu) \subset E \} \]
%
is a closed subset of $\mathcal{E} \times P(\mu)$, and thus complete in its own right. If $(E_n,\mu_n)$ are elements of $\mathcal{G}$ converging to $(E,\mu)$ in $\mathcal{E} \times P(\mu)$, and $\varepsilon > 0$ is fixed, then for suitably large $n$, $E_n \subset E_\varepsilon$. We also know $\mu_n \to \mu$, and since $\text{supp}(\mu_n) \subset E_\varepsilon$ for suitably large $n$, $\text{supp}(\mu) \subset E_\varepsilon$. And since $\varepsilon > 0$ was arbitrary, $\text{supp}(\mu) \subset E$, so $(E,\mu) \in \mathcal{G}$. The next lemma shows that $\mathcal{G}$ is the metric completion of $M(A)$.

\begin{lemma}
	For quasi-all $(E,\mu) \in \mathcal{G}$, $\text{supp}(\mu) = E$.
\end{lemma}
\begin{proof}
	For each interval $I$, let $A(I)$ be the family of all $(E,\mu) \in \mathcal{G}$ such that $E \cap I \neq \emptyset$ and $\mu(I) = 0$. Clearly this set is closed, using Hausdorff convergence of sets, and weak convergence of measures. Moreover, this set is nowhere dense; if $\varepsilon > 0$ is fixed, then we can find $F \in \mathcal{E}$ with $E \subset F$ and $d_H(E,F) < \varepsilon$, where $F \cap I$ contains a length $\varepsilon/2$ interval $J$. If $\psi \in C^\infty(\TT)$ is a non-negative probability density function supported on $J$, define $\mu_\varepsilon = (1 - \varepsilon) \mu + \varepsilon \psi$. Then $\| \mu_\varepsilon - \mu \| \lesssim \varepsilon$, so $d((E,\mu), (F,\mu_\varepsilon)) \lesssim \varepsilon$. Since $(F,\mu_\varepsilon)$ is an element of $\mathcal{G}$, but not an element of $A(I)$, this proves nowhere density. Since $\bigcap_I A(I)$ is the family of pairs $(E,\mu)$ with $\text{supp}(\mu) = E$, and the uncountable intersection can be replaced with a countable intersection by a base of intervals, this completes the proof of the claim.
\end{proof}

The set $\mathcal{G}_0 = \{ (E,\mu) \in \mathcal{G}: \widehat{\mu}(n) = o(A_n) \}$ is a closed subset of $\mathcal{G}$. Moreover, quasi-all pairs $(E,\mu) \in \mathcal{G}_0$ satisfy $\text{supp}(\mu) = E$, by the same construction in the last lemma. If we show that $E$ is an independent set for quasi-all $(E,\mu) \in \mathcal{G}_0$, then our proof will be complete, since if $\mu_0$ is the uniform probability measure on $\TT$, then $(\TT,\mu_0) \in \mathcal{G}_0$, so we can find $(E,\mu) \in \mathcal{G}_0$, with $E$ independent, such that $\| \mu - \mu_0 \|_A \leq 1$, which implies $|\widehat{\mu}(n)| \leq A(n)$ for each $n \neq 0$. The main reason that we use $\mathcal{G}_0$ rather than $\mathcal{G}$ is so that we can approximate measures by smooth functions.

We will have need to consider mollifications, i.e. convolutions with smooth approximation to the identity, so we begin by fixed notation. Choose a non-negative bump function $\phi \in C^\infty(\TT)$ supported on $[-1,1]$ with
%
\[ \int \phi(x)\; dx = 1. \]
%
For each $\varepsilon > 0$, define
%
\[ \phi_\varepsilon(x) = \begin{cases} \varepsilon^{-1} \phi(x/\varepsilon) &: x \in [-\varepsilon, \varepsilon], \\ 0 &: \text{otherwise}. \end{cases}. \]
%
Then $\phi_\varepsilon$ is non-negative and supported on $[-\varepsilon,\varepsilon]$, and $\int \phi_\varepsilon(x)\; dx = 1$. As $\varepsilon \to 0$, $\phi_\varepsilon$ converges weakly to the Dirac delta function at the origin, so for each $k \in \ZZ$,
%
\[ \lim_{\varepsilon \to 0} \widehat{\phi_\varepsilon}(k) = 1. \]
%
Moreover, for each $\alpha > 0$, there exists $C_\alpha > 0$ such that for all $\varepsilon > 0$ and non-zero $k \in \ZZ$,
%
\[ |\widehat{\phi_\varepsilon}(k)| \leq \frac{C_\alpha}{\varepsilon^\alpha |k|^\alpha}. \]
%
As $\varepsilon \to 0$, $\{ \phi_\varepsilon \}$ is an approximation to the identity.

\begin{lemma}
	The family of all $(E,\mu) \in \mathcal{G}_0$ with $\mu \in C^\infty(\TT)$ is dense in $\mathcal{G}_0$.
\end{lemma}
\begin{proof}
	Fix $(E,\mu) \in \mathcal{G}_0$. For each $\varepsilon > 0$, define $\mu_\varepsilon = \mu * \phi_\varepsilon$. Then $\mu_\varepsilon \in C^\infty(\TT)$. Since $\mu$ is supported on $E$, $\mu_\varepsilon$ is supported on $\overline{E_\varepsilon}$. Given $\delta$, since $\mu \in \mathcal{G}_0$, we can pick $N$ suitably large that $|\widehat{\mu}(n)| \leq \delta A(n)$ for $|n| \geq N$. Since $\widehat{\phi_\varepsilon}(k)$ converges to 1 for all $k$, there is $\varepsilon(\delta,N)$ such that if $\varepsilon < \varepsilon(\delta)$, $|\widehat{\phi_\varepsilon}(k) - 1| < \delta$ for all $|k| \leq N$. This means that for $|k| \leq N$
	%
	\begin{align*}
		|\widehat{\mu_\varepsilon}(k) - \widehat{\mu}(k)| &= |\widehat{\mu}(k) \widehat{\phi_\varepsilon}(k) - \widehat{\mu}(k)|\\
		&= |\widehat{\mu}(k)| |\widehat{\phi_\varepsilon}(k) - 1|\\
		&< \delta |\widehat{\mu}(k)| < \delta \| \mu \|_A \cdot A(k).
	\end{align*}
	%
	But if $|k| \geq N$,
	%
	\[ |\widehat{\mu_\varepsilon}(k) - \widehat{\mu}(k)| \leq 2 |\widehat{\mu}(k)| \leq 2 \delta A(k). \]
	%
	Thus we have shown that $\| \mu - \mu_\varepsilon \|_A \lesssim \delta$. for suitably small $\varepsilon$. If $\varepsilon < \delta$, then $\mu_\varepsilon$ is supported on $E_\delta$, and $d(E,E_\delta) \lesssim \delta$. Thus we conclude that $d((E,\mu), (\overline{E_\delta},\mu_\varepsilon)) \lesssim \delta$.
\end{proof}

\begin{remark}
	The last lemma implies that to show a set $A \subset \mathcal{G}_0$ is dense, it suffices to show that $\overline{A}$ contains all $(E,\mu)$, where $\mu \in C^\infty(\TT)$.
\end{remark}

To prove that $E$ is an independant set for quasi-all elements $(E,\mu) \in \mathcal{G}_0$, we can by taking countable unions restrict ourselves to avoiding a particular equation $m_1 x_1 + \dots + m_n x_n = 0$ for some non-zero $m \in \ZZ^n$, where $x_1, \dots, x_n$ are distinct. Moreover, we can also restrict ourselves to avoiding solutions $(x_1, \dots, x_n)$ such that $|x_i - x_j| \geq \delta$ for all $i \neq j$, for a fixed $\delta > 0$. So we set $A(m,\delta)$ to be the family of all $(E,\mu) \in \mathcal{G}_0$, where there is $x_1, \dots, x_n \in E$ with $|x_i - x_j| \geq \delta$, and $m_1 x_1 + \dots + m_n x_n = 0$. $A(m,\delta)$ is clearly closed, since if $(E_i,\mu_i)$ converges to $(E,\mu)$ in $\mathcal{G}_0$, and there are $x_i = (x_{i1}, \dots, x_{in}) \in E_i^n$ for each $i$ with $m \cdot x_i = 0$ and $|x_{ij} - x_{ik}| \geq \delta$ for each $j,k$, then by compactness of $\TT^n$ we may thin the sequence, assuming $x_i$ converges to some $x \in E^n$. It is then easy to see that $|x_j - x_k| \geq \delta$ for each $j,k$, and $m \cdot x = 0$, so $(E,\mu) \in \mathcal{G}_0$. All that remains is to show $A(m,\delta)$ is nowhere dense in $\mathcal{G}_0$. We rely on a randomized construction procedure to establish density.

\begin{theorem}
	Fix $n > 0$ and non-zero $m \in \ZZ^n$. Then for suitably large integers $M$, there are $X_1, \dots, X_M \in \TT$ such that for any $j_1, \dots, j_n \in \{ 1, \dots, M \}$,
	%
	\[ |m_1X_{j_1} + \dots + m_n X_{j_n} | \geq \frac{1}{10 M^n}, \]
	%
	and if $\mu = M^{-1}(\delta_{X_1} + \dots + \delta_{X_M})$, then for any $|k| \leq M^{10n}$,
	%
	\[ |\widehat{\mu}(k)| \leq 10 n^{1/2} \log(M)^{1/2} M^{-1/2}. \]
\end{theorem}
\begin{proof}
	Consider $M$ random variables $X_1, \dots, X_M$, independant and uniformly distributed on $\TT$. Then for each $j_1, \dots, j_n \in \{ 1, \dots, M \}$, $m_1 X_{j_1} + \dots + m_n X_{j_n}$ is uniformly distributed on $\TT$, so
	%
	\[ \PP(|m_1 X_{j_1} + \dots + m_n X_{j_n}| \leq \varepsilon) = 2 \varepsilon. \]
	%
	Applying a union bound, we conclude that
	%
	\[ \PP(\text{for all}\ j_1, \dots, j_n \in \{ 1, \dots, M \}: |m_1 X_{j_1} + \dots + m_n x_{j_n}| \geq \varepsilon ) \geq 1 - 2 M^n \varepsilon. \]
	%
	Consider the random measure $\mu = M^{-1}(\delta_{X_1} + \dots + \delta_{X_M})$. Then
	%
	\[ \widehat{\mu}(k) = M^{-1}(e^{- 2 \pi i k X_1} + \dots + e^{- 2 \pi i k X_M}). \]
	%
	Thus $\widehat{\mu}(k)$ is an average of $M$ bounded random variables, so we can apply Hoeffding's inequality to conclude that for any $\delta > 0$,
	%
	\[ \PP(|\widehat{\mu}(k)| \geq \delta) \leq 2 \exp(- 2 M \delta^2). \]
	%
	Thus another union bound shows that
	%
	\[ \PP(\text{for all}\ k \in [-K,K] : |\widehat{\mu}(k)| \leq \delta) \geq 1 - 5 K \exp(-2 M \delta^2) \]
	%
	Thus, assuming
	%
	\[ 2M^n \varepsilon + 5 K \exp(-2 M \delta^2) < 1, \]
	%
	then there exists $X_1, \dots, X_M \in \TT$ such that $m_1 X_{j_1} + \dots + m_n X_{j_n} \geq \varepsilon$ for all $j_1, \dots, j_n \in \{ 1, \dots, M \}$, and if $\mu = M^{-1}(\delta_{X_1} + \dots + \delta_{X_m})$, then $|\widehat{\mu}(k)| \leq \delta$ for all $k \in [-K,K]$. In particular, the result holds if we choose $\varepsilon = 1/10 M^n$, $K = M^{10n}$, and $\delta = 10 n^{1/2} \log(M)^{1/2} M^{-1/2}$.
\end{proof}

\begin{lemma}
	Suppose $\varepsilon > 0$, $m \in \ZZ^n$, and fix an arbitrary sequence $\{ B(k) : k \neq 0 \}$ such that $\lim_{|k| \to \infty} B(k) = \infty$. Then there exists a measure $\mu \in M(\TT)$ such that for each $x_1, \dots, x_n$ in the support of $\mu$, $m_1 x_1 + \dots + m_n x_n \neq 0$, and for all nonzero $k \in \ZZ$,
	%
	\[ |\widehat{\mu}(k)| \leq \varepsilon \cdot B(k) \log \left( 1 + |k| \right)^{1/2} \cdot |k|^{-1/2n}. \]
\end{lemma}
\begin{proof}
	Let $\mu$ be as in the proof above. If
	%
	\[ \delta = \frac{1}{20 (|m_1| + \dots + |m_n|) M^n}, \]
	%
	then for any $x_1, \dots, x_n$ in the support of $\mu_\delta = \mu * \phi_\delta$, $m_1 x_1 + \dots + m_n x_n \neq 0$. Since $\{ B(k) \}$ converges to infinity, it is lower bounded, and so for each $\varepsilon > 0$, there exists a small constant $c(\varepsilon)$ independant of $M$ such that if $|k| \leq c(\varepsilon) M^n$, then
	%
	\[ |\widehat{\mu_\delta}(k)| \leq |\widehat{\mu}(k)| \leq 10 \log(M^n)^{1/2} (M^n)^{-1/2n} \leq \varepsilon B(k) \log(1 + |k|)^{1/2} |k|^{-1/2n}. \]
	%
	On the other hand, if $c(\varepsilon) M^n \leq |k| \leq M^{10n}$, then
	%
	\begin{align*}
		|\widehat{\mu_\delta}(k)| &\leq |\widehat{\mu}(k)| |\widehat{\phi_\delta}(k)|\\
		&\lesssim \frac{\log(M)^{1/2} M^{-1/2}}{\delta |k|}\\
		&\lesssim_m \frac{\log(M)^{1/2} M^{n-1/2}}{\log(1 + |k|)^{1/2} \cdot |k|^{1-1/2n}} \log(1 +|k|)^{1/2} |k|^{-1/2n}\\
		&\lesssim_\varepsilon \log(1 + |k|)^{1/2} |k|^{-1/2n}.
	\end{align*}
	%
	If $M$ is suitably large that $B(k) \geq 1/\varepsilon$ for $|k| \geq M^n$, then for all $k$ with $M^n \leq |k| \leq M^{10n}$,
	%
	\[ |\widehat{\mu_\delta}(k)| \leq \varepsilon B(k) \log(1 + |k|)^{1/2} |k|^{-1/2n}. \]
	%
	If $|k| \geq M^{10n}$,
	%
	\begin{align*}
		|\widehat{\mu_\delta}(k)| &\leq |\widehat{\phi_\delta}(k)| \lesssim_m M^n / |k| \leq (M^n / |k|^{1-1/2n}) |k|^{-1/2n} \leq |k|^{-1/2},
	\end{align*}
	%
	so if $M$ is suitably large, and $|k| \geq M^{10n}$,
	%
	\[  |\widehat{\mu_\delta}(k)| \leq \varepsilon B(k) \log(1 + |k|)^{1/2} |k|^{-1/2}. \]
	%
	This addresses all possible values of $k$, completing the proof.
\end{proof}

If $\{ B(k) \}$ is a sequence chosen carefully enough that
%
\[ \lim_{|k| \to \infty} B(k) \log(1 + |k|)^{1/2} |k|^{-1/2} = 0, \]
%
and if $\mu$ is chosen such that for $k \neq 0$,
%
\[ \widehat{\mu}(k) \leq \varepsilon B(k) \log(1 + |k|)^{1/2} |k|^{-1/2}, \]
%
then $|\widehat{\mu}(k)| \lesssim \varepsilon$ for all $k \neq 0$, in which case the following lemma comes into play, showing a quantitative density statement about the support of $\mu$.

\begin{lemma}
	For any $\varepsilon > 0$, there exists $\delta > 0$ such that if $\mu$ is a probability measure on $\TT$ such that $|\widehat{\mu}(k)| \leq \delta$ for all $k \neq 0$, then the support of $\mu$ contains a point in every length $\varepsilon$ interval.
\end{lemma}
\begin{proof}
	By translation, it suffices to show that the support of $\mu$ intersects $(-\varepsilon/2,\varepsilon/2)$. But if $\mu$ did not intersect this interval, then
	%
	\[ \int \phi_{\varepsilon/2} d\mu = 0. \]
	%
	Applying Parseval's equality, this means that
	%
	\[ \sum_{k \in \ZZ} \widehat{\phi_{\varepsilon/2}}(k) \widehat{\mu}(k) = 0. \]
	%
	But
	%
	\begin{align*}
		\left| \sum_{k \in \ZZ} \widehat{\phi_{\varepsilon/2}}(k) \widehat{\mu}(k) \right| &\geq 1 - \delta \sum_{k \neq 0} |\widehat{\phi_{\varepsilon/2}}(k) = 1 - O_\varepsilon(\delta),
	\end{align*}
	%
	where the last equality holds because $\phi_{\varepsilon/2}$ is smooth, and so it's Fourier coefficients are rapidly decreasing. But this is impossible if $\delta$ is sufficiently small, depending on $\varepsilon$.
\end{proof}

\begin{lemma}
	For any nonzero $m \in \ZZ^n$, and $\delta > 0$, $A(m,\delta)$ is dense in $\mathcal{G}_0$.
\end{lemma}
\begin{proof}
	Fix $\varepsilon_0 > 0$, and $(E,\mu_0) \in \mathcal{G}_0$. Without loss of generality, we may assume that $\mu_0 \in C^\infty(\TT)$, and that $\varepsilon_0$ is suitably small that the support of $\mu_0$ is a union of length $\varepsilon_0$ intervals. For any $\varepsilon > 0$, and for any sequence $\{ B(k) \}$ converging to $\infty$ as $|k| \to \infty$, we can find a measure $\eta \in M(\TT)$ such that for each $x_1, \dots, x_n$ in the support of $\eta$, $m_1 x_1 + \dots + m_n x_n \neq 0$, and for any nonzero $k \in \ZZ$,
	%
	\[ |\widehat{\eta}(k)| \leq \varepsilon B(k) \log(1 + |k|)^{1/2} |k|^{-1/2n}. \]
	%
	Assume, without loss of generality, that $B(k) \lesssim_\varepsilon |k|^\varepsilon$ for each $\varepsilon > 0$, and that there exists a universal constant $C > 0$ such that for each $|k|$, if $|k|/2 \leq |k'| \leq 2 |k|$, then
	%
	\[ (1/C) B(k) \leq B(k') \leq C B(k). \]
	%
	Such a choice is provided, for instance, by setting $B(k) = \log(1 + |k|)$, with $C = 2$, but can be chosen as slowly growing as necessary. Define $\mu = \mu_0 \eta$. If $\varepsilon$ is suitably small, depending on $\varepsilon_0$, this implies that the support of $\eta$ contains a point in each length $\varepsilon_0$ interval. Thus
	%
	\[ d_H(\text{supp}(\mu), \text{supp}(\mu_0)) \leq \varepsilon_0. \]
	%
	Since $\mu_0 \in C^\infty(\TT)$, we calculate that
	%
	\begin{align*}
		|\widehat{\mu}(k) - \widehat{\mu_0}(k)| &= \left| (\widehat{\mu_0} * \widehat{\eta})(k) - \widehat{\mu_0}(k) \right|\\
		&= \left| \sum_{k' \neq 0} \widehat{\mu_0}(k') \widehat{\eta}(k-k') \right|\\
		&\lesssim_{\mu_0} \sum_{k' \neq 0} \frac{|\widehat{\eta}(k-k')}{|k'|^2}\\
		&\leq \sum_{|k'| \leq |k|/2} \frac{|\widehat{\eta}(k-k')|}{|k'|^2} + \sum_{|k'| > |k|/2} \frac{|\widehat{\eta}(k-k')|}{|k'|^2}\\
		&\lesssim \varepsilon B(k) \log(1 + |k|)^{1/2} |k|^{-1/2n} \sum_{|k'| \leq |k|/2} \frac{1}{|k'|^2} + \sum_{|k'| > |k|/2} \frac{\varepsilon}{|k'|^2}\\
		&\lesssim \varepsilon B(k) \log(1 + |k|)^{1/2} |k|^{-1/2n} + \varepsilon |k|^{-1}\\
		&\lesssim \varepsilon B(k) \log(1 + |k|)^{1/2} |k|^{-1/2n}.
	\end{align*}
	%
	We recall that for the sequence $\{ A(k) \}$ that we chose, for any $\alpha > 0$,
	%
	\[ \lim A(k) |k|^\alpha = \infty. \]
	%
	If $\alpha < 1/2n$, we therefore find that
	%
	\[ B(k) \log(1 + |k|)^{1/2} |k|^{-1/2n} \lesssim |k|^{-\alpha} \lesssim A(k). \]
	%
	Thus $d_A(\mu, \mu_0) \lesssim \varepsilon \lesssim \varepsilon_0$. Thus we conclude that
	%
	\[ d((E,\mu),(\overline{E_{\varepsilon_0}},\mu_0)) \lesssim \varepsilon_0, \]
	%
	which completes the proof of density since $\varepsilon_0$ was arbitrary.
\end{proof}

This completes our proof that quasi-all $(E,\mu)$ have $\text{supp}(\mu) = E$, and such that $E$ is an independent set. We note that the decay of the measure $\mu$ constructed using the probabilistic construction has a constant decay depending only on the number $n$ of coefficients in the linear equation
%
\[ m_1 x_1 + \dots + m_N x_N. \]
%
Working with the sequence $A(k) = |k|^{-1/2n} \log(1 + |k|)^{1/2 + \varepsilon}$, for any $\varepsilon > 0$, one can follow through the proof above to show that for quasi all elements $(E,\mu) \in \mathcal{G}_0$, $\text{supp}(\mu) = E$, and for any $m \in \ZZ^n$, $m_1 x_1 + \dots + m_n x_n \neq 0$. In particular, this implies that $E$ is a set with Fourier dimension $\geq 1/n$. This is far from the result which guarantees the existence of solutions of such an equation in sets with Fourier dimension greater than $2/n$, but it is a useful start. A slightly more complicated probabilistic construction improves this construction to obtain a set with Fourier dimension $1/(n-1)$ avoiding solutions to the equation $m_1 x_1 + \dots + m_n x_n = 0$ for all non-zero $m \in \ZZ^n$.

\begin{theorem}
	Fix $n > 0$ and non-zero $m \in \ZZ^n$. Then for suitably large integers $M$, there are $X_1, \dots, X_M \in \TT$ such that for any $j_1, \dots, j_n \in \{ 1, \dots, M \}$,
	%
	\[ |m_1X_{j_1} + \dots + m_n X_{j_n} | \geq \frac{1}{10 M^{n-1/2}}, \]
	%
	and if $\mu = M^{-1}(\delta_{X_1} + \dots + \delta_{X_M})$, then for any $|k| \leq M^{10n}$,
	%
	\[ |\widehat{\mu}(k)| \leq 10 n^{1/2} \log(M)^{1/2} M^{-1/2}. \]
\end{theorem}
\begin{proof}
	Consider independent random variables $X_1, \dots, X_M$ uniformly distributed on $\TT$, and consider the measure
	%
	\[ \mu = \delta_{X_1} + \dots + \delta_{X_M}. \]
	%
%	For each distinct $i,j \in \{ 1, \dots, M \}^n$, the two random variables $m_1 X_{i_1} + \dots + m_n X_{i_n}$ and $m_1 X_{j_1} + \dots + m_n X_{j_n}$ are independent.
	Let $Z$ denotes the number of tuples $i \in \{ 1, \dots, M \}^n$ such that
	%
	\[ |m_1 X_{i_1} + \dots + m_n X_{i_n}| \leq \varepsilon. \]
	%
%	\[ \VV(Z) = 2\varepsilon (1 - 2\varepsilon) M^n \leq 2 M^n \varepsilon. \]
	%
	Then $\EE(Z) = 2 M^n \varepsilon$, Markov's inequality implies that
	%
	\[ \PP(Z \geq 10M^n \varepsilon) \leq 1/5. \]
	%
	%Chebyshev's inequality implies that
	%
	%\[ \PP(Z \geq 2 M^n \varepsilon + t) \leq 2 M^n \varepsilon/t^2 \]
	%
	Setting $\varepsilon = 1/10M^{n-1/2}$ and $t = M^{1/2}$, we conclude
	%
	\[ \PP(Z \geq M^{1/2}) \leq 1/4. \]
	%
	For each $k$,
	%
	\[ \widehat{\mu}(k) = \exp(2 \pi i X_1) + \dots + \exp(2 \pi i X_M), \]
	%
	is a sum of $M$ independant random variables, so we can apply Hoeffding's inequality to conclude
	%
	\[ \PP(|\widehat{\mu}(k)| \geq \delta) \leq 2 \exp(-2 \delta^2 / M). \]
	%
	A union bound thus shows
	%
	\[ \PP(\text{for all}\ k \in [-K,K] : |\widehat{\mu}(k)| \leq \delta) \geq 1 - 5K \exp(-2 \delta^2 / M). \]
	%
	In particular, if $K = M^{10n}$, and $\delta = 5 n^{1/2} M^{1/2} \log(M)^{1/2}$, we conclude that
	%
	\[ \PP(\text{for all}\ |k| \leq M^{10n} : |\widehat{\mu}(k)| \leq 5n^{1/2} M^{1/2} \log(M)^{1/2} ) \leq 1/4. \]
	%
	Applying a union bound, we therefore conclude that there exists $X_1, \dots, X_M$ such that there are at most $3M^{1/2}$ tuples $i$ such that $|m_1 X_{i_1} + \dots + m_n X_{i_n}| \leq 1/M^{n-1/2}$, and for all $|k| \leq M^{10n}$,
	%
	\[ |\widehat{\mu}(k)| \leq 5n^{1/2} M^{1/2} \log(M)^{1/2}. \]
	%
	If we let
	%
	\[ I = \{ 1, \dots, M \} - \{ i_1 : |m_1 X_{i_1} + \dots + m_n X_{i_n}| \leq 1/M^{n-1/2} \}, \]
	%
	This means that
	%
	\[ \left\| \mu - \sum_{i \in I} X_i \right\|_{M(\TT)} \leq |I|^c \leq 3M^{1/2}, \]
	%
	so for each $|k| \leq M^{10n}$, if $\nu = 1/|I| \sum_{i \in I} X_i$, and if $M$ is sufficiently large, then
	%
	\begin{align*}
		|\widehat{\nu}(k)| &\leq \frac{1}{|I|} \left( 3M^{1/2} + |\widehat{\mu}(k)| \right)\\
		&\leq \frac{1}{M - 3M^{1/2}} \left( 3M^{1/2} + 5n^{1/2} M^{1/2} \log(M)^{1/2} \right)\\
		&\leq 10 n^{1/2} \log(M)^{1/2} M^{-1/2}.
	\end{align*}
	%
	This completes the proof.
\end{proof}

In the last result, we were able to choose $\varepsilon$ proportionally larger than in our previous construction. Thus we are free to convolve our measure with a less convoluted smooth function while still avoiding solutions to the linear equations. Going through the remainder of the construction as we have just done shows that for quasi-all pairs $(E,\mu)$, $\text{supp}(\mu) = E$, and $E$ has Fourier dimension greater than
%
\[ \frac{1}{n - 1/2}. \]

Perform a decomposition on $E_\varepsilon$, writing it as the countable union of small boxes, which tensorize nicely? But the probability of a union of boxes is hard to calculate.

\end{document}
