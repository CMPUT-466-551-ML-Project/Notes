\documentclass[answers]{exam}
\usepackage[utf8]{inputenc}

\usepackage{comment}
\usepackage{amsmath, mathtools}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage[shortlabels]{enumitem}
\usepackage{esint}

\DeclareMathOperator{\CC}{\mathbf{C}}
\DeclareMathOperator{\RR}{\mathbf{R}}
\DeclareMathOperator{\ZZ}{\mathbf{Z}}

% Define a custom "problem" environment
\newtheoremstyle{problemstyle}  % <name>
        {3pt}                                               % <space above>
        {3pt}                                               % <space below>
        {\normalfont}                               % <body font>
        {}                                                  % <indent amount}
        {\bfseries\itshape}                 % <theorem head font>
        {\normalfont\bfseries:}         % <punctuation after theorem head>
        {.5em}                                          % <space after theorem head>
        {}                                                  % <theorem head spec (can be left empty, meaning `normal')>
\theoremstyle{problemstyle}
\newtheorem{problem}{Problem}%[section] % Comment out [section] to remove section number dependence


%Custom Math Commands
\newcommand{\vt}{\vskip 5mm} % vertical space
\newcommand{\fl}{\noindent\textbf} % first line
\newcommand{\Fl}{\vt\noindent\textbf} % first line with space above
\newcommand{\norm}[1]{\left\lVert#1\right\rVert} % norm
\newcommand{\pnorm}[1]{\left\lVert#1\right\rVert_p} % p-norm
\newcommand{\qnorm}[1]{\left\lVert#1\right\rVert_q} % q-norm
\newcommand{\1}[1]{\textbf{1}_{\left[#1\right]}} % indicator function 
\newcommand{\EE}[1]{\mathbb{E}\left[#1\right]} % expectation with bracket
\def\limn{\lim_{n\to\infty}} % shortcut for lim as n-> infinity
\def\sumn{\sum_{n=1}^{\infty}} % shortcut for sum from n=1 to infinity
\def\sumkn{\sum_{k=1}^{n}} % shortcut for sum from k=1 to n
\def\sumin{\sum_{i=1}^{n}} % shortcut for sum from i=1 to n
\def\SAs{\sigma\text{-algebras}} % shortcut for $\sigma$-algebras
\def\SA{\sigma\text{-algebra}} % shortcut for $\sigma$-algebra
\def\Ft{\mathcal{F}_t} % time-indexed sigma-algebra (t)
\def\Fs{\mathcal{F}_s} % time-indexed sigma-algebra (s)
\def\F{\mathcal{F}} % sigma-algebra
\def\G{\mathcal{G}} % sigma-algebra
\def\R{\mathbb{R}} % Real numbers
\def\Z{\mathbb{Z}} % Integers
\def\E{\mathbb{E}} % Expectation
\def\P{\mathbb{P}} % Probability
\def\Q{\mathbb{Q}} % Q probability
\def\dist{\text{dist}} %Text 'dist' for things like 'dist(x,y)'

% Brackets and Parentheses
%\def\[{\left [}
%\def\]{\right ]}
\def\({\left (}
\def\){\right )}

\usepackage{titling}



% Colorful Notes
\usepackage{color}
\definecolor{Red}{rgb}{1,0,0}
\definecolor{Blue}{rgb}{0,0,1}
\def\red{\color{Red}}
\def\blue{\color{Blue}}
\newcommand{\rnote}[1]{\red#1} % \rnote{foo} then 'foo' is red
\newcommand{\bnote}[1]{{\blue#1}} % \bnote{foo} then 'foo' is blue



\title{Analysis SEP Problems \& Solutions}
\date{July-August 2021}
\author{Max Bacharach and Jacob Denson}

\begin{document}

\maketitle

\begin{questions}

\newpage
\section{\centering Day 1: Basic Analysis}

\question (Aug 2016 \#1)
  For $n\geq 2$ an integer, define $F(n)$ to be the function $F(n)= \max \left\{ k\in \Z: 2^{k}/k\leq n \right\}$. Does $\sum_{n=2}^{\infty}2^{-F(n)}$ converge or diverge?
\begin{solution}
  The series diverges.
  \begin{align*}
    \sum_{n=2}^{\infty}2^{-F(n)}
    &= \sum_{k=1}^{\infty} \#\left\{ n:F(n)=k \right\}\\
    &=\sum_{k=1}^{\infty}2^{-k}\#\left\{ n: \frac{2^{k}}{k}\leq n < \frac{2^{k+1}}{k+1} \right\}\\
    &=\sum_{k=1}^{\infty}2^{-k}\left( \frac{2^{k+1}}{k+1}-\frac{2^{k}}{k} \right)\\
    &=\sum_{k=1}^{\infty}2^{-k}2^{k}\left( \frac{1}{k+1}-\frac{1}{k(k+1)} \right)\\
    &=\sum_{k=1}^{\infty}\frac{1}{k+1}-\frac{1}{k(k+1)}
  \end{align*}
  It is clear from the last expression that the series diverges.
\end{solution}

\question (September, 2017) Let $\{ a_n \}$ be a sequence of complex numbers and let
%
\[ c_n = n^{-5} \sum_{k = 1}^n k^4 a_k. \]
\begin{parts}
	\part Prove or Disprove: If $\lim_{n \to \infty} a_n = a$ exists, then $\lim_{n \to \infty} c_n = c$ exists.
	\begin{solution}
		Fix $\varepsilon > 0$. If $|a_k - a| < \varepsilon$ for $k > N$, then
		%
		\begin{align*}
			n^{-5} \sum_{k = 1}^n k^4 a_k &= O_N(n^{-5}) + n^{-5} \sum_{k = N+1}^n k^4 a_k\\
			&= O_N(n^{-5}) + a n^{-5} \sum_{k = N+1}^n k^4 + O(\varepsilon n^{-5} \sum_{k = N+1}^n k^4)\\
			&= O_N(n^{-5}) + O(\varepsilon) + a(1/5 + O_N(1/n)).
		\end{align*}
		%
		Thus $|c_n - a/5| \leq 2\varepsilon$ for suitable large $n$.
	\end{solution}
	
	\begin{solution}
      First observe that
      \begin{equation*}
      \frac{1}{n^{5}}\sum_{k=1}^{n}k^{4} = \frac{1}{n^{5}}\sum_{k=1}^{n}\int_{k}^{k+1}k^{4}dx \leq \frac{1}{n^{5}}\sum_{k=1}^{n}\int_{k}^{k+1}x^{4}dx = \frac{1}{n^{5}}\int_{1}^{n+1}x^{4}dx = \frac{(n+1)^{5}-1}{5n^{5}}.
      \end{equation*}
      Therefore $\limsup_{n\to\infty} \frac{1}{n^{5}}\sum_{k=1}^{n}k^{4}\leq 1/5$. By a similar argument,  $\liminf_{n\to\infty} \frac{1}{n^{5}}\sum_{k=1}^{n}k^{4}\geq 1/5$. Therefore $\limn \frac{1}{n^{5}}\sum_{k=1}^{n}k^{4}=1/5$.
    
      Let $a=\limn a_{n}$. We claim that $c_{n}\to a/5$. To see this, choose $n_{0}>0$ such that $|a_{n}-a|<5\epsilon$ whenever $n> n_{0}$. Then
      \begin{align*}
        \left| c_{n} - \frac{1}{n^{5}}\sum_{k=1}^{n}k^{4}a\right|
        &=\left| \frac{1}{n^{5}}\sum_{k=1}^{n}k^{4}a_{k} - \frac{1}{n^{5}}\sum_{k=1}^{n}k^{4}a\right|\\
        &\leq \frac{1}{n^{5}}\sum_{k=1}^{n_{0}}k^{4}|a_{k}-a|+ \frac{1}{n^{5}}\sum_{k=n_{0}+1}^{n}k^{4}|a_{k}-a|\\
        &\leq \frac{1}{n^{5}}\sum_{k=1}^{n_{0}}k^{4}|a_{k}-a|+ 5\epsilon \left(\frac{1}{n^{5}}\sum_{k=n_{0}+1}^{n}k^{4}|a_{k}-a|\right)\\
      \end{align*}
      Therefore
      \begin{equation*}
        \limsup_{n\to\infty }\left| c_{n} - \frac{1}{n^{5}}\sum_{k=1}^{n}k^{4}a\right| \leq \epsilon.
      \end{equation*}
      Since $\epsilon>0$ was arbitrary, it follows that $\limn c_{n} = \limn \frac{1}{n^{5}}\sum_{k=1}^{n}k^{4}a = a/5$.
    \end{solution}


	\part Prove or Disprove: If $\lim_{n \to \infty} c_n = c$ exists, then $\lim_{n \to \infty} a_n = a$ exists.
	\begin{solution}
		This is false. Let $a_n = (-1)^n$. Then $a_n$ does not converge, but we claim $c_n$ does converge. Then
		%
		\[ c_n = \frac{1}{n^5} \sum_{k = 1}^n (-1)^k k^4 = \frac{S_n}{n^5}, \]
		%
		where $S_n = \sum (-1)^k k^4$. We claim that $|S_n| \leq n^4$ for all $n$, and $\text{sign}(S_n) = (-1)^n$. We prove this by induction, the case $n = 1$ being obvious. Assuming the result for $n$, we have
		%
		\[ S_{n+1} = S_n + (-1)^{n+1} (n+1)^4. \]
		%
		Now $S_n$ and $(-1)^{n+1}(n+1)^4$ have opposite signs, $|S_n| \leq n^4$, and $(n+1)^4 > n^4$, so $S_n + (-1)^{n+1} (n+1)^4$ has sign $(-1)^{n+1}$, and
		%
		\[ |S_{n+1}| \leq (n+1)^4. \]
		%
		But this implies that $c_n = O(1/n)$, so $c_n \to 0$.
	\end{solution}
	
	\begin{solution}
	Let $a_{k} =\left\{ 
	\begin{array}{l@{\quad}l}
	1 & k=2^{\ell}, \text{if }\ell=0,1,2,\ldots\\
	0 & \text{else}
	\end{array}\right.$
	Then $c_{2n+1}= 0$ for all $n$, and
	\begin{equation*}
	c_{2n}= \frac{1}{(2n)^{5}}\sum_{k=1}^{2n}k^{4}a_{k} = \frac{1}{(2n)^{5}}\sum_{k=1}^{\lfloor \log n \rfloor}2^{4i}\leq \frac{1}{(2n)^{5}}(2n)^{4}\#\left\{ i: 1\leq 2^{i}\leq 2n \right\}\leq \frac{\log 2n}{2n}\to 0.
	\end{equation*}
	It follows that $\limn c_{n} = 0$ but $\limn a_{n}$ does not exist.
	\end{solution}
\end{parts}

\question (Aug 2018 \#2)
  For $c_k\in \R$, say that $\Pi c_k$ converges if $\lim_{K\to\infty} \prod_{k=1}^{K} c_k = C$ exists with $C\neq 0, \infty$.
\begin{parts}
  \part Prove that if $0<a_{k}<1$ for all $k$, or if $-1<a_{k}<0$, for all $k$, then $\prod (1+a_{k})$ converges if and only if $\sum_{k}a_{k}$ converges.
  
    \begin{solution}
  Let $P_n = \prod_{k=1}^n (1+a_k)$ and $S_n = \sum_{k=1}^n a_k$. 
  
  \textbf{Case 1:} Assume $a_k\in (0,1)$ for all $k$. 
  First assume $\lim_{n\to\infty} S_n = L <\infty$. We wish to show that $\lim_{n\to\infty} P_n$ converges. Since $(P_n)$ is increasing and $P_1>1$, it suffices to show that $(P_n)$ is bounded above.
  Since $e^x\geq 1+x$ for all $x$, we have
  \begin{equation*}
  1\leq P_n \leq \prod_{k=1}^n e^{a_k} = e^{S_n} \leq e^{L}<\infty
  \end{equation*}
  where we have used the fact that $S_n$ is increasing, so that $S_n\leq L$.
  
  Next, assume that $\lim_{n\to\infty}P_n= M$ where $M\neq 0,\infty$. Wish to show that $\lim_{n\to\infty} S_n$ exists. Since $(S_n)$ is increasing, it suffices to show that $(S_n)$ is bounded above.
  
  
  We claim that $P_n \geq S_n + 1$. We prove this using induction. The case $n=1$ is trivial since equality holds. For $n>1$, observe that
  \begin{align*}
  P_n 
  &= (1+a_n) P_{n-1}\\
  &\geq (1+a_n)(1+S_{n-1}) &&\text{by induction hypothesis}\\
  &= 1+ S_{n} + a_nS_{n-1}\\
  &\geq 1+S_n
  \end{align*}
  This proves the claim. It follows that $S_n\leq P_n$ for all $n$. Therefore since $P_n$ is increasing, we have
  \begin{equation*}
  S_n \leq P_n \leq \lim_{n\to\infty} P_n = M<\infty
  \end{equation*}
  as required.
  
  An alternative approach uses the inequality $\log(1+x)\geq \frac{x}{1+x}$ which holds for all $x>-1$. In that case, we have the inequality
  \begin{align*}
  P_n = \exp \(\sum_{k=1}^n \log(1+a_k)\) \geq \exp\(\sum_{k=1}^{n} \frac{a_k}{1+a_k} \)\geq \exp\(\frac{1}{2}\sum_{k=1}^n a_k\).
  \end{align*}
  This inequality implies that if $\lim_n P_n$ converges then $\lim_n S_n$ converges as well.
  
  
  \textbf{Case 2:} Assume that $a_k\in (-1,0)$ for all $k$. Suppose $\lim_{n\to\infty} P_n$ converges. Wish to show that $S_n$ converges as well. Since $(S_n)$ is decreasing, it suffices to show that $(S_n)$ is bounded below. 
  
  Since $(P_n)$ is decreasing and convergent, there exists $L\in (0,1)$ such that $L = \lim_{n\to\infty} P_n = \inf_{n\geq 1}{P_n}$. Using the inequality $\log(1+x)\leq x$ for $x>-1$, for all $n$ we have
  \begin{align*}
  0< L \leq P_n = \exp\(\sum_{k=1}^n \log(1+a_k)\)\leq e^{S_n}.
  \end{align*}
  Therefore $S_n\geq \log L>-\infty$ for all $n$. Therefore since $(S_n)$ is decreasing and bounded below, it converges.
  
  Next, assume that $(S_n)$ converges. Need to show that $(P_n)$ converges. Since
  \begin{equation*}
  \prod_{k=1}^n (1+a_k) = \exp\(\sum_{k=1}^n \log(1+a_k)\)
  \end{equation*}
  it follows that $\prod(1+a_k)$ converges if and only if $\sum_k \log(1+a_k)$ converges. Since $a_k\in (-1,0)$ for all $k$, the sequences $\sum_k \log(1+a_k)$ and $\sum_k a_k$ both have all negative terms, and so we can apply the limit comparison test, as follows.
  Since $(S_n)$ converges, $a_k\to0$ as $k\to \infty$. Therefore since $\frac{d}{dx}\log(x)=\frac{1}{x}$,
  \begin{equation}
  \frac{\log(1+a_k)}{a_k} = \frac{\log(1+a_k)-\log(1)}{a_k}\to 1 \text{ as }k\to\infty. 
  \end{equation}
  Therefore by the limit comparison test, $\sum_k\log(1+a_k)$ converges if $\sum_k a_k$ converges. Therefore $(P_n)$ converges. \bnote{[Actually I think this argument might work for the general case.]} 
  \end{solution}
  
  \part However, prove that $\prod_{k>1} \left( 1+ \frac{(-1)^{k}}{\sqrt{k}} \right)$ diverges.
  
  \begin{solution}
  \noindent\textbf{Proof of Part (b):} Let $P_n = \prod_{k=2}^n \(1+ \frac{(-1)^k}{\sqrt{k}}\)$. Then
  \begin{align*}
  P_{2n} 
  &=\(1+\frac{1}{\sqrt{2}}\) \prod_{k=3}^{2n} \(1+\frac{(-1)^k}{\sqrt{k}}\) \\
  &=\(1+\frac{1}{\sqrt{2}}\) \prod_{k=4}^{n} \(1-\frac{1}{\sqrt{2k-1}}\)\(1+\frac{1}{\sqrt{2k}}\) \\
  &=\(1+\frac{1}{\sqrt{2}}\) \prod_{k=4}^{n} \(1+\frac{\sqrt{2k-1}-\sqrt{2k}-1}{\sqrt{2k(2k-1)}}\). \\
  \end{align*}
  Using the Mean Value Theorem, $\sqrt{2k+1}-\sqrt{2k}\leq \frac{1}{2\sqrt{2k}}$. Using this, we have
  \begin{equation*}
  1+\frac{\sqrt{2k-1}-\sqrt{2k}-1}{\sqrt{2k(2k-1)}}  \leq 1 - \frac{\sqrt{k}+1}{\sqrt{2k(2k-1)}} \leq 1-\frac{1}{2\sqrt{2k-1}} < 1-\frac{1}{2k}.
  \end{equation*}
  Therefore 
  \begin{equation*}
  P_{2n} = \(1+\frac{1}{\sqrt{2}}\) \prod_{k=4}^{n} \(1-\frac{1}{2k}\).
  \end{equation*}
  By part (a), since $\sum_{k=4}^{\infty} \frac{1}{2k}$ diverges, it follows that $\prod_{k=4}^{\infty} \(1-\frac{1}{2k}\) = 0$. Therefore $(P_n)$ diverges.
  \end{solution}
  \end{parts}
  
\question (September, 2019) Let $f$ be a continuous function on $\RR$ satisfying
%
\[ |f(x)| \leq 1/(1 + x^2). \]
%
Define a function $F$ on $\RR$ by
%
\[ F(x) = \sum_{n = -\infty}^\infty f(x + n). \]
\begin{parts}
	\part Prove that $F$ is continuous and periodic with period 1.
	\begin{solution}
		If $N \geq 2|x|$, then for $|n| \geq N$, $|x + n| \geq |n|/2$, and so
		%
		\[ \sum_{|n| \geq N} |f(x+n)| \leq \sum_{|n| \geq N} \frac{1}{1 + |n|^2/4} \lesssim \sum_{|n| \geq N}^\infty \frac{1}{n^2} \lesssim 1/N. \]
		%
		Thus if we write $F = \lim F_N$, where
		%
		\[ F_N(x) = \sum_{|n| \leq N} f(x + n), \]
		%
		then we see that for $M > N \geq 2R$,
		%
		\[ \| F_M - F_N \|_{L^\infty[-R,R]} \lesssim 1/N. \]
		%
		Thus the sequence $\{ F_N \}$ converges locally uniformly to $F$, and thus $F$ is continuous.

		To show $F$ is periodic, we note that
		%
		\[ F(x + 1) - F(x) = \lim_{N \to \infty} F_N(x+1) - F_N(x) = \lim_{N \to \infty} f(x + N + 1) - f(x - N). \]
		%
		For $N \geq 2|x|$, we have
		%
		\[ f(x + N + 1) - f(x - N) \lesssim \frac{1}{N^2}, \]
		%
		and thus
		%
		\[ F(x + 1) - F(x) = \lim_{N \to \infty} f(x+N+1) - f(x-N) = 0. \]
		%
		Thus $F$ is periodic.
	\end{solution}

	\part Prove that if $G$ is continuous and periodic with period one, then
	%
	\[ \int_0^1 F(x) G(x) = \int_{-\infty}^\infty f(x) G(x)\; dx. \]
	\begin{solution}
		Since $F$ is the locally uniform limit of the functions $\{ F_N \}$, we can interchange integrals and limits, writing
		%
		\begin{align*}
			\int_0^1 F(x) G(x)\; dx &= \lim_{N \to \infty} \int_0^1 F_N(x) G(x)\; dx\\
			&= \lim_{N \to \infty} \int_{-N}^{N+1} f(x) G(x)\; dx\\
			&= \int_{-\infty}^\infty f(x) G(x)\; dx.
		\end{align*}
	\end{solution}
\end{parts}
    
\question (September, 2015) Let $a_1, a_2, \dots$ be a sequence of positive real numbers and assume that
%
\[ \lim_{n \to \infty} \frac{a_1 + \dots + a_n}{n} = 1. \]
\begin{parts}
	\part Show that $\lim_{n \to \infty} a_n n^{-1} = 0$.
	\begin{solution}
		We can extract the value $a_n/n$ from the sequence $\{ S_n/n \}$, since
		%
		\[ \frac{a_n}{n} = \frac{S_n}{n} - \frac{n-1}{n} \frac{S_{n-1}}{n-1}. \]
		%
		Thus
		%
		\[ \lim_{n \to \infty} a_n/n = \lim_{n \to \infty} \frac{S_n}{n} - \lim_{n \to \infty} \frac{n-1}{n} \frac{S_{n-1}}{n-1} = 1 - 1 = 0. \]
	\end{solution}

	\part If $b_n = \max(a_1,\dots,a_n)$, show that $\lim_{n \to \infty} b_n n^{-1} = 0$.
	\begin{solution}
		We have
		%
		\[ b_n/n = \max(1/n \cdot a_1/1, 2/n \cdot a_2/2, \dots, (n/n) \cdot (a_n/n)). \]
		%
		Fix $\varepsilon > 0$. There exists $N > 0$ such that for $n \geq N$, $|a_n/n| \leq \varepsilon$. Thus if $A = \max(a_1/1, \dots, a_N/N)$, we conclude that for $M \geq N$,
		%
		\[ b_M/M \leq \max(AN/M, \varepsilon). \]
		%
		Thus if $M \geq AN/\varepsilon$, $b_M/M \leq \varepsilon$.
	\end{solution}

	\part Show that
	%
	\[ \lim_{n \to \infty} \frac{a_1^\beta + \dots + a_n^\beta}{n^\beta} = \begin{cases} 0 &: \beta > 1 \\ \infty &: \beta < 1. \end{cases}. \]
	\begin{solution}
		For $\beta > 1$, we have
		%
		\[ \frac{a_1^\beta + \dots + a_n^\beta}{n^\beta} = \frac{a_1 a_1^{\beta - 1} + \dots + a_n a_n^{\beta - 1}}{n^\beta} \leq \frac{a_1 + \dots + a_n}{n} \max(a_1/n, \dots, a_n/n)^{\beta - 1} \leq (S_n/n) \cdot (b_n/n)^\beta. \]
		%
		Thus
		%
		\[ \lim_{n \to \infty} \frac{a_1^\beta + \dots + a_n^\beta}{n^\beta} = \lim_{n \to \infty} (S_n / n) \cdot ( \lim_{n \to \infty} b_n/n )^\beta = 1 \cdot 0 = 0. \]

		To prove the result for $\beta < 1$, we notice that for suitably large $n$, we have $a_k/n \ll 1$ for $1 \leq k \leq n$. But this implies that $(a_k/n)^\beta \gg a_k/n$, which implies
		%
		\[ \frac{a_1^\beta + \dots + a_n^\beta}{n^\beta} \gg \frac{a_1 + \dots + a_n}{n} \approx 1. \]
		%
		More precisely, if $\delta > 0$, then there exists $n_0$ such that for $n \geq n_0$, and $1 \leq k \leq n$, $a_k/n \leq \delta$, and $S_n/n \geq 1/2$. But this implies that
		%
		\[ (a_k/n)^\beta = (a_k/n) (a_k/n)^{\beta - 1} \geq \delta^{\beta - 1} (a_k/n). \]
		%
		Thus
		%
		\[ \frac{a_1^\beta + \dots + a_n^\beta}{n^\beta} = (a_1/n)^\beta + \dots + (a_n/n)^\beta \geq \delta^{\beta - 1} \frac{a_1 + \dots + a_n}{n} \geq \delta^{\beta - 1} / 2. \]
		%
		Taking $\delta \to 0$ completes the proof.
	\end{solution}
\end{parts}
    
\newpage
\section{\centering Day 2: Basic Analysis}

\question (Jan 2017 \#1, Jan 2011 \#3, cf Jan 2007 \#3)
Show that the sequence of functions
  \begin{equation*}
    S_{n}(x)= \sum_{k=1}^{n}\frac{\sin(kx)}{k}, \quad \quad n=1,2,3,\ldots,
  \end{equation*}
  is uniformly bounded in $\R$.
\begin{solution}
\bnote{Hint: Summation by parts. Break the sum into two parts for $kx\leq 1$ and $kx>1$ respectively.}



The idea is to use Summation by Parts, also known as Abel's lemma, which says the following:

Let $a_{k},b_{k}$ be two sequences of real numbers, and denote $T_{k} = \sum_{k=1}^{n}a_{k}$ as the partial sum of $a_{k}$. Then we have:
\begin{equation*}
  \sum_{k=m}^{n}a_{k}b_{k} = \sum_{k=m}^{n}\left( T_{k}-T_{k-1} \right)b_{k} = \sum_{k=m}^{n}T_{k}b_{k}-\sum_{k=m}^{n}T_{k-1}b_k = T_{n}b_{n} - T_{m-1}b_{m} + \sum_{k=m}^{n-1}T_{k}\left( b_{k}-b_{k+1} \right).
\end{equation*}

A solution which uses Summation by Parts is the following. First break the sum into two parts: fix $x\in\R$ and let $N$ be the largest integer such that $N|x|<1$, (so we also have $(N+1)|x|\geq 1$).

Write $\sum_{k=1}^{n}\frac{\sin(kx)}{k}= S_{1}+S_{2}$, where $S_{1} = \sum_{k=1}^{N}\frac{\sin(kx)}{k}$ and $S_{2} = \sum_{k=N+1}^{n}\frac{\sin(kx)}{k}$.

\begin{equation*}
  |S_{1}| = \left| \sum_{k=1}^{N}\frac{\sin(kx)}{k} \right|\leq \sum_{k=1}^{N}\frac{|kx|}{k}\leq N|x|<1.
\end{equation*}
To estimate $S_{2}$, we use summation by parts. Let $T_{k}= \sum_{j=1}^{k}\frac{\sin(jx)}{j}$. Then
\begin{equation*}
  |S_{2}| = \left| \sum_{k=N+1}^{n}\frac{\sin(kx)}{k} \right|
          = \left| \frac{T_{n}}{n}-\frac{T_{N}}{N+1} + \sum_{k=N+1}^{n-1}T_{k}\left(\frac{1}{k}-\frac{1}{k+1}  \right) \right|
          \leq 2 + \left| \sum_{k=N+1}^{n-1}\frac{T_{k}}{k(k+1)} \right|.
\end{equation*}
To estimate the second term, we need to estimate $T_{k}$ first. Indeed, let $x\in[0,\pi]$. Then we have:
\begin{equation*}
  |T_{k}| = \left| \sum_{j=1}^{k}\sin(jx) \right| = \left| \text{Im} \left( \sum_{j=1}^{k}e^{ijx} \right) \right|\leq \left|\frac{ e^{ix}(1-e^{ikx})}{1-e^{ix}}\right| \leq \left|\frac{1}{\sin(x/2)}\right| \leq \frac{\pi}{x}
\end{equation*}
The last inequality follows from the fact that $\sin(x)/x$ is a decreasing function on the interval $[0,\pi]$.

Now we finish our estimate of $S_{2}$. Notice that $\left|\frac{T_{n}}{n}\right|\leq 1$ and $\left| \frac{T_{N}}{N+1} \right|\leq 1$, and the term:
\begin{equation*}
  \left| \sum_{k+N+1}^{n-1} \frac{T_{k}}{k(k-1)}\right| \leq \frac{\pi}{|x|}\cdot \sum_{k=N+1}^{n-1}\frac{1}{k}-\frac{1}{k+1}\leq \frac{\pi}{|x|}\cdot 2 \cdot \frac{1}{N+1}\leq 2\pi
\end{equation*}
where the last inequality follows from our choice of $N$, since we chose $N$ such that $|x|(N+1)\geq 1$, which implies that $\frac{1}{|x|}\leq N+1$.

Thus we see that $|S_{2}|\leq 2+ 2\pi$. This upper bound is independent of $x\in [0,\pi]$ and $n$. In the case of $x\in [\pi,2\pi]$, simply notice that $S(x)=-S(2\pi-x)$.

An alternate approach is to employ Fourier analysis + a Tauberian theorem, though this uses tools which are beyond the scope of the prerequisites of the qualifying exam, though the proof may be of interest for those who know some basic Fourier analysis. The sums here are the partial Fourier series corresponding to the Fourier coefficients of a bounded, $2 \pi$-periodic function $f(x)$ on $[0,2\pi]$ (it is not necessary to know the function, but it is a constant multiple of the function
%
\[ x \mapsto \begin{cases} -\pi/2 - x/2 &: -\pi < x < 0 \\ +\pi/2 - x/2 &: 0 < x < \pi \end{cases} \]
%
It follows that $S_n = D_n * f$, where $D_n$ is the \emph{Dirichlet kernel}. If $\| D_n \|_{L^1((0,2\pi))}$ was uniformly bounded in $n$, we could apply Young's inequality, implying
%
\[ \| S_n \|_{L^\infty((0,2\pi))} \leq \| D_n \|_{L^1((0,2\pi))} \| f \|_{L^\infty(0,2\pi))} \lesssim 1. \]
%
Unfortunately, we have $\| D_n \|_{L^1((0,2\pi))} \sim \log(n)$, so this approach doesn't work completely. But there is a general result for functions $f$ such that $\widehat{f}(n) \lesssim 1/n$, known as a \emph{Tauberian theorem}, which shows that $D_n * f$ is uniformly bounded in $n$ if and only if $P_r * f$ is bounded as $r \to 1$, where $\{ P_r \}$ is the \emph{Poisson kernel}. Since $\| P_r \|_{L^1((0,2\pi))} \lesssim 1$ for $0 < r < 1$, we can use Young's inequality to conclude that $\| P_r * f \|_{L^\infty((0,2\pi))} \lesssim 1$. Thus $P_r * f$ is uniformly bounded in $r$, and thus $D_n * f$ is uniformly bounded, completing the proof.

\end{solution}


\question (August, 2015) Consider the series
%
$$ \sum_{n = 1}^\infty \frac{1}{\sqrt{n}} \sin(x/n). $$
%
\begin{parts}
	\part Show that the series converges pointwise to some function $f$ on $\RR$.
	\begin{solution}
		The main idea to understanding the sum is to use the bound $|\sin(y)| \leq |y|$, which is tight when $|y| \leq 1$. Thus little is lost in our estimates if we apply this bound in the sum above for $|n| \geq |x|$.

		We will actually find this sum converges absolutely, locally uniformly in $x$. Indeed, plugging in the bound $|\sin(x)| \leq |x|$, we find that
		%
		\[ \sum_{n = 1}^\infty \left| \frac{1}{\sqrt{n}} \sin(x/n) \right| \leq \sum_{n = 1}^\infty \frac{1}{\sqrt{n}} \frac{|x|}{n} = |x| \sum_{n = 1}^\infty \frac{1}{n^{3/2}} \lesssim |x|. \]
		%
		Since the sum converges pointwise absolutely, it must converge pointwise.
	\end{solution}

	\part Is $f$ continuous on $\RR$? Does $f'(x)$ exist for all $x \in \RR$?
	\begin{solution}
		To see that $f$ is continuous, it suffices to show that the partial sums
		%
		\[ f_N(x) = \sum_{n = 1}^N \frac{1}{\sqrt{n}} \sin(x/n) \]
		%
		converge \emph{locally uniformly} in $x$ to $f$, since the limit of a sequence of continuous functions converging locally uniformly is continuous. But employing the bound $|\sin(x)| \leq |x|$ as above, we find that for $M > N$,
		%
		\[ |f_M(x) - f_N(x)| \leq \sum_{n = N+1}^M \left| \frac{1}{\sqrt{n}} \sin(x/n) \right| \leq |x| \sum_{n = N+1}^M 1/n^{3/2} \lesssim |x| / N^{1/2}. \]
		%
		But this equation implies locally uniform convergence, i.e. for any interval $I = [-K,K]$, we have proved that
		%
		\[ \| f_M - f_N \|_{L^\infty(I)} \lesssim K/N^{1/2}. \]
		%
		Thus $f$ is a continuous function.

		Now to understand the differentiability of $f$, it makes sense to look at the derivatives
		%
		\[ f_N'(x) = - \sum_{n = 1}^N (1/n^{3/2}) \cos(x/n). \]
		%
		Since the cosine term is uniformly bounded in $x$ and $n$, it is fairly negligible to studying the limit of this quantity as $N \to \infty$. Indeed, we find that for $M > N$, we can plug in the bound $|\cos(y)| \leq 1$ to conclude that
		%
		\[ |f_M'(x) - f_N'(x)| \leq \sum_{n = N+1}^M 1/n^{3/2} \lesssim N^{-1/2}. \]
		%
		Thus $\| f_M - f_N \|_{L^\infty(\RR)} \lesssim N^{-1/2}$, which implies the sequence is uniformly cauchy, and thus converges to some function $g$. But it is a general rule that if $\{ f_N \}$ converges locally uniformly to some function $f$, and $\{ f_N' \}$ converges locally uniformly to some function $g$, then $f$ is differentiable, and $f' = g$. Thus $f$ is differentiable.

		An alternative, but less clean way to show $f$ is differentiable is using the definition of the derivative, i.e. by proving that for each $x \in \RR$, the limit
		%
		\[ \lim_{h \to 0} \frac{f(x + h) - f(x)}{h} = \lim_{h \to 0} \sum_{n = 1}^\infty \frac{1}{\sqrt{n}} \frac{\sin((x + h)/n) - \sin(x/n)}{h}. \]
		%
		exists. One way to do this is to write
		%
		\[ \lim_{h \to 0} \frac{f(x + h) - f(x)}{h} = \lim_{h \to 0} \frac{f_N(x + h) - f_N(x)}{h} + \lim_{h \to 0} \sum_{n = N+1}^\infty \frac{1}{\sqrt{n}} \frac{\sin((x + h)/n) - \sin(x/n)}{h}. \]
		%
		Since $f_N$ is differentiable, the first limit is easily shown to exist. One might understand the second sum by using the mean value theorem to conclude that $|\sin((x + h)/n) - \sin(x/n)| \lesssim |h| / n$, thus obtaining that
		%
		\[ \limsup_{h \to 0} \left| \sum_{n = N+1}^\infty \frac{1}{\sqrt{n}} \frac{\sin((x + h)/n) - \sin(x/n)}{h} \right| \lesssim 1/N^{1/2}. \]
		%
		This means that
		%
		\[ \limsup_{h \to 0} \frac{f(x + h) - f(x)}{h} - \liminf_{h \to 0} \frac{f(x + h) - f(x)}{h} \lesssim 1/N^{1/2}. \]
		%
		Taking $N \to \infty$ shows that $\liminf = \limsup$, so that the limit exists, and thus $f$ is differentiable.
	\end{solution}

	\part Does the series converge uniformly on $\RR$?
	\begin{solution}
		The bounds in part (a) of the problem, which depend on $x$, should hint to you that the series does \emph{not} converge uniformly in $x$, in particular, as we take $x$ to be very large. To show that the sum does not converge uniformly, we need lower bounds, and to do this we again employ the heuristic that $|\sin(y)| \leq |y|$ is a good estimate for $|y| \leq 1$, so we should get a similar estimate which lower bounds $\sin(y)$ in this range. In fact, for $0 \leq y \leq 1$ we actually have $\sin(y) \geq y/2$. Concentrating on the case where $x$ is a positive integer for simplicity, we find that
		%
		\[ \sum_{n \geq x} \frac{1}{\sqrt{n}} \sin(x/n) \gtrsim \sum_{n \geq x} \frac{x}{n^{3/2}} \gtrsim \sqrt{x}. \]
		%
		Thus if $N = x$, we can reword this inequality as saying that
		%
		\[ \lim_{M \to \infty} f_M(x) - f_N(x) \gtrsim \sqrt{x}. \]
		%
		Thus
		%
		\[ \limsup_{M \to \infty} \| f_M - f_N \|_{L^\infty(\RR)} \gtrsim \sqrt{N}. \]
		%
		In particular, this implies $\{ f_N \}$ is not a Cauchy sequence in $L^\infty(\RR)$, and thus does not converge uniformly.

		Alternatively, we can use the fact that if $\pi/3 \leq y \leq 2\pi/3$, then $\sin(y) \geq 1/2$. Thus, for any $N$, if we pick $x = (\pi/3)N$, then for $1 \leq n \leq N$, $\sin(x/n)$ is non-negative, and for $N/2 \leq n \leq N$, $\sin(x/n) \geq 1/2$, so
		%
		\[ |f_N(x)| \gtrsim \sum_{N/2 \leq n \leq N} 1/\sqrt{n} \gtrsim \sqrt{N}. \]
		%
		Thus $\| f_N \|_{L^\infty(\RR)} \gtrsim \sqrt{N}$, which implies $\{ f_N \}$ is not bounded in $L^\infty(\RR)$, and so $\{ f_N \}$ is not a Cauchy suquence in $L^\infty(\RR)$.
	\end{solution}
\end{parts}

\question (September, 2019) Show that if $K \subset \RR^n$, and every continuous function on $K$ is bounded, then $K$ is compact.
\begin{solution}
	It suffices to show that $K$ is bounded and closed.

	If $K$ was not closed, then we could find $y \in \overline{K} - K$. The function $f(x) = 1/d(x,y)$ would then be continuous, but not bounded, on $K$. Thus $\overline{K} - K$ is empty, so $\overline{K} = K$.

	If $K$ was not bounded, then $f(x) = |x|$ would be a continuous, unbounded function. Thus $K$ is bounded.

	Thus $K$ is compact.
\end{solution}

\question (January, 2015) Prove that the integral
%
\[ f(a) = \int_0^\infty \frac{\sin(x^2 + ax)}{x}\; dx \]
%
converges for $a \geq 0$, and $f$ is continuous on $[0,\infty)$.
\begin{solution}
	Let
	%
	\[ f_0(a) = \int_0^1 \frac{\sin(x^2 + ax)}{x}\; dx. \]
	%
	We perform a dyadic decomposition, writing, for $n \in \ZZ$,
	%
	\[ f_n(a) = \int_{2^n}^{2^{n+1}} \frac{\sin(x^2 + ax)}{x}\; dx. \]
	%
	Then $f = \sum_{n = 0}^\infty f_n$. Since the integrand is continuous, and each integral is on a finite interval, all of the functions $\{ f_n \}$ are continuous.

	We claim this sum converges locally uniformly. To do this we \emph{must} exploit the oscillation in the integrand, for $1/x$ is not summable. To do this, we perform an integration by parts. Indeed, for $a \geq 0$,
	%
	\begin{align*}
		\int_{2^n}^{2^{n+1}} \frac{\sin(x^2 + ax)}{x} &= \int_{2^n}^{2^{n+1}} \frac{d}{dx} \left( \cos(x^2 + ax) \right) \cdot \frac{-1}{x(2x + a)}\\
		&= \left( \int_{2^n}^{2^{n+1}} \frac{\cos(x^2 + ax)}{x(2x + a)} \right) + O(1/2^n)\\
		&\leq \int_{2^n}^{2^{n+1}} \frac{1}{x(2x + a)} + O(1/2^n)\\
		&\lesssim 1/2^n.
	\end{align*}
	%
	Thus $\| f_n \|_{L^\infty[0,\infty)} \lesssim 1/2^n$. Thus $\{ f_n \}$ is uniformly summable, and so $f = \sum f_n$ exists, and is continuous for $a \geq 0$.
\end{solution}

\question (September, 2017) Consider the sequence of functions $f_n: \RR \to \RR$ defined by
%
\[ f_n(x) = \int_0^n \frac{\sin(sx)}{\sqrt{s}}\; ds. \]
%
\begin{parts}
	\part Show that $\{ f_n \}$ converges locally uniformly on $(0,\infty)$.
	\begin{solution}
		This integral can only converge because of the oscillation of $\sin(sx)$ for large $x$. Thus we integrate by parts, writing
		%
		\begin{align*}
			\int_{n_0}^{n_1} \frac{\sin(sx)}{\sqrt{s}}\; ds &= \int_{n_0}^{n_1} \frac{- d/ds (\cos(sx))}{x \sqrt{s}}\; ds\\
			&= \left. \frac{- \cos(sx)}{x s^{1/2}} \right|^{n_1}_{n_0} + \int_{n_0}^{n_1} \frac{\cos(sx)}{x s^{3/2}} (-1/2)\; ds\\
			&= O(1/xn_0^{1/2}) + O(1/x \int_{n_0}^{n_1} 1/s^{3/2}\; ds)\\
			&= O(1/xn_0^{1/2}).
		\end{align*}
		%
		Thus for any fixed $\alpha > 0$, we get uniform convergence for $\alpha < x < \infty$.
	\end{solution}

    
	\part Show that $\{ f_n \}$ does \emph{not} converge uniformly on $(0,1]$.
	\begin{solution}
		If the convergence was uniform, there would be $n_0$ such that for any $n_1 \geq n_0$, and $x \in [0,1)$,
		%
		\[ \left| \int_{n_0}^{n_1} \frac{\sin(sx)}{\sqrt{s}}\; ds \right| \leq 1. \]
		%
		Now pick $x \sim 1/n$, such that for $s \in [n_0,n_1]$, $\sin(sx) \geq sx/2$. Then
		%
		\[ 1 \geq \int_{n_0}^{n_1} \frac{\sin(sx)}{\sqrt{s}}\; ds \geq \frac{x}{2} \int_{n_0}^{n_1} \sqrt{s}\; ds \gtrsim n_1^{3/2} x \gtrsim n_1^{1/2}. \]
		%
		This gives a contradiction for sufficiently large $n_1$.
	\end{solution}

	\part Does the sequence $\{ f_n \}$ converge uniformly on $[1,\infty)$ as $n \to \infty$?
\end{parts}

\newpage
\section{\centering Day 3: Basic Analysis}


\question (Aug 2018 \#2) 
Prove that for $1\leq p \leq 2$ and $0<b<a$, $$(a+b)^p + (a-b)^p \geq 2a^p + p(p-1)a^{p-2}b^2.$$

\begin{solution}
\bnote{Hint: Taylors theorem}
  By subtracting the right-hand side, factoring out $a^p$, and noting that $0<b/a<1$, it suffices to show that the function
  \begin{equation*}
    f(x) = \left( 1+x \right)^{p} + \left( 1-x \right)^{p} - 2 - p(p-1)x ^{2}
  \end{equation*}
  is nonnegative for all $x\in (0,1)$. Let $g(x) = (1+x)^p$, so that
  \begin{equation*}
    f(x) = g(x)+ g(-x) -2 - p(p-1)x^{2}.
  \end{equation*}
  We next Taylor expand $g$ about the point $0$.
  For any $x>-1$, we have
  \begin{equation*}
    g(x) = 1 + px + \frac{1}{2}p(p-1)x^{2} + R_{2}(x)
  \end{equation*}
  where
  \begin{equation*}
    R_{2}(x)= \frac{1}{6}p(p-1)(p-2)(1+\xi)^{p-3}x^{3}
  \end{equation*}
  for some number $\xi$ between $0$ and $x$. Substituting the Taylor expansions for $g(x)$ and $g(-x)$ into the formula for $f$ gives
  \begin{equation*}
    f(x) = R_{2}(x) + R_{2}(-x)
  \end{equation*}
  or equivalently
  \begin{equation*}
    f(x) = \frac{1}{6}p(p-1)(p-2)\left[(1+\xi_{+})^{p-3}-(1+\xi_{-})^{p-3}\right]x^{3}
  \end{equation*}
  for some $\xi_{+}\in(0,x)$ and $\xi_{-}\in(-x,0)$. Since $\xi_{-}<\xi_{+}$ and $p<3$, the part in brackets is negative, and since $0\leq p \leq 2$, it follows that $f(x)$ is nonnegative, as required.
\end{solution}

\question (Jan 2018 \#1, Jan 2021 \#1)
  Determine if
  \begin{equation*}
    \sum_{k=1}^{\infty}\frac{\cos(\sqrt{k})}{k}
  \end{equation*}
  converges.


\begin{solution}
\bnote{Hint: integration by parts, mean value theorem}
Yes, the series converges. We first claim that the integral $\int_{1}^{\infty}\frac{\cos(x^{1/2})}{x}dx$ converges. To see this, we use integration by parts:
  \begin{align*}
    \int_{1}^{\infty}\frac{\cos(x^{1/2})}{x}dx
    &= \int_{1}^{\infty}2x^{-1/2}\frac{d}{dx}\left[ \sin(x^{1/2}) \right]dx\\
    &= -2\sin(1)+ \int_{1}^{\infty}\frac{\sin(x^{1/2})}{x^{3/2}}dx<\infty.
  \end{align*}
  This proves the claim. Next we claim that $\sum_{k=1}^{n} \frac{\cos(\sqrt{k})}{k}$ is a Cauchy sequence (and therefore converges as $n\to\infty$). To prove this, it suffices by the previous claim to show that for every $\epsilon>0$ there exists $N$ such that $m,n>N$ implies 
  \begin{equation}\label{partial-sum-difference}
    \left|\sum_{k=m}^{n}\frac{\cos(\sqrt{k})}{k} - \int_{m}^{n+1}\frac{\cos(\sqrt{x})}{x}dx\right|<\epsilon.
  \end{equation}
  Let $1\leq n \leq m$. Then
  \begin{equation}\label{eq:series-integral}
    \sum_{k=m}^{n}\frac{\cos(\sqrt{k})}{k} - \int_{m}^{n+1}\frac{\cos(\sqrt{x})}{x}dx
    = \sum_{k=m}^{n}\int_{k}^{k+1}\(\frac{\cos(\sqrt{k})}{k} - \frac{\cos(\sqrt{x})}{x}\)dx.
  \end{equation}
  By the Mean Value Theorem, since $\frac{d}{dx}\left[ \frac{\cos(x^{1/2})}{x} \right]= -\frac{\cos(x^{1/2})}{x^{2}} - \frac{\sin(x^{1/2})}{2x^{3/2}}$, it follows that for every $x\in [k,k+1]$, there exists some $\xi\in (x,k+1)$ such that
  \begin{equation*}
    \frac{\cos(\sqrt{k})}{k} - \frac{\cos(\sqrt{x})}{x} \leq \frac{1}{\xi^{2}}+ \frac{1}{2\xi^{3/2}}
  \end{equation*}
  and since $\xi \geq k$,
  \begin{equation*}
     \frac{\cos(\sqrt{k})}{k} - \frac{\cos(\sqrt{x})}{x} \leq\frac{1}{k^{2}} + \frac{1}{2k^{3/2}}.
   \end{equation*}
   Therefore
  \begin{equation*}
    \left|\int_{k}^{k+1}\(\frac{\cos(\sqrt{k})}{k} - \frac{\cos(\sqrt{x})}{x}\)dx\right| \leq  \frac{1}{k^{2}} + \frac{1}{2k^{3/2}}
  \end{equation*}
  Therefore using equation \eqref{eq:series-integral},
  \begin{equation*}
    \left| \sum_{k=m}^{n}\frac{\cos(\sqrt{k})}{k} - \int_{m}^{n+1}\frac{\cos(\sqrt{x})}{x}dx \right| \leq \sum_{k=m}^{n}\frac{1}{k^{2}} + \frac{1}{2k^{3/2}}
  \end{equation*}
  Since the series on the right hand side is summable, it tends to zero as $m,n\to\infty$, which establishes \eqref{partial-sum-difference}.
\end{solution}

\question (January, 2015) Let $g$ be a non-constant differentiable real function on a finite interval $[a,b]$, with $g(a) = g(b) = 0$. Show that there exists $c \in (a,b)$ such that
%
\[ |g'(c)| > \frac{4}{(b - a)^2} \int_a^b |g(t)|\; dt. \]
\begin{solution}
	My main intuition is that the fundamental theorem of calculus enables us to relate $g'$ and $g$. If we are clever about using the fundamental theorem, we obtain the bound, namely
	%
	\begin{align*}
		\int_a^b |g(t)|\; dt &= \int_a^b \min \left( \left| \int_a^t g'(s)\; ds \right|, \left| \int_t^b g'(s) \right| \right)\; dt\\
		&\leq \max_{a < c < b} |g'(c)| \cdot \int_a^b \min(|t - a|, |t - b|)\; dt\\
		&= \max_{a < c < b} |g'(c)| \cdot \left( \int_a^{(a + b)/2} (t - a)\; dt + \int_{(a + b)/2}^b (b - t)\; dt \right)\\
		&= \max_{a < c < b} |g'(c)| \cdot \left( (b - a)^2/8 + (b - a)^2/8 \right)\\
		&= \max_{a < c < b} |g'(c)| \cdot (b-a)^2/4.
	\end{align*}
	%
	Rearranging this inequality completes the proof, except in the case that all the inequalities in this calculation are equalities (so we cannot get the strict inequality required). But this only holds if $g'$ is a constant function, hence $g$ is linear, which is impossible since $g$ is non constant, and $g(0) = g(1) = 0$.
\end{solution}

\question (September, 2019) If $f: \RR^n \to \RR$ is differentiable on $\RR^n - \{ 0 \}$, continuous at 0, and
%
\[ \lim_{x \to 0} \frac{\partial f}{\partial x^i}(x) = 0, \]
%
for $1 \leq i \leq n$, then $f$ is differentiable at 0.
\begin{solution}
	We claim that $\nabla f(0) = 0$, i.e. that $|f(x) - f(0)| = o(|x|)$ as $x \to 0$. To see this, we apply the mean value theorem. Assume without loss of generality that $f(0) = 0$. Fix $\varepsilon > 0$. For any $x \in \RR^n - \{ 0 \}$, since $f$ is continuous at $0$, there is $\lambda_0 \leq 1/2$ depending only on $|x|$ such that
	%
	\[ |f(\lambda_0 x)| \leq |x|^2. \]
	%
	Now we apply the mean value theorem, writing $g(\lambda) = f(\lambda x)$. The mean value theorem implies that there is $\lambda \in (\lambda_0, 1)$ such that
	%
	\[ g'(\lambda) = \frac{f(x) - f(\lambda_0 x)}{1 - \lambda_0}. \]
	%
	But
	%
	\[ g'(\lambda) = \sum_{i = 1}^n \frac{\partial f}{\partial x^i}(\lambda x) \cdot x_i. \]
	%
	If $|x|$ is suitably small, then $|\frac{\partial f}{\partial x^i}(\lambda x)| \leq \varepsilon$, which implies that
	%
	\[ |f(x) - f(\lambda_0 x)| \leq 2 \left| \frac{f(x) - f(\lambda_0 x)}{1 - \lambda_0} \right| \lesssim \varepsilon |x|. \]
	%
	Thus
	%
	\[ |f(x)| \leq |f(\lambda_0 x)| + 2 \varepsilon |x| \leq |x|^2 + \varepsilon |x|. \]
	%
	Thus if $|x|$ is suitably small, we conclude that $|f(x)| \lesssim \varepsilon |x|$. Since $\varepsilon$ was arbitrary, this shows that $f$ is differentiable at zero, and $\nabla f(0) = 0$.
\end{solution}




\question (January, 2017) For any pair of sequences $\{ a_k \}$ and $\{ b_n \}$, show that
%
\[ \sum_{n = 1}^\infty \sum_{m = 1}^\infty \frac{a_n b_m}{n + m} \lesssim \left( \sum_{n = 1}^\infty a_n^2 \right)^{1/2} \left( \sum_{m = 1}^\infty b_m^2 \right)^{1/2}. \]
\begin{solution}
	This is a hard problem, with the simplest proof relying on some clever applications of Cauchy-Schwartz. Fix $\lambda$, and write
	%
	\[ a_{nm} = \frac{a_n}{\sqrt{m + n}} (n/m)^\lambda \quad\text{and}\quad b_{nm} = \frac{b_m}{\sqrt{m + n}} (m/n)^\lambda. \]
	%
	Then Cauchy-Schwartz implies that
	%
	\[ \sum_{n,m} \frac{a_n b_m}{n + m} = \sum_{n,m} a_{nm} b_{nm} \leq \left( \sum_{n,m} a_{nm}^2 \right)^{1/2} \left( \sum_{n,m} b_{nm}^2 \right)^{1/2}. \]
	%
	Now
	%
	\begin{align*}
		\sum_{n,m} a_{nm}^2 &= \sum_{n = 1}^\infty a_n^2 \sum_{m = 1}^\infty \frac{(n/m)^{2\lambda}}{n + m}\\
		&= \sum_{n = 1}^\infty a_n^2 n^{2\lambda} \sum_{m = 1}^\infty \frac{1}{m^{2\lambda} (n + m)}. 
	\end{align*}
	%
	Now
	%
	\begin{align*}
		\sum_{m = 1}^\infty \frac{1}{m^{2\lambda} (n + m)} &\lesssim \frac{1}{n} \sum_{m = 1}^n \frac{1}{m^{2\lambda}} + \sum_{m = n+1}^\infty \frac{1}{m^{1 + 2\lambda}}\\
		&\lesssim \frac{1}{n^{2\lambda}}
	\end{align*}
	%
	Thus
	%
	\[ \left( \sum_{n,m} a_{nm}^2 \right) \lesssim \sum_{n = 1}^\infty a_n^2. \]
	%
	Similarily, one can show
	%
	\[ \left( \sum_{n,m} b_{nm}^2 \right) \lesssim \sum_{n = 1}^\infty b_n^2. \]
	%
	Combining these estimates completes the proof.

	If one is less sneaky, but knows more analysis, there is an alternate, much more technical proof. If we consider the operator $T$, mapping a sequence $a(n)$ to a sequence $(Ta)(m)$ such that
	%
	\[ (Ta)(m) = \sum_{n = 1}^\infty \frac{a_n}{n+m}, \]
	%
	then the bound holds if and only if $T$ is bounded from $l^2(\mathbf{N})$ to $l^2(\mathbf{N})$. For $1 < p < \infty$, one can show that if $a$ is the \emph{indicator function} of some finite set $E \subset \{ 1, \dots, \infty \}$, then we can show that
	%
	\[ \left( \sum_{m = 1}^\infty |Ta(m)|^p \right)^{1/p} \lesssim_p \#(E)^{1/p}. \]
	%
	Indeed, if $N = \#(E)$, then it is simple to see that $Ta \leq Ta^*$, where $a^*$ is the indicator function of $\{ 1, \dots, N \}$, and so one needs only estimate $Ta^*$, and it is not too difficult to show that $\| Ta^* \|_{L^p} \lesssim_p \#(E)^{1/p}$ for $1 < p < \infty$. This is known as a \emph{restricted} estimate. Standard techniques in the theory of real interpolation thus imply that
	%
	\[ \left( \sum_{m = 1}^\infty |Ta(m)|^2 \right)^{1/2} \lesssim \left( \sum_{n = 1}^\infty |a(n)|^2 \right)^{1/2}, \]
	%
	which completes the argument.
\end{solution}
    

\newpage
\section{Day 4: Measure Theory}

\question  (Jan 2021 \#2, Jan 2016 \#4)
  Let $E\subset \R$ be a Lebesgue measurable set with $|E|<\infty$. Prove that the function $f:\R\to \R$ defined by $f(r)= |E\cap (E+r)|$ is continuous
\begin{solution}
    %It suffices to prove that for all $s$,
    %
    %\[ \lim_{r \to s} f(r) = f(s). \]
    %
    %Now
    %
    %\[ f(r) - f(s) = \int \mathbf{I}_E(x) [\mathbf{I}_E(x + r) - \mathbf{I}_E(x + s)]. \]
    %
    %As $r \to s$, the integrand tends to zero pointwise. And moreover, the integrands are uniformly dominated by $2\mathbf{I}_E$, which is an integrable function. Thus the dominated convergence theorem implies that
    %
    %\[ \lim_{r \to s} f(r) - f(s) = 0. \]
    %
    %Thus $f$ is a %continuous function.

  Let $\epsilon>0$. Since $E$ is measurable and $|E|<\infty$, $\chi_{E}$ is integrable. Since $C_{c}(\R)$ is dense in $L^{1}(\R)$, there exists $g\in C_{c}(\R)$ such that $\norm{g-\chi_{E}}_{L^{1}(\R)}<\epsilon/3$. Since $g$ is continuous and compactly supported, it is unformly continuous. Therefore (again using the fact that $|E|<\infty$) we may choose $\delta>0$ such
  \begin{equation}
    |g(x)-g(y)|< \frac{\epsilon}{3|E|}\label{eq:uniform-continuity}
  \end{equation}
  whenever $|x-y|<\delta$.
Let $r,s\in \R$ such that $|s-r|<\delta$. Writing $f(r)= \int_{\R}\chi_{E}(x)\chi_{E}(x-r)dx$, we have
\begin{align*}
  f(r)-f(s) & = \int_{\R}\chi_{E}(x)\left[\chi_{E}(x-r)-\chi_{E}(x-s)\right]dx\\
            & = \int_{\R}\chi_{E}(x)\left[\chi_{E}(x-r)-g(x-r)+g(x-r)-g(x-s)+g(x-s)-\chi_{E}(x-s)\right]dx.
\end{align*}
Therefore by the triangle inequality,
\begin{align*}
  |f(r)-f(s)| &\leq \int_{\R}\chi_{E}(x)|\chi_{E}(x-r)-g(x-r)|dx + \int_{\R}\chi_{E}(x)|g(x-r)-g(x-s)|dx \\ 
  &\quad +\int_{\R}\chi_{E}|g(x-s)-\chi_{E}(x-s)|dx.\\
              &\leq \int_{\R}|\chi_{E}(x-r)-g(x-r)|dx + \int_{E}|g(x-r)-g(x-s)|dx \\\quad &+\int_{\R}|g(x-s)-\chi_{E}(x-s)|dx.
\end{align*}
By translation invariance (i.e. do a u-substitution), the first and third integrals both equal  $\int_{\R}|\chi_{E}(x)-g(x)|dx < \epsilon/3$. By \eqref{eq:uniform-continuity}, the second integral is less than $\epsilon/3$. Therefore $|f(r)-f(s)|<\epsilon$. We have shown that $\delta$ responds to the $\epsilon$-challenge in the definition of continuity. Therefore $f$ is continuous.
\end{solution}



\question (January, 2015) Does there exists a Borel measurable function $f: \RR \to [0,\infty)$ such that
%
\[ \int_a^b f(x)\; dx = \infty \]
%
for all real numbers $a < b$. Find an example or show that no such function exists.
\begin{solution}
    Here I construct such a function. There are many ways of doing this. We note that it suffices to construct such a function $f: [0,1] \to [0,\infty)$, since one can piece together a Borel measurable function on $\RR$ by patching together translates of this function.
    
    For each rational number $x \in [0,1]$ expressed in the simplest form as $p/q$, let $E_x = \{ y \in \RR: |y - p/q| \leq 1/q^3 \}$. Then
    %
    \[ \sum_{x \in \mathbf{Q} \cap [0,1]} |E_x| \leq \sum_{q = 1}^\infty \sum_{p = 1}^q 2/q^3 = \sum_{q = 1}^\infty 2/q^2 < \infty. \]
    %
    The Borel-Cantelli lemma implies that $E = \limsup_x E_x$ is a set of measure zero. We set
    %
    \[ f(x) = \mathbf{I}(x \not \in E) \sum_{p/q \in \mathbf{Q} \cap [0,1]} q^4 \cdot \mathbf{I}(x \in (p/q - 1/q^3, p/q + 1/q^3). \]
    %
    If $x \not \in E$, then $x$ lies in at most finitely many of the intervals $(p/q - 1/q^3, p/q + 1/q^3)$, so $f(x)$ is finite. Moreover, $f$ is a limit of simple functions, and is therefore measurable. And if $a < b$, there exists arbitrarily large denominators $q$ for which there is a simple fraction $p/q$ with $a < p/q - 1/q^3 < p/q + 1/q^3 < b$; on $(p/q - 1/q^3, p/q + 1/q^3) \cap E^c$, we have $f(x) \geq q^4$, and thus
    %
    \[ \int_a^b f(x)\; dx \geq \int_{p/q - 1/q^3}^{p/q + 1/q^3} q^4 = 2q. \]
    %
    Taking $q \to \infty$ shows that
    %
    \[ \int_a^b f(x)\; dx = \infty. \]
\end{solution}

\question (Aug 2018 \#5) Two parts:

    \begin{parts}
    \part Give an example, with explanation, of each of the following:
        \begin{itemize}
        \item A sequence of functions on $\R$ that converges to zero in $L^1(\R)$, but it does not converge almost anywhere on $\R$ to any function. 
        \item A sequence of functions in $L^1(\R)$ that converges almost everywhere to zero, but it does not converge in measure to any function. 
        \end{itemize}
  \begin{solution} 
  One idea for (a): For $n>1$, let $a_n = 1+ \frac{1}{2} + \frac{1}{3} + \ldots + \frac{1}{n-1}$ mod 1. Define $f_n = \chi_{[a_n, \min\{a_n+\frac{1}{n},1\}]}$. Then $\int_{\R}|f_n|dx \leq \int_{a_n}^{a_n+\frac{1}{n}}dx = 1/n \to 0$. So $f_n \to 0$ in $L^1$. However, since $a_n\to \infty$, one can see that for all $x\in [0,1]$, the sequence of real numbers $(f_n(x))$ is 0 infinitely often and 1 infinitely often. Hence $\limsup_{n\to\infty} f_n(x) = 1 \neq 0 = \liminf_{n\to\infty} f_n(x)$. Thus $f_n$ doesn't converge almost surely.
  
  For the second part of $(a)$, let $f_n = \chi_{(n,n+1)}$. The details are easy to verify. (This is the classic ``moving bump".)
  \end{solution}    
        
    \part Prove that a sequence of functions on $\R$ that converges to zero in measure must have a subsequence that converges to zero almost everywhere. Do not quote any theorems that trivialize the problem. 
    
    \begin{solution}
    By definition of convergence in measure, there exists a subsequence $(n_k)$ such that 
    $$|\{ x: f_{n_k}(x)>2^{-k} \}|< 2^{-k}$$
    for every $k\geq1$. Therefore by the Borel-Cantelli lemma, it follows that 
    $$|\{x: f_{n_k}(x) > 2^{-k} \mathrm{\ i.o.}\}|=0.$$ 
    In other words, for a.e. $x\in\R$, there exists an integer $k_0$ (possibly depending on $x$) such that $f_{n_k}(x)<2^{-k}$ whenever $k\geq k_0$. Therefore $\lim_{k\to\infty} f_{n_k}(x)= 0$ a.e.
    \end{solution}
    \end{parts}
    
    
\question (January, 2017)
    Let $f: [0,\infty) \to \RR$ be a continuously differentiable function for which $\| f' \|_\infty < \infty$. Define, for $x > 0$,
    %
    \[ F(x) = \int_0^\infty f(x + yx) \psi(y)\; dy, \]
    %
    where $\psi$ satisfies
    %
    \[ \int_0^\infty |\psi(y)|\; dy \quad\text{and}\quad \int_0^\infty y \cdot |\psi(y)|\; dy < \infty. \]
    %
    Show that $F(x)$ is well defined for all $x \geq 0$, and that $F$ is continuously differentiable.
\begin{solution}
    The fundamental theorem of calculus implies that
    %
    \[ |f(x + yx)| = \left| f(x) + \int_x^{x+yx} f'(t)\; dt \right| = f(x) + O(yx). \]
    %
    Thus combined with the fact that $\int_0^\infty |\psi(y)|\; dy < \infty$ and $\int_0^\infty y \cdot |\psi(y)|\; dy < \infty$, this implies that
    %
    \[ \int_0^\infty |f(x + yx)| |\psi(y)|\; dy \lesssim |f(x)| + |x| < \infty, \]
    %
    so $F$ is well defined.
    
    To show that $F$ is continuously differentiable, we note that for a fixed $x \in [0,\infty)$, we calculate that, for $h$ with $0 \leq x + h$,
    %
    \begin{align*}
        \frac{F(x+h) - F(x)}{h} &= \int_0^\infty \frac{|f(x+yx + h(1 + y)) - f(x + yx)|}{h} \psi(y)\; dy.
    \end{align*}
    %
    Now
    %
    \[ \left| \frac{|f(x+yx + h(1 + y)) - f(x + yx)|}{h} \psi(y) \right| \lesssim (1 + y) |\psi(y)|. \]
    %
    Since $(1 + y) \psi(y)$ is integrable, the dominated convergence theorem implies that $F$ is differentiable at $x$, and
    %
    \[ F'(x) = \int_0^\infty f'(x + yx) (1 + y) \psi(y)\; dy. \]
    %
    Finally, we show $F'$ is continuous. We note that for any $\varepsilon > 0$, there exists $R > 0$ such that
    %
    \[ \int_R^\infty (1 + y) |\psi(y)|\; dy \leq \varepsilon. \]
    %
    Since $f'$ is continuous, it is uniformly continuous on $[0,2R(1 + x)]$. Thus there exists $\delta > 0$ such that for $|h| \leq \delta$, and $0 \leq y \leq R$, $|f'((x + yx) + h(1 + y)) - f(x + yx)| \leq \varepsilon$, and so
    %
    \begin{align*}
        F'(x+h) - F(x) &\lesssim \varepsilon + \int_0^R [f'((x + yx) + h(1 + y)) - f'(x + yx)] (1 + y) \psi(y)\; dy\\
        &\lesssim \varepsilon + \int_0^R \varepsilon (1 + y) \psi(y)\; dy \lesssim \varepsilon.
    \end{align*}
\end{solution}

\question (Aug 2016 \# 4) Let $f:[0,1]\to \R$ be continuous with $\min_{0\leq x\leq 1} f(x) = 0$. Assume that for any $0\leq a\leq b\leq 1$ we have $\int_{a}^{b}[f(x)-\min_{a\leq y\leq b}f(y)]dx \leq \frac{|b-a|}{2}$. Prove that for any $\lambda\geq 0$, we have
\begin{equation*}
\left| \left\{ x:f(x)>\lambda+1 \right\} \right|\leq \frac{1}{2} \left| \left\{ f(x)>\lambda) \right\} \right|.
\end{equation*}

\begin{solution}
  Since $f$ is continuous, $\left\{x: f(x)>\lambda \right\}$ is open. Therefore we may write $\left\{x: f(x)>\lambda \right\} = \bigcup_{i=1}^{\infty}I_{i}$ where $(I_{i})_{i=1}^{\infty}$ is a countable pairwise disjoint sequence of intervals $I_{i}=(a_{i},b_{i})$ with $a_{i}\leq b_{i}$.
  \vt
  \noindent
  \textit{Claim:} $\min_{t\in \bar{I}_{i}} f(t) \leq \lambda$.
  \begin{proof}[Proof of Claim:]
    If $I_{i}=\emptyset$ there is nothing to show. If $a_{i} = 0$ and $b_{i}=1$, then by hypothesis, $\min_{[a_{i},b_{i}]}f =\min_{[0,1]}f = 0\leq \lambda$. So assume that is not the case; i.e., that at least one of $a_{i},b_{i}$ is in $(0,1)$. Without loss of generality, assume that $a_{i}\in (0,1)$. The $a_{i}\in \partial \left\{ x: f(x)\leq \lambda \right\}$. Hence by continuity of $f$, we have $f(a_{i})\leq \lambda$. Hence $\min_{[a_{i},b_{i}]}f \leq \lambda$. 
  \end{proof}
  Then we have:
  \begin{align*}
    \frac{1}{2}|I_{i}| &\geq \int_{I_{i}} f(x)-\min_{t\in {\bar{I}_{i}}}f(t) dx
    &&\text{by assumption}\\
                       &\geq \int_{I_{i}\cap \left\{ f > \lambda+1 \right\}}f(x)-\min_{t\in{\bar{I}_{i}}}f(t)dx
    &&\text{by nonnegative of the integrand}\\
                       &\geq \int_{I_{i}\cap \left\{ f > \lambda+1 \right\}}f(x)-\lambda dx
    &&\text{by the claim}\\
                       &\geq \int_{I_{i}\cap \left\{ f > \lambda+1 \right\}}(\lambda+1)-\lambda dx
    &&\text{by domain of integration}\\
                       &= \left|I_{i} \cap \left\{  f> \lambda+1\right\} \right|.
  \end{align*}
  By countable additivity for disjoint sets, summing over $i$ and using $\left\{f>\lambda+1 \right\}\subseteq
 \left\{f>\lambda \right\}$ gives
  \begin{equation*}
    \frac{1}{2}\left| \left\{f >\lambda \right\} \right|  \geq \left| \left\{ f>\lambda \right\}\cap \left\{ f>\lambda+1 \right\} \right| = \left| \left\{ f>\lambda+1 \right\} \right|.
  \end{equation*}
\end{solution}




\newpage
\section{Day 5: Basic Functional Analysis}

\question (January, 2015) Let $f \in L^2[0,1]$ satisfy $\int_0^1 t^n f(t)\; dt = (n+2)^{-1}$ for $n = 0, 1,\dots$. Must then $f(t) = t$ for almost every $t \in [0,1]$?
\begin{solution}
    The identity $\int_0^1 t^n f(t)\; dt = (n+2)^{-1}$ shows that for any polymonial $p(t)$,
    %
    \[ \int_0^1 p(t) [f(t) - t]\; dt = 0. \]
    %
    Applying some type of density theorem (the Stone-Weirstrass theorem, and its variants), we find that the family of all polynomials is dense in $L^2[0,1]$. Applying the continuity of the map $g \mapsto \int_0^1 g(t) [f(t) - t]$, we conclude that for all $g \in L^2[0,1]$,
    %
    \[ \int_0^1 g(t) [f(t) - t]\; dt = 0. \]
    %
    But setting $g(t) = \overline{f(t) - t}$, we conclude that
    %
    \[ \int_0^1 |f(t) - t|^2\; dt = 0. \]
    %
    This implies $f(t) = t$ for almost every $t$.
\end{solution}

\question (September 2015) Find all $f \in L^2[0,\pi]$ such that
%
\[ \int_0^\pi |f(x) - \sin x|^2\; dx \leq \frac{4\pi}{9} \]
%
and
%
\[ \int_0^\pi |f(x) - \cos x|^2\; dx \leq \frac{\pi}{9} \]
\begin{solution}
    We note that $\sin x$ and $\cos x$ are orthogonal in $L^2[0,1]$. Thus we may consider a family of orthogonal vectors $\{ e_n \}$ such that $\{ \sin x, \cos x \} \cup \{ e_n \}$ is an orthogonal basis for $L^2[0,1]$. Thus there exists constants $a$, $b$, and $\{ c_n \}$ such that
    %
    \[ f(x) = a \sin x + b \cos x + \sum c_n e_n, \]
    %
    where the convergence of this sum is in the $L^2$ norm. Applying Parseval's theorem, we find that
    %
    \begin{align*}
        \int_0^\pi |f(x) - \sin x|^2\; dx &= |a - 1|^2 \int_0^\pi |\sin x|^2\; dx + |b|^2 \int_0^\pi |\cos x|^2\; dx + \sum |c_n|^2\\
        &= |a - 1|^2 (\pi/2) + |b|^2 (\pi/2) + \sum |c_n|^2.
    \end{align*}
    %
    Similarily,
    %
    \begin{align*}
        \int_0^\pi |f(x) - \cos x|^2\; dx &= |a|^2 (\pi/2) + |b - 1|^2 (\pi/2) + \sum_n |c_n|^2.
    \end{align*}
    %
    Next, we note that
    %
    \[ \int_0^\pi |\sin x - \cos x|^2 = \pi. \]
    %
    The triangle inequality thus implies that for any $f$ satisfying the requirements above, we actually have \emph{equality}, i.e.
    %
    \[ \int_0^\pi |f(x) - \sin x|^2\; dx = \frac{4\pi}{9} \]
    %
    and
    %
    \[ |f(x) - \cos x|^2\; dx = \frac{\pi}{9} \]
    %
    Thus we must find all families of coefficients $a$, $b$, and $\{ c_n \}$ such that
    %
    \[ |a - 1|^2 (\pi/2) + |b|^2 (\pi / 2) + \sum |c_n|^2 = 4 \pi / 9 \]
    %
    and
    %
    \[ |a|^2 (\pi/2) + |b - 1|^2 (\pi / 2) + \sum |c_n|^2 = \pi / 9. \]
    %
    Subtracting the second identity from the first, then multiplying by $2/\pi$, we conclude that
    %
    \[ (|a - 1|^2 - |a|^2) + (|b|^2 - |b-1|^2) = 2/3. \]
    %
    This equation can be simplified to
    %
    \[ \text{Re}(b) = \text{Re}(a) + 1/3. \]
    %
    %
    Substituting this into the first equation, we find that if $a = x + iy$, $b = (x + 1/3) + iz$, and $C = 2/\pi \sum c_n^2$, then
    %
    \[ 2x^2 - (4/3)x + (y^2 + z^2 + 2/9 + C) = 0. \]
    %
    The quadratic formula implies that there exists $x$ satisfying this equation for a fixed $y$ and $z$ if
    %
    \[ 16/9 - 8(y^2 + z^2 + 2/9 + C) \geq 0, \]
    %
    which can be rearranged to read
    %
    \[ 8(y^2 + z^2 + C) \leq 0. \]
    %
    This can only occur if $y = z = C = 0$, and it then follows from the quadratic formula that $x = 1/6$. Thus the only function $f$ satisfying this result is the function
    %
    \[ f(x) = (1/6) \sin x + (1/2) \cos x. \]
\end{solution}

\begin{solution}
Let $u(x)= \sin(x)-f(x)$ and $v(x)=f(x)-\cos(x)$. Then

\begin{equation*}
  \norm{u+v}_{L^{2}}^{2} = \int_{0}^{\pi}\left( \sin(x)+\cos(x) \right)^{2}dx = \int_{0}^{\pi} \sin^{2}(x)+ \cos^{2}(x)dx =\pi.
\end{equation*}
By the triangle inequality and the hypotheses of the problem,

\begin{equation*}
  \sqrt{\pi}=\norm{u+v}_{L^{2}} \leq \norm{u}_{L^{2}} + \norm{v}_{L^{2}} \leq \frac{2}{3}\sqrt{\pi}+ \frac{1}{3}\sqrt{\pi}=\sqrt{\pi}.
\end{equation*}
Therefore
$\norm{u+v}_{L^{2}} = \norm{u}_{L^{2}} + \norm{v}_{L^{2}}$. Therefore
\begin{equation*}
  \left( \norm{u}_{L^{2}}+ \norm{v}_{L^{2}} \right)^{2} = \norm{u+v}_{L^{2}}^{2} = \langle u+v, u+v\rangle = \norm{u}^{2}_{L^{2}}+\norm{v}^{2}_{L^{2}} + 2\langle u,v\rangle.
\end{equation*}
Therefore since $  \left( \norm{u}_{L^{2}}+ \norm{v}_{L^{2}} \right)^{2}= \norm{u}_{L^{2}}^{2}+\norm{v}_{L^{2}}^{2}+2 \norm{u}_{L^{2}}\norm{v}_{L^{2}}$, it follows that $\norm{u}_{L^{2}}\norm{v}_{L^{2}}= \langle u, v \rangle$. Therefore by the Cauchy Schwarz inequality, $u$ and $v$ are linearly dependent (viz. the condition for equality in the statement of Cauchy Schwarz). That is, there exists $\alpha\in \R$ such that $\sin(x)-f(x)= \alpha \left( f(x)-\cos(x) \right)$ almost everywhere. Solving for $f$ gives
\begin{equation}\label{eq:form-of-f}
  f(x) = \frac{1}{1+\alpha}\sin(x)+ \frac{\alpha}{1+\alpha}\cos(x).
\end{equation}
It remains to determine $\alpha$. Since $\norm{u}_{L^{2}}+ \norm{v}_{L^{2}}=\sqrt{\pi}$, $\norm{u}_{L^{2}}\leq 2 \sqrt{\pi}/3$, and $\norm{v}_{L^{2}}\leq \sqrt{\pi}/3$, it follows that $\norm{u}^2_{L^{2}} = 4 \pi/9$. Therefore
\begin{align*}
  \frac{4}{9}\pi &= \int_{0}^{\pi}\left( \sin(x)- \frac{1}{1+\alpha}\sin(x) -\frac{\alpha}{1+\alpha}\cos(x)\right)^{2}dx\\
                 &= \left( \frac{\alpha}{1+\alpha} \right)^{2}\int_{0}^{\pi}\left( \sin(x)-\cos(x) \right)^{2}dx\\
                 &=  \left( \frac{\alpha}{1+\alpha} \right)^{2}\pi.
\end{align*}
This implies $\alpha = 2$ or $\alpha= -2/5$. A similar calculation using $\norm{v}^{2}_{L^{2}}= \pi /9$ implies that $\alpha = 2$ or $\alpha = -4$. The only value for $\alpha$ consistent with both of these conditions is $\alpha =2$. Therefore by \eqref{eq:form-of-f},
\begin{equation*}
  f(x) = \frac{1}{3}\sin(x)+ \frac{2}{3}\cos(x).
\end{equation*}
\end{solution}

\question (January 2017)
    Let $l^1(\mathbf{N})$ be the space of summable sequences, i.e.
    %
    \[ l^1(\mathbf{N}) = \{ x : \sum_{n = 1}^\infty |x_n| < \infty \}. \]
    %
    Let $\{ a_n \}$ be a sequence with $a_n \geq 0$ for all $n \in \mathbf{N}$ and consider the subset $K \subset l^1(\mathbf{N})$ defined by
    %
    \[ K = \{ x \in l^1(\mathbf{N}) : 0 \leq x_n \leq a_n\ \text{for all $n$} \}. \]
    %
    Show that $K$ is compact if and only if the sequence $\{ a_n \}$ itself belongs to $l^1(\mathbf{N})$.
\begin{solution}
    First suppose $K$ is compact. Then consider the family of sequences
    %
    \[ \{ x(k) = (a_1,\dots,a_k,0,\dots) \}. \]
    %
    Each sequence $x(k)$ belongs to $K$. Thus by compactness, this sequence has a convergent subsequence $x(k_i)$ converging to some sequence in $l^1(\mathbf{N})$. But $x(k_i)$ converges pointwise to $a$, and so $x(k_i)$ can only converge to $a$, which implies $a \in l^1(\mathbf{N})$.
    
    On the other hand, suppose $a \in l^1(\mathbf{N})$. Consider an arbitrary sequence $\{ x(k) \}$ in $K$. For any $N > 0$, the projection of $K$ onto the first $N$ elements of the sequence is compact, and thus we may inductively find subsequences $x(k_{N,i})$ for each $N$ such that $\{ k_{N,i} \}$ is a subsequence of $\{ k_{M,i} \}$ for each $M \leq N$, and the first $N$ elements of the sequences $x(k_{N,i})$ converge pointwise. Consider the subsequence of sequences $y(n) = x(k_{n,n})$. For each $N > 0$, this sequence is a subsequence of the sequence $\{ x(k_{N,i} \}$ and so we can conclude from this that $\{ y(n) \}$ converges pointwise to some sequence $y$. Since $K$ is defined pointwise, it is simple to see that $y \in K$. For each $\varepsilon > 0$, we pick $N > 0$ such that
    %
    \[ \sum_{k > N} a_k < \varepsilon. \]
    %
    Then exists $M$ such that for $n > M$, and $1 \leq k \leq N$, $|y(n)_k - y_k| \leq \varepsilon / N$. And thus
    %
    \[ \| y(n) - y \|_1 \leq \sum_{k = 1}^N |y(n)_k - y_k| + \sum_{n > N} |y(n)_k| + |y_k| \leq \sum_{k = 1}^N (\varepsilon / N) + \sum_{n > N} 2a_n \leq 3\varepsilon. \]
    %
    Taking $\varepsilon \to 0$ completes the proof.
\end{solution}

\question (Jan 2018 \#2)
  Let $K$ be a continuous function on $[0,1]\times [0,1]$. Suppose that $g$ is a continuous function on $[0,1]$. Show that there exists a unique continuous function $f$ on $[0,1]$ such that
  \begin{equation*}
    f(x)=g(x)+\int_{0}^{x}f(y)K(x,y)dy
  \end{equation*}

  \begin{solution}
    Define an integral operator $T$ by $Tf(x) = g(x)+\int_{0}^{x}f(y)K(x,y)dy$. Since $g$ is continuous, $T:X\to X$ where $X=C[0,1]$, which is a Banach space with respect to the topology induced by the norm $\norm{f} = \max_{x\in[0,1]} |f(x)|$. 
    Since $K$ is continuous and $[0,1]\times[0,1]$ is compact, there exists $M$ such that $|K(x,y)|\leq M$ for all $x,y\in [0,1]\times[0,1]$.
    By induction we can show that for any $f_{1},f_{2}\in C[0,1]$ and any $x\in [0,1]$,
    \begin{align*}
      |T^{n}f_{1}(x)-T^{n}f_{2}(x)|
      &\leq \norm{f_{1}-f_{2}}M^{n}\int_{0}^{x}\int_{0}^{x_{1}}\cdots \int_{0}^{x_{n-1}}x_{n}dx_{n}\cdots dx_{1}\\
      &=\norm{f_{1}-f_{2}}M^{n}\frac{x^{n}}{n! }\\
      &\leq \norm{f_{1}-f_{2}}\frac{M^{n}}{n!}.
    \end{align*}
    Therefore $\norm{T^{n}f_{1}-T^{n}f_{2}}\leq \frac{M^{n}}{n!}\norm{f_{1}-f_{2}}$. In particular,  since $\lim_{n\to\infty}\frac{M^{n}}{n!}=0$ for any $M>0$, we can choose $n$ sufficiently large that $\frac{M^{n}}{n!}<1$, in which case $T^{n}$ is a contraction. The existence and uniqueness of $f$ then follow from the contraction mapping theorem.
\end{solution}
\begin{solution} Remark: in the previous solution, we wished to apply the contraction mapping theorem, but could not do so directly with $T$ because $T$ is not a contraction on $C[0,1]$. We got around this difficulty by considering the operator $T^n$ for some positive integer $n$, which fortuitously turned out to be a contraction when $n$ is large enough. Another approach is to consider $T$ as an operator on ``smaller'' Banach spaces, e.g. $C[0,x_1], C[x_1,x_2], \ldots$ etc, where $x_i-x_{i-1}$ are small enough that $T$ is a contraction on $C[x_{i-1},x_{i}]$ and then patch the solutions together. We detail this second proof here.

The idea is to apply the contraction mapping theorem on small intervals and then patch thigns together. Assume $|K|\leq M$ for all $x,y$. Define $$T_{1}(f)= g(x)+\int_{0}^{x}f(y)K(x,y)dy$$ on $C([0,x_{1}])$ where $x_{1}>0$ is sufficiently small that $\norm{T_{1}f-T_{1}h}_{\infty}\leq \frac{1}{2}\norm{f-h}_{\infty}$ on the interval $[0,x_{1}]$. We can do this because $\norm{K}_{\infty}\leq M$. Therefore we can apply the contraction mapping theorem to get a unique solution $f_{1}\in C([0,x_{1}])$. Then we define $$T_{2}(f)= g(x)+\int_{x_{1}}^{x}f(y)K(x,y)dy + \int_{0}^{x_{1}}f_1(y) K(x,y)dy$$ on $C([x_{1},2x_{1}])$ where $f_{1}$ is the solution we get from the first step. It is easy to check that this operator is also a contraction. Moreover, the unique solution we get $f_{2}$ agrees with $f_{1}$ at the point $x_{1}$, so it can be patched together continuously. (Why?) Repeat this process finitely many times, we're done. The uniqueness follows from the contraction mapping theorem.  

\end{solution}

\question Let $\phi: \RR \to \RR$ be a continuous function with compact support.
\begin{parts}
    \part Prove that there exists a constant $A$ such that
    %
    \[ \| f * \phi \|_q \leq A \| f \|_p \]
    %
    for $1 \leq p \leq q \leq \infty$.
\begin{solution}
    Let us begin by showing that
    %
    \[ \| f * \phi \|_\infty \leq A \| f \|_p. \]
    %
    Indeed, H\"{o}lder's inequality implies that if $p^*$ is the conjugate to $p$, then
    %
    \begin{align*}
        \| f * \phi \|_{L^\infty_x} &= \left\| \int f(x-y) \phi(y)\; dy \right\|_{L^\infty_x}\\
        &\leq \left\| \left( \int |\phi(y)|^{p^*}\; dy \right)^{1/p^*} \cdot \left( \int |f(x-y)|^p\; dy \right)^{1/p} \right\|_{L^\infty_x}\\
        &\leq \| \phi \|_{L^{p^*}} \| f \|_{L^p}.
    \end{align*}
    %
    Next, we calculate using Minkowski's integral inequality that
    %
    \[ \| f * \phi \|_{L^p_x} = \left\| \int f(x-y) \phi(y)\; dy \right\|_{L^p_x} \leq \int |\phi(y)| \| f \|_{L^p}\; dy = \| \phi \|_{L^1} \| f \|_{L^p}. \]
    %
    Thus we have found a constant $A = \max_{1 \leq r \leq \infty} (\| \phi \|_{L^r})$ such that the result holds for $(p,q)$ of the form $(p,\infty)$, and of the form $(p,p)$. The remaining estimates lie `in-between' this range. One approach here is to apply the Riesz-Thorin interpolation theorem, which gives all the intermediary bounds $(p,q)$ for $p \leq q \leq \infty$. Alternatively, a sneaky application of H\"{o}lder's inequality shows that for $q \geq p$, if we fix $\alpha \in (0,1)$ such that $\alpha q = p$, then
    %
    \begin{align*}
        \| f * \phi \|_{L^q_x}^q &= \int |(f * \phi)(x)|^{\alpha q} |(f * \phi)(x)|^{(1 - \alpha)q}\\
        &\leq \left( \int |(f * \phi)(x)|^p |(f * \phi)(x)|^{(1 - \alpha)q}\; dx \right)\\
        &\leq \int |(f * \phi)(x)|^p\; dx \cdot \sup_x |(f * \phi)(x)|^{(1 - \alpha)q}\\
        &\leq \| f * \phi \|_{L^p_x}^p \| f * \phi \|_{L^\infty_x}^{(1 - \alpha)q}\\
        &\leq \left( A \| f \|_{L^p} \right)^p \left( A \| f \|_{L^p} \right)^{(1 - \alpha) q}\\
        &= A \| f \|_{L^p}.
    \end{align*}
\end{solution}
    
    \part Show by example that such general inequality cannot hold for $p > q$.
\begin{solution}
  It suffices, for any $R > 0$, to construct a function $f \in L^p$ such that
  %
  \[ \| f * \phi \|_{L^q} \geq R \| f \|_{L^p}. \]
  %
  One should think of bounds on $L^r$ for large $r$ as controlling how `peaked' a function can be, whereas bounds on $L^r$ for small $r$ control how `long' a function can be. Thus, intuitively, we must construct a function $f$ which is not peaked, but can be long (small in $L^p$ norm), into a function $f * \phi$ which is long (has large $L^q$ norm).
  
  Here is one approach that `almost' works for all $\phi$. A good choice for a non-peaked, long function is just a constant function supported on a large set. For instance, if $f(x) = \mathbf{I}(|x| \leq R)$, then $\| f \|_p \sim R^{1/p}$. If we assume that $\phi$ is supported on $|x| \leq S$, then for $|x| \leq R - S$,
  %
  \[ (\phi * f)(x) = \int \phi(x)|\; dx. \]
  %
  Provided that $\int \phi(x)\; dx \neq 0$, this implies that $|(\phi * f)(x)| \gtrsim_\phi 1$ for $|x| \leq R - S$, which implies that for $R \geq 2S$,
  %
  \[ \| \phi * f \|_{L^q} \gtrsim_\phi \left( \int_{|x| \leq R - S} 1 \right)^{1/q}] \gtrsim (R - S)^{1/q} \gtrsim R^{1/q}. \]
  %
  Thus
  %
  \[ \| \phi * f \|_{L^q} \gtrsim_\phi R^{1/q - 1/p} \| f \|_{L^p}. \]
  %
  If $q < p$, then $1/q - 1/p > 0$, and so we may take $R \to \infty$ to show that the operator $Tf = \phi * f$ cannot be bounded. The only problem is that this idea cannot approach functions such that
  %
  \[ \int \phi(x)\; dx = 0. \]
  %
  If this is the case, in our examples above, $f * \phi = 0$ on $|x| \leq R - S$, which means $\| f * \phi \|_q \sim 1$, so this approach doesn't work. In order to approach this case, we must choose $f$ more carefully so that $f * \phi$ cannot average out to zero on a large set.
  
  Fix a large integer $N > 0$, and set
  %
  \[ f(x) = \sum_{n = -N}^N \overline{\phi(2R \cdot n-x)}, \]
  %
  where we assume $\phi(x) = 0$ for $|x| \geq R$.  Then $f$ is not `peaked' (because $\phi$ is continuous, and not peaked), but supported on a very wide set. Indeed, we find that
  %
  \[ \| f \|_p \sim_\phi N^{1/p}. \]
  %
  For $|n| \leq N$, we compute that
  %
  \[ (\phi * f)(2Rn) = \int \phi(x) f(2Rn - x) = \int \phi(x) \overline{\phi(x)} = \| \phi \|_{L^1}. \]
  %
  By continuity of the quantities involved, there exists $\delta$ such that for $|x| \leq \delta$, $|(\phi * f)(x)| \geq \| \phi \|_{L^1} / 2$. Thus $\phi * f$ is non-zero on  a very wide set. More precisely, $|(\phi * f)| \gtrsim \| \phi \|_1$ on $N$ intervals of radius $\delta$, so
  %
  \[ \| \phi * f \|_q \gtrsim (N \delta)^{1/q} \| \phi \|_{L^1} \gtrsim_\delta N^{1/q}. \]
  %
  Thus
  %
  \[ \| \phi * f \|_q \gtrsim_{\phi,\delta} N^{1/q - 1/p} \| f \|_p. \]
  %
  Taking $N \to \infty$ thus shows that the operator is unbounded.
\end{solution}
\end{parts}


\item (Aug 2016 \#5)
  Give an example of a non-empty closed subset of $L^{2}([0,1])$ that does not contain a vector of smallest norm. Prove your assertion.

\begin{solution}
  Let $e_{n} = \sqrt{2}\sin(n\pi x)$ for $n=1,2,\ldots$, and define $x_{n}= \left(\frac{n+1}{n}\right)e_{n}$. Then $\{x_{n}\}_{n=1}$ is a nonempty closed subset with no element of smallest norm. To prove this, we first prove two claims:

  

  \vt
  \noindent \textit{Claim 1:} $\{e_{n}\}_{n\geq 1}$ is an orthonormal set in $L^{2}([0,1])$.
  \begin{proof}[Proof of Claim 1:]
    Need to show two things: (1) that $\norm{e_{n}}_{L^{2}([0,1])}=1$ for all $n$, and (2) that $\langle e_{n},e_{m}\rangle$ whenever $m\neq n$. These can be shown by direct computation using trig identities:

    Suppose $n\geq 1$. Then using $\sin^{2}(\theta) = \frac{1}{2}\left( 1-\cos(2\theta) \right)$,

    \begin{equation*}
      \norm{e_{n}}_{L^{2}([0,1])}^{2} = \int_{0}^{1}2\sin^{2}(n\pi x)dx = \int_{0}^{1}1-\cos(n\pi x)dx=1.
    \end{equation*}
    This proves (1).
    Next, suppose $m\neq n$. Using $\sin(A)\sin(B) = \frac{1}{2}\left(\cos(A-B)-\cos(A+B)  \right)$,
    \begin{align*}
      \langle e_{n},e_{m}\rangle
      &= \int_{0}^{1}2\sin(n\pi x)\sin(m\pi x)dx\\
      &= \int_{0}^{1} \cos((n-m)\pi x) - \cos((n+m)\pi x)dx\\
      &=0.
    \end{align*}
    This proves (2), which completes the proof of the claim.
  \end{proof}

  \vt
  \noindent  \textit{Claim 2:} If $m\neq n$ then $\norm{x_{n}-x_{m}}_{L^{2}([0,1])}\geq \sqrt{2}$.
  \begin{proof}[Proof of Claim 2:]
    Suppose $m\neq n$. Denote $c_{n}= \frac{n+1}{n}$. Then 
    \begin{align*}
      \norm{x_{n}-x_{m}}^{2}_{L^{2}([0,1])}
      &= \langle x_{n}-x_{m}, x_{n}-x_{m}\rangle\\
      &= \langle c_{n} e_{n}-c_{m} e_{m},  c_{n}e_{n}- c_{m}e_{m}\rangle\\
      &=c_{n}^{2}\langle e_{n},e_{n}\rangle -2c_{m}c_{n}\langle e_{n},e_{m}\rangle + c_{m}^{2}\langle e_{m},e_{m}\rangle\\
      &= c_{n}^{2}+ c_{m}^{2}
    \end{align*}
    where the final equality is justified by Claim 1. It follows that
    \begin{equation*}
       \norm{x_{n}-x_{m}}_{L^{2}([0,1])} = \sqrt{c_{n}^{2}+c_{m}^{2}} = \sqrt{\left(1+ \frac{1}{n} \right)^{2}  + \left( 1+\frac{1}{m} \right)^{2}}\geq \sqrt{2}.
     \end{equation*}
     This proves claim 2.
  \end{proof}



Using Claim 1, we see that $\norm{x_{n}}_{L^2([0,1])} = \left( \frac{n+1}{n} \right)\norm{e_{n}}_{L^{2}([0,1])} = 1+\frac{1}{n}$, and from this it is clear that $(x_{n})$ has no element of smallest norm. The fact that $x_{n}$ is closed follows from Claim 2, which implies that any convergent sequence consisting of elements in $\left\{ x_{n} \right\}_{n}$ is eventually constant, and hence its limit point must again be an element in $\left\{ x_{n} \right\}_{n}$.


  
\end{solution}






\newpage
\section{Day 6: Functional Analysis}

\question (September, 2019) Show that there is no sequence $\{ a_n \}$ of positive numbers such that $\sum a_n |c_n| < \infty$ if and only if $\{ c_n \}$ is a bounded sequence. Hint: Suppose that there exists a sequence and consider the map $T: l^\infty \to l^1$ given by $Tf(n) = a_n f(n)$. The set of $f$ such that $f(n) = 0$ for all but finitely many $n$ is dense in $l^1$ but not in $l^\infty$.
\begin{solution}
    Consider the operator $T$ defined in the hint. Then $T$ is injective, since all elements of the sequence $\{ a_n \}$ are positive. We also claim that $T$ is surjective, given the property assumed of the sequence. Indeed, if $\sum b_n < \infty$, and we define $c_n = b_n/a_n$, then $\sum a_n |c_n| < \infty$, and thus $\{ c_n \}$ is a bounded sequence, and $Tc = b$.
    
    Thus we conclude that $T$ is an isomorphism, so that there exists a constants $C_1,C_2 > 0$ such that $C_1 \| c \|_{l^\infty} \leq \| Tc \|_{l^1} \leq C_2 \| c \|_{l^\infty}$. Plugging in the bounded sequence $(1,1,1,\dots)$ into the operator $T$ gives the sequence $\{ a_n \}$, and so this sequence lies in $l^1$. Clearly any sequence $\{ a_n \}$ in $l^1$ will give rise to a bounded operator from $l^\infty$ to $l^1$, so we wish to disprove that the lower bound exists, i.e there does not exist a sequence $\{ a_n \}$ in $l^1$ such that $\| Tc \|_{l^1} \gtrsim \| c \|_{l^\infty}$.
    
    To do this, we must construct a non-negative sequence $c$ where $\| c \|_{l^\infty}$ is large, but such that $\| Tc \|_{l^1}$ is small. The best way to do this is to concetrate the sequence $c$ at a single point, i.e. we consider the sequence $c = (0,\dots,0,1,\dots)$, where the $1$ is in the $N$th term in the sequence. Then $Tc = (0,\dots,0,a_n,\dots)$, and so we have
    %
    \[ \| c \|_{l^\infty} = 1 \quad\text{and}\quad \| Tc \|_{l^1} = |a_N|. \]
    %
    As $N \to \infty$, $|a_N| \to 0$ since the sequence is integrable. But this is impossible since the bound $\| Tc \|_{l^1} \gtrsim \| c \|_{l^\infty}$ implies that $|a_N| \gtrsim 1$ for all $N$.
\end{solution}

\question (Aug 2020, Problem \#7R)

Suppose that $X,Y$ and $Z$ are Banach spaces, and $T:X\times Y\to Z$ is a mapping such that:
\begin{enumerate}[(a)]
\item For each $x\in X$, the map $y\mapsto T(x,y)$ is a bounded linear map $Y\to Z$.
\item For each $y\in Y$, the map $x\mapsto T(x,y)$ is a bounded linear map $X\to Z$.
\end{enumerate}
Prove there exists a constant $C$ such that
\begin{equation*}
\norm{T(x,y)}_{Z}\leq C \norm{x}_{X}\norm{y}_{Y}
\end{equation*}

\begin{solution}
  Without loss of generality we may assume that $x,y$ are nonzero since if either $x=0$ or $y=0$, the inequality holds for any $C$. Further, we claim that it suffices to show the inequality holds for all $x,y$ satisfying $\norm{x}_{X}=1$ and $\norm{y}_{Y}=1.$ To see this, suppose $\norm{T(\tilde{x},\tilde{y})}_{Z}\leq C$ for all $\tilde{x}\in X$ and $\tilde{y}\in Y$ with $\norm{\tilde{x}}_{X}=1$, $\norm{\tilde{y}}_{Y}=1$. Then for any nonzero $x\in X$, $y\in Y$,
  \begin{equation*}
    \norm{T(x,y)}_{Z}= \norm{x}_{X}\norm{y}_{Y}\norm{T \left( \frac{x}{\norm{x}_{X}},\frac{y}{\norm{y}_{Y}} \right)}_{Z} \leq C \norm{x}_{X}\norm{y}_{Y}.
  \end{equation*}
  This proves the claim.

  Next, let for each $x\in X$, let $\phi_{x}:Y\to Z$ denote the map $y\mapsto T(x,y)$, and for each $y\in Y$, let $\psi_{y}:X\to Z$ denote the map $x\mapsto T(x,y)$. Let $B= \left\{ x\in X: \norm{x}_{X}=1 \right\}$. Then since $\phi_{x}(y)=T(x,y)=\psi_{y}(x)$ and since $\psi_{y}$ is assumed to be a bounded operator, it holds for all $y\in Y$ that
  \begin{equation*}
    \sup_{x\in B}\norm{\phi_{x}(y)}_{Z} = \sup_{x\in B}\norm{\psi_{y}(x)}_{Z} \leq \sup_{x\in B}\norm{\psi_{y}} \norm{x}_{X} = \norm{\psi_{y}} <\infty.
  \end{equation*}
  Therefore by the Uniform Boundedness Principle,
  \begin{equation*}
    \sup_{x\in B}\norm{\phi_{x}}= C <\infty.
  \end{equation*}
  Therefore for any $x,y$ with $\norm{x}_{X}=1$ and $\norm{y}_{Y}=1$,
  \begin{equation*}
    \norm{T(x,y)}_{Z} = \norm{\phi_{x}(y)}_{Z}\leq \norm{\phi_{x}}\norm{y}_{Y} = \norm{\phi_{x}} \leq C.
  \end{equation*}
\end{solution}

\question (September, 2015) For $p \in (1,\infty)$, and for $f \in L^p(\RR)$ define
%
\[ Tf(x) = \int_0^1 f(x + y)\; dy. \]
%
\begin{parts}
    \part Show that $\| Tf \|_p \leq \| f \|_p$ and equality holds if and only if $f = 0$ almost everywhere.
    \begin{solution}
        We use Minkowski's inequality. For those unfamiliar, recall the triangle inequality, which for $1 \leq p \leq \infty$ says that
        %
        \[ \| \sum_n f_n \|_p \leq \sum_n \| f_n \|_p. \]
        %
        Minkowski's inequality occurs when we replace the sum with an integral, i.e. for $1 \leq p \leq \infty$,
        %
        \[ \left\| \int_y f_y\; dy \right\|_p \leq \int_y \| f_y \|_p\; dy. \]
        %
        In this case, we set $f_y(x) = f(x + y)$. Then
        %
        \[ Tf(x) = \int_0^1 f_y(x)\; dy. \]
        %
        Thus, using the fact that $\| f_y \|_p = \| f \|_p$, we conclude
        %
        \[ \| Tf \|_p = \left\| \int_0^1 f_y\; dy \right\|_p \leq \int_0^1 \| f_y \|_p\; dy = \int_0^1 \| f \|_p\; dy = \| f \|_p. \]
        %
        To address the case of equality, we recall the case of the triangle inequality, i.e. that
        %
        \[ \| \sum_n f_n \|_p = \sum_n \| f_n \|_p \]
        %
        if and only if $\{ f_n \}$ are all scalar multiples of one another. Similarily, \emph{Minkowski's inequality} is an equality if and only if $\{ f_y \}$ are all scalar multiples of one another \emph{almost everywhere}. Thus if $\| Tf \|_p = \| f \|_p$, then the application of Minkowski's inequality is an equality, which implies that there exists $c(y)$ such that $f_y(x) = c(y) f(x)$, i.e. $f(x + y) = c(y) f(x)$. But if
        %
        \[ \int_0^y |f(x)|^p\; dx \neq 0, \]
        %
        the dominated convergence theorem implies that
        %
        \begin{align*}
            \| f \|_p^p &= \lim_{n \to \infty} \sum_{k = -n}^n \int_0^y f(x + ky)\; dy\\
            &= \lim_{n \to \infty} \int_0^y f(x) \sum_{k = -n}^n c(y)^k.
        \end{align*}
        %
        But this sum cannot possibly converge. Thus
        %
        \[ \int_0^y |f(x)|^p = 0, \]
        %
        which implies $f = 0$ almost everywhere.
    \end{solution}
    
    \part (2015, September) Prove that the map $f \mapsto Tf - f$ does not map $L^p(\RR)$ onto $L^p(\RR)$.
    \begin{solution}
        First, we claim that $Tf - f$ is injective. Indeed, if $Tf = f$, then $\| Tf \|_p = \| f \|_p$, and by the last part of the problem, this implies that $f = 0$. If $Tf - f$ was surjective, then the open mapping theorem would therefore imply that there would exist a constant $C > 0$ such that for all $f \in L^p(\RR)$, $\| Tf - f \|_p \geq C \| f \|_p$. Our goal is to show this is not true.
        
        Intuitively, we wish to find a function $f$ such that $Tf - f$ is small. This would be possible if $Tf \approx f$, which would hold if $f$ was approximately constant. So we consider the `almost' constant function $f(x) = \mathbf{I}(|x| \leq R)$. Then $Tf(x)$ is supported on $|x| \leq R + 1$, $Tf(x) = f(x)$ for $|x| \leq R - 1$, and $\| Tf \|_\infty \leq 1$. Thus $Tf - f$ is supported on a set of total mass $O(1)$, and $\| Tf - f \|_\infty = O(1)$, so
        %
        \[ \| Tf - f \|_p \lesssim 1,  \]
        %
        independently of $R$. On the other hand, $\| f \|_p \sim R^{1/p}$, so it is impossible for a bound of the form $\| Tf - f \|_p \geq C \| f \|_p$ to hold.
    \end{solution}
\end{parts}



\question (Aug 2014 \# 9)

\begin{parts}
\part For any $n\geq 1$ an integer, there exists two positive measures $\mu_{1}^{n},\mu_{2}^{n}$ supported on $[0,1]$ such that for any polynomial $P(x)$ with $\deg P(x)\leq n$ it holds:
\begin{equation*}
  P'(0) = \int_{0}^{1}P(x)d\mu^{n}_{1}(x)-\int_{0}^{1}P(x)d\mu_{2}^{n}(x).
\end{equation*}

\begin{solution}
  Let $X = \left\{ p: p\text{ is a real-valued polynomial on }[0,1]\text{ of degree}\leq n \right\}$. Then $X$ is a finite dimensional linear subspace of $C[0,1]$. Define two norms
  $\norm{p}_{u}:= \max_{0\leq x\leq 1}|p(x)|$ and $\norm{\cdot}$ by $\norm{p}:= \max_{0\leq k\leq n }|a_{k}|$ when $p(x)= \sum_{k=0}^{n}a_{k}x^{k}$. Since all norms on a finite dimensional space are equivalent, there is a constant $C>0$ such that
  \begin{equation*}
    \norm{p}\leq C\norm{p}_{u}.
  \end{equation*}
  Let $T:X\to\R$ be defined by $Tp = p'(0)$. If $p(x)= \sum_{k=0}^{n}a_{k}x^{k}$ then
  \begin{equation*}
    |Tp| = |p'(0)| = |a_{1}|\leq \norm{p} \leq C \norm{p}_{\infty}.
  \end{equation*}
  Therefore $\norm{T}\leq C<\infty$. Since $T$ is also linear, $T$ is a bounded linear functional $X$. Since $X$ is a subspace of $C[0,1]$, by the Hahn-Banach theorem $T$ can be extended to a bounded linear functional on $C_{c}[0,1]$. That is, we have $T\in (C[0,1])^{*}$. Therefore by the Riesz Representation Theorem (e.g. Royden p464), there is a finite signed measure $\mu$ on defined on the Borel subsets of $[0,1]$ such that
  \begin{equation*}
    Tp = \int_{0}^{1}p(x)d\mu(x) = \int_{0}^{1}p(x)d\mu_{1}^{n}-\int_{0}^{1}p(x)d\mu_{2}^{n}(x)
  \end{equation*}
  where $\mu=\mu_{1}^{n}-\mu_{2}^{n}$ is the Jordan Decomposition of $\mu$.
\end{solution}

\begin{solution} (This is an alternate solution to part (a). It is Chun's solution from the 2016 SEP, problem 39. He provides an explicit form for the measures, which I thought was interesting enough to type up. -m)


  We will show that there exists constants $c_{j}\in \R, x_{j}\in (0,1)$ with $0\leq j\leq n$ such that the measure $\mu^{n}$ defined by
  \begin{equation}\label{eq:mu-form}
    \mu^{n}:= \sum_{j=0}^{n}c_{j}\delta_{x_{j}}
  \end{equation}
  satisfies $\int_{0}^{1}P(x)d\mu^{n}(x)=P'(x)$ for any polynomial $P'(x)$ with $\deg P(x)\leq n$. The result will then follow by taking
  \begin{equation*}
    \mu_{1}^{n} = \sum_{j=0}^{n}c_{j}^{+}\delta_{a_{j}} \quad \text{and}\quad    \mu_{2}^{n} = \sum_{j=0}^{n}c_{j}^{-}\delta_{a_{j}}
  \end{equation*}
  where $c_{j}^{+}=\max\{c_{j},0\}$ and $c^{-}= \max\{-c_{j},0\}$.

  Suppose $P(x)=\sum_{k=0}^{n}a_{k}x^{k}$. Then $P'(0)=a_{1}$. By \eqref{eq:mu-form}, $\int_{0}^{1}x^{k}d\mu^{n}(x) = \sum_{j=0}^{n}c_{j}x_{j}^{k}$ whenever $0\leq k\leq n$, and hence
  \begin{equation*}
    \int_{0}^{1}P(x)d\mu^{n}(x)
    = \int_{0}^{1}\sum_{k=0}^{n}a_{k}x^{k}d\mu^{n}(x)
    = \sum_{k=0}^{n}a_{k}\int_{0}^{1}x^{k}d\mu^{n}(x)
    = \sum_{k=0}^{n}\sum_{j=0}^{n}a_{k}c_{j}x_{j}^{k}.
  \end{equation*}
  Therefore $\int_{0}^{1}P(x)d\mu^{n}(x)=P'(0)$ if and only if
  \begin{equation*}
    \sum_{k=0}^{n}a_{k}\sum_{j=0}^{n}x_{j}^{k}=a_{1}
  \end{equation*}
  or equivalently,
  \begin{equation*}
    \sum_{j=0}^{n}c_{j}x_{j}^{k}=\left\{ \begin{array}{l@{\quad:\quad}l}
                                           1  &k=1 \\
                                           0  &k\neq 1
                                         \end{array}\right.
  \end{equation*}
  or equivalently
  \begin{equation}\label{eq:matrix-equation}
    \begin{pmatrix}
      1 & 1 & \cdots & 1 \\
      x_{0} & x_{1} & \cdots & x_{n} \\
      x_{0}^{2} & x_{1}^{2} & \cdots & x_{n}^{2}\\ 
      \vdots  & \vdots  & \ddots & \vdots  \\
      x_{0}^{n} & x_{1}^{n} & \cdots & x_{n}^{n} 
    \end{pmatrix}
    \begin{pmatrix}
      c_{0}\\
      c_{1}\\
      c_{2}\\
      \vdots\\
      c_{n}\\
    \end{pmatrix}
    =
    \begin{pmatrix}
      0\\
      1\\
      0\\
      \vdots\\
      0\\
    \end{pmatrix}.
  \end{equation}
  Define 
  \begin{equation*}
    Q(x_{0},\ldots,x_{n}):= \det
    \begin{pmatrix}
      1 & 1 & \cdots & 1 \\
      x_{0} & x_{1} & \cdots & x_{n} \\
      x_{0}^{2} & x_{1}^{2} & \cdots & x_{n}^{2}\\ 
      \vdots  & \vdots  & \ddots & \vdots  \\
      x_{0}^{n} & x_{1}^{n} & \cdots & x_{n}^{n} 
    \end{pmatrix}.
  \end{equation*}
  The matrix equation \eqref{eq:matrix-equation} has a solution $\vec{c}=(c_{0},\ldots,c_{n})\in \R^{n+1}$ if and only if $Q(x_{0},\ldots,x_{n})\neq 0$. Therefore to prove the existence of the desired $\mu^{n}$, it will suffice to show there exists $(x_{0},\ldots,x_{n})\in (0,1)^{n+1}$ such that $Q(x_{0},\ldots,x_{n})\neq 0$.

  Since $Q$ is a polynomial, its null set has $(n+1)$-dimensional Lebesgue measure zero; i.e., 
  \begin{equation*}
    \mathcal{L}^{n+1} \left\{ (x_{0},\ldots,x_{n})\in (0,1)^{n+1}: Q(x_{0},\ldots,x_{n}) \right\} = 0.
  \end{equation*}
  (This is a fairly involved induction proof. \bnote{2021-07-22: Type this up?}) It follows that there exists $(y_{0},\ldots,y_{n})\in (0,1)^{n+1}$ such that $Q(y_{0},\ldots,y_{n})\neq 0$. This completes the proof.
\end{solution}

\part Does there exist two finite positive measures $\mu_{1},\mu_{2}$ supported on $[0,1]$ such that for any polynomial $P(x)$, it holds
\begin{equation*}
  P'(0) = \int_{0}^{1}P(x)d\mu_{1}(x) - \int_{0}^{1}P(x)d\mu_{2}(x)?
\end{equation*}

\begin{solution}
    No. Idea: if it were the case, then by Riesz Representation Theorem (which identifies an isometry between $C[0,1]^{*}$ and the normed linear space of signed radon measures on $[0,1]$) it would follow that there exists some $S\in C[0,1]^{*}$ such that $Sp =p'(0)$ for all polynomials on $[0,1]$. But this cannot be, because such an operator $S$ would not be continuous! To see why, let $p_{n}(x)= (1-x)^{n}$. Then $\norm{Sp_{n}}=n$ but $\norm{p_{n}}\leq 1$. Therefore $S$ is not bounded. 

\end{solution}
\end{parts}







\newpage
\section{Day 7: Baire Category}

\item (Jan 2020 \#7 R)
  A \textbf{Hamel basis} for a vector space $X$ is a collection $\mathcal{H}\subset X$ of vectors such that $x\in X$ can be written uniquely as a finite linear combination of elements in $\mathcal{H}$. Prove that an infinite dimensional Banach space cannot have a countable Hamel basis. (Hint: otherwise the Banach space would be first category in itself.)

\begin{solution}
  Denote the norm of $X$ by $\norm{\cdot}$. Suppose $\mathcal{H}$ is countable. Then there exists an enumeration $f_{1},f_{2},\ldots$ of $\mathcal{H}$. Let $E_{n}= \text{span}\left\{ f_{1},\ldots,f_{n} \right\}$. By definition of Hamel basis, $X=\cup_{n=1}^{\infty} E_{n}$. It will suffice to show that $E_{n}$ is nowhere dense, as this will imply that $X$---which is a complete metric space with respect to the norm topology---is a countable union of nowhere dense sets, contradicting the Baire Category theorem.

  Need to show $(\bar{E_{n}})^{\circ}=\emptyset$. Since $E_{n}$ is finite dimensional, it is closed (see lemma 1 below), and hence it suffices to show that $E_{n}^{\circ}=\emptyset$. Suppose $x\in E_{n}$, and let $\epsilon>0$. Then $x= x_{1}f_{1}+ \ldots + x_{n}f_{n}$. Since $X$ is infinite dimensional, there exists $f^{*}\in \mathcal{H}\backslash\left\{f_{1},\ldots,f_{n}\right\}$. Since $f^{*}\neq 0$, it follows that $y=x+ \frac{\epsilon}{2 \norm{f^{*}}}f^{*}\in E_{n}^{c}$. Moreover, $\norm{y-x} = \frac{\epsilon}{2 \norm{f^{*}}}\norm{f^{*}}< \epsilon$ (here $B(x,\epsilon)$ denotes the open ball $\left\{ z\in X: \norm{x-z}<\epsilon \right\}$). Therefore $y\in B(x,\epsilon)\cap E_{n}^{c}$. Therefore $B(x,\epsilon)\not\subset E_{n}$. Since $\epsilon>0$ was arbitrary, $x\notin E_{n}^{\circ}$. Since $x$ was arbitrary, $E_{n}^{\circ}=\emptyset$. This completes the proof.


  \vt
  \noindent \textit{Lemma 1:} $E_{n}$ is closed.
  \begin{proof}[Proof of Lemma 1:] Suppose $x_{k}\in E_{n}$ is a sequence such that $\norm{x_{k}-x}\to 0$ for some $x\in X$. We need to show that $x\in E_{n}$. We can write $x_{k} = \sum_{i=1}^{n} x_{k,i}f_{i}$.  Since $x_{k}$ is Cauchy in $E_{n}$,
    \begin{equation}\label{eq:cauchy-in-norm}
      \norm{x_{j}-x_{k}}\to 0\text{ as }j,k\to 0.
    \end{equation}
    
    Define a new norm $\norm{\cdot}_{1}$ by $\norm{z}_{1}:= |c_{1}|+\ldots+ |c_{n}|$ for $z=c_{1}f_{1}+ \ldots + c_{n}f_{n}$. Since norms on a finite-dimensional vector space are equivalent, \eqref{eq:cauchy-in-norm} implies that
    \begin{equation*}
      \norm{x_{j}-x_{k}}_{1} =  \norm{\sum_{i=1}^{n} (x_{j,i}-x_{k,i})f_{i}}= \sum_{i=1}^{n}|x_{j,i}-x_{k,i}| \to 0\text{ as }j,k\to 0.
    \end{equation*}
Therefore $(x_{k,i})_{k=1}^{\infty}$ is a Cauchy sequence of reals for each $i=1,\ldots,n$. Therefore by completeness of $\R$, for each $i$ there exists $y_{i}\in \R$ such that $\lim_{k\to\infty}x_{k,i}=y_{i}$. It is then easy to see that $x_{k}\to \sum_{i=1}^{n}y_{i}f_{i}$ in norm. By uniqueness of limits, $x=\sum_{i=1}^{n}y_{i}f_{i}$. Since $\sum_{i=1}^{n}y_{i}f_{i}\in E_{n}$, it follows $x\in E_{n}$, as desired.
  \end{proof}
\end{solution}

\question (September, 2017) Let $f_n$ be a sequence of real functions on $\RR$ such that each $f_n'$ is continuous on $\RR$. Suppose that as $n \to \infty$, $f_n$ converges to a function $f: \RR \to \RR$ pointwise, and $f_n'$ converges to a function $g$ pointwise.

Prove that there exists a non-empty interval $(a,b)$ and a constant $L < \infty$ such that
%
\[ |f(x) - f(y)| \leq L |x-y|. \]
%
Hint: Consider the sets $K_c = \{ x: \sup_n |f_n'(x)| \leq c \}$.
\begin{solution}
    For each $x$, $f_n'(x) \to f(x)$, so that the sequence of quantities $\{ f_n(x) \}$ is bounded. It follows that if
    %
    \[ K_c = \{ x : \sup_n |f_n'(x)| \leq c \}, \]
    %
    then $\bigcup_{c = 1}^\infty K_c = \RR$. Since the supremum of continuous functions is lower semi-continuous, each $K_c$ is a closed set. And thus the Baire category theorem implies that there exists $L$ such that $K_L$ contains an interval. Thus there is an interval $(a,b)$ such that for all $x \in (a,b)$, $\sup |f_n'(x)| \leq L$. Thus by the Mean value theorem
    %
    \[ |f(x) - f(y)| = \limsup_{n \to \infty} |f_n(x) - f_n(y)| \leq \limsup_{n \to \infty} |x - y| \| f_n \|_{L^\infty(a,b)} \leq L |x - y|. \]
\end{solution}

\item (Fall 2016 \# 8) Show that there is a continuous real valued function on $[0,1]$ that is not monotone on any open interval $(a,b)\subset [0,1]$.

% \begin{solution}
%   Suppose not. Let $E_{q,n}= \left\{ f\in C([0,1]): f \text{ monotone on }(q-1/n,q+1/n) \right\}.$ Then
%   \begin{equation}\label{eq:big-union}
%     C([0,1]) = \bigcup_{q\in \Q}\bigcup_{n\geq 1}E_{q,n}.
%   \end{equation}
%   We claim that each $E_{q,n}$ is closed, indeed suppose $(f_{k})$ is a sequence of monotone function on $(q-1/n,q+1/n)$ such that $f_{k}\to f$ uniformly. Then there exists a subsequence $(k_{j})$ with $k_{j}\to \infty$ and such that $f_{k_{j}}$ is an increasing function for all $j$ or $f_{k_{j}}$ is a decreasing function for all $j$. Without loss suppose that they are increasing functions. If $x\leq y$ then $f_{k_{j}}(x)-f_{k_{j}}(y)\leq $ for all $j$, and hence sending $j\to \infty$, we have $f(x)\leq f(y)$. Thus $f$ is increasing. This proves that $E_{q,n}$ is closed.
  
%   Since $C([0,1])$ is a complete metric space and  \eqref{eq:big-union} is a countable union of close sets, it follows by Baire's theorem that there exists some $q\in Q$ and $n\geq 1$ such that $E_{q,n}$ has nonempty interior. That is, there exists $f^{*}\in E_{q,n}$ and $\epsilon>0$ such that $\left\{ f\in C([0,1]): \norm{f^{*}-f}_{\infty} < \epsilon\right\}\subset E_{q,n}.$ Therefore every $f$ with $\norm{f^{*}-f}_{\infty}<\epsilon$ is monotone on the interval $(q-1/n,q+1/n)$. But this is absurd, since any function can by approximated uniformly by zig-zag functions (draw a picture). 

% \end{solution}

\begin{solution}
  Suppose not. Then we can write $C([0,1])$ as the following countable union:
  \begin{equation}\label{eq:big-union}
    C([0,1]) = \bigcup_{a,b\in \Q, a<b}E_{a,b}.
  \end{equation}
  where $E_{a,b}= \left\{ f\in C([0,1]): f \text{ monotone on }(a,b) \right\}.$
  
  We claim that each $E_{a,b}$ is closed. Indeed suppose $(f_{k})$ is a sequence of monotone function on $(a,b)$ such that $f_{k}\to f$ uniformly. Then there exists a subsequence $(k_{j})$ with $k_{j}\to \infty$ and such that $f_{k_{j}}$ is an increasing function for all $j$ or $f_{k_{j}}$ is a decreasing function for all $j$. Without loss suppose that they are increasing functions. If $x\leq y$ then $f_{k_{j}}(x)-f_{k_{j}}(y)\leq $ for all $j$, and hence sending $j\to \infty$, we have $f(x)\leq f(y)$. Thus $f$ is increasing. Thus $E_{a,b}$ is closed. This proves the claim.
  
  Next, we observe that since $C([0,1])$ is a complete metric space and can be written as a countable union \eqref{eq:big-union} of close sets, it follows by Baire's theorem that there exists some $a,b\in Q$ with $a<b$ such that $E_{a,b}$ has nonempty interior. That is, there exists $f^{*}\in E_{a,b}$ and $\epsilon>0$ such that $\left\{ f\in C([0,1]): \norm{f^{*}-f}_{\infty} < \epsilon\right\}\subset E_{a,b}.$ Therefore every $f$ with $\norm{f^{*}-f}_{\infty}<\epsilon$ is monotone on the interval $(a,b)$. But this is absurd, since any function can by approximated uniformly by zig-zag functions (draw a picture). 

\end{solution}

\item (Jan 2014 \#6)
  Does there exist a sequence of continuous functions $f_{n}:[0,1]\to \R$ such that $f_{n}\to \chi_{\Q}$ pointwise?

\begin{solution}
  No. Suppose such a sequence $(f_{n})$ exists. Then we can write
  \begin{equation*}
    \left[ 0,1 \right] = \bigcup_{k\geq 1} \left\{ x\in [0,1]: \left| f_{n}(x)-f_{m}(x) \right| \leq \frac{1}{4} \text{ for all }m,n\geq k\right\}.
  \end{equation*}

  Since the right hand side is a countable union of closed sets, it follow by the Baire Category theorem taht there exists some $k_{0}$ and some $(a,b)$ such that for all $x\in (a,b)$,
  \begin{equation*}
    |f_{n}(x)-f_{m}(x)| \leq \frac{1}{4}\quad\text{ for all }n,m\geq k_{0}.
  \end{equation*}
  Sending $m\to \infty$,
  \begin{equation*}
    |f_{n}(x)-f(x)| \leq \frac{1}{4}\quad\text{ for all }n\geq k_{0}.
  \end{equation*}
  Let $n\geq k_{0}$. If $x\in (a,b)\backslash \Q$ then $|f_{n}(x)|\leq \frac{1}{4}$. But if $x\in (a,b)\cap \Q$ then $|f_{n}(x)-1|\geq \frac{1}{4}$, so that $|f_{n}(x)|\geq \frac{3}{4}$. But this contradicts the continuity of $f_{n}$.
\end{solution}


\item (August 2014 \#6)
  Let $X,Y$ be Banach spaces and $\left\{ T_{j,k}: j,k\in \mathbb{N} \right\}$ be a set of bounded linear transformations $X\to Y$. Suppose for each $k$, there exists $x\in X$ such that $\sup \left\{ \norm{T_{j,k}x}:  j\in \mathbb{N} \right\} = \infty.$ Then there is an $x\in X$ such that $\sup \left\{ \norm{T_{j,k} x} : j\in \mathbb{N}\right\} = \infty$ for all $k.$
  \begin{solution}
    Proof by contrapositive. Suppose that the conclusion does not hold: that is, suppose that for all $x\in X$ there exists some $k$ such that $\sup \{\norm{T_{j,k_{0}}x}:j\in\mathbb{N}\}<\infty$. Then we can write
\begin{equation*}
  X=\bigcup_{k= 1}^{\infty} \bigcup_{N= 1}^{\infty} \bigcap_{j= 1}^{\infty} \left\{ x\in X: \norm{T_{j,k}x}\leq N \right\}.
\end{equation*}
By Baire Category theorem, there exists $k_{0},N_{0}\geq 1$ and some ball $\bar{B}_{r}(x_{0})= \{x\in X : \norm{x-x_0}\leq r\}$ with $r>1$ such that $$\sup_{j\geq 1}\norm{T_{j,k_{0}}x}\leq N_{0}$$ for all $x\in \bar{B}_r(x_0)$.

It will suffice to show that for this choice of $k_{0}$, we have $\sup \{\norm{T_{j,k_{0}}x}: j\in \mathbb{N}\}<\infty$ for all $x\in X$.

Let $x\in X$. There are two cases:

\textit{Case 1.} Suppose $\norm{x}\leq 1$. Then $rx+x_{0}\in \bar{B}_{r}(x_{0})$, and hence
\begin{align*}
  \norm{T_{j,k_{0}}x}
  &= \frac{1}{r}\norm{T_{j,k_{0}}(rx)}\\ 
  &=  \frac{1}{r} \norm{T_{j,k_{0}}(rx + x_{0})-T_{j,k_{0}}x_{0}}\\ 
  &\leq \frac{1}{r}\norm{T_{j,k_{0}}(rx + x_{0})} +\frac{1}{r}\norm{T_{j,k_{0}}x_{0}}\\ 
  &\leq 2N_{0}/r
\end{align*}
for all $j$.

\textit{Case 2.} Suppose $\norm{x}>1$. Let $x_1 = x/\norm{x}$. By Case 1,
\begin{equation*}
\norm{T_{j,k_0} x} = \norm{x} \norm{T_{j,k_0}x_1} \leq 2\norm{x}N_0/r
\end{equation*}
for all $j$. 

Combining the two cases, the result follows.
\end{solution}








\newpage

\section{Day 8: Intro to Distribution}
\item (Fall 2020, \# 8R)
Consider the function $f:\R^{2}\to \R$ given by $f(x,y)=|x|$. Find $\left( \frac{\partial ^{2}}{\partial x^{2}}+ \frac{\partial ^{2}}{\partial y^{2}} \right)f$, where the derivative is taken in the sense of distributions.

\begin{solution}
  Let $\phi\in C_{c}^{\infty}(\R^{2})$. By definition of distributional derivative, 
  \begin{align*}
    \Big\langle  \left( \frac{\partial ^{2}}{\partial x^{2}}+ \frac{\partial ^{2}}{\partial y^{2}} \right)f, \phi\Big\rangle
    &= \Big\langle f, \left(\frac{\partial ^{2}}{\partial x^{2}}+ \frac{\partial ^{2}}{\partial y^{2}} \right) \phi \Big\rangle\\ 
    &= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}|x| \phi_{xx}(x,y)+ |x|\phi_{yy}(x,y)dxdy\\
    &= \underbrace{\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}|x| \phi_{xx}(x,y)dxdy}_{A}+ \underbrace{\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}|x|\phi_{yy}(x,y)dxdy}_{B}.
  \end{align*}
  Integrating by parts,
  \begin{align*}
    A&= \int_{-\infty}^{\infty}\left[\int_{0}^{\infty}x \phi_{xx}(x,y)dx - \int_{-\infty}^{0}x\phi_{xx}(x,y)\right]dy\\
     &= \int_{-\infty}^{\infty}\left[-\int_{0}^{\infty}\phi_{x}(x,y)dx + \int_{-\infty}^{0}\phi_{x}(x,y)\right]dy\\
     &= \int_{-\infty}^{\infty} -\left[ \phi(x,y) \right]^{x=\infty}_{x=0}+ \left[ \phi(x,y) \right]^{x=0}_{x=-\infty}dy\\
     &=2\int_{-\infty}^{\infty}\phi(0,y)dy
  \end{align*}
  Next, by Fubini's theorem,
  \begin{align*}
    B= \int_{-\infty}^{\infty}|x|\int_{-\infty}^{\infty}\phi_{yy}(x,y)dydx = 0
  \end{align*}
  because $\int_{-\infty}^{\infty}\phi_{yy}(x,y)dy = \left[ \phi_{y}(x,y) \right]^{y=\infty}_{y=-\infty}= 0$ for every $x$. It follows from our calcuations for $A$ and $B$ that
  \begin{equation*}
    \Big\langle  \left( \frac{\partial ^{2}}{\partial x^{2}}+ \frac{\partial ^{2}}{\partial y^{2}} \right)f, \phi\Big\rangle = 2\int_{-\infty}^{\infty}\phi(0,y)dy
  \end{equation*}
  for every $\phi$. Therefore $\left( \frac{\partial ^{2}}{\partial x^{2}}+ \frac{\partial ^{2}}{\partial y^{2}} \right)f= 2\delta(x)$ in the sense of distributions, where $\delta$ is the point mass at $x=0$.
\end{solution} 


\question (January 2017)
\begin{parts}
    \part Let $f \in L^1(\RR)$ and consider the sequence of distributions $T_n(x) = \sin(nx^2) f(x)$. Show that $\lim_{n \to \infty} T_n = 0$ in the sense of distributions.
    \begin{solution}
        We perform an integration by parts, which is always handy when dealing with oscillatory things. If $\Lambda_n(x) = \sin(nx^2)$, then
        %
        \begin{align*}
            \int \Lambda_n(x) \phi(x)\; dx &= \int \Lambda_n'(x) \frac{\phi(x)}{2n x}\\
            &= - \int \Lambda_n(x) \frac{d}{dx} \left( \frac{\phi(x)}{2nx} \right)\\
            &= - \int \Lambda_n(x) \left( \frac{\phi'(x)}{2nx} - \frac{\phi(x)}{2nx^2} \right).
        \end{align*}
        %
        Now performing a Taylor expansion, we can write
        %
        \[ \frac{\phi'(x)}{2nx} - \frac{\phi(x)}{2nx^2} = \frac{\phi'(0)}{2nx} - \frac{\phi(0)}{2nx^2} - \frac{\phi'(0)}{2nx} + O(1/n) = \frac{\phi'(0)}{2nx} + O(1/n). \]
        %
        But since $1/x$ is odd, and $\sin(nx^2)$ is even, we have
        %
        \[ \int \Lambda_n(x) \frac{\phi'(0)}{2nx}\; dx = 0. \]
        %
        Thus
        %
        \[ \int \Lambda_n(x) \phi(x) \lesssim_\phi O(1/n), \]
        %
        Taking $n \to \infty$ shows that $\Lambda_n$ converges to 0 distributionally.
    \end{solution}
    
    \part Find a distribution $T \in \mathcal{D}'(\RR)$ such that $T_n = \sin(nx^2)T$ does not converge to $0$ in the sense of distributions as $n \to \infty$.
    \begin{solution}
        One can find a distribution $T$ such that for $\phi$ supported away from the origin,
        %
        \[ \int \phi(x) (1/x^2)\; dx. \]
        %
        One choice is provided in a previous question. Consider a non-negative test function $\phi$ supported away from the origin (for simplicity, supported on $x > 0$), we have
        %
        \[ \int \sin(nx^2) T(x) \phi(x)\; dx = \int \frac{\sin(nx^2) \phi(x)}{x^2}. \]
        %
        For large $n$, we have $\sin(nx^2) \geq nx^2/2$ on the support of $\phi$, which implies that
        %
        \[ \int \frac{\sin(nx^2) \phi(x)}{x^2} \geq n/2 \int \phi(x)\; dx.  \]
        %
        This clearly does not converge to zero as $n \to \infty$.
    \end{solution}
\end{parts}

\question (January, 2015)
\begin{parts}
    \part If $f \in C[0,1]$, and the distributional derivative $f'$ of $f$ on $(0,1)$ is in $L^1((0,1))$, prove that
    %
    \[ f(1) - f(0) = \int_0^1 f'(x)\; dx. \]
    \begin{solution}
        In order to relate $f'$ and $f$, since $f'$ is a distributional derivative, we need to integrate it against a test function, which reduces the question to a basic analysis problem. Fix $\delta > 0$ and consider $\phi_\delta \in C_c^\infty[0,1]$ with $\| \phi_\delta \|_\infty \leq 1$, $\phi_\delta(x) = 1$ for $\delta \leq x \leq 1-\delta$, and supported on $\delta/2 \leq x \leq 1 - \delta/2$, and with $\| \phi_\delta' \|_\infty \leq 10/\delta$. Then $\phi_\delta'$ is supported on $\delta/2 \leq x \leq \delta$ and $1-\delta/2 \leq x \leq 1-\delta$. Since $f'$ is integrable, we have
        %
        \[ \int_0^1 f'(x)\; dx = \lim_{\delta \to 0} \int_0^1 f'(x) \phi_\delta(x)\; dx. \]
        %
        Since $f'$ is a distributional derivative, we can apply an integration by parts, from which we conclude that
        %
        \[ \int_0^1 f'(x) \phi_\delta(x)\; dx = - \int_0^1 f(x) \phi_\delta'(x)\; dx. \]
        %
        We can write
        %
        \[ \int_0^1 f(x) \phi_\delta'(x)\; dx = \int_0^{\delta} f(x) \phi_\delta'(x)\; dx + \int_{1-\delta} f(x) \phi_\delta'(x)|; dx. \]
        %
        Since $f \in C[0,1]$, for each $\varepsilon > 0$, there exists $\delta_0 > 0$ such that for $x,y \in [0,1]$ with $|x-y| \leq \delta_0$, $|f(x) - f(y)| \leq \varepsilon$. If $\delta \leq \delta_0$, this implies that
        %
        \[ \left| \int_0^\delta [f(x) - f(0)] \phi_\delta'(x)\; dx \right| \leq \int_0^\delta \varepsilon |\phi_\delta'(x)| \leq \varepsilon. \]
        %
        Similarily,
        %
        \[ \left| \int_{1 - \delta}^1 [f(x) - f(1)] \phi_\delta'(x)\; dx \right| \leq \int_{1-\delta}^1 \varepsilon |\phi_\delta'(x)| \leq \varepsilon. \]
        %
        The fundamental theorem of calculus implies that
        %
        \[ \int_0^\delta f(0) \phi_\delta'(x) = f(0) [\phi_\delta(\delta) - \phi_\delta(0)] = f(0), \]
        %
        and
        %
        \[ \int_{1-\delta}^1 f(1) \phi_\delta'(x) = f(1) [\phi_\delta(1) - \phi_\delta(1-\delta)] = - f(1). \]
        %
        Putting these calculations together shows that
        %
        \[ \lim_{\delta \to 0} \int_0^1 f(x) \phi_\delta'(x)\; dx = f(0) - f(1), \]
        %
        and thus
        %
        \[ \int_0^1 f'(x)\; dx = - \lim_{\delta \to 0} \int_0^1 f(x) \phi_\delta'(x) = f(1) - f(0). \]
    \end{solution}
    
    \part Let $p \in [1,\infty)$ and let $F \subset C[0,1]$ be such that for each $f \in F$ we have $\| f \|_{L^1[0,1]} \leq 1$ and $\| f' \|_{L^p[0,1]} \leq 1$, where $f'$ is the distributional derivative of $f$. Prove that $F$ is precompact in $C[0,1]$, or find a counter-example.
    \begin{solution}
        Problems about pre-compactness in $C[0,1]$ normally want us to apply the Arzela-Ascoli theorem, so lets try that here. We wish to show there is a constant $C > 0$ such that for each $f \in C[0,1]$,
        %
        \[ \| f \|_\infty \leq C, \]
        %
        (uniform boundedness), and that for each $\varepsilon > 0$, there is $\delta > 0$ such that for $|x - y| \leq \delta$ and $f \in F$, $|f(x) - f(y)| \leq \varepsilon$ (equicontinuity).
        
        Using the last part of the problem, together with H\"{o}lder's inequality, if $p$ and $p^*$ are conjugates, then for $x < y$,
        %
        \[ |f(x) - f(y)| = \left| \int_x^y f'(x)\; dx \right| \leq \| f' \|_p \left( \int_x^y 1 \right)^{1/p^*} = |y - x|^{1/p^*} \| f' \|_p \leq |y - x|^{1/p^*}. \]
        %
        Thus $f$ satisfies a H\"{o}lder condition, uniformly over elements of $f$. This gives equicontinuity.
        
        To show $F$ is uniformly bounded, we must exploit the fact that $\| f \|_1 \leq 1$. Suppose that $\| f \|_\infty \geq M$. Then there exists $x_0 \in [0,1]$ such that $|f(x_0)| \geq M$. Using the H\"{o}lder condition, we find that $|f(x_0)| \geq M/2$ for $|y - x_0| \leq (M/2)^{p^*}$. And so we find that $\| f \|_1 \geq (M/2) \cdot 2 (M/2)^{p^*} \gtrsim_p M^{1 + p^*}$. Since $\| f \|_1 \leq 1$, this means that $M^{1 + p^*} \lesssim_p 1$, and so $M \lesssim_p 1$. This means we have shown that there exists a constant $C_p$ such that for all $f \in F$, $\| f \|_\infty \leq C_p$.
        
        Thus we have shown that the hypothesis of the Arzela-Ascoli theorem applies, and so $F$ is precompact.
    \end{solution}
\end{parts}


\item (January 2016 \#8) Prove or disprove:
  \begin{parts}
    \part There exists a distribution $u\in \mathcal{D}(\R)$ so that the restriction to $(0,\infty)$ is given by
    \begin{equation*}
      \langle u, f \rangle = \int_{0}^{\infty}e^{1/x^{2}}f(x)dx
    \end{equation*}
    for all $f\in C^{\infty}(\R)$ which are compactly supported in $(0,\infty)$.
    \begin{solution}
      Part (a): Does not exist. Idea: if such a distribution exists, then there exists $N,C$ such that $$|\langle u,\phi\rangle|\leq C \norm{\phi}_{N}.$$ But we will construct a sequence $\phi_{n}$ so that the left hand side blows up faster than the right hand side. We will want the functions $\phi_{n}$ to get more an more concentrated near 0.
      
      Let $\phi\in C_{c}^{\infty}(0,2)$ such that $\phi(x)=1$ for all $x\in [1/2,1]$. Define $\phi_{n}(x) = \phi(2^{n}x)$. Then $\phi_{n}(x)=1$ for all $x\in [2^{-(n+1)},2^{-n}]=:I_{n}$. We have
      \begin{equation*}
        \langle u, \phi_{n}\rangle \geq \int_{I_{n}} e^{x^{-2}}dx \geq e^{4^{n}}2^{-(n+1)}
      \end{equation*}
      On the other hand,
      \begin{equation*}
        \norm{\phi_{n}}_{N} = \sum_{k\leq N}\norm{\phi_{n}^{(k)}}_{\infty}= \sum_{k\leq N}\norm{2^{kn}\phi^{(k)}(2^{n}x)}_{\infty}\leq 2^{Nn}\norm{\phi}_{N}
      \end{equation*}
      Therefore,
      \begin{equation*}
        \frac{\langle u, \phi_{n}\rangle }{\norm{\phi_{n}}_{N}}\geq \frac{e^{4^{n}}2^{-(n+1)}}{2^{Nn}}\to \infty \text{ as }n\to\infty.
      \end{equation*}
    \end{solution}

    \part There exists a distribution $u\in \mathcal{D}'(\R)$ so that its restriction to $(0,\infty)$ is given by
    \begin{equation*}
      \langle u,f \rangle = \int_{0}^{\infty}x^{-2}e^{i/x^{2}}f(x)dx
    \end{equation*}
    for all $f\in C^{\infty}$ which are compactly supported in $(0,\infty)$.
    \begin{solution}
      Part (b): Yes, such a distribution exists. Let $f\in \mathcal{D}(\R)$ with $\text{supp}(f)\subset (0,\infty)$. Write $x^{-2}e^{ix^{-2}} = \frac{ix}{2}\frac{d}{dx}\left[ e^{ix^{-2}} \right]$, so that
      \begin{align*}
        \langle u , f \rangle &= \int_{0}^{\infty} \frac{d}{dx}\left[ e^{ix^{-2}} \right]\frac{ix}{2}f(x) dx\\
                              &= \int_{0}^{\infty} e^{ix^{-2}}\left(\frac{i}{2}f(x) + \frac{ix}{2}f'(x)\right) dx\\
                              &= \frac{i}{2}\int_{0}^{\infty} e^{ix^{-2}}\left(f(x) + xf'(x)\right) dx.
      \end{align*}
      and it is easy to verify that this formula defines a distribution for all $f\in \mathcal{D}(\R)$.
    \end{solution}
  \end{parts}





\question (September, 2017) A distribution $T \in \mathcal{S}'(\RR^n)$ is said to be \emph{nonnegative} if $\langle T, \phi \rangle \geq 0$ for every test function $\phi \in \mathcal{S}(\RR^n)$ with $\phi(x) \geq 0$ for all $x \in \RR^n$.
\begin{parts}
    \part Suppose $f \in L^1_{\text{loc}}(\RR^n)$, and let $T_f$ be the distribution defined by $f$. Show that $T_f \geq 0$ if and only if $f \geq 0$ for almost all $x \in \RR^n$.
    \begin{solution}
        Suppose $f < 0$ on a set of positive measure. Then we may find $R > 0$ and $c > 0$ such that the set $E = \{ |x| \leq R: f(x) < -c \}$ has positive measure. Fix $\delta > 0$ and find an open set $U$ contained $E$ with $|U - E| \leq \delta$. Since $U$ is pre-compact, we can find a smooth function $\phi$ compactly supported on a set $V$ such that $f(x) = 1$ for $x \in U$, and $|V - U| \leq \delta$. Then
        %
        \[ \left| \int f(x) \phi(x)\; dx - \int_E f(x)\; dx \right| \leq \int_{V - U} |f(x)|\;dx. \]
        %
        Since $f$ is integrable, and $|V - E| \leq 2\delta$, for any fixed $\varepsilon > 0$, if $\delta$ is suitably small, then
        %
        \[ \int_{V - U} |f(x)|\; dx \leq \varepsilon. \]
        %
        On the other hand,
        %
        \[ \int_E f(x)\; dx \leq -c|E|, \]
        %
        and so
        %
        \[ 0 \leq \int f(x) \phi(x) \leq \varepsilon - c |E|. \]
        %
        Taking $\varepsilon \to 0$ gives a contradiction.
    \end{solution}
    
    \part Show that if $T_n \to T$ in the sense of distributions, and if $T_n \geq 0$ for all $n$, then $T \geq 0$.
    \begin{solution}
        If $\phi \geq 0$, then $\langle T_n, \phi \rangle \geq 0$ for all $n$ since $T_n \geq 0$. But $\langle T, \phi \rangle = \lim_n \langle T_n, \phi \rangle$, which implies that $\langle T,\phi \rangle \geq 0$.
    \end{solution}
    
    \part Suppose $\Phi: \RR \to \RR$ is a $C^2$ function with $\Phi'' \geq 0$ in $\RR$, and let $f \in C^2(\RR^n)$ have compact supported. Show that $\Delta(\Phi(f(x)) \geq \Phi'(f(x)) \Delta f(x)$.
    \begin{solution}
        We calculate directly that
        %
        \[ \Delta(\Phi(f(x))) = \Phi'(f(x)) \Delta f + \sum_{i = 1}^n \Phi''(f(x)) \left( \frac{\partial f}{\partial x^i} \right)^2. \]
        %
        Since $\Phi''(f(x)) (\partial f / \partial x^i)^2 \geq 0$, this easily implies the inequality.
    \end{solution}
    
    \part Suppose $f \in C^2(\RR^n)$ has compact support. Show that $\Delta |f| \geq \text{sign}(f(x)) \Delta f(x)$ holds in the sense of distributions. (Hint use (c) with $\Phi(t) = \sqrt{\varepsilon + t^2})$.
    \begin{solution}
        For each $\varepsilon > 0$, if $\Phi_\varepsilon(t) = \sqrt{\varepsilon + t^2}$, then $\Phi_\varepsilon \in C^\infty(\RR)$, and the part (c) implies that
        %
        \[ \Delta(\sqrt{\varepsilon + f^2}) \geq \frac{f \cdot \Delta f}{\sqrt{\varepsilon + f^2}} \]
        %
        Our goal is to take $\varepsilon \to 0$ to show that $\Delta|f| \geq \text{sign}(f) \Delta f$.
        
        As $\varepsilon \to 0$, $\sqrt{\varepsilon + f^2}$ converges distributionally to $|f|$ by the dominated convergence theorem. Given $\phi \in C_c^\infty(\RR^d)$, $\phi(x) \sqrt{\varepsilon + f(x)^2} \to \phi(x) |f(x)|$ pointwise for every $x$, and is upper bounded by $2|\phi(x)| (1 + |f(x)|)$, which is integrable since $\phi$ is compactly supported. Thus
        %
        \[ \int \sqrt{\varepsilon + f(x)^2} \phi(x)\; dx \to \int |f(x)| \phi(x)|; dx. \]
        %
        Similarily, one can argue using the dominated convergence theorem that $f(x) \Delta f(x) / \sqrt{\varepsilon + f(x)^2}$ converges distributionally to $\text{sign}(f(x)) \Delta f(x)$, since it converges pointwise to this function, and is uniformly upper bounded in absolute value by $\Delta f(x)$. Applying (b) shows that $\Delta |f(x)| \geq \text{sign}(f(x)) \cdot \Delta f(x)$.
    \end{solution}
\end{parts}






\item (Jan 2020 \#8 R)
\begin{parts}
  \part Suppose $\Lambda$ is a distribution on $\R^{n}$ such that $\text{supp}(\Lambda)=\left\{ 0 \right\}.$ If $f\in C^{\infty}(\R^{n})$ satisfies $f(0)=0$, does it follow that $f\Lambda = 0$ as a distribution?
  \begin{solution}
    No. Let $n=1$, $f(x)=x$, and $\Lambda=D\delta$. It is clear that $\Lambda$ has support $\left\{ 0 \right\}$. But $\langle f\Lambda, \phi \rangle = \langle \Lambda , x\phi\rangle = \langle \delta, -(x\phi)'\rangle = \langle \delta, -\phi' - x\phi\rangle = -\phi'(0)$. Therefore $f\Lambda = -\delta$ in the sense of distributions, and hence is not the zero distribution.
  \end{solution}

  \part Suppose $\Lambda$ is a distribution on $\R^{n}$ such that $\text{supp}(\Lambda)\subseteq K$, where $K=\left\{ x\in \R^{n}: |x|\leq 1 \right\}$. If $f\in C^{\infty}(\R^{n})$ vanishes on $K$, does it follow that $f\Lambda =0$ as a distribution?
  \begin{solution}
    This part is true. Since $\text{supp}(\Lambda)$ is compact, it follows that $\Lambda$ is of finite order. Then $\Lambda = \sum_{\alpha\in \mathcal{A}}D^{\alpha}g_{\alpha}$ where $g_{\alpha}$ is a continuous function for each $\alpha\in \mathcal{A}$ and $\mathcal{A}$ is a finite set of multi-indices. Let $N = \max\left\{|\alpha|: \alpha\in \mathcal{A}\right\}$.

    Let $\phi\in C^{\infty}_{c}(\R^{n})$ and let $M>0$ such that $\text{supp}(\phi)\subseteq \left\{ x: |x|\leq M \right\}$. Then
    \begin{align*}
      \langle f\Lambda, \phi \rangle
      &=\langle \Lambda, f\phi \rangle\\
      &=\int_{\R^{n}} \sum_{\alpha\in \mathcal{A}}(-1)^{|\alpha|}g_{\alpha}(x)D^{\alpha}(f\phi)(x)dx\\
      &=\sum_{\alpha \geq \beta }(-1)^{|\alpha|}c_{\alpha\beta}\int_{\R^{n}} g_{\alpha}(x)(D^{\alpha-\beta}f)(D^{\beta}\phi)dx
      &&\text{by Leibniz Formula}\\
      &=\sum_{\alpha \geq \beta }(-1)^{|\alpha|}c_{\alpha\beta}\int_{|x|>1} g_{\alpha}(x)(D^{\alpha-\beta}f)(D^{\beta}\phi)dx
      &&\text{since $D^{\alpha-\beta}f(x)=0$ for all $x\in K$}\\
      &=\lim_{\epsilon\to 0^{+}}\sum_{\alpha \geq \beta }(-1)^{|\alpha|}c_{\alpha\beta}\int_{|x|>1+\epsilon} g_{\alpha}(x)(D^{\alpha-\beta}f)(D^{\beta}\phi)dx
    \end{align*}
    We claim this limit is zero. To see this, we first define a cutoff function $\eta_1(x)\in C_c^{\infty}(\R^n)$ with $0\leq \eta_1\leq 1$ such that $\eta_1(x)= 0$ if $|x|<1$, and $\eta_1(x)= 1$ if $2\leq |x|\leq M$. Next, for each $\epsilon\in (0,1)$, define $\eta_{\epsilon}\in C_c^{\infty}$ satisfying
    \begin{equation*}
      \eta_{\epsilon}(x) = \left\{ \begin{array}{l@{\quad:\quad}l}
                                   0  & |x|\leq 1+\epsilon/2 \\
                                   \eta_{1}\left(\frac{2x}{\epsilon} - \frac{2}{\epsilon}\right) & 1+\epsilon/2 < |x| \leq 1+\epsilon \\
                                   1  & 1+\epsilon <|x|\leq M \\
                                   \text{smooth} & |x|>M
                                   \end{array}\right.
    \end{equation*}
    (Draw a picture for the $n=1$ case. This isn't as complicated as it looks.) 
    
    
    By the chain rule, $|D^{\alpha} \eta_{\epsilon}| \leq C\cdot 2^{|\alpha|}\epsilon^{-|\alpha|}$ where $C<\infty$ is an upper bound for the first order derivatives of $\eta_1$. Then taking $\phi_{\epsilon} = \eta_{\epsilon} \phi$,
    
    
    \begin{align*}
      \langle f\Lambda, \phi_{\epsilon}\rangle
      &= \sum_{\alpha \geq \beta }(-1)^{|\alpha|}c_{\alpha\beta}\int_{1+ \epsilon\geq |x|>1+\frac{\epsilon}{2}} g_{\alpha}(x)(D^{\alpha-\beta}f)(D^{\beta}\phi_{\epsilon})dx\\
      &\quad +  \sum_{\alpha \geq \beta }(-1)^{|\alpha|}c_{\alpha\beta}\int_{|x|>1+\epsilon} g_{\alpha}(x)(D^{\alpha-\beta}f)(D^{\beta}\phi)dx
    \end{align*}
    On the other hand, $\text{supp}(f\phi_{\epsilon}) \subset \R^n\backslash B(0,1+\frac{\epsilon}{2})$. Therefore $f\phi_{\epsilon}\in \mathcal{D}(K^{c})$ and hence by definition of distribution support, $\langle f\Lambda, \phi_{\epsilon}\rangle = \langle \Lambda, f\phi_{\epsilon}\rangle =0$. Therefore
    \begin{align*}
      \langle f\Lambda, \phi \rangle
      &= \lim_{\epsilon\to 0^{+}}-\sum_{\alpha \geq \beta }(-1)^{|\alpha|}c_{\alpha\beta}\int_{1+ \epsilon\geq |x|>1+\frac{\epsilon}{2}} g_{\alpha}(x)(D^{\alpha-\beta}f)(D^{\beta}\phi_{\epsilon})dx
    \end{align*}
    Therefore
    \begin{align} \label{dist-up-bound}
      |\langle f\Lambda, \phi \rangle|
      &\leq \limsup_{\epsilon\to 0^{+}}\sum_{\alpha \geq \beta } |c_{\alpha\beta}|\int_{1+ \epsilon\geq |x|>1+\frac{\epsilon}{2}} \left| g_{\alpha}(x)(D^{\alpha-\beta}f)(D^{\beta}\phi_{\epsilon})\right|dx.
    \end{align}
    In particular, for each $\epsilon>0$, using the Leibniz formula again
    \begin{align*}
    &\sum_{\alpha \geq \beta } |c_{\alpha\beta}|\int_{1+ \epsilon\geq |x|>1+\frac{\epsilon}{2}} \left| g_{\alpha}(D^{\alpha-\beta}f)(D^{\beta}\phi_{\epsilon})\right|dx \\
    &\leq \sum_{\alpha \geq \beta } |c_{\alpha\beta}|\int_{1+ \epsilon\geq |x|>1+\frac{\epsilon}{2}} \left| g_{\alpha}(D^{\alpha-\beta}f)\right|\left|\sum_{\beta\geq \gamma} c_{\gamma} D^{\gamma}\phi  D^{\gamma-\beta}\eta_{\epsilon} \right|dx \\
    &\leq \sum_{\alpha \geq \beta }  \sum_{\beta\geq \gamma} |c_{\alpha\beta}| |c_{\gamma}|\frac{C}{(\epsilon/2)^N}\int_{1+ \epsilon\geq |x|>1+\frac{\epsilon}{2}} \left| g_{\alpha}(D^{\alpha-\beta}f)\right| \left| D^{\gamma}\phi \right|dx.
    \end{align*}
    Therefore as $\epsilon\to 0^+$, we have $\frac{1}{(\epsilon/2)^N}\int_{1+ \epsilon\geq |x|>1+\frac{\epsilon}{2}} \left| g_{\alpha}(D^{\alpha-\beta}f)\right| \left| D^{\gamma}\phi \right|dx \to 0$ since $(D^{\alpha-\beta}f)(x)=0$ for all $x$ with $|x|=1$. Then it follows by \eqref{dist-up-bound} that $\langle f\Lambda, \phi\rangle = 0$. Since $\phi$ was arbitrary, $f\Lambda=0$ in the sense of distributions.
  \end{solution}
\end{parts}





\newpage 
\section{Day 9: Fourier Analysis + Distribution Theory}

\question (January 2017) Let $f \in L^1(\RR^n)$ be a function all of whose distributional derivatives $D^\alpha f$ of order $|\alpha| = m$ also belong to $L^1(\RR^n)$. Show that if $m > n$, then $f \in C(\RR^n)$.
\begin{solution}
    The duality between differentiation and multiplication by polynomials in the Fourier transform, and the fact that the Fourier transform of an $L^1$ function is in $L^\infty$, implies that for each $\alpha$ with $|\alpha| = m$,
    %
    \[ |\xi^\alpha \widehat{f}| \in L^\infty(\RR^n). \]
    %
    We have $|\sum_{|\alpha| = m} |\xi^\alpha| \sim |\xi|^m$, so we conclude that $|\xi^m \widehat{f}| \in L^\infty$. Since $f \in L^1$, $\widehat{f} \in L^\infty$, so that we have a bound
    %
    \[ |\widehat{f}(\xi)| \lesssim \frac{1}{1 + |\xi|^m}. \]
    %
    Since $m > n$, this means $\widehat{f}$ is also integrable. The Fourier inversion formula thus implies that $f$ agrees almost everywhere with a bounded, continuous function.
\end{solution}

\question (September, 2019)
    Let $s \in \RR$, and let $H^s(\RR)$ be the Sobolev space on $\RR$ with the norm
    %
    \[ \| u \|_{(s)} = \left( \int_{\RR} (1 + |\xi|^2)^s |\widehat{u}(\xi)|^2\; d\xi \right)^{1/2} \]
    %
    where $\widehat{u}$ is the Fourier transform of $u$. Let $r < s < t$ be real numbers. Prove that for every $\varepsilon > 0$ there is $C > 0$ such that
    %
    \[ \| u \|_{(s)} \leq \varepsilon \| u \|_{(t)} + C \| u \|_{(r)} \]
    %
    for every $u \in H^t(\RR)$.
\begin{solution}
    Intuitively, we only need the $H^t$ norm to control $H^s$ for large frequencies, since the $H^r$ norm gives enough control over low frequencies. We can let the low frequencies we apply the $H^r$ norm to be arbitrarily large, which means we depend arbitrarily in an arbitrarily small way on the $H^t$ norm. Thus we fix $R > 0$, and write
    %
    \[ \int (1 + |\xi|^2)^s |\widehat{u}(\xi)|^2\; d\xi = \int_{|\xi| \leq R} (1 + |\xi|^2)^s |\widehat{u}(\xi)|^2 + \int_{|\xi| > R} (1 + |\xi|^2)^s |\widehat{u}(\xi)|^2. \]
    %
    Now
    %
    \[ \int_{|\xi| \leq R} (1 + |\xi|^2)^s |\widehat{u}(\xi)|^2\; d\xi \leq R^{s-r} \int_{|\xi| \leq R} (1 + |\xi|^2)^r |\widehat{u}(\xi)|^2\; d\xi \leq R^{s-r} \| u \|_{(r)}^2, \]
    %
    and
    %
    \[ \int_{|\xi| \geq R} (1 + |\xi|^2)^s |\widehat{u}(\xi)|^2\; d\xi \leq R^{s-t} \int_{|\xi| \geq R} (1 + |\xi|^2)^t |\widehat{u}(\xi)|^2\; d\xi \leq R^{s-t} \| u \|_{(t)}^2. \]
    %
    Thus we find that
    %
    \[ \| u \|_{(s)} \leq \sqrt{R^{s-r} \| u \|_{(r)}^2 + R^{s-t} \| u \|_{(t)}^2} \leq (2R^{s-r})^{1/2} \| u \|_{(r)} + (2R^{s-t})^{1/2} \| u \|_{(t)}.  \]
    %
    Given $\varepsilon > 0$, the proof is completed by picking $R \geq (2/\varepsilon^2)^{1/(t-s)}$.
\end{solution}


\begin{solution}
(Alternate solution using Young's inequality). Let $A = 1+|\xi|^{2}$. 


\textit{Claim 1:} Suppose $r<s<t$. Then for each $\epsilon>0$, there exists $C>0$ such that $A^{s} \leq \epsilon A^{t}+ C A^{r}$.

To prove this claim, we will use Young's inequality for products with $\epsilon$. Recall Young's inequality states that if $a,b\geq 0$ and $p,q>1$ with $\frac{1}{p}+\frac{1}{q}=1$ then
\begin{equation*}
  ab\leq \frac{a^{p}}{p}+\frac{b^{q}}{q}.
\end{equation*}
For any $\epsilon>0$ we may write $ab= ((p\epsilon)^{1/p}a)\cdot \frac{b}{(p\epsilon)^{1/p}}$, which gives
\begin{equation}\label{eq:youngs-ineq-with-epsilon}
  ab\leq \epsilon a^{p} + (p\epsilon)^{-q/p}\frac{b^{q}}{q}.
\end{equation}
Let $\beta=\frac{t(s-r)}{t-r}$, $p=t/\beta$ and $q=\frac{p}{p-1}= \frac{t}{t-\beta} =\frac{t-r}{t-s}$. Then $p,q>1$ and $\frac{1}{p}+\frac{1}{q}=1$. Applying inequality \eqref{eq:youngs-ineq-with-epsilon} with $a=A^{\beta}$ and $b=A^{s-\beta}$, we have:
\begin{align*}
  A^{s} &= A^{\beta}A^{s-\beta}\\ 
        &\leq \epsilon A^{\beta t/\beta} + \frac{1}{q(p\epsilon)^{q/p}} A^{(s-\beta) q}\\ 
        &=\epsilon A^{t} + \frac{1}{q(p\epsilon)^{q/p}} A^{(s-\beta) q}\\
        &=\epsilon A^{t} +  \frac{1}{q(p\epsilon)^{q/p}} A^{r}.
\end{align*}
This proves Claim 1.

Next we apply Claim 1 with $r/2<s/2<t/2$, which gives
\begin{equation*}
  A^{s/2}\leq \epsilon A^{t/2}+ C A^{r/2}.
\end{equation*}
Multiplying both sides by $|\hat{u}|$ and making the substitution $A=1+|\xi|^{2}$, we have
\begin{equation*}
  (1+|\xi|^{2})^{s/2}|\hat{u}(\xi)|\leq \epsilon (1+|\xi|^{2})^{t/2}|\hat{u}(\xi)|+ C (1+|\xi|^{2})^{r/2}|\hat{u}(\xi)|.
\end{equation*}
Therefore using Minkowski's inequality,
\begin{align*}
    \norm{(1+|\xi|^{2})^{s/2}|\hat{u}(\xi)|}_{L^{2}}
  &\leq \norm{\epsilon (1+|\xi|^{2})^{t/2}|\hat{u}(\xi)|+ C (1+|\xi|^{2})^{r/2}|\hat{u}(\xi)|}_{L^{2}}\\ 
  &\leq  \epsilon\norm{(1+|\xi|^{2})^{t/2}|\hat{u}(\xi)|}_{L^{2}}+ C\norm{ (1+|\xi|^{2})^{r/2}|\hat{u}(\xi)|}_{L^{2}}.
\end{align*}
This is exactly the inequality we needed to show, so we are done.

\end{solution}
\question (September, 2019) Let $f \in L^2(\RR)$. Define
%
\[ g(x) = \int_{-\infty}^\infty f(x-y) f(y)\; dy \]
%
Show that there exists a function $h \in L^1(\RR)$ such that
%
\[ g(\xi) = \int_{-\infty}^\infty e^{- i \xi x} h(x)\; dx, \]
%
i.e. $g$ is a Fourier transform of a function in $L^1(\RR)$. Hint: The following formal argument may be helpful:
%
\[ \widehat{g}(x) = \widehat{f * f}(x) = \widehat{f}(x)^2, \]
%
where $*$ denotes convolution, and $\widehat{\cdot}$ denotes the Fourier transform.
\begin{solution}
    If one only knows Fourier analysis in $L^1(\RR)$, the argument in the hint may be justified using the fact that $L^1(\RR) \cap L^2(\RR)$ is dense in $L^2(\RR)$, together with some continuity arguments.
    
    Young's convolution inequality implies that $g$ is a continuous function in $L^\infty(\RR)$. One cannot take the Lebesgue integral defining the Fourier transform for $g$, but one may take the distributional Fourier transform. If we consider a family of functions $\{ f_n \}$ lying in $L^2(\RR) \cap L^1(\RR)$, which converge to $f$ in $L^2(\RR)$ as $n \to \infty$, then Young's convolution inequality implies that $f_n * f_n$ converges to $f * f$ in $L^\infty(\RR)$. In particular, $f_n * f_n$ converges to $f * f$ distributionally. By continuity of the Fourier transform, $\widehat{f_n * f_n}$ converges to $\widehat{f * f}$, and $\widehat{f_n * f_n} = \widehat{f_n}^2$, which converges distributionally to $\widehat{f}^2$ (by Cauchy Schwartz it actually converges in $L^1(\RR)$, which is a stronger statement). Thus we conclude that $\widehat{g} = \widehat{f * f} = \widehat{f}^2$. But since the Fourier transform of $g$ lies in $L^1$, we know that $g$ acts as a distribution in exactly the same way as the distribution
    %
    \[ \xi \mapsto \int \widehat{f}(x)^2 e^{2 \pi i \xi \cdot x}. \]
    %
    Since $g$ is a continuous function, and the integral above defines a continuous function, it follows that for all $\xi$,
    %
    \[ g(\xi) = \int \widehat{f}(x)^2 e^{2 \pi i \xi \cdot x}. \]
\end{solution}


\question (September, 2015) Let $f$ be a tempered distribution on $\RR$ with Fourier transform
%
\[ \widehat{f}(\xi) = 1 + \xi^{12} + \sin \xi + \text{sign}(\xi). \]
%
Find $f$ and $f'$ (specify the definition of the Fourier transform you are using).
\begin{solution}
    I will be using the Fourier transform defined by
    %
    \[ \widehat{f}(\xi) = \int f(x) e^{-2 \pi i \xi \cdot x}\; d\xi. \]
    %
    The problem is really asking us to compute the inverse Fourier transform of $1$, $\xi^{12}$, $\sin \xi$, and $\text{sign}(\xi)$ individually.
    
    If $\delta$ is the Dirac delta function at the origin, then
    %
    \[ \widehat{\delta}(\xi) = \int e^{-2 \pi i \xi \cdot x} \delta(x)\; dx = 1. \]
    %
    Thus $\widehat{\delta} = 1$.
    
    To find a function whose Fourier transform is $\xi^{12}$, we recall the applying linear differential operators with constant coefficients on one side of the Fourier transform is the same as multiplying by a polynomial on the other side. If we compute the right constants, we find that the tempered distribution $\Lambda$ with $\widehat{\Lambda}(\xi) = \xi^{12}$ is a multiple of the tempered distribution mapping a test function $\phi$ to a constant multiplier $D^{12} \phi(0)$. If we compute the relationship carefully, we find that it is actually $\phi \mapsto (1/2\pi i)^{12} D^{12} \phi(0)$.
    
    Next, we find a function whose Fourier transform is $\sin \xi$. A simple way to compute this is to write
    %
    \[ \sin \xi = [e^{i \xi} - e^{-i \xi}]/2i. \]
    %
    Since $e^{i \xi}$ is the Fourier transform of the Dirac delta $\delta_{-1/2\pi}$ at $-1/2\pi$, and $e^{-i \xi}$ is the Fourier transform of the Dirac delta $\delta_{1/2\pi}$ at $1/2\pi$. Thus if we write $\Gamma(x) = \delta_{-1/2\pi}/2i - \delta_{1/2\pi}/2i$, then $\widehat{\Gamma}(\xi) = \sin \xi$.
    
    Finally, we find a function whose Fourier transform is $g(\xi) = \text{sign}(\xi)$. The distributional derivative of $g(\xi)$ is the Dirac delta at the origin. Since the Dirac delta at the origin is equal to a constant function $1$, this implies that if $h(x)$ is the distribution $(-1/2\pi i) \text{p.v}(1/x)$, where we interpret $\text{p.v}(1/x)$ as the distribution
    %
    \[ \phi \mapsto \lim_{\delta \to 0} \int_{|x| \geq \delta} \phi(x) / x\; dx. \]
    %
    Then $-2 \pi i x h(x) = 1$, and so the symmetry of polynomial multiplication and differentiation implies that the distributional derivative of $g(\xi) - \widehat{h}(\xi)$ is equal to zero. This implies that $g(\xi) - \widehat{h}(\xi) = C$ for some constant $C$. If $\phi(x) = e^{- \pi |x|^2}$ is a Gaussian, then $\widehat{\phi}(\xi) = \phi(\xi)$, then
    %
    \[ \int [g(\xi) - \widehat{h}(\xi)] \phi(\xi) = C, \]
    %
    and we calculate directly that, first using the symmetry of the Gaussian,
    %
    \[ \int g(\xi) \phi(\xi)\; d\xi = \int \text{sign}(\xi) \phi(\xi)\; d\xi = 0,  \]
    %
    and the multiplication formula for the Fourier transform, together with the symmetry of the Gaussian, shows that
    %
    \[ \int \widehat{h}(\xi) \phi(\xi) = \int h(x) \phi(x)\; dx = \lim_{\delta \to 0} \int_{|x| \geq \delta} \phi(x) / (-2\pi i x) = 0. \]
    %
    Thus $C = 0$, and so $\widehat{h}(\xi) = \widehat{g}(\xi)$.
    
    In conclusion, we have found that $f = \delta_0 + \Lambda + \Gamma + h$, where each of these terms are calculated explicitly above.
    
    We finish by giving the rough idea of how to calculate the distributional derivative of $f$. One approach is to multiply by a power of $\xi$ on the Fourier transform side, and then take a Fourier transform, but we choose to work directly from the definition of the distributional derivative.
    
    First, we calculate directly using the definition of the distributional derivative that for any test function $\phi$,
    %
    \[ \int \delta_0'(x) \phi(x)\; dx = - \int \delta_0(x) \phi'(x)\; dx = - \phi'(0). \]
    %
    Thus $\delta_0'$ maps a test function $\phi$ to $-\phi'(0)$. Similarily, the derivative of $\delta_{-1/2\pi}$ maps $\phi$ to $-\phi'(-1/2\pi)$, and the derivative of $\delta_{1/2\pi}$ maps $\phi$ to $-\phi'(1/2\pi)$. This allows us to calculate the distributional derivative of $\Gamma$ simply. For the distribution $u: \phi \mapsto D^{12} \phi(0)$ we calculate
    %
    \[ \int u'(x) \phi(x)\; dx = -\int u(x) \phi'(x)\; dx = - D^{12} \phi'(0) = - D^{13}(0). \]
    %
    This enables us to calculate the distributional derivative of $\Lambda$. Finally,
    %
    \[ \int \text{p.v}(1/x)' \cdot \phi(x)\; dx = -\int \text{p.v}(1/x) \phi'(x)\; dx = - \lim_{\delta \to 0} \int_{|x| \geq \delta} (1/x) \phi'(x); dx. \]
    %
    Integration by parts shows that
    %
    \[ \int_\delta^\infty (1/x) \phi'(x)\; dx = - \phi(\delta) / \delta + \int_\delta^\infty (1/x^2) \phi(x)\; dx \]
    %
    and
    %
    \[ \int_{-\infty}^{-\delta} (1/x) \phi'(x)\; dx = -\phi(-\delta)/\delta + \int_{-\infty}^\delta (1/x^2) \phi(x)\; dx. \]
    %
    Thus
    %
    \begin{align*}
        \lim_{\delta \to 0} - \int_{|x| \geq \delta} (1/x) \phi'(x)\; dx &= \lim_{\delta \to 0} \frac{\phi(\delta) + \phi(-\delta)}{\delta} - \int_{|x| \geq \delta} (1/x^2) \phi(x)\; dx\\
        &= \lim_{\delta \to 0} \frac{2 \phi(0)}{\delta} - \int_{|x| \geq \delta} (1/x^2) \phi(x)\; dx.
    \end{align*}
    %
    Thus if we define the distribution $\text{f.p}(1/x^2)$ (the finite part distribution) as mapping a test function $\phi$ to
    %
    \[ \lim_{\delta \to 0} \int_{|x| \geq \delta} (1/x^2) \phi(x) - 2 \phi(0) / \delta, \]
    %
    then the derivative of $\text{p.v}(1/x)$ is $- \text{f.p}(1/x^2)$. This allows us to calculate the distributional derivative of $h$.
\end{solution}

\question (September, 2015) Recall that $H^s(\RR^n)$ is the Sobolev space consisting of all tempered distributions $g$ on $\RR^n$ for which the Fourier transform $\widehat{g}$ of $g$ is locally integrable and satisfies
%
\[ \int_{\RR^n} (1 + |\xi|^2)^s |\widehat{g}(\xi)|^2\; d\xi < \infty. \]
%
Let $u$ be a Schwartz function on $\RR^n$ and for $a \in \CC$, let
%
\[ f_a(x) = |x|^a u(x). \]
%
Show that if $\text{Re}(a) > - n/2$ and $s \in [0,\text{Re}(a) + n/2)$, then $f_a \in H^s(\RR^n)$.
\begin{solution}
    We wish to compute the Fourier transform of $f_a$, in order to apply the $H^s$ norm. $f_a$ is the product of a Schwartz function with $|x|^a$, so a useful avenue is to study the distributional derivative of $\Lambda(x) = |x|^a$, since $\widehat{f_a} = \widehat{\Lambda} * \widehat{u}$. The important properties of $\Lambda$ we will use is that $\Lambda$ acts as a $C^\infty$ functions on $\RR^n - \{ 0 \}$, is a radial function, and is \emph{homogeneous} of degree $a$. It follows from general Fourier analysis that $\widehat{\Lambda}$ acts as a $C^\infty$ function on $\RR^n - \{ 0 \}$, is a radial function, and is homogeneous of degree $-a-n$. Thus we can write $\widehat{\Lambda}(\lambda \theta) = \lambda^{-a - d} g(\theta)$ where $g$ is a $C^\infty$ function defined for $|\theta| = 1$, and $\lambda > 0$. Since $\text{Re}(a) > -n/2$, $\text{Re}(-a-n) < -n/2$. This implies that $\widehat{\Lambda}$ decays away from the origin. In particular, $\widehat{\Lambda}$ is $L^2$ away from the origin.

    Now we write
    %
    \[ |x|^a u(x) = T_1 u(x) + T_2 u(x), \]
    %
    where
    %
    \[ \widehat{T_1 u}(\xi) = \int_{|\eta| \leq 1} |\eta|^{-a-n} g(\eta/|\eta|) \widehat{u}(\xi - \eta)\; d\eta, \]
    %
    and
    %
    \[ \widehat{T_2 u}(\xi) = \int_{|\eta| \geq 1} |\eta|^{-a-n} g(\eta/|\eta|) \widehat{u}(\xi - \eta)\; d\eta. \]
    %
    Since $u$ is Schwartz, $\widehat{u}$ is also Schwartz. In particular, for $|\eta| \geq 2|\xi|$, $|\widehat{u}(\xi - \eta)| \lesssim_N |\eta|^{-N}$ for all $N > 0$, which implies that
    %
    \[ \left| \int_{|\eta| \geq 2|\xi|} |\eta|^{-a-n} g(\eta/|\eta|) \widehat{u}(\xi - \eta)\; d\eta \right| \lesssim_M |\xi|^{-M}. \]
    %
    For $1 \leq |\eta| \leq |\xi|/2$, $|\widehat{u}(\xi - \eta)| \lesssim_N |\xi|^{-N}$, which implies that
    %
    \[ \left| \int_{1 \leq |\eta| \leq |\xi|/2} |\eta|^{-a-n} g(\eta/|\eta|) \widehat{u}(\xi - \eta)\; d\eta \right| \lesssim_N |\xi|^{-N}. \]
    %
    For $|\xi|/2 \leq |\eta| \leq 2|\xi|$, we can really only use the bound $|\widehat{u}(\xi - \eta)| \lesssim 1$, which implies that
    %
    \[ \left| \int_{|\xi|/2 \leq |\eta| \leq |\xi|} |\eta|^{-a-n} g(\eta/|\eta|) \widehat{u}(\xi - \eta)\; d\eta \right| \lesssim |\xi|^{-\text{Re}(a)}. \]
    %
    Putting these bounds together shows that
    %
    \[ |\widehat{T_2 u}(\xi)| \lesssim |\xi|^{-\text{Re}(a)}, \]
    %
    which is sufficent to show that $T_2 u \in H^s$ for $0 \leq s \leq \text{Re}(a) + n/2$.
    
    To show $T_1 u \in H^s$, we `cheat' a little, since this is the average of $u$ over `low frequencies' (and a good intuition to have is that low frequencies are very smooth). More precisely, $\widehat{T_1 u} = \widehat{\Psi} * \widehat{u}$, where $\widehat{\Psi}$ is a compactly supported distribution. The Paley-Wiener theorem implies that $\Psi$ is a $C^\infty$ function, and there exists some $N > 0$ such that $|\Psi(x)| \lesssim_N 1 + |x|^N$. And $T_1 u = \Psi \cdot u$, so $T_1 u$ is therefore actually a \emph{Schwartz function}, and thus certainly in $H^s(\RR^n)$.
\end{solution}




\newpage
\section{Day 10: Bonus Questions}

\question (September, 2017) Let $a_1, \dots, a_n > 0$. Let $f: \RR^n \to \RR$ be defined by
%
\[ f(x) = \frac{1}{1 + \sum |x_i|^{\alpha_i}}. \]
%
Determine for each $p > 0$ whether
%
\[ \int |f(x)|^p\; dx < \infty. \]
\begin{solution}
	Let $E_i = \{ x: x_i^{\alpha_i} \geq x_1^{\alpha_1}, \dots, x_n^{\alpha_n} \}$. On $E$, we have
	%
	\[ |f(x)|^p \sim \frac{1}{1 + |x_i|^{p \alpha_1}}. \]
	%
	Let us determine what values of $p > 0$ we have
	%
	\[ \int_{E_i} \frac{1}{1 + |x_i|^{p \alpha_1}} < \infty.  \]
	%
	Since $\RR^n = \bigcup E_i$, this will suffices to determine the range of $p$ required in the problem. Set $E_i(n) = E_i \cap \{ x : 2^{n-1} \leq x_1 \leq 2^n \}$. For $n > 0$, on $E_i(n)$ we have $|f(x)|^p \sim_p 1/2^{p \alpha_i n}$, and for $n < 0$ we have $|f(x)|^p \sim 1$. It is simple to calculate that $|E_i(n)| \sim 2^n 2^{n(\alpha_i/\alpha_2 + \dots + \alpha_i / \alpha_n)} = 2^{n \alpha_i (1/\alpha_1 + \dots + 1/\alpha_n)}$. For any value of $p$, we thus have
	%
	\[ \sum_{n \leq 0} \int_{E_i(n)} |f(x)|^p \sim \sum_{n < 0} 2^{n \alpha_i (1/\alpha_1 + \dots + 1/\alpha_n)} < \infty. \]
	%
	On the other hand, we have
	%
	\[ \sum_{n > 0} \int_{E_i(n)} |f(x)|^p \sim \sum_{n = 1}^\infty 2^{-p\alpha_i n} 2^{n \alpha_i(1/\alpha_1 + \dots + 1/\alpha_n)} = \sum_{n = 1}^\infty 2^{n \alpha_i(1/\alpha_1 + \dots + 1/\alpha_n -p)}. \]
	%
	This sum is finite if and only if $1/\alpha_1 + \dots + 1/\alpha_n < p$. Thus this is the range for which
	%
	\[ \int_{E_i} |f(x)|^p < \infty. \]
	%
	But this condition is invariant of $i$, so this is precisely the range for which
	%
	\[ \int |f(x)|^p < \infty. \]
\end{solution}

\begin{solution}

Let $\gamma=\frac{1}{\alpha_{1}}+\ldots+\frac{1}{\alpha_{n}}$. We claim the integral converges if and only if $p>\gamma$.

\vt
\textit{Case 1:} Suppose $p>\gamma$. Then
\begin{equation*}
  \int_{\R^{n}} |f(x)|^{p}dx = \int_{0}^{\infty}p t^{p-1}|E_{t}|dt
\end{equation*}
where $E_{t}= \left\{ x: f(x)>1 \right\}$. Since $E_{t}=\emptyset$ if $t\geq 1$, it follows that
\begin{equation}\label{eq:10000}
  \int_{\R^{n}} |f(x)|^{p}dx = \int_{0}^{1}p t^{p-1}|E_{t}|dt.
\end{equation}
Observe that
\begin{align*}
  E_{t}
  &= \left\{ x\in \R^{n} : \sum_{i=1}^{n}|x_{i}|^{\alpha_{i}}< \frac{1-t}{t} \right\} \\
  &\subseteq \bigcap_{i=1}^{n}\left\{ x\in \R^{n}: |x_{i}| < \left(\frac{1-t}{t}\right)^{\frac{1}{\alpha_{i}}} \right\}\\
  &= \left\{ x\in \R^{n}:  -\left(\frac{1-t}{t}\right)^{\frac{1}{\alpha_{i}}} < x_{i}< \left(\frac{1-t}{t}\right)^{\frac{1}{\alpha_{i}}} \text{ for all }i\right\}
\end{align*}

Since the set on the right hand side is a rectangle with Lebesgue measure $2^{n}\left(\frac{1-t}{t}\right)^{\gamma}$, it follows that
\begin{equation*}
  |E_{t}| \leq 2^{n}\left(\frac{1-t}{t}\right)^{\gamma}.
\end{equation*}
Combining this with equation \eqref{eq:10000} gives
\begin{equation*}
  \int_{\R^{n}} |f(x)|^{p}dx \leq 2^{n}p \int_{0}^{1}t^{p-1}(1-t)^{\gamma}t^{-\gamma}dt \leq 2^{n}p \int_{0}^{1}t^{p-1-\gamma}dt
\end{equation*}
which is integrable since $p>\gamma$.


\vt
\textit{Case 2:} Suppose $p\leq\gamma$. We will prove that $\int_{\R^{n}} |f|^{p}dx = +\infty$ by induction on $n$. If $n=1$,
\begin{equation*}
  \int_{\R} \(\frac{1}{1+ |x|^{\alpha_{1}}}\)^{p}dx \geq  \frac{1}{2}\int_{|x|>1} |x|^{-\alpha_{1}p}dx \geq \frac{1}{2}\int_{|x|>1}\frac{1}{|x|}dx= +\infty.
\end{equation*}

Next assume $n>1$. For convenience of notation we will write $R=1+ \sum_{i=2}|x_{i}|^{\alpha_{i}}$. We have
\begin{align*}
  \int_{\R^{n}}|f(x)|^{p}dx
  &= \int_{\R^{n-1}} \left[ \int_{\R} \left( \frac{1}{|x_{1}|^{\alpha_{1}}+ 1+ \sum_{i=2}|x_{i}|^{\alpha_{i}}} \right)^{p}dx_{1} \right]dx_{2}\cdots dx_{n}\\
  &=\int_{\R^{n-1}} \left[ \int_{\R} \left( \frac{1}{|x_{1}|^{\alpha_{1}}+ R} \right)^{p}dx_{1} \right]dx_{2}\cdots dx_{n}\\
  &\geq \int_{\R^{n-1}} \left[ \int_{|x_{1}|>R^{1/\alpha_{1}}} \left( \frac{1}{|x_{1}|^{\alpha_{1}}+ R} \right)^{p}dx_{1} \right]dx_{2}\cdots dx_{n}\\
  &\geq \frac{1}{2^{p}}\int_{\R^{n-1}} \left[ \int_{|x_{1}|>R^{1/\alpha_{1}}} \left( \frac{1}{|x_{1}|^{\alpha_{1}}} \right)^{p}dx_{1} \right]dx_{2}\cdots dx_{n}\\
  &= \frac{1}{2^{p-1}}\int_{\R^{n-1}} \int_{R^{1/\alpha_{1}}}^{\infty}x_{1}^{-p\alpha_{1}}dx_{1}\cdots dx_{n}.
\end{align*}
If $p\alpha_{1}\leq 1$ then $\int_{\R^{n-1}} \int_{R}^{\infty}x_{1}^{-p\alpha_{1}}dx_{1}= +\infty$ and we are done. On the other hand, if $p\alpha_{1}<1$, then by the above, we have
\begin{align*}
  \int_{\R^{n}}|f(x)|^{p}dx
  &= \frac{1}{2^{p-1}(1-p\alpha_{1})}\int_{\R^{n-1}} R^{\frac{1}{\alpha_{1}}-p}dx_{2}\cdots dx_{n}\\
  &= \frac{1}{2^{p-1}(1-p\alpha_{1})}\underbrace{\int_{\R^{n-1}} \left( \frac{1}{1+ \sum_{i=2}|x_{i}|^{\alpha_{i}}}
    \right)^{p-\frac{1}{\alpha_{1}}} dx_{2}\cdots dx_{n}}_{\text{Call this }A}
\end{align*}
However, since $p\geq \gamma$, it follows that $p-\frac{1}{\alpha_{1}}\geq \frac{1}{\alpha_{2}}+ \ldots + \frac{1}{\alpha_{n}}.$ Therefore by the induction hypothesis, the integral $A=+\infty$. Therefore $\int_{\R^{n}}|f(x)|^{p}dx = +\infty$.
\end{solution}


\question Let $f \in L^1(\RR)$. Let
%
\[ G(\lambda) = \int_{-\infty}^\infty e^{i \lambda t^2} f(t)\; dt. \]
%
Prove that $G$ is a continuous function and that $\lim_{\lambda \to \infty} G(\lambda) = 0$.
\begin{solution}
    It is simple to see that the operator $Tf = G$ is continuous from $L^1(\RR)$ to $L^\infty(\RR)$, with $\| Tf \|_\infty \leq \| f \|_1$. We claim that it thus suffices to show the result for $\phi \in C_c^\infty(\RR)$ supported away from the origin. Indeed, if $f \in L^1(\RR)$, we can find $\phi_n \in C_c^\infty(\RR)$ supported away from the origin, converging in $L^1(\RR)$ to $f$. Then $T\phi_n$ converges to $Tf$ uniformly, and $T\phi_n$ is continuous for each $n$, so $Tf$ is continuous. Moreover, if $\varepsilon > 0$, there is $n$ large enough that $\| f - \phi_n \|_1 \leq \varepsilon$. This means that $\| Tf - T\phi_n \|_\infty \leq \varepsilon$, and so
    %
    \[ \limsup_{\lambda \to \infty} |Tf(\lambda)| \leq \limsup_{\lambda \to \infty} |Tf(\lambda) - T\phi_n(\lambda)| + \limsup_{\lambda \to \infty} |T\phi_n(\lambda)| \leq \varepsilon + 0 \leq \varepsilon. \]
    %
    Taking $\varepsilon \to 0$ completes the argument. So now we show the result for $\phi \in C_c^\infty(\RR)$. Continuity here is easy because $\phi$ is compactly supported (in this case, $G$ is actually a smooth function). And to show that $T\phi(\lambda)$ converges to zero as $\lambda \to \infty$, we integrate by parts, writing
    %
    \[ T\phi(\lambda) = \int_{-\infty}^\infty e^{i \lambda t^2} \phi(t)\; dt = \int_{-\infty}^\infty \frac{\phi(t)}{2i \lambda t} \frac{d}{dt} \left( e^{i \lambda t^2} \right) = - \frac{1}{2i \lambda} \int_{-\infty}^\infty \frac{d}{dt} \left( \frac{\phi(t)}{t} \right) e^{i \lambda t^2}. \]
    %
    Since $\phi$ lies in $C^\infty_c$ and is supported away from the origin, so too is $\phi(t)/t$, and thus we find
    %
    \[ |T\phi(\lambda)| \leq \frac{1}{2\lambda} \int_{-\infty}^\infty \left| \frac{d}{dt} \left( \frac{\phi(t)}{t} \right) \right|\; dt \lesssim 1/\lambda. \]
    %
    Thus $T\phi(\lambda) \to 0$ as $\lambda \to \infty$.
\end{solution}

\question Let $(X,\mu)$ be a $\sigma$-finite measure space. Let $\{ f_n \}$ be a sequence of measurable functions and assume that $f_n \to f$ almost everywhere. Prove that there exists measurable $A_1,A_2,\dots \subset X$ such that $\mu(X - \bigcup_i A_i) = 0$, and such that $f_n|_{A_i} \to f|_{A_i}$ uniformly for each $i$.
\begin{solution}
    We may assume without loss of generality that $X$ is actually a \emph{finite} measure space, since if $\bigcup X_n = X$, with $X_n$ a finite measure space, then we can find $A_{n1}, A_{n2}, \dots$ such that $\mu(X_n - \bigcup_i A_{ni}) = 0$, such that $f_k$ converges uniformly on each $A_{ni}$, and then $\mu(X - \bigcup_{n,i} A_{ni}) = 0$. Normalizing, we assume $|X| = 1$.
    
    Now let
     %
    \[ E_n(k) = \{ x \in X : \sup_{m \geq n} |f_m(x) - f(x)| \leq 1/2^k \}. \]
    %
    Since $f_n \to f$ almost everywhere, as $n \to \infty$ and for a fixed $k > 0$, $\{ E_n(k) \}$ is an increasing sequence, and $X - \bigcup_n E_n(k)$ is a set of measure zero. Thus for each $r > 0$, we can pick $n_1$ such that $|X - E_{n_1}(1)| \leq 1/2^r$. Similarily, we can for each $k$ pick $n_k$ such that $|E_{n_{k-1}}(k-1) - E_{n_k}(k)| \leq 1 / 2^{k+r}$. If we define $A_r = \bigcap_k E_{n_k}(k)$, then $|X - A_r| \leq 1/2^{r-1}$, and by definition, $f_k$ converges uniformly on $A_r$ for each $r$ since for $n \geq n_k$, $|f_n(x) - f(x)| \leq 1/2^k$. Thus we have found the required sequence $\{ A_r \}$.
\end{solution}

\question (January, 2017) Given for each function $f \in C^0(\RR^2)$ we define for each $y \in \RR$ a function $f_y \in C[0,1]$ by $f_y(x) = f(x,y)$. Assume that for each fixed $y$, the distributional derivative of $f_y \in \mathcal{D}'(\RR)$ defines a function $a_y \in L^p(\RR)$. Assume further that
%
\[ \| a_y \|_p \leq C < \infty \]
%
for some constant $C$ independent of $y$. Show that the distributional derivative $\partial_x f \in \mathcal{D}'(\RR^2)$ is in $L^p_{\text{loc}}(\RR^2)$, provided $1 < p \leq \infty$.
\begin{solution}
    We apply duality, which says that $\partial_x f$ is in $L^p_{\text{loc}}$ if and only if for each $R > 0$, and $\phi \in C_c^\infty(\RR^d)$ supported on $|z| \leq R$,
    %
    \[ \left| \int_{\RR^2} (\partial_x f)(z) \phi(z)\; dz \right| \lesssim_R \| \phi \|_{p^*}, \]
    %
    where $p^*$ is the conjugate to $p$. Now
    %
    \[  \int_{\RR^2} (\partial_x f)(z) \phi(z) = - \int f(z) (\partial_x \phi)(z)\; dz. \]
    %
    Since $f$ is continuous, and $\partial_x \phi$ is compactly supported on $|z| \leq R$, we can apply Fubini's theorem, writing
    %
    \[ \int f(z) (\partial_x \phi)(z)\; dz = \int_{-\infty}^\infty \int_{-\infty}^\infty f(x,y) (\partial_x \phi)(x,y)\; dx\; dy. \]
    %
    But applying integration by parts in just the $x$-variable, we have
    %
    \[ \int_{-\infty}^\infty f(x,y) (\partial_x \phi)(x,y)\; dx = - \int a_y(x) \phi(x,y)\; dx. \]
    %
    Thus we conclude that
    %
    \[ \int (\partial_x f)(z) \phi(z)\; dz = \int_{-\infty}^\infty \int_{-\infty}^\infty a_y(x) \phi(x,y)\; dx\; dy. \]
    %
    But by H\"{o}lder's inequality, if $p^*$ is the dual to $p$,
    %
    \begin{align*}
        \left| \int_{-\infty}^\infty \int_{-\infty}^\infty a_y(x) \phi(x,y)\; dx\; dy \right| &= \left| \int_{-R}^R \int_{-\infty}^\infty a_y(x) \phi(x,y)\; dx\; dy \right|\\
        &\leq \left( \int_{-R}^R \int_{-\infty}^\infty |a_y(x)|^p\; dx\; dy \right)^{1/p} \| \phi \|_{p^*}\\
        &= \left( \int_{-R}^R \| a_y \|_p^p\; dy \right)^{1/p} \| \phi \|_{p^*}\\
        &\leq C \cdot (2R)^{1/p} \| \phi \|_{p^*}\\
        &\lesssim_R \| \phi \|_{p^*}.
    \end{align*}
    %
    Thus we conclude that $\partial_x f \in L^p_{\text{loc}}$.
\end{solution}

\question (Jan 2020 \#4)
  Let $E\subset[0,1]$ be a measurable set with positive Lebesgue measure. Moreover, it satisfies the following property: As long as $x$ and $x$ belong to $E$, we know $\frac{x+y}{2}$ belongs to $E$. Prove that $E$ is an interval.
  
  
\begin{solution}
  Let $m=\inf E$ and $M = \sup E$. Since $|E|>0$, $E$ contains more than one element and hence $m<M$. We first prove two claims:

  \vt
  \noindent
  \textit{Claim 1:} $E$ is dense in $(m,M)$.
  \begin{proof}[Proof of Claim 1:]
    Let $z\in (m,M)$.
    By definition of infimum and supremum, there exists $u,v\in E$ such that $m \leq u<z<v\leq M$. Let $\delta>0$. It will suffice to show there exists an element $w\in E$ such that $|w-z|<\delta$. Define a sequence of intervals inductively by $I_{0}= [u,v]$ and if $I_{n-1}=[x,y]$, then
    \begin{equation*}
      I_{n} = \left\{
        \begin{array}{l@{\quad}l}
          \left[ \frac{x+y}{2}, y \right]  & \text{if } w\geq \frac{x+y}{2}\\
          \left[ x, \frac{x+y}{2} \right]  & \text{if } w< \frac{x+y}{2}
        \end{array}\right.
    \end{equation*}
     By construction, $w\in I_{n}$, and using the midpoint convexity of $E$, the endpoints of $I_{n}$ are elements of $E$. Choosing $N$ sufficiently large that $|I_{N}|=2^{-N}(v-u)<\delta$, it follows that $|w-\max I_{N}| < |\max I_{N}-\min I_{N}|= 2^{-N}(v-u)<\delta$. This proves the claim.
   \end{proof}

   \vt
   \noindent
   \textit{Claim 2:} $E$ contains a nonempty interval.
   \begin{proof}[Proof of Claim 2:]
     Denote by $E/2$ the set $\left\{ x/2 : x\in E   \right\}$. First observe that $|E/2|>0$. (Indeed, if $|E/2|=0$, then by absolute continuity of the function $x\mapsto 2x$, $|E|=0$, a contradiction.) We will show that $\frac{E}{2}+\frac{E}{2}$ contains a nonempty interval. The proof of the claim will then follow since $ E\supset \frac{E+E}{2}=\frac{E}{2}+\frac{E}{2}.$
     
     Let $h(x)= \int_{\R} \chi_A(x) \chi_A(x-y)dy$ where $A=E/2$. If $x\notin A+A$, then $h(x) = 0$. Therefore by contrapositive, if $\phi(x)>0$ then $x\in A+A$. Moreover, $h$ is continuous, so the set $\{x: h(x)>0\}$ is open and therefore contains an interval provided it is nonempty. Therefore it remains to show that $\{x: h(x)>0\}$ is nonempty. Indeed, by the Fubini-Tonelli theorem, $\int_{\R} h(x) dx = \int_A \int_{\R} \chi_A(x-y)dxdy = \int_A \int_{\R} \chi_A(x)dxdy = |A|^2>0$. Since $h$ is nonnegative function whose integral is positive, it follows that $h(x)>0$ for some $x$, as desired.
   \end{proof}

   We now proceed with the proof. By Claim 2, there exists a nonempty interval $(a,b)\subset E$. Let $b_{0} = \sup \left\{ r>0: (a,r)\subset E \right\}$ and $a_{0} = \inf \left\{ s>0 : (s,b) \subset E \right\}$. It will suffice to show that $a_{0}=m$ and  $b_{0}=M$, since this will imply that $(m,M)\subset E$, which is enough to conclude that $E$ is an interval. We shall show that $b_{0} = M$ as the proof that $a_{0}=m$ is similar.

   Suppose $b_{0}<M$. By Claim 1, there exists $b_{1}\in E$ such that $b_{0}<b_{1}< 2b_{0}-a$. Since $(a,b_{0})\subset E$ and $b_{1}\in E$, it follows that
   \begin{equation*}
     E\supset \left\{ \frac{b_{1}+s}{2}: a<s<b_{0} \right\} = \left\{ t: \frac{a+b_{1}}{2}<t<\frac{b_{0}+b_{1}}{2} \right\}= \left( \frac{a+b_{1}}{2},\frac{b_{0}+b_{1}}{2} \right).
   \end{equation*}
   Since $b_{1}<2b_{0}-a$, we have $\frac{a+b_{1}}{2}<b_{0}$. Therefore $\left( a, \frac{b_{0}+b_{1}}{2} \right)= (a,b_{0})\cup \left( \frac{a+b_{1}}{2},\frac{b_{0}+b_{1}}{2} \right)\subset E$. Moreover, since $b_{0}< b_{1}$, we have $\frac{b_{0}+b_{1}}{2}>b_{0}$. Therefore $b_{0}$ is not an upper bound for the set $\left\{ r>0: (a,r)\subset E \right\}$. But this is a contradiction since we defined $b_{0}$ to be the supremum of that set. Therefore $b_{0}=M$.
 \end{solution}

\question
\begin{parts}
    \part Does $p_N = \prod_{n = 2}^N (1 + (-1)^n/n)$ tend to a nonzero limit as $N \to \infty$.
    \begin{solution}
        We have
        %
        \[ \sum_{n = 2}^N \log(1 + (-1)^n/n) = \sum_{n = 2}^N (-1)^n/n + O(1/n^2). \]
        %
        The error terms converge absolutely, since $1/n^2$ is summable, and Leibniz's test implies since $(-1)^n/n$ is an alternating sequence decreasing in absolute value, that
        %
        \[ \sum_{n = 2}^N (-1)^n/n \]
        %
        converges as $N \to \infty$, and that the limiting value exceeds
        %
        \[ 1/2 - 1/3 > 0. \]
        %
        Thus taking exponentials shows that $p_N$ converges as $N \to \infty$.
    \end{solution}
    
    \part Does $q_N = \prod_{n = 2}^N (1 + (-1)^n/\sqrt{n})$ tend to a nonzero limit as $N \to \infty$.
    \begin{solution}
        We apply Taylor series, writing
        %
        \[ \log(1 + (-1)^n/\sqrt{n}) = (-1)^n/\sqrt{n} - 1/2n + O(1/n^{3/2}). \]
        %
        The error term is absolutely summable, and the sum of $(-1)^n/\sqrt{n}$ converges by Leibniz test as above. Thus the convergence of the sum
        %
        \[ \sum_{n = 2}^N \log(1 + (-1)^n/\sqrt{n}) \]
        %
        is equivalent to the convergence of the sum
        %
        \[ \sum_{n = 2}^N -1/2n. \]
        %
        But this sum converges to $-\infty$, so we find that, taking exponentials, $q_N \to 0$ as $N \to \infty$.
    \end{solution}
\end{parts}

\newpage
\section{Day 11: Bonus Questions}


\question (September, 2015) Let $\chi \in C^\infty(\RR)$ have a compact support and define
%
\[ f_n(x) = n^2 \chi'(nx). \]
%
\begin{parts}
    \part Does $f_n$ converge in the sense of distributions as $n \to \infty$? If so, what is the limit?
    \begin{solution}
        Applying an integration by parts, we calculate that
        %
        \[ \int f_n(x) \phi(x)\; dx = \int n^2 \chi'(nx) \phi(x)|; dx = - \int n \chi(nx) \phi'(x)\; dx. \]
        %
        As $n \to \infty$, each function $x \mapsto n \chi(nx)$ has total mass one, but is concentrated in small and smaller neighborhoods of the origin. In particular, these functions operate as an approximation to the identity, so that
        %
        \[ - \int n \chi(nx) \phi'(x)\; dx = - \phi'(0). \]
        %
        Thus as $n \to \infty$, $f_n$ converges distributionally to the distribution $\phi \mapsto - \phi'(0)$.
    \end{solution}
    
    \part Let $p \in [1,\infty)$ and $g \in L^p(\RR)$ be such that the distributional derivative of $g$ also lies in $L^p(\RR)$. Does $f_n * g$ converge in $L^p(\RR)$ as $n \to \infty$? If so, what is the limit?
    \begin{solution}
        As mentioned before, integration by parts shows that
        %
        \[ (f_n * g)(x) = \int_{-\infty}^\infty f_n(y) g(x-y)\; dy = \int n \chi(ny) g'(x-y)\; dy = (n \chi(ny) * g')(x). \]
        %
        The function $n \chi(ny)$ is an approximation to the identity, and so as $n \to \infty$, $(f_n * g)$ converges in $L^p$ to $g'$.
    \end{solution}
\end{parts}

\question Let
%
\[ s_N(x) = \sum_{n = 1}^N (-1)^n \frac{x^{3n}}{n^{2/3}}. \]
%
Prove that $s_N(x)$ converges to a limit $s(x)$ on $[0,1]$, and that there is a constant $C > 0$ so that for all $N \geq 1$ the inequality
%
\[ \sup_{x \in [0,1]} |s_N(x) - s(x)|\leq C N^{-2/3} \]
%
holds.
\begin{solution}
    The convergence here becomes highly singular near $x = 1$, because the power series diverges for $|x| > 1$. Thus we cannot use normal power series techniques here. It seems we must exploit the oscillation of the series here to get explicit bounds since removing the $(-1)^n$ in the definition of the series causes the sum to diverge at $x = 1$. If we define
    %
    \[ S_N(x) = \sum_{n = 1}^N (-x^3)^n \]
    %
    for $N > 0$, and $S_0 = 0$, then the geometric series formula shows that there is $C > 0$ such that $|S_N(x)| \leq C$ for all $N$ and $x \in [0,1]$, and a summation by parts shows that
    %
    \[ \sum_{n = 1}^N (-1)^n \frac{x^{3n}}{n^{2/3}} = \sum_{n = 1}^N (S_n - S_{n-1}) \frac{1}{n^{2/3}} = \sum_{n = 1}^{N-1} S_n \left( \frac{1}{n^{2/3}} - \frac{1}{(n+3)^{2/3}} \right) + S_N / n^{2/3}. \]
    %
    Now a mean value theorem / Taylor series expansion implies that
    %
    \[ \left| \frac{1}{n^{2/3}} - \frac{1}{(n+3)^{2/3}} \right| \lesssim \frac{1}{n^{5/3}}, \]
    %
    which is summable, and so for $M \geq N$,
    %
    \[ |s_M(x) - s_N(x)| \lesssim \sum_{n = N}^{M-1} S_n / n^{5/3} + S_M / M^{2/3} \lesssim C/N^{2/3}. \]
    %
    This is sufficient to show the existence of the point wise limit (since it shows $s_N$ is a Cauchy sequence), and also shows the required inequality.
\end{solution}


\question (Aug 2018 \#5)
  Prove that in an infinite dimensional Banach space,
  \begin{enumerate}[(a)]
  \item every norm bounded set is weakly bounded,
  \item every norm closed set is weakly closed
  \item a norm bounded set has empty interior in the weak topology
  \end{enumerate}
  
\begin{solution}
    We first prove part (a). Let $X$ be a Banach space and supppose $E\subset X$ is norm bounded; i.e., that $\sup_{x\in E}\norm{x}=C<\infty$. Recall that to show $E$ is weakly bounded, we need to show that $\sup_{x\in E}|\phi(x)|<\infty$ for all $\phi\in X^{*}$. This follows immediately by definition of norm:
    \begin{equation*}
      \sup_{x\in E}|\phi(x)| \leq\sup_{x\in E} \norm{\phi}\norm{x} \leq C \norm{\phi}<\infty.
    \end{equation*}

    Next we prove (c). Let $X$ be an infinite-dimensional Banach space, and let $A\subset X$ be a norm-bounded set. Then there exists $\rho>0$ such that $A\subset B:=\left\{ x\in X: \norm{x}<\rho \right\}$. It suffices to show that $B$ has empty interior in the weak topology.
    
      By definition, the weak topology has a base consisting of sets of the form
    \begin{equation}\label{eq:1}
      N(x_{0},F,r)=\left\{ x\in X : |\phi(x-x_{0})|<r \mathrm{\ for\ all\ }\phi\in F\right\}
    \end{equation}
    where $x_{0}\in X$, $r>0$, and $F$ is a finite subset of $X^{*}$. Letting $K:= \bigcap_{\phi \in F} \ker(\phi)$, observe that
    \begin{equation*}
      x_{0}+ K \subset N(x_{0},F,r).
    \end{equation*}
    Since $\ker(\phi)$ is of co-dimension 1 in $X$ for every $\phi\in X^{*}$ and since $F$ is a finite set, it follows that $K$ is of finite codimension in $X$. Therefore since $X$ is infinite-dimensional, it follows that $\dim K >0$, and therefore $K$ contains a nonzero element $y$. Since $K$ is a subspace, it follows that $\alpha y\in K$ for any $\alpha\in \R$. This implies that $K$---and therefore $N(x_{0},F,r)$---contains elements of arbitrarily large norm. Therefore $N(x_{0},F,r)\not\subset B$. Therefore $B$ has empty interior in the weak topology. This proves statement (c).

    Incidentally, we have also shown that statement (b) is false: while $B^c$ is clearly norm closed, it is not weakly closed because $B$ is not weakly open.

    Finally we claim that the converse of statement (b)---i.e., that every weakly closed set is norm closed---is true. To see this, let $F$ be weakly closed. Then $F^c$ is weakly open, and hence can be written as a union of sets of the form given in equation \eqref{eq:1}. Moreover, since $x\mapsto |\phi(x-x_{0})|$ is continuous with respect to the norm topology, it follows that $N(x_{0},F,r)$ is open in the norm topology. Therefore $F^c$ is a union of norm open sets. Therefore $F^c$ is norm open, and hence $F$ is norm closed.

    Another way to prove the converse of statement (b) is the following. Suppose $F\subset X$ is weakly closed, and suppose that $x_{n}\in F$ converges in norm to $x\in X$. To show that $F$ is strongly closed, we need to show that $x\in F$. Using the linearity of $\phi$ and the definition of operator norm,
    \begin{equation*}
      |\phi(x_{n})-\phi(x)| = |\phi(x_{n}-x)|\leq \norm{\phi} \norm{x_{n}-x}
    \end{equation*}
    for every $\phi\in X^{*}$. Since the right-hand side converges to zero as $n\to\infty$, it follows that $\phi(x_{n})\to \phi(x)$ as well, i.e. that $x_{n}$ converges weakly to $x$. Therefore since $F$ is weakly closed, $x\in F$, as required.
\end{solution}


\item (January 2016 \#1) Let $1<p<\infty$, and let $\chi_{[1-\frac{1}{n},1]}$ denote the characteristic function of $[1-\frac{1}{n},1]$. For which $\alpha\in \R$ does the sequences $n^{\alpha}\chi_{[1-\frac{1}{n},1]}$ converge weakly to $0$ in $L^{p}(\R)$?

\begin{solution}
  Case 1: Suppose $\alpha> 1/p$. Then $\norm{f_{n}}_{p}^{p} = \int_{1-\frac{1}{n}}^{1}n^{\alpha p}dx = n^{\alpha p - 1}\to \infty$ as $n\to\infty$. Since weakly convergent sequences are bounded in norm, it follows that $f_{n}$ does not weakly converge if $\alpha>1/p$.

  Case 2: Suppose $\alpha<1/p$. Let $g\in L^{q}(\R)$ where $\frac{1}{p}+\frac{1}{q}=1$. Using Holder's inequality,
  \begin{align*}
    \int f_{n}g &= \int_{1-\frac{1}{n}}^{1}n^{\alpha} g \leq \left( \int_{\R}n^{\alpha p}\chi_{[1-\frac{1}{n},1]} \right)^{\frac{1}{p}} \norm{g}_{q} = n^{\alpha-\frac{1}{p}}\norm{g}_{q}\to 0 \text{ as }n\to\infty.
  \end{align*}
  Since $g\in L^{q}$ was arbitrary, it follows that $f_{n}$ converges weakly to $0$ in $L^{p}$.

  Case 3: Suppose $\alpha=1/p$. Let $g\in L^{q}(\R)$ where $\frac{1}{p}+\frac{1}{q}=1$. By density of $C_{c}^{\infty}(\R)$ in $L^{q}(\R)$, there exists $\phi\in C_{c}^{\infty}(\R)$ with $\norm{\phi-g}_{q}<\epsilon$. Then
  \begin{align*}
    \left|\int_{\R }f_{n}g\right|
    &= \int_{\R} |f_{n}(g-\phi)| + \int_{\R} |f_{n}\phi|\\
    &\leq \norm{f_{n}}_{p}\underbrace{\norm{g-\phi}_{q}}_{<\epsilon} + \int_{1-\frac{1}{n}}^{1}n^{\frac{1}{p}}|\phi(x)|dx
    &&\text{ by Holder's inequality}\\
    &\leq \epsilon + \int_{1-\frac{1}{n}}^{1}n^{\frac{1}{p}}|\phi(x)|dx
    &&\text{ since }\norm{f_{n}}_{p}= 1\text{ for all }n\\
    &\leq \epsilon + \norm{\phi}_{\infty}\int_{1-\frac{1}{n}}^{1}n^{\frac{1}{p}}dx
    &&\text{ since }\phi\in C_{c}^{\infty}(\R)\\
    &= \epsilon + \norm{\phi}_{\infty}n^{\frac{1}{p}-1}.
  \end{align*}
  Since $\frac{1}{p}<1$, it follows that $\limsup_{n\to\infty}\left| \int_{\R}f_{n}g\right| \leq \epsilon$. Since $\epsilon>0$ and $g\in L^{q}(\R)$ were arbitrary, it follows that $\lim_{n\to\infty} \int f_{n}g = 0$ for all $g\in L^{q}$. So $f_{n}$ converges weakly to $0$ in $L^{p}$.
\end{solution}


\item (Jan 2018 \#5) Let $x_{n}$ be a sequence in a Hilbert space $H$. Suppose that $x_{n}$ converges to $x$ weakly. Prove that there is a subsequence $x_{n_{k}}$ such that
\begin{equation*}
  \frac{1}{N}\sum_{k=1}^{N}x_{n_{k}}
\end{equation*}
converges to $x$ (in norm) as $N\to\infty$. 

\begin{solution}
  (Note: this result is called the Banach-Saks theorem). Without loss of generality, assume that $x=0$. Since $x_{n}$ converges weakly, it follows that $x_{n}$ is bounded in norm (this is a consequence of the uniform boundedness principle). Let $C = \max_{n\geq 1}\norm{x_{n}}$. We construct a subsequence in the following manner. Let $x_{n_{1}}=x_{1}$. Having chosen $x_{n_{N}}$, choose $x_{n_{N+1}}$ so that
  \begin{equation*}
    \Big\langle \sum_{i=1}^{N}x_{n_{k}},x_{n_{N+1}}\Big\rangle \leq 2^{-(N+1)}.
  \end{equation*}
  Such an $x_{n_{N=1}}$ exists since $\langle y,x_{n}\rangle \to 0$ as $n\to \infty$ for all $y\in H$. We need to show that
  \begin{equation*}
    \norm{N^{-1}\sum_{k=1}^{N}x_{n_{k}}}\to 0 \text{ as }n\to\infty.
  \end{equation*}
  To see this, we have:
  \begin{align*}
    N^{-2}\Big\langle \sum_{k=1}^{N}x_{n_{k}}, \sum_{j=1}^{N}x_{n_{j}} \Big\rangle
    &= N^{-2}\sum_{j,k=1}^{N}\Big\langle x_{n_{k}}, x_{n_{j}}\Big\rangle\\
    &= N^{-2}\left( \sum_{j=1}^{N}\norm{x_{n_{j}}}^{2}+ \sum_{k=2}^{N}\sum_{j=1}^{k-1}\langle x_{n_{j}},x_{n_{k}}\rangle \right)\\
    &=N^{-2} \left(  \sum_{j=1}^{N}\norm{x_{n_{j}}}^{2}+ \sum_{k=2}^{N}\underbrace{\Big\langle \sum_{j=1}^{k-1} x_{n_{j}},x_{n_{k}}\Big\rangle}_{\leq 2^{-k}} \right)\\
    &\leq N^{-2} \left( C N + 1  \right) \to 0 \text{ as } N\to\infty.
  \end{align*}
\end{solution}

  
  
\question (September 2015) Let $E \subset \RR$ be a measurable set, such that $E + r = E$ for all $r \in \mathbf{Q}$. Show that $|E| = 0$ or $|E^c| = 0$.
\begin{solution}
    We apply the Lebesgue density theorem. Suppose $|E| \neq 0$. Fix $\delta > 0$. Then there exists $\varepsilon_0 > 0$ such that for $\varepsilon < \varepsilon_0$, we can find $a,b \in \mathbf{Q}$ with $b - a < \varepsilon$ with
    %
    \[ |E \cap (a,b)| \geq (1 - \delta) (b - a) \]
    %
    Set $\varepsilon_1 = b - a$. Because $E$ is invariant under translations in $\mathbf{Q}$,
    %
    \[ |E \cap (0,\varepsilon_1)| \geq (1 - \delta) \varepsilon_1. \]
    %
    Then $|E \cap (a,a + \varepsilon_1)| \geq (1 - \delta) \varepsilon_1$ for all $a \in \mathbf{Q}$. This implies that for any $x \in \RR$,
    %
    \[ \limsup_{\substack{x \in I\\|I| \to 0}} \frac{|E \cap I|}{|I|} \geq 1. \]
    %
    The Lebesgue density theorem thus implies that $|E^c| = 0$.
\end{solution}

\question (Jan 2015)
    Let $\{ r_n \} \in [0,1]$ be an arbitrary sequence, and define the function
    %
    \[ f(x) = \sum_{r_n < x} \frac{1}{2^n} \]
    %
    Show that $f$ is Borel measurable, find all it's points of discontinuity, and find $\int_0^1 f(x)\; dx$.
\begin{solution}
    Write
    %
    \[ f_n(x) = \sum_{k = 1}^n \mathbf{I}_{(r_n, \infty)} \cdot 2^{-n}. \]
    %
    Then for each $n$, $f_n$ is a simple function, and is thus measurable. Moreover, $f = \lim_{n \to \infty} f_n$, and this limit is monotone. The pointwise limit of measurable functions is measurable, so $f$ is measurable.
    
    Next, we look at the discontinuity points. We claim that the set of discontinuity points is \emph{precisely} the set of values $\{ r_n \}$. To see this, fix $\varepsilon > 0$, and note that
    %
    \[ f(x + \varepsilon) - f(x) = \sum_{x \leq r_n < x + \varepsilon} 2^{-n} \]
    %
    Suppose there exists some $n_0$ such that $x = r_{n_0}$. Then
    %
    \[ f(x + \varepsilon) - f(x) \geq 1/2^{n_0}, \]
    %
    and thus
    %
    \[ \limsup_{\varepsilon \to 0^+} f(x + \varepsilon) - f(x) \geq 1/2^{n_0}, \]
    %
    implying $f$ is not continuous at $x$. On the other hand, if $x \neq r_n$ for any $n$, then for any $N > 0$, there exists $\varepsilon_N$ such that for $\varepsilon < \varepsilon_N$, $\{ r_1, \dots, r_N \}$ is disjoint from $[x,x+\varepsilon)$. Therefore, for $\varepsilon < \varepsilon_0$,
    %
    \[ f(x + \varepsilon) - f(x) \leq \sum_{k = N+1}^\infty 2^{-n} = 2^{-N}. \]
    %
    Thus we conclude that
    %
    \[ \lim_{\varepsilon \to 0^+} f(x + \varepsilon) - f(x) = 0. \]
    %
    On the other hand, I claim that the left hand limit does not impact continuity, since for all $x \in [0,1]$,
    %
    \[ \lim_{\varepsilon \to 0^-} f(x) - f(x-\varepsilon) = 0. \]
    %
    Indeed, we have
    %
    \[ f(x) - f(x-\varepsilon) = \sum_{x - \varepsilon \leq r_n < x}. \]
    %
    If $N > 0$, there is $\varepsilon_0$ such that for $\varepsilon < \varepsilon_0$, $[x-\varepsilon,x)$, $\{ r_1, \dots, r_N \}$ is disjoint from $[x-\varepsilon,x)$, and thus for such $\varepsilon$,
    %
    \[ f(x) - f(x-\varepsilon) \leq 2^{-N}. \]
    %
    Taking $N \to \infty$ gives the limit, and completes the classification of discontinuity points.
    
    Finally, we note the monotone convergence theorem implies that
    %
    \[ \int_0^1 f(x)\; dx = \lim_{n \to \infty} \int_0^1 f_n(x)\; dx. \]
    %
    Since $f_n$ is a simple function, we easily evaluate
    %
    \[ \int_0^1 f_n(x)\; dx = \sum_{k = 1}^n (1 - r_k) \cdot 2^{-k}. \]
    %
    Thus
    %
    \[ \int_0^1 f(x)\; dx = \sum_{k = 1}^\infty (1 - r_k) \cdot 2^{-k}. \]
\end{solution}


\newpage
\section{Day 12: Bonus Questions}

\question (Aug 2013 \# 5) Let $E= \left\{ (x_{1},x_{2}) : x_{1},x_{2}\in \R, x_{1}-x_{2}\in \Q\right\}$. Is it possible to find to Lebesgue measurable sets $A_{1},A_{2}\subset\R$ such that $|A_{1}|,|A_{2}|>0$, and $A_{1}\times A_{2}\subset E^{c}$?
\begin{solution}
  No, it is not possible. We will show that $|A_{1}|\cdot|A_{2}| = 0$ whenever $A_{1}\times A_{2}\subset E^{c}$. 

 \textbf{ Case 1:} Suppose $A_{1},A_{2}\subset [-n,n]$ for some positive integer $n$.
  Let $h(y)= \int_{\R}\chi_{A_{1}}(x)\chi_{A_{2}}(x+y)dx$. By Tonelli's Theorem,
  \begin{align*}
    \int_{\R}h(y)dy
    &=\int_{\R} \chi_{A_{1}}(x) \int_{\R} \chi_{A_{2}}(y+x)dy dx\\
    &=\int_{\R} \chi_{A_{1}}(x) \int_{\R} \chi_{A_{2}}(y)dy dx\\
    &=\left(\int_{\R} \chi_{A_{1}}(x)dx\right)\left( \int_{\R} \chi_{A_{2}}(y)dy\right)\\
    &=|A_{1}|\cdot |A_{2}|.
  \end{align*}

  Next we claim that $h$ is also continuous. This is by average continuity of the $L^{1}$ norm. For a detailed proof, let $\epsilon>0$. Since $\chi_{A_{2}}\in L^{1}(\R)$, there exists $\phi\in C_{c}(\R)$ with compact support $K\subset \R$ such that $\norm{\chi_{A_{2}}-\phi}_{L^{1}}<\epsilon/3$. Since $\phi$ is continuous on a compact set, it is uniformly continuous, so we may choose $\delta>0$ such that $|\phi(s)-\phi(t)|\leq\epsilon/3|K|$ whenever $|s-t|\leq\delta$. Then
  \begin{align*}
    |h(y+\delta)-h(y)|
    &= \int_{A_{1}}\chi_{A_{2}}(x+y+\delta)dx - \chi_{A_{2}}(x+y)dx\\
    &\leq \int_{A_{1}}|\chi_{A_{2}}(x+y+\delta) -\phi(x+y+\delta)|dx +\int_{A_{1}}|\phi(x+y+\delta)-\phi(x+y)|dx\\
    &\quad+\int_{A_{1}}|\phi(x+y) - \chi_{A_{2}}(x+y)|dx\\
    &\leq 2\int_{\R}|\chi_{A_{2}} -\phi|dx +\int_{K}|\phi(x+\delta)-\phi(x)|dx\\
    &\leq 2\epsilon/3 + \epsilon/3\\
    &= \epsilon.
  \end{align*}
  Since $\epsilon>0$ was arbitrary, $h$ is continuous.

  Finally we claim that $h(y)=0$ for all $y\in \Q$. Indeed, if $y\in \Q$ then for any $x$, we have $x-(y+x)\in \Q$ and hence $(x,y+x)\in E$. Therefore since $A_{1}\times A_{2}\subset E^{c}$, $(x,y+x)\notin A_{1}\times A_{2}$. Therefore 
  \begin{equation*}
    \chi_{A_{1}}(x)\chi_{A_{2}}(y+x)=0.
  \end{equation*}
  Since this holds for all $x\in \R$, it follows that $h(y)= 0$.
  We have shown that
  \begin{enumerate}
  \item $\int_{\R} h = |A_{1}|\cdot |A_{2}|$
  \item $h$ is continuous
  \item $h(y) = 0$ for all $y\in \Q$.
  \end{enumerate}
  By density of $\Q$ in $\R$, (2) and (3) imply that $h\equiv 0$, so that by (1), $|A_{1}|\cdot |A_{2}| = 0$.

  \textbf{Case 2:} Let $A_{1},A_{2}\subset \R$ be arbitrary measurable sets. By case 1,  $|A_{1}\cap [-n,n]|\cdot |A_{2}\cap [-n,n]| =0$ for all $n$. Therefore by continuity of Lebesgue measure,
  \begin{equation*}
    |A_{1}|\cdot|A_{2}| = \lim_{n\to\infty}|A_{1}\cap [-n,n]|\cdot |A_{2}\cap [-n,n]| =\lim_{n\to\infty}0=0.
  \end{equation*}
\end{solution}

\question (September, 2015) Let $(X, \mu)$ be a measure space, and let $f: X \to \RR$ be measurable. Then if $1 \leq p < r < q < \infty$ and there is $C < \infty$ such that
%
\[ \mu(\{ x : |f(x)| > \lambda \}) \leq \frac{C}{\lambda^p + \lambda^q} \]
%
for every $\lambda > 0$. Then $f \in L^r(\mu)$.
\begin{solution}
    We perform a dyadic decomposition, writing
    %
    \begin{align*}
        \int |f(x)|^r\; dx &= \sum_{k = -\infty}^\infty \int_{2^k < |f(x)| \leq 2^{k+1}} |f(x)|^r\; dx\\
        &\leq \sum_{k = -\infty}^\infty \mu(\{ 2^k < |f(x)|) \cdot 2^{kr}.
    \end{align*}
    %
    For $\lambda < 1$, $\lambda^p \leq \lambda^q$, so
    %
    \[ \mu(\{ 2^k < |f(x)| \}) \leq C/2^{kp}. \]
    %
    For $\lambda \geq 1$, $\lambda^q \leq \lambda^p$, so
    %
    \[ \mu(\{ 2^k < |f(x)| \}) \leq C/2^{kq}. \]
    %
    Thus we conclude
    %
    \[ \int |f(x)|^r\; dx \leq C \left( \sum_{k = -\infty}^0 2^{k(r - p)} + \sum_{k = 1}^\infty 2^{k(r - q)} \right). \]
    %
    Both of these sums converge, so
    %
    \[  \int |f(x)|^r\; dx \lesssim_{p,q} C < \infty. \]
\end{solution}

\begin{solution}
  \textit{Case 1:} Suppose that $(X,\mathcal{M},\mu)$ is $\sigma$-finite. This assumption of $\sigma$-finiteness allows us to apply the Fubini-Tonelli Theorem in the following calcuation:
  \begin{align*}
    \int_{X}|f(x)|^{r}dx
    &= \int_{X} \int_{0}^{|f(x)|}r t^{r-1}dt dx\\
    &=\int_{X} \int_{0}^{\infty}  rt^{r-1}\chi_{[ |f(x)|>t]}dtdx \\
    &=\int_{0}^{\infty}r t^{r-1}\int_{X} \chi_{[ |f(x)|>t]}dxdt &&\text{by Tonelli's Theorem}\\
    &=\int_{0}^{\infty}r t^{r-1}\mu\{x: |f(x)|>t\}dt\\ 
    &\leq Cr\int_{0}^{1}\frac{t^{r-1}}{t^{p}+t^{q}}dt + Cr\int_{1}^{\infty} \frac{t^{r-1}}{t^{p}+t^{q}}dt\\ 
    &\leq Cr\int_{0}^{1}t^{r-1-p}dt + Cr\int_{1}^{\infty} t^{r-1-q}dt
  \end{align*}
  and the right-hand side is finite since $1<p<r<q<\infty$.
  
  \vt
  \textit{Case 2:} Suppose $(X,\mathcal{M},\mu)$ is not $\sigma$-finite. Let $X'= \left\{ x\in X: |f(x)|>0 \right\}$. Also define $\mathcal{M}'=\left\{ M\cap X' : M\in \mathcal{M} \right\}$ (it is easy to see this is a $\sigma$-algebra) and define $\mu'$ as the restriction of $\mu$ to $\mathcal{M}'$. Then $(X',\mathcal{M}',\mu')$ is $\sigma$-finite because
  \begin{equation*}
    X'= \bigcup_{n=1}^{\infty}\left\{ x\in X': |f(x)|>\frac{1}{n} \right\}
  \end{equation*}
  and 
  \begin{equation*}
    \mu\left\{ x\in X': |f(x)|>\frac{1}{n} \right\} \leq \frac{C}{n^{-p}+n^{-q}}<\infty
  \end{equation*}
  for all $n$.

  Therefore by Case 1, $\int_{X'}|f(x)|^{r}dx<\infty$. And since $\int_{X}|f(x)|^{r}dx = \int_{X'}|f(x)|^{r}dx$, we are done. 
  \end{solution}

\question (January, 2017)
    Let $E \subset \RR^n$ be a set of finite, positive measure, and let $\{ t_k \}$ be a sequence with $\{ t_k \} > 0$ and $\lim_k t_k = 0$. Define, for $f \in L^p(\RR^n)$,
    %
    \[ Mf(x) = \sup_k \fint_{t_k E} |f(x-y)|\; dy. \]
    %
    Suppose furthermore that there is $C > 0$ such that
    %
    \[ | \{ x: Mf(x) > \lambda \}| \leq C \lambda^{-p} \| f \|_p^p. \]
    %
    Show that for every $f \in L^p(\RR^n)$,
    %
    \[ \lim_k \fint_{t_k E} f(x-y)\; dy = f(x). \]
    %
    for almost every $x \in \RR^d$.
\begin{solution}
    We note that the result is true for any $f \in C(\RR^n)$, i.e. for such functions, and any $x \in \RR$,
    %
    \[ \limsup_k \left| \fint_{t_k E} f(x) - f(x-y) \right| = 0. \]
    %
    Now given any $f \in L^p(\RR^n)$, for $1 \leq p < \infty$, fix $\varepsilon > 0$, and find $g \in C(\RR^n)$ with $\| f - g \|_p \leq \varepsilon$. Then
    %
    \[ |\{ M(f - g) > \lambda \}| \leq C \varepsilon^p \lambda^{-p}. \]
    %
    Thus
    %
    \begin{align*}
        &\left\{ \limsup_k \left| \fint_{t_k E} f(x) - f(x-y)\; dy \right| \geq \delta \right\}\\
        &\quad \subset \left\{ \limsup_k \left| \fint_{t_k E} f(x) - g(x) + g(x-y) - f(x-y)\; dy \right| \geq \delta \right\}\\
        &\quad \subset \left\{ x : |f(x) - g(x)| \geq \delta / 2 \right\} \cup \left\{ \limsup_k \left| \fint_{t_k E} g(x - y) - f(x-y)\; dy \right| \geq \delta/2 \right\}.
    \end{align*}
    %
    Now Markov's inequality implies that
    %
    \[ \left| \left\{ |f(x) - g(x)| \geq \delta / 2 \right\} \right| \leq \| f - g \|_p (\delta/2)^{-p} \lesssim_p \varepsilon \delta^{-p}. \]
    %
    and
    %
    \[ \left| \left\{ x: \limsup_k \left| \fint_{t_k E} g(x - y) - f(x-y)\; dy \right| \geq \delta/2 \right\} \right| \leq \left| \left\{ x: \left| M(g - f)(x) \right| \geq \delta/2 \right\} \right| \lesssim \varepsilon^p \delta^{-p}. \]
    %
    Thus we conclude that
    %
    \[ \left| \left\{ \limsup_k \left| \fint_{t_k E} f(x) - f(x-y)\; dy \right| \geq \delta \right\} \right| \lesssim (\varepsilon + \varepsilon^p) \delta^{-p}. \]
    %
    Taking $\varepsilon \to 0$ shows that for each $\delta > 0$,
    %
    \[ \left| \left\{ \limsup_k \left| \fint_{t_k E} f(x) - f(x-y)\; dy \right| \geq \delta \right\} \right| = 0. \]
    %
    Taking a union bound over $\delta = 1, 1/2, 1/4, \dots$ completes the proof.
\end{solution}




\question (Jan 2020 \#6)
  Let $f_{n}:[0,1]\to \R$ be a sequence of Lebesgue measurable functions such that $f_{n}$ converges to $f$ almost everywhere on $[0,1]$ and such that $\norm{f_{n}}_{L^{2}([0,1])}\leq 1$ for all $n$. Show that
  \begin{equation*}
    \limn \norm{f_{n}-f}_{L^{1}([0,1])}=0.
  \end{equation*}

\begin{solution}
  
  \textit{[This proof may border on trivializing the problem by invoking the Vitali convergence theorem, but I seem to have gotten away with a proof like this on my qual, so... -m]}. Since $|E|<\infty$, it follows trivially that $\{f_{n}\}$ is tight. Since $f_{n}\to f$ a.e., the result will then then follow by the Vitali Convergence Theorem provided that the sequence $\{f_{n}\}$ is uniformly integrable.
  We wish to show that $\left\{ f_{n} \right\}$ is uniformly integrable. Let $\epsilon>0$ and let $A\subset [0,1]$ be measurable. We need to show there exists a $\delta>0$ such that $\int_{A}|f_{n}| <\epsilon$ for all $n$ whenever $|A|<\delta$. By Cauchy-Schwarz inequality and the assumption that $\norm{f_{n}}_{L^{2}}\leq 1$ for all $n$,
  \begin{equation*}
    \int_{A}|f_{n}| = \int_{[0,1]}\chi_{A}|f_{n}| \leq |A|^{1/2}\norm{f_{n}}_{L^{2}} \leq |A|^{1/2}.
  \end{equation*}
  It follows that $\int_{A}|f_{n}|<\epsilon $ for all $n$ whenever $|A|<(\epsilon/2)^{2}$. Therefore $\left\{ f_{n} \right\}$ is uniformly integrable. This completes the proof.


Another (similar) proof is given:
\begin{proof}

  We first prove the following claim:
  \vt
  \noindent
  \textit{Claim 1:} $f_{n},f\in L^{1}([0,1])$ and $\norm{f_{n}}_{L^{1}},\norm{f}_{L^{1}}\leq 1$.
  \begin{proof}[Proof of Claim 1:]
    Since $x\mapsto x^{2}$ is convex and $[0,1]$ has measure 1, it follows by Jensen's inequality that
    \begin{equation*}
      \left(\int_{0}^{1}|f_{n}(x)|dx\right)^{2}\leq \int_{0}^{1}|f_{n}(x)|^{2}dx\leq 1.
    \end{equation*}
    Therefore $\norm{f_{n}}_{L^{1}}\leq 1$ and hence $f_{n}\in L^{1}([0,1])$ for all $n$. Since $f_{n}\to f$ a.e., it follows by Fatou's lemma that
    \begin{equation*}
      \int_{0}^{1}|f(x)|dx \leq \liminf_{n\to\infty}\int_{0}^{1}|f_{n}(x)|dx \leq 1.
    \end{equation*}
    Therefore $f\in L^{1}([0,1])$ with $\norm{f}_{L^{1}}\leq 1$  as well.
  \end{proof}



  By Egorov's Theorem, since $[0,1]$ has finite measure, there exists $E\subset [0,1]$ with $|E|<(\epsilon/4)^{2}$ such that $f_{n}\to f$ uniformly on $[0,1]\backslash E$. By uniform convergence, we may choose a positive integer $n_{0}$ such that $\left| f_{n}(x)-f(x) \right|< \epsilon/2$ for all $x\in [0,1]\backslash E$ and all $n\geq n_{0}$. Then for $n\geq n_{0}$,
  \begin{align*}
    \int_{0}^{1}\left| f_{n}-f \right|
    &= \int_{E} |f_{n}-f| + \int_{[0,1]\backslash E} |f_{n}-f|\\
    &< \int_{E} |f_{n}(x)-f(x)|dx + \epsilon/2\\
    &= \int_{[0,1]} \chi_{E}|f_{n}(x)|dx  + \int_{[0,1]}\chi_{E}|f(x)|dx + \epsilon/2 \\
    &\leq |E|^{1/2}\norm{f_{n}}_{L^{2}}+ |E|^{1/2}\norm{f}_{L^{2}} + \epsilon/2 &&\text{by Cauchy Schwarz}\\
    &\leq 2 |E|^{1/2}+ \epsilon/2 &&\text{by Claim 1}\\
    &< \epsilon/2+\epsilon/2\\
    &=\epsilon.
  \end{align*}
  It follows that $\limn \norm{f_{n}-f}_{L^{1}([0,1])}=0$.
\end{proof}
\end{solution}


\question (Jan 2020 \#1)
Let $\sum_{n=1}^{\infty}a_{n}$ be a convergent series. Let $b_{n}\in\R$ be an increasing sequence with $\lim_{n\to\infty}b_{n}=\infty$. Show that
\begin{equation*}
  \lim_{n\to\infty} \frac{1}{b_{n}}\sum_{k=1}^{n}b_{k}a_{k} = 0.
\end{equation*}

\begin{solution}
  Let $k_{n}= \max \left\{ k\geq 1: \left| \sum_{i=1}^{k}a_{i}b_{i} \right| < \sqrt{b_{n}}\text{ and }k\leq n\right\}$. Since $\sqrt{b_{n}}\to\infty$ monotonically as $n\to \infty$, $k_{n}$ is defined for sufficiently large $n$, is increasing, and $k_{n}\to\infty$. For $n$ sufficiently large, we may write
\begin{equation*}
  \frac{1}{b_{n}}\sum_{k=1}^{n}b_{k}a_{k} =   \frac{1}{b_{n}}\sum_{k=1}^{k_{n}-1}b_{k}a_{k} +  \frac{1}{b_{n}}\sum_{k=k_{n}}^{n}b_{k}a_{k}
\end{equation*}
By choice of $k_{n}$, $\left|\frac{1}{b_{n}}\sum_{k=1}^{k_{n}-1}b_{k}a_{k}\right|\leq \frac{1}{\sqrt{b_{n}}}\to 0$ as $n\to\infty$, so it suffices to show that
\begin{equation*}
  \limn \frac{1}{b_{n}}\sum_{k=k_{n}}^{n}b_{k}a_{k} = 0.
\end{equation*}
Let $T_{k}= \sum_{i=1}^{k}a_{k}$ and let $a=\sum_{n=1}^{\infty}a_{n}$. Using the summation by parts formula,
\begin{align*}
  \frac{1}{b_{n}}\sum_{k=k_{n}}^{n}b_{k}a_{k}
  &= \frac{1}{b_{n}}\left[ T_{n}b_{n} - T_{k_{n}-1}b_{k_{n}}+ \sum_{k=k_{n}}^{n-1}T_{k}(b_{k}-b_{k+1}) \right]\\
  &=\frac{1}{b_{n}}\Bigg[ (T_{n}-a)b_{n} +ab_{n}- (T_{k_{n}-1}-a)b_{k_{n}}-ab_{k_{n}}\\
  &\quad +\left.\sum_{k=k_{n}}^{n-1}(T_{k}-a)(b_{k}-b_{k+1}) +a\sum_{k=k_{n}}^{n-1}(b_{k}-b_{k+1}) \right]\\
  &= \frac{1}{b_{n}}\left[ (T_{n}-a)b_{n} - (T_{k_{n}-1}-a)b_{k_{n}}+ \sum_{k=k_{n}}^{n-1}(T_{k}-a)(b_{k}-b_{k+1})\right]
\end{align*}
where for the last equality we used the fact that $\sum_{k=k_{n}}^{n-1}(b_{k}-b_{k+1})= b_{k_{n}}-b_{n}$. Let $M_{n}= \max_{k_{n}\leq k <n}|T_{k}-a|$. By the triangle inequality, and using $b_{k_{n}}\leq b_{n}$,
\begin{align*}
  \left| \frac{1}{b_{n}}\sum_{k=k_{n}}^{n}b_{k}a_{k} \right|
  &\leq 2\left| T_{n}-a \right| +  \frac{1}{b_{n}}\left|\sum_{k=k_{n}}^{n-1}(T_{k}-a)(b_{k}-b_{k+1})\right|\\
  &\leq 2\left| T_{n}-a \right| +  \frac{M_{n}}{b_{n}}\sum_{k=k_{n}}^{n-1}|b_{k}-b_{k+1}|\\
  &= 2\left| T_{n}-a \right| +  \frac{M_{n}}{b_{n}}\sum_{k=k_{n}}^{n-1}b_{k+1}-b_{k}\\
  &= 2\left| T_{n}-a \right| +  \frac{M_{n}}{b_{n}}(b_{n}-b_{k_{n}})\\
  &\leq 2\left| T_{n}-a \right| +  2M_{n}
\end{align*}
The result then follows since $T_{n}\to a$ and $M_{n}\to 0$ as $n\to \infty$. 
\end{solution}

\question (Aug 2018 \#8R)
  Let $1<p\leq \infty$. Let $(X,\mathcal{M},\mu)$ be a finite measure speace. Let $\left\{ f_{n} \right\}$ be a sequence of measurable functions converging $\mu$-a.e. to the function $f$. Assume further that $\norm{f_{n}}_{p}\leq 1$ for all $n$. Prove that $f_{n}\to f$ as $n\to \infty$ in $L^{r}$ for all $1\leq r<p$.
\begin{solution}
  \textit{Case 1.} If $p=\infty$ then since $\norm{f}_{\infty}\leq 1$ and $f_{n}\to f$ a.e., it follows that $\norm{f}_{\infty}\leq 1$. Therefore by the triangle inequality and using the fact that $r\geq 1$, we have $|f_{n}-f|^{r}\leq (|f_{n}| + |f| )^{r}\leq 2^{r}$. Since the constant function $2^{r}$ is integrable on $X$ with respect to $\mu$, it follows by the dominated convergence theorem that $\lim_{n\to\infty}\int_{X} |f_{n}-f|^{r}d\mu = 0$. Therefore $f_{n}\to f$ in $L^{r}$.

  \textit{Case 2.} Suppose $1<p<\infty$. Let $\epsilon>0$, and let $\epsilon_{0} = 2^{-r} \epsilon^{\frac{p}{p-r}}$ (here we use the assumption that $p>r$ so that $\epsilon_{0}>0$ is defined). By Egorov's theorem there exists $A\subset X$ such that $\mu(A^{c})<\epsilon_{0}$ and $f_{n}\to f$ uniformly on $A$. Then
  \begin{equation*}
    \int_{X} |f_{n}-f|^{r} = \int_{A^{c}}|f_{n}-f|^{r}d\mu + \int_{A}|f_{n}-f|^{r}d\mu
  \end{equation*}
  Since $r\geq 1$, it follows that $|f_{n}-f|^{r}\to 0$ uniformly. Therefore $\lim_{n\to\infty }\int_{A}|f_{n}-f|^{r}d\mu =0$. Therefore
  \begin{equation}\label{eq:2}
    \limsup_{n\to\infty} \int_{X} |f_{n}-f|^{r} \leq \limsup_{n\to\infty} \int_{A^{c}}|f_{n}-f|^{r}d\mu
  \end{equation}
  By Holder's inequality,
  \begin{align*}
    \int_{A^{c}}|f_{n}-f|^{r}d\mu
    &= \int_{X} |f_{n}-f|^{r}\chi_{A^{c}} d\mu\\
    &\leq \left( \int_{X}|f_{n}-f|^{p} d\mu\right)^{r/p}\left( \int_{X}\chi_{A^{c}}d\mu  \right)^{\frac{p-r}{p}}\\
    &= \norm{f_{n}-f}_{p}^{r}\mu(A^{c})^{\frac{p-r}{r}}\\
    &= \epsilon\norm{f_{n}-f}_{p}^{r}\\
    &\leq \epsilon ( \norm{f_{n}}_{p}+ \norm{f}_{p})^{r}\\
    &\leq \epsilon \left( 1 + \norm{f}_{p} \right)^{r}
  \end{align*}
  Also, by Fatou's lemma, $\norm{f}_{p}\leq \liminf_{n\to\infty} \norm{f_{n}}_{p}\leq 1$. Therefore
  \begin{equation*}
    \int_{A^{c}} | f_{n}-f|^{r}d\mu \leq \epsilon 2^{r}
  \end{equation*}
  Therefore by \eqref{eq:2},
  \begin{equation*}
     \limsup_{n\to\infty} \int_{X} |f_{n}-f|^{r}d\mu  \leq \epsilon 2^{r}
   \end{equation*}
   Since $\epsilon>0$ was arbitrary, it follows that $\limsup_{n\to\infty} \int_{X} |f_{n}-f|^{r}d\mu=0$. Therefore $f_{n}\to f$ in $L^{r}$.
\end{solution}

\question (September, 2017) Let $f: \RR \to \RR$ be a compactly supported function that satisfies the H\"{o}lder condition with exponent $\beta \in (0,1)$, i.e. that there exists a constant $A < \infty$ such that for all $x,y \in \RR$, $|f(x) - f(y)| \leq A|x-y|^\beta$. Consider the function $g$ defined by
%
\[ g(x) = \int_{-\infty}^\infty \frac{f(y)}{|x-y|^\alpha}\; dy, \]
%
where $\alpha \in (0,\beta)$.
%
\begin{parts}
    \part Prove that $g$ is a continuous function at zero.
    \begin{solution}
        One way to see this immediately is to apply Young's inequality for convolution. More directly, we can write
        %
        \begin{align*}
            g(x) - g(0) = \int_{-\infty}^\infty f(y) \left( \frac{1}{|x - y|^\alpha} - \frac{1}{|y|^\alpha} \right)\; dy
        \end{align*}
        %
        For $|y| \leq |x|/2$, we have
        %
        \[ \left( \frac{1}{|x - y|^\alpha} - \frac{1}{|y|^\alpha} \right) \lesssim 1/|x|^\alpha. \]
        %
        Thus
        %
        \[ \left| \int_{|y| \leq |x|/2} f(y) \left( \frac{1}{|x - y|^\alpha} - \frac{1}{|y|^\alpha} \right)\; dy \right| \lesssim \| f \|_\infty |x|^{1-\alpha} \]
        %
        For $|y| \geq 2|x|$, we can apply Taylor's theorem / the mean value theorem to conclude that
        %
        \[ \left| \frac{1}{|x - y|^\alpha} - \frac{1}{|y|^\alpha} \right| \lesssim \frac{|x|}{|y|^{\alpha + 1}}. \]
        %
        This bound implies that
        %
        \[ \left| \int_{|y| \geq 2|x|} f(y) \left( \frac{1}{|x - y|^\alpha} - \frac{1}{|y|^\alpha} \right)\; dy \right| \lesssim \| f \|_\infty |x|^{1-\alpha}. \]
        %
        For $|x|/2 \leq |y| \leq 2|x|$, we have
        %
        \[ \left| \int_{|x|/2 \leq |y| \leq 2|x|} f(y) \left( \frac{1}{|x - y|^\alpha} - \frac{1}{|y|^\alpha} \right)\; dy \right| \leq 2 \| f \|_\infty \int_{|y| \leq 3|x|} \frac{1}{|y|^\alpha} \lesssim \| f \|_\infty |x|^{1-\alpha}. \]
        %
        These bounds together imply that
        %
        \[ |g(x) - g(0)| \lesssim \| f \|_\infty |x|^{1-\alpha}. \]
        %
        Thus $g(x) \to g(0)$ as $x \to 0$.
    \end{solution}
    
    \part Prove that $g$ is differentiable at zero. (Hint: Try the dominated convergence theorem).
    \begin{solution}
        Assume first that $f(0) = 0$. We have
        %
        \[ \frac{g(x) - g(0)}{x} = \int_{-\infty}^\infty f(y) \frac{1}{x} \left( \frac{1}{|y - x|^\alpha} - \frac{1}{|y|^\alpha} \right)\; dy. \]
        %
        The integrand here converges pointwise as $x \to 0$ to
        %
        \[ f(y) \alpha / |y|^{\alpha+1}, \]
        %
        which is integrable since the function is compactly supported and continuous away from the origin, and $|f(y)| \lesssim |y|^\beta$ near the origin. The mean value theorem implies that if $x \leq 1$,
        %
        \[ \left| \frac{1}{x} \left( \frac{1}{|y - x|^\alpha} - \frac{1}{|y|^\alpha} \right) \right| \lesssim 1/|y|^{\alpha+1} \]
        
        
        so we might expect that
        %
        \[ g'(0) = \int_{-\infty}^\infty f(y) \alpha / |y|^{\alpha+1}, \]
        %
        at least if the dominated convergence theorem
    \end{solution}
\end{parts}




\newpage
\section{Day 13: Interchanging limits and integrals + Arzela-Ascoli Theorem}

\subsection{Limits and Integrals (DCT and friends)}

\question (Rice Winter Qualifying Exam 2011) Let $\{ f_n \}$ be a sequence of Lebesgue measurable functions defined on $[0,1]$ such that $\| f(x) \| \leq 1$ for all $n \geq 1$ and all $0 < x \leq 1$, and
\[ \lim_{n \to \infty} f_n(x) = f(x) \]
%
exists for each $0 \leq x \leq 1$. Prove that
%
\[ \lim_{n \to \infty} \int_0^1 \frac{f_n(x)}{\sqrt{|x-1/n|}} = \int_0^1 \frac{f(x)}{\sqrt{x}}\; dx \]
\begin{solution}
    Let $g_n(x) = f_n(x) / \sqrt{|x - 1/n|}$. We wish to apply the Vitali convergence theorem. To do this, let us first show that the sequence $\{ g_n \}$ is uniformly integrable. Now for a fixed $M > 0$ and $n > 0$, since $|f_n(x)| \leq 1$, if $|g_n(x)| \geq M$, then $|x- 1/n| \leq 1/M^2$, and so
    %
    \[ \int_{|g_n(x)| \geq M} |g_n(x)| \leq \int_{|x - 1/n| \leq 1/M^2} \frac{1}{|x - 1/n|^{1/2}} \leq \int_{|x| \leq 1/M^2} \frac{1}{|x|^{1/2}} \lesssim M^{-1}. \]
    %
    Thus
    %
    \[ \lim_{M \to \infty} \sup_{|g_n(x)| \geq M} |g_n(x)| = 0. \]
    %
    To show $g_n$ converges to $g(x) = f(x) / \sqrt{x}$, it thus suffices to show that $g_n$ converges to $g$ in measure. Now $g_n$ clearly converges to $g$ except when $x = 0$, and thus $g_n$ converges to $g$ almost everywhere. But this implies $g_n$ converges to $g$ in measure (since we are working over a finite measure space), and thus $g_n$ converges to $g$ in $L^1[0,1]$.
\end{solution}

\question (Rice, Spring 2005) Compute
%
\begin{parts}
    \part $\lim_{n \to \infty} \int_0^\infty \frac{x^{n-2}}{1 + x^n}$.
    \begin{solution}
        We apply the dominated convergence theorem. For $0 \leq x \leq 1$, $x^{n-2} / 1 + x^n \leq 1$, and for $1 \leq x \leq \infty$, $x^{n-2} / (1 + x^n) \leq x^{n-2} / x^n \leq 1/x^2$. Thus the family of integrands $x^{n-2} / (1 + x^n)$ is domainated by an integrable function, namely the function
        %
        \[ \mathbf{I}(0 \leq x \leq 1) + \mathbf{I}(1 \leq x) \cdot 1/x^2. \]
        %
        The sequence converges pointwise to zero for $0 \leq x < 1$, and for $x > 1$,
        %
        \[ \lim_{n \to \infty} x^{n-2} / (1 + x^n) = \lim_{n \to \infty} 1 / (x^2 + 1/x^{n-2}) = 1/x^2. \]
        %
        Thus the domainated convergence theorem implies that
        %
        \[ \lim_{n \to \infty} \frac{x^{n-2}}{1 + x^n} = \int_1^\infty \frac{1}{x^2} = 1. \]
    \end{solution}
    
    \part $\lim_{n \to \infty} n \int_0^\infty \frac{\sin y}{y(1 + n^2 y)}\; dy$ (Hint: Substitute $x = ny$).
    \begin{solution}
        We have
        %
        \[ n \int_0^\infty \frac{\sin y}{y(1 + n^2 y)}\; dy = n \int_0^\infty \frac{\sin(y/n)}{y (1 + ny)}\; dy. \]
        %
        For $y \geq 1$,
        %
        \[ n \frac{\sin(y/n)}{y ( 1 + ny) } \leq n \frac{1}{y(ny)} \leq 1/y^2. \]
        %
        For $y \leq 1$, we employ the bound $\sin(y/n) \leq y/n$ to conclude that
        %
        \[ n \frac{\sin(y/n)}{y ( 1 + ny) } \leq \frac{1}{1 + ny} \leq 1. \]
        %
        These bounds imply that the family of integrands is uniformly integrable. Now for all $0 \leq x \leq 1$,
        %
        \[ \lim_{n \to \infty} n \frac{\sin(y/n)}{y(1 + ny)} = \lim_{n \to \infty} \frac{1}{1 + ny} + O \left( n \frac{(y/n)^2}{y(1 + ny)} \right) = \lim_{n \to \infty} \frac{1}{1 + ny} + O \left( \frac{y}{n(1 + ny)} \right) = 0. \]
        %
        Thus the dominated convergence theorem implies that
        %
        \[ \lim_{n \to \infty} n \int_0^\infty \frac{\sin y}{y(1 + n^2 y)}\; dy = 0. \]
    \end{solution}
\end{parts}

\question (January, 2017)
    Let $f: [0,\infty) \to \RR$ be a continuously differentiable function for which $\| f' \|_\infty < \infty$. Define, for $x > 0$,
    %
    \[ F(x) = \int_0^\infty f(x + yx) \psi(y)\; dy, \]
    %
    where $\psi$ satisfies
    %
    \[ \int_0^\infty |\psi(y)|\; dy \quad\text{and}\quad \int_0^\infty y \cdot |\psi(y)|\; dy < \infty. \]
    %
    Show that $F(x)$ is well defined for all $x \geq 0$, and that $F$ is continuously differentiable.
\begin{solution}
    The fundamental theorem of calculus implies that
    %
    \[ |f(x + yx)| = \left| f(x) + \int_x^{x+yx} f'(t)\; dt \right| = f(x) + O(yx). \]
    %
    Thus combined with the fact that $\int_0^\infty |\psi(y)|\; dy < \infty$ and $\int_0^\infty y \cdot |\psi(y)|\; dy < \infty$, this implies that
    %
    \[ \int_0^\infty |f(x + yx)| |\psi(y)|\; dy \lesssim |f(x)| + |x| < \infty, \]
    %
    so $F$ is well defined.
    
    To show that $F$ is continuously differentiable, we note that for a fixed $x \in [0,\infty)$, we calculate that, for $h$ with $0 \leq x + h$,
    %
    \begin{align*}
        \frac{F(x+h) - F(x)}{h} &= \int_0^\infty \frac{|f(x+yx + h(1 + y)) - f(x + yx)|}{h} \psi(y)\; dy.
    \end{align*}
    %
    Now
    %
    \[ \left| \frac{|f(x+yx + h(1 + y)) - f(x + yx)|}{h} \psi(y) \right| \lesssim (1 + y) |\psi(y)|. \]
    %
    Since $(1 + y) \psi(y)$ is integrable, the dominated convergence theorem implies that $F$ is differentiable at $x$, and
    %
    \[ F'(x) = \int_0^\infty f'(x + yx) (1 + y) \psi(y)\; dy. \]
    %
    Finally, we show $F'$ is continuous. We note that for any $\varepsilon > 0$, there exists $R > 0$ such that
    %
    \[ \int_R^\infty (1 + y) |\psi(y)|\; dy \leq \varepsilon. \]
    %
    Since $f'$ is continuous, it is uniformly continuous on $[0,2R(1 + x)]$. Thus there exists $\delta > 0$ such that for $|h| \leq \delta$, and $0 \leq y \leq R$, $|f'((x + yx) + h(1 + y)) - f(x + yx)| \leq \varepsilon$, and so
    %
    \begin{align*}
        F'(x+h) - F(x) &\lesssim \varepsilon + \int_0^R [f'((x + yx) + h(1 + y)) - f'(x + yx)] (1 + y) \psi(y)\; dy\\
        &\lesssim \varepsilon + \int_0^R \varepsilon (1 + y) \psi(y)\; dy \lesssim \varepsilon.
    \end{align*}
\end{solution}

\subsection{Arzela-Ascoli}


The key part of the Arzela-Ascoli theorem to know for the qual is the following: If $\{f_n\}\subset C[0,1]$ is a sequence which is uniformly bounded and equicontinuous, then $\{f_n\}$ has a uniformly convergent subsequence. 

(Note that we can replace $[0,1]$ by any compact subset of $\R^d$. Also, there is a converse to the theorem, but I haven't seen it used in any qual problems.)

By \textit{uniformly bounded}, we mean that $|f_n(x)|\leq C$ for all $x\in [0,1]$, $n\in \mathbb{N}$.

By \textit{equicontinuous}, we mean that for all $\epsilon>0$, there exists $\delta$ such that  $|f_n(x)-f_n(y)|<\epsilon$ whenever $|x-y|<\delta$ for all $n\in \mathbb{N}$.


\question (From a UBC Math 321 Midterm) Let $\{ f_n \}$ be a sequence of functions in $C[a,b]$ with no uniformly convergent subsequence. Define
%
\[ F_n(x) = \int_a^x \sin(f_n(t))\; dt. \]
%
Does $\{ F_n \}$ has a uniformly convergent subsequence.
\begin{solution}
    The sequence $\{ F_n \}$ does have a uniformly convergent subsequence, by Arzela-Ascoli. Indeed, it is simple to see that $\| F_n \|_\infty \leq b - a$ for all $n > 0$, so the sequence $\{ F_n \}$ is uniformly bounded. The sequence is also equicontinuous, because
    \[ |F_n(x) - F_n(y)| \leq |x - y| \]
    %
    uniformly in $n$. Thus Arzela-Ascoli implies the existence of a uniformly convergent subsequence.
\end{solution}

\question (August 2004) Let $f_{n}:[0,1]\to \R$ be a sequence of continuous functions whose derivatives $f'_{n}$ in the sense of distributions belong to $L^{2}(0,1)$. The functions also satisfy $f_{n}(0)=0$.
\begin{parts}
  \part
Assume that
\begin{equation*}
  \lim_{n\to\infty} \int_{0}^{1}f'_{n}(x)g(x)dx
\end{equation*}
exists for all $g\in L^{2}(0,1)$. Show that the $f_{n}$ converge uniformly as $n\to\infty$.
\begin{solution}
  Define $T_n(g) = \int_0^1 f_n'gdx$ for $g\in L^2(0,1)$. Then $T_n$ is clearly linear and by Cauchy-Schwarz inquality, $T_n$ is bounded. Then by the part (a) assumption, we have
  \begin{equation*}
  \sup \{ T_n(g) : n\geq 1 \} <\infty.
  \end{equation*}
  Therefore by the Uniform Boundedness Principle, 
  \begin{equation*}
  C:= \sup_n \norm{f_n'}_{L^2} <\infty
  \end{equation*}
  Uniform boundedness principle to obtain a uniform bound on $f_n'$. Then apply Arzela ascoli to a subsequence to obtain convergence of whole sequence. [Note the uniform boundedness of the derivatives suggests that we have uniform equicontinuity -- and hence maybe we can use the Arzela-Ascoli Theorem.] In particular, since $f'\in L^2[0,1]$, it follows that $f'\in L^1[0,1]$. Therefore
  \begin{equation}\label{newton-leibniz}
  f_n(x)-f_n(y) = \int_y^x f_n(t)dt
  \end{equation}
  Taking $y=0$ and using $f_n(0)=0$, we have 
  \begin{equation*}
  |f_n(x)|\leq \int_0^x |f_n'(t)|dt \leq \int_0^1 |f_n'(t)|dt \leq \(\int_0^1 |f_n'(t)|^2dt\)^{\frac{1}{2}} \leq C.
  \end{equation*}
  Therefore $\{f_n\}_n$ is uniformly bounded. In addition, by \eqref{newton-leibniz} and Cauchy-Schwarz inequality, we have 
  \begin{equation*}
  |f_n(x)-f_n(y)| \leq \left| \int_y^x f_n'(t)dt\right| \leq \sqrt{x-y} \(\int_y^x |f_n'|^2dt \)^{\frac{1}{2}} \leq C \sqrt{x-y}.
  \end{equation*}
  Therefore $\{f_n\}$ is uniformly equi-continuous. Therefore by the Arzela-Ascoli theorem, $\{f_n\}_{n\in \mathbb{N}}$ is a relatively compact subset of $C([0,1])$. 
  
  Recall that by assumption $\lim_{n\to\infty} \int_{0}^{1}f'_{n}(x)g(x)dx$ exists for any $g\in L^2[0,1]$. Taking $g(x) = \chi_{[0,a]}$, we have $\lim_{n\to\infty} \int_{0}^{a}f'_{n}(x)dx=\limn f'_n(a)$ exists. That is, there exists some real-valued function $f$ such that $f_n\to f$ pointwise.  
  
  Suppose that $f_n$ does not converge uniformly to $f$. Then there exists a subsequence $n_k$ and $\epsilon_0>0$ such that 
  \begin{equation*}
  \sup_{x\in[0,1]} |f(x)-f_{n_k}(x)|\geq \epsilon_0
  \end{equation*}
  for all $k$. However, since $\{f_n\}_n$ is relatively compact, there exists a subsequence $f_{n_{k_j}}$ which is uniformly Cauchy--and therefore must converge uniformly to $f$. But this implies that
  \begin{equation*}
  \sup_{x\in[0,1]} |f(x)-f_{n_{k_j}}(x)|\to 0 \quad \text{as }j\to\infty
  \end{equation*}
  This is a contradiction.
\end{solution}

\part Assume that
\begin{equation*}
  \lim_{n\to\infty} \int_{0}^{1}f'_{n}(x)g(x)dx
\end{equation*}
exists for all $g\in C([0,1])$. Do we still have the $f_{n}$ converge uniformly?
\begin{solution}
  Maybe yes by density?
\end{solution}
\end{parts}

\question (January 2014)

Consider the following operator

\begin{equation*}
  Af = \frac{1}{x \sqrt{1+|\log x|}} \int_{0}^{x}f(t)dt  
\end{equation*}
Is $A$ bounded as an operator from $L^{2}[0,1]$ to $L^{2}[0,1]$. Is it compact?
\begin{solution}
We first prove the following lemma: 

  \textit{Lemma 1 (Hardy's Inequality):} If $F(x)= \int_{0}^{x}f(t)dt$ then
  \begin{equation*}
    \int_{0}^{1}\left( \frac{F(x)}{x} \right)^{2}dx \leq 4 \int_{0}^{1}f^{2}(x)dx
  \end{equation*}
  \begin{proof}[Proof of Lemma:] 
    \begin{align*}
      \int_{0}^{1}\frac{F(x)^{2}}{x^{2}}dx
      &= - \left.\frac{F(x)^{2}}{x}\right|_{0}^{1} - \int_{0}^{1}\left( \frac{-1}{x} \right)2F(x)f(x)dx &&\text{Integration by parts}\\
      &\leq 2 \int_{0}^{1}\frac{F(x)}{x}f(x)dx\\
      &\leq 2 \left(  \int_{0}^{1}\frac{F(x)^{2}}{x^{2}}dx \right)^{\frac{1}{2}} \left( \int_{0}^{1}f(x)^{2}dx \right)^{\frac{1}{2}}&&\text{Cauchy-Schwarz}
    \end{align*}
    Dividing by $ \left(  \int_{0}^{1}\frac{F(x)^{2}}{x^{2}}dx \right)^{\frac{1}{2}}$ and squaring both sides gives the result.
  \end{proof}
  
  We will use Hardy's inequality to prove that $A$ is bounded. Letting $F(x) = \int_{0}^{x}f(t)dt$, we have
  \begin{align*}
    \norm{Af}_{2}^{2} = \int_{0}^{1}\frac{|F(x)|^{2}}{|x|^{2}} \frac{1}{1+|\log x|}dx \leq \int_{0}^{1}\frac{|F(x)|^{2}}{|x|^{2}}dx \leq 4 \norm{f}^{2}_{2}
  \end{align*}
  where the last inequality is due to Hardy's inequality. Since $A$ is clearly linear, it follows that $A$ is a bounded linear operator.
  
  Next we show that $A$ is a compact operator. Let $\left\{ f_{n} \right\}_{n\geq 1}$ be a bounded sequence in $L^{2}[0,1]$. To show that $A$ is compact, it suffices to show that there exists a subsequence $\left\{ f_{n_{k}} \right\}_{k\geq 1}$ such that $\left\{ Af_{n_{k}} \right\}_{k\geq 1}$ converges in $L^{2}[0,1]$.

  
  \vt
  \textit{Claim 2.} Let $F_{n}(x):=\int_{0}^{x}f_{n}(t)dt$. Then $\{F_{n}\}_{n=1}^{\infty}$ is a relatively compact subset of $C[0,1]$ (with respect to the topology induced by the uniform norm).

  To prove claim 2, we apply the Arzela-Ascoli Theorem. First, since $\{f_{n}\}_{n}$ is bounded in $L^{2}[0,1]$, there exists some $C>0$ such that $\norm{f_{n}}_{L^{2}}\leq C$ for all $n$. Then
  \begin{equation*}
    |F_{n}(x)| \leq \int_{0}^{x}|f_{n}(x)|dx \leq \(\int_{0}^{1}|f_{n}(x)|^{2}dx \)^{\frac{1}{2}} \leq C <\infty.
  \end{equation*}
  Therefore $\left\{ F_{n} \right\}$ is uniformly bounded. It remains to show that $\left\{ F_{n} \right\}$ is equicontinuous. By the Cauchy-Schwarz inequality,
  \begin{equation*}
    \left| F_{n}(x)-F_{n}(y) \right| = \left| \int_{y}^{x}f_{n}(t)dt \right| \leq \norm{f_{n}}_{L^{2}} \sqrt{|x-y|} \leq C \sqrt{|x-y|}.
  \end{equation*}
  Therefore  $\left\{ F_{n} \right\}$ is equicontinuous. Therefore by the Arzela-Ascoli theorem, $\{F_{n}\}_{n=1}^{\infty}$ is a relatively compact. This proves Claim 2.

  By Claim 2, there exists a subsequence $F_{n_{k}}$ such that $\{F_{n_{k}}\}_{k}$ is uniformly Cauchy. We claim that $\{Af_{n_{k}}\}_{k\geq 1}$ converges in $L^{2}$-norm, which will complete the proof. Indeed,
  \begin{align*}
    \norm{Af_{n_{j}}-Af_{n_{k}}}_{L^{2}}^{2}
    &\leq \int_{0}^{1}\frac{|F_{n_{j}}(x)-F_{n_{k}}(x)|^{2}}{|x|^{2}\left( 1+|\log x| \right)} dx\\
    &= \int_{0}^{\delta}\frac{|F_{n_{j}}(x)-F_{n_{k}}(x)|^{2}}{|x|^{2}\left( 1+|\log x| \right)} dx + \int_{\delta}^{1}\frac{|F_{n_{j}}(x)-F_{n_{k}}(x)|^{2}}{|x|^{2}\left( 1+|\log x| \right)} dx\\
    &\leq \frac{1}{1+|\log \delta |} \underbrace{\int_{0}^{\delta}\frac{|F_{n_{j}}(x)-F_{n_{k}}(x)|^{2}}{|x|^{2}} dx}_{\text{apply Hardy's inequality again}} + \norm{F_{n_{j}}-F_{n_{k}}}_{L^{\infty}} \cdot\frac{1}{\delta^{2}}\\
    &\leq \frac{1}{1+|\log \delta |} \norm{f_{n_{j}}-f_{n_{k}}}_{L^{2}} + \frac{1}{\delta^{2}} \norm{F_{n_{j}}-F_{n_{k}}}_{L^{\infty}}\\
    &\leq \frac{2C}{1+|\log \delta|} + \frac{1}{\delta^{2}} \norm{F_{n_{j}}-F_{n_{k}}}_{L^{\infty}}.
  \end{align*}
  Let $\epsilon>0$. Choose $\delta$ sufficiently small that $\frac{2C}{1+|\log \delta|}<\epsilon/2$, and choose $N\geq 0$ sufficiently large that $\norm{F_{n_{j}}-F_{n_{k}}}_{L^{\infty}}\leq \delta^{2}\epsilon/2$ whenever $j,k\geq N$. So $j,k\geq N$ implies $\norm{Af_{n_{j}}-Af_{n_{k}}}_{L^{2}}^{2} \leq \epsilon/2 + \epsilon/2= \epsilon$.
  
  We have shown that $\left\{ Af_{n_{k}} \right\}_{k}$ is Cauchy in $L^2[0,1]$, as required.
\end{solution}


\question (Problem 36 from the 2017 SEP) Consider the Hilbert space $L^{2}([0,1])$ with inner product $(f,g):=\int_{0}^{1}f(t)\bar{g}(t)dt$. Let $\left\{ e_{n} \right\}_{n=1}^{\infty}$ be an orthonormal system of functions in $L^{2}([0,1])$.
\begin{parts}
  \part
Suppose that $e_{n}\in L^{2}([0,1])$ for all $n\in\mathbb{N}$. Show that
\begin{equation*}
  \sup_{n}\max_{x\in[0,1]}|e_{n}'(x)| = \infty.
\end{equation*}

\begin{solution}
  Suppose not. Then there exists some $C<\infty$ such that
  \begin{equation*}
  \sup_n \max_{x\in [0,1]} \left| e'_{n}(x) \right| \leq C.
\end{equation*}
Therefore $|e_{n}(x)-e_{n}(y)| \leq C|x-y|$. Hence $\{e_{n}\}$ is equicontinuous.

By Chebychev's inequality,
\begin{equation*}
  \left| \left\{ x\in [0,1]: |e_{n}(x)|>\alpha \right\} \right|\leq \frac{\int_{0}^{1}e_{n}(x)^{2}dx}{\alpha^{2}}= \frac{1}{\alpha^{2}}.
\end{equation*}
Taking $\alpha=2$, we find that $\left| \left\{ x\in [0,1]: |e_{n}(x)|\leq 2 \right\} \right|>\frac{1}{4}$. Since every set with positive measure has at least one element, there exists some $x_{n}\in [0,1]$ such that $|e_{n}(x)|\leq 2$. Therefore for any $x\in [0,1]$ and any $n\in \mathbb{N}$, we have
\begin{equation*}
  |e_{n}(x)| = \left| e_{n}(x_{n})+\int_{x_{n}}^{x}e'_{n}(t)dt \right|\leq 2 + \left| x_{n}-x \right| \leq 3.
\end{equation*}
Therefore $\left\{ e_{n} \right\}$ is uniformly bounded. Therefore by the Arzela-Ascoli theorem, there exists some subsequence $(e_{n_{k}})$ such that $e_{n_{k}}\to f$ uniformly in $C[0,1]$ as $k\to \infty$. Therefore $e_{n_{k}}\to f$ in $L^{2}[0,1]$. But this contradicts the orthonormality of the sequence $\left\{ e_{n} \right\}_{n=1}^{\infty}$. (In particular, by orthonormality we have for all $m\neq n$: 
\begin{equation*}
  \norm{e_{n}-e_{m}}_{L^{2}} ^{2}= \langle e_{n}-e_{m},e_{n}-e_{m}\rangle = \langle e_{n},e_{n} \rangle - \langle e_{m},e_{n} \rangle - \langle e_{n},e_{m} \rangle + \langle e_{m},e_{m} \rangle =1-0-0+1 =2
\end{equation*}
and this implies that $\{e_{n}\}$ can have no subsequence which is Cauchy in $L^{2}$.)
\end{solution}

\part Suppose that $e_{n}$ is complete, which means $(g,e_{n})=0$ for all $n$ implies $g=0$ almost everywhere. Prove
\begin{equation*}
  \sum_{n=1}^{\infty}|e_{n}(x)|^{2}=\infty, \quad\text{almost everywhere.}
\end{equation*}

\begin{solution}
We first prove the following claim: 

  \textit{Claim 1.} If $E\subset [0,1]$ is measurable and $|E|>0$, then
  \begin{equation*}
    \int_{E} \sum_{n=1}^{\infty} \left| e_{n}(x) \right|^{2}dx \geq 1.
  \end{equation*}
  To prove the claim, observe that
  \begin{equation*}
    |E|= \norm{\chi_{E}}_{L^{2}}^{2}  = \sum_{n=1}^{\infty} (\chi_{E},e_{n})^{2} = \sum_{n=1}^{\infty} \left( \int_0^{1}\chi_{E}(x) e_{n}(x)dx \right)^{2}\leq \sum_{n=1}^{\infty} \(\int_{E} e_{n}^{2}dx \) |E|
  \end{equation*}
  where the second equality is by Completeness of $(e_{n})$ and the inequality is due to Cauchy-Schwarz. Dividing both sides by $|E|$ and applying the Fubini-Tonelli theorem proves the claim.

  Define
  \begin{equation*}
  A_M = \left\{ x:  \sum_{n=1}^{\infty} |e_n(x)|^2 \leq M\right\}.
  \end{equation*}
  Suppose there exists some $M>0$ such that $|A_M|>0$. Let $E_n\subset A_M$ with $0<|E_n|<1/n$. Then by Claim 1,
  
  $$1\leq \int_{E_n} \sum_{n=1}^{\infty} \left| e_{n}(x) \right|^{2}dx \leq \frac{M}{n} \to 0$$
  a contradiction. Therefore $|A_M|=0$ for all $M$. Since $\{A_M\}_M$ is an ascending sequence of sets, it follows by continuity of measure that
  
  $$\left|\left\{x: \sum_{n=1}^{\infty} |e_n(x)|^2 dx <\infty\right\}\right|=\left|\bigcup_{M=1}^{\infty} A_M\right| = \lim_{M\to\infty} |A_M| =0.$$
\end{solution}
\end{parts}





\newpage
\section{Day 14: Misc. Topics}

\question (Rice Qualifying Exam, Winter 2008) Is it possible to construct a measurable set $E \subset \RR$ of positive measure such that for any pair $a < b$, $|E \cap [a,b]| \leq 0.5 (b - a)$?
\begin{solution}
    No, since the Lebesgue differentiation theorem implies that if $E$ has positive measure, then there exists $x_0$ such that
    %
    \[ \limsup_{x_0 \in I} |E \cap I|/|I| = 1. \]
    %
    However, if $E$ is as above, then $|E \cap I| / |I| \leq 0.5$ for any interval $I$, so $x_0$ cannot possibly exist. Thus any $E$ satisfying the condition above must have measure zero.
\end{solution}

\question (January 2010) For $\lambda>0$, set
\begin{equation*}
  F(\lambda)= \int_{0}^{1}e^{-10\lambda x^{4}+\lambda x^{6}}dx
\end{equation*}
Prove there exists constants $A$ and $C>0$, such that $F(\lambda)=\frac{A}{\lambda^{\frac{1}{4}}} + E(\lambda)$ where $|E(\lambda)|\leq \frac{C}{\lambda^{\frac{1}{2}}}$.
\begin{solution}
  Supposing $A$ and $C$ exist, then $A=\lim_{\lambda\to\infty} \lambda^{\frac{1}{4}}F(\lambda)$. To determine the value of $A$, we make the $u$-substitution $u=\lambda^{\frac{1}{4}}x$, which gives
  \begin{equation}\label{eq:u-form-of-F}
    \lambda^{\frac{1}{4}}F(\lambda)= \int_{0}^{\lambda^{\frac{1}{4}}}e^{-10u^{4}+\lambda^{-\frac{1}{2}}u^{6}}du = \int_{0}^{\infty}\chi_{\(0,\lambda^{\frac{1}{4}}\)}e^{-10u^{4}+\lambda^{-\frac{1}{2}}u^{6}}du.
  \end{equation}
  Note that for $0<u<\lambda^{\frac{1}{4}}$, it holds that $\lambda^{-\frac{1}{2}}u^{6} \leq u^{4}$. It follows that
  \begin{equation*}
    \chi_{\(0,\lambda^{\frac{1}{4}}\)}e^{-10u^{4}+\lambda^{-\frac{1}{2}}u^{6}}\leq e^{-9u^{4}}.
  \end{equation*}
  Since the right-hand side is integrable and $\chi_{\(0,\lambda^{\frac{1}{4}}\)}e^{-10u^{4}+\lambda^{-\frac{1}{2}}u^{6}}\to \chi_{(0,\infty)}e^{-10u^{4}}$ pointwise as $\lambda\to\infty$, it follows by the Dominated Convergence Theorem that
  \begin{equation*}
    \lim_{\lambda\to\infty} \lambda^{\frac{1}{4}}F(\lambda) = \int_{0}^{\infty}e^{-10u^{4}}du.
  \end{equation*}
  So let $A:= \int_{0}^{\infty}e^{-10u^{4}}du$. We need to show that there exists some constant $C$ such that
  \begin{equation*}
     \left|\lambda^{\frac{1}{4}}F(\lambda) - A \right| \leq \frac{C}{\lambda^{\frac{1}{4}}}.
   \end{equation*}
In particular, by equation \eqref{eq:u-form-of-F} and the triangle inequality,
   \begin{align*}
     \left|\lambda^{\frac{1}{4}}F(\lambda) - A\right|
     &\leq \underbrace{\left|\int_{0}^{\lambda^{\frac{1}{4}}} e^{-10u^{4}}\left( e^{\lambda^{-\frac{1}{2}}u^{6}}-1 \right)du\right|}_{\text{Call this } g(\lambda)} + \underbrace{\int_{\lambda^{\frac{1}{4}}}^{\infty}e^{-10u^{4}}du}_{\text{Call this }h(\lambda)},
   \end{align*}
   so it will suffice to show that $\lambda^{\frac{1}{4}}g(\lambda)\leq C_{1}$ and $\lambda^{\frac{1}{4}}h(\lambda)\leq C_{2}$ for all $\lambda$.

  To estimate $\lambda^{\frac{1}{4}}g(\lambda)$, we use the inequality $|e^{x}-1|\leq |x|e^{x}$  (which holds for all $x>0$ since $|e^{x}-1|=|\int_{0}^{x}e^{t}dt|\leq xe^{x}$). Using this inequality, we have:
   \begin{align*}
     \lambda^{\frac{1}{4}}g(\lambda)
     &\leq \lambda^{\frac{1}{4}}\int_{0}^{\lambda^{\frac{1}{4}}} e^{-10u^{4}}\lambda^{-\frac{1}{2}}u^{6}e^{\lambda^{-\frac{1}{2}}u^{6}}du\\
     &=\lambda^{-\frac{1}{4}}\int_{0}^{\lambda^{\frac{1}{4}}} u^{6}e^{-10u^{4}+\lambda^{-\frac{1}{2}}u^{6}}du\\
     &\leq \int_{0}^{\lambda^{\frac{1}{4}}} u^{5}e^{-9u^{4}}du &&\text{using }u\leq \lambda^{\frac{1}{4}}\\
     &\leq  C_{1}
   \end{align*}
   where $C_{1} := \int_{0}^{\infty} u^{5}e^{-9u^{4}}du<\infty$.
   
   It remains to estimate $\lambda^{\frac{1}{4}}h(\lambda)$. Using $\lambda^{\frac{1}{4}}\leq u$, we have
   \begin{equation*}
     \lambda^{\frac{1}{4}}h(\lambda)
      = \lambda^{\frac{1}{4}}\int_{\lambda^{\frac{1}{4}}}^{\infty}e^{-10u^{4}}du
     < \int_{\lambda^{\frac{1}{4}}}^{\infty}ue^{-10 u^{4}}du < C_{2}
   \end{equation*}
   where $C_{2} := \int_{0}^{\infty}ue^{-10u^{4}}du<\infty$. This completes the proof.
 \end{solution}

\question (August 2010)
Let $I = [0,1]$ and define for $f\in L^{2}(I)$ the Fourier coefficients as $\hat{f}(k) =\int_{0}^{1}f(t)e^{-2\pi i k t}dt$ for any $k\in \Z$. 


\begin{parts}
\part Let $\mathcal{G}$ be the set of all $L^{2}(I)$ functions with the property that  $|\hat{f}(0)|\leq 1$ and  $|\hat{f}(k)|\leq |k|^{-3/5}$ for any $k\in \Z$, $k\neq 0$. Prove that $\mathcal{G}$ is a compact subset of $L^{2}(I)$.


\begin{solution}

  Let $f_{n}\in \mathcal{G}$. It will suffice to show that there exists a subsequence $f_{n_{j}}$ and an $f\in \mathcal{G}$ such that $f_{n_{j}}\to f$ in $L^{2}(I)$.

  We will apply Cantor's diagonal sequence argument to obtain a subsequence $n_{j}$ such that $\lim_{j\to\infty}\hat{f}_{n_{j}}(k)$ exists for all $k\in \Z$. The details of this argument are as follows:

  
  First, since $\{\hat{f}_{n}(0)\}_{n\in\mathbb{N}}$ is a bounded sequence of real numbers, there exists a subsequence $\{s(n,0)\}_{n\in \mathbb{N}}$ of $\mathbb{N}$ such that $\limn \hat{f}_{s(n,0)}(0)= c_{0}$ for some $c_{0}\in \R$.

  Next, since $|\hat{f}_{s(n,0)}(k)|\leq |k|^{-3/5}$ for any $k\in \Z\backslash \left\{ 0 \right\}$, it follows that  $\{\hat{f}_{s(n,0)}(1)\}_{n\in\mathbb{N}}$ and $\{\hat{f}_{s(n,0)}(-1)\}_{n\in\mathbb{N}}$ are both bounded sequences of real numbers. Therefore there exists a subsequence $\left\{ s(n,1) \right\}_{n\in \mathbb{N}}$ of  $\left\{ s(n,0) \right\}_{n\in \mathbb{N}}$ such that $\limn \hat{f}_{s(n,1)}(1) = c_{1}$ and $\limn \hat{f}_{s(n,1)}(-1) = c_{-1}$ for some $c_{1},c_{-1}\in \R$.
  
  In general, suppose we have chosen the subsequence $s(n,m-1)$. Then by the inequality $|\hat{f}(k)|\leq |k|^{-3/5}$, it follows that both $\{\hat{f}_{s(n,m-1)}(m)\}_{n\in\mathbb{N}}$ and $\{\hat{f}_{s(n,m-1)}(-m)\}_{n\in\mathbb{N}}$ are bounded sequences of real numbers, and therefore we may choose a further subsequence $\{s(n,m)\}_{n\in\mathbb{N}}$ of $\{s(n,m-1)\}_{n\in\mathbb{N}}$ such that 
  $\limn \hat{f}_{s(n,m)}(m) = c_{m}$ and $\limn \hat{f}_{s(n,m)}(-m) = c_{-m}$ for some $c_{m},c_{-m}\in \R$.

  We now have in our hands a nested sequence of subsequences
  \begin{equation*}
    \left\{ s(n,0) \right\}_{n\in\mathbb{N}}\supset  \left\{ s(n,1) \right\}_{n\in\mathbb{N}}\supset \left\{ s(n,2) \right\}_{n\in\mathbb{N}}\supset \cdots
  \end{equation*}
  Now consider the diagonal subsequence $\{s(n,n)\}_{n\in \mathbb{N}}$. By construction,
  \begin{equation}
    \label{eq:1}
    \lim_{n\to\infty} \hat{f}_{s(n,n)}(k) =c_{k}\in \R
  \end{equation}
  for all $k\in \Z$.

  Let $f(t)=\sum_{k\in\Z} c_{k}e^{2\pi i k t}$. By Parseval's identity and the inequality $|\hat{f}(k)|\leq |k|^{-3/5}$, we have
  \begin{equation*}
    \norm{f}^{2}_{L^{2}(I)} =  \sum_{k\in\Z}|\hat{f}(k)|^{2} \leq  \left( 1 + 2\sum_{k\geq 1}|k|^{-6/5} \right)<\infty
  \end{equation*}
  Therefore $f$ is well defined and in $L^{2}(I)$.
  
  It remains to show that $f_{s(n,n)}\to f$ in $L^{2}(I)$. To see this, observe that by Parseval's identity,
  \begin{align*}
    \norm{f_{s(n,n)}-f}_{L^{2}}^{2}
    &= \sum_{k\in \Z} \left| \hat{f}_{s(n,n)}(k)-c_{k} \right|^{2}\\
    &= \sum_{|k|\leq N} \left| \hat{f}_{s(n,n)}(k)-c_{k} \right|^{2} + \sum_{|k|> N} \left| \hat{f}_{s(n,n)}(k)-c_{k} \right|^{2}\\
    &\leq \sum_{|k|\leq N} \left| \hat{f}_{s(n,n)}(k)-c_{k} \right|^{2} + \sum_{|k|> N} \left| K \right|^{-6/5}
  \end{align*}
  Therefore
  \begin{align*}
    \limsup_{n\to\infty}  \norm{f_{s(n,n)}-f}_{L^{2}}^{2}
    &\leq \sum_{|k|> N} \left| K \right|^{-6/5} \to 0 \text{ as }N\to\infty
  \end{align*}
  Therefore $f_{s(n,n)}\to f$ in $L^{2}(I)$.
\end{solution}

\part Let $\mathcal{E}$ be the set of all $L^{2}(I)$ functions with the property that $\sum_{k}|\hat{f}(k)|^{5/3}\leq 2016^{-2016}$. Is $\mathcal{E}$ a compact subset of $L^{2}(I)$?

\begin{solution}
  $\mathcal{E}$ is not compact. To see this, let $f_{n}(t)= e^{2\pi i n t}$. Then $\hat{f_{n}}(k) = \delta(k-n)$ where $\delta$ is the Kronecker-delta function. If $\epsilon_{0} \in (0,2016^{-2016})$, then $\left\{ \epsilon_{0}f_{n} \right\}_{n=1}^{\infty}\subset \mathcal{E}$ but it is not compact because it contains no convergent subsequence.
\end{solution}
\end{parts}

\question (August 2011) Let $\ell^{2}(\mathbb{N})$ denote the Hilbert space of square summable sequences with inner product $(x,y)= \sum_{n=1}^{\infty}x_{n}y_{n}$, where $x=(x_{1},x_{2},\cdots)$ and $y=(y_{1},y_{2},\cdots)$.
\begin{parts}
\part What are the necessary and sufficient conditions on $\lambda_n>0$ for the set
\begin{equation*}
  S = \left\{ (x_{1},x_{2}\cdots) \in \ell^{2}(\mathbb{N}): |x_{n}| \leq \lambda_{n}, \forall n\right\}
\end{equation*}
to be compact in $\ell^{2}(\mathbb{N})$? 
\begin{solution}
    For any sequence $\{ x(1), x(2), \dots \}$ in $S$, and any fixed $i$, the sequence $\{ x(1)_i, x(2)_i, \dots \}$ is bounded, and thus has a convergent sub-sequence. Assuming that
    %
    \[ \lim_{N \to \infty} \sum_{i = N}^\infty \lambda_i^2 = 0, \]
    %
    we will use diagonalization to construct a convergent subsequence. This is necessary, because the sequence $\{ (\lambda_1,0, \dots), (\lambda_1,\lambda_2,0,\dots), (\lambda_1,\lambda_2,\lambda_3, 0, \dots), \dots \}$ only has a convergent subsequence if this property was true.
    
    We will define a family of elements $x(i,j) \in l^2(\mathbf{N})$ for $0 \leq i < \infty$ and $1 \leq j < \infty$, such that for $0 < k \leq i$, $x(i,j)_k$ converges as $j \to \infty$. Begin by setting $x(0,i) = x(i)$. Given $x(i_0,j)$, the sequence $x(i_0,j)_{i_0 + 1}$ is bounded in $j$, so we can find a sequence $y(j)$ such that $y(j)_{i_0 + 1}$ converges. Let $x_{i_0+1,j}$ be this convergent sub-sequence. Now define $y(k) = x(k,k)$. For each $i$, the sequence $\{ y(k) : k > i \}$ is a subsequence of $\{ x(i,j) \}$, and so $y(k)_i$ converges as $i \to \infty$ for each $i$. Thus for any fixed $K$,
    %
    \[ \limsup_{N \to \infty} \sup_{M > N} \sum_{j \leq K} |y(N)_j - y(M)_j|^2 = 0. \]
    %
    But
    %
    \[ \limsup_{N \to \infty} \sup_{M > N} \sum_{j > K} |y(N)_j - y(M)_j|^2 \leq 4 \sum_{j > K} \lambda_j^2. \]
    %
    Thus for any $K$,
    %
    \[ \limsup_{N \to \infty} \sum_{M > N} \| y(N) - y(M) \|_2 \leq 2 \left( \sum_{j > K} \lambda_j^2 \right)^{1/2} \]
    %
    Taking $K \to \infty$ gives
    %
    \[ \limsup_{N \to \infty} \sum_{M > N} \| y(N) - y(M) \|_2 = 0, \]
    %
    and so $\{ y(k) \}$ is a Cauchy sequence in $l^2(\mathbf{N})$, and is thus convergent.
\end{solution}

\part What are the necessary and sufficient conditions on $\mu_{n}>0$ for the set
\begin{equation*}
  \left\{ (x_{1},x_{2}\cdots) \in \ell^{2}(\mathbb{N}): \sum_{n}\frac{|x_{n}|^{2}}{\mu_{n}^{2}}\leq 1\right\}
\end{equation*}
to be compact in $\ell^{2}(\mathbb{N})$?
\begin{solution}
The necessary and sufficient condition is that $\mu_n\to 0$ as $n\to \infty$.

\vt
\textit{Proof of Necessity:} Suppose that $\mu_n\not\to 0$. Then there exists an $\epsilon>0$ and a subsequence $\{\mu_{n_j}\}$ with $\mu_{n_j}\geq \epsilon$.
Let $x^{(j)} = (0,\cdots,\mu_{n_j},0,\cdots)$. It is easy to check that this sequence has no convergent subsequence.

\vt
\textit{Proof of Sufficiency:} Suppose $\mu_n\to 0$. 


Let $\{x^{(n)}\}$ be a seqeunce with $x^{(n)}\in \left\{ (x_{1},x_{2}\cdots) \in \ell^{2}(\mathbb{N}): \sum_{n}\frac{|x_{n}|^{2}}{\mu_{n}^{2}}\leq 1\right\}$.

By a Cantor diagonalization argument, there exists a subsequence $\{x^{(n_j)}\}_j$ such that $x^{n_j}_k\to y_k\in \R$ for each $k$ as $j\to\infty$. 

We then check that that $y = (y_1,y_2,\cdots) \in \ell^2$ and that $x^{n_j}\to y$ in $\ell^2$.

\end{solution}
\end{parts}


\question Let $f:\R\to\R$ be a convex function, let $E=\left\{ x\in \R : f \text{ is not differentiable at }x\right\}$. Show that $E$ is at most countable.


\begin{solution}
For each $x_{0}\in \R$, define $f_{-}'(x_{0}) := \lim_{x\to x_{0}^{-}} \frac{f(x)-f(x_{0})}{x-x_{0}}$ and $f_{+}'(x_{0}) := \lim_{x\to x_{0}^{+}} \frac{f(x)-f(x_{0})}{x-x_{0}}$.

\vt
\textit{Claim 1:} Both $f_{-}'(x_{0})$ and $f_{+}'(x_{0})$ exist and are finite for all $x_{0}\in \R$. 


To prove this, we will demonstrate that $f_{-}'(x_{0})$ exists and is finite, as the case for $f_{+}'(x_{0})$ is similar. Recall the chordal slope property of convex functions: if $f$ is convex on $\R$, then for any $x_{1}<x_{2}<x_{3}$, the following inequality holds (draw a picture of this)
\begin{equation}\label{eq:chord-inequality}
  \frac{f(x_{2})-f(x_{1})}{x_{2}-x_{1}}\leq \frac{f(x_{3})-f(x_{1})}{x_{3}-x_{1}}\leq \frac{f(x_{3})-f(x_{2})}{x_{3}-x_{2}}.
\end{equation}

The proof of \eqref{eq:chord-inequality} requires only the definition of convexity and a little bit of algebra.  Suppose $x_{1}<x_{2}<x_{3}$. Recall $f$ convex means that for all $a,b\in \R$ and all $0\leq \lambda\leq 1$, we have
  \begin{equation*}
    f(\lambda x + (1-\lambda)y)\leq \lambda f(x) + (1-\lambda)f(y).
  \end{equation*}
  Taking $x=x_{1}, y=x_{3}$ and $\lambda=\frac{x_{3}-x_{2}}{x_{3}-x_{1}}$ (so that $x_{2}= \lambda x_{1} + (1-\lambda)x_{3}$) in the above equation, we obtain 
\begin{equation*}
  \frac{f(x_{2})-f(x_{1})}{x_{2}-x_{1}}\leq \frac{f(x_{3})-f(x_{2})}{x_{3}-x_{2}}.
\end{equation*}
Then, with a little more algebra, we can rewrite this inequalilty as the equivalent forms
\begin{equation*}
  \frac{f(x_{2})-f(x_{1})}{x_{2}-x_{1}}\leq \frac{f(x_{3})-f(x_{1})}{x_{3}-x_{1}} \quad \text{and}\quad \frac{f(x_{1})-f(x_{3})}{x_{1}-x_{3}}\leq \frac{f(x_{2})-f(x_{3})}{x_{2}-x_{3}}.
\end{equation*}
This proves \eqref{eq:chord-inequality}

From \eqref{eq:chord-inequality}, we can deduce the following:
\begin{enumerate}
\item For each fixed $x_{0}\in \R$, the function $x\mapsto \frac{f(x)-f(x_{0})}{x-x_{0}}$ is increasing on $(-\infty,x_{0})$.
\item The family $\left\{   \frac{f(x)-f(x_{0})}{x-x_{0}}:  x\in (-\infty,x_{0})\right\}$ is bounded above by $\frac{f(x_{0}+1)-f(x_{0})}{(x_{0}+1)-x_{0}} = f(x_{0}+1)-f(x_{0})<\infty$.
\end{enumerate}
These two facts together imply that the limit
\begin{equation*}
  f_{-}'(x_{0}):=\lim_{x\to x_{0}^{-}}\frac{f(x)-f(x_{0})}{x-x_{0}}
\end{equation*}
is both increasing and bounded above, and therefore exists as a real number. The case for $f_{+}'(x_{0})$ is similar. This proves Claim 1.



By Claim 1, it follows that $f$ is not differentiable at a point $x\in \R$ if and only if $f'_{+}(x)\neq f'_{-}(x)$. Let $E=\left\{ x\in \R : f'_{-}(x)\neq f'_{+}(x) \right\}$. We need to show that $E$ is at most countable.


To see this, we first make the following observations, all of which follow from \eqref{eq:chord-inequality}:
\begin{enumerate}[(a)]
\item \label{item:3} $f'_{+}$ and $f'_{-}$ are both increasing functions
\item \label{item:5} $f'_{-}(x)\leq f'_{+}(x)$ for all $x\in\R$
\item \label{item:4} $f_{+}'(a) \leq \frac{f(b)-f(a)}{b-a}\leq f'_{-}(b)$ if $a<b$
\end{enumerate}

By \ref{item:3}, $f_{+}'$ and $f'_{-}$ are continuous at all but countably many points. That is, the set  $$D:=\left\{ x\in \R: f_{+}'\text{ is not continuous at }x \right\}\cup \left\{ x\in \R: f_{-}'\text{ is not continuous at }x \right\}$$ is countable. We will show that $E\subset D$, which will complete the proof.

Suppose $x\notin D$. We need to show that $x\notin E$. By \ref{item:5}, $E=\left\{ x\in \R : f'_{-}(x)< f'_{+}(x) \right\}$, so it will suffice to show that $f'_{-}(x)\geq f_{+}'(x)$.

Let $x_{n}$ be a sequence such that $x_{n}>x$ and $x_{n}\to x$. Since $x\notin D$,
\begin{equation*}
  f'_{-}(x)=\limn f'_{-}(x_{n})\geq f'_{+}(x)
\end{equation*}
where the final inequality is justified by \ref{item:4} since $x_{n}>x$.

(This proof was adapted from Royden and Fitzpatrick's \textit{Real Analysis} 4th ed.)
\end{solution}

\question (August 2015) Identify all $x\in \R$ such that $\lim_{n\to\infty} \sin(nx)$ exists.

\begin{solution} \bnote{(need to rewrite this for clarity)} Define $f(x)=\sin(2\pi x)$. It will suffice to characterize the $\alpha$ for which $\limn f(n\alpha)$ converges, since $\limn f(n\alpha)$ exists if and only if $\limn \sin(n2\pi \alpha)$ exists. Observe that $f$ is periodic: if $k\in \Z$ then $f(x)=\sin(2\pi x) = \sin(2\pi x +2\pi k) =f(x+k)$. By periodicity it suffices to consider $\alpha\in [0,1)$, since $\limn f(n\alpha)$ converges if and only if $\limn f(n(\alpha+k))$ converges for all $k\in \Z$. 


  \vt
  \textit{Case 1.} Suppose $\alpha \notin \Q$. Let $\xi_{n}:= n\alpha - \lfloor n\alpha \rfloor$. Then $(\xi_{n})$ is an equidistributed sequence on $[0,1)$ and hence is dense. Therefore we may choose a subseqeuence $n_{j}$ of positive integers such that $\xi_{n_{j}}\to \frac{3}{4}$ as $j\to \infty$ and another subsequence $n_{k}$ such that $\xi_{n_{k}}\to \frac{1}{4}$ as $k\to \infty$.
  
  Since $f$ is 1-periodic and continuous, we have $f(n_{j}\alpha)= f(\xi_{n_{j}}) \to f(1/4)$ as $j\to\infty$. Therefore
  \begin{equation*}
    \limsup_{n\to\infty} f(n\alpha)  \geq \limsup_{j\to \infty}f(n_{j}\alpha) = \limsup_{j\to\infty} f(\xi_{n_{j}})= f(1/4)=\sin(\pi/2)=1.
  \end{equation*}
  But by similar reasonsing, we also have
  \begin{equation*}
    \liminf_{n\to\infty} f(n\alpha) \leq \limsup_{k\to\infty}f(n_{k}\alpha) = \limsup_{k\to\infty} f(\xi_{n_{k}})=f(3/4)=\sin(3\pi/2)=-1.
  \end{equation*}
  Therefore $f(n\alpha)$ does not converge as $n\to\infty$. Therefore $\sin(2\pi n \alpha)$ does not converge for any $\alpha\notin \Q$
  
  \vt
  \textit{Case 2.} Suppose $\alpha\in\Q$. Write $\alpha = p/q$ where $p,q$ are integers with $\gcd(p,q)=1$. Let $x = 2\pi p/q$. Then the sequence $\xi_{n}:= n\alpha-\lfloor n \alpha \rfloor$ is periodic with $q$ distinct values, one of which is zero. Indeed,
  \begin{equation*}
    \xi_{q}=q \frac{p}{q} - \left\lfloor q \frac{p}{q} \right\rfloor = p-p = 0
  \end{equation*}
  and
  \begin{equation*}
    \xi_{q+1}= (q+1)\frac{p}{q} - \left\lfloor \frac{(q+1)p}{q} \right\rfloor = \frac{p}{q} - \left\lfloor \frac{p}{q}\right\rfloor = \xi_{1}.
  \end{equation*}
  Since $f(n\alpha) = f(\xi_{n})$, it follows that the seuence $\{f(n\alpha)\}_{n=1}^{\infty}$ is periodic and takes up to $q$ distinct values. Therefore, in order for $\limn f(n\alpha)$ to converge, we must have $f(\xi_{1})=f(\xi_{2})=\ldots=f(\xi_{q})=f(0)=0$. By periodicity of $f$, this is equivalent to
  \begin{equation*}
    f\(\frac{p}{q}\)= f\(\frac{2p}{q}\)=\ldots=f\left(\frac{(q-1)p}{q}\right)=f(p)
  \end{equation*}
  and
  \begin{equation*}
    f(p) = \sin(2\pi p)=0.
  \end{equation*}
  Therefore $\sin(2\pi p/q)=0$. This implies that $q=1$ or $q=2$. So either $\alpha =0$ or $1/2$ (mod 1). That is, $x=k\pi$ for $k\in \Z$.
\end{solution}


\newpage
\section{Day 15: January 2021 Final Qualifying Exam}

\question (1) Determine if
%
\[ \sum_{k = 1}^\infty \frac{\cos(\sqrt{k})}{k} \]
%
converges.
\begin{solution}
    Since the sum of $1/k$ diverges, this convergence could only possibly happen from the oscillation present in the $\cos(\sqrt{k})$ causes enough cancellation. Thus trying to control the oscillation is key to understanding this series. In particular, let us try and understand how often $\cos(\sqrt{k})$ changes sign. We can use conjugation, an often useful trick to understand square roots, to write
    %
    \begin{align*}
        \sqrt{k+n} - \sqrt{k} &= (\sqrt{k+n} - \sqrt{k}) \left( \frac{\sqrt{k+n} + \sqrt{k}}{\sqrt{k+n} + \sqrt{k}} \right)\\
        &= \frac{n}{\sqrt{k+n} + \sqrt{k}}\\
        &= \frac{n}{2\sqrt{k} + O(n/\sqrt{k})}\\
        &= \frac{n}{2\sqrt{k}} + O \left( \frac{n^2}{k^{3/2}} \right).
    \end{align*}
    %
    In particular,
    %
    \[ \sqrt{k + 2 \pi \sqrt{k}} + \sqrt{k} = \pi + O(1/\sqrt{k}). \]
    %
    Thus for each $n$, the sign of $\cos(\sqrt{k})$ stays roughly the same for $k = n \pm \sqrt{n}$. More precisely, let $\{ m_1, m_2, \dots \}$ be an increasing family of integers with $m_1 = 1$, and such that for each $i$, and $k \in \{ m_i, m_i + 1, \dots, m_{i+1} - 1 \}$ , $\cos(\sqrt{k})$ has the same sign. Then $m_{i+1} - m_i \sim \sqrt{m_i}$. For more than half of the values in $\{ m_i, \dots, m_{i+1} - 1 \}$, $|\cos(\sqrt{k})| \geq 1/2$, and it follows that
    %
    \begin{align*}
        \left| \sum_{k = m_i}^{m_{i+1} - 1} \frac{\cos(\sqrt{k})}{k} \right| \sim \frac{1}{\sqrt{m_i}}.
    \end{align*}
    %
    Roughly speaking, an application of Leibnitz's alternating series test then implies that this series converges.
\end{solution}

\question (2) Let $E \subset \RR$ be a Lebesgue measurable set with $|E| < \infty$. Prove that the function $f: \RR \to \RR$ defined by $f(r) = |E \cap (E + r)|$ is continuous.
\begin{solution}
    Write $g = \mathbf{I}_E$. Then $g$ lies in $L^1$ and $L^\infty$, and $f(r) = (g * g)(-r)$. But Young's convolution inequality implies that $g * g$ is continuous, so that $f$ is continuous.
\end{solution}

\question (3) For a Lebssgue measurable subset $E$ of $\R$, denote $\textbf{1}_E$ the indicator function of $E$ (i.e. $\textbf{1}_E(x)=1$ for $x\in E$ and $\textbf{1}_E(x) = 0$ for $x\in E^c$).

Let $\{E_n: n\in \mathbb{N}\}$ be a family of Lebesgue measurable subsets of $\R$ with finite measure and let $f$ be a measurable function such that \begin{equation*}
\limn \int_{\R} | f(x)-\textbf{1}_{E_n}(x)| dx = 0.
\end{equation*}
Prove that $f$ is the indicator function of a measurable set.

\begin{solution}
For each $\epsilon>0$, 
\begin{equation*}
  \epsilon \mu \left\{ x: |f(x)-\mathbf{1}_{E_{n}}(x)| >\epsilon \right\}
  <  \int_{\left[|f-\mathbf{1}_{E_{n}}| >\epsilon \right]} |f(x)-\mathbf{1}_{E_{n}}(x)|dx
  \leq \int_{\R} |f(x)-\mathbf{1}_{E_{n}}(x)|dx \to 0
\end{equation*}
as $n\to \infty$.
Therefore $\mathbf{1}_{E_{n}}\to f$ in measure. By definition of convergence in measure, we may choose a subsequence $n_{k}$ such that
\begin{equation*}
  \mu \left\{ x: |f(x)-\mathbf{1}_{E_{n_{k}}}(x)|>\epsilon \right\} \leq 2^{-k}.
\end{equation*}
Therefore
\begin{equation*}
  \sum_{k\geq 1}\mu \left\{ x: |f(x)-\mathbf{1}_{E_{n_{k}}}(x)|>\epsilon \right\}<\infty.
\end{equation*}
Therefore by the Borel-Cantelli lemma,
\begin{equation*}
  \mu \left\{ x: |f(x)-\mathbf{1}_{E_{n_{k}}}(x)|>\epsilon \text{ for infinitely many }k \right\}=0.
\end{equation*}
In other words, $\lim_{k\to \infty} \mathbf{1}_{E_{n_{k}}}(x) = f(x)$ for a.e. $x\in \R$. Therefore $f$ is equal to zero or one almost everywhere, and as the a.e. limit of measureable functions, $f$ is also measurable. Therefore $f$ is the indicator function of a measurable set.

\end{solution}


\question (4) Let $f$ be a $C^1$ function on $[0,\infty)$. Suppose that
%
\[ \int_0^\infty t |f'(t)|^2\; dt < \infty \]
%
and
%
\[ \lim_{T \to \infty} \frac{1}{T} \int_0^T f(t)\; dt = L. \]
%
Show that $f(t) \to L$ as $t \to \infty$.
\begin{solution}
    To relate $f$ and $f'$, we apply the fundamental theorem of calculus. Suppose that
    %
    \[ \int_R^\infty t |f'(t)|^2\; dt \leq \varepsilon. \]
    %
    Then if $S = R e^{1/\varepsilon^{1/2}}$, then for $s \in [R,S]$,
    %
    \[ |f(s) - f(R)| = \left| \int_R^s f'(t)\; dt \right| \leq \left( \int_R^s t |f'(t)|^2\; dt \right)^{1/2} \left( \int_R^s 1/t\; dt \right)^{1/2} \leq \varepsilon^{1/2} \log(s/R)^{1/2} \leq \varepsilon^{1/4}. \]
    %
    If $R$ is suitably large, then
    %
    \[ \left| \frac{1}{R} \int_0^R f(t)\; dt \right| \leq 2L. \]
    %
    Thus
    %
    \[ \left| \frac{1}{R e^{1/\varepsilon^{1/2}}} \int_0^R f(t)\; dt \right| \leq 2L e^{-1/\varepsilon^{1/2}}. \]
    %
    Next,
    %
    \begin{align*}
        \frac{1}{R e^{1/\varepsilon^{1/2}}} \int_R^{Re^{1/\varepsilon^{1/2}}} f(t)\; dt &= \frac{1}{R e^{1/\varepsilon^{1/2}}} \int_R^{Re^{1/\varepsilon^{1/2}}} f(R) + [f(t) - f(R)]\; dt\\
        &= \left( 1 - e^{-1/\varepsilon^{1/2}} \right) f(R) + \int_R^{R e^{1/\varepsilon^{1/2}}} [f(t) - f(R)]\; dt.
    \end{align*}
    %
    Again, for any $\delta > 0$, if $R$ is suitably large, then
    %
    \[ \left| \frac{1}{R e^{1/\varepsilon^{1/2}}} \int_0^{R e^{1/\varepsilon^{1/2}}} f(t)\; dt - L \right| \leq \delta \]
    %
    Combining all these inequalities yields that
    %
    \begin{align*}
        |L - f(R)| &= \left| \frac{1}{R e^{1/\varepsilon^{1/2}}} \int_0^{R e^{1/\varepsilon^{1/2}}} f(t)\; dt - f(R) \right| + \delta\\
        &= \left| \frac{1}{R e^{1/\varepsilon^{1/2}}} \int_R^{R e^{1/\varepsilon^{1/2}}} f(t)\; dt - f(R) \right| + \delta + 2Le^{-1/\varepsilon^{1/2}}\\
        &= \left| \frac{1}{R e^{1/\varepsilon^{1/2}}} \int_R^{R e^{1/\varepsilon^{1/2}}} [f(t) - f(R)]\; dt - e^{-1/\varepsilon^{1/2}} f(R) \right| + \delta + 2Le^{-1/\varepsilon^{1/2}}\\
        &\leq e^{-1/\varepsilon^{1/2}} |f(R)| + \delta + 2L e^{-1/\varepsilon^{1/2}} + \varepsilon^{1/4}.
    \end{align*}
    %
    The fact that
    %
    \[ |f(R)| \leq 2 \left| \frac{1}{R e^{1/\varepsilon^{1/2}}} \int_R^{Re^{1/\varepsilon^{1/2}}} f(t)\; dt \right| + 2 \left| \int_R^{R e^{1/\varepsilon^{1/2}}} [f(t) - f(R)]\; dt \right| \leq 2L + 2 \varepsilon^{1/4} \]
    %
    shows $f$ is bounded, which is sufficient to complete the proof.
\end{solution}


\begin{solution}
(Due to Anuk D.) Integration by parts with $u=f(t)$, $dv=1$ gives
\begin{equation*}
  \frac{1}{T}\int_{0}^{T}f(t)dt = f(T) - \frac{1}{T}\int_{0}^{T}tf'(t)dt.
\end{equation*}
Therefore it suffices to show that $\frac{1}{T}\int_{0}^{T}tf'(t)dt$ converges as $T\to \infty$. Indeed, by the Cauchy Schwarz inequality,
\begin{align*}
  \left|\frac{1}{T}\int_{0}^{T}tf'(t)dt\right|
  &= \left|\frac{1}{T}\int_{0}^{\sqrt{T}}\sqrt{t}\cdot\sqrt{t}f'(t)dt + \frac{1}{T}\int_{\sqrt{T}}^{T}\sqrt{t}\cdot \sqrt{t}f'(t)dt\right|\\
  & \leq \frac{1}{T}\left(\int_{0}^{\sqrt{T}}t dt \right)^{\frac{1}{2}}\left( \int_{0}^{\sqrt{T}}t |f'(t)|^{2}dt \right)^{\frac{1}{2}}+ \frac{1}{T}\left( \int_{\sqrt{T}}^{T}tdt \right)^{\frac{1}{2}}\left( \int_{\sqrt{T}}^{T}t|f'(t)|^{2}dt \right)^{\frac{1}{2}}\\
  &\leq \frac{1}{2 \sqrt{T}} \left(\int_{0}^{\infty}t|f'(t)|^{2} dt \right)^{\frac{1}{2}} + \frac{1}{T}\left( \frac{T^{2}-T}{2} \right)^{1/2}\left(\int_{\sqrt{T}}^{\infty}t|f'(t)|^{2}dt \right)^{\frac{1}{2}}\\
  &\leq \frac{C}{2 \sqrt{T}}  +\left(\int_{\sqrt{T}}^{\infty} t|f'(t)|^{2}dt \right)^{\frac{1}{2}} \to 0 \text{ as }T\to 0
\end{align*}

\end{solution}
\question (5) Let $K$ be a continuous function on $[0,1]\times[0,1]$ satisfying $|K|<1$. Suppose that $g$ is a continuous function on $[0,1]$. Show that there exists a unique continuous function $f$ on $[0,1]$ such that 
\begin{equation*}
f(x) = g(x) + \int_0^1 f(y) K(x,y)dy.
\end{equation*}
\begin{solution}
Since $(x,y)\mapsto |K(x,y)|$ is a continuous function, it achieves its maximum on the compact set $[0,1]\times[0,1]$. In particular, since $|K(x,y)|<1$ for all $0\leq x,y\leq 1$, it follows that $M:= \max_{0\leq x,y\leq 1} |K(x,y)| <1$. Define an operator $T: C[0,1]\to C[0,1]$ by
\begin{equation*}
Tf(x) = g(x) + \int_0^1 K(x,y)f(y)dy
\end{equation*}
for each $f\in C[0,1]$. Letting $\norm{\cdot}$ denote the uniform norm, it follows by the triangle inequality that
\begin{equation*}
\norm{Tf_1-Tf_2} \leq \int_0^1 M \norm{f_1-f_2}_{\infty} dx  = M\norm{f_1-f_2}.
\end{equation*}
Since $M<1$, therefore $T$ is a contraction on $C[0,1]$. Since $C[0,1]$ is a complete metric space (under the metric induced by the uniform norm), it follows by the Contraction Mapping Theorem that there exists a unique function $f_0\in C[0,1]$ such that $Tf_0 = f_0$.
\end{solution}


\question (6) Let $f: \R\to\R$ be a compactly supported function that satisfies the Holder condition with exponent $\beta\in (0,1)$, i.e., there exists a constant $A<\infty$ such that $\forall x,y\in \R: |f(x)-f(y)|\leq A|x-y|^{\beta}$. Consider the function $g$ defined by
\begin{equation*}
g(x) = \int_{-\infty}^{\infty} \frac{f(y)}{|x-y|^{\alpha}} dy
\end{equation*}
where $\alpha \in (0,\beta).$
\begin{parts}
\part Prove that $g$ is a continuous function at $0$.
\begin{solution}
We will show that $|g(x)-g(0)|\to 0$ as $|x|\to 0$. Without loss of generality, we may assume that $|x|\leq 1$. Performing the $u$-substitution $u=y-x$, we may write
\begin{equation*}
g(x) = \int_{-\infty}^{\infty} \frac{f(x+y)}{|y|^{\alpha}} dy.
\end{equation*}
Therefore, taking $k>0$ sufficiently large that supp$(f)\subseteq [-k,k]$, we have
\begin{align*}
|g(x)-g(0)| 
&= \left|\int_{-\infty}^{\infty} \frac{f(x+y)-f(y)}{|y|^{\alpha}} dy\right|\\
&= \left|\int_{-(k+1)}^{k+1} \frac{f(x+y)-f(y)}{|y|^{\alpha}} dy\right| &&\text{since }|x|\leq 1\\
& \leq \int_{-(k+1)}^{k+1} \frac{|f(x+y)-f(y)|}{|y|^{\alpha}} dy\\
&\leq 2A|x|^{\beta} \int_0^{k+1} y^{-\alpha}dy \\
& = 2A |x|^{\beta} \frac{(k+1)^{1-\alpha}}{1-\alpha} \to 0 \text{ as } |x|\to0
\end{align*}
where we have used the fact that $\alpha<1$ so that the integral is finite.
\end{solution}
\part Prove that $g$ is differentiable at $0$. (Hint: Try the dominated convergence theorem).
\begin{solution}

So the idea is to use the so called generalized dominated convergence theorem, whose proof is exactly the same as the usual dominant convergence theorem. And the statement is the following:

\textit{Let $\{h_n\}$ be a family of $L^1$ function which converge almost everywhere to a $L^1$ function $h$, let $g_n$ be another family of $L^1$ functions such that $g_n\to g$ a.e., $|h_n|\le g_n$ for each $n$ and $|h|\le g$,  Suppose now we have $\lim \int g_n=\int g$, then $\lim\int h_n=\int h$.}

Now come back to our problem. First attempt would be to use the standard test, which means we just naively take the derivative of the inside function and then check integrability. We immediately encounter a problem because we don't have the desired integrability condition. In fact, we have $f(y)\cdot sgn(x-y)|x-y|^{-\alpha-1}$, which is not integrable.

So our second attempt would be to use the Holder condition to balance this singularity. Assume that supp$(f)\subset [-K,K]$ for some $K>1$. Let $(x_n)$ be a sequence of real numbers converging to zero. Without loss of generality, we may assume $|x_n|\leq1$ for all $n$. By the Mean Value Theorem, for each $n$ there exists some $\xi_n$ with $0\le |\xi_n|\le |x_n|$ such that $$\frac{1}{|y-x_n|^\alpha}-\frac{1}{|y|^\alpha}=\alpha\cdot sgn(y-\xi_n)\cdot |y-\xi_n|^{-\alpha-1}\cdot |x_n|.$$
Therefore
\begin{align}
\frac{g(x_n)-g(0)}{x_n} &=\int_{-K}^K \frac{f(y)-f(\xi_n)}{|y-x_n|^\alpha\cdot x_n}-\frac{f(y)-f(\xi_n)}{|y|^\alpha\cdot x_n}dy+E_n \nonumber\\
&=\int_{-K}^K \frac{f(y)-f(\xi_n)}{x_n}\cdot \(\frac{1}{|y-x_n|^{\alpha}}-\frac{1}{|y|^\alpha}\)dy+E_n \nonumber\\
&=\int_{-K}^K (f(y)-f(\xi_n))\cdot \alpha\cdot sgn(y-\xi_n)\cdot |y-\xi_n|^{-\alpha-1}dy+E_n \label{first-deriv-form}
\end{align}
where 
\begin{equation*}
E_{n}=\int_{-K}^K \frac{f(\xi_n)}{x_n}\(\frac{1}{|y-x_n|^\alpha}-\frac{1}{|y|^\alpha}\)dy.
\end{equation*}
In particular, we have 
\begin{align*}
|E_{n}|&=\left|\int_{-K-x_n}^{-K}\frac{f(\xi_n)}{x_n}\frac{1}{|y|^\alpha}dt-\int_{K-x_n}^{K}\frac{f(\xi_n)}{x_n}\frac{1}{|y|^\alpha}dy\right| = \left|\frac{f(\xi_n)}{x_n}\int_{K-x_n}^{K+x_n} \frac{1}{|y|^{\alpha}} dy\right| \leq \frac{C}{K^{\alpha}}.
\end{align*}
for $C>0$ sufficiently large. Therefore by the above estimate for $|E_n|$ and equation \eqref{first-deriv-form} we have:
\begin{equation}\label{deriv-equation}
\left|\frac{g(x_n)-g(0)}{x_n} - \int_{\R} h_n(y)dy\right| \leq \frac{C}{K^\alpha}
\end{equation}
where
$$h_n(y)=\chi_{[-K,K]}\cdot (f(y)-f(\xi_n))\cdot \alpha\cdot sgn(y-\xi_n)\cdot |y-\xi_n|^{-\alpha-1}.$$

Let $$h(y):= \lim_{n\to\infty} h_n(y) = \chi_{[-K,K]}\cdot(f(y)-f(0))\cdot \alpha\cdot sgn(y)\cdot |y|^{-\alpha-1}.$$

We wish to show that $\int_{\R}h_n(y)dy \to  \int_{\R}h(y)dt$ as $n\to\infty$. We now justify this by applying the generalized dominant convergence theorem. Define 
$$g_n=C\cdot |y-\xi_n|^{\beta-\alpha-1}\cdot \chi_{[-K,K]}$$ where $C$ is some large constant. Similarly, define 
$$g=C\cdot |y|^{\beta-\alpha-1}\cdot \chi_{[-K,K]}.$$ 
One easily sees that $|h_n|\le g_n$ and $|h|\le g$ by applying the Holder condition. Moreover, each $g_n$ is in $L^1$. Since $\xi_n\to 0$, we have $\lim \int g_n\to \int g$ and $g_n\to g$ a.e. Finally, invoke the generalized dominated convergence theorem, and it follows that $\limn \int h_n = \int h$, so that by equation \eqref{deriv-equation},
\begin{equation*}\limsup_{n\to\infty} \left|\frac{g(x_n)-g(0)}{x_n} - \int_{\R} h(y)dy\right| \leq \frac{C}{K^\alpha}\end{equation*}

Taking $K\to \infty$, it follows that
\begin{equation*}
\limn \frac{g(x_n)-g(0)}{x_n} = \int_{\R} (f(y)-f(0))\cdot \alpha\cdot sgn(y)\cdot |y|^{-\alpha-1}dy.
\end{equation*}
Since $(x_n)$ was an arbitrary sequence converging to zero, it follows that $$g'(0) = \int_{\R} (f(y)-f(0))\cdot \alpha\cdot sgn(y)\cdot |y|^{-\alpha-1}dy$$
which is finite.
\end{solution}
\end{parts}


\question (7R) Let $f_n \to f$ weakly in $L^2(\R)$ and $\norm{f_n}_2 \to \norm{f}_2$ as $n\to\infty$. Show that $f_n\to f$ strongly in $L^2(\R)$.

\begin{solution}
Since $f_n\to f$ weakly, therefore $\langle f_n, g \rangle \to \langle f, g \rangle$ for any $g\in L^2$. Since $\norm{f}_2 \leq \sup_{n}\norm{f_n}_2 <\infty$, we have $f\in L^2$. Therefore taking $g=f$, we have $\langle f_n,f\rangle \to \norm{f}_2^2$, so that
\begin{equation*}
\norm{f_n-f}_2^2 = \langle f_n-f,f_n-f\rangle = \norm{f_n}_2^2 -2 \langle f_n,f\rangle + \norm{f}^2_2 \to 0
\end{equation*}
as $n\to \infty$.
\end{solution}
\question (8R) 
\begin{parts}
\part Let $H_1$ and $H_2$ be Hilbert spaces, and let $T:H_1\to H_2$ be a continuous linear operator. Give a precise definition of the adjoint operator $T^*$.
\begin{solution}
    The adjoint operator $T^*$ is a bounded operator from $H_2$ to $H_1$. For each $x \in H_2$, $T^*x$ is the unique element of $H_1$ such that for any $y \in H_1$, $\langle T^* x, y \rangle = \langle x, Ty \rangle$.
\end{solution}

\part Let $(a,b)\subset \R$ be a (possibly infinite) open interval. If $f\in L^2(a,b)$, explain what it means that the distributional derivative $f'$ is also in $L^2(a,b)$. 
\begin{solution}
    This means that there exists $g \in L^2(a,b)$, such that for any $\phi \in C_c^\infty(a,b)$,
    %
    \[ \int f(X) \phi'(x)\; dx = - \int g(x) \phi(x)\; dx. \]
\end{solution}

\part Let $\R_+$ denote the positive real axis $[0,\infty)$. Let $H^1(\R)$ (respectively $H^1(\R_+)$) be the space of real-valued functions $f\in L^2(\R)$  (respectively $f\in L^2(\R_+)$ such tha thte distributional derivative $f'$ is also in $L^2(\R)$ (respectively $L^2(\R_+)$). Then $H^1(\R)$ and $H^1(\R_+)$ are Hilbert spaces with inner product given by
\begin{align*}
\langle f, g \rangle_{H^1(\R)} &= \int_{\R} f(x)g(x)dx + \int_{\R} f'(x) g'(x)dx,\\
\langle f, g \rangle_{H^1(\R_+)} &= \int_{\R_+} f(x)g(x)dx + \int_{\R_+} f'(x) g'(x)dx
\end{align*}
Let $T:H^1(\R)\to H^1(\R_+)$ be the mapping given by the restriction. Compute exactly the adjoint operator $T^*$.
\begin{solution}
\begin{comment}
    Let $K$ be the kernel of $T$, and let $V$ be the orthogonal complement of $K$. We claim $T$ is a unitary map when restricted as a map from $V$ to $H^1(\RR_+)$. Indeed, if $f \in V$, then $f \in L^2(\RR)$, and since $\langle f, \phi \rangle = 0$ for any $\phi \in C_c^\infty(\RR)$ supported compactly on $(-\infty,0)$, we conclude via an integration by parts that the distribution $f - f''$ is supported on $x \geq 0$. Thus on $x \leq 0$, we can write $f(x) = A e^x + B e^{-x}$ on $x \leq 0$, and the fact that $f \in L^2(\RR)$ implies that $B = 0$.
    
    
    Any element of $H^1(\RR_+)$ is continuous, and has a well defined value at zero (a trace). Given $f \in H^1(\RR_+)$, define
    %
    \[ T^*f(x) = \begin{cases} f(0) e^x &: x < 0 \\ f(x) &: x > 0. \end{cases} \]
    %
    Then $T^* f$ is obviously square integrable, and
    %
    \begin{align*}
        \int T^*f(x) \phi(x)\; dx &= f(0) \int_{-\infty}^0 e^x \phi'(x)\; dx + \int_0^\infty f(x) \phi'(x)\; dx\\
        &= f(0) \left[ \phi'(0) - \int_{-\infty}^0 e^x \phi(x)\; dx \right] + \int_0^\infty f(x) \phi'(x)\; dx\\
        &= - f(0) \int_{-\infty}^0 e^x \phi(x)\; dx + \int_0^\infty f(x) \phi'(x)\; dx
    \end{align*}
    
    
    One can argue (Morrey's inequality for example, plus the density of $C_c^\infty(\RR)$ in $H^1(\RR)$), that if $g \in K$, then $g(0) = 0$.
\end{comment}
\end{solution}

\end{parts}


\question (9R) A real valued function $f$ defined on $\RR$ belongs to the space $C^{1/2}(\RR)$ if and only if
%
\[ \sup_{x \in \RR} |f(x)| + \sup_{x \neq y} \frac{|f(x) - f(y)|}{\sqrt{|x - y|}} < \infty. \]
%
Prove that a function $f \in C^{1/2}(\RR)$ if and only if there exists a constant $C$ so that for every $\varepsilon > 0$, there is a bounded function $\varphi \in C^\infty(\RR)$ such that
%
\[ \sup_{x \in \RR} |f(x) - \varphi(x)| \leq C \varepsilon^{1/2} \quad\text{and}\quad \sup_{x \in \RR} \varepsilon^{1/2} |\varphi'(x)| \leq C. \]
\begin{solution}
    Suppose $f \in C^{1/2}(\RR)$. Let $\phi$ be a bump function symmetrical about the origin supported on $|x| \leq 1$, set $\phi_\varepsilon(y) = (1/\varepsilon) \phi(y/\varepsilon)$ and define $\varphi = f * \phi_\varepsilon$. Then $\varphi$ is bounded, and lies in $C^\infty(\RR)$. Since $\phi_\varepsilon(y)$ is supported on $|y| \leq \varepsilon$, We have
    %
    \[ f(x) - \varphi(x) = \int [f(x) - f(x-y)] \phi_\varepsilon(y) \lesssim \varepsilon^{1/2}. \]
    %
    We write (using the symmetry of $\phi$)
    %
    \[ \varphi'(x) = (1/\varepsilon)^2 \int_0^\infty \phi'(y/\varepsilon) [f(x-y) - f(x+y)]\; dy. \]
    %
    Now $|f(x-y) - f(x+y)| \lesssim \varepsilon^{1/2}$ for $|y| \leq \varepsilon$, the support of our integrand lies on $0 \leq y \leq \varepsilon$, and $|\phi'(y/\varepsilon)| \lesssim 1$. Thus it follows that $|\varphi'(x)| \lesssim \varepsilon^{1/2}$, which completes the proof.

    Now suppose the second condition. Given $\varphi$ satisfying the condition above, the derivative condition together with the fundamental theorem of calculus implies that
    %
    \[ |f(x) - f(y)| \leq |f(x) - \varphi(x)| + |\varphi(x) - \varphi(y)| + |\varphi(y) - f(y)| \leq 2C \varepsilon^{1/2} + C |x - y| / \varepsilon^{1/2}. \]
    %
    If we choose $\varepsilon = |x - y|$, then we conclude that
    %
    \[ |f(x) - f(y)| \leq 3C |x-y|^{1/2}, \]
    %
    so that
    %
    \[ \sup_{x \neq y} \frac{|f(x) - f(y)|}{|x-y|^{1/2}} \leq 3C. \]
    %
    The fact that $\varphi$ is bounded shows that if the condition holds for any $\varepsilon > 0$, then $f$ is bounded. Thus $f \in C^{1/2}(\RR)$.
\end{solution}









\newpage
\section{Questions that need solutions}

\question (September, 2017) Let $g: \RR^2 \to \RR$ be a function that has continuous partial derivatives in $\RR^2$. Define $\chi: \RR^3 \to \{ 0, 1 \}$ by $\chi(x) = 1$ if $x_3 > g(x_1,x_2)$, and $\chi(x) = 0$ otherwise. Compute the derivatives $\partial \chi / \partial x^i$ for $i = 1, 2, 3$.

\question Let $\alpha \in (0,1)$, and for $f \in C[0,1]$, and $x \in [0,1]$, define
%
\[ (T_\alpha f)(x) = \int_0^1 \sin(x+y) |x-y|^{-\alpha} f(y)\; dy. \]
\begin{parts}
    \part Prove that $T_\alpha$ extends to a bounded operator on $L^2[0,1]$.
    
    \item For which $\alpha \in (0,1)$ is $T_\alpha: L^2[0,1] \to L^2[0,1]$ a compact operator?
\end{parts}

\end{questions}

\end{document}
