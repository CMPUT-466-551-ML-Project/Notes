%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = HarmonicAnalysis.tex

\part{Euclidean Harmonic Analysis}

Here, we try and describe the more modern approaches to real-variable harmonic analysis, as developed by the \emph{Calderon-Zygmund school} in the 1960s and 1970s. Almost all of the problems we consider can be phrased as showing some operator is bounded as a map between functions spaces. Given some function $f$ lying in a space $V$, we have an associated function $Tf$ lying in some space $W$. The main goal of the techniques in this part of the book attempt to understand how quantitative control on certain properties of $f$ imply quantitative control on properties of $Tf$. In particular, given some quantity $A(f)$ associated with each $f \in V$, and a quantity $B(g)$ defined for all $g \in W$, our goal is to understand whether a general bound $B(Tf) \lesssim A(f)$ is possible for all functions $f \in V$, i.e. whether these exists a universal constant $C > 0$ such that $B(Tf) \leq C \cdot A(f)$ for all $f \in V$.

A core technique we employ here is the method of \emph{decomposition}. We write $f = \sum_k f_k$, where the function $f_k$ have particular properties, perhaps being concentrated in a particular region of space, or having a Fourier transform concentrated in a particular region. These concentration properties often simplify the analysis of the operator $T$, enabling us to obtain bounds $B(Tf_k) \lesssim A(f_k)$ for each $n$. Provided that the operator $T$, and the quantities $A$ and $B$ are `stable under addition', we can then obtain the bound $B(Tf) \leq A(f)$ by `summing' up the related quantities. The stability of $A$ and $B$ is often obtained by assuming these quantities are \emph{norms} on their respective function spaces, i.e. that there exists norms $\| \cdot \|_V$ and $\| \cdot \|_W$ such that $A(f) = \| f \|_V$ for each $f \in V$ and $B(g) = \| g \|_W$ for each $g \in W$. The stability of $T$ under addition is obtained by assuming linearity, or at least sub-linearity, in the sense that for each $f_1, f_2 \in V$,
%
\[ \| T(f_1 + f_2) \|_W \leq \| T f_1 \|_W + \| Tf_2 \|_W. \]
%
We can then use the triangle inequality to conclude that
%
\[ \| Tf \|_W \leq \sum_k \| Tf_k \|_W \lesssim \sum_k \| f_k \|_V. \]
%
Thus if $\sum_k \| f_k \|_V \lesssim \| f \|_V$, our argument is complete. This will be true, for instance, if there exists $\varepsilon > 0$ such that $\| f_k \|_V \lesssim 2^{- \varepsilon k} \| f \|_V$. This can often be obtained if we employ a \emph{dyadic decomposition technique}. For such decompositions, it is also possible to generalize are technique not only to norms, but also to \emph{quasinorms}, i.e. maps $\| \cdot \|$ which are homogeneous and satisfy a \emph{quasi-triangle inequality} $\| v + w \| \lesssim \| v \| + \| w \|$.

\begin{lemma}
    Suppose $\| \cdot \|_V$ is a quasi-norm on a vector space $V$, and under the topology induced by $\| \cdot \|_V$, we can write $f = \sum_{k = 1}^\infty f_k$, where there is $\varepsilon > 0$ and $C > 0$ such that for each $n$, $\| f_k \|_V \leq C \cdot 2^{-\varepsilon k}$. Then $\| f \|_V \lesssim_\varepsilon C$.
\end{lemma}

\begin{remark}
	Thus if $T$ is sublinear and we have $\| Tf_k \|_W \lesssim \| f_k \|_V$ and $\| f_k \|_V \lesssim 2^{- \varepsilon k} \| f \|_V$, we conclude $\| Tf_k \|_W \lesssim 2^{-\varepsilon k} \| f \|_V$, and then by sublinearity and the lemma applied to $\| \cdot \|_W$, we conclude
	%
	\[ \| Tf \|_W \leq \| \sum_k Tf_k \|_W \lesssim_\varepsilon \| f \|_V. \]
	%
	A slight modification of the proof below even gives this claim provided $T$ is \emph{quasi sublinear}, in the sense that for all $f_1, f_2 \in V$, $\| T(f_1 + f_2) \|_W \lesssim \| Tf_1 \|_V + \| Tf_2 \|_V$ for all $f_1, f_2 \in V$. However, such operators occur so rarely in practice that it isn't worth concentrating on them.
\end{remark}

\begin{proof}
	Pick $A > 0$ such that $\| f_1 + f_2 \|_V \leq A \cdot (\| f_1 \|_V + \| f_2 \|_V)$ for all $f_1$ and $f_2$. If $A < 2^{\varepsilon}$, we can write apply the quasitriangle inequality iteratively to conclude
    %
    \begin{align*}
        \| f \| &\leq C \cdot \sum_{k = 1}^\infty A^k \| f_k \|_V \leq C \cdot \left( \sum_{k = 1}^\infty (A 2^{-\varepsilon})^k \right) \leq C \cdot \left( \frac{1}{1 - A 2^{-\varepsilon}} \right) \lesssim_\varepsilon C.
    \end{align*}
    %
    In general, fix $N$, and write $f = f^1 + \dots + f^N$, where $f^m = \sum_{k = 0}^\infty f_{m + Nk}$. Then $\| f_{m + Nk} \|_V \leq C \cdot 2^{- N \varepsilon k}$, and if $N$ is chosen large enough that $A < 2^{N \varepsilon}$, we can apply the previous case to conclude that $\| f^m \|_V \lesssim_\varepsilon C$. Then we can apply the quasi-triangle inequality to conclude that $\| f \| \lesssim_\varepsilon C$.
\end{proof}

We can even apply the method of decomposition in the presence of suitably large polynomial decay.

\begin{lemma}
    Suppose $\| \cdot \|_V$ is a quasinorm on a function space $V$. Then there exists $t$ such that for all $s > t$, if $f = \sum_{k = 1}^\infty f_k$, and if $\| f_k \|_V \leq C \cdot k^{-s}$, for $s > t$, then $\| f \|_V \lesssim_s C$.
\end{lemma}
\begin{proof}
    As in the previous lemma, pick $A > 0$ such that $\| f_1 + f_2 \|_V \leq A (\| f_1 \|_V + \| f_2 \|_V)$ for all $f_1,f_2 \in V$. We perform a decomposition of dyadic type, writing $f = \sum_{m = 0}^\infty f^m$, where
    %
    \[ f^m = \sum_{k = 2^m}^{2^{m+1} - 1} f_k. \]
    %
    By splitting up the sum into a binary tree, we can ensure that
    %
    \[ \| f^m \|_V \lesssim A^{m+1} \sum_{k = 2^m}^{2^{m+1} - 1} \| f_k \|_V \leq C \cdot A^{m+1} \sum_{k = 2^m}^{2^{m+1} - 1} k^{-s} \lesssim C (A 2^{1-s})^m. \]
    %
    If $s > 1 + \lg(A)$, the previous lemma applies that $\| f \|_V \lesssim C$.
\end{proof}

In this part of the notes, we define the various classes of quasi-norms we will study, describe the general methods which make up the Calderon-Zygmund theory, and find applications to geometric measure theory, complex analysis, partial differential equations, and analytic number theory.





\chapter{Monotone Rearrangement Invariant Norms}

In this chapter, we discuss common families of \emph{monotone, rearrangement invariant quasinorms} that occur in harmonic analysis. The general framework is as follows. For each function $f$, we associate it's \emph{distribution function} $F: [0,\infty) \to [0,\infty]$ given by $F(t) = |\{ x : |f(x)| > t \}|$. A \emph{rearrangement invariant space} is a subspace $V$ of the collection of measurable complex-valued functions on some measure space $X$, equipped with a quasi-norm $\| \cdot \|$, satisfying the following two properties:
%
\begin{itemize}
    \item \emph{Monotonicity}: If $|f(x)| \leq |g(x)|$ for all $x \in X$, then $\| f \| \leq \| g \|$.

    \item \emph{Rearrangement-Invariance}: If $f$ and $g$ have the same distribution function, then $\| f \| = \| g \|$.
\end{itemize}
%
A monotone rearrangement-invariant norm essentially provides a way of quantifying the height and width of functions on $X$. It has no interest in the `shape' of the objects studied, because of the property of rearrangement invariance. In a particular problem, one picks the norm best emphasizing a particular family of features useful in the problem.

There are two very useful classes of functions useful for testing the behaviour of translation invariant norms:
%
\begin{itemize}
    \item The \emph{indicator functions} $\mathbf{I}_E(x) = \mathbf{I}(x \in E)$, for a measurable set $E$.
    \item The \emph{simple functions} $f = \sum_{i = 1}^n a_i \mathbf{I}_{E_i}$, for disjoint sets $E_i$.
\end{itemize}
%
The class of all simple functions forms a vector space, and for almost all the monotone rearrangement invariant norm we consider in this section, this vector space will form a dense subspace of the class of all functions. This means that when we want to study how an operator transforms the height and width of functions, the behaviour of the operator on simple functions often reflects the behaviour of an arbitrary function.

\section{The $L^p$ norms}

For $p \in (0,\infty)$, we define the $L^p$ norm on measurable function on a measure space $X$ by
%
\[ \| f \|_p = \left( \int |f(x)|^p\; dx \right)^{1/p}. \]
%
For $p = \infty$, we define
%
\[ \| f \|_\infty = \min \left\{ t \geq 0: |f(x)| \leq t\ \text{almost surely} \right\}. \]
%
These are the most fundamental monotone, rearrangement invariant norms. The space of functions $f$ with $\| f \|_p < \infty$ is denoted by $L^p(X)$. The most important spaces to consider here are the space $L^1(X)$, consisting of absolutely square integrable functions, $L^\infty(X)$, consisting of almost-everywhere bounded functions, and $L^2(X)$, consisting of square integrable functions. The main motivation for the introduction of the other $L^p$ spaces is that much of the quantitative theory for $p \in \{ 1, \infty \}$ is rather trivial, in the sense that it is easy to see when certain operators are bounded on these spaces, or unbounded.

As $p$ increases, the $L^p$ norm of a particular function $f$ gives more control over the height of the function $f$, and weaker control on values where $f$ is particular small. At one extreme, $L^\infty(X)$ only has control over the height of a function, and no control over it's width. Conversely, one can think of $L^0(X)$ as being the space of functions with finite support, though no natural norm exists on this space of functions solely classifying width. After all, such a quantity couldn't be homogenous, since the width of $f$ and $\alpha f$ are the same for each $\alpha \neq 0$. Thus the space $L^0(X)$ isn't so interesting to us from a quantitative perspective.

\begin{example}
  If $f(x) = |x|^{-s}$ for $x \in \RR^d$ and $s > 0$, then integration by radial coordinates shows that
  %
  \[ \int_{\varepsilon \leq |x| \leq M} \frac{1}{|x|^{s p}}\; dx \approx \int_\varepsilon^M r^{d-1 - ps}\; dr = \frac{M^{d - p s} - \varepsilon^{d - p s}}{d - p s}. \]
  %
  This quantity remains finite as $\varepsilon \to 0$ if and only if $d > p s$, and finite as we let $M \to \infty$ if and only if $d < p s$. Thus if $p < d/s$, $f$ is \emph{locally} in $L^p$, in the sense that $f \in L^p(B)$ for every bounded $B \in \RR^d$. The class of functions for which this condition holds is denoted $L^p_{\text{loc}}(X)$. Conversely, if $p > d/s$, then for every domain $B$ separated from the origin, $f \in L^p(B)$. For $p = d/s$, the function $f$ fails to be $L^p(\RR^d)$, but only `by a logarithm', in the sense that
  %
  \[ \int_{\varepsilon \leq |x| \leq M} \frac{1}{|x|^{s p}}\; dx \approx \int_\varepsilon^M \frac{dr}{r} = \log(M/\varepsilon). \]
  %
  We will later find `weaker' versions of the $L^p$ norm, and $f$ will have finite version of these norms.
\end{example}

The last example shows that, roughly speaking, control on the $L^p$ norm of a function for large values of $p$ prevents the formation of higher order singularities, and control of the norm for small values of $p$ ensures that functions have large decay at infinity.

\begin{example}
  If $s = A \chi_E$, and we set $H = |A|$ and $W = |E|$, then $\| s \|_p = W^{1/p} H$. As $p \to \infty$, the value of $\| s \|_p$ depends more and more on $H$, and less on $W$, and in fact $\lim_{p \to \infty} \| s \|_p = H$. If $s = \sum A_n \chi_{E_n}$, and $|A_m|$ is the largest constant from all other values $A_n$, then as $p$ becomes large, $|A_m|^p$ overwhelms all other terms. We calculate that as $p \to \infty$,
  %
  \[ \| s \|_p = \left( \sum |E_n| |A_n|^p \right)^{1/p} = |A_m|^p (|E_m| + o(1))^{1/p} = |A_m| (1 + o(1)). \]
  %
  This implies $\| s \|_p \to |A_m|$ as $p \to \infty$. But as $p \to 0$, $\lim_{p \to 0} \| f \|_p$ does not in general exist, even for step functions with finite support. Nonetheless, we can conclude that $\lim_{p \to 0} \| s \|_p^p = \sum |E_n|$, which is the measure of the support of $s$.
\end{example}

As $p \to \infty$, the width of a function is disregarded completely by the $L^p$ norm, motivating the definition of \emph{the $L^\infty$ norm}; Given a measurable $f$, we define $\| f \|_\infty$ to be the smallest number such that $|f| \leq \| f \|_\infty$ almost surely. We then define $L^\infty(X)$ to be the space of measurable functions $f$ for which $\| f \|_\infty < \infty$. We have already shown $\| s \|_p \to \| s \|_\infty$ if $s$ is a simple function, and the density of such functions gives a general result.

\begin{theorem}
    Let $p \in (0,\infty)$. If $f \in L^p(X) \cap L^\infty(X)$, then
    %
    \[ \lim_{t \to \infty} \| f \|_t = \| f \|_\infty. \]
\end{theorem}
\begin{proof}
    Without loss of generality, assume $p \geq 1$. Consider the norm $\| \cdot \|$ on $L^p(X) \cap L^\infty(X)$ given by
    %
    \[ \| f \| = \| f \|_p + \| f \|_\infty. \]
    %
    Then $L^p(X) \cap L^\infty(X)$ is complete with respect to this metric. For each $t \in [p,\infty)$, define $T_t(f) = \| f \|_t$. Then the functions $\{ T_t \}$ are uniformly bounded in the norm $\| \cdot \|$, since if $p = \theta t$, then
    %
    \[ |T_t(f)| = \| f \|_t \leq \| f \|_p^\theta \| f \|_\infty^{1-\theta} \leq \| f \|^\theta \| f \|^{1-\theta} = \| f \|. \]
    %
    For any $\varepsilon > 0$, we can find a step function $s$ with $\| s - f \|_p, \| s - f \|_\infty \leq \varepsilon$. This means that for all $t \in (p,\infty)$,$\| s - f \|_t \leq \varepsilon$. And so
    %
    \begin{align*}
        \Big| T_t(f) - \| f \|_\infty \Big| &\leq |T_t(f) - T_t(s)| + |T_t(s) - \| s \|_\infty| + |\| s \|_\infty - \| f \|_\infty| \leq 2\varepsilon + o(1). 
    \end{align*}
    %
    Taking $\varepsilon \to 0$ gives the result.
\end{proof}

Abusing notation, we define $\| f \|_0^0 = | \text{supp} f | = | \{ x: f(x) \neq 0 \} |$, and let $L^0(X)$ be the space of functions with finite support. We know that for any simple function $s$, $\| s \|_p^p \to \| s \|_0^0$ as $p \to 0$. If $f \in L^0(X) \cap L^p(X)$ for some $p \in (0,\infty)$, then the monotone and dominated convergence theorems implies that
%
\[ \| f \|_0^0 = \int \mathbf{I}(f(x) \neq 0) = \int \left( \lim_{t \to 0} |f(x)|^t \right)\; dx = \lim_{t \to 0} \int |f(x)|^t\; dx = \lim_{t \to 0} \| f \|_t^t. \]
%
Thus the space $L^0(X)$ lies at the opposite end of the spectrum to $L^\infty$.

The fact that $\| f \|_0^0$ is a norm taken to the `power of zero' implies that many nice norm properties of the $L^p$ spaces fail to hold for $L^0(X)$. For instance, homogeneity no longer holds; in fact, for each $\alpha \neq 0$,
%
\[ \| \alpha f \|_0^0 = \| f \|_0^0. \]
%
It does, however, satisfy the triangle inequality $\| f + g \|_0^0 \leq \| f \|_0^0 + \| g \|_0^0$, which follows from a union bound on the supports of the functions.

\begin{example}
  Let $p < q$, and suppose $f \in L^p(X) \cap L^q(X)$. For any $r \in (p,q)$, the $L^r$ norm emphasizes the height of $f$ less than the $L^q$ norm, and emphasizes the width of $f$ less than the $L^p$ norm. In particular, we find that for any $\lambda \geq 0$,
  %
  \begin{align*}
    \| f \|_r^r = \int_{\RR} |f(x)|^r\; dx &= \int_{|f(x)| \leq 1} |f(x)|^r\; dx + \int_{|f(x)| > 1} |f(x)|^r\; dx\\
    &\leq \int_{|f(x)| \leq 1} |f(x)|^p\; dx + \int_{|f(x)| > 1} |f(x)|^q\; dx\\
    &\leq \| f \|_p^p + \| f \|_q^q < \infty.
  \end{align*}
  %
  In particular, this shows $f \in L^r(X)$.
\end{example}

\begin{remark}
    The bound obtained in the last example can be improved by using scaling symmetries. For any $A > 0$,
    %
    \[ \| f \|_r^r = \frac{\| Af \|_r^r}{A^r} \leq \frac{\| Af \|_p^p + \| Af \|_q^q}{A^r} \leq \frac{A^p \| f \|_p^p + A^q \| f \|_q^q}{A^r}. \]
    %
    If $1/r = \theta/p + (1 - \theta)/q$, and we set $A = \| f \|_q^{q/(p-q)} / \| f \|_p^{p/(p-q)}$, then the above inequality implies $\| f \|_r \leq 2 \| f \|_p^\theta \| f \|_q^{1 - \theta}$, which is a homogenous equality. The constant 2 can be removed in the equation using the {\it tensor power trick}. If we consider the function on $X^n$ defined by $f^{\otimes n}(x_1, \dots, x_n) = f(x_1) \dots f(x_n)$, then $\| f^{\otimes n} \|_r = \| f \|_r^n$, and so
    %
    \[ \| f \|_r = \| f^{\otimes n} \|_r^{1/n} \leq \left( 2 \| f^{\otimes n} \|_p^\theta \| f^{\otimes n} \|_q^{1-\theta} \right)^{1/n} = 2^{1/n} \| f \|_p^\theta \| g \|_q^{1-\theta}. \]
    %
    We can then take $n \to \infty$ to conclude that $\| f \|_r \leq \| f \|_p^\theta \| f \|_q^{1-\theta}$.
\end{remark}

The argument in the last remark is an instance of \emph{real interpolation}; In order to conclude some fact about a function which lies `between' two other functions we know how to deal with, we split the function up into two parts lying in the other spaces, deal with them separately, and then put them back together to get some equality. One can then apply various symmetry considerations (homogeneity and the tensor power trick being two examples) to eliminate extraneous constants. We now also show how to prove this inequality using convexity, which illustrates another core technique. In the next theorem, $1/\infty = 0$.

\begin{theorem}[H\"{o}lder]
  If $0 < p,q \leq \infty$ and $1/p + 1/q = 1/r$, $\| f g \|_r \leq \| f \|_p \| g \|_q$.
\end{theorem}
\begin{proof}
  The case where $p$ or $q$ is $\infty$ is left as an exercise to the reader. In the other case, by moving around exponents, we may simplify to the case where $r = 1$. The theorem depends on the log convexity inequality, such that for $A,B \geq 0$ and $0 \leq \theta \leq 1$, $A^\theta B^{1 - \theta} \leq \theta A + (1 - \theta) B$. But since the logarithm is concave, we calculate
  %
  \[ \log(A^\theta B^{1 - \theta}) = \theta \log A + (1 - \theta) \log B \leq \log(\theta A + (1 - \theta) B), \]
  %
  and we can then exponentiate. To prove H\"{o}lder's inequality, by scaling $f$ and $g$, which is fine by homogeneity, we may assume that $\| f \|_p = \| g \|_q = 1$. Then we calculate
  %
  \begin{align*}
    \| f g \|_1 &= \int |f(x)| |g(x)| = \int |f(x)|^{p/p} |g(x)|^{q/q}\\
    &\leq \int \frac{|f(x)|^p}{p} + \frac{|g(x)|^q}{q} = \frac{1}{p} + \frac{1}{q} = 1 = \| f \|_p \| g \|_q.
  \end{align*}
  %
  If $p = \infty$, $q = 1$, then the inequality is trivial, since we have the pointwise inequality $|f(x) g(x)| \leq \| f \|_\infty |g(x)|$ almost everywhere, which we can then integrate.
\end{proof}

\begin{remark}
  Note that $A^\theta B^{1-\theta} \leq \theta A + (1 - \theta) B$ is an \emph{equality} if and only if $A = B$, or $\theta \in \{ 0, 1 \}$. In particular, following through the proof above shows that if $\| f \|_p = \| g \|_q = 1$, we must have $|f(x)|^{1/p} = |g(x)|^{1/q}$ almost everywhere. In general, this means H\"{o}lder's inequality is sharp if and only if $|f(x)|^{1/p}$ is a constant multiple of $|g(x)|^{1/q}$.
\end{remark}

The next inequality is known as the \emph{triangle inequality}.

\begin{corollary} \label{lptriangleinequality}
  Given $f$,$g$, and $p \geq 1$, $\| f + g \|_p \leq \| f \|_p + \| g \|_p$.
\end{corollary}
\begin{proof}
  The inequality when $p = 1$ is obtained by integrating the inequality $|f(x) + g(x)| \leq |f(x)| + |g(x)|$, and the case $p = \infty$ is equally trivial. When $1 < p < \infty$, by scaling we can assume that $\| f \|_p + \| g \|_p = 1$. Then we can apply H\"{o}lder's inequality combined with the $p = 1$ case to conclude
  %
  \begin{align*}
    \int |f(x) + g(x)|^p &\leq \int |f(x)| |f(x) + g(x)|^{p-1} + |g(x)| |f(x) + g(x)|^{p-1}\\
    &\leq \| f \|_p \| (f + g)^{p-1} \|_q + \| g \|_p \| (f + g)^{p-1} \|_q = \| f + g \|_{p}^{p-1}
  \end{align*}
  %
  Thus $\| f + g \|_p^p \leq \| f + g \|_p^{p-1}$, and simplifying gives $\| f + g \|_p \leq 1$.
\end{proof}

\begin{remark}
  Suppose $\| f + g \|_p = \| f \| + \| g \|_p$. Following through the proof given above shows that both applications of H\"{o}lder's inequality must be sharp. And this is true if and only if $|f(x)|^p$ and $|g(x)|^p$ are scalar multiples of $|f(x) + g(x)|^p$ almost everywhere. But this means $|f(x)|$ and $|g(x)|$ are scalar multiples of $|f(x) + g(x)|$. If $|f(x)| = A|f(x) + g(x)|$ and $|g(x)| = B|f(x) + g(x)|$. If $g \neq 0$, this implies there is $C$ such that $|f(x)| = C |g(x)|$ for some $C > 0$. Thus we can write $f(x) = C e^{i \theta(x)} g(x)$, and we must have
  %
  \[ \| f + g \|_p^p = \int |1 + C e^{i \theta(x)}|^p |g(x)|^p = (1 + C)^p \int |g(x)|^p \]
  %
  so $|1 + Ce^{i \theta(x)}| = |1 + C|$ almost everywhere but this can only be true if $e^{i \theta(x)} = 1$ almost everywhere, so $f = C g$. Thus the triangle inequality is only sharp is $f$ and $g$ are positive scalar multiples of one another.
\end{remark}

This discussion leads to a useful heuristic: Unless $f$ and $g$ are `aligned' in a certain way, the triangle inequality is rarely sharp. For instance, if $f$ and $g$ have disjoint support, we calculate that
%
\[ \| f + g \|_p = \left( \| f \|_p^p + \| g \|_p^p \right)^{1/p} \]
%
For $p > 1$, this is always sharper than the triangle inequality.

If $p < 1$, then the proof of Corollary \ref{lptriangleinequality} no longer works, and in fact, is no longer true. In fact, if $f$ and $g$ are non-negative functions, then we actually have the \emph{anti} triangle inequality
%
\[ \| f + g \|_p \geq \| f \|_p + \| g \|_p, \]
%
as proved in the next theorem.

\begin{theorem}
    If $p \geq 1$, then for any functions $f_1, \dots, f_N \geq 0$,
    %
    \begin{equation} \label{triangleInequality} ( \| f_1 \|_p^p + \dots + \| f_N \|_p^p )^{1/p} \leq \| f_1 + \dots + f_N \|_p \leq \| f_1 \|_p + \dots + \| f_N \|_p. \end{equation}
    %
    If $p \leq 1$, then the inequality reverses, i.e. for any positive functions $f_1, \dots, f_N$,
    %
    \begin{equation} \label{antiTriangleInequality} \| f_1 \|_p + \dots + \| f_N \|_p \leq \| f_1 + \dots + f_N \|_p \leq (\| f_1 \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \end{equation}
\end{theorem}
\begin{proof}
    The upper bound in \eqref{triangleInequality} is just obtained by applying the triangle inequality iteratively. To obtain the lower bound, we note that for $A_1, \dots, A_N \geq 0$,
    %
    \[ (A_1 + \dots + A_N)^p \geq A_1^p + \dots + A_N^p, \]
    %
    One can prove this from induction from the inequality $(A_1 + A_2)^p \geq A_1^p + A_2^p$, which holds when $A_2 = 0$, and the derivative of the left hand side is greater than the right hand side for all $A_2 \geq 0$. But then setting $A_k = f_k$ and then integrating gives
    %
    \[ \| f_1 + \dots + f_N \|_p^p \geq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \]
    %
    Now assume $0 < p < 1$. We begin by proving the lower bound in \ref{antiTriangleInequality}. We can assume $N = 2$, and $\| f_1 \|_p + \| f_2 \|_p = 1$, and then it suffices to show $\| f_1 + f_2 \|_p \geq 1$. For any $\theta \in (0,1)$, and $A,B \geq 0$, concavity implies
    %
    \[ (A + B)^p = (\theta (A/\theta) + (1 - \theta) (B/(1-\theta)))^p \geq \theta^{1-p} A^p + (1 - \theta)^{1-p} B^p. \]
    %
    Thus setting $A = f_1(x)$, $B = f_2(x)$, and $\theta = \| f_1 \|_p$, so that $1 - \theta = \| f_2 \|_p$, and then integrating, we find
    %
    \[ \| f_1 + f_2 \|_p^p \geq \theta + (1 - \theta) = 1. \]
    %
    On the other hand, the inequality $(A_1 + \dots + A_N)^p \leq A_1^p + \dots + A_N^p$, which holds for $A_1, \dots, A_N \geq 0$, can be applied with $f_k = A_k$ and integrated to yield
    %
    \[ \| f_1 + \dots + f_N \|_p^p \leq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \qedhere \]
\end{proof}

Thus the triangle inequality is not satisfied for the $L^p$ norms when $p < 1$. This is one of the deficiencies which leads the $L^p$ theories for $0 < p < 1$ to be rather deficient when compared to the case with $p \geq 1$. One way to fix this is to use the theory of Hardy spaces. We note that for $p < 1$, we do have a \emph{quasi} triangle inequality.

\begin{theorem} \label{quasitriangleinequalitylp}
    For $f_1, \dots, f_N \in L^p(X)$, with $0 < p < 1$,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \]
\end{theorem}
\begin{proof}
    By H\"{o}lder's inequality applied to sums,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq (\| f \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \qedhere \]
\end{proof}

This result is sharp, i.e. if we take a disjoint family of sets $\{ E_1, E_2, \dots \}$ with $|E_i| = 1$ for each $i$, and then set $f_i = \mathbf{I}_{E_i}$, then the inequality is sharp for each $N$.

\begin{remark}
    When $p < 1$, the space $L^p(X)$ is \emph{not} normable. To see why, we look at the topological features of $L^p(X)$. Fix $\varepsilon > 0$, and let $C$ be a convex set containing all functions $f$ with $\| f \|_p < \varepsilon$. Thus, in particular, $C$ contains all step functions $H \mathbf{I}_E$ where $H |E|^{1/p} < \varepsilon$. But if we now find a countable sequence of disjoint sets $\{ E_k \}$, each with positive measure, and for each $k$, define $H_k = (\varepsilon/2) |E_k|^{-1/p}$, then for any $N$, the function
    %
    \[ f_N = (H_1/N) \mathbf{I}_{E_1} + \dots + (H_N/N) \mathbf{I}_{E_N} \]
    %
    lies in $C$, and
    %
    \[ \| f_N \|_p = (1/N) (H_1^p |E_1| + \dots + H_N^p |E_N|)^{1/p} = (\varepsilon/2) N^{1/p - 1} \]
    %
    as $N \to \infty$, the $L^p$ norm of $f_N$ becomes unbounded. In particular, this means that we have proven that every bounded convex subset of $L^p(X)$ has empty interior, and a norm space certainly does not have this property.
\end{remark}

As we have mentioned, as $p \to \infty$, the $L^p$ norm excludes functions with large peaks, or large height, and as $p \to 0$, the $L^p$ norm excludes functions with large tails, or large width. They form a continuously changing family of functions as $p$ ranges over the positive numbers. In general, there is no inclusion of $L^p(X)$ in $L^q(X)$ for any $p,q$, except in two circumstances which occur often enough to be mentioned.

\begin{example}
  If $X$ is a finite measure space, and $0 < p \leq q \leq \infty$, $L^p(X) \subset L^q(X)$. H\"{o}lder's inequality implies $\| f \|_p = \| f \chi_X \|_p \leq \| f \|_q |X|^{1/p-1/q}$. Taking $q \to \infty$, we conclude $\| f \|_p \leq | X |^{1/p} \| f \|_\infty$. One can best remember the constants here by the formula
  %
  \[ \left( \fint |f(x)|^p \right)^{1/p} \leq \left( \fint |f(x)|^q \right)^{1/q}. \]
  %
  In particular, when $X$ is a probability space, the $L^p$ norms are increasing.
\end{example}

\begin{example}
  On the other hand, suppose the measure space is {\it granular}, in the sense that there is $\varepsilon > 0$ such that either $|E| = 0$ or $|E| \geq \varepsilon$ for any measurable set $E$. Then $L^q(X) \subset L^p(X)$ for $0 < p \leq q \leq \infty$. First we check the $q = \infty$ case, which follows by the trivial estimate
  %
  \[ \int |f(x)|^p \geq \varepsilon \| f \|_\infty, \]
  %
  so $\| f \|_\infty \leq \| f \|_p \varepsilon^{-1/p}$. But then applying log convexity, if $p \leq q < \infty$, we can write $1/q = \theta/p$ for $0 < \theta \leq 1$, and then log convexity shows
  %
  \[ \| f \|_q = \| f \|_p^\theta \| f \|_\infty^{1-\theta} \leq \varepsilon^{-(1 - \theta)/p} \| f \|_p = \varepsilon^{-1/p - 1/q} \| f \|_p. \]
  %
  If $\varepsilon = 1$, which occurs if $X = \ZZ$, then the $L^p$ norms are decreasing in $p$. This gives the best way to remember the constants involved, since the measure $\mu(E) = |E|/\varepsilon$ is one granular, and so
  %
  \[ \left( \frac{1}{\varepsilon} \int |f(x)|^q\; dx \right)^{1/q} \leq \left( \frac{1}{\varepsilon} \int |f(x)|^p\; dx \right)^{1/p}. \]
\end{example}

%\begin{example}
%  Controlling additional properties of the function offers similar properties as for control on the measure space. If $|f(x)| \leq M$ for almost all $x$, then for $p \leq q$,
  %
%  \[ \| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}. \]
  %
%  Conversely, if $|f(x)| \geq M$ whenever $f(x) \neq 0$, then
  %
%  \[ \| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}. \]
  %
  
%\end{example}

\begin{remark}
  We can often use such results in spaces which are not granular by coarsening the sigma algebra. For instance, the Lebesgue measure is $\varepsilon^d$ granular over the sigma algebra generated by the length $\varepsilon$ cubes whose corner's lie on the lattice $(\ZZ/\varepsilon)^d$, and if a function is measurable with respect to such a $\sigma$ algebra we call the function $\varepsilon$ granular.
\end{remark}

\begin{remark}
  If we let $X = \{ 1, \dots, N \}$, then $X$ is both finite and granular, so all $L^p$ norms are comparable. In particular, if $p \leq q$,
  %
  \[ \| f \|_q \leq \| f \|_p \leq N^{1/p - 1/q} \| f \|_q. \]
  %
  The left hand side of this inequality becomes sharp when $f$ is concentrated at a single point, i.e. $f(n) = \mathbf{I}(n = 1)$. On the other hand, the left hand side becomes sharp when $f$ is constant, i.e. $f(n) = 1$ for all $n$.
\end{remark}

\begin{example}
    We can obtain similar $L^p$ bounds by controlling the functions $f$ involved, rather than the measure space. For instance, if $|f(x)| \leq M$, and $p \leq q$, then then $\| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}$, which follows by log convexity. On the other hand, if $|f(x)| \geq M$ on the support of $f$, then $\| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}$.
\end{example}

\begin{theorem}
  If $p_\theta$ lies between $p_0$ and $p_1$, then
  %
  \[ L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X) \subset L^{p_0}(X) + L^{p_1}(X) \]
\end{theorem}
\begin{proof}
  If $\| f \|_{p_0}, \| f \|_{p_1} < \infty$, then for any $p_\theta$ between $p_0$ and $p_1$,
  %
  \[ \| f \chi_{|f| \leq 1} \|_{p_\theta}^{p_\theta} = \int_{|f| \leq 1} |f|^{p_\theta} \leq \int_{|f| \leq 1} |f|^{p_0} < \infty \]
  \[ \| f \chi_{|f| > 1} \|_{p_\theta}^{p_\theta} = \int_{|f| > 1} |f|^{p_\theta} \leq \int_{|f| > 1} |f|^{p_1} < \infty \]
  %
  Applying the triangle inequality, we conclude that $\| f \|_{p_\theta} < \infty$. In the case where $p_1 = \infty$, then $f \chi_{|f| > 1}$ is bounded, and must have finite support if $p_0 < \infty$, which shows this integral is bounded. Note the inequalities above show that we can split any function with finite $L^{p_\theta}$ norm into the sum of a function with finite $L^{p_0}$ norm and another with finite $L^{p_1}$ norm.
\end{proof}

\begin{remark}
  This theorem is important in the study of interpolation theory, because if we have two linear operators $T_{p_0}$ defined on $L^{p_0}(X)$ and $T_{p_1}$ on $L^{p_1}(X)$, and they agree on $L^{p_0}(X) \cap L^{p_1}(X)$, then there is a unique linear operator $T_{p_\theta}$ on $L^{p_\theta}(X)$ which agrees with these two functions, and we can consider the boundedness of such a function with respect to the $L^{p_\theta}$ norms.
\end{remark}

The last property of the $L^p$ norms we want to focus on is the principle of \emph{duality}. Given any values of $p$ and $q$ with $1/p + 1/q = 1$, H\"{o}lder's inequality implies that if $f \in L^p(X)$ and $g \in L^q(X)$, then $fg \in L^1(X)$. In particular, for each function $g \in L^q(X)$, the map
%
\[ \lambda: f \mapsto \int f(x)g(x)\; dx \]
%
is a linear functional on $L^p(X)$. H\"{o}lder's inequality implies that $\| \lambda \| \leq \| g \|_q$. But this is actually an \emph{equality}. In particular, if $1 < p < \infty$, one can show these are \emph{all} linear functionals. For $p \in \{ 1, \infty \}$, the dual space of $L^p(X)$ is more subtle. But, since in harmonic analysis we concentrate on quantitative bounds, the following theorem often suffices as a replacement.

\begin{theorem}
    If $1 \leq p < \infty$, and $f \in L^p(X)$, then
    %
    \[ \| f \|_p = \sup \left\{ \int f(x)g(x) : \| g \|_q = 1 \right\}. \]
    %
    If the underlying measure space is $\sigma$ finite, then this claim also holds for $p = \infty$.
\end{theorem}
\begin{proof}
    Suppose that $1 \leq p < \infty$. Given $f$, we define
    %
    \[ g(x) = \frac{1}{\| f \|_p^{p-1}} \text{sgn}(f(x)) |f(x)|^{p-1}. \]
    %
    If $\| f \|_p < \infty$, then
    %
    \[ \| g \|_q^q = \frac{1}{\| f \|_p^{pq - q}} \int |f(x)|^{pq-q} = \frac{1}{\| f \|_p^p} \| f \|_p^p = 1, \]
    %
    and
    %
    \[ \int f(x) g(x) = \frac{1}{\| f \|_p^{p-1}} \int |f(x)|^p = \| f \|_p. \]
    %
    On the other hand, suppose $\| f \|_p = \infty$. Then there exists a sequence of step functions $s_1 \leq s_2 \leq \dots \to |f|$. Each $s_k$ lies in $L^p(X)$, but the monotone convergence theorem implies that $\| s_k \|_p \to \infty$. For each $k$, find a function $g_k \geq 0$ with $\| g_k \|_q = 1$, and $\int g_k(x) s_k(x) \geq \| s_k \|_p / 2$. Then
    %
    \[ \int g_k(x) \text{sgn}(f(x)) f(x) = \int g_k(x) |f(x)| \geq \int g_k(x) s_k(x) \geq \| s_k \|_p / 2 \to \infty, \]
    %
    this completes the proof in this case. 

    Now we take the case $p = \infty$. Given any $f$, fix $\varepsilon > 0$. Then we can find a set $E$ with $0 < |E| < \infty$ such that $|f(x)| \geq \| f \|_\infty - \varepsilon$ for $x \in E$. If $g(x) = \text{sgn}(f(x)) \mathbf{I}_E / |E|$, then $\| g \|_1 = 1$, and
    %
    \[ \int f(x) g(x) = \frac{1}{|E|} \int_E |f(x)| \geq \| f \|_\infty - \varepsilon. \]
    %
    Taking $\varepsilon \to 0$ completes the claim.
\end{proof}

\section{Decreasing Rearrangements}

 The properties of a functions distribution are best reflected quite simply in the \emph{distribution function} of the function $f$, i.e. the function $F: [0,\infty) \to [0,\infty)$ given by $F(t) = |\{ x : |f(x)| > t \}|$, and any rearrangement invariant norm on $f$ should be a function of $F$. The function $F$ is right-continuous and decreasing, but has a jump discontinuity whenever $\{ x : |f(x)| = t \}$ is a set of positive measure. We denote distributions of functions $g$ and $h$ by $G$ and $H$.

\begin{lemma}
  Given a function $f$ and $g$, $\alpha \in \mathbf{C}$, and $t,s > 0$, then
  %
  \begin{itemize}
    \item If $|g| \leq |f|$, then $G \leq F$.
    \item If $g = \alpha f$, then $G(t) = F(t/|\alpha|)$.
    \item If $h = f + g$, then $H(t+s) \leq F(t) + G(s)$.
    \item If $h = fg$, then $H(ts) \leq F(t) + G(s)$.
  \end{itemize}
\end{lemma}
\begin{proof}
    The first point follows because $\{ x : |g(x)| > t \} \subset \{ x : |f(x)| > t \}$, and the second because $\{ x : |\alpha f(x)| > t \} = \{ x : |f(x)| > t/|\alpha| \}$. The third point follows because if $|f(x) + g(x)| \geq t + s$, then either $|f(x)| \geq t$ or $|g(x)| \geq s$. Finally, if $|f(x) g(x)| \geq ts$, then $|f(x)| \geq t$ or $|g(x)| \geq s$.
\end{proof}

We can simplify the study of the distribution of $f$ even more by defining the \emph{decreasing rearrangement} of $f$, a decreasing function $f^*: [0,\infty) \to [0,\infty)$ such that $f^*(s)$ is the \emph{smallest} number $t$ such that $F(t) \leq s$. Effectively, $f^*(s)$ is the inverse of $F$:
%
\begin{itemize}
    \item If there is a unique $t$ with $F(t) = s$, then $f^*(s) = t$.
    \item If there are multiple values $t$ with $F(t) = s$, let $f^*(s)$ be the \emph{smallest} such value.
    \item If there are no values $t$ with $F(t) = s$, then we pick the first value $t$ with $F(t) < s$.
\end{itemize}
%
We find
%
\[ \{ s : f^*(s) > t \} = \{ s : s < F(t) \} = [0,F(t)), \]
%
which has measure $F(t)$. This is the most important property of $f^*$; it is a decreasing function on the line which has the same distribution as the function $|f|$. It is also the unique such function which is right continuous. Thus our intuition when analyzing monotone, rearrangement invariant norms is not harmed if we focus on right continuous decreasing functions.

\begin{theorem}
    The function $f^*$ is right continuous.
\end{theorem}
\begin{proof}
    We note that $F(t) > s$ if and only if $t < f^*(s)$. Since $f^*$ is decreasing, for any $s \geq 0$, we automatically have $f^*(s^+) \leq f^*(s)$. If $f^*(s^+) < f^*(s)$, then
    %
    \[ s < F \left( f^*(s^+) \right) \leq F(f^*(s)) \leq s, \]
    %
    which gives a contradiction, so $f^*(s) = f^*(s^+)$.
\end{proof}

\begin{remark}
    We have a jump discontinuity at a point $s$ wherever $F$ is flat, and $f^*$ is flat wherever $F$ has a jump discontinuity.
\end{remark}

In particular, when understanding intuition about monotone rearrangement invariant norms, one is allowed to focus on non-increasing, right continuous functions on $(0,\infty)$. For instance, this means that these norms do not care about the number of singularities that a function has, since all these singularities `pile up' in the decreasing rearrangement.

\section{Weak Norms}

The weak $L^p$ norms are obtained as a slight `refinement' of the $L^p$ norms.

\begin{theorem}
  If $\phi$ is an increasing, differentiable function on the real line with $\phi(0) = 0$, then
  %
  \[ \int_X \phi(|f(x)|) = \int_0^\infty \phi'(t) F(t)\; dt \]
\end{theorem}
\begin{proof}
  An application of Fubini's theorem is all that is needed to show
  %
  \begin{align*}
    \int_X \phi(|f(x)|)\; dx &= \int_X \int_0^{|f(x)|} \phi'(t)\; dt\; dx\\
    &= \int_0^\infty \phi'(t) \int_{|f(x)| > t}\; dx\; du\\
    &= \int_0^\infty \phi'(t) F(t)\; dt. \qedhere
  \end{align*}
\end{proof}

As a special case we find
%
\[ \| f \|_p = \left( p \int_0^\infty F(t) t^p \frac{dt}{t} \right)^{1/p}. \]
%
For this to be true, $F(t)$ must tend to zero `logarithmically faster' than $1/t^p$. Indeed, we find
%
\[ F(t) = |\{ |f|^p > t^p \}| \leq \frac{1}{t^p} \int |f|^p = \frac{\| f \|_p^p}{t^p}, \]
%
a fact known as \emph{Chebyshev's inequality}. But a bound $F(t) \lesssim 1/t^p$ might be true even if $f \not \in L^p(\RR^d)$. This leads to the \emph{weak $L^p$ norm}, denoted by $\| f \|_{p,\infty}$, which is defined to be the smallest value $A$ such that $F(t) \leq (A/t)^p$ for all $t$. We let $L^{p,\infty}(X)$ denote the space of all functions $f$ for which $\| f \|_{p,\infty} < \infty$. By Chebyshev's inequality, $\| f \|_{p,\infty} \leq \| f \|_p$ for any function $f$. The reason that the value $A$ occurs within the brackets is so that the norm is homogenous; if $g = \alpha f$, and $\| f \|_{p,\infty} = A$, then
%
\[ G(t) = F(t/|\alpha|) \leq \left( \frac{A |\alpha|}{t} \right)^p, \]
%
so $\| \alpha f \|_{p,\infty} = |\alpha| \| f \|_p$. The weak norms do not satisfy a triangle inequality, but they do satisfy a quasitriangle inequality. This can be proven quite simply from the property that if $f = f_1 + \dots + f_N$, and $\alpha_1, \dots, \alpha_N \in [0,1]$ satisfy $\alpha_1 + \dots + \alpha_N = 1$, then
%
\[ F(t) = F_1(\alpha_1 t) + \dots + F_N(\alpha_N t). \]
%
Thus if $f = g + h$, then
%
\[ F(t) \leq G(t/2) + H(t/2) \leq \frac{\| g \|_{p,\infty}^p + \| h \|_{p,\infty}^p}{t^p} \lesssim_p \left( \frac{\| g \|_{p,\infty} + \| h \|_{p,\infty}}{t} \right)^p. \]
%
Thus $\| f + g \|_{p,\infty} \lesssim \| f \|_{p,\infty} + \| g \|_{p,\infty}$. We can measure the degree to which the weak $L^p$ norm fails to be a norm by determining how much the triangle inequality fails for the sum of $N$ functions, instead of just one function.

\begin{theorem}[Stein-Weiss Inequality]
  Let $f_1, \dots, f_N$ be functions. If $p > 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty}. \]
  %
  If $p = 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{1,\infty} \lesssim \log N \left[ \| f_1 \|_{1,\infty} + \dots + \| f_N \|_{1,\infty} \right]. \]
  %
  If $0 < p < 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \left( \| f_1 \|_{p,\infty}^p + \dots + \| f_N \|_{p,\infty}^{1/p} \right)^{1/p} \]
\end{theorem}
\begin{proof}
    Begin with the case $p \geq 1$. Without loss of generality, assume $\| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty} = 1$. Fix $t > 0$. For each $k \in [1,N]$, define
    %
    \[ g_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \geq t/2, \\ 0 &: \text{otherwise}, \end{cases} \]
    %
    and
    %
    \[ h_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \leq \| f_k \|_{p,\infty} \cdot (t/2), \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    Also define $j_k = f_k - g_k - h_k$. Then write $f = f_1 + \dots + f_N$, $g = g_1 + \dots + g_N$, $h = h_1 + \dots + h_N$, and $j = j_1 + \dots + j_N$. Note that $\| h \|_\infty \leq t/2$, so
    %
    \[ \{ x : |f(x)| \geq t \} \subset \{ x : |g(x)| \geq t/4 \} \cup \{ x : |j(x)| \geq t/4 \}. \]
    %
    Each $g_k$ is supported on a set of measure at most $\| f_k \|_{p,\infty}^p \cdot (2/t)^p$. We conclude that $g$ is supported on a set of measure at most
    %
    \[ (2/t)^p \sum_{k = 1}^N \| f_k \|_{p,\infty}^p \leq (2/t)^p. \]
    %
    If $p > 1$, then the measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded by
    %
    \begin{align*}
        \frac{4}{t} \int |j(x)|\; dx &\leq \frac{4}{t} \sum_{k = 1}^N \int |j_k(x)|\\
        &= \frac{4}{t} \sum_{k = 1}^N \int_{\| f_k \|_{p,\infty} (t/2)}^{t/2} \frac{\| j_k \|_{p,\infty}^p}{s^p}\; ds\\
        &= \frac{2^{p+1}}{p-1} \frac{1}{t^p} \sum_{k = 1}^N \| j_k \|_{p,\infty}^p \left( \frac{1}{\| f_k \|_{p,\infty}^{p-1}} - 1 \right) \\
        &\leq \frac{2^{p+1}}{p-1} \frac{1}{t^p} \sum_{k = 1}^N \| f_k \|_{p,\infty}^p \left( \frac{1}{\| f_k \|_{p,\infty}^{p-1 }} - 1 \right)\\
        &\leq \frac{2^{p+1}}{p-1} \frac{1}{t^p}.
    \end{align*}
    %
    Thus in total, we conclude the measure of $\{ x: |f(x)| \geq t \}$ is at most
    %
    \[ \frac{2^p}{t^p} + \frac{2^{p+1}}{p - 1} \frac{1}{t^p} \lesssim_p \frac{1}{t^p}. \]
    %
    If $p = 1$, then the measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded
    %
    \begin{align*}
        (4/t) \int |j(x)|\; dx &\leq (4/t) \sum_{k = 1}^N \int |j_k(x)|\\
        &= (4/t) \sum_{k = 1}^N \int_{\| f_k \|_{1,\infty} (t/2)}^{t/2} \frac{\| j_k \|_{1,\infty}}{s}\; ds\\
        &= (4/t) \sum_{k = 1}^N \| f_k \|_{1,\infty} \log(1/\| f_k \|_{1,\infty}).
    \end{align*}
    %
    Now the maximum of $x_1 \log(1/x_1) + \dots + x_N \log(1/x_N)$, subject to the constraint that $x_1 + \dots + x_N = 1$, is maximized by taking $x_k = 1/N$ for all $N$, which gives a maximal bound of $\log(N)$. In particular, we find that
    %
    \[ (2/t) \sum_{k = 1}^N \| f_k \|_{1,\infty} \log(1/\| f_k \|_{1,\infty}) \leq (2 \log N)/t. \]
    %
    Thus in total, we conclude the measure of $\{ x: |f(x)| \geq t \}$ is at most
    %
    \[ 2(1 + \log N)/t \lesssim \log N / t. \]
    %
    If $p < 1$, we may assume without loss of generality that
    %
    \[ \| f_1 \|_{p,\infty}^p + \dots + \| f_N \|_{p,\infty}^p = 1. \]
    %
    Then, we perform the same decomposition as before, with functions $\{ g_k \}$, $\{ h_k \}$, and $\{ j_k \}$, defined the same as before, except that
    %
    \[ h_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \leq \| f_k \|_{p,\infty}^p \cdot (t/2), \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    The function $g_k$ has support at most $\| f_k \|_{p,\infty}^p \cdot (2/t)^p$, and thus $g$ has total support
    %
    \[ \sum \| f_k \|_{p,\infty}^p (2/t)^p = (2/t)^p. \]
    %
    The measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded by
    %
    \begin{align*}
      \frac{4}{t} \int |j(x)|\; dx &\leq \frac{4}{t} \sum_{k = 1}^N \int_{\| f_k \|_{p,\infty}^p (t/2)}^{t/2} \frac{\| f_k \|_{p,\infty}^p}{s^p}\; ds\\
      &\leq \frac{2^{p+1}}{t^p} \frac{1}{1 - p} \sum_{k = 1}^N \| f_k \|_{p,\infty}^{p + p(1-p)}\\
      &= \frac{2^{p+1}}{t^p} \frac{1}{1 - p} \max \| f_k \|_{p,\infty}^{p(1-p)} \lesssim_p \frac{1}{t^p},
    \end{align*}
    %
    Combining the two bounds gives that $\| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p 1$.
\end{proof}

\begin{remark}
  For $p = 1$, compare this \emph{logarithmic} failure to be a norm with the \emph{polynomial} failure to be a norm found in the norms $\| \cdot \|_p$, when $p < 1$, in Theorem \ref{quasitriangleinequalitylp}.
\end{remark}

For $p = 1$, the Stein-Weiss inequality is asymptotically tight in $N$.

\begin{example}
  Let $X = \RR$. For each $k$, let
  %
  \[ f_k(x) = \frac{1}{|x - k|}. \]
  %
  Then $\| f_k \|_{1,\infty} \lesssim 1$ is bounded independantly of $k$. If $|x| \leq N$, there are integers $k_1, \dots, k_N > 0$ such that $|x - k_i| \leq 2i$, so
  %
  \[ f(x) \geq \sum_{i = 1}^N \frac{1}{|x - k_i|} \geq \sum_{i = 1}^N \frac{1}{2i} \gtrsim \log(N). \]
  %
  Thus $\| f \|_{1,\infty} \gtrsim N \log N \gtrsim \log N \sum \| f_k \|_{1,\infty}$.
\end{example}

The weak $L^p$ norms provide another monotone translation invariant norm, and it oftens comes up when finer tuning is needed in certain interpolation arguments, especially when dealing with maximal functions.

\begin{example}
  If $f = H \mathbf{I}_E$, with $|E| = W$, then
  %
  \[ F(t) = W \cdot \mathbf{I}_{[0,H)}. \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \sup_{0 \leq t < H} W t^p \right)^{1/p} = W^{1/p} H^p = \| f \|_p. \]
  %
  If $f = H_1 \mathbf{I}_{E_1} + H_2 \mathbf{I}_{E_2}$, with $|E_1| = W_1$ and $|E_2| = W_2$, with $H_1 \leq H_2$, then
  %
  \[ F(t) = \begin{cases} W_1 + W_2 &: t < H_1, \\ W_2 &: t < H_2, \\ 0 &: \text{otherwise.} \end{cases} \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \max((W_1 + W_2) H_1^p, W_2 H_2^p) \right)^{1/p} = \max((W_1 + W_2)^{1/p} H_1, W_2^{1/p} H_2). \]
\end{example}

\begin{example}
    The function $f(x) = 1/|x|^s$ does not lie in any $L^p(\RR^d)$, but lies in $L^{p,\infty}$ precisely when $p = d/s$, since
    %
    \[ \left| \{ 1/|x|^{ps} > t \} \right| = \left| \left\{ |x| \leq \frac{1}{t^{1/ps}} \right\} \right|\ \propto_d\ \frac{1}{t^{d/ps}}. \]
\end{example}

Before we move on, we consider a form of duality for the weak norm, at least when $p > 1$.

\begin{theorem}
	If $p > 1$, and $X$ is $\sigma$ finite, then
	%
	\[ \| f \|_{p,\infty} \sim_p \sup_{|E| < \infty} \frac{1}{|E|^{1-1/p}} \int_E |f(x)|\; dx \]
\end{theorem}
\begin{proof}
	Suppose $\| f \|_{p,\infty} < \infty$. If we write $f = \sum f_k$, where $f_k = \mathbf{I}_{F_k} f$, and $F_k = \{ x: 2^{k-1} < |f(x)| \leq 2^k \}$, then $|F_k| \leq \| f \|_{p,\infty}^p 2^{-kp}$. Thus
	%
	\[ \left| \int_E |f_k(x)| \right| \leq 2^k \| f \|_{p,\infty}^p 2^{-kp} = \| f \|_{p,\infty}^p 2^{k(1-p)}. \]
	%
	Fix some integer $n$. Then
	%
	\begin{align*}
		\int_E |f(x)|\; dx &\leq \sum_{k = -\infty}^{n-1} \int_E |f_k(x)|\; dx + \sum_{k = n}^\infty \int_E |f_k(x)|\; dx\\
		&\leq |E| 2^{n-1} + \| f \|_{p,\infty}^p \sum_{k = n}^\infty 2^{k(1-p)}\\
		&\lesssim_p |E| 2^n + \| f \|_{p,\infty}^p 2^{-k(1-p)}.
	\end{align*}
	%
	If we let $2^n \sim \| f \|_{p,\infty} |E|^{1/p}$, then we conclude
	%
	\[ \int_E |f(x)|\; dx \lesssim_p |E|^{1 - 1/p} \| f \|_{p,\infty}. \]
	%
	Conversely, write 
	%
	\[ A = \sup_{|E| < \infty} \frac{1}{|E|^{1-1/p}} \int_E |f(x)|\; dx/ \]

	%
	If $G_t = \{ x: |f(x)| \geq t \}$, then
	%
	\[ |G_t| \leq \frac{1}{t} \int_{G_t} |f(x)|\; dx \leq \frac{A |G_t|^{1 - 1/p}}{t}, \]
	%
	so
	%
	\[ |G_t| \leq \frac{A^p}{t}, \]
	%
	which gives $\| f \|_{p,\infty} \leq A$.
\end{proof}

For $p \leq 1$, the spaces $L^{p,\infty}(X)$ are not normable, as seen by the tightness of the Stein-Weiss inequality. Nonetheless, we still have a certain `duality' property, that is often useful in the analysis of operators on these spaces. Most useful is it's application when $p = 1$.

\begin{theorem} \label{weakdualitytheorem}
  Let $0 < p < \infty$, and let $f \in L^{p,\infty}(X)$, and let $\alpha \in (0,1)$. Then the following are equivalent:
  %
  \begin{itemize}
    \item $\| f \|_{p,\infty} \lesssim_{\alpha,p} A$.

    \item For any set $E \subset X$ with finite measure, there is $E' \subset E$ with $|E'| \geq \alpha |E|$ such that
    %
    \[ \int_{E'} |f(x)|\; dx \lesssim_{\alpha,p} A |E'|^{1 - 1/p}. \]
  \end{itemize}
\end{theorem}
\begin{proof}
  By homogeneity, assume $\| f \|_{p,\infty} \leq 1$, so that if $F$ is the distribution of $f$, $F(t) \leq 1/t^p$. If $|E| = (1-\alpha)^{-1} / t_0^p$, and we set
  %
  \[ E' = \{ x: |f(x)| \leq t_0 \}, \]
  %
  then
  %
  \[ |E'| \geq |E| - F(t_0) = \frac{(1 - \alpha)^{-1} - 1}{t_0^p} = \alpha |E|, \]
  %
  and
  %
  \[ \int_{E'} |f(x)| \leq t_0 |E'| \lesssim_\alpha |E'|^{1-1/p}. \]
  %
  Conversely, suppose Property (2) holds. For each $k$, set
  %
  \[ E_k = \{ x: 2^k \leq |f(x)| < 2^{k+1} \}. \] 
  %
  Then there exists $E_k'$ with $|E_k'| \geq \alpha |E_k|$ and
  %
  \[ \int_{E_k'} |f(x)|\; dx \leq |E_k'|^{1 - 1/p} \]
  %
  On the other hand,
  %
  \[ \int_{E_k'} |f(x)|\; dx \geq 2^k |E_k'|. \]
  %
  Rearranging this equation gives $|E_k'| \leq 2^{-pk}$, and so $|E_k| \lesssim_\alpha 2^{-pk}$. But this means
  %
  \[ F(2^N) = \sum_{k = N}^\infty |E_k| \lesssim_{\alpha,p} 2^{-Np}, \]
  %
  and this implies $\| f \|_{p,\infty} \lesssim_{\alpha,p} 1$.
\end{proof}

\section{Lorentz Spaces}

Recall that we can write
%
\[ \| f \|_p = \left( p \int_0^\infty F(t) t^p \frac{dt}{t} \right)^{1/p}. \]
%
Thus $F(t) t^p$ is integrable with respect to the Haar measure on $\RR^+$. But if we change the integrality condition to the condition that $F(t) t^p \in L^q(\RR^+)$ for some $0 < q \leq \infty$, we obtain a different integrability condition, giving rise to a monotone, translation-invariant norm. Thus leads us to the definition of the \emph{Lorentz norms}. For each $0 < p,q < \infty$, we define the Lorentz norm
%
\[ \| f \|_{p,q} = p^{1/q} \| t F^{1/p} \|_{L^q(\RR^+)} \]
%
The \emph{Lorentz space} $L^{p,q}(X)$ as the space of functions $f$ with $\| f \|_{p,q} < \infty$. We can define the norm in terms of $f^*$ as well.

\begin{lemma}
  For any measurable $f: X \to \RR$, $\| f(t) \|_{p,q} = \| s^{1/p} f^*(s) \|_{L^q(\RR^+)}$.
\end{lemma}
\begin{proof}
  First, assume $f^*$ has non-vanishing derivative on $(0,\infty)$, and that $f$ is bounded, with finite support. An integration by parts gives
  %
  \[ \| f \|_{p,q} = p^{1/q} \left( \int_0^\infty t^{q-1} F(t)^{q/p}\; dt \right)^{1/q} = \left( \int_0^\infty t^q F(t)^{q/p - 1} (-F'(t))\; dt \right)^{1/q}. \]
  %
  If we set $s = F(t)$, then $f^*(s) = t$, and $ds = F'(t) dt$, and so
  %
  \[ \left( \int_0^\infty t^q F(t)^{q/p - 1} F'(t)\; dt \right)^{1/q} = \left( \int_0^\infty f^*(s)^q s^{q/p - 1} ds \right)^{1/q} = \| s^{1/p} f^* \|_{L^q(\RR^+)}. \]
  %
  This gives the result in this case. The general result can then be obtained by applying the monotone convergence theorem to an arbitrary $f^*$ with respect to a family of smooth functions.
\end{proof}

The definition of the Lorentz space may seem confusing, but we really only require various special cases in most applications. Aside from the weak $L^p$ norms $\| \cdot \|_{p,\infty}$ and the $L^p$ norms $\| \cdot \|_p = \| \cdot \|_{p,p}$, the $L^{p,1}$ norms and $L^{p,2}$ norms also occur, the first, because of the connection with integrability, and the second because we may apply orthogonality techniques. As $q \to 0$, the norms $\| \cdot \|_{p,q}$ give stronger control over the function $f$.

\begin{theorem}
    For $q < r$, $\| f \|_{p,r} \lesssim_{p,q,r} \| f \|_{p,q}$.
\end{theorem}
\begin{proof}
    First we treat the case $r = \infty$. We have
    %
    \begin{align*}
        s_0^{1/p} f^*(s_0) &= \left( (p/q) \int_0^{s_0} [s^{1/p} f^*(s_0)]^q \frac{ds}{s} \right)^{1/q}\\
        &\leq \left( (p/q) \int_0^{s_0} [s^{1/p} f^*(s)]^q \frac{ds}{s} \right)\\
        &\leq (p/q)^{1/q} \| f \|_{p,q}.
    \end{align*}
    %
    When $r < \infty$, we can interpolate, calculating
    %
    \begin{align*}
      \| f \|_{p,r} &= \left( \int_0^\infty [s^{1/p} f^*(s)]^r \frac{ds}{s} \right)^{1/r}\\
    &\leq \| f \|_{p,\infty}^{1 - q/r} \| f \|_{p,q}^{q/r} \leq (p/q)^{p(1/q - 1/r)} \| f \|_{p,q}. \qedhere
    \end{align*}
\end{proof}

The fact that multiplying a function by a constant dilates the distribution implies that the Lorentz norm is homogeneous. We do not have a triangle inequality for the Lorentz norms, but we have a quasi triangle inequality.

\begin{theorem}
	For each $p,q > 0$, $\| f_1 + f_2 \|_{p,q} \lesssim_{p,q} \| f_1 \|_p + \| f_2 \|_q$.
\end{theorem}
\begin{proof}
    We calculate that if $g = f_1 + f_2$,
    %
    \begin{align*}
    \| g \|_{p,q} &= \left( q \int_0^\infty \left[t G(t)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\leq \left( q \int_0^\infty \left[ t (F_1(t/2) + F_2(t/2))^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\lesssim \left( q \int_0^\infty \left[ t \left( F_1(t) + F_2(t) \right)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\lesssim_p \left( q \int_0^\infty t^q \left( F_1(t)^{q/p} + F_2(t)^{q/p} \right) \frac{dt}{t} \right)^{1/q}\\
    &\lesssim_q  \left( q \int_0^\infty t^q F_1(t)^{q/p} \frac{dt}{t} \right)^{1/q} +  \left( q \int_0^\infty t^q F_2(t)^{q/p} \frac{dt}{t} \right)^{1/q}\\
    &= \| f_1 \|_{p,q} + \| f_2 \|_{p,q}. \qedhere
  \end{align*}
\end{proof}

\section{Dyadic Layer Cake Decompositions}

An important trick to utilizing Lorentz norms is by utilizing a dyadic layer cake decomposition. The dyadic layer cake decompositions enable us to understand a function by breaking it up into parts upon which we can control the height or width of a function. We say $f$ is a \emph{sub step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \leq W$, and $|f(x)| \leq H$. A \emph{quasi step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \sim W$ and on $E$, $|f(x)| \sim H$.

\begin{remark}
  It might seem that sub step functions of height $H$ and width $W$ can take on a great many different behaviours, rather than that of a step function with height $H$ and width $W$. However, from the point of view of monotone, translation invariant norms, this isn't so. This is because using the binary expansion of real numbers, for every sub-step function $f$ of height $H$ and width $W$, we can find sets $\{ E_k \}$ such that
  %
  \[ f(x) = H \sum_{k = 1}^\infty 2^{-k} \mathbf{I}_{E_k}, \]
  %
  where $|E_k| = 1$. Thus bounds on step functions that are stable under addition tend to automatically imply bounds on substep functions.
\end{remark}

We start by discussing the \emph{vertical dyadic layer cake decomposition}. We define, for each $k \in \ZZ$,
%
\[ f_k(x) = f(x) \mathbf{I}(2^{k-1} < |f(x)| \leq 2^k) \]
%
Then we set $f = \sum f_k$. Each $f_k$ is a quasi step function with height $2^k$ and width $F(2^{k-1}) - F(2^k)$. We can also perform a \emph{horizontal layer cake decomposition}. If we define $H_k = f^*(2^k)$, and set
%
\[ f_k(x) = f(x) \mathbf{I}(H_{k-1} < |f(x)| \leq H_k), \]
%
then $f_k$ is a substep function with height $H_k$ and width $2^k$. These decompositions are best visualized with respect to the representation $f^*$ of $f$, in which case the decomposition occurs over particular intervals.

\begin{theorem}
    The following values $A_1, \dots, A_4$ are all comparable up to absolute constant depending only on $p$ and $q$:
    %
    \begin{enumerate}
        \item \label{onebound} $\| f \|_{p,q} \leq A_1$.

        \item \label{twobound} We can write $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a quasi-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[ 2^k W_k^{1/p} \right]^q \right)^{1/q} \leq A_2. \]

        \item \label{threebound} We can write $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a sub-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[2^{k} W_k^{1/p} \right]^q \right)^{1/q} \leq A_3. \]

        \item \label{fourbound} We can write $f(x) = \sum_{k \in \ZZ} f_k$, where $f_k$ is a sub-step function with width $2^k$ and height $H_k$, where $\{ H_k \}$ is a decreasing family of functions, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[H_k 2^{k/p} \right]^q \right)^{1/q} \leq A_4. \]
    \end{enumerate}
\end{theorem}
\begin{proof}
    It is obvious that we can always select $A_3 \leq A_2$. Next, we bound $A_2$ in terms of $A_1$ by performing a vertical layer cake decomposition on $f$. If we write $f = \sum_{k \in \ZZ} f_k$, then $f_k$ is supported on a set with measure $W_k = F(2^{k-1}) - F(2^k) \leq F(2^{k-1})$, and so
    %
    \begin{align*}
        \sum_{k \in \ZZ} [2^k W_k^{1/p}]^q &\leq \sum_{k \in \ZZ} [2^k F(2^{k-1})^{1/p}]^q\\
        &\lesssim_q \sum_{k \in \ZZ} [2^{k-1} F(2^k)^{1/p}]^q\\
        &\lesssim \sum_{k \in \ZZ} \int_{2^{k-1}}^{2^k} [tF(t)^{1/p}]^q\; \frac{dt}{t} \lesssim_q \| f \|_{p,q}^q \leq A_1^q.
    \end{align*}
    %
    Thus $A_2 \lesssim_q A_1$. Next, we bound $A_4$ in terms of $A_1$. Perform a horizontal layer cake decomposition, writing $f = \sum f_k$, where $f_k$ is supported on a set with measure $W_k \leq 2^k$, and $H_{k+1} \leq |f_k(x)| \leq H_k$. Then a telescoping sum shows
    %
    \begin{align*}
        H_k 2^{k/p} &= \left( \sum_{m = 0}^\infty (H_{k+m}^q - H_{k+m+1}^q) 2^{kq /p} \right)^{1/q}\\
        &\lesssim_q \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t 2^{k/p}]^q \frac{dt}{t} \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q}
    \end{align*}
    %
    Thus
    %
    \[ \left( \sum_{k \in \ZZ} [H_k 2^{k/p}]^q \right)^{1/q} \leq \left( \int_0^\infty [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q} \lesssim_q A_1. \]
    %
    Thus $A_4 \lesssim_q A_1$. It remains to bound $A_1$ by $A_4$ and $A_3$. Given $A_3$, we can write $|f(x)| \leq \sum 2^k \mathbf{I}_{E_k}$, where $|E_k| \leq W_k$. We then find
    %
    \[ F(2^k) \leq \sum_{m = 1}^\infty W_{k+m}. \]
    %
    Thus
    %
    \[ \int_{2^{k-1}}^{2^k} [t F(t)^{1/p}]^q \frac{dt}{t} \lesssim \left[ 2^k \left(\sum_{m = 0}^\infty W_k \right)^{1/p} \right]^q. \]
    %
    Thus if $q \leq p$,
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \ZZ} \left[2^k \left( \sum_{m = 0}^\infty W_{k+m} \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{k \in \ZZ} \sum_{m = 0}^\infty \left[ 2^k W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty 2^{-qm} \sum_{k \in \ZZ} \left[ 2^{k+m} W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( A_3^q \sum_{m = 0}^\infty 2^{-mq} \right)^{1/q} \lesssim_q A_3.
    \end{align*}
    %
    If $q \geq p$, we can employ the triangle inequality for $l^{q/p}$ to write
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \ZZ} \left[2^k \left( \sum_{m = 0}^\infty W_{k + m}  \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \left( \sum_{k \in \ZZ} 2^{kq} W_{k+m}^{q/p} \right)^{p/q} \right)^{1/p}\\
        &\leq \left( A_3^p \sum_{m = 0}^\infty 2^{-mq} \right)^{1/p} \lesssim_{p,q} A_3.
    \end{align*}
    %
    The bound of $A_1$ in terms of $A_4$ involves the same `shifting' technique, and is left to the reader.
\end{proof}

\begin{remark}
    Heuristically, the theorem above says that if $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a quasi-step function with width $H_k$ and width $W_k$, and if either $\{ H_k \}$ and $\{ W_k \}$ grow faster than powers of two, then
    %
    \[ \| f \|_{p,q} \sim_{p,q} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}. \]
    %
    Thus the $L^{p,q}$ norm has little interaction between elements of the sum when the sum occurs over dyadically different heights or width. This is one reason why we view the $q$ parameter as a `logarithmic' correction of the $L^p$ norm. In particular, if we can write $f = f_1 + \dots + f_N$, and $q_1 < q_2$, then the last equation, combined with a $l^{q_1}$ to $l^{q_2}$ norm bound, gives
    %
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^{q_1} \right)^{1/q_1} \leq N^{1/q_1 - 1/q_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^{q_2} \right)^{1/q_2} \]
    %
    This implies
    %
    \[ \| f \|_{p,q_2} \lesssim_{p,q_1,q_2} \| f \|_{p,q_1} \lesssim_{p,q_1,q_2} N^{1/q_1 - 1/q_2} \| f \|_{p,q_2}. \]
    %
    In particular, this occurs if there exists a constant $C$ such that $C \leq |f(x)| \leq C \cdot 2^N$ for all $x$. On the other hand, if we vary the $p$ parameter, we find that for $p_1 < p_2$,
    %
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} \leq \max(W_k)^{1/p_1 - 1/p_2} \left( \sum_{k \in \ZZ} \left[H_k W_k^{1/p_2} \right]^q \right)^{1/q}, \]
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} \leq \left( \frac{1}{\min(W_k)} \right)^{1/p_1 - 1/p_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q}. \]
    %
    which gives
    %
    \[ \min(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q} \lesssim_{p_1,p_2,q} \| f \|_{p_1,q} \lesssim_{p_1,p_2,q} \max(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q}. \]
    %
    Both of these inequalities can be tight. Because of the dyadic decomposition of $f$, we find $\max(W_k) \geq 2^N \min(W_k)$, so these two norms can differ by at least $2^{N(1/p_1 - 1/p_2)}$, and at \emph{most} if the $f_k$ occur over consecutive dyadic values, which is \emph{exponential} in $N$. Conversely, if the heights change dyadically, we find that
    % q = q'p_2/p-1
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} &\leq \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^{qp_2/p_1} \right)^{(p_1/p_2)/q}\\
        &\leq \max(H_k)^{1 - p_1/p_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{(p_1/p_2)/q}
    \end{align*}
    %
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} &\lessapprox \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^{qp_1/p_2} \right)^{(p_2/p_1)/q}\\
        &\leq \left( \frac{1}{\min(H_k)} \right)^{p_2/p_1 - 1} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{(p_2/p_1)/q}
    \end{align*}
    %
    where $\lessapprox$ denotes a factor ignoring polynomial powers of $N$ occuring from the estimate. Thus
    %
    \[ \min(H_k)^{p_2 - p_1} \| f \|_{p_1,q}^{p_1} \lessapprox_{p_1,p_2,q} \| f \|_{p_2,q}^{p_2} \lesssim_{p_1,p_2,q} \max(H_k)^{p_2-p_1} \| f \|_{p_1,q}^{p_1} \]
    %
    again, these inequalities can be both tight, and $\max(H_k) \geq 2^N \min(H_k)$, with equality if the quasi step functions from which $f$ is composed occur consecutively dyadically.
\end{remark}

\begin{example}
    Consider the function $f(x) = |x|^{-s}$. For each $k$, let
    %
    \[ E_k = \{ x : 2^{-(k+1)/s} \leq |x| < 2^{-k/s} \} \]
    %
    and define $f_k = f \mathbf{I}_{E_k}$. Then $f_k$ is a quasi-step function with height $2^k$, and width $1/2^{dk/s}$. We conclude that if $p = d/s$, and $q < \infty$,
    %
    \[ \| f \|_{p,q} \sim_{p,q,d} \left( \sum_{k = -\infty}^\infty 2^{qk(1 - d/ps)} \right)^{1/q} = \infty. \]
    %
    Thus the function $f$ lies exclusively in $L^{p,\infty}(\RR^d)$.
\end{example}

A simple consequence of the layer cake decomposition is H\"{o}lder's inequality for Lorentz spaces.

\begin{theorem}
    If $0 < p_1,p_2,p < \infty$ and $0 < q_1,q_2,q < \infty$ with
    %
    \[ 1/p = 1/p_1 + 1/p_2 \quad \text{and} \quad 1/q = 1/q_1 + 1/q_2, \]
    %
    then
    %
    \[ \| f g \|_{p,q} \lesssim_{p_1,p_2,q_1,q_2} \| f \|_{p_1,q_1} \| g \|_{p_2,q_2}. \]
\end{theorem}
\begin{proof}
    Without loss of generality, assume $\| f \|_{p_1,q_1} = \| g \|_{p_2, q_2} = 1$. Perform horizontal layer cake decompositions of $f$ and $g$, writing $|f| \leq \sum_{k \in \ZZ} H_k \mathbf{I}_{E_k}$ and $|g| \leq \sum_{k \in \ZZ} H_k' \mathbf{I}_{F_k}$, where $|E_k|, |F_k| \leq 2^k$. Then
    %
    \[ |fg| \leq \sum_{k,k' \in \ZZ} H_k H_k' \mathbf{I}_{E_k \cap F_{k'}} \]
    %
    For each fixed $k$, $|E_{k + m} \cap F_m| \leq 2^m$, and so
    %
    \begin{align*}
        \left\| \sum_{m \in \ZZ} H_{k + m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q} &\lesssim_{p,q} \left( \sum_{m \in \ZZ} [H_{k+m} H_m' 2^{m/p}]^q \right)^{1/q}\\
        &= \left( \sum_{m \in \ZZ} \left[ (H_{k+m} 2^{m/p_1}) (H_m 2^{m/p_2}) \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m \in \ZZ} [H_{k+m} 2^{m/p_1} ]^{q_1} \right)^{1/q_1} \left( \sum_{m \in \ZZ} [H_m' 2^{m/p_2}]^{q_2} \right)^{1/q_2}\\
        &\lesssim_{p,q,p_1,q_1,p_2,q_2} 2^{-k/p_1}\\
    \end{align*}
    %
    Summing over $k > 0$ gives that
    %
    \[ \left\| \sum_{k \geq 0} \sum_{m \in \ZZ} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\| \lesssim_{p,q,p_1,q_1,p_2,q_2} 1 \]
    %
    By the quasitriangle inequality, it now suffices to obtain a bound
    %
    \[ \left\| \sum_{k < 0} \sum_{m \in \ZZ} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q}. \]
    %
    This is done similarily, but using the bound $|E_{k+m} \cap F_m| \leq 2^{k+m}$ instead of the other bound.
\end{proof}

\begin{corollary}
    If $p > 1$ and $q > 0$, $L^{p,q}(X) \subset L^1_{\text{loc}}(X)$.
\end{corollary}
\begin{proof}
    Let $E$ have finite measure and let $f \in L^{p,q}(X)$. Then the H\"{o}lder's inequality for Lorentz spaces shows
    % 1 = 1/p + 1/p_2 = 1/q + 1/q_2
    %
    \[ \| f \|_{L^1(E)} = \| \mathbf{I}_E f \|_{L^1(X)} \lesssim_{p,q} |E|^{1 - 1/p} \| f \|_{p,q} < \infty. \qedhere \]
\end{proof}

Finally, we consider the duality of the $L^{p,q}$ norms. If $1 < p < \infty$, and $1 < q < \infty$, then $L^{p,q}(X)^* = L^{p',q'}(X)$. When $q = 1$ or $q = \infty$, things are more complex, but the following theorem often suffices. When $p = 1$, things get more tricky, so we leave this case out.

\begin{theorem}
    Let $1 < p < \infty$ and $1 \leq q < \infty$. Then if $f \in L^{p,q}(X)$,
    %
    \[ \| f \|_{p,q} \sim \sup \left\{ \int fg : \| g \|_{p',q'} \leq 1 \right\}. \]
\end{theorem}
\begin{proof}
    Without loss of generality, we may assume $\| f \|_{p,q} = 1$. We may perform a vertical layer cake decomposition, writing $f = \sum_{k \in \ZZ} f_k$, where $2^{k-1} \leq |f_k(x)| \leq 2^k$, is supported on a set with width $W_k$, and
    %
    \[ \left( (2^k W_k^{1/p})^q \right) \sim_{p,q} 1. \]
    %
    Define $a_k = 2^k W_k^{1/p}$, and set $g = \sum_{k \in \ZZ} g_k$, where $g_k(x) = a_k^{q-p} \text{sgn}(f_k(x)) |f_k(x)|^{p-1}$. Then
    %
    \begin{align*}
        \int f(x) g(x) &= \sum_{k \in \ZZ} \int f_k(x) g_k(x) = \sum_{k \in \ZZ} a_k^{q-p} \int |f_k(x)|^p\\
        &\gtrsim_p \sum_{k \in \ZZ} a_k^{q-p} W_k 2^{kp} = \sum_{k \in \ZZ} a_k^q \gtrsim_{p,q} 1.
    \end{align*}
    %
    We therefore need to show that $\| g \|_{p',q'} \lesssim 1$. We note $|g_k(x)| \lesssim a_k^{q-p} 2^{kp}$, and has width $W_k$. The gives a decomposition of $g$, but neither the height nor the widths necessarily in powers of two. Still, we can fix this since the heights increase exponentially; define
    %
    \[ H_k = \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2}. \]
    %
    Then $|g_k(x)| \lesssim_{p,q} H_k$, and $H_{k+1} \geq 2^{p/2} H_k$. In particular, if we pick $m$ such that $2^{mp/2} \geq 1$, then for any $l \leq m$, the sequence $H_{km + l}$, as $k$ ranges over values, increases dyadically, and so by the quasitriangle inequality for the $L^{p',q'}$ norm, and then the triangle inequality in $l^q$, we find
    % W_k = a_k^p/ 2^{kp}
    \begin{align*}
        \| g \|_{p',q'} &\lesssim_{m,p,q} \left( \sum [H_k W_k^{1/p'}]^{q'} \right)^{1/q'}\\
        &\lesssim \left( \sum_{k \in \ZZ} \left[ \left( \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2} \right) (a_k 2^{-k})^{p-1} \right]^{q'} \right)^{1/q'}\\
        &\lesssim_p \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} \sum_{l = 0}^\infty a_{k-l}^{q-p} 2^{-lp/2} \right]^{q'} \right)^{1/q'}\\
        &\lesssim \sum_{l = 0}^\infty 2^{-lp/2} \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'}.
    \end{align*}
    %
    Applying's H\"{o}lder's inequality shows
    %
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'} &\leq  \left( \sum_{k \in \ZZ} a_k^q \right)^{(p-1)/q} \left( \sum_{k \in \ZZ} a_{k-l}^q \right)^{(q-p)/q}\\
        &\lesssim_{p,q} \| f \|_{p,q}^{q-1} \lesssim_{p,q} 1. \qedhere
    \end{align*}
\end{proof}

\begin{remark}
    This technique shows that if $f = \sum f_k$, where $f_k$ is a quasi-step function with measure $W_k$ and height $2^{ck}$, then we can find $m$ such that $cm > 1$, and then consider the $m$ functions $f^1, \dots, f^m$, where $f_i = \sum f_{km + i}$. Then the functions $f_{km + i}$ have heights which are separated by powers of two, and so the quasi-triangle inequality implies
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_m \sum_{i = 1}^m \| f^i \|_{p,q}\\
        &\lesssim_{p,q} \sum_{i = 1}^m \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\lesssim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}
    \end{align*}
    %
    On the other hand,
    %
    \begin{align*}
        \| f \|_{p,q} &\gtrsim \max_{1 \leq i \leq m} \| f^i \|_{p,q}\\
        &\sim \max_{1 \leq i \leq m} \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\gtrsim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}.
    \end{align*}
    %
    Thus the dyadic layer cake decomposition still works in this setting.
\end{remark}

We remark that if $1 < p < \infty$ and $1 \leq q \leq \infty$, then for each $f \in L^{p,q}$, the value
%
\[ \sup \left\{ \int fg : \| g \|_{p',q'} \leq 1 \right\} \]
%
gives a norm on $L^{p,q}(X)$ which is comparable with the $L^{p,q}$ norm. In particular, this implies that for $p > 1$ and $q \geq 1$,
%
\[ \| f_1 + \dots + f_N \|_{p,q} \lesssim_{p,q} \| f_1 \|_{p,q} + \dots + \| f_N \|_{p,q}, \]
%
so that the triangle inequality has constants independent of $N$. We can also use a layer cake decomposition to get a version of the Stein-Weiss inequality for Lorentz norms.

\begin{theorem}
	For each $1 < q < \infty$, there is $\alpha(q) > 0$ such that for any functions $f_1, \dots, f_N$,
	%
	\[ \| f_1 + \dots + f_N \|_{1,q} \lesssim (\log N)^{\alpha(q)} \left( \| f_1 \|_{1,q} + \dots + \| f_N \|_{1,q} \right). \]
\end{theorem}
\begin{proof}
	For values $A$ and $B$ in this argument, we write $A \lessapprox B$ if there exists $\alpha$ such that $A \lesssim (\log N)^\alpha B$. Given $f_1, \dots, f_N$, write $f_i = \sum_{j = -\infty}^\infty f_{ij}$, where $f_{ij}$ has width $W_{ij}$ and height $2^j$. If we assume, without loss of generality, that $\| f_1 \|_{1,q} + \dots + \| f_N \|_{1,q} = 1$, then
	%
	\[ \sum_{i = 1}^N \left( \sum_{j = -\infty}^\infty (2^j W_{ij})^q \right)^{1/q} \lesssim_q 1 \]
	%
	Thus we want to show $\| f_1 + \dots + f_N \|_{1,q} \lessapprox_q 1$. Our first goal is to upper bound the measure of the set
	%
	\[ E = \{ x: 2^{k-1} < |f_1(x) + \dots + f_N(x)| \leq 2^k  \} \]
	%
	The measure of the set $E$ is upper bounded by the measure of the set
	%
	\[ E' = \left\{ x: 2^{k-2} < \left|\sum_{j = k - \lg(N)}^k f_{1j}(x) + \dots + f_{Nj}(x) \right| \leq 2^{k+1} \right\} \]
	%
	Applying the usual Stein-Weiss inequality, we have
	%
	\[ \left\| \sum_{i = 1}^N \sum_{j = k - \lg N}^k f_{ij} \right\|_{1,\infty} \lessapprox \sum_{i = 1}^N \sum_{j = k - \lg N}^k \| f_{ij} \|_{1,\infty} \lesssim \sum_{i = 1}^N \sum_{j = k - \lg N}^k \| f_{ij} \|_{1,\infty} \lesssim_q \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \]
	%
	Thus we conclude
	%
	\[ |E'| \lessapprox_q 2^{-k} \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \]
	%
	This implies that
	%
	\[ \| f_1 + \dots + f_N \|_{1,q} \lessapprox_q \left( \sum_{k = -\infty}^\infty \left( \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \right)^q \right)^{1/q}. \]
	%
	Applying Minkowski's inequality, we conclude
	%
	\begin{align*}
		\left( \sum_{k = -\infty}^\infty \left( \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \right)^q \right)^{1/q} &\lesssim \sum_{i = 1}^N \left( \sum_{k = -\infty}^\infty \left( \sum_{j = k - \lg N}^k W_{ij 2^j} \right)^q \right)^{1/q}\\
		&\lessapprox \sum_{i = 1}^N \left( \sum_{k = -\infty}^\infty \sum_{j = k - \lg N}^k W_{ij}^q 2^{qj} \right)^{1/q}\\
		&\lessapprox \sum_{i = 1}^N \left( \sum_{j = -\infty}^\infty W_{ij}^q 2^{qj} \right)^{1/q} \lesssim 1. \qedhere
	\end{align*}
\end{proof}

\begin{comment}

\section{Normability of the Lorentz Spaces}

Though the Lorentz norms do not satisfy the triangle inequality, the space $L^{p,q}(X)$ is still a `Banach-able' space when $p > 1$, and $q \geq 1$. First off, the standard proof shows the norm gives a complete quasimetric, since a Cauchy sequence in the $L^{p,q}$ norm converges to a function almost everywhere, which is easily verified to have finite $L^{p,q}$ norm. The easiest way to define a norm is to through the decreasing rearrangement.

\begin{lemma}
    For any measurable set $E$,
    %
    \[ \int_E |f(x)|\; dx \leq \int_0^{|E|} f^*(t)\; dt. \]
    %
    and
    %
    \[ \int_{\{ |f(x)| > t \}} |f(x)|\; dx = \int_0^{F(t)} f^*(t)\; dt. \]
\end{lemma}
\begin{proof}
    If $g \leq f$, $g^* \leq f^*$. Thus $(\chi_E f)^* \leq f^*$, so
    %
    \[ \int_E |f(x)|\; dx = \int \chi_E |f(x)| = \int_0^\infty (\chi_E f)^*(t)\; dt = \int_0^{|E|} (\chi_E f)^*(t)\; dt \leq \int_0^{|E|} f^*(t)\; dt. \]
    %
    On the other hand, $(\chi_E f)^* = f^*$ when $E = \{ |f(x)| > t \}$, which gives the second equality.
\end{proof}

For a function $f$ and $t > 0$, we define a family of averages
%
\[ m(t) = \frac{1}{t} \int_0^t f^*(t)\; dt. \]
%
For any fixed $t > 0$, the map $f \mapsto m(t)$ is a norm. Provided our measure space is non-atomic, we have
%
\[ m(t) = \sup_{|E| \leq t} \int_E |f(x)|\; d\mu. \]
%
We define
%
\[ \vvvert f \vvvert_{p,q} = \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} \]
and
%
\[ \vvvert f \vvvert_{p,\infty} = \sup t^{1/p} m(t). \]
%
For $q \geq 1$, each of these functions is a norm, simply because the function $m$ is a norm. On the other hand, since $f^*$ is decreasing, $f^*(t) \leq m(t)$ for all $t$, which shows $\vvvert f \vvvert_{p,q} \geq \| f \|_{p,q}$. If $p = 1$ and $q < \infty$, if $\vvvert f \vvvert_{1,q} < \infty$, then $f = 0$, so these norms are effectively useless. If $q = \infty$, then
%
\[ \vvvert f \vvvert_{1,\infty} = \| f^* \|_{L^1[0,\infty)} = \| f \|_1, \]
%
and therefore doesn't measure the correct norm. But in all other cases, i.e. for $p > 1$ and $q \geq 1$, the norm is comparable to the $L^{p,q}$ norm.

\begin{theorem}
    If $p > 1$,
    %
    \[ \vvvert f \vvvert_{p,q} \leq \frac{p}{p-1} \| f \|_{p,q}. \]
\end{theorem}
\begin{proof}
    We utilize a \emph{Hardy's inequality} technique, which shows that the $L^p$ norm of the averages of a function are comparable to the $L^p$ norm of the function. Applying Minkowski's integral inequality, we conclude that
    %
    \begin{align*}
        \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} &= \left( \frac{q}{p} \int_0^\infty \left( \int_0^1 t^{1/p} f^*(ts)\; ds \right)^q\; \frac{dt}{t} \right)^{1/q}\\
        &\leq \int_0^1 \left( \int_0^\infty \frac{q}{p} (t^{1/p} f^*(ts))^q\; \frac{dt}{t} \right)^{1/q}\; ds\\
        &\leq \left( \int_0^1 s^{- 1/p}\; ds \right) \left( \frac{q}{p} \int_0^\infty (t^{1/p} f^*(t))^q\; \frac{dt}{t} \right)^{1/q}\\
        &\leq \frac{1}{1 - 1/p} \| f \|_{p,q} = \frac{p}{p - 1} \| f \|_{p,q}.
    \end{align*}
    %
    For $q = \infty$, and $t > 0$, we have
    %
    \begin{align*}
        t^{1/p} m(t) &= t^{1/p - 1} \int_0^t f^*(t)\\
        &\leq (\sup_{s > 0} s^{1/p} f^*(s)) t^{1/p - 1} \int_0^t t^{-1/p}\\
        &= \frac{1}{1 - 1/p} \| f \|_{p,\infty} = \frac{p}{p-1} \| f \|_{p,\infty}.
    \end{align*}
    %
    since $t$ was arbitrary, this gives the required bound.
\end{proof}

\end{comment}

\section{Mixed Norm Spaces}

Given two measure spaces $X$ and $Y$, we can form the product measure space $X \times Y$. If we have a norm space $V$ of functions on $X$, with norm $\| \cdot \|_V$ and a norm space $W$ of functions on $Y$, with norm $\| \cdot \|_W$, we can consider a `product norm'; for each function $f$ on $X \times Y$, we can consider the function $y \mapsto \| f(\cdot,y) \|_V$, and take the norm of this function over $Y$, i.e. $\| \| f(\cdot,y) \|_V \|_W$. The most important case of this process is where we fix $0 < p,q \leq \infty$, and consider
%
\[ \| f \|_{L^p(X) L^q(Y)} = \left( \int \left( \int |f(x,y)|^p \; dx \right)^{q/p}\; dy \right)^{1/q}. \]
%
Similarly, we can define $\| f \|_{L^q(Y) L^p(X)}$. We have a duality theory here; for each $1 \leq p,q < \infty$ and any $f$ with $\| f \|_{L^p(X) L^q(Y)} < \infty$, the standard $L^p$ and $L^q$ duality gives
%
\[ \| f \|_{L^p(X) L^q(Y)} = \sup \left\{ \int_{X \times Y} f(x,y) h(x,y)\; dx\;dy : \| h \|_{L^{p^*}(X) L^{q^*}(Y)} \leq 1 \right\}. \]
%
It is often important to interchange norms, and we find the biggest quantity obtained by interchanging norms is always obtained with the largest exponents on the inside.

\begin{theorem}
	If $q \geq p \geq 1$, $\| f \|_{L^p(X) L^q(Y)} \leq \| f \|_{L^q(Y) L^p(X)}$.
\end{theorem}
\begin{proof}
  If $p = q$, then the Fubini-Tonelli theorem implies that
  %
  \[ \| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)}. \]
  %
  If $p = 1$, then this result is precisely the Minkowski inequality. We now apply complex interpolation to obtain the result in general. In fact, a simple variation of the proof of Riesz-Thorin using the duality established above gives the result.
\end{proof}

Two special cases are that pointwise maxima dominate individual maxima
%
\[ \sup_n \| f_n \|_{L^p(X)} \leq \left\| \sup_n f_n \right\|_{L^p(X)} \]
%
and that we have the triangle inequality
%
\[ \left\| \sum_n f_n \right\|_{L^p(X)} \leq \sum_n \| f_n \|_{L^p(X)} \]
%
for $p \geq 1$.

It turns out that if $q > p$ and $\| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)}$, then $|f|$ is a tensor product. Thus switching mixed norms is likely only efficient if the functions we are working with are close to tensor products.

\begin{theorem}
  Suppose $q > p$, $f$ is a function on $X \times Y$, and
  %
  \[ \| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)} < \infty. \]
  %
  Then there exists $f_1(x)$ and $f_2(y)$ such that for any $x \in X$ and $y \in Y$, $|f(x,y)| = |f_1(x)| |f_2(y)|$.
\end{theorem}
\begin{proof}
  Expanding this equation out, we conclude
  %
  \[ \left( \int_Y \left( \int_X |f(x,y)|^p\; dx \right)^{q/p}\; dy \right)^{1/q} = \left( \int_X \left( \int_Y |f(x,y)|^q\; dy \right)^{p/q}\; dx \right)^{1/p}. \]
  %
  Setting $g(x,y) = |f(x,y)|^p$, we see that Minkowski's integral inequality is tight for $g$, i.e.
  %
  \[ \left( \int_Y \left( \int_X |g(x,y)|\; dx \right)^{q/p}\; dy \right)^{p/q} = \left( \int_X \left( \int_Y |g(x,y)|^{q/p}\; dy \right)^{p/q}\; dx \right). \]
  %
  Thus it suffices to show that to show the theorem for $p = 1$ and $q > 1$. Recall the standard proof of Minkowski's inequality, i.e. that by H\"{o}lder's inequality
  %
  \begin{align*}
    \int_Y \left( \int_X |f(x,y)|\; dx \right)^p\; dy &= \int_X \left[ \int_Y |f(x_1,y)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^{p-1}\; dy \right]\; dx_1\\
    &\leq \int_X \left[ \left( \int_Y |f(x_1,y)|^p\; dy \right)^{1/p} \left( \int_Y \left( \int_X |f(x_2,y)|\; dx_2 \right)^{(p-1)p^*}\; dy \right)^{1/p^*} \right]\; dx_1 \\
    &= \left[ \int_X \left( \int_Y |f(x_1,y)|^p\; dy \right)^{1/p}\; dx_1 \right] \left[ \int_Y \left( \int_X |f(x_2,y)|\; dx_2 \right)^p \right]^{1/p^*}.
  \end{align*}
  %
  and rearranging gives Minkowski's inequality. If this inequality is tight, then our application of H\"{o}lder's inequality is tight for almost every $x_1 \in X$. Since $\int |f(x_2,y)|\; dx_2 \neq 0$ for all $y$ unless $f = 0$, it follows that there exists $\lambda(x_1)$ for almost every $x_1 \in X$ such that for almost every $y \in Y$,
  %
  \[ |f(x_1,y)|^p = |\lambda(x_1)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^{p^*(p-1)} = |\lambda(x_1)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^p. \]
  %
  Setting $f_1(x) = |\lambda(x)|^{1/p}$ and $f_2(y) = \int_X |f(x,y)|\; dx$ thus completes the proof.
\end{proof}

TODO: Show that if $q < p$ and $\| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^p(Y) L^q(X)} < \infty$, then $|f|$ is a tensor product. Thus interchanging norms is only a good idea if we think the worst case example in a problem is a tensor-product like function.

\section{Orlicz Spaces}

To develop the class of Orlicz spaces, we note that if $\| f \|_p \leq 1$, and we set $\Phi(t) = t^p$, then
%
\[ \int \Phi \left( |f(x)| \right)\; dx = 1. \]
%
More generally, given any function $\Phi: [0,\infty) \to [0,\infty)$, we might ask if we can define a norm $\| \cdot \|_\Phi$ such that if $\| f \|_\Phi \leq 1$, then
%
\[ \int \Phi \left( |f(x)| \right)\; dx = 1. \]
%
Since a norm would be homogenous, this would imply that if $\| f \|_\Phi \leq A$, then
%
\[ \int \Phi \left( \frac{|f(x)|}{A} \right)\; dx \leq 1. \]
%
If we want these norms to be monotone, we might ask that if $A < B$, then
%
\[ \int \Phi \left( \frac{|f(x)|}{B} \right)\; dx \leq \int \Phi \left( \frac{|f(x)|}{A} \right), \]
%
and the standard way to ensure this is to ask the $\Phi$ is an increasing function. To deal with the property that $\| 0 \| = 0$, we set $\Phi(0) = 0$. In order for $\| \cdot \|_\Phi$ to be a norm, the set of functions $\{ f : \| f \|_\Phi \leq 1 \}$ needs to be convex, and the standard way to obtain this is to assume that $\Phi$ is convex.

In short, we consider an increasing, convex function $\Phi$ with $\Phi(0) = 0$. We then define
%
\[ \| f \|_\Phi = \inf \left\{ A > 0 : \int \Phi \left( \frac{|f(x)|}{A} \right)\; dx \leq 1 \right\}. \]
%
This function is a norm on the space of all $f$ with $\| f \|_\Phi < \infty$. It is easy to verify that $\| f \|_\Phi = 0$ if and only if $f = 0$ almost everywhere, and that $\| \alpha f \|_\Phi = |\alpha| \| f \|_\Phi$. To justify the triangle inequality, we note that if
%
\[ \int \Phi \left( \frac{|f(x)|}{A} \right) \leq 1 \quad\text{and} \quad \int \Phi \left( \frac{|f(x)|}{B} \right) \leq 1, \]
%
then applying convexity gives
%
\begin{align*}
    \int \Phi \left( \frac{|f(x) + g(x)|}{A + B} \right) &\leq \int \Phi \left( \frac{|f(x)| + |g(x)|}{A + B} \right)\\
    &\leq \int \left( \frac{A}{A + B} \right) \Phi \left( \frac{|f(x)|}{A} \right) + \left( \frac{B}{A + B} \right) \Phi \left( \frac{|g(x)|}{B} \right) \leq 1.
\end{align*}
%
Thus we obtain the triangle inequality.

The spaces $L^p(X)$ for $p \in [1,\infty)$ are Orlicz spaces with $\Phi(t) = t^p$. The space $L^\infty(X)$ is not really an Orlicz space, but it can be considered as the Orlicz function with respect to the `convex' function
%
\[ \Phi(t) = \begin{cases} \infty & t > 1, \\ t & t \leq 1. \end{cases} \]
%
More interesting examples of Orlicz spaces include
%
\begin{itemize}
    \item $L \log L$, given by the Orlicz norm induced by $\Phi(t) = t \log(2 + t)$.
    \item $e^L$, defined with respect to $\Phi(t) = e^t - 1$.
    \item $e^{L^2}$, defined with respect to $\Phi(t) = e^{t^2} - 1$.
\end{itemize}
%
One should not think too hard about the constants in the functions defined above, which are included to make $\Phi(0) = 0$. When we are dealing with a finite measure space, they are irrelevant.

\begin{lemma}
  If $\Phi(x) \lesssim \Psi(x)$ for all $x$, then $\| f \|_{\Phi(L)} \lesssim \| f \|_{\Psi(L)}$. If $X$ is finite, and $\Phi(x) \lesssim \Psi(x)$ for sufficiently large $x$, then $\| f \|_{\Phi(L)} \lesssim \| f \|_{\Psi(L)}$.
\end{lemma}
\begin{proof}
  The first proposition is easy, and we now deal with the finite case. We note that the condition implies that for each $\varepsilon > 0$, there exists $C_\varepsilon$ such that $\Phi(x) \leq C_\varepsilon \Psi(x)$ if $|x| \geq \varepsilon$. Assume that $\| f \|_{\Psi(L)} \leq 1$, so that
  %
  \[ \int \Psi(|f(x)|)\; dx \leq 1. \]
  %
  Then convexity implies that for each $A > 0$,
  %
  \[ \int \Psi \left( \frac{|f(x)|}{A} \right) \leq \frac{1}{A}. \]
  %
  Thus
  %
  \begin{align*}
    \int \Phi\left( \frac{|f(x)|}{A} \right)\; dx &\leq \Phi(\varepsilon) |X| + C_\varepsilon \int \Psi \left( \frac{|f(x)|}{A} \right)\\
    &\lesssim \Phi(\varepsilon) |X| + \frac{C_\varepsilon}{A}.
  \end{align*}
  %
  If $\Phi(\varepsilon) \leq 2/|X|$, and $A \geq 2C_\varepsilon$, then we conclude that
  %
  \[ \int \Phi\left( \frac{|f(x)|}{A} \right)\; dx \leq 1. \]
  %
  Thus $\| f \|_{\Phi(L)} \lesssim 1$.
\end{proof}

The Orlicz spaces satisfy an interesting duality relation. Given a function $\Phi$, which we assume is \emph{superlinear}, in the sense that $\Phi(x)/x \to \infty$ as $x \to \infty$, define it's \emph{Young dual}, for each $y \in [0,\infty)$, by
%
\[ \Psi(y) = \sup \{ xy - \Phi(x) : x \in [0,\infty) \}. \]
%
Then $\Psi$ is the smallest function such that $\Phi(x) + \Psi(y) \geq xy$ for each $x,y$. This quantity is finite for each $y$ because $\Phi$ is superlinear; for each $y \geq 0$, there exists $x(y)$ such that $\Phi(x(y)) \geq xy$, and thus the maximum of $xy - \Phi(x)$ is attained for $x \leq x(y)$. In particular, since $\Phi$ is continuous, the supremum is actually attained. Conversely, for each $x_0 \in [0,\infty)$, convexity implies there exists a largest $y$ such that the line $y(x - x_0) + f(x_0) \leq f(x)$ for all $x \in [0,\infty)$. This means that $\Psi(y) = x_0y - x_0$.

We note also that $\Psi(0) = 0$, and $\Psi$ is increasing. Most importantly, the function is convex. Given any $y,z \in [0,\infty)$, and any $x \in [0,\infty)$,
%
\begin{align*}
  x (\alpha y + (1 - \alpha) z) - \Phi(x) &\leq \alpha(xy - \Phi(x)) + (1 - \alpha)(xz - \Phi(x))\\
  &\leq \alpha \Psi(y) + (1 - \alpha) \Psi(z).
\end{align*}
%
Taking infimum over all $x$ gives convexity. The function $\Psi$ is also superlinear, since for any $x \in [0,\infty)$,
%
\[ \lim_{y \to \infty} \frac{\Psi(y)}{y} \geq \lim_{y \to \infty} \frac{xy - \Phi(x)}{y} = x. \]
%
In particular, we can consider the Young dual of $\Psi$.

\begin{lemma}
  If $\Psi$ is the Young dual of $\Phi$, then $\Phi$ is the Young dual of $\Psi$.
\end{lemma}
\begin{proof}
  $\Pi$ is the smallest function such that $\Pi(x) + \Psi(y) \geq xy$. Since $\Phi(x) + \Psi(y) \geq xy$ for each $x$ and $y$, we conclude that $\Pi(x) \leq \Phi(x)$ for each $x$. For each $x$, there exists $y$ such that $\Psi(y) = yx - \Phi(x)$. But this means that $\Phi(x) = yx - \Psi(y) \leq \Pi(x)$.
\end{proof}

Given the Orlicz space $\Phi(L)$ for superlinear $\Phi$, we can consider the Orlicz space $\Psi(L)$, where $\Psi$ is the Young dual of $\Phi$. The inequality $xy \leq \Phi(x) + \Psi(y)$, then
%
\[ |f(x) g(x)| \leq \Phi(|f(x)|) + \Psi(|g(x)|), \]
%
so if $\| f \|_{\Phi(L)}, \| g \|_{\Psi(L)} \leq 1$, then
%
\[ \left| \int f(x) g(x) \right| \leq \int |f(x)| |g(x)| \leq \int \Phi(|f(x)|) + \int \Psi(|g(x)|) \leq 2. \]
%
Thus in general, we have
%
\[ \left| \int f(x) g(x) \right| \leq 2 \| f \|_{\Phi(L)} \| g \|_{\Psi(L)}, \]
%
a form of H\"{o}lder's inequality. The duality between convex functions extends to a duality between the Orlicz spaces.

\begin{theorem}
  For any superlinear $\Phi$ with Young dual $\Psi$,
  %
  \[ \| f \|_{\Phi(L)} \sim \sup \left\{ \int fg : \| g \|_{\Psi(L)} \leq 1 \right\}. \]
\end{theorem}
\begin{proof}
  Without loss of generality, assume $\| f \|_{\Phi(L)} = 1$. The version of H\"{o}lder's inequality proved above shows that
  %
  \[ \| f \|_{\Phi(L)} \lesssim 1. \]
  %
  Conversely, for each $x$, we can find $g(x)$ such that $f(x) g(x) = \Phi(|f(x)|) + \Psi(|g(x)|$. Provided $\| g \|_{\Psi(L)} < \infty$, we have
  %
  \[ \int fg = \int \Phi(|f(x)|) + \int \Psi(|g(x)|) \geq 1 + \| g \|_{\Psi(L)}. \]
  %
  Assuming $f \in L^\infty(X)$, we may choose $g \in L^\infty(X)$. For such a choice of function, $\| g \|_{\psi(L)} < \infty$, which implies the result. Taking an approximation argument then gives the result in general.
\end{proof}

Let us now consider some examples of duality.

\begin{example}
  If $\Phi(x) = x^p$, for $p \geq 1$, and $1 = 1/p + 1/q$, then it's Young dual $\Psi$ satisfies
  % q = p/(p-1)
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - x^p = y^{1 + q/p} / p^{q/p} - y^q / p^q = y^q [p^{-q/p} - p^{-q}].
  \end{align*}
  %
  Thus the Young dual corresponds, up to a constant, to the conjugate dual in the $L^p$ spaces.
\end{example}

\begin{example}
  Suppose $X$ has finite measure. If $\Phi(t) = e^t - 1$, then it's dual satisfies, for large $y$,
  %
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - (e^x - 1)\\
    &= y \log y - (y - 1) \sim y \log y.
  \end{align*}
  %
  This is comparable to $y \log (y + 2)$ for large $y$. Thus $L \log L$ is dual to $e^L$.
\end{example}

\begin{example}
  Suppose $X$ has finite measure. If $\Phi(x) = e^{x^2} - 1$, then for $y \geq 2$,
  %
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - (e^{x^2} - 1) \sim y \log(y/2)^{1/2}.
  \end{align*}
  %
  Thus the dual of $e^{L^2}$ is the space $L (\log L)^{1/2}$.
\end{example}

There is a generalization of both the Lorentz spaces and the Orlicz spaces, known as the Lorentz-Orlicz spaces, but these come up so rarely in analysis that we do not dwell on these norms.
















\chapter{Interpolation Theory}

One of the most fundamental tools in the `hard style' of mathematical analysis, involving explicit quantitative estimates on quantities that arises in basic methods of mathematics, is the theory of interpolation. The main goal of interpolation is to take two estimates, and blend them together to form a family of intermediate estimates. Often each estimate will focus on one component of the problem at hand (an estimate in terms of the decay of the function at $\infty$, an estimate involving the growth of the derivative, or the low frequency the function is, etc). By interpolating, we can optimize and obtain an estimate which simultaneously takes into account multiple features of the function. As should be expected, our main focus will be on the \emph{interpolation of operators}.

\section{Convex Interpolation}

The most basic way to interpolate is using the notion of convexity. Given two inequalities $A_0 \leq B_0$ and $A_1 \leq B_1$, for any parameter $0 \leq \theta \leq 1$, if we define the additive weighted averages $A_\theta = (1 - \theta) A_0 + \theta A_1$ and $B_\theta = (1 - \theta) B_0 + \theta B_1$, then we conclude $A_\theta \leq B_\theta$ for all $\theta$. Similarily, we can consider the weighted multiplicative averages $A_\theta = A_0^{1 - \theta} A_1^\theta$ and $B_\theta = B_0^{1 - \theta}B_1^\theta$, in which case we still have $A_\theta \leq B_\theta$. Note that the additive averages are obtained by taking the unique linear function between two values, and the multiplicative averages are obtained by taking the unique log-linear function between two values. In particular, if $A_\theta$ is defined to be any convex function, then $A_\theta \leq (1 - \theta) A_0 + \theta A_1$, and if $B_\theta$ is logarithmically convex, so that $\log B_\theta$ is convex, then $B_\theta \leq B_0^{1 - \theta} B_1^\theta$. Thus convexity provides us with a more general way of interpolating estimates, which is what makes this property so useful in analysis, enabling us to simplify estimates.

\begin{example}
    For a fixed, measurable function $f$, the map $p \mapsto \| f \|_p$ is a log convex function. This statement is precisely H\"{o}lder's inequality, since the inequality
    %
    \[ \| f \|_{\theta p + (1 - \theta) q} \leq \| f \|_p^\theta \| f \|_{q}^{1-\theta} \]
    %
    says
    %
    \[ \| |f|^{\theta p} |f|^{(1 - \theta) q} \|_1^{1/(\theta p + (1 - \theta) q)} \leq \| f^{\theta p} \|_{1/\theta}^{\theta} \| f^{(1-\theta)q} \|_{1/(1-\theta)}^{1-\theta} \]
    %
    which is precisely H\"{o}lder's inequality. Note this implies that if $p_0 < p_\theta < p_1$, then $L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X)$.
\end{example}

\begin{example}
    The weak $L^p$ norm is log convex, because if $F(t) \leq A_0^{p_0}/t^{p_0}$, and $F(t) \leq A_1^{p_1}/t^{p_1}$, then we can apply scalar interpolation to conclude that if $p_\theta = (1 - \alpha) p_0 + \alpha p_1$,
    %
    \[ F(t) \leq \frac{A_0^{(1 - \alpha) p_0}A_1^{\alpha p_1}}{t^{(1 - \alpha)p_0 + \alpha p_1}} = \frac{A_\theta^{p_\theta}}{t^{p_\theta}} \]
    %
    where $p_\theta$ is the harmonic weighted average between $p_0$ and $p_1$, and $A_\theta$ the geometric weighted average. Using this argument, interpolating slightly to the left and right of $p_\theta$, we can conclude that if $p_0 < p_\theta < p_1$, then $L^{p_0,\infty}(X) \cap L^{p_1,\infty}(X) \subset L^{p_\theta}(X)$.
\end{example}

\section{Complex Interpolation}

Another major technique to perform an interpolation is to utilize the theory of complex analytic functions to obtain estimates. The core idea of this technique is to exploit the maximum principle, which says that bounding an analytic function at its boundary enables one to obtain bounds everywhere in the domain of the function. The next result, known as Lindel\"{o}f's theorem, is one of the fundamental examples of the application of complex analysis.

\begin{theorem}[The Three Lines Lemma]
    If $f$ is a holomorphic function on the strip $S = \{ z : \text{Re}(z) \in [a,b] \}$ and there exists constants $A,B,\delta > 0$ such that for all $z \in S$,
    %
    \[ |f(z)| \leq Ae^{Be^{(\pi - \delta)|z|}}. \]
    %
    Then the function $M: [a,b] \to [0,\infty]$ given by
    %
    \[ M(s) = \sup_{s \in \RR} |f(s + it)| \]
    %
    is log convex on $[a,b]$.
\end{theorem}
\begin{proof}
    By a change of variables, we can assume that $a = 0$, and $b = 1$, and we need only show that if there are $A_0, A_1 > 0$ such that
    %
    \[ |f(it)| \leq A_0 \quad\text{and}\quad |f(1 + it)| \leq A_1 \quad \text{for all $t \in \RR$}, \]
    %
    then for any $s \in [a,b]$ and $t \in \RR$,
    %
    \[ |f(s + it)| \leq A_0^{1 - s} A_1^s. \]
    %
    By replacing $f(z)$ with the function $A_0^{1-z} A_1^z f(z)$, we may assume without loss of generality that $A_0 = A_1 = 1$, and we must show that $\| f \|_{L^\infty(S)} \leq 1$. If $|f(s + it)| \to 0$ as $|t| \to \infty$, then for large $N$, we can conclude that $|f(s + it)| \leq 1$ for $s \in [a,b]$ and $|t| \geq N$. But then the maximum principle entails that $|f(s + it)| \leq 1$ for $s \in [a,b]$ and $|t| \leq N$, which completes the proof in this case. In the general case, for each $\varepsilon > 0$, define
    %
    \[ u_\varepsilon(z) = \exp(- 2 \varepsilon \sin((\pi - \varepsilon) z + \varepsilon/2)). \]
    %
    Then if $z = s + it$,
    %
    \[ |u_\varepsilon(z)| = \exp(- \varepsilon [e^{(\pi - \varepsilon) t} + e^{-(\pi - \varepsilon) t}] \sin((\pi - \varepsilon) s + \varepsilon/2)), \]
    %
    So, in particular, $|u_\varepsilon(z)| \leq 1$, and there exists a constant $C$ such that if $z \in S$,
    %
    \[ |u_\varepsilon(z)| \leq e^{- C \varepsilon^2 e^{(\pi - \varepsilon) |z|}} \]
    %
    Note that if $\varepsilon < \delta$, then as $|\text{Im}(z)| \to \infty$,
    %
    \[ |f(z) u_\varepsilon(z)| \leq A e^{B e^{(\pi - \delta) |z|} - C \varepsilon^2 e^{(\pi - \varepsilon) |z|} } \to 0. \]
    %
    Applying the previous case to the function $|f(z) u_\varepsilon(z)|$, we conclude that for any $\varepsilon > 0$,
    %
    \[ |f(z)| \leq \frac{1}{|u_\varepsilon(z)|}. \]
    %
    Thus
    %
    \[ |f(z)| \leq \lim_{\varepsilon \to 0} \frac{1}{|u_\varepsilon(z)|} = 1, \]
    %
    which completes the proof.
\end{proof}

\begin{remark}
    The function $e^{-ie^{\pi i s}}$ shows that the assumption of the three lines lemma is essentially tight. In particular, this means there is no family of holomorphic functions $g_\varepsilon$ which decays faster than double exponentially, and pointwise approximates the identity as $\varepsilon \to 0$.
\end{remark}

\begin{remark}
    Similar variants can be used to show that if $f$ is a holomorphic function on an annulus, then the supremum over circles centered around the origin is log convex in the radius of the circle (a result often referred to as the three circles lemma).
\end{remark}

\begin{example}
    Here we show how we can use the three lines lemma to prove that the $L^p$ norms are log convex. If $f = \sum a_n \chi_{E_n}$ is a simple function, then the function
    %
    \[ g(s) = \int |f|^s = \sum |a_n|^s |E_n| \]
    %
    is analytic in $s$, and satisfies the growth condition of the three lines lemma because each term of the sum is exponential in growth. Since $|g(s)| \leq |g(\sigma)|$, the three lines lemma implies that $g$ is log convex on the real line. By normalizing the function $f$ and the underlying measure, given $p_0$, $p_1$, we may assume $\| f \|_{p_0} = \| f \|_{p_1} = 1$, and it suffices to prove that $\| f \|_{p_\theta} \leq 1$ for all $p_\theta \in [p_0, p_1]$. But the log convexity of $g$ guarantees this is true, since $|g(p)| = \| f \|_p^p$. A standard limiting argument then gives the inequality for all functions $f$.
\end{example}

\begin{example}
    Let $f$ be a holmomorphic function on a strip $S = \{ z : \text{Re}(z) \in [a,b] \}$, such that if $z = a + it$, or $z = b + it$, for some $t \in \RR$,
    %
    \[ |f(z)| \leq C_1 (1 + |z|)^\alpha. \]
    %
    Then there exists a constant $C'$ such that for any $z \in S$,
    %
    \[ |f(z)| \leq C_2 (1 + |z|)^\alpha. \]
\end{example}
\begin{proof}
    The function
    %
    \[ g(z) = \frac{f(z)}{(1 + z)^\alpha} \]
    %
    is holomorphic on $S$, and if $z = a + it$ or $z = b + it$,
    %
    \[ |g(z)| \leq \frac{C_1 (1 + |z|)^\alpha}{|1 + z|^\alpha} \lesssim 1. \]
    %
    Thus the three lines lemma implies that $|g(z)| \lesssim 1$ for all $z \in S$, so
    %
    \[ |f(z)| \lesssim |1 + z|^\alpha \lesssim (1 + |z|)^\alpha. \qedhere \]
\end{proof}

\section{Interpolation of Operators}

A major part of modern harmonic analysis is the study of operators, i.e. maps from function spaces to other function spaces. We are primarily interested in studying \emph{linear operators}, i.e. operators $T$ such that $T(f + g) = T(f) + T(g)$, and $T(\alpha f) = \alpha T(f)$, and also \emph{sublinear operators}, such that $|T(\alpha f)| = |\alpha| |T(f)|$ and $|T(f + g)| \leq |Tf| + |Tg|$. Even if we focus on linear operators, it is still of interest to study sublinear operators because one can study the \emph{uniform boundedness} of a family of operators $\{ T_k \}$ by means of the function $T^*(f)(x) = \max (T_k f)(x)$. This is the method of \emph{maximal functions}. Another important example are the $l^p$ sums
%
\[ (S^p f)(x) = \left( \sum |T_k(x)|^p \right). \]
%
These two examples are specific examples where we have a family of operators $\{ T_y \}$, indexed by a measure space $Y$, and we define an operator $S$ by taking $Sf$ to be the norm of $\{ T_y f \}$ in the variable $y$.

Here we address the most basic case of operator interpolation. As we vary $p$, the $L^p$ norms provide different ways of measuring the height and width of functions. Let us consider a simple example. Suppose that for an operator $T$, we have a bound
%
\[ \| Tf \|_{L^1(Y)} \leq \| f \|_{L^1(X)} \quad\text{and}\quad \| Tf \|_{L^\infty(Y)} \leq \| f \|_{L^\infty(X)}. \]
%
The first inequality shows that the width of $Tf$ is controlled by the width of $f$, and the second inequality says the height of $Tf$ is controlled by the height of $f$. If we take a function $f \in L^p(X)$, for some $p \in (1,\infty)$, then we have some control over the height of $f$, and some control of the width. In particular, this means we might expect some control over the width and height of $Tf$, i.e. for each $p$, a bound
%
\[ \| Tf \|_{L^p(Y)} \leq \| f \|_{L^p(X)}. \]
%
This is the idea of interpolation on the $L^p(X)$ spaces.

\section{Complex Interpolation of Operators}

The first theorem we give is the Riesz-Thorin theorem, which utilizes complex interpolation to give such a result. In the next theorem, we work with a linear operator $T$ which maps simple functions $f$ on a measure space $X$ to functions on a measure space $Y$. For the purposes of applying duality, we make the mild assumption that for each simple function $g$,
%
\[ \int |(Tf)(y)| |g(y)|\; dy < \infty. \]
%
Our goal is to obtain $L^p$ bounds on the function $T$. The Hahn-Banach theorem then guarantees that $T$ has a unique extension to a map defined on all $L^p$ functions.

\begin{theorem}[Riesz-Thorin]
    Let $p_0,p_1 \in (0,\infty]$ and $q_0,q_1 \in [1,\infty]$. Suppose that
    %
    \[ \| Tf \|_{L^{q_0}(Y)} \leq A_0 \| f \|_{L^{p_0}(X)} \quad \text{and} \| Tf \|_{L^{q_1}(Y)} \leq A_1 \| f \|_{L^{p_1}(X)}.  \]
    %
    Then for any $\theta \in (0,1)$, if
    %
    \[ 1/p_\theta = (1 - \theta)/p_0 + \theta/p_1 \quad\text{and}\quad 1/q_\theta = (1 - \theta)/q_0 + \theta/q_1, \]
    %
    then
    %
    \[ \| Tf \|_{L^{q_\theta}(Y)} \leq A_\theta \| f \|_{L^{p_\theta}(X)}, \]
    %
    where $A_\theta = A_0^{1 - \theta} A_1^\theta$.
\end{theorem}
\begin{proof}
    If $p_0 = p_1$, the proof follows by the log convexity of the $L^p$ norms of a function. Thus we may assume $p_0 \neq p_1$, so $p_\theta$ is finite in any case of interest. By normalizing the measures on both spaces, we may assume $A_0 = A_1 = 1$. By duality and homogeneity, it suffices to show that for any two simple functions $f$ and $g$ such that $\| f \|_{q_\theta} = \| g \|_{q_\theta^*} = 1$,
    %
    \[ \left| \int_Y (Tf) g\; dy \right| \leq 1. \]
    %
    Our challenge is to make this inequality complex analytic so we can apply the three lines lemma. We write $f = F_0^{1 - \theta} F_1^\theta a$, where $F_0$ and $F_1$ are non-negative simple functions with $\| F_0 \|_{L^{p_0}(X)} = \| F_1 \|_{L^{p_1}(X)} = 1$, and $a$ is a simple function with $|a(x)| = 1$. Similarily, we can write $g = G_0^{1-\theta} G_1^\theta b$. We now write
    %
    \[ H(s) = \int_Y T(F_0^{1 - s} F_1^s a) G_0^{1-s} G_1^s b\; dy. \]
    %
    Since all functions involved here are simple, $H(s)$ is a linear combination of positive numbers taken to the power of $1-s$ or $s$, and is therefore obviously an entire function in $s$. Now for all $t \in \RR$, we have
    %
    \[ \| F_0^{1-it} F_1^{it} a \|_{L^{p_0}(X)} = \| F_0 \|_{L^{p_0}(X)} = 1, \]
    \[ \| G_0^{1-it} G_1^{it} b \|_{L^{q_0}(Y)} = \| G_0 \|_{L^{q_0}(X)} = 1. \]
    %
    Therefore
    %
    \begin{align*}
      |H(it)| &= \left| \int T(F_0^{1 - it} F_1^{it} a) G_0^{1-it} G_1^{it} b\; dy \right| \leq 1.
    \end{align*}
    %
    Similarily, $|H(1 + it)| \leq 1$ for all $t \in \RR$. An application of Lindel\"{o}f's theorem implies $|H(s)| \leq 1$ for all $s$. Setting $s = \theta$ completes the argument.
\end{proof}

If, for each $p,q$, we let $F(1/p,1/q)$ to be the operator norm of a linear operator $T$ viewed as a map from $L^p(X)$ to $L^q(Y)$, then the Riesz-Thorin theorem says that $F$ is a log-convex function. In particular, the set of $(1/p,1/q)$ such that $T$ is bounded as a map from $L^p(X)$ to $L^q(Y)$ forms a convex set. If this is true, we often say $T$ is of \emph{strong type} $(p,q)$.

\begin{example}
  For any two integrable functions $f,g \in L^1(\RR^d)$, we can define an integrable function $f * g \in L^1(\RR^d)$ almost everywhere by the integral formula
  %
  \[ (f * g)(x) = \int f(y) g(x-y)\; dy. \]
  %
  If $f \in L^1(\RR^d)$ and $g \in L^p(\RR^d) \cap L^1(\RR^d)$, for some $p \geq 1$, then Minkowski's integral inequality implies
  %
  \begin{align*}
      \| f * g \|_p &= \left( \int |(f * g)(x)|^p\; dx \right)^{1/p} \leq \int \left( \int |f(y)g(x-y)|^p dx\; \right)^{1/p} dy\\
      &= \int |f(y)| \| g \|_{L^p(\RR^d)} = \| f \|_{L^1(\RR^d)} \| g \|_{L^p(\RR^d)}.
  \end{align*}
  %
  H\"{o}lder's inequality implies that if $f \in L^p(\RR^d)$ and $g \in L^q(\RR^d)$, where $p$ and $q$ are conjugates of one another, then
  %
  \begin{align*}
    \left| \int f(y) g(x-y)\; dy \right| \leq \int |f(y-x)| |g(x)| \leq \| f \|_{L^p(\RR^d)} \| g \|_{L^q(\RR^d)}.
  \end{align*}
    %
    Thus we have the bound
    %
    \[ \| f * g \|_{L^\infty(\RR^d)} \leq \| f \|_{L^p(\RR^d)} \| g \|_{L^q(\RR^d)}. \]
    %
    Now that these mostly trivial results have been proved, we can apply convolution. For each $f \in L^1(\RR^d) \cap L^p(\RR^d)$, we have a convolution operator $T: L^1(\RR^d) \to L^1(\RR^d)$ defined by $Tg = f * g$. We know that $T$ is of strong type $(1,p)$, and of type $(q,\infty)$, where $q$ is the harmonic conjugate of $p$, and $T$ has operator norm $1$ with respect to each of these types. But the Riesz Thorin theorem then implies that if $1/r = \theta + (1 - \theta)/q$, then $T$ is bounded as a map from $L^r(\RR^d)$ to $L^{p/\theta}(\RR^d)$ with operator norm one. Reparameterizing gives \emph{Young's convolution inequality}. Note that we never really used anything about $\RR^d$ here other than it's translational structure, and as such Young's inequality continues to apply in the theory of any modular locally compact group. In particular, the Haar measure $\mu$ on such a group is only defined up to a scalar multiple, and if we swap $\mu$ with $\alpha \mu$, for some $\alpha > 0$, then Young's inequality for this measure implies
    %
    \[ \lambda^{1 + 1/r} \| f * g \|_r = \lambda^{1/p + 1/q} \| f \|_p \| g \|_p \]
    %
    which is a good way of remembering that we must have $1 + 1/r = 1/p + 1/q$. 
\end{example}

\begin{example}
Let $X$ be a measure space with $\sigma$ algebra $\Sigma_0$, and let $\Sigma \subset \Sigma_0$ be a $\sigma$ finite sub $\sigma$ algebra. Then $L^2(X,\Sigma)$ is a closed subspace of $L^2(X,\Sigma_0)$, and so there is an orthogonal projection operator $\EE(\cdot|\Sigma): L^2(X,\Sigma_0) \to L^2(X,\Sigma)$, which we call the \emph{conditional expectation operator}. The properties of the projection operator imply that for any $f,g \in L^2(X, \Sigma_0)$,
%
\[ \int \EE(f|\Sigma) \overline{g} = \int f \overline{g} = \int \EE(f|\Sigma) \overline{\EE(g|\Sigma)}. \]
%
If $g \in L^2(X,\Sigma)$, then
%
\[ \int \EE(f|\Sigma) \overline{g} = \int f \overline{g}. \]
%
This gives a full description of $\EE(f|\Sigma)$. In particular, if $u \in L^\infty(X,\Sigma_0)$, then for each $g \in L^2(X,\Sigma)$
%
\[ \int \EE(uf|\Sigma) \overline{g} = \int f [u\overline{g}] = \int u \EE(f|\Sigma) \overline{g}. \]
%
Since this is true for all $g \in L^2(X,\Sigma)$, we find $\EE(uf|\Sigma) = u \EE(f|\Sigma)$. Moreover, if $0 \leq f \leq g$, then $\EE(f|\Sigma) \leq \EE(g|\Sigma)$. This is easy to see because if $f \geq 0$, and $F = \{ x : \EE(f|\Sigma) < 0 \}$, then if $|F| \neq 0$,
%
\[ 0 > \int \EE(f|\Sigma) \mathbf{I}_F = \int f \mathbf{I}_F \geq 0. \]
%
Thus $|F| = 0$, and so $\EE(f|\Sigma) \geq 0$ almost everywhere.

Like all other orthogonal projection operators, conditional expectation is a contraction in the $L^2$ norm, i.e. $\| \mathbf{E}(f|\Sigma) \|_{L^2(X)} \leq \| f \|_{L^2(X)}$. We now use interpolation to show that conditional expectation is strong $(p,p)$, for all $1 \leq p \leq \infty$. It suffices to prove the operator is strong $(1,1)$ and strong $(\infty,\infty)$. So suppose $f \in L^2(X,\Sigma_0) \cap L^\infty(X,\Sigma_0)$. If $|E| < \infty$, then $\mathbf{I}_E \in L^2(X)$, so
%
\[ |\EE(f|\Sigma)| \mathbf{I}_E = |\EE(\mathbf{I}_E f | \Sigma)| \leq \EE(\mathbf{I}_E |f| | \Sigma) \leq \| f \|_\infty \mathbf{E}(\mathbf{I}_E|\Sigma) = \| f \|_\infty \mathbf{I}_E. \]
%
Since $\Sigma$ is a sigma finite sigma algebra, we can take $E \to \infty$ to conclude $\| \EE(f|\Sigma) \|_\infty \leq \| f \|_\infty$. The case $(1,1)$ can be obtained by duality, since conditional expectation is self adjoint, or directly, since if $f \in L^1(X,\Sigma_0) \cap L^2(X,\Sigma_0)$, then for any set $E \in \Sigma$ with $|E| < \infty$,
%
\[ \int |\EE(f|\Sigma)| \mathbf{I}_E \leq \int \EE(|f||\Sigma) \mathbf{I}_E = \int_E |f| \mathbf{I}_E \leq \| f \|_1. \]
%
Since $\Sigma$ is $\sigma$ finite, we can take $E \to \infty$ to conclude $\| \EE(f|\Sigma) \|_1 \leq \| f \|_1$. Thus the Riesz interpolation theorem implies that for each $1 \leq p \leq \infty$, $\| \EE(f|\Sigma) \|_p \leq \| f \|_p$.

Since $L^2(X,\Sigma_0)$ is dense in $L^p(X,\Sigma_0)$ for all $1 \leq p < \infty$, there is a unique extension of the conditional expectation operator from $L^p(X,\Sigma_0)$ to $L^p(X,\Sigma_0)$. For $p = \infty$, there are infinitely many extensions of the conditional expectation operator from $L^\infty(X,\Sigma_0)$ to $L^\infty(X,\Sigma_0)$. However, there is a \emph{unique} extension such that for each $f \in L^2(\Sigma_0)$ and $g \in L^\infty(\Sigma)$, $\EE(fg|\Sigma) = g \EE(f|\Sigma)$. This is because for any $E \in \Sigma$ with $|E| < \infty$, $\EE(f \mathbf{I}_E | \Sigma) = \mathbf{I}_E \EE(f|\Sigma)$ is uniquely defined since $f \mathbf{I}_E \in L^2(\Sigma_0)$, and taking $E \to \infty$ by $\sigma$ finiteness.

A simple consequence of the uniform boundedness of these operators on the various $L^p$ spaces is that if $\Sigma_1, \Sigma_2, \dots$ are a family of $\sigma$ algebras, and $\Sigma_\infty$ is the smallest $\sigma$ algebra containing all sets in $\bigcup_{i = 1}^\infty \Sigma_i$, then for each $1 \leq p < \infty$, and for each $f \in L^p(\Sigma_0)$, $\lim_{i \to \infty} \EE(f|\Sigma_i) = \EE(f|\Sigma_\infty)$. This is because the operators $\{ \EE(\cdot|\Sigma_i) \}$ are uniformly bounded. The limit equation holds for any simple function $f$ composed of sets in $\bigcup_{i = 1}^\infty \Sigma_i$, and a $\sigma$ algebra argument can then be used to show this family of simple functions is dense in $L^p(\Sigma_0)$.
\end{example}

It was an important observation of Elias-Stein that complex interpolation can be used not only with a single operator $T$, but with an `analytic family' of operators $\{ T_s \}$, one for each $s$, such that for each pair of simple functions $f$ and $g$, the function
%
\[ \int (T_s f)(y) g(y) \]
%
is analytic in $s$. Thus bounds on $T_{0+it}$ and $T_{1 + it}$ imply intermediary bounds on all other operators, provided that we still have at most doubly exponential growth. The next theorem gives an example application.

\begin{theorem}[Stein-Weiss Interpolation Theorem]
  Let $T$ be a linear operator, and let $w_0, w_1: X \to [0,\infty)$ and $v_0, v_1 : Y \to [0,\infty)$ be weights which are integrable on every finite-measure set. Suppose that
  %
  \[ \| Tf \|_{L^{q_0}(X,v_0)} \leq A_0 \| f \|_{L^{p_0}(X,w_0)}\quad\text{and}\quad \| Tf \|_{L^{q_1}(X,v_1)} \leq A_1 \| f \|_{L^{p_1}(X,w_0)}. \]
  %
  Then for any $\theta \in (0,1)$,
  %
  \[ \| Tf \|_{L^{q_\theta}(X,v_\theta)} \leq A_\theta \| f \|_{L^{p_\theta}(X,w_\theta)}, \]
  %
  where $w_\theta = w_0^{1-\theta} w_\theta$ and $v_\theta = v_0^{1-\theta} v_1^\theta$.
\end{theorem}
\begin{proof}
  Fix a simple function $f$ with $\| f \|_{L^{p_\theta}(X,w_\theta)}$. We begin with some simplifying assumptions. A monotone convergence argument, replacing $w_i(t)$ with
  %
  \[ w_i'(y) = \begin{cases} w_i(y) &: \varepsilon \leq w_i(t) \leq 1/\varepsilon, \\ 0 &: \text{otherwise}, \end{cases} \]
  %
  and then taking $\varepsilon \to 0$, enables us to assume without loss of generality that $w_0$ and $w_1$ are both bounded from below and bounded from above. Truncating the support of $Tf$ enables us to assume that $Y$ has finite measure. Since $f$ has finite support, we may also assume without loss of generality that $X$ has finite support, and by applying the dominated convergence theorem we may replace the weights $v_i$ with
  %
  \[ v_i'(x) = \begin{cases} v_i(x) &: \varepsilon \leq v_i(x) \leq 1/\varepsilon, \\ 0 &: \text{otherwise}, \end{cases} \]
  %
  and then take $\varepsilon \to 0$. Thus we can assume that the $v_i$ are bounded from above and below. Restricting to the support of $X$, we can also assume $X$ has finite measure.

  For each $s$, consider the operator $T_s$ defined by
  %
  \[ T_s f = w_0^{\frac{1-s}{q_0}} w_1^{\frac{s}{q_1}} T \left( f v_0^{- \frac{1-s}{p_0}} v_1^{-\frac{s}{p_1}} \right). \]
  %
  The fact that all functions involved are simple means that the family of operators $\{ T_s \}$ is analytic. Now for all $t \in \RR$
  %
  \[ \| T_{it} f \|_{L^{q_0}(Y)} = \| T f \|_{L^{q_0}(Y,w_0)} \leq A_0 \| f v_0^{-1/p_0} \|_{L^{p_0}(X,v_0)} = A_0 \| f \|_{L^{p_0}(X)}. \]
  %
  For similar reasons, $\| T_{1 + it} f \|_{L^{q_1}(Y)} \leq A_1 \| f \|_{L^{p_0}(X,v_0)}$. Thus the Stein variant of the Riesz-Thorin theorem implies that
  %
  \[ \| T_\theta f \|_{L^{q_\theta}(Y)} \leq A_\theta \| f \|_{L^{p_\theta}(X)}. \]
  %
  But this, of course, is equivalent to the bound we set out to prove.
\end{proof}

\section{Real Interpolation of Operators}

Now we consider the case of real interpolation. One advantage of real interpolation is that it can be applied to sublinear as well as linear operators, and requires weaker endpoint estimates that the complex case. A disadvantage is that, usually, the operator under study cannot vary, and we lose out on obtaining explicit bounds.

A strong advantage to using real interpolation is that the criteria for showing boundedness at the endpoints can be reduced considerably. Let us give names for the boundedness we will want to understand for a particular operator $T$.
%
\begin{itemize}
  \item We say $T$ is \emph{strong type} $(p,q)$ if $\| Tf \|_{L^q(Y)} \lesssim \| f \|_{L^p(X)}$.
  
  \item We say $T$ is \emph{weak type} $(p,q)$ if $\| Tf \|_{L^{q,\infty}(Y)} \lesssim \| f \|_{L^p(X)}$.

  \item We say $T$ is \emph{restricted strong type} $(p,q)$ if we have a bound
  %
  \[ \| Tf \|_{L^q(Y)} \lesssim HW^{1/p} \]
  %
  for any sub-step functions with height $H$ and width $W$. Equivalently, for any set $E$,
  %
  \[ \| T(\mathbf{I}_E) \|_{L^q(Y)} \lesssim |E|^{1/p}. \]

  \item We say $T$ is \emph{restricted weak type} $(p,q)$ if we have a bound
  %
  \[ \| Tf \|_{L^{q,\infty}(Y)} \lesssim HW^{1/p} \]
  %
  for all sub-step functions with height $H$ and width $W$. Equivalently, for any set $E$,
  %
  \[ \| T(\mathbf{I}_E) \|_{L^{q,\infty}(Y)} \lesssim |E|^{1/p}. \]
\end{itemize}
%
An important tool for us will be to utilize duality to make our interpolation argument `bilinear'. Let us summarize this tool in a lemma. Proving the lemma is a simple application of Theorem \ref{weakdualitytheorem}.

\begin{lemma}
  Let $0 < p < \infty$ and $0 < q < \infty$. Then an operator $T$ is restricted weak-type $(p,q)$ if and only if for any finite measure sets $E \subset X$ and $F \subset Y$, there is $F' \subset Y$ with $|F'| \geq \alpha |F|$ such that
  %
  \[ \int_{F'} |T(\mathbf{I}_E)| \lesssim_\alpha |E|^{1/p} |F|^{1-1/q}. \]
\end{lemma}

Scalar interpoation leads to a simple version of real interpolation, which we employ as a subroutine to obtain a much more powerful real interpolation principle.

\begin{lemma}
  Let $0 < p_0,p_1 < \infty$, $0 < q_0,q_1 < \infty$. If $T$ is restricted weak type $(p_0,q_0)$ and $(p_1,q_1)$, then $T$ is restricted weak type $(p_\theta,q_\theta)$ for all $\theta \in (0,1)$.
\end{lemma}
\begin{proof}
  By assumption, if $E \subset X$ and $F \subset Y$, then there is $F_0, F_1 \subset Y$ with $|F_i| \geq (3/4)|F|$ such that
  %
  \[ \int_{F_i} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_i} |F_i|^{1 - 1/q_i}. \]
  %
  If we let $F_\theta = F_0 \cap F_1$, then $|F_\theta| \geq |F|/2$, and for each $i$,
  %
  \[ \int_{F_\theta} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_i} |F_\theta|^{1 - 1/q_i}. \]
  %
  Scalar interpolation implies
  %
  \[ \int_{F_\theta} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_\theta} |F_\theta|^{1 - 1/q_\theta}, \]
  %
  and thus we have shown
  %
  \[ \| T(\mathbf{I}_E) \|_{q_\theta,\infty} \lesssim |E|^{1/p_\theta}. \]
  %
  This is sufficient to show $T$ is restricted weak type $(p_\theta,q_\theta)$.
\end{proof}

\begin{theorem}[Marcinkiewicz Interpolation Theorem]
  Let $0 < p_0,p_1 < \infty$, $0 < q_0,q_1 < \infty$, and suppose $T$ is restricted weak type $(p_i,q_i)$, with constant $A_i$, for each $i$. Then, for any $\theta \in (0,1)$, if $q_\theta > 1$, then for any $0 < r < \infty$, then
  %
  \[ \| Tf \|_{L^{q_\theta,r}(Y)} \lesssim A_\theta \| f \|_{L^{p_\theta,r}(X)}, \]
  %
  with implicit constants depending on $p_0, p_1, q_0$, and $q_1$.
\end{theorem}
\begin{proof}
  By scaling $T$, and the measures on $X$ and $Y$, we may assume that $\| f \|_{L^{p_\theta,r}(X)} \leq 1$, and that $T$ is restricted type $(p_i,q_i)$ with constant $1$, so that for any step function $f$ with height $H$ and width $W$,
  %
  \[ \| Tf \|_{L^{q_i,\infty}(Y)} \leq \| f \|_{L^{p_i}(X)}. \]
  %
  By duality, using the fact that $q_\theta > 1$, it suffices to show that for any simple function $g$ with $\| g \|_{L^{q_\theta',r'}(Y)} = 1$,
  %
  \[ \int |Tf| |g| \leq 1. \]
  %
  Using the previous lemma, we can `adjust' the values $q_0,q_1$ so that we can assume $q_0,q_1 > 1$. We can perform a horizontal layer decomposition, writing
  %
  \[ f = \sum_{i = -\infty}^\infty f_i, \quad\text{and}\quad g = \sum_{i = -\infty}^\infty g_i, \]
  %
  where $f_i$ and $g_i$ are sub-step functions with width $2^i$ and heights $H_i$ and $H_i'$ respectively, and if we write $A_i = H_i 2^{i/p_\theta}$, and $B_i = H_i' 2^{i/q_\theta}$, then
  %
  \[ \| A \|_{l^r(\ZZ)}, \| B \|_{l^{r'}(\ZZ)} \lesssim 1. \]
  %
  Applying the restricted weak type inequalities, we know for each $i$ and $j$,
  %
  \[ \int |Tf_i| |g_j| \lesssim H_i H_j \min_{k \in \{0,1\}} \left[ 2^{i/p_k + j(1 - 1/q_k)} \right]. \]

  Applying sublinearity (noting that really, the decomposition of $f$ and $g$ is finite, since both functions are simple). Thus
  %
  \begin{align*}
    \int |Tf| |g| &\leq \sum_{i,j} \int |Tf_i| |g_j|\\
    &\lesssim \sum_{i,j} H_i H_j' \min_{k \in \{0,1\}} \left[ 2^{i/p_k + j(1 - 1/q_k)} \right]\\
    &\lesssim \sum_{i,j} A_i B_j \min_{k \in \{ 0, 1 \}} \left[ 2^{i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k)} \right].
  \end{align*}
  %
  If $i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k) = \varepsilon(i + \lambda j)$, where $\varepsilon = (1/p_k - 1/p_\theta)$. We then have
  %
  \[ \sum_{i,j} A_i B_j \min_{k \in \{ 0, 1 \}} \left[ 2^{i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k)} \right] \sim \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \sum_i A_i B_{k - \lfloor i/\lambda \rfloor}. \]
  %
  Applying H\"{o}lder's inequality,
  %
  \begin{align*}
    \sum_i A_i B_{k - \lfloor i/\lambda \rfloor} &\leq \| A \|_{l^r(\ZZ)} \left( \sum_i |B_{k - \lfloor i/\lambda \rfloor}|^{r'} \right)^{1/r'}\\
    &\lesssim \lambda^{1/r'} \| A \|_{l^r(\ZZ)} \| B \|_{l^{r'}(\ZZ)} \lesssim 1.
  \end{align*}
  %
  Thus we conclude that
  %
  \begin{align*}
    \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \sum_i A_i B_{k - \lfloor i/\lambda \rfloor} &\lesssim \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \lesssim_\varepsilon 1. \qedhere
  \end{align*}
\end{proof}

There are many variants of the real interpolation method, but the general technique almost always remains the same: incorporate duality, decompose inputs, often dyadically, bound these decompositions, and then sum up.









\chapter{The Theory of Distributions}

The theory of distributions is a tool which enables us to justify formal manipulations which occur in harmonic analysis in such a way that we can avoid the technical issues which occur from having to interpret such manipulations analytically. For instance, the Fourier transform is only defined for functions in $L^1(\RR^d)$. On the other hand, the theory of tempered distributions enables us to define the Fourier transform of \emph{any} locally integrable function, and even more general functions. Thus distributions are a cornerstone to the formulation of many problems in modern harmonic analysis.

The path of modern analysis has extended analysis from the study of continuous and differentiable functions to measurable functions. The power of this approach is that we can study a very general class of functions. On the other hand, the more general the class of functions we work with, the more restricted the analytical operations we can perform. Nonetheless, $C^\infty_c(\RR^d)$ is dense in almost all the spaces of measurable functions we consider in basic analysis, and for such functions we can apply all the fundamental analytical operations in this region. One approach to studying the general class of measurable functions is to prove results for elements of $C_c^\infty(\RR^d)$, and then apply an approximation result to obtain the result for a wider class of measurable functions. The theory of distributions provides an alternate approach, using \emph{duality} to formally extend analytical operations on $C^\infty_c(\RR^d)$ to larger sets.

From the perspective of set theory, functions $f: X \to Y$ are a way of assigning values in $Y$ to each point in $X$. However, in analysis this is not often the way we view functions. For instance, in measure theory, we are used to identifying functions which are equal almost everywhere, so that functions in this setting are only defined `almost everywhere'. In distribution theory, we view functions as `integrands', whose properties are understand by integration against a family of `test functions'. For instance, recall that for $1 \leq p < \infty$, the dual space of $L^p(\RR^d)$ is $L^q(\RR^d)$. Thus we can think of elements $f \in L^q(\RR^d)$ as `integrands', whose properties can be understood by integration against elements of $L^p(\RR^d)$, i.e. through the linear functional on $L^p(\RR^d)$ given by
%
\[ \phi \mapsto \int_{\RR^d} f(x) \phi(x)\; dx. \]
%
Similarily, the dual space of $C(K)$, where $K$ is a compact topological space, is the space $M(K)$ of finite Borel measures on $K$. Thus we can think of measures as a family of `generalized functions'. For each measure $\mu \in M(K)$, we consider the linear functional on $C(K)$ through the map
%
\[ \phi \mapsto \int_K \phi(x) d\mu(x). \]
%
Notice that as we shrink the family of test functions, the resultant family of `generalized functions' becomes larger and larger, and so elements can behave more and more erratically. A distribution is a `generalized function' tested against functions in $C_c^\infty(\RR^d)$. Since most operations in analysis can be applied to elements of $C_c^\infty(\RR^d)$, we can then use duality to extend these operations to distributions. Moreover, since $C_c^\infty(\RR^d)$ is a very `tame' space of functions, distributions are a very general family of generalized functions.

\begin{remark}
  From the perspective of experimental physics, viewing functions as integrands is more natural than the pointwise sense. Indeed, points in space are idealizations which do not correspond to real world phenomena. One can never measure the exact value of some quantity of a function at a point, but rather only understand the function by looking at it's averages over a small region around that point. Thus the only physically meaningful properties of a `function' are those obtained by testing that function against test functions.
\end{remark}

\section{The Space of Test Functions}

We fix an open subset $\Omega$ of $\RR^n$, and let $C_c^\infty(\Omega)$ denote the family of all smooth functions on $\Omega$ with compact support. Our goal is to equip $C_c^\infty(\Omega)$ with a complete locally convex topology, so that we can consider the dual space $C_c^\infty(\Omega)^*$ of \emph{distributions} on $\Omega$. We could equip $C_c^\infty(\Omega)$ with a locally convex, metrizable topology with respect to the seminorms
%
\[ \| f \|_{C^n(\Omega)} = \max_{|\alpha| \leq n} \| D^\alpha f \|_{L^\infty(\Omega)} \]
%
However, the resultant topology on $C_c^\infty(\Omega)$ is not complete.

\begin{example}
    Let $\Omega = \RR$, pick a bump function $\phi \in C_c^\infty(\RR)$ supported on $[0,1]$ with $\phi > 0$ on $(0,1)$, and define
    %
    \[ \psi_m(x) = \phi(x-1) + \frac{\phi(x-2)}{2} + \dots + \frac{\phi(x-m)}{m} \]
    %
    Then $\psi_m$ is compactly supported on $[1,m]$, and Cauchy, since for $m_1 \geq m_0$,
    %
    \[ \| \psi_{m_0} - \psi_{m_1} \|_{C^n(\RR)} = \frac{ \max_{r \leq n} \| D^r \phi \|_{L^\infty(\RR^d)}}{m_0+1} \lesssim_n 1/m_0. \]
    %
    However, the sequence $\{ \psi_m \}$ does not converge to any element of $C_c^\infty(\RR)$, since the sequence converges uniformly to the function
    %
    \[ \psi(x) = \sum_{n = 1}^\infty \psi(x-n) \]
    %
    an element of $C^\infty(\RR)$ which is not compactly supported.
\end{example}

We instead assign $C_c^\infty(\Omega)$ a stronger locally convex topology which prevents convergent functions from `escaping a set'; the cost, however, is that the topology is no longer metrizable. The process we perform here is quite general and can be viewed as a way to construct the `categorical limit' of a family of complete, locally convex spaces. For each compact set $K \subset \Omega$, the subspace $C_c^\infty(K) \subset C_c^\infty(\Omega)$ is a complete metric space under the family of seminorms $\| \cdot \|_{C^n(K)}$. We consider a convex topology on $C_c^\infty(\Omega)$ by considering the family of sets $\{ \phi + W \}$ as a basis, where $\phi$ ranges over all elements of $C_c^\infty(\Omega)$, and $W$ ranges over all convex, balanced subsets of $C_c^\infty(\Omega)$ such that $W \cap C_c^\infty(K)$ is open in $C_c^\infty(K)$ for each $K \subset \Omega$.

\begin{theorem}
    This gives a basis of a Hausdorff topology on $C_c^\infty(\Omega)$.
\end{theorem}
\begin{proof}
    If $\phi_1 + W_1$ and $\phi_2 + W_2$ both contain $\phi$, then $\phi - \phi_1 \in W_1$ and $\phi - \phi_2 \in W_2$. The functions $\phi, \phi_1$, and $\phi_2$ are all supported on some compact set $K$. By continuity of multiplication on $C_c^\infty(K)$, and the fact that $W_n \cap C_c^\infty(K)$ is open, there is a small constant $\delta$ such that $\phi - \phi_n \in (1 - \delta) W_n$ for each $n \in \{ 1, 2 \}$. The convexity of the $W_n$ implies that $\phi - \phi_n + \delta W_n \subset W_n$. But then $\phi + \delta W_n \subset \phi_n + W_n$, and so $\phi + \delta (W_1 \cap W_2) \subset (\phi_1 + W_1) \cap (\phi_2 + W_2)$. Thus we have verified the family of sets specified above is a basis. Now we show $C_c^\infty(\Omega)$ is Hausdorff under this topology. Suppose $\phi$ is in every open neighbourhood of the origin, then in particular, for each $\varepsilon > 0$, $\phi$ lies in the set $W_\varepsilon = \{ f \in C_c^\infty(\Omega): \| f \|_{L^\infty(\Omega)} < \varepsilon \}$, and it is easy to see these sets are open. Since $\bigcap_{\varepsilon > 0} W_\varepsilon = \{ 0 \}$, this means $\phi = 0$.
\end{proof}

\begin{remark}
    This technique can be formulated more abstractly to give a locally convex topological structure to the direct limit of locally convex spaces. From this perspective, we also see why our metrization doesn't work; if $X = \lim X_n$, with each $X_n$ a locally convex metrizable space, then we cannot give $X$ a complete metrizable topology such that each $X_n$ is an embedding and has empty interior in $X$, because this would contradict the Baire category theorem. In particular, this means that the topology we have given to $C_c(\Omega)$ cannot be metrizable, and therefore the space cannot be first countable. Later we will see a more explicit proof of this.
\end{remark}

\begin{theorem}
    $C_c^\infty(\Omega)$ is a locally convex space.
\end{theorem}
\begin{proof}
    Fix $\phi$ and $\psi$, and consider any neighbourhood $W$ of the origin. By convexity, we have $(\phi + W/2) + (\psi + W/2) \subset (\phi + \psi) + W$. This shows addition is continuous. To show multiplication is continuous, fix $\lambda$, $\phi$, and a neighbourhood $W$ of the origin. Then $\phi$ is supported on some compact set $K$, and $W \cap C_c^\infty(K)$ is open, in particular absorbing, so there is $\varepsilon > 0$ such that if $|\alpha| < \varepsilon$, $\alpha \phi \in W/2$. Then if $|\gamma - \lambda| < \varepsilon$, then because $W$ is balanced and convex,
    %
    \begin{align*}
        \gamma \left(\phi + \frac{W}{2(|\lambda| + \varepsilon)} \right) &= \lambda \phi + (\gamma - \lambda) \phi + \frac{\gamma}{2(|\lambda| + \varepsilon)} W\\
        &\subset \lambda \phi + W/2 + W/2 \subset \lambda \phi + W
    \end{align*}
    %
    so multiplication is continuous.
\end{proof}

\begin{theorem}
    For each compact set $K \subset \Omega$, the canonical embedding of $C_c^\infty(K)$ in $C_c^\infty(\Omega)$ is continuous.
\end{theorem}
\begin{proof}
    We shall prove a convex, balanced neighbourhood $V$ is open in $C_c^\infty(\Omega)$ if and only if $C_c^\infty(K) \cap V$ is open in $C_c^\infty(K)$ for each $K$. Since $V$ is open, $V$ is the union of convex, balanced sets $W_\alpha$ with $W_\alpha \cap C_c^\infty(K)$ open in $C_c^\infty(K)$ for each $K$. But then $V \cap C_c^\infty(K) = (\bigcup W_\alpha) \cap C_c^\infty(K)$ is open in $C_c^\infty(K)$. The converse is true by definition of the topology. But this statement means exactly that the map $C_c^\infty(K) \to C_c^\infty(\Omega)$ is an embedding, because it is certainly continuous, and if $W$ is a convex neighbourhood of the origin equal to the set of $\phi$ supported on $K$ with $\| \phi \|_{C^n(K)} \leq \varepsilon$ for some $n$, then the image is the intersection of $C_c^\infty(K)$ with the set of all $\phi$ supported on $\Omega$ satisfying the inequality, which is open. This shows that the map is open onto its image, hence an embedding.
\end{proof}

It is difficult to see from the definition above why the topology is much stronger than the previous one given. We can see this more numerically by introducing the topology in terms of seminorms. The topology we have given $C_c^\infty(\Omega)$ is the same as the locally convex topology introduced by all norms $\| \cdot \|$ on the space which are continuous when restricted to each $C_c^\infty(K)$. As an example, if we choose an increasing family $U_1, U_2, \dots$ of precompact open sets whose closure is contained in $\Omega$, then any compact set $K$ is contained in some $U_N$ for large enough $N$, and for any increasing sequence $\alpha_1, \alpha_2, \dots$ of positive constants and increasing sequence $k_1, k_2, \dots$ of positive integers the norm
%
\[ \| f \| = \min_{\text{supp}(f) \subset U_n} \alpha_n \| f \|_{C^{k_n}(U_n)} \]
%
is well defined on $C_c^\infty(\Omega)$ and continuous. But if $\{ f_i \}$ is a sequence such that $\lim_{i \to \infty} f_i = 0$, then $\lim_{i \to \infty} \| f_i \| = 0$ for any choice of constants $\alpha_n$ and $k_n$. This means that, asymptotically, as we approach the boundary of $\Omega$, the sequence $\{ f_i \}$ must converge arbitrarily rapidly to zero. The next theorem shows that this implies that the union of the domains $f_n$ must actually be precompact. It is this `uniform compactness' that gives us completeness.

\begin{theorem}
    Consider any $E \subset C_c^\infty(\Omega)$. Then $E$ is a bounded subset of $C_c^\infty(\Omega)$ if and only if $E$ is contained in $C_c^\infty(K)$ for some compact set $K$, and there is a sequence of constants $\{ M_n \}$ such that $\| \phi \|_{C^n(\Omega)} \leq M_n$ for all $\phi \in E$.
\end{theorem}
\begin{proof}
    We shall now prove that if $E$ is not contained in some $C_c^\infty(K)$ for any compact set $K \subset \Omega$, then $E$ is not bounded. If our assumption is true, we can find functions $\phi_n \in E$ and a set of points $x_n \in X$ with no limit point such that $\phi_n(x_n) \neq 0$. For each $n$, set
    %
    \[ W_n = \left\{ \psi \in C_c^\infty(\RR^d): |\psi(x_n)| < n^{-1} |\phi_n(x_n)| \right\}. \]
    %
    Certainly $W_n$ is convex and balanced, and for each compact set $K$, if $\psi \in W_n \cap C_c^\infty(K)$, then there is $\varepsilon > 0$ such that $|\psi(x_n)| < n^{-1} |\phi_n(x_n)| - \varepsilon$. Thus if $\eta \in C_c^\infty(K)$ satisfies $\| \eta \|_{L^\infty(\RR^d)} < \varepsilon$, then $\psi + \eta \in W_n$. In particular, this means $W_n \cap C_c^\infty(K)$ is open in $C_c^\infty(K)$ for each $K$, so $W_n$ is open.

    Now we claim $W = \bigcap_{n = 1}^\infty W_n$ is open. Certainly this set is convex and balanced. Moreover, each compact set $K$ contains finitely many of the points $\{ x_n \}$, so $W \cap C_c^\infty(K)$ can be replaced by a finite intersection of the $W_n$, and is therefore open. Since $\phi_n \not \in nW$ for all $n$, this implies that $E$ is not bounded. The fact that $\| \cdot \|_{C^n(\Omega)}$ specifies the topological structure of $C_c^\infty(K)$ for each compact $K$ now shows that if $E$ is bounded, there exists constants $\{ M_n \}$ such that $\| \phi \|_{C^n(\Omega)} \leq M_n$ for all $\phi \in E$. The converse property follows because $C_c^\infty(K)$ is embedded in $C_c^\infty(\Omega)$.
\end{proof}

\begin{corollary}
    $C_c^\infty(\Omega)$ has the Heine Borel property.
\end{corollary}
\begin{proof}
    This follows because if $E$ is bounded and closed, it is a closed and bounded subset of some $C_c^\infty(K)$ for some $K$, hence $E$ is compact since $C_c^\infty(K)$ satisfies the Heine-Borel property (this can be proved by a technical application of the Arzela-Ascoli theorem).
\end{proof}

\begin{corollary}
    $C_c^\infty(\Omega)$ is quasicomplete.
\end{corollary}
\begin{proof}
    If $\phi_1, \phi_2, \dots$ is a Cauchy sequence in $C_c^\infty(\Omega)$, then the sequence is bounded, hence contained in some common $C_c^\infty(K)$. Since the sequence is Cauchy, they converge in $C_c^\infty(K)$ to some $\phi$, since $C_c^\infty(K)$ is complete, and thus the $\phi_n$ converge to $\phi$ in $C_c^\infty(\Omega)$.
\end{proof}

It is often useful to use the fact that we can perform a `separation of variables' to a smooth function. This is done formally in the following manner. Say $f \in C_c^\infty(\RR^d)$ is a {\it tensor function} if there are $f_1, \dots, f_n \in C_c^\infty(\RR)$ such that $f(x) = f_1(x_1) \dots f_n(x_n)$. We write $f = f_1 \otimes \dots \otimes f_n$. Since the product of two tensor functions is a tensor function, the family of all finite sums of tensor functions forms an algebra.

\begin{theorem}
    Finite sums of tensor functions are dense in $C_c^\infty(\RR^d)$.
\end{theorem}
\begin{proof}
    Recall from the theory of multiple Fourier series that if $f \in C^\infty(\RR^d)$ is $N$ periodic, in the sense that $f(x + n) = f(x)$ for all $x \in \RR^d$ and $n \in (N \ZZ)^d$, then there are coefficients $a_m$ for each $m \in \ZZ^n$ such that $f = \lim_{M \to \infty} S_M f$, where the convergence is dominated by the sminorms $\| \cdot \|_{C^n(\RR^d)}$, for all $n > 0$, and
    %
    \[ (S_M f)(x) = \sum_{\substack{m \in \ZZ^d\\|m| \leq M}} a_m e^{\frac{2 \pi i m \cdot x}{N}}. \]
    %
    Note that since
    %
    \[ e^{\frac{2 \pi i m \cdot x}{N}} = \prod_{k = 1}^d e^{2 \pi i m_ix_i/N} \]
    %
    is a tensor product, $S_M f$ is a finite sum of tensor functions. If $\phi \in C_c^\infty(\RR^d)$ is compactly supported on $[-N,N]^d$, we let $f$ be a $10N$ periodic function which is equal to $\phi$ on $[-N,N]^d$. We then find coefficients $\{ a_m \}$ such that $S_M f$ converges to $f$. If $\psi: \RR \to \RR$ is a compactly supported bump function equal to one on $[-N,N]^d$, and vanishing outside of $[-2N,2N]^d$, then $\psi^{\otimes d} S_M f$ converges to $\psi$ as $M \to \infty$, and each is a finite sum of tensor functions.
\end{proof}

Because $C_c^\infty(\Omega)$ is the limit of metrizable spaces, it's linear operators still have many of the same properties as metrizable spaces.

\begin{theorem}
    If $T: C_c^\infty(\Omega) \to X$ is a map from $C_c^\infty(\Omega)$ to some locally convex space $X$, then the following are equivalent:
    %
    \begin{itemize}
        \item[(1)] $T$ is continuous.
        \item[(2)] $T$ is bounded.
        \item[(3)] If $\{ \phi_n \}$ converges to zero, then $\{ T\phi_n \}$ converges to zero.
        \item[(4)] For each compact set $K \subset \Omega$, $T$ is continuous restricted to $C_c^\infty(K)$.
    \end{itemize}
\end{theorem}
\begin{proof}
    We already known that (1) implies (2). If $T$ is bounded, and we have a sequence $\{ \phi_n \}$ converging to zero, then the sequence is bounded, hence contained in some $C_c^\infty(K)$. Then $T$ is bounded as a map from $C_c^\infty(K)$ to $X$, hence $\{ T\phi_n \} \to 0$. (3) implies (4) because each $C_c^\infty(K)$ is metrizable, and any convergent sequence is contained in some common $C_c^\infty(K)$. To prove that (4) implies (1), we let $V$ be a convex, balanced, open subset of $X$. Then $T^{-1}(V) \cap C_c^\infty(K)$ is open for each $K$, and $T^{-1}(V)$ is convex and balanced, so $T^{-1}(V)$ is an open set.
\end{proof}

Because convergence is so strict in $C_c^\infty(\Omega)$, almost every operation we want to perform on smooth functions is continuous in this space.
%
\begin{itemize}
    \item Since $f \mapsto D^\alpha f$ is a continuous operator from $C_c^\infty(K)$ to itself, it is therefore continuous on the entire space $C_c^\infty(\Omega)$. More generally, any linear differential operator with coefficients in $C_c^\infty(\Omega)$ is a continuous operator from $C_c^\infty(\Omega)$ to itself.

    \item The inclusion $C_c^\infty(\Omega) \to L^p(\Omega)$ is continuous. To prove this, it suffices to prove for each compact $K$, the inclusion $C_c^\infty(K) \to L^p(\Omega)$ is continuous, and this follows because $\| f \|_{L^p(\Omega)} \leq |K|^{1/p} \| f \|_\infty$.

    \item If $f \in L^1(\RR^d)$ is compactly supported, then for any $g \in C_c^\infty(\RR^d)$, $f * g \in C_c^\infty(\RR^d)$. This is because $f * g$ is continuous since $g \in L^\infty(\RR^n)$, and it's support is contained in the algebraic sums of the support of $f$ and $g$, as well as the identity $D^\alpha(f * g) = f * (D^\alpha g)$. In fact, the map $g \mapsto f * g$ is a continuous operator on $C_c^\infty(\RR^n)$. This is because if we restrict our attention to $C_c^\infty(K)$, and $f$ has supported on $K'$, then our convolution operator maps into the compact set $K+K'$, and since
    %
    \[ \| D^\alpha (g * f) \|_{L^\infty(K + K')} = \| D^\alpha g * f \|_{L^\infty(K + K')} \leq \| D^\alpha g \|_{L^\infty(K)} \| f \|_{L^1(K')}, \]
    %
    we conclude
    %
    \[ \| g * f \|_{C^n(K+K')} \leq \| g \|_{C^n(K)} \| f \|_{L^1(K')}, \]
    %
    which gives continuity of the operator as a map from $C_c^\infty(K)$ to $C_c^\infty(K+K')$. Since the latter space embeds in $C_c^\infty(\RR^n)$, we obtain continuity of the operator on $C_c^\infty(\RR^n)$.
\end{itemize}

\begin{theorem}
    If a map $T: C_c^\infty(K_0) \to C_c^\infty(\RR^n)$ is continuous, then the image of $C_c^\infty(K_0)$ is actually $C_c^\infty(K_1)$ for some compact set $K_1$.
\end{theorem}
\begin{proof}
    Suppose there is a sequence $\{ x_i \}$ in $\RR^d$ with no limit point and smooth functions $\{ \phi_i \}$ compactly supported on $C_c^\infty(K_0)$ such that
    %
    \[ (T\phi_i)(x_i) \neq 0. \]
    %
    Then for any sequence $\{ \alpha_i \}$ of positive scalars, the sequence $\{ \alpha_i T\phi_i \}$ does not converge to zero, since the union of the supports of $\alpha_i T\phi_i$ is unbounded. This means $\alpha_i \phi_i$ does not converge to zero. But this is clearly not true, for if we let
    %
    \[ \alpha_i = \frac{1}{2^i \| \phi_i \|_{C^i(\RR^d)}}, \]
    %
    then for any fixed $n$, $\lim_{i \to \infty} \| \alpha_i \phi_i \|_{C^n(\RR^d)} = 0$, so the sequence $\{ \alpha_i \phi_i \}$ converges to zero. Thus there cannot exist a sequence $\{ x_i \}$, and so the union of the supports of $T(C_c^\infty(K_0))$ is supported on some compact set $K_1$.
\end{proof}

Thus the topology on the space $C_c^\infty(\RR^d)$ is as strict as can be. As a consequence, we shall see that the weak-$*$ topology on $C_c^\infty(\RR^d)^*$ is essentially the weakest topology available in analysis. This is surprising, because we are still able to obtain the continuity of many operators in the dual space to $C_c^\infty(\RR^d)$.

\section{The Space of Distributions}

We now have the tools to explain the idea of a distribution. If $f$ is a locally integrable function defined on $\Omega$, then the linear functional $\Lambda[f]$ on $C_c^\infty(\Omega)$ defined for each $\phi \in C_c^\infty(\Omega)$ by setting
%
\[ \Lambda[f](\phi) = \int f(x) \phi(x)\; dx \]
%
is continuous. Moreover, $\Lambda[f]$ determines $f$ up to a set of measure zero, and so we can safely identify $f$ with $\Lambda[f]$ (this is the `distributional viewpoint' of $f$). The idea of the theory of distributions is to treat any continuous linear functional $\Lambda$ on $C_c^\infty(\Omega)$ as if it were given by integration against a function. Using the properties of integration for these integration, we can usually cheat out a definition of operations for general distributions. Thus the operations of analysis generalize to an incredibly large family of objects. As an example, if $f \in C^1(\RR)$, then for any $\phi \in C_c^\infty(\RR)$, we would find
%
\[ \int_{-\infty}^\infty f'(x) \phi(x)\; dx = - \int_{-\infty}^\infty f(x) \phi'(x)\; dx \]
%
Since the right hand side is defined independantly of how nice the function $f(x)$ is, we could define the {\it derivative} of a continuous linear functional $\Lambda$ as
%
\[ \Lambda'(\phi) = - \Lambda(\phi') \]
%
and more generally, for a linear functional on $n$ dimensional space, we could define $(D^\alpha \Lambda)(\phi) = (-1)^{|\alpha|} \Lambda(D^\alpha \phi)$.

\begin{example}
    Let $H(x) = \mathbf{I}(x > 0)$ denote the {\it Heaviside step function}. Then $H$ is locally integrable, and so for any test function $\phi$, we calculate
    %
    \[ \int_{-\infty}^\infty H'(x) \phi(x)\; dx = - \int_{-\infty}^\infty H(x) \phi'(x) = - \int_0^\infty \phi'(x) = \phi(0) \]
    %
    Thus the \emph{distributional derivative} of the Heaviside step function is the Dirac delta function. It is not a function, but if we were to think of it as a `generalized function', it would be zero everywhere except at the origin, where it is infinitely peaked.
\end{example}

\begin{example}
    Consider the Dirac delta function at the origin, which is the distribution $\delta$ such that for any $\phi \in C_c^\infty(\RR)$,
    %
    \[ \int_{-\infty}^\infty \delta(x) \phi(x)\; dx = \phi(0). \]
    %
    Then
    %
    \[ \int_{-\infty}^\infty \delta'(x) \phi(x)\; dx = - \int_{\RR^d} \delta(x) \phi'(x)\; dx = - \phi'(0). \]
    %
    This is a distribution that does not arise from integration with respect to a locally integrable function nor integration against a measure.
\end{example}

In general, we define a \emph{distribution} to be a continuous linear functional on the space of test functions $C_c^\infty(\Omega)$. In the last section, our exploration of continuous linear transformations on $C_c^\infty(\Omega)$ guarantees that a linear functional $\Lambda$ on $C_c^\infty(\Omega)$ is continuous if and only if for every compact $K \subset X$ there is an integer $n_k$ such that $|\Lambda \phi| \lesssim_K \| \phi \|_{C^{n_k}(K)}$ for $\phi \in C_c^\infty(K)$. If one integer $n$ works for all $K$, and $n$ is the smallest integer with such a property, we say that $\Lambda$ is a distribution of \emph{order $n$}. If such an $n$ doesn't exist, we say the distribution has infinite order. If such an $n$ doesn't exist, we say the distribution has infinite order.

\begin{example}
    If $\mu$ is a locally finite Borel measure, or a finite complex valued measure, then we can define a distribution $\Lambda[\mu]$ such that for each $\phi \in C_c^\infty(\RR^d)$.
    %
    \[ \Lambda[\mu](\phi) = \int_{\RR^d} \phi(x) d\mu(x) \]
    %
    Thus $\Lambda[\mu]$ is a distribution, since if $\phi$ is supported on $K$, then
    %
    \[ |\Lambda[\mu](\phi)| \leq \mu(K) \| \phi \|_{L^\infty(K)}. \]
    %
    Thus $\Lambda[\mu]$ is a distribution of order zero.
\end{example}

\begin{example}
    Not all distributions arise from functions or measures. For instance, consider a functional $\Lambda$ defined such that for any $\phi \in C_c^\infty(\RR)$ vanishing in a neighbourhood of the origin,
    %
    \[ \Lambda(\phi) = \int_{-\infty}^\infty \frac{\phi(x)}{x}\; dx. \]
    %
    Such functions are dense in $C_c^\infty(\RR)$. We claim $\Lambda$ extends to a continuous functional on the entirety of $C_c^\infty(\RR)$. To prove this, fix $\phi \in C_c^\infty[-N,N]$ vanishing on a neighbourhood $(-\varepsilon,\varepsilon)$ of the origin. Then
    %
    \[ |\Lambda \phi| = \left| \int_{-\infty}^\infty \frac{\phi(x)}{x}\; dx \right| = \left| \int_{\varepsilon \leq |x| \leq N} \frac{\phi(x) - \phi(0)}{x}\; dx \right|. \]
    %
    Applying the mean-value theorem, we find
    %
    \[ |\Lambda \phi| \leq N \| \phi \|_{C^1[-N,N]}. \]
    %
    Since $N$ was arbitrary, it follows that $\Lambda$ is continuous in the topology induced by that of $C_c^\infty(\RR)$, and thus extends uniquely to a distribution on the entirety of $C_c^\infty(\RR)$. To be precise, we often denote the application of $\Lambda$ to $C_c^\infty(\RR)$ as
    %
    \[ \text{p.v} \int_{-\infty}^\infty \frac{\phi(x)}{x}\; dx. \]
    %
    A simple approximation argument shows that for any $\phi \in C_c^\infty(\RR)$,
    %
    \[ \Lambda \phi = \lim_{\varepsilon \to 0} \int_{|x| \geq \varepsilon} \frac{\phi(x)}{x}\; dx. \]
    %
    The distribution can also be described as the distribution derivative of the locally integrable function $\log |x|$, since an integration by parts shows that for each $\phi \in C_c^\infty(\RR^d)$,
    %
    \begin{align*}
        \int (\log |x|)'\; \phi(x)\; dx &= - \int \log |x| \phi'(x)\; dx\\
        &= \lim_{\varepsilon \to 0} \int_{|x| \geq \varepsilon} \log |x| \phi'(x)\\
        &= \lim_{\varepsilon \to 0} \left( \log(\varepsilon) \cdot \left( \phi(x) - \phi(-x) \right) + \int_{|x| \geq \varepsilon} \frac{\phi(x)}{x} \right)\\
        &= \text{p.v.} \int \frac{\phi(x)}{x}\; dx.
    \end{align*}
    %
    This distribution arises most prominantly in the theory of the Hilbert transform.
\end{example}

As we stated before, given any distribution $\Lambda$, we can define it's {\it derivative} $D^\alpha \Lambda$ to be the distribution
%
\[ D^\alpha \Lambda (\phi) = (-1)^{|\alpha|} \Lambda(D^\alpha \phi) \]
%
which is continuous since the derivative operation is continuous on $C_c^\infty(\Omega)$. Just as the partial derivatives commutes on $C_c^\infty(\Omega)$, the partial differentiation operation commutes on the the space of distributions, i.e. $D^\alpha D^\beta \Lambda = D^\beta D^\alpha \Lambda$, and we take the common value to be $D^{\alpha + \beta} \Lambda$. If $D^\alpha f$ is continuous, then we already know an integration by parts gives $D^\alpha \Lambda[f] = \Lambda[D^\alpha f]$, so we can think of the distributional derivative as a true generalization of the usual derivative. On the other hand, in general the distribution derivative may disagree with the usual derivative if the function is less well behaved (as might be expected, given that the distributional derivative always commutes). More generally, if $P$ is a polynomial, we have
%
\[ P(D)(\Lambda)(\phi) = \Lambda(P(-D)(\phi)) \]
%
if we understand the polynomial applications of derivatives linearly.

\begin{example}
    Let $f$ be a left continuous function on the real line with bounded variation and with $f(-\infty) = 0$. Then $f'$ exists almost everywhere in the classical sense, and $f' \in L^1(\RR)$. By Fubini's theorem, if we let $\mu$ be the measure defined by $\mu([a,b)) = f(b) - f(a)$, then for any $\phi \in C_c^\infty(\RR)$,
    %
    \begin{align*}
        \int_{-\infty}^\infty \phi(x) d\mu(x) &= - \int_{-\infty}^\infty \int_x^\infty \phi'(y)\; dy\; d\mu(x)\\
        &= - \int_{-\infty}^\infty \phi'(y) \int_{-\infty}^y d\mu(x)\; dy\\
        &= - \int_{-\infty}^\infty \phi'(y) f(y) dy
    \end{align*}
    %
    and we know $f(-\infty) = 0$. Thus we find $\smash{\Lambda[f'] = \Lambda[\mu]}$. In particular, we only have $\smash{\Lambda[f]' = \Lambda[f'}]$ if $\smash{f' dx = \mu}$, which only holds if $f$ is absolutely continuous.
\end{example}

\begin{theorem}
  If $u$ is a distribution and $D^i u = 0$, then there exists $v \in C_c^\infty(\RR^d)'$ such that
  %
  \[ \int_{\RR^d} u(x) \phi(x)\; dx = \int_{\RR^{d-1}} v(x) \left( \int_{-\infty}^\infty \phi(x)\; dx^i \right)\; dx. \]
\end{theorem}
\begin{proof}
  Suppose without loss of generality that $i = d$. Suppose $\phi \in C_c^\infty(\RR^d)$ and for each $x \in \RR^{d-1}$,
  %
  \[ \int_{-\infty}^\infty \phi(x,t)\; dt = 0. \]
  %
  Then the function
  %
  \[ \psi(x,t) = \int_{-\infty}^t \phi(x,s)\; ds = 0 \]
  %
  has compact support and $D^i \psi = \phi$. Thus
  %
  \begin{align*}
    \int_{-\infty}^\infty u(x,t) \phi(x,t)\; dx\; dt &= \int_{-\infty}^\infty u(x,t) D^i \psi(x,t)\; dx\; dt\\
    &= - \int_{-\infty}^\infty D^i u(x,t) \psi(x,t)\; dx\; dt = 0.
  \end{align*}
  %
  Now fix $\phi_0 \in C_c^\infty(\RR)$ with $\int_{-\infty}^\infty \phi_0(x) = 1$. Then given any $\phi \in C_c^\infty(\RR^d)$,
  %
  \[ \int_{-\infty}^\infty u(x,t) \phi(x,t)\; dx\; dt = \int_{-\infty}^\infty u(x,t) \phi_0(t) \left( \int_{-\infty}^\infty \phi(x,s)\; ds \right)\; dx\; dt. \]
  %
  Thus it suffices to set
  %
  \[ v(x) = \int_{-\infty}^\infty u(x,t) \phi_0(t)\; dt. \qedhere \]
\end{proof}

If $f \in L^1_{\text{loc}}(\RR^d)$, and $g \in C^\infty(\RR^d)$, then $fg$ is locally integrable. The identity
%
\[ \int (f(x)g(x)) \phi(x)\; dx = \int f(x) (g(x) \phi(x))\; dx \]
%
enables us to define the product of a $C^\infty(\Omega)$ function with a distribution. Given any distribution $\Lambda$ on $\Omega$ and $f \in C^\infty(\Omega)$, we define $(f \Lambda)(\phi) = \Lambda(f \phi)$. To see why $f \Lambda$ is a distribution, fix a compact set $K \subset \Omega$, and pick $A$ and $n$ such that for any $\phi \in C_c^\infty(K)$, $|\Lambda(f)| \leq A \| f \|_{C^n(K)}$. The Leibnitz rule tells us that
%
\[ D^\alpha(f \phi) = \sum_{\lambda + \gamma = \alpha} C_{\lambda \gamma} D^\lambda f D^\gamma \phi \]
%
for some constants $C_{\lambda \gamma} > 0$, and so
%
\begin{align*}
  |\Lambda(f \phi)| &\lesssim \| f \phi \|_{C^n(K)}\\
  &\lesssim_n \max_{|\alpha| \leq n} \max_{\lambda + \gamma = \alpha} \| D^\lambda f \|_{L^\infty(K)} \| D^\gamma \phi \|_{L^\infty(K)}\\
  &\leq \| f \|_{C^n(K)} \| \phi \|_{C^n(K)},
\end{align*}
%
which completes the argument.

Since $C_c^\infty(X)^*$ is the dual space of a topological vector space, we can give it a natural topology, the weak $*$ topology. Thus a net of distributions $\Lambda_\alpha$ converges to $\Lambda$ if and only if $\Lambda_\alpha(\phi) \to \Lambda(\phi)$ for all test functions $\phi$. This gives a further topology on the space of measures and functions, and we often write $f_\alpha \to f$ `in the distribution sense' if we have a convergence $\Lambda[f_\alpha] \to \Lambda[f]$ for the corresponding distributions. Since the convergence in $C_c^\infty(\Omega)$ is incredibly strict, convergence of distributions is incredibly weak. The following is thus quite a surprising result.

\begin{theorem}
  Suppose that $\{ \Lambda_i \}$ are a sequence of distributions converging weakly to a distribution $\Lambda$. Then $D^\alpha \Lambda_i$ converges weakly to $D^\alpha \Lambda$ for any multi-index $\alpha$.
\end{theorem}
\begin{proof}
  For each $\phi \in C_c^\infty(\Omega)$, $D^\alpha \phi \in C_c^\infty(\Omega)$, so
  %
  \begin{align*}
    \lim_{i \to \infty} (D^\alpha \Lambda_i)(\phi) &= \lim_{i \to \infty} (-1)^{|\alpha|} \Lambda_i(D^\alpha \phi)\\
    &= (-1)^{|\alpha|} \Lambda(D^\alpha \phi)\\
    &= (D^\alpha \Lambda)(\phi). \qedhere
  \end{align*}
\end{proof}

Thus differentiation is continuous in the space of distributions. So too is multiplication by elements of $C^\infty(\RR^d)$, which turns the space of distributions into a $C^\infty(\RR^d)$ module.

\begin{theorem}
  Fix a sequence $\{ g_i \}$ in $C^\infty(\RR^d)$ and a sequence of distributions $\{ \Lambda_i \}$ such that $g_i \to g$ in $C^\infty(\RR^d)$ and $\Lambda_i \to \Lambda$ weakly. Then $g_i \Lambda_i$ converges weakly to $g \Lambda$.
\end{theorem}
\begin{proof}
  For each $\phi \in C_c^\infty(\RR^d)$, the map $(\Lambda_i \times g_i) \mapsto \Lambda_i g_i$ is bilinear, and continuous in each variable. The result then follows from a variant of Banach-Steinhaus.
\end{proof}

\section{Localization of Distribuitions}

Just as we can consider the local behaviour of functions around a point, we can consider the local behaviour of a distribution around points, and this local behaviour contains most of the information of the distribution. For instance, given an open subset $U$ of $X$, we say two distributions $\Lambda$ and $\Psi$ are equal on $U$ if $\Lambda \phi = \Psi \phi$ for every test function $\phi$ compactly supported in $U$. We recall the notion of a partition of unity, which, for each open cover $U_\alpha$ of Euclidean space, gives a family of $C^\infty$ functions $\psi_\alpha$ which are positive, {\it locally finite}, in the sense that only finitely many functions are positive on each compact set, and satisfy $\sum \psi_\alpha = 1$ on the union of the $U_\alpha$.

\begin{theorem}
    If $X$ is covered by a family of open sets $U_\alpha$, and $\Lambda$ and $\Psi$ are locally equal on each $U_\alpha$, then $\Lambda = \Psi$. If we have a family of distributions $\Lambda_\alpha$ which agree with one another on $U_\alpha \cap U_\beta$, then there is a unique distribution $\Lambda$ locally equal to each $\Lambda_\alpha$.
\end{theorem}
\begin{proof}
    Since we can find a $C^\infty$ partition of unity $\psi_\alpha$ compactly supported on the $U_\alpha$, upon which we find if $\phi$ is supported on $K$, then finitely many of the $\psi_\alpha$ are non-zero on $K$, and so
    %
    \[ \Lambda(\phi) = \sum \Lambda(\psi_\alpha \phi) = \sum \Psi(\psi_\alpha \phi) = \Psi(\phi) \]
    %
    Thus $\Lambda = \Psi$. Conversely, if we have a family of distributions $\Lambda_\alpha$ like in the hypothesis, then we can find a partition of unity $\psi_{\alpha \beta}$ subordinate to $U_\alpha \cap U_\beta$, and we can define
    %
    \[ \Lambda(\phi) = \sum \Lambda_\alpha(\psi_{\alpha \beta} \phi) = \sum \Lambda_\beta(\psi_{\alpha \beta} \phi) \]
    %
    The continuity is verified by fixing a compact $K$, from which there are only finitely many nonzero $\psi_{\alpha \beta}$ on $K$, and the fact that this definition is independant of the partition of unity follows from the first part of the theorem.
\end{proof}

In the language of modern commutative algebra, the association of $C_c^\infty(U)^*$ to each open subset $U$ of $\Omega$ gives a sheaf structure to $\Omega$. Given a distribution $\Lambda$, we might have $\Lambda(\phi) = 0$ for every $\phi$ supported on some open set $U$. The complement of the largest open set $U$ for which this is true is called the \emph{support} of $\Lambda$.

\begin{theorem}
    If a distribution has compact support, the distribution has finite order, and extends uniquely to a continuous linear functional on $C^\infty(X)$.
\end{theorem}
\begin{proof}
    Let $\Lambda$ be a distribution supported on a compact set. If $\psi$ is a function with compact support with $\psi(x) = 1$ on the support of $\Lambda$, then $\psi \Lambda = \Lambda$, because for any $\phi$, $\phi - \phi \psi$ is supported on a set disjoint from the support of $\Lambda$. But if $\psi$ is supported on $K$, then there is $N$ such that for any $\phi \in C_c^\infty(K)$,
    %
    \[ |\Lambda(\phi)| \lesssim \| \phi \|_{N,K} \]
    %
    and so for any other compact set $K$,
    %
    \[ |\Lambda(\phi)| = |\Lambda(\phi \psi)| \lesssim \| \phi \psi \|_{N,K} \lesssim \| \psi \|_{C^N(K)} \| \phi \|_{C^N(K)} \]
    %
    which shows $\Lambda$ has order $N$. We have shown that $\Lambda$ is continuous with respect to the seminorm $\| \cdot \|_{C^N(K)}$ on $C^\infty(X)$, and so by the Hahn Banach theorem, $\Lambda$ extends uniquely to a continuous functional on $C^\infty(X)$.
\end{proof}

\begin{example}
    If $\Lambda(\phi) = \sum_{|\alpha| \leq N} \lambda_\alpha D^\alpha \phi(x)$, then $\Lambda$ is supported on $x$. Conversely, every distribution $\Lambda$ supported on $x$ is of this form. We know $\Lambda$ must have finite order $N$, and consider $\phi$ with $D^\alpha \phi(x) = 0$ for all $|\alpha| \leq N$. We claim $\Lambda(\phi) = 0$. Fix $\varepsilon > 0$, and choose a compact neighbourhood $K$ of the origin with $|D^\alpha \phi(x)| < \varepsilon$ on $K$ for all $|\alpha| = N$. Then for $|\alpha| < N$, the mean value theorem implies that, by induction,
    %
    \[ |D^\alpha \phi(x)| \leq \varepsilon n^{N - |\alpha|} |x|^{N-|\alpha|} \]
    %
    Find $A$ such that for functions $\phi$ supported on $K$,
    %
    \[ |\Lambda(\phi)| \leq A \| \phi \|_{C^N(K)} \]
    %
    Fix a bump function $\psi$ with support on the ball of radius one and $\psi(x) = 1$ in a neighbourhood of the origin, and define $\psi_\delta(x) = \psi(x/\delta)$. If $\delta$ is small enough, then $\psi$ is supported on $K$, and because $\Lambda$ is supported on $x$,
    %
    \begin{align*}
        |\Lambda(\phi)| &= |\Lambda(\phi \psi_\delta)| \leq A \| \phi \psi_\delta \|_{C^N(K)}\\
        &\leq A \sum_{|\alpha + \beta| = N} |c_{\alpha \beta}| \| D^\alpha \phi \|_\infty \| D^\beta \psi_\delta \|\\
        &\leq A \| \psi \|_{C^N} \sum_{|\alpha + \beta| = N} |c_{\alpha \beta}| \delta^{|\beta| - |\alpha|} \| D^\beta \phi \|_{L^\infty(K)}\\
        &\leq \varepsilon A \left( \sum_{|\alpha + \beta| = N} |c_{\alpha \beta}| n^{N - |\beta|} \right)
    \end{align*}
    %
    We can then let $\varepsilon \to 0$ to conclude $\Lambda(\phi) = 0$. But this means that $\Lambda(\phi)$ is a linear function of the partial derivatives of $\phi$ with order $\leq N$, completing the proof.
\end{example}

\begin{example}
    If $\delta$ is the Dirac delta distribution in $\RR^d$, then $f \delta = f(0) \delta$ for any $f \in C^\infty(\RR^d)$. Thus, in particular, $x \delta = 0$. Conversely, if $\Lambda$ is any distribution with $x \Lambda = 0$, then $\Lambda$ is a multiple of the Dirac delta distribution. To see this, we note that this would imply $\Lambda(f) = 0$ for all functions $f$ such that $f/x$ is also smooth and compactly supported. In particular, this is true if the support of $f$ does not contain the origin. Thus $\Lambda$ is supported on the origin, hence there are constants $a_n$ such that
    %
    \[ \Lambda f = \sum_{n = 0}^N a_n f^{(n)}(0) \]
    %
    But $(xf)^{(n)}(0) = n f^{(n-1)}(0)$ only vanishes for all $f$ when $n = 0$, so $\Lambda$ is a multiple of the Dirac delta distribution. A more simple way to see this is that if $f$ is compactly supported on $[-N,N]$, the function
    %
    \[ g(x) = \frac{f(x) - f(0)}{x} = \int_0^1 f'(tx)\; dt \]
    %
    is smooth, and $f = f(0) + xg$. Since $\Lambda$ and $x \Lambda$ have bounded support, they extend uniquely to $C^\infty(\Omega)$, and so $\Lambda f = f(0) \Lambda 1 + \Lambda(xg) = f(0) \Lambda 1$.
\end{example}

In many other ways, distributions act like functions. For instance, any distribution $\Lambda$ can be uniquely written as $\Lambda_1 + i \Lambda_2$ for two distributions $\Lambda_1, \Lambda_2$ that are real valued for any real-valued smooth continuous function. However, we cannot write a real-valued distribution as the difference of two positive distributions, i.e. those which are non-negative when evaluated at any non-negative functional. Given a non-negative functional $\Lambda$ (which is automatically continuous),  we define $\Lambda f$ for a compactly supported continuous function $f \geq 0$ as
%
\[ \Lambda f = \sup \{ \Lambda g: g \in C_c^\infty(\RR^n), g \leq f \} \]
%
and then in general define $\Lambda (f^+ - f^-) = \Lambda f^+ - \Lambda f^-$. Then $\Lambda$ is obviously a positive extension of $\Lambda$ to all continuous functions, and is linear. But then the Riesz representation theorem implies that there is a Radon measure such that $\Lambda = \Lambda_\mu$, completing the proof.

\section{Derivatives of Continuous Functions}

One of the main reasons to consider the theory of distributions is so that we can take the derivative of any function we want. We now show that, at least locally, every distribution is the derivative of some continuous function, which means the theory of distributions is essentially the minimal such class of objects which enable us to take derivatives of continuous functions.

\begin{theorem}
    If $\Lambda$ is a distribution on $\Omega$, and $K$ is a compact set, then there is a continuous function $f$ and $\alpha$ such that for every $\phi$,
    %
    \[ \Lambda \phi = (-1)^{|\alpha|} \int_\Omega f(x) (D^\alpha \phi)(x)\; dx \]
\end{theorem}
\begin{proof}
    TODO
\end{proof}

\begin{theorem}
    If $K$ is compact, contained in some open subset $V$, which in turn is a subset of $\Omega$, and $\Lambda$ has order $N$, then there exists finitely many continuous functions $f_\beta \in C(\Omega)$ supported on $V$, for each $|\beta| \leq N + 2$, with supports on $V$, and with $\Lambda = \sum D^\beta f_\beta$.
\end{theorem}

\begin{theorem}
    If $\Lambda$ is a distribution on $\Omega$, then there exists continuous functions $g_\alpha$ on $\Omega$ such that each compact set $K$ intersects the supports of finitely many of the $g_\alpha$, and $\Lambda = \sum D^\alpha g_\alpha$. If $\Lambda$ has finite order, then only finitely many of the $g_\alpha$ are nonzero.
\end{theorem}

\section{Convolutions of Distributions}

Using the convolution of two functions as inspiration, we will not define the convolution of a distribution $\Lambda$ with a test function $\phi$, and under certain conditions, the convolution of two distributions. Recall that if $f,g \in L^1(\RR^n)$, then their convolution is the function in $L^1(\RR^n)$ defined by
%
\[ (f * g)(x) = \int f(y) g(x - y)\; dy \]
%
If we define the translation operators $(T_y g)(x) = g(x-y)$, then $(f * g)(x) = \int f(y) (T_x g^*)(y)\; dy$, where $g^*$ is the function defined by $g^*(x) = g(-x)$. Thus, if $\Lambda$ is any distribution on $\RR^n$, and $\phi$ is a test function on $\RR^n$, we can define a function $\Lambda * \phi$ by setting $(\Lambda * \phi)(x) = \Lambda(T_x \phi^*)$. Notice that since
%
\begin{align*}
    \int (T_x f)(y) g(y)\; dy &= \int f(y-x) g(y)\; dy = \int f(y) g(x+y)\; dy\\
    &= \int f(y) (T_{-x}g)(y)\; dy,
\end{align*}
%
so we can also define the translation operators on distributions by setting $(T_x \Lambda)(\phi) = \Lambda (T_{-x} \phi)$. One mechanically verifies that convolution commutes with translations, i.e. $T_x (\Lambda * \phi) = (T_x \Lambda) * \phi = \Lambda * (T_x \phi)$.

\begin{theorem}
    $\Lambda * \phi$ is $C^\infty$, and $D^\alpha(\Lambda * \phi) = (D^\alpha \Lambda) * \phi = \Lambda * (D^\alpha \phi)$.
\end{theorem}
\begin{proof}
    It is easy to calculate that
    %
    \begin{align*}
        (D^\alpha \Lambda * \phi)(x) &= (D^\alpha \Lambda)(\phi^*_x) = (-1)^{|\alpha|} \Lambda(D^\alpha (T_x \phi^*))\\
        &= \Lambda(T_x (D^\alpha \phi)^*) = (\Lambda * D^\alpha \phi)(x)
    \end{align*}
    %
    If $k \in \{ 1, \dots, d \}$ and $h \in \RR$, we set
    %
    \[ (\Delta_h f)(x) = \frac{f(x + he_k) - f(x)}{h} \]
    %
    then $\Delta_h \phi$ converges to $D^k \phi$ in $C_c^\infty(\RR^d)$, and as such
    %
    \begin{align*}
      \Delta_h(\Lambda * \phi)(x) &= \frac{(\Lambda * \phi)(x + he_k) - (\Lambda * \phi)(x)}{ h}\\
      &= \Lambda \left( \frac{T_{-x - he_k} \phi^* - T_{-x} \phi^*}{h} \right)
    \end{align*}
    %
    As $h \to 0$, in $C_c^\infty(\RR^d)$ we have
    %
    \[ \frac{T_{-x - he_k} \phi^* - T_{-x} \phi^*}{h} \to - T_{-x} D_k \phi^* = T_{-x} (D_k \phi)^*. \]
    %
    Thus, by continuity,
    %
    \[ \lim_{h \to 0} \Delta_h(\Lambda * \phi)(x) = \Lambda(T_{-x} (D_k \phi)^*) = (\Lambda * D_k \phi)(x) \]
    %
    Iteration gives the general result that $\Lambda * \phi \in C^\infty(\RR^d)$. An easy calculation then shows that for each $x \in \RR^d$,
    %
    \begin{align*}
      [(D^\alpha \Lambda) * \phi](x) &= (D^\alpha \Lambda)(T_{-x} \phi^*)\\
      &= (-1)^{|\alpha|} \Lambda(T_{-x} D^\alpha \phi^*)\\
      &= \Lambda(T_{-x} (D^\alpha \phi)^*)\\
      &= (\Lambda * D^\alpha \phi)(x). \qedhere
    \end{align*}
\end{proof}

There is a certain duality going on here. Distributions can be viewed as linear functionals on $C_c^\infty(\RR^d)$, but one can also view them as a certain family of linear operators from $C_c^\infty(\RR^d) \to C^\infty(\RR^d)$ , and the convolution operator uniquely represents the distribuition. In fact, any such operator that is translation invariant and continuous can be represented as convolution by a distribution.

\begin{theorem}
  Let $T: C_c^\infty(\RR^d) \to C^\infty(\RR^d)$ be a translation invariant continuous operator. Then there exists a distribution $\Lambda$ such that $T\phi = \Lambda * \phi$ for all $\phi \in C_c^\infty(\RR^d)$.
\end{theorem}
\begin{proof}
  If we knew $T\phi = \Lambda * \phi$ for some $\Lambda$, then we could recover $\Lambda$ since
  %
  \[ \int \Lambda(x) \phi(x)\; dx = T \tilde{\phi}(0). \]
  %
  Since $T$ is a continuous operator, the right hand side defines a distribution $\Lambda$, and translation invariance allows us to conclude that $T\phi = \Lambda * \phi$ for all $\phi \in C_c^\infty(\RR^d)$.
\end{proof}

For more general operators that are translation invariant, we cannot represent all operators via convolution by distributions. A significantly more general family of operators can be found if, instead of considering operators of the form
%
\[ T\phi(y) = \int \Lambda(y - x) \phi(x)\; dx \]
%
we instead study \emph{kernel} operators
%
\[ T\phi(y) = \int K(x,y) \phi(x)\; dx \]
%
where $K$ is a distribution on $\RR^n \times \RR^m$ and $\phi \in C_c^\infty(\RR^n)$. To formally interpret the output of this operator, we need to test it against another bump function, i.e. for $\psi \in C_c^\infty(\RR^m)$ we consider
%
\[ \int T\phi(y) \psi(y)\; dy = \int K(x,y) \phi(x) \psi(y)\; dx\; dy. \]
%
Thus $T\phi$ is naturally a distribution on $\RR^m$, and this definition naturally gives a continuous map from $C_c^\infty(\RR^n)$ to $C_c^\infty(\RR^m)'$. In 1953, Schwartz showed that essentially every linear operator encountered in Euclidean analysis is of this form.

\begin{theorem}
  Let $T: C_c^\infty(\RR^n) \to C_c^\infty(\RR^m)'$ be a continuous linear operator. Then there exists a unique distribution $K \in C_c^\infty(\RR^n \times \RR^m)$ such that for $\phi \in C_c^\infty(\RR^n)$ and $\psi \in C_c^\infty(\RR^m)$,
  %
  \[ \int T\phi(y) \psi(y)\; dy = \int K(x,y) \phi(x) \psi(y)\; dx\; dy. \]
\end{theorem}

Looking at the properties of kernels defining an operator is often a useful technique to gain insight in how an operator behaves. For instance, if $T$ is an operator corresponding to a kernel $K(x,y)$, then $D^\alpha \circ T \circ D^\beta$ has kernel $(-1)^{|\beta|} D^\alpha D^\beta K(x,y)$.

\section{Schwartz Space and Tempered Distributions}

We have already encountered the fact that Fourier transforms are well behaved under differentiation and multiplication by polynomials. If we let $\mathcal{S}(\RR^d)$ denote a class of functions under which to study this phenomenon, it must be contained in $L^1(\RR^d)$ and $C^\infty(\RR^d)$, and closed under multiplication by polynomials, and closed under applications of arbitrary constant-coefficient differential operators. A natural choice is then the family of functions which \emph{decays rapidly}, as well as all of it's derivatives; i.e. we let $\mathcal{S}(\RR^d)$ be the space of all functions $f \in C^\infty(\RR^d)$ such that for any integer $n$ and multi-index $\alpha$, $|x|^n D^\alpha f \in L^\infty(\RR^d)$. The space $\mathcal{S}(\RR^d)$ is then locally convex if we consider the family of seminorms
%
\[ \| f \|_{\mathcal{S}^{n,m}(\RR^d)} = \sup_{|\beta| \leq n} \| |1+x|^m D^\beta f \|_{L^\infty(\RR^d)}. \]
%
Elements of $\mathcal{S}(\RR^d)$ are known as \emph{Schwartz functions}, and $\mathcal{S}(\RR^d)$ is often known as the \emph{Schwartz space}. The seminorms naturally give $\mathcal{S}(\RR^d)$ the structure of a Fr\'{e}chet space. Sometimes, it is more convenient to use the equivalent family of seminorms $\| f \|_{\mathcal{S}^{\alpha, \beta}(\RR^d)} = \| x^\alpha D^\beta f \|_{L^\infty(\RR^d)}$, because $x^\alpha$ often behaves more nicely under various Fourier analytic operations. It is obvious that $\mathcal{S}(\RR^d)$ is separated by the seminorms defined on it, because $\| \cdot \|_{L^\infty(\RR^d)} = \| \cdot \|_{\mathcal{S}^{0,0}(\RR^d)}$ is a norm used to define the space. We now show the choice of seminorms make the space complete.

\begin{theorem}
    $\mathcal{S}(\RR^d)$ is a complete metric space.
\end{theorem}
\begin{proof}
    Let $\{ f_i \}$ be a Cauchy sequence with respect to the seminorms $\| \cdot \|_{\mathcal{S}^{n,\alpha}(\RR^d)}$. This implies that for each integer $m$, and multi-index $\alpha$, the sequence of functions $[1 + |x|^m] D^\alpha f_k$ is Cauchy in $L^\infty(\RR^d)$. Since $L^\infty(\RR^d)$ is complete, there are functions $g_{m,\alpha}$ such that $(1 + |x|^m) D^\alpha f_k$ converges uniformly to $g_{m,\alpha}$. If we set $f = g_{0,0}$, then it is easy to see using the basic real analysis of uniform continuity that $f$ is infinitely differentiable, and $(1 + |x|^m) D^\alpha f = g_{m,\alpha}$. It is then easy to show that $f_i$ converges to $f$ in $\mathcal{S}(\RR^d)$.
\end{proof}

\begin{example}
    The Gaussian function $\phi: \RR^d \to \RR$ defined by $\phi(x) = e^{-|x|^2}$ is Schwartz. For any multi-index $\alpha$, there is a polynomial $P_\alpha$ of degree at most $|\alpha|$ such that $D^\alpha \phi = P_\alpha \phi$; this can be established by a simple induction. But this means that for each fixed $\alpha$, $|P_\alpha(x)| \lesssim_\alpha 1 + |x|^{|\alpha|}$. Since $e^{-|x|^2} \lesssim_{m,\alpha} 1/(1 + |x|)^{m + |\alpha|}$ for any fixed $m$ and $\alpha$, we find that for any $x \in \RR^d$,
    %
    \[ | (1 + |x|^m) D^\alpha \phi| \lesssim_{\alpha,m} 1. \]
    %
    Since $m$ and $\alpha$ were arbitrary, this shows $\phi$ is Schwartz.
\end{example}

\begin{example}
    The space $C^\infty_c(\RR^d)$ consists of all compactly supported $C^\infty$ functions. If $f \in C^\infty_c(\RR^d)$, then $f$ is Schwartz. This is because for each $\alpha$ and $m$, $(1 + |x|)^m f_\alpha$ is a continuous function vanishing outside a compact set, and is therefore bounded.
\end{example} 

Because of the sharp control we have over functions in $\mathcal{S}(\RR^d)$, almost every analytic operation we want to perform on $\mathcal{S}(\RR^d)$ is continuous. To show that an operator $T$ on $\mathcal{S}(\RR^d)$ is bounded, it suffices to show that for each $n_0$ and $m_0$, there is $n_1$, $m_1$ such that
%
\[ \| Tf \|_{\mathcal{S}^{n_0,m_0}(\RR^d)} \lesssim_{n_0,m_0} \| f \|_{\mathcal{S}^{n_1,m_1}(\RR^d)}. \]
%
For a functional $\Lambda: \mathcal{S}(\RR^d) \to \RR$, it suffices to show that there exists $n$ and $m$ such that $|\Lambda f| \lesssim \| f \|_{\mathcal{S}^{n,m}(\RR^d)}$. The minimal such choice of $n$ is known as the \emph{order} of the functional $\Lambda$. We normally do not care about the constant behind the operators for these norms, since the norms are not translation invariant and therefore highly sensitive to the positions of various functions. We really just care about proving the existence of such a constant.

\begin{lemma}
  The map $(f,g) \mapsto fg$ for $f,g \in \mathcal{S}(\RR^d)$ gives a bounded bilinear map from $\mathcal{S}(\RR^d) \times \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$.
\end{lemma}
\begin{proof}
  A simple application of the Leibnitz formula shows that for any multi-index $\alpha$ with $|\alpha| = m$, and two non-negative integers $n_1$ and $n_2$ with $n_1 + n_2 = n$,
  %
  \[ \| fg \|_{\mathcal{S}^{n,\alpha}(\RR^d)} \lesssim_n \| f \|_{\mathcal{S}^{n_1,m}(\RR^d)} \| g \|_{\mathcal{S}^{n_2,m}(\RR^d)}. \]
  %
  More generally, this argument shows that the analogoue bilinear map from $C^\infty(\RR^d) \times \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$ is bounded.
\end{proof}

\begin{theorem}
    The following operators are all bounded on $\mathcal{S}(\RR^n)$.
    %
    \begin{itemize}
        \item For each $h \in \RR^n$, the translation operator $(T_h f)(x) = f(x - h)$.

        \item For each $\xi \in \RR^n$, the modulation operator $(M_\xi f)(x) = e(\xi \cdot x) f(x)$.

        \item The $L^p$ norms $\| f \|_{L^p(\RR^n)}$, for $1 \leq p \leq \infty$.

        \item The Fourier transform from $\mathcal{S}(\RR^d)$ to $\mathcal{S}(\RR^d)$.
    \end{itemize}
    %
    Furthermore, the Fourier transform is an isomorphism of $\mathcal{S}(\RR^d)$.
\end{theorem}
\begin{proof}
%   Let $(T_h f)(x) = f(x - h)$. We calculate that if $|\alpha| \leq n$, then
    %
%   \begin{align*}
%       (1 + |x|^m) (T_h f)_\alpha &= T_h((1 + |x + h|^m) f_\beta)\\
%       &\leq 2^m T_h((1 + |x|^m + |h|^m) f_\alpha)\\
%       &\leq 2^m |h|^m \| f_\alpha \|_{n,0} + 2^m \| f \|_{n,m}.
%   \end{align*}
    %
%   Thus $\| T_h f \|_{n,m} \leq 2^m(1 + |h|^m) \| f \|_{n,m}$, so $T_h$ is continuous.

%   Similarily, we calculate using the Leibnitz formula and the formula for the derivatives of $e(\xi \cdot x)$ that if $|\alpha| \leq n$, then
    %
%   \[ (1 + |x|^m) |(e(\xi \cdot x) f)_\alpha| \leq 4^n (2\pi)^n (1 + |\xi|^n) \| f \|_{n,m} \]
    %
%   Thus $\| M_\xi f \|_{n,m} \leq (8 \pi)^n (1 + |\xi|^n) \| f \|_{n,m}$.

%   For any Schwartz function $f$, and $|\alpha| \leq n$,
    %
%   \[ f(x) \leq \frac{\| f \|_{0,d+1}}{1 + |x|^{d+1}} \]
    %
%   Integrating this equation gives
    %
%   \[ \| f_\alpha \|_{L^1(\RR^d)} \leq 2^d \| f \|_{0,d+1}. \]
    %
%   Thus $\| \cdot \|_1$ is a bounded norm on the space. Interpolation then shows that for any $1 < p < \infty$,
    %
%   \[ \| f \|_{L^p(\RR^d)} \leq \| f \|_{L^1(\RR^d)}^{1 - 1/p} \| f \|_{L^\infty(\RR^d)}^{1/p} \leq \| f \|_{L^1(\RR^d)} + \| f \|_{L^\infty(\RR^d)} \leq 2 \| f \|_{0,d+1}. \]
    %
%   This implies $\| \cdot \|_{L^p(\RR^d)}$ is bounded.

%   A simple calculation using the Leibnitz formula shows that if $|\alpha| \leq n$,
    %
%   \begin{align*}
%       (1 + |x|^m) |\mathcal{F}(f)_\alpha| &\leq |\mathcal{F}(f)_\alpha| + \sum_{k = 1}^d |x_k^m \mathcal{F}(f)_\alpha|\\
%       &\leq (2 \pi)^n \left( \| \mathcal{F} f \|_{L^\infty(\RR^d)} + \sum_{k = 1}^d |\mathcal{F}((x^\alpha f)_{me_k})| \right)\\
%       &\leq n! (2 \pi)^n 2^m (n+1) \max_{0 \leq k \leq d} \max_{1 \leq l \leq m} \left( \| \mathcal{F} f \|_{L^\infty(\RR^d)} + \sum_{k = 1}^n \max_{1 \leq l \leq m} \| \mathcal{F}(f_{le_k}) \|_{L^\infty(\RR^d)} \right)\\
%       &\leq n! (2 \pi)^n 2^m \left( \| f \|_{L^1(\RR^d)} + \sum_{k = 1}^n \max_{1 \leq l \leq m} \| f_{le_k} \|_{L^1(\RR^d)} \right)\\
%       &\leq n! (2 \pi)^n 2^m 2^d (n+1) \| f \|_{n,d+1}.
%   \end{align*}

%   there are constants $c_{\alpha \beta \gamma}$ for each $\gamma \leq \alpha \wedge \beta$ such that
    %
%   \begin{align*}
%       |x^\alpha \mathcal{F}(f)_\beta| &= (2 \pi)^{|\beta|} |x^\alpha \cdot \mathcal{F}(x^\beta f)|\\
%       &= (2\pi)^{|\beta| - |\alpha|} \mathcal{F}((x^\beta f)_\alpha)\\
%       &\leq (2\pi)^{|\beta| - |\alpha|} \sum_{\gamma \leq \alpha \wedge \beta} c_{\alpha \beta \gamma} |\mathcal{F}(x^{\beta - \gamma} f_{\alpha - \gamma})|.
%   \end{align*}
    %
%   This calculation shows
    %
%   \begin{align*}
%       \| \mathcal{F} f \|_{\alpha,\beta} &\lesssim_{\alpha,\beta} \sum \| \mathcal{F}(x^{\beta - \gamma} f_{\alpha - \gamma}) \|_{L^\infty(\RR^n)}\\
%       &\leq \sum \| x^{\beta - \gamma} f_{\alpha - \gamma} \|_{L^1(\RR^n)}.
%   \end{align*}
    %
%   The right hand side is a continuous function of $f$, so the Fourier transform is bounded. The smoothness of the Schwartz space implies that $\mathcal{F}$ is a bijective map. But then the open mapping theorem implies that $\mathcal{F}^{-1}$ is a bounded operation, and therefore $\mathcal{F}$ is a homeomorphism.

    We leave all but the last point as exercises. Here it will be convenient to use the norms $\| \cdot \|_{\mathcal{S}^{\alpha,\beta}(\RR^d)}$ as well as the norms $\| \cdot \|_{\mathcal{S}^{n,m}(\RR^d)}$. If $|\alpha| \leq m$, $|\beta| \leq n$, then we can use the Leibnitz formula to conclude that
    %
    \begin{align*}
        \| \xi^\alpha D^\beta \mathcal{F}(f) \|_{L^\infty(\RR^d)} &\lesssim_{\alpha,\beta} \| \mathcal{F}(D^\alpha(x^\beta f)) \|_{L^\infty(\RR^d)}\\
        &\lesssim_{\alpha,\beta} \max_{\gamma \leq \alpha \wedge \beta} \| \mathcal{F}(x^{\gamma} D^\gamma f) \|_{L^\infty(\RR^d)}\\
        &\leq \max_{\gamma \leq \alpha \wedge \beta} \| x^\gamma D^\gamma f \|_{L^1(\RR^d)}\\
        &\lesssim \| f \|_{\mathcal{S}^{\gamma,|\gamma| + d+1}(\RR^d)}.
    \end{align*}
    %
    Thus $\mathcal{F}$ is a bounded linear operator on $\mathcal{S}(\RR^d)$. Since all Schwartz functions are arbitrarily smooth, the Fourier inversion formula applies to all Schwartz functions, and so $\mathcal{F}$ is a bijective bounded linear operator with inverse $\mathcal{F}^{-1}$. The open mapping theorem then immediately implies that $\mathcal{F}^{-1}$ is bounded.
\end{proof}

\begin{corollary}
    If $f$ and $g$ are Schwartz, then $f * g$ is Schwartz.
\end{corollary}
\begin{proof}
    Since $f * g = \mathcal{F}^{-1}(\mathcal{F}(f) \mathcal{F}(g))$, this fact follows from the previous two lemmas.
\end{proof}

Now we get to the interesting part of the theory. We have defined a homeomorphic linear transform from $\mathcal{S}(\RR^d)$ to itself. The theory of functional analysis then says that we can define a dual map, which is a homeomorphism from the dual space $\mathcal{S}(\RR^d)^*$ to itself. Note the inclusion map $C_c^\infty(\RR^d) \to \mathcal{S}(\RR^d)$ is continuous, and $C_c^\infty(\RR^d)$ is dense in $\mathcal{S}(\RR^d)$. This implies that we have an injective, continuous map from $\mathcal{S}^*(\RR^d)$ to $(C_c^\infty)^*(\RR^d)$, so every functional on the Schwarz space can be identified with a distribution. We call such distributions \emph{tempered}. They are precisely the linear functionals on $C_c^\infty(\RR^d)$ which have a continuous extension to $\mathcal{S}(\RR^d)$. Intuitively, this corresponds to an asymptotic decay condition.

\begin{example}
    Recall that for any $f \in L^1_{\text{loc}}(\RR^d)$, we can consider the distribution $\Lambda[f]$ defined by setting
    %
    \[ \Lambda[f](\phi) = \int f(x) \phi(x)\; dx. \]
    %
    However, this distribution is not always tempered. If $f \in L^p(\RR^d)$ for some $p$, then, applying H\"{o}lder's inequality, we obtain that
    %
    \[ |\Lambda[f](\phi)| \leq \| f \|_{L^p(\RR^d)} \| \phi \|_{L^q(\RR^d)}. \]
    %
    Since $\| \cdot \|_{L^q(\RR^d)}$ is a continuous norm on $\mathcal{S}(\RR^d)$, this shows $\Lambda[f]$ is bounded. More generally, if $f \in L^1_{\text{loc}}(\RR^d)$, and $f(x) (1 + |x|)^{-m}$ is in $L^p(\RR^d)$ for some $m$, then $\Lambda[f]$ is a tempered distribution. If $p = \infty$, such a function is known as \emph{slowly increasing}.
\end{example}

\begin{example}
    For any Radon measure, $\mu$, we can define a distribution
    %
    \[ \Lambda[\mu](\phi) = \int \phi(x) d\mu(x) \]
    %
    But this distribution is not always tempered. If $|\mu|$ is finite, the inequality $\| \Lambda[\mu](\phi) \| \leq \| \mu \| \| \phi \|_{L^\infty(\RR^d)}$ gives boundedness. More generally, if $\mu$ is a measure such that for some $n$,
    %
    \[ \int_{\RR^d} \frac{d|\mu|(x)}{1 + |x|^n}\; dx < \infty \]
    %
    then $\mu$ is known as a \emph{tempered measure}, and acts as a tempered distribution since
    %
    \begin{align*}
      |\Lambda[\mu](\phi)| &\leq \int_{\RR^d} |\phi(x)|\; d|\mu|(x)\\
      &\leq \left( \int_{\RR^d} \frac{d|\mu|(x)}{1 + |x|^n}\; dx \right) \cdot \| \phi \|_{\mathcal{S}^{0,n}(\RR^d)}.
    \end{align*}
\end{example}

\begin{example}
  Any compactly supported distribution is tempered. Indeed, if $\Lambda$ is a distribution supported on a compact set $K$, then it has finite order $n$ for some integer $n$, and extends to an operator on $C^\infty(\RR^d)$. We then find
  %
  \[ |\Lambda(\phi)| \lesssim \| \phi \|_{C^n(\RR^d)} \leq \| \phi \|_{\mathcal{S}^{0,n}(\RR^d)}. \]
\end{example}

\begin{example}
  The distribution $\Lambda$ on $\RR$ given by
  %
  \[ \Lambda(\phi) = \text{p.v.} \int_{-\infty}^\infty \frac{\phi(x)}{x}\; dx \]
  %
  is tempered, since
  %
  \[ \int_{|x| \geq 1} \frac{\phi(x)}{x} \lesssim \| \phi \|_{\mathcal{S}^{1,0}(\RR^d)} \]
  %
  and
  %
  \[ \text{p.v.} \int_{-\infty}^\infty \frac{\phi(x)}{x}\; dx \lesssim \| \phi \|_{C^1(\RR^d)} = \| \phi \|_{\mathcal{S}^{0,1}(\RR^d)} \]
  %
  and so $\Lambda$ is tempered of order 1.
\end{example}

Using the same techniques as for distributions, the derivative $D^\alpha \Lambda$ of a tempered distribution $\Lambda$ is tempered, as is $\phi \Lambda$, whenever $\phi$ is a Schwartz function, or $f \Lambda$, where $f$ is a polynomial. Of course, we can multiply by polynomially increasing smooth functions as well.

Let us now apply the distributional method to define the Fourier transform of a tempered distribution. Recall that we heuristically think of $\Lambda$ as formally corresponding to a regular function $f$ such that
%
\[ \Lambda(\phi) = \int f(x) \phi(x)\; dx \]
%
The multiplication formula
%
\[ \int_{\RR^d} \widehat{f}(\xi) g(\xi)\; d\xi = \int_{\RR^d} f(x) \widehat{g}(x)\; dx \]
%
gives us the perfect opportunity to move the analytical operations on $f$ to analytical operations on $g$. Thus if $\Lambda$ is the distribution corresponding to a Schwartz $f \in \mathcal{S}(\RR^d)$, the distribution $\widehat{\Lambda}$ corresponding to $\widehat{f}$, then for any Schwartz $\phi \in \mathcal{S}(\RR^d)$,
%
\[ \widehat{\Lambda}(\phi) = \Lambda \left( \widehat{g} \right). \]
%
In particular, this motivates us to define the Fourier transform of \emph{any} tempered distribution $\Lambda$ to be the unique tempered distribution $\widehat{\Lambda}$ such that the equation above holds for all Schwartz $\phi$. This distribution exists because the Fourier transform is an isomorphism on the space of Schwartz functions. Clearly, the Fourier transform is a homeomorphism on the space of tempered distributions under the weak topology, and moreover, satisfies all the symmetry properties that the ordinary Fourier transform does, once we interpret scalar, rotation, translation, differentiation, etc, in a natural way on the space of distributions.

\begin{example}
    Consider the constant function $1$, interpreted as a tempered distribution on $\RR^d$. Then for any $\phi \in \mathcal{S}(\RR^d)$,
    %
    \[ 1(\phi) = \int \phi(x)\; dx, \]
    %
    Thus for any $\phi \in \mathcal{S}(\RR^d)$,
    %
    \[ \widehat{1} \left( \widehat{\phi} \right) = 1(\phi) = \int \phi(\xi)\; d\xi = \widehat{\phi}(0). \]
    %
    Thus $\widehat{1}$ is the Dirac delta function at the origin. Similarily, the Fourier inversion formula implies that
    %
    \[ \widehat{\delta} \left( \widehat{\phi} \right) = \phi(0) = \int \widehat{\phi}(\xi)\; d\xi = 1 \left( \widehat{\phi} \right) \]
    %
    so the Fourier transform of the Dirac delta function is the constant 1 function.
\end{example}

\begin{example}
  The theory of tempered distributions enables us to take the Fourier transform of $f \in L^p(\RR^d)$, when $p > 2$ or when $p < 1$. The introduction of distributions is in some sense, essential to this process, because for each $p \not \in [1,2]$, there is $f \in L^p(\RR^d)$ such that $\widehat{f}$ is \emph{not} a locally integrable function. Otherwise, we could define an operator $T: L^p(\RR^d) \to L^1(\RR^d)$ given by
  %
  \[ Tf = \widehat{f} \mathbf{I}_{|\xi| \leq 1}. \]
  %
  If a sequence of functions $\{ f_n \}$ converges to $f$ in $L^p(\RR^d)$, and $Tf_n$ converges to $g$ in $L^1(\RR^d)$, then $Tf_n$ converges distributionally to $g$, which implies $Tf = g$. The closed graph theorem thus implies that $T$ is a continuous operator from $L^p(\RR^d)$ to $L^1(\RR^d)$, so there exists $M > 0$ such that
  %
  \[ \int_{|\xi| \leq 1} |\widehat{f}(\xi)| \leq M \| f \|_{L^p(\RR^d)}. \]
  %
  If $f_\alpha(x) = e^{-\pi \alpha |x|^2}$, then $\widehat{f_\alpha}(\xi) = \alpha^{-d/2} e^{-\pi |x|^2 / \alpha}$. We have
  %
  \begin{align*}
    \| f_\alpha \|_{L^p(\RR^d)} &= \left( \int_{\RR^d} e^{- \pi \alpha p |x|^2}\; dx \right)^{1/p}\\
    &= (\alpha p)^{-d/2p} \left( \int_{\RR^d} e^{- \pi |x|^2}\; dx \right)^{1/p} \lesssim_d (\alpha p)^{-1/2p}.
  \end{align*}
  %
  On the other hand, for $|\xi| \leq 1$, $|\widehat{f_\alpha}(\xi)| \geq \alpha^{-d/2} e^{-\pi/\alpha}$, so
  %
  \[ \int_{|\xi| \leq 1} |\widehat{f_\alpha}(\xi)| \gtrsim_d \alpha^{-d/2} e^{-\pi/\alpha}. \]
  %
  Thus we conclude that $\alpha^{-d/2} e^{-\pi/\alpha} \lesssim_d M (\alpha p)^{-d/2p}$, or equivalently,
  %
  \[ \alpha^{d/2(1/p-1)} e^{-\pi/\alpha} \lesssim_d M p^{-d/2p}. \]
  %
  Taking $\alpha \to \infty$ gives a contradiction if $p < 1$. For $p > 2$, we give the Gaussian an oscillatory factor that does not affect the $L^p$ norm but boosts the $L^1$ norm of the Fourier transform. We set
  %
  \[ g_\delta(x) = \prod_{k = 1}^d \frac{e^{- \pi x_k^2 / (1 + i \delta)}}{(1 + i \delta)^{1/2}}. \]
  %
  The Fourier transform formula of the Gaussian, when applied using the theory of analytic continuation, shows that
  %
  \[ \widehat{g_\delta}(\xi) = \prod_{k = 1}^d e^{- \pi (1 + i \delta) \xi_k^2}. \]
  %
  We have
  %
  \[ \int_{|\xi| \leq 1} |\widehat{g_\delta}(\xi)| = \int_{|\xi| \leq 1} e^{- \pi |\xi|^2} \gtrsim 1. \]
  %
  On the other hand, for $\delta \geq 1$,
  %
  \begin{align*}
    \| g_\delta \|_{L^p(\RR^d)} &= \left( \int |g_\delta(x)|^p\; dx \right)^{1/p}\\
    &= |1 + i \delta|^{-d/2} \left( \int_{-\infty}^\infty e^{- p \pi x^2/(1 + \delta^2)}\; dx \right)^{d/p}\\
    &\lesssim_d \delta^{-d/2} \delta^{d/p} p^{-d/p} = \delta^{d(1/p - 1/2)} p^{-d/p}.
  \end{align*}
  %
  Thus we conclude $1 \lesssim_d M \delta^{d(1/p - 1/2)} p^{d/p}$, which gives a contradiction as $\delta \to \infty$ if $p > 2$.
\end{example}

\begin{example}
  Consider the Riesz Kernel on $\RR^d$, for each $\alpha \in \CC$ with positive real part, as the function
  %
  \[ K_\alpha(x) = \frac{\Gamma(\alpha/2)}{\pi^{\alpha/2}} |x|^{-\alpha}. \]
  %
  Then for $0 < \text{Re}(\alpha) < d$, $\widehat{K_\alpha} = K_{d-\alpha}$. We recall that $\Gamma$ is defined by the integral formula
  %
  \[ \Gamma(s) = \int_0^\infty e^{-t} t^{s-1}\; ds, \]
  %
  where $\text{Re}(s) > 0$. We note that if $p = d/\text{Re}(\alpha)$, $K_\alpha \in L^{p,\infty}(\RR^d)$. The Marcinkiewicz interpolation theorem implies that if $d/2 < \text{Re}(\alpha) < d$, then $K_\alpha$ can be decomposed as the sum of a $L^1(\RR^d)$ function and a $L^2(\RR^d)$ function, and so we can intepret the Fourier transform of $\widehat{K_\alpha}$ using techniques in $L^1(\RR^d)$ and $L^2(\RR^d)$, and moreover, the Marcinkiewicz interpolation theorem implies that
  %
  \[ \| \widehat{K_\alpha} \|_{L^{q,\infty}(\RR^d)} \leq \| K_\alpha \|_{L^{p,\infty}(\RR^d)}. \]
  %
  where $q$ is the dual of $p$. In particualr, the Fourier transform of $K_\alpha$ is a function. We note that $K_\alpha$ obeys multiple symmetries. First of all, $K_\alpha$ is radial, so $\widehat{K_\alpha}$ is also radial. Moreover, $K_\alpha$ is homogenous of degree $-\alpha$, i.e. for each $x \in \RR^d$, $K_\alpha(\varepsilon x) = \varepsilon^{-\alpha} K_\alpha(x)$. This actually uniquely characterizes $K_\alpha$ among all locally integrable functions. Taking the Fourier transform of both sides of the equation for homogeneity, we find
  %
  \[ \varepsilon^{-d} \widehat{K_\alpha}(\xi/\varepsilon) = \varepsilon^{-\alpha} \widehat{K_\alpha}(x). \]
  %
  Thus $\widehat{K_\alpha}$ is homogenous of degree $\alpha - d$. But this uniquely characterizes $\widehat{K_{d-\alpha}}$ out of any distribution, up to multiplicity, so we conclude that for $d/2 < \text{Re}(\alpha) < d$, that $\widehat{K_\alpha}$ is a scalar multiple of $K_{d-\alpha}$. But we know that by a change into polar coordinates, if $A_d$ is the surface area of a unit sphere in $\RR^d$, then
  %
  \begin{align*}
    \int_{\RR^d} K_\alpha(x) e^{- \pi |x|^2}\; dx &= \frac{\Gamma(\alpha/2)}{\pi^{\alpha/2}} \int_{\RR^d} |x|^{-\alpha} e^{-\pi |x|^2}\; dx\\
    &= A_d \frac{\Gamma(\alpha/2)}{\pi^{\alpha/2}} \int_0^\infty r^{d-1-\alpha} e^{- \pi r^2}\; dr\\
    &= A_d \frac{\Gamma(\alpha/2)}{2 \pi^{d/2}} \int_0^\infty s^{(d-\alpha)/2 - 1} e^{-s}\; ds\\
    &= A_d \frac{\Gamma(\alpha/2) \Gamma((d-\alpha)/2)}{\pi^{d/2}}.
  \end{align*}
  %
  But this is also the value of
  %
  \[ \int_{\RR^d} K_{d - \alpha}(x) e^{- \pi |x|^2}, \]
  %
  so we conclude $\widehat{K_\alpha} = K_{d-\alpha}$ if $d/2 < \text{Re}(\alpha) < d$. We could apply Fourier inversion to obtain the result for $0 < \text{Re}(\alpha) < d/2$, but to obtain the case $\text{Re}(\alpha) = d/2$, we must apply something different. For each $s \in \CC$ with $0 < \text{Re}(s) < d$, and for each Schwartz $\phi \in \mathcal{S}(\RR^d)$ we define
  %
  \[ A(s) = \int K_s(\xi) \widehat{\phi}(\xi)\; d\xi = \frac{\Gamma(s/2)}{\pi^{s/2}} \int |\xi|^{-s/2} \widehat{\phi}(\xi)\; d\xi. \]
  %
  and
  %
  \[ B(s) = \int K_{d-s}(\xi) \widehat{\phi}(\xi)\; d\xi = \frac{\Gamma((d-s)/2)}{\pi^{(d-s)/2}} \int |\xi|^{(d-s)/2} \widehat{\phi}(\xi)\; d\xi. \]
  %
  The integrals above converge absolutely for $0 < \text{Re}(s) < d$, and the dominated convergence theorem implies that $A$ and $B$ are both complex differentiable. Since $A(s) = B(s)$ for $d/2 < \text{Re}(s) < d$, analytic continuation implies $A(s) = B(s)$ for all $0 < \text{Re}(s) < d$, completing the proof. For $\text{Re}(\alpha) \geq d$, $K_\alpha$ is no longer locally integrable, and so we must interpret the distribution given by integration by $K_\alpha$ in terms of principal values. The fourier transform of these functions then becomes harder to define.
\end{example}

\begin{example}
  Let us consider the complex Gaussian defined, for a given invertible symmetric matrix $T: \RR^d \to \RR^d$, as $G_T(x) = e^{- i \pi (Tx \cdot x)}$. Then
  %
  \[ \widehat{G_T} = e^{- i \pi \sigma/4} |\det(T)|^{-1/2} G_{-T^{-1}}, \]
  %
  where $\sigma$ is the \emph{signature} of $T$, i.e. the number of positive eigenvalues, minus the number of negative eigenvalues, counted up to multiplicity. Thus we need to show that for any Schwartz $\phi \in \mathcal{S}(\RR^d)$,
  %
  \[ e^{-i \pi \sigma/4} |\det(T)|^{-1/2} \int_{\RR^d} e^{i \pi (T^{-1}\xi \cdot \xi)} \widehat{\phi}(\xi)\; d\xi = \int_{\RR^d} e^{- i \pi (Tx \cdot x)} \phi(x)\; dx. \]
  %
  Let us begin with the case $d = 1$, in which case we also prove the theorem when $T$ is a complex symmetric matrix. If $T$ is given by multiplication by $-iz$, and if $\sqrt{\cdot}$ denotes the branch of the square root defined for all non-negative numbers and positive on the real-axis, then we note that when $z = \lambda i$,
  %
  \[ e^{- i \pi \sigma/4} |\det(T)|^{-1/2} = e^{- i \pi \text{sgn}(\lambda)/4} |\lambda|^{-1/2} = \sqrt{z}. \]
  %
  Thus it suffices to prove the analytic family of identities
  %
  \[ \int_{-\infty}^\infty e^{- (\pi/z) \xi^2} \widehat{\phi}(\xi)\; d\xi = \sqrt{z} \int_{-\infty}^\infty e^{-\pi z x^2} \phi(x)\; dx, \]
  %
  where both sides are well defined and analytic whenever $z$ has positive real part. But we already know from the Fourier transform of the Gaussian that this identity holds whenever $z$ is positive and real, and so the remaining identities follows by analytic continuation. We note that the higher dimensional identity is invariant under changes of coordinates in $SO(n)$. Thus it suffices to prove the remaining theorem when $T$ is diagonal. But then everything tensorizes and reduces to the one dimensional case. More generally, if $T = T_0 - i T_1$ is a complex symmetric matrix, which is well defined if $T_1$ is positive semidefinite, then
  %
  \[ \widehat{G_T} = \frac{1}{\sqrt{i \det(T)}} \cdot G_{-T^{-1}}, \]
  %
  which follows from analytic continuation of the case for real $T$.
\end{example}

\begin{example}
    We know $((-2 \pi i x)^\alpha)^\ft = ((- 2 \pi i x)^\alpha \cdot 1)^\ft = \delta_\alpha$, which essentially provides us a way to compute the Fourier transform of any polynomial, i.e. as a linear combination of dirac deltas and the distribution derivatives of dirac deltas, which are derivatives evaluated at points.
\end{example}

\begin{theorem}
    If $\mu$ is a finite measure, $\widehat{\mu}$ is a uniformly continuous bounded function with $\| \widehat{\mu} \|_{L^\infty(\RR^d)} \leq \| \mu \|$, and
    %
    \[ \widehat{\mu}(\xi) = \int e(- 2 \pi i x \cdot \xi) d\mu(x) \]
    %
    The function $\widehat{\mu}$ is also smooth if $\mu$ has moments of all orders, i.e. $\int |x|^k d\mu(x) < \infty$ for all $k > 0$.
\end{theorem}
\begin{proof}
    Let $\phi \in \mathcal{S}(\RR^d)$. We must understand the integral
    %
    \[ \int_{\RR^d} \widehat{\phi}(x)\; d\mu(x). \]
    %
    Applying Fubini's theorem, which applies since $\mu$ has finite mass, we conclude that
    %
    \[ \int_{\RR^d} \widehat{\phi}(x)\; d\mu(x) = \int_{\RR^d} \int_{\RR^d} \phi(\xi) e^{-2 \pi i \xi \cdot x} d\mu(x)\; d\xi = \int_{\RR^d} \phi(\xi) f(\xi)\; d\xi, \]
    %
    where
    %
    \[ f(\xi) = \int_{\RR^d} e^{-2 \pi i \xi x} d\mu(x). \]
    %
    Thus $\widehat{\mu}$ is precisely $f$, and it suffices to show that $\| f \|_{L^\infty(\RR^d)} \leq \| \mu \|$, and that $f$ is uniformly continuous. The inequality follows from a simple calculation of the triangle inequality, and the second inequality follows because for some $y$,
    %
    \begin{align*}
      |f(\xi + \eta) - f(\xi)| &= \left| \int_{\RR^d} e^{-2 \pi i \xi \cdot x} (e^{-2 \pi i \eta \cdot x} - 1)\; d\mu(x) \right|\\
      &\leq \int_{\RR^d} |e^{-2 \pi i \eta \cdot x} - 1|\; d|\mu|(x).
    \end{align*}
    %
    As $\eta \to 0$, the dominated convergence theorem implies that this quantity tends to zero, which proves uniform continuity. On the other hand, if $x_i \mu$ is finite for some $i$, then
    %
    \begin{align*}
      \frac{f(\xi + \varepsilon e_i) - f(\xi)}{\varepsilon} &= \int_{\RR^d} e^{-2 \pi i \xi \cdot x} \frac{(e^{- 2 \pi \varepsilon i x_i} - 1)}{\varepsilon} d\mu(x).
    \end{align*}
    %
    We can apply the dominated convergence theorem to show that as $\varepsilon \to 0$, this quantity converges to the classical partial derivative $f_i$, which has the integral formula
    %
    \[ f_i(\xi) = (-2 \pi i) \int_{\RR^d} e^{-2 \pi i \xi \cdot x} x_i d\mu(x), \]
    %
    which is the Fourier transform of $x_i \mu$. Higher derivatives are similar.
\end{proof}

Not being compactly supported, we cannot compute the convolution of tempered distributions with all $C^\infty$ functions. Nonetheless, if $\phi$ is Schwartz, and $\Lambda$ is tempered, then the definition $(\Lambda * \phi)(x) = \Lambda(T_{-x} \phi^*)$ certainly makes sense, and gives a $C^\infty$ function satisfying $D^\alpha(\Lambda * \phi) = (D^\alpha \Lambda) * \phi = \Lambda * (D^\alpha \phi)$ just as for $\phi \in C_c^\infty(\RR^d)$. Moreover, $\Lambda * \phi$ is a slowly increasing function; to see this, we know there is $n$ such that
%
\[ |\Lambda \phi| \lesssim \| \phi \|_{\mathcal{S}^{n,m}(\RR^d)}. \]
%
Now for $|y| \geq 1$,
%
\[ \| T_y \phi \|_{\mathcal{S}^{n,m}(\RR^d)} \leq |x-y|^n \leq 2^n (1 + |y|^n) \| \phi \|_{\mathcal{S}^{n,m}(\RR^d)}, \]
%
and so
%
\[ (\Lambda * \phi)(x) = \Lambda(T_{-x} \phi^*) \lesssim_n (1 + |x|^n) \| \phi \|_{\mathcal{S}^{n,m}(\RR^d)}, \]
%
which gives that $\Lambda * \phi$ is slowly increasing. In particular, we can take the Fourier transform of $\Lambda * \phi$. Now for any $\psi \in \mathcal{S}(\RR^d)$ with $\widehat{\psi} \in C_c^\infty(\RR^d)$,
%
\begin{align*}
  \int_{\RR^d} \widehat{\Lambda * \phi}(\xi) \psi(\xi)\; d\xi &= \int_{\RR^d} (\Lambda * \phi)(x) \widehat{\psi}(x)\; dx\\
  &= \int_{\RR^d} \Lambda( \widehat{\psi}(x) \cdot T_{-x} \phi^*)\; dx\\
  &= \Lambda \left( \int_{\RR^d} \widehat{\psi}(x) T_{-x} \phi^*\; dx \right)\\
  &= \Lambda \left( \widehat{\psi} * \phi^* \right) = \Lambda \left( \widehat{\psi} * \widehat{\widehat{\phi}} \right)\\
  &= \Lambda \left( \widehat{\psi \widehat{\phi}} \right) = \widehat{\Lambda} \left( \psi \widehat{\phi} \right) = \widehat{\phi} \widehat{\Lambda}(\psi).
\end{align*}
%
We therefore conclude that $\widehat{\Lambda * \phi} = \widehat{\phi} \widehat{\Lambda}$.

\section{Paley-Wiener Theorems}

TODO: See Rudin, Functional Analysis.








\chapter{Spectral Analysis of Singularities}

Suppose $u$ is a compactly supported distribution on $\RR^d$. The \emph{singular support} of a distribution $u$ are the set of points $x_0 \in \RR^d$ which \emph{do not} have an open neighbourhood upon which $u$ acts as integration against a $C^\infty$ function. Understanding the singular support of a distribution, and how to control it, is often a useful perspective in harmonic analysis. For instance, to reduce the study of $u$ to the study of a $C^\infty$ function one need only smoothen around the singular support of $u$.

The smoothness of a distribution is linked to the decay of it's Fourier transform. In particular, suppose there is a compactly supported bump function $\phi \in C^\infty(\RR^d)$ with $\phi(x) = 1$ in a neighbourhood of some point $x_0 \in \RR^d$. Since $\phi u$ is compactly supported, $\widehat{\phi u}$ is an analytic function. If for all $N \geq 0$, we find
%
\begin{equation}
  |\widehat{\phi u}(\xi)| \lesssim_N \frac{1}{1 + |\xi|^N}
\end{equation}
%
then we conclude $\phi u \in C^\infty(\RR^d)$. Thus we can infer the singular support of $u$ via purely spectral means, provided we are first able to localize about a point.

We can also gain more detailed information about the singularities of a distribution $u$ through the Fourier transform. If $x_0$ is a singularity of $u$, then for any bump function $\phi \in C^\infty(\RR^d)$ with $\phi(x) = 1$ in a neighbourhood of $x_0$, there must exist a value $\xi_0 \neq 0$ such that there exists no conical neighbourhood $U$ from the origin containing $\xi_0$ such that for all $\xi \in U$ and all $N > 0$,
%
\begin{equation} \label{nonsingularfourierdecay}
  |\widehat{u \phi}(\xi)| \lesssim_N \frac{1}{1 + |\xi|^N}.
\end{equation}
%
Since the set of such values $\xi_0$ itself forms a closed conical set about the origin, a compactness argument shows that the set of values $\xi_0$ which does not satisfy \eqref{nonsingularfourierdecay} for any choice of bump function $\phi$ around $x_0$ is nonempty. This is called the \emph{wavefront} of $u$ about the singularity $x_0$. The set
%
\[ \text{WF}(u) = \{ (x_0,\xi_0) : \xi_0\ \text{is in the wavefront of $u$ at $x_0$} \} \]
%
is the \emph{wavefront} of the distribution, and provides a deeper characterization of the singularities of $u$. For instance, in order to smoothen out a distribution $u$ one need only average along the directions in the wave-front set.

\begin{remark}
  Why does this not defy the uncertainty principle heuristically?
\end{remark}

Let us now argue a little more precisely. If $u$ is a compactly supported distribution on $\RR^d$, we define $\Gamma(u)$ to be the set of $\xi_0 \in \RR^d$ which have no conical neighbourhood $U$ such that for each $N > 0$ and $\xi \in U$,
%
\begin{equation} \label{fastDecayEquation}
  |\widehat{u}(\xi)| \lesssim_N \frac{1}{1 + |\xi|^N}.
\end{equation}
%
It is simple to verify that if $\Gamma(u) = \emptyset$, then $u \in C^\infty(\RR^d)$.

\begin{lemma} \label{wavefrontlocalizationlemma}
  If $u$ is a compactly supported distribution and $\phi \in C_c^\infty(\RR^d)$, then
  %
  \[ \Gamma(\phi u) \subset \Gamma(u). \]
\end{lemma}
\begin{proof}
  Suppose $\xi_0 \not \in \Gamma(u)$, so $\xi_0$ has a conical neighbourhood $U$ such that \eqref{fastDecayEquation} holds. Then there exists $\varepsilon > 0$ such that $U$ contains
  %
  \[ \left\{ \eta \in \RR^d : \frac{\xi_0 \cdot \eta}{|\xi_0| |\eta|} \geq 1 - 2\varepsilon \right\} \]
  %
  Let $V$ be the conical neighbourhood of $\xi_0$ defined by setting
  %
  \[ V = \left\{ \eta \in \RR^d : \frac{\xi_0 \cdot \eta}{|\xi_0| |\eta|} \geq 1 - \varepsilon \right\}. \]
  %
  We claim $V$ satisfies \eqref{fastDecayEquation}. Fix $\xi \in V$. Then
  %
  \[ |\widehat{\phi u}(\xi)| = (\widehat{\phi} * \widehat{u})(\xi) = \int_{\RR^d} \widehat{\phi}(\eta) \widehat{u}(\xi - \eta)\; d\xi. \]
  %
  If $|\xi - \eta| \leq 0.25 \varepsilon |\xi|$, then it is simple to verify that
  %
  \[ (\xi_0 \cdot \eta) \geq (1 - 2\varepsilon) |\xi_0| |\eta| \]
  %
  so $\eta \in U$. Thus for any $N > 0$, $\widehat{u}(\eta) \lesssim_N 1/(1 + |\eta|)^N$. Since $\phi \in L^\infty(\RR^d$, we conclude
  %
  \begin{align*}
    \int_{|\eta| \leq 0.25 \varepsilon |\xi|} \widehat{\phi}(\eta) \widehat{u}(\xi - \eta)\; d\xi &\lesssim_{\phi} \int_{|\eta| \leq 0.25 \varepsilon |\xi|} \frac{1}{1 + |\xi - \eta|^N}\\
    &\lesssim_{\varepsilon,d} \frac{|\xi|^d}{(1 + 2 |\xi|^{N})} \lesssim \frac{1}{1 + |\xi|^{N-d}}.
  \end{align*}
  %
  On the other hand, since $u$ is compactly supported, $\widehat{u}$ is slowly increasing, i.e. there exists $m > 0$ such that
  %
  \[ |\widehat{u}(\xi)| \leq 1 + |\xi|^m. \]
  %
  Since $\phi \in C_c^\infty(\RR^d)$, we have $|\widehat{\phi}(\eta)| \lesssim_M 1/(1 + |\eta|^M)$ for all $M > 0$ and thus we conclude that if $M > m + d$
  %
  \begin{align*}
    \int_{|\eta| \geq 0.25 \varepsilon |\xi|} \widehat{\phi}(\eta) \widehat{u}(\xi - \eta) &\lesssim_M \int_{|\eta| \geq 0.25 \varepsilon |\xi|} \frac{1 + |\xi - \eta|^m}{1 + |\eta|^M}\\
    &\lesssim_{\varepsilon,m} \int_{|\eta| \geq 0.25 \varepsilon |\xi|} \frac{1 + |\eta|^m}{1 + |\eta|^M}\\
    &\lesssim_{\varepsilon,d} \frac{1}{1 + |\xi|^{M-m-d}}.
  \end{align*}
  %
  Choosing the parameter $M$ and $N$ appropriately, we obtain the required bound which shows that $\xi_0 \not \in \Gamma(\phi u)$.
\end{proof}

This fact means we can obtain a consistant localization about a point. If $u$ is a distribution, and $\phi_1,\phi_2 \in C_c^\infty(\RR^d)$ are given and the support of $\phi_2$ is compactly supported on the support of $\phi_1$, then $\phi_2/\phi_1 \in C_c^\infty(\RR^d)$, and so we conclude that
%
\[ \Gamma(\phi_2 u) = \Gamma((\phi_2/\phi_1) \phi_1 u) \subset \Gamma(\phi_1 u). \]
%
Thus if $u$ is a distribution, and $x \in \RR^d$, then we define $\Gamma_x(U)$ to be equal to
%
\[ \bigcap \left\{ \Gamma(\phi u) : \phi \in C_c^\infty(\RR^d), x \in \text{supp}(\phi) \right\}. \]
%
It is simple to see that if $\{ \phi_n \}$ is a sequence in $C_c^\infty(\RR^d)$ such that $\text{supp}(\phi_{n+1})$ is compactly supported in $\text{supp}(\phi_n)$ for each $n$, and if $\bigcap \text{supp}(\phi_n) = \{ x \}$, then $\Gamma_x(u) = \lim_{n \to \infty} \Gamma(\phi_n u)$. Finally, we define
%
\[ \text{WF}(u) = \{ (x,\xi): \xi \in \Gamma_x(u) \}. \]
%
This is the \emph{wavefront set} of $u$.

\begin{lemma}
  If $u$ is a compactly supported distribution, then the projection $\pi_x(\text{WF}(u))$ is the singular support of $u$, and the projection $\pi_\xi(\text{WF}(u))$ is the set $\Gamma(u)$ of singular frequencies.
\end{lemma}
\begin{proof}
  Fix $x \in \RR^d$ and suppose $x \not \in \pi_x(\text{WF}(u))$. Then by a compactness argument, there exists $\phi \in C_c^\infty(\RR^d)$ with $\phi(x) \neq 0$ and with $\Gamma(\phi u) = \emptyset$, which implies $\phi u \in C^\infty(\RR^d)$. But this means that $u$ is $C^\infty$ in a neighbourhood of $x$, so $x$ is not a singular point.

  Now suppose $\xi \in \RR^d$ and $\xi \not \in \pi_\xi(\text{WF}(u))$.
\end{proof}

\begin{example}
  Suppose $u$ is a homogenous distribution which is $C^\infty$ away from the origin. Then $\widehat{u}$ is homogenous and $C^\infty$ away from the origin, and we claim that
  %
  \[ \text{WF}(u) = \{ (0,\xi): \xi \in \text{supp}(\widehat{u}) \}. \]
  %
  Since the singular support of $u$ is $\{ 0 \}$, it suffices to calculate $\Gamma_0(u)$. Fix a radial bump function $\phi \in C_c^\infty(\RR^d)$ with $\phi(0) = 1$. If $\xi_0$ is \emph{not} in the support of $\widehat{u}$, then $\widehat{u}$ vanishes on a conical neighbourhood of $\xi_0$, and so it follows from similar arguments to Lemma \ref{wavefrontlocalizationlemma} that $\xi_0 \not \in \Gamma(u \phi)$. Conversely, suppose $\widehat{u}(\xi_0) \neq 0$. Let $\beta > 0$ be the degree of $\widehat{u}$. For each $\varepsilon > 0$, let
  %
  \[ u_\varepsilon = \text{Dil}_{1/\varepsilon} \phi \cdot u. \]
  %
  To show $\xi_0 \in \Gamma_0(u)$ it suffices to show that $\xi_0 \in \Gamma(u_\varepsilon)$ for all $\varepsilon > 0$. Without loss of generality, we may assume $|\xi_0| = 1$ and $u(\xi_0) = 1$. We calculate using homogeneity that
  %
  \begin{align*}
    \widehat{u_\varepsilon} &= \varepsilon^d \cdot (\text{Dil}_\varepsilon \widehat{\phi}) * \widehat{u}\\
    &= \text{Dil}_\varepsilon (\widehat{\phi} * \text{Dil}_{1/\varepsilon} \widehat{u})\\
    &= \varepsilon^{-\beta} \cdot \text{Dil}_\varepsilon (\widehat{\phi} * \widehat{u}).
  \end{align*}
  %
  Thus it suffices to show that $\xi_0 \in \Gamma(\phi u)$ to conclude that $\xi_0 \in \Gamma(u_\varepsilon)$ for each $\varepsilon > 0$. For each $R > 0$, we have
  %
  \[ \widehat{u_\varepsilon}(R \xi_0) = \int_{\RR^d} \widehat{\phi}(R \xi_0 - \xi) \widehat{u}(\xi)\; d\xi. \]
  %
  Now for any $K,N > 0$, for $|R \xi_0 - \xi| \geq cR$ we have
  %
  \[ |(\nabla^K \phi)(R \xi_0 - \xi)| \lesssim_{K,N} \frac{1}{1 + R^N}, \]
  %
  which implies, interpreting the integral as a principal value if $\beta < 0$, that for any $N > 0$,
  %
  \[ \left| \int_{|R \xi_0 - \xi| \geq cR} \widehat{\phi}(R \xi_0 - \xi) \widehat{u}(\xi)\; d\xi \right| \lesssim_N \frac{1}{1 + R^N}. \]
  %
  Since $\widehat{u}$ is continuous and homogenous away from the origin, there exists $c \in (0,1)$ such that for any $R > 0$ and any $\xi \in \RR^d$ with $|\xi - R \xi_0| \leq cR$,
  %
  \[ \left| \widehat{u}(\xi) - |\xi|^\beta \right| \leq |\xi|^\beta / 2. \]
  %
  Thus
  %
  \[ \int_{|R \xi_0 - \xi| \leq cR} \widehat{\phi}(R \xi_0 - \xi) \widehat{u}(\xi)\; d\xi = R^\beta \int_{|R \xi_0 - \xi| \leq cR} \widehat{\phi}(R \xi_0 - \xi)\; d\xi + O \left( R^{d+\beta} \right). \]
\end{example}


One important relation between $u$ and $\text{WF}(u)$ is the \emph{propogation of singularities theorem}. If $u$ is a solution to a linear partial differential equation
%
\[ \sum_{|\alpha| \leq K} a_\alpha(x) (\partial_\alpha u)(x) = v \]
%
where $v$ is a distribution, then for any $(x,\xi) \in \text{WF}(u) - \text{WF}(v)$,
%
\[ q(x,\xi) = \sum_{|\alpha| \leq K} a_\alpha(x) \xi^\alpha = 0, \]
%
and $\text{WF}(u) - \text{WF}(v)$ is invariant under the flow generated by the Hamiltonian vector field
%
\[ H_{x,\xi} = \sum_{i = 1}^d \frac{\partial q}{\partial x^j} \frac{\partial}{\partial \xi^j} - \frac{\partial q}{\partial \xi_j} \frac{\partial}{\partial x^j}. \]
%
As a particular example, if $u(t,x,y)$ is a distributional solution to the wave equation $u_{tt} = \Delta u$ and we let $v_t(x,y) = u(t,x,y)$, then $\Delta v_t = u_{tt}$, and so by the propogation of singularities theorem $\text{WF}(v_t) \subset \text{WF}(u_{tt})$.

Then the Paley-Wiener theorem implies that $\widehat{u}$ is an analytic function on $\RR^d$. If $\widehat{u}$ decays rapidly, then $u$ is also a smooth function. However, even if $u$ is not smooth, $\widehat{u}$ may still decrease rapidly in certain directions, which implies that the singularities of $u$ `propogate' in certain directions and understanding these directions is often useful to understanding the distribution $u$. We can also get even more information about the distribution $u$ by looking at the singular frequencies.

To begin with, let 

To begin with, a distribution $u$ is \emph{nonsingular} at a point $x \in \RR^d$ if $u$ is locally a $C^\infty$ function in a neighbourhood of $x$, i.e. there exists a bump function $\phi \in C^\infty(\RR^d)$ with $\phi(x) \neq 0$ such that $\phi u \in C^\infty(\RR^d)$. The  \emph{singular support} of a compactly supported distribution $u$ to be the set of all points $x \in \RR^d$ upon which $u$ is not nonsingular.










\chapter{Differentiation and Averages}

This chapter is about exploring the behaviour of averages of functions. A classical example, given a function $f \in L^1_{\text{loc}}(\RR)$, are the averaging operators
%
\[ A_\delta f(x) = \frac{1}{2\delta} \int_{x-\delta}^{x+\delta} f(y)\; dy. \]
%
If $f \in C(\RR)$, then for each $x \in \RR$, $\lim_{\delta \to 0} A_\delta f(x) = f(x)$. This fact is fundamentally connected to differentiation under the integral sign; if we define the function
%
\[ F(x) = \int_0^x f(y)\; dy \]
%
then for each $x \in \RR$,
%
\[ F'(x) = \lim_{h \to 0} \frac{F(x+h) - F(x)}{h} = \lim_{h \to 0} \frac{1}{h} \int_x^{x+h} f(y)\; dy = f(x). \]
%
Our main goal will be study whether pointwise convergence of the averages $A_\delta f$ hold for a more general family of functions or equivalently, studying whether a kind of fundamental theorem of calculus holds for a more general family of functions.

Recently, the real-variable analysis of these averages have been shown to generalize to a wide variety of situations, which encompasses the averaging problem above, as well as higher dimensional variants. All that is really required for the basic theory is a basic `covering type argument' that holds in a great many situations. In particular, we choose to work in a \emph{space of homogenous type}. We consider a locally compact topological space $X$. For each $x \in X$ and $\delta > 0$, we fix an open, precompact set $B(x,\delta)$, which we assume to be monotonically increasing in $\delta$. The fundamental properties we require of our balls are that there exists two universal constants $c_1,c_2 > 1$ such that
%
\begin{enumerate}
  \item[(i)] For any $x_1,x_2 \in X$ and $\delta > 0$, if $B(x_1,\delta) \cap B(x_2,\delta) \neq \emptyset$, then
  %
  \[ B(x_2,\delta) \subset B(x_1,c_1 \delta). \]

  \item[(ii)] For any $x \in X$ and $\delta > 0$, $|B(x,c_1\delta)| \leq c_2 |B(x,\delta)|$.
\end{enumerate}
%
To avoid technical complications, we assume two further assumptions that are true in almost all reasonable examples under consideration:
%
\begin{enumerate}
  \item[(iii)] For any $x \in X$,
  %
  \[ \bigcap_{\delta > 0} \overline{B}(x,\delta) = \{ x \} \quad\text{and}\quad \bigcup_{\delta > 0} B(x,\delta) = X \]

  \item[(iv)] For any open set $U \subset X$ and $\delta > 0$, the function
  %
  \[ x \mapsto |B(x,\delta) \cap U| \]
  %
  is a continuous function of $x$.
\end{enumerate}

\begin{remark}
  For each $x \in X$ and $\delta > 0$, let $B^*(x,\delta) = \bigcup \{ B(x',\delta) : B(x',\delta) \cap B(x,\delta) \neq \emptyset \}$. Often, assumptions (i) and (ii) can be replaced with the following weaker assumption, that there exists $c > 1$ such that 
  %
  \begin{itemize}
    \item[(i-ii)] $|B^*(x,\delta)| \leq c |B(x,\delta)|$.
  \end{itemize}
  %
  If (i) holds, then $B^*(x,\delta) \subset B(x,c_1\delta)$ and so (ii) implies (i-ii).
\end{remark}

It follows from these technical assumptions that $|B(x,\delta)| > 0$ for each $x \in X$ and $\delta > 0$. Thus for each $\delta > 0$, and $f \in L^1_{\text{loc}}(X)$, we can consider the averaged function $A_\delta f$ given by setting
%
\[ A_\delta f(x) = \frac{1}{|B(x,\delta)|} \int_{B(x,\delta)} f(y)\; dy, \]
%
where the integral on the right hand side is interpreted in the Lebesgue sense.

\begin{lemma}
  If $f \in L_1^{\text{loc}}(X)$, then $A_\delta f$ is a measurable function.
\end{lemma}
\begin{proof}
  If $f = a_1 \mathbf{I}_{U_1} + \dots + a_N \mathbf{I}_{U_N}$ is a simple function, where $U_1,\dots,U_N$ are open sets, then
  %
  \[ A_\delta f(x) = a_1 \frac{|B(x,\delta) \cap U_1|}{|B(x,\delta)|} + \dots + a_N \frac{|B(x,\delta) \cap U_N|}{|B(x,\delta)|} \]
  %
  is a continuous function by (iv). Next, if $f \geq 0$ is a step function, then there exists a monotonically decreasing family of simple functions $\{ f_n \}$ such that $f_n \to f$ pointwise, then the monotone convergence theorem implies that $A_\delta f_n \to A_\delta f$ pointwise, so $A_\delta f$ is measurable. Finally, decomposing any measurable function into the difference of non-negative measurable functions and then considering pointwise limits of step functions completes the proof.
\end{proof}

It follows from (iii) that for any open set $U$ containing $x$, there exists $\delta_0$ such that for $\delta \leq \delta_0$, $\overline{B(x,\delta)} \subset U$. It follows that for any $f \in C(X)$ and $x \in X$,
%
\begin{equation} \label{pointwiseaverageconvergence}
  \lim_{\delta \to 0} A_\delta f(x) = f(x).
\end{equation}
%
This pointwise inequality cannot possibly hold for all $f \in L^1_{\text{loc}}(X)$ because $A_\delta f$ only depends on the `distributional behaviour' of $f$, i.e. on the values of $f$ up to a set of measure zero. However, we can still consider whether \eqref{pointwiseaverageconvergence} holds for \emph{almost every} $x \in X$. Hardy and Littlewood introduced a powerful technique to study such problems, known as the \emph{method of maximal functions}. For each $f \in L^1_{\text{loc}}(X)$, we define
%
\[ Mf(x) = \sup_{\delta > 0} A_\delta |f|(x) = \sup_{\delta > 0} \frac{1}{|B(x,\delta)|} \int_{B(x,\delta)} |f(y)|\; dy. \]
%
The next theorem indicates why obtaining bounds on a maximal operator gives pointwise convergence results.

\begin{theorem}
  Fix $0 < p \leq \infty$, and let $\{ T_t: L^p(X) \to L^{q,\infty}(X) \}$ be a family of bounded operators. Then we can define the pointwise maximal operator
  %
  \[ T_* f(x) = \sup_t |T_t f(x)|. \]
  %
  Suppose there exists $0 < q < \infty$ such that we have a bound
  %
  \[ \| T_* f \|_{L^{q,\infty}(X)} \lesssim \| f \|_{L^p(X)}. \]
  %
  Then the set
  %
  \[ \{ f \in L^p(X) : \lim_{t \to \infty} T_t f(y) = f(y)\; \text{a.e} \} \]
  %
  is closed in $L^p(X)$.
\end{theorem}
\begin{proof}
  Let $\{ f_n \}$ be a sequence of functions converging in $L^p(X)$ to a function $f$, and suppose for each $n$,
  %
  \[ \lim_{t \to \infty} (T_t f_n)(x) = f_n(x) \]
  %
  for almost every $x \in X$. For each $\lambda > 0$, we find
  %
  \begin{align*}
    |\{ x \in X: &\limsup_{t \to \infty} |T_t f(x) - f(x)| > \lambda \}|\\
    &\leq |\{ x \in X: \limsup_t |T_t(f - f_n)(x) - (f - f_n)(x)| > \lambda \}|\\
    &\leq |\{ x \in X : |T_*(f - f_n)(x)| > \lambda/2 \}| + | \{ x: |(f - f_n)(x)| > \lambda/2 \} |\\
    &\lesssim_{p,q} \frac{\| f - f_n \|_{L^p(X)}^q}{\lambda^q} + \frac{\| f - f_n \|_{L^p(X)}^p}{\lambda^p}.
  \end{align*}
  %
  as $n \to \infty$, this quantity tends to zero. Thus for all $\lambda > 0$,
  %
  \[ |\{ x: \limsup_{t \to \infty} |T_t f(x) - f(x)| > \lambda \}| = 0 \]
  %
  Taking $\lambda \to 0$ gives that $\limsup_t |T_t f(x) - f(x)| = 0$ for almost every $x \in X$. But this means precisely that $T_tf(x) \to f(x)$ for almost every $x \in X$.
\end{proof}

The theorem implies that if we can obtain operator bounds for the maximal operator $M$, then we can obtain almost everywhere convergence for the averages we consider. All that is required is to understand the properties of the maximal operator $T_*$. Of course, Schur's lemma implies that for any $\delta > 0$ and $f \in L^1(X)$,
%
\[ \| A_\delta f \|_{L^1(\RR^d)} \leq \| f \|_{L^1(X)}. \]
%
Thus for $f \in L^1(X)$, the functions $A_\delta f$ are uniformly bounded in size. Since the inequality $\sup_{\delta > 0} A_\delta f \leq Mf$ holds pointwise, a bound of the form
%
\[ \| Mf \|_{L^{q,r}(X)} \lesssim \| f \|_{L^p(X)} \]
%
implies
%
\[ \| \sup_{\delta > 0} |A_\delta f| \|_{L^{q,r}(X)} \lesssim \| f \|_{L^p(X)}. \]
%
Thus a bound on the maximal operator also implies that we can uniformly control the size of $A_\delta f$ in a pointwise sense as well.

An initial hope is that we have a bound $\| Mf \|_{L^1(\RR)} \lesssim \| f \|_{L^1(\RR)}$, but $Mf$ is never integrable except in the trivial case where $f = 0$.

\begin{example}
  Let $f \in L^1(\mathbf{R}^d)$ be nonzero. Then, for suitably large $R \geq 1$,
  %
  \[ \int_{B_R(0)} |f(x)|\; dx \geq 0.5 \| f \|_{L^1(\RR^d)} \]
  %
  For each $x \in \mathbf{R}^d$, $B_R(0) \subset B_{|x|+R}(x)$ and so
  %
  \[ Mf(x) \geq \fint_{B_{|x|+R}(x)} |f(y)|\; dy \gtrsim \frac{0.5 \| f \|_{L^1(\RR)}}{(|x| + R)^d} \gtrsim \frac{1}{|x|^d} \]
  %
  But this means, $Mf$ is non-integrable. In certain cases, $Mf$ isn't even locally integrable. If $f(x) = 1/|x| \log|x|^2$, then the fact that for $x \geq 0$
  %
  \begin{align*}
    \frac{1}{2h} \int_{x-h}^{x+h} \frac{dy}{|y| \log |y|^2} &= \frac{1}{2h} \left( \frac{1}{\log(x-h)} - \frac{1}{\log(x+h)} \right)\\
    &= \frac{1}{2x \log x} + O \left( \frac{h}{\log x} \right)
  \end{align*}
  %
  implies that
  %
  \[ Mf(x) \geq \frac{1}{2x \log x}. \]
  %
  Thus $Mf$ isn't integrable about the origin. Note however, that $Mf$ is on the \emph{border} of integrability, which hints at the fact that we have a weak type $(1,1)$ bound.
\end{example}

It is easy to see that for any $f \in L^\infty(\RR^d)$,
%
\[ \| Mf \|_{L^\infty(\RR^d)} \leq \| f \|_{L^\infty(\RR^d)}, \]
%
since the average of a function on a ball is bounded by it's maximum on that ball. Our goal is to show that we also have a bound
%
\[ \| Mf \|_{L^{1,\infty}(\RR^d)} \lesssim_d \| f \|_{L^1(\RR^d)}. \]
%
It thus follows by the Marcinkiewitz interpolation theorem that for any $1 < p < \infty$ and $f \in L^p(\RR^d)$, $Mf \in L^p(\RR^d)$, and that
%
\[ \| Mf \|_{L^p(\RR^d)} \lesssim_{p,d} \| f \|_{L^p(\RR^d)}. \]
%
The bound from $L^1(\RR^d)$ to $L^{1,\infty}(\RR^d)$ is less trivial than the bound from $L^\infty(\RR^d)$ to $L^\infty(\RR^d)$, as is often the case. For each $\lambda > 0$, we must show
%
\[ |\{ x \in \RR^d : Mf(x) \geq \lambda \}| \lesssim_{d,p} \frac{\| f \|_{L^1(\RR^d)}}{\lambda}. \]
%
Let $A(\lambda)$ denote the set on the left hand side. By definition of the maximal function, for each $x \in A(\lambda)$ we can find a ball $B_x$ such that
%
\[ \int_{B_x} |f(x)| \geq \lambda |B_x|. \]
%
Thus for any disjoint collection of balls $\{ B_{x_1}, \dots, B_{x_N} \}$,
%
\[ \| f \|_{L^1(\RR^d)} \geq \lambda \sum_{i = 1}^N |B_{x_i}|. \]
%
Our proof would be complete if we could find a family of non-overlapping balls with volume proportional to the volume of $A(\lambda)$. Vitali's covering lemma provides precisely this family.

\begin{lemma}[Vitali Covering Lemma]
    If $B_1, \dots, B_n$ is a finite collection of balls in $\mathbf{R}^d$, then there is a disjoint subcollection $B_{i_1}, \dots, B_{i_m}$ such that
    %
    \[ \left| \bigcup B_i \right| \leq 3^d \sum |B_{i_k}| \]
\end{lemma}
\begin{proof}
    We begin with the elementary observation that if $B$ and $B'$ are two intersecting balls with the radius of $B$ greater than the radius of $B'$, then $B'$ is a subset of $3B$. Now, if we choose the balls greedily, picking a ball with maximal radius that doesn't intersect any of our previously chosen balls. It then follows that if $B_{i_1}, \dots B_{i_m}$ are the balls chosen then
    %
    \[ \bigcup B_i \subset \bigcup 3B_{i_k} \]
    %
    and so
    %
    \[ \left| \bigcup B_i \right| \leq \left| \bigcup 3B_{i_k} \right| \leq \sum |3B_{i_k}| = 3^d \sum |B_{i_k}| \]
    %
    and we therefore obtain the required inequality.
\end{proof}

\begin{theorem}
    The function $Mf$ is measurable, and for any $\alpha > 0$,
    %
    \[ |\{ x \in \mathbf{R}^d: Mf(x) > \alpha \}| \leq \frac{3^d}{\alpha} \| f \|_1 \]
    %
    Thus $Mf$ has a weak $(1,1)$ bound $\| Mf \|_{L^{1,\infty}(\RR^d)} \leq 3^d \| f \|_1$.
\end{theorem}
\begin{proof}
    The measurability of $Mf$ is easy, because $Mf$ is a lower semicontinuous function, and all lower semicontinuous functions are measurable. If $Mf(x) > \alpha$, then we can choose a ball $B$ containing a point $x$ such that the average of $|f|$ on $B$ is greater than $\alpha$, and then for any $y \in B$, $Mf(y) > \alpha$. Set $E_\alpha = \{ x \in \mathbf{R}^d: Mf(x) > \alpha \}$. Then for each $x$, we can find a ball $B_x$ such that the average of $|f|$ on $B_x$ is greater than $\alpha$. This implies that
    %
    \[ |B_x| < \frac{1}{\alpha} \int_{B_x} |f(y)|\ dy \]
    %
    Let $K \subset E_\alpha$ be compact. Then $K$ is covered by finitely many of the balls, and applying the Vitali covering lemma, we can find a disjoint collection $B_{x_1}, \dots, B_{x_m}$ of these balls such that
    %
    \[ |K| \leq 3^d \sum |B_{x_m}| < \frac{3^d}{\alpha} \int_{\bigcup B_{x_i}} |f(y)|\ dy \leq \frac{3^d}{\alpha} \|f\|_1 \]
    %
    Since $K$ is arbitrary, inner regularity says $|E_\alpha| \leq 3^d \| f \|_1/\alpha$.
\end{proof}

We immediately obtain the Lebesgue differentiation theorem from our discussion of maximal function techniques.

\begin{corollary}
    If $f \in L^1(\mathbf{R}^d)$, then for almost every $x$,
    %
    \[ \lim_{r \to 0} \frac{1}{|B_r(x)|} \int_{B_r(x)} f(y)\ dy = f(x). \]
\end{corollary}

The integrability of $f$ over all of $\mathbf{R}^d$ isn't {\it really} applied anywhere in the proof of the Lebesgue differentiation theorem. Indeed, we only needed that the integral of $f$ is bounded over suitably small balls. If we define the space of \emph{locally integrable functions} $L^1_{\text{loc}}(\mathbf{R}^d)$ to be all functions $f$ such that $f \chi_B$ is integrable for any ball $B$, then the Lebesgue differentiation theorem continues to hold for any function in $L^1_{\text{loc}}(\RR^d)$. This in particular includes all functions in $L^p(\RR^d)$, for any $1 \leq p \leq \infty$.

\section{Dyadic Methods}

Before we move onto further applications of the Lebesgue density theorem, let us discuss a few more methods to prove the Hardy-Littlewood maximal inequality. First, we apply some dyadic methods for proving the inequality. Recall that the set of dyadic cubes is
%
\[ \{ Q_{n,k} : n \in \ZZ, k \in 2^n \ZZ^d \} \]
%
where $Q_{n,k}$ is the cube $[k_1, k_1 + 2^n] \times \dots \times [k_d, k_d + 2^n]$. We note that dyadic cubes nest within one another much more easily than balls do (cubes are either nested or disjoint). In particular, if $Q_1,\dots,Q_N$ is any collection of dyadic cubes, there exists an almost disjoint subcollection $Q_{i_1}, \dots, Q_{i_k}$ with $Q_{i_1} \cup \dots \cup Q_{i_k} = Q_1 \cup \dots \cup Q_N$. In particular, this operates as a Vitali-type covering lemma with a constant independant of $d$, so if we define the \emph{dyadic} Hardy-Littlewood maximal operator
%
\[ M_\Delta f(x) = \sup_{x \in Q} \frac{1}{|Q|} \int_Q |f(y)|\; dy \]
%
then we easily obtain the bound $\| M_\Delta f \|_{L^{\infty,1}(\RR^d)} \leq \| f \|_{L^1(\RR^d)}$, with no implicit constant depending on $d$. The bound $\| M_\Delta f \|_{L^\infty(\RR^d)} \leq \| f \|_{L^\infty(\RR^d)}$ is easy, so interpolation gives $\| M_\Delta f \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)}$ for all $1 < p \leq \infty$.

If $Q$ is a dyadic cube, then it is contained in a ball $B$ with $|Q| \lesssim_d B$. It follows that for any function $f$ and $x \in \RR^d$,
%
\[ M_\Delta f(x) \lesssim_d Mf(x). \]
%
Thus bounds on $M$ automatically give bounds on $M_\Delta$. The opposite pointwise inequality is unfortunately, \emph{not true}. For instance, if $f$ is the indicator function on $[0,1]$. Then $M_\Delta f$ is supported on $[0,1]$, but $Mf$ is positive on the entirety of $\RR$. To reduce the study of $M$ to the study of $M_\Delta$, we must instead rely on the \emph{$1/3$ translation trick} of Michael Christ.

\begin{lemma}
  Let $I \subset [0,1]$ be an interval. Then there exists an interval $J$, which is either a dyadic interval, or a dyadic interval shifted by $1/3$, such that $I \subset J$ and $|J| \lesssim |I|$.
\end{lemma}
\begin{proof}
  Let $I = [a,b]$. Perform a binary expansion of $a$ and $b$, writing
  %
  \[ a = 0.a_1a_2 \dots \quad\text{and}\quad b = b_1 b_2 \dots. \]
  %
  Let $n$ be the first value where $a_n \neq b_n$. Then $a_n = 0$ and $b_n = 1$. Then $[a,b]$ is contained in the dyadic interval
  %
  \[ Q_1 = \left[ 0.a_1 \dots a_{n-1}, 0.a_1\dots a_{n-1} + 1/2^{n-1} \right] \]
  %
  which has length $1/2^{n-1}$. Find $0 \leq i < \infty$ such that
  %
  \[ a = 0.a_1 \dots a_{n-1} 0 1^i 0 \dots \]
  %
  and $0 \leq j < \infty$ such that
  %
  \[ b = 0.a_1 \dots a_{n-1} 1 0^j 1. \]
  %
  If no such $j$ exists, then $b = 0.a_1 \dots a_{n-1} 1$, and so $[a,b]$ is contained in the rational interval
  %
  \[ Q_2 = \left[ 0.a_1 \dots a_{n-1} 0 1^i, 0.a_1 \dots a_{n-1} 0 1^i + 1/2^{n+i} \right] \]
  %
  and $b - a \geq 1/2^{n+i+1}$, so $|Q_2| \leq 2(b - a)$. Now if $i \leq 5$ or $j \leq 5$, then $b - a \geq 1/2^{n+5}$, so $|Q_1| \leq 2^5(b-a)$. On the other hand, if $i \geq 5$ and $j \geq 5$, we find $b - a \geq 1/2^{n+\min(i,j)}$. Then we can find a dyadic interval $Q_3$ and $2 \leq r \leq 5$ such that
  %
  \[ 1/3 + Q_3 = \left[ 0.a_1 \dots a_{n-1} 0 1^{\min(i,j)-r} 1 0 1 0 \dots, 0.a_1 \dots a_{n-1} 0 1^{i-r} 1 0 1 0 \dots + 1/2^{n+\min(i,j)-r}  \right] \]
  %
  and so $1/3 + Q_3$ contains $[a,b]$ and $|Q_3| = 1/2^{n+\min(i,j)-r} \leq 2^5 (b - a)$.
\end{proof}

It follows that for each $x \in \RR^d$, and any function $f$,
%
\[ Mf(x) \lesssim_d (M_\Delta f)(x) + (M_\Delta \text{Trans}_{1/3} f)(x). \]
%
Since the $L^p$ norms are translation invariant, this implies that the dyadic maximal operator and the maximal operator satisfy equivalent bounds, with operator norms differing by a constant depending on $n$. Since we independently obtained bounds on $M_\Delta$, this section provides an alternate proof to the boundedness of $M$.

\section{Bellman Function Methods}

It is interesting to ask whether we can obtain bounds of the form
%
\[ \| M f \|_{L^p(\RR^d)} \lesssim_{d,p} \| f \|_{L^p(\RR^d)} \]
%
without employing any interpolation techniques. This is possible, though nontrivial. We begin with a Bellman function approach, which works best in the dyadic scheme, i.e. proving bounds on $M_\Delta$.

The idea here is to perform an \emph{induction on scales}, i.e. to induct on the complexity of the function $f$. For a fixed $f \in L^p(\RR^d)$, our goal is to obtain bounds of the form
%
\[ \left( \int |M_\Delta f(x)|^p\; dx \right)^{1/p} \lesssim \left( \int |f(x)|^p \right)^{1/p} \]
%
where the implicit constant is independent of $p$.

We begin by applying some monotone convergence arguments to simplify our analysis. For each $x \in \RR^d$, $|M_\Delta f(x)| = \lim_{m \to -\infty} |M_{\geq m} f(x)|$, where $M_{\geq m}$ is the operator giving a maximal average over all dyadic cubes containing a point with sidelength exceeding $2^m$, and the limit is monotone increasing. It follows that for any $f \in L^p(\RR^d)$,
%
\[ \| M_\Delta f \|_{L^p(\RR^d)} = \lim_{m \to -\infty} \| M_{\geq m} f \|_{L^p(\RR^d)}. \]
%
Thus if we can obtain a bound
%
\[ \| M_{\geq m} f \|_{L^p(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
with a bound independant of $m$, we would obtain the required bound on $M_\Delta$. But if we could obtain a bound
%
\[ \| M_{\geq 0} f \|_{L^p(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
for all $f \in L^p(\RR^d)$, then a rescaling argument, using the fact that
%
\[ M_{\geq m} f = \text{Dil}_{1/2^d} M_{\geq 0} \text{Dil}_{2^d} f \]
%
shows that we in fact have
%
\begin{align*}
  \| M_{\geq m} f \|_{L^p(\RR^d)} &= 2^{d/p} \| M_{\geq 0} \text{Dil}_{2^d} f \|_{L^p(\RR^d)}\\
  &\lesssim 2^{d/p} \| \text{Dil}_{2^d} f \|_{L^p(\RR^d)} = \| f \|_{L^p(\RR^d)}.
\end{align*}
%
Thus we need only concentrate on the operator $M_{\geq 0}$. Finally, we note we can \emph{localize} our estimates. Given a function $f$ supported on a dyadic cube $Q$ with sidelength $2^n$, and given $x \not \in Q$, then there exists a smallest value $m_x > n$ such that $x$ is contained in a dyadic cube with sidelength $2^{m_x}$ which also contains $Q$. It then follows that
%
\[ (M_{\geq 0} f)(x) = \frac{\int_Q |f(y)|\; dy}{2^{dm_x}} = \frac{\| f \|_{L^1(Q)}}{2^{dm_x}} \]
%
For each $m > n$, if we set $E_m = \{ x \in \RR^d: m_x = m \}$, then $E_m$ is contained in a dyadic cube of sidelength $2^m$, so $|E_m| \leq 2^{dm}$. Thus we have
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(Q^c)} &= \left( \sum_{m = n+1}^\infty \| M_{\geq 0} f \|_{L^p(E_m)}^p \right)^{1/p}\\
  &\leq \left( \sum_{m = n+1}^\infty \left( \| f \|_{L^1(Q)}^p / 2^{dpm} \right) 2^{dm} \right)^{1/p}\\
  &\lesssim_{d,p} \| f \|_{L^1(Q)} 2^{dn(1/p - 1)} = \| f \|_{L^1(Q)} |Q|^{1/p-1} \leq \| f \|_{L^p(Q)}.
\end{align*}
%
Thus, if we obtained the bound $\| M_{\geq 0} f \|_{L^p(Q)} \lesssim \| f \|_{L^p(Q)}$, then we would find
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(\RR^d)} &\leq \| M_{\geq 0} f \|_{L^p(Q)} + \| M_{\geq 0} f \|_{L^p(Q^c)} \lesssim \| f \|_{L^p(Q)}.
\end{align*}
%
Thus if $f$ is supported on a dyadic cube $Q$, it suffices to estimate $M_{\geq 0} f$ on the support of $f$. But by a final monotone convergence argument, it suffices to bound such functions, since given any $n$ we can write $[-2^n,2^n]$ as the almost disjoint union of $2^d$ sidelength $2^d$ dyadic cubes $Q_{n,1},\dots,Q_{n,2^d}$. For any $f \in L^p(\RR^d)$, we consider a pointwise limit $f = \lim_{n \to \infty} f_{n,1} + \dots + f_{n,2^d}$, where $f_{n,i}$ is equal to $f$ restricted to $Q_{n,i}$, and the limit is monotone. We also have
%
\[ M_{\geq 0} f = \lim_{n \to \infty} M_{\geq 0} f_{n,1} + \dots + M_{\geq 0} f_{n,2^d}. \]
%
where the limit is pointwise and monotone, so
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(\RR^d)} &= \lim_{n \to \infty} \| M_{\geq 0} f_{n,1} + \dots + M_{\geq 0} f_{n,2^d} \|_{L^p(\RR^d)}\\
  &\lesssim \lim_{n \to \infty} \| f_{n,1} \|_{L^p(\RR^d)} + \dots + \| f_{n,2^d} \|_{L^p(\RR^d)} \lesssim 2^d \| f \|_{L^p(\RR^d)}.
\end{align*}
%
Thus, after a technical reduction argument, we now show that we only have to establish a bound
%
\[ \| M_{\geq 0} f \|_{L^p(Q)} \lesssim \| f \|_{L^p(Q)}, \]
%
where $f \in L^p(Q)$, $Q$ is a dyadic cube with sidelength $\geq 1$, and the implicit constant is independant of $Q$.

To carry out the inequality, we perform an \emph{induction on scales}. For each $n \geq 0$, we let $C(n)$ denote the optimal constant such that for any function $f \in L^p(\RR^d)$ supported on a dyadic cube $Q$ of sidelength $2^n$,
%
\[ \| M_{\geq 0} f \|_{L^p(Q)} \leq C(n) \cdot \| f \|_{L^p(Q)}. \]
%
If $n = 0$, the problem is trivial, since if $Q$ is dyadic with sidelength $1$ and $x \in Q$, then
%
\[ M_{\geq 0} f = \fint_Q |f(y)|\; dy \]
%
so $\| M_{\geq 0} f \|_{L^p(Q)} = \| f \|_{L^1(Q)}$, and $C(0) = 1$. Our goal is to show that $\sup_{n \geq 0} C(n) < \infty$. Given $f$ supported on a cube $Q$ with sidelength $2^n$, the cube has $2^d$ children $Q_1,\dots,Q_{2^d}$ with sidelength $2^{n-1}$. If we decompose $f = f_1 + \dots + f_{2^d}$ onto these cubes, then by induction we know that
%
\[ \| M_{\geq 0} f_i \|_{L^p(Q_i)} \leq C(n-1) \| f_i \|_{L^p(Q_i)}. \]
%
Now for $x \in Q_i$,
%
\[ (M_{\geq 0} f)(x) = \max \left(M_{\geq 0} f_i(x), \fint_Q |f(y)|\; dy \right). \]
%
Thus if $A = \fint_Q |f(y)|\; dy$, then
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(Q)} &= \left( \| M_{\geq 0} f \|_{L^p(Q_1)}^p + \dots + \| M_{\geq 0} f \|_{L^p(Q_{2^d})}^p \right)^{1/p}\\
  &= \left( \| \max(M_{\geq 0} f_1, A) \|_{L^p(Q_1)}^p + \dots + \| \max(M_{\geq 0} f_{2^d}, A) \|_{L^p(Q_{2^d})}^p \right)^{1/p}
\end{align*}
%
The bound $\max(M_{\geq 0} f_i, A) \leq M_{\geq 0} f_i + A$ gives
%
\[ \| M_{\geq 0} f \|_{L^p(Q)} \leq C(n-1) \| f \|_{L^p(Q)} + 2^{d/p} |Q|^{1/p} A = (C(n-1) + 2^{d/p}) \| f \|_{L^p(Q)}. \]
%
This gives $C(n) \leq C(n-1) + 2^{d/p}$, which is not enough to obtain a uniform bound. The idea here is to include more information in our induction hypothesis which gives control on $\max(M_{\geq 0} f_i, A)$. Since $Q$ contains points not in $Q_i$, we need to treat $A$ as an arbitrary quantity in our hypothesis.

To do this, we introduce \emph{cost functions}. For each $A,B,D > 0$ and any integer $n \geq 0$, we let $V_n(A,B,D)$ be the optimal constant such that
%
\[ \| \max(M_{\geq 0} f, A)^p \|_{L^p(Q)} \leq V_n(A,B,D) \]
%
For any function $f$ supported on a dyadic cube $Q$ with sidelength $2^n$, with
%
\[ \| f \|_{L^1(Q)} = B\quad\text{and}\quad \| f \|_{L^p(Q)} = D. \]
%
Our goal will be to show $V_n(A,B,D) \lesssim_p 2^{-dn/p} A + D$ which completes the proof. The role of $B$ is subtle, but will soon become apparan. Of course, we have $\| f \|_{L^1(Q)} \leq 2^{dn(1-1/p)} \| f \|_{L^p(Q)}$, so we have $V_n(A,B,D) = -\infty$ unless $B \leq 2^{dn(1 - 1/p)} D$.

The recursive inequality gives an inequality for the values $V_n(A,B,D)$. TODO: COMPLETE THIS PROOF.

\section{$TT^*$ Arguments}

The method of $TT^*$ arguments enables us to obtain bounds on an operator $T$ by exploiting cancellation between an operator and it's adjoint. However, this approach only works when establishing $L^2$ estimates (or at least where one side of an inequality has a norm induced by an inner product). By monotocity, it suffices to consider maximal operators of the form $\max(A_{r_1} f, \dots, A_{r_N} f)$ (provided the implicit constants are independant of $N$),  and by linearization, it suffices to show that for any measurable function $r: \RR^d \to \{ r_1, \dots, r_N \}$,
%
\[ \left( \int |A_{r(x)} f(x)|^p\; dx \right)^{1/p} \lesssim \| f \|_{L^p(\RR^d)} \]
%
where the implicit constant is independant of the function $r$. Thus we consider the linearized operator $M_r: L^2(\RR^d) \to L^2(\RR^d)$ obtained by setting
%
\[ M_r f(y) = (A_{r(y)} f)(y). \]
%
We see easily that $M_r$ is a kernel operator with kernel
%
\[ K(x,y) = \frac{1}{|B_{r(y)}(y)|} \mathbf{I}(|x - y| \leq r(y)). \]
%
Thus
%
\[ M_r^* g(x) = \int_{\RR^d} \frac{\mathbf{I}(|x - y| \leq r(y))}{|B_{r(y)}(y)|} g(y)\; dy, \]
%
and so one can verify that
%
\begin{align*}
  |(M_r M_r^* f)(y)| &= \left| \int_{\RR^d} \int_{\RR^d} \frac{\mathbf{I}(|z - x| \leq r(z)) \mathbf{I}(|y - x| \leq r(y))}{|B(z,r(z))| |B(y,r(y))|} f(z)\; dz\; dx \right|\\
  &= \left| \int_{\RR^d} \int_{\RR^d} \frac{\mathbf{I}(|z - x| \leq r(z)) \mathbf{I}(|y - x| \leq r(y))}{|B(z,r(z))| |B(y,r(y))|} f(z)\; dx\; dz \right|.
\end{align*}
%
For a fixed $z$, the integrand in $x$ vanishes unless $|z - y| \leq r(y) + r(z)$, and in this case we find
%
\[ \left| \int_{\RR^d} \frac{\mathbf{I}(|z - x| \leq r(z)) \mathbf{I}(|y - x| \leq r(y))}{|B(z,r(z))| |B(y,r(y))|} \right| \lesssim_d \frac{1}{\max(r(y)^d, r(z)^d)}. \]
%
Thus we can write
%
\begin{align*}
  |(M_r M_r^* f)(y)| &\lesssim_d \int_{\RR^d} \left( \int_{\substack{|z - y| \leq r(y) + r(z)\\r(y) \leq r(z)}} \frac{|f(z)|}{r(z)^d} + \int_{\substack{|z - y| \leq r(y) + r(z)\\r(y) \geq r(z)}} \frac{|f(z)|}{r(y)^d}\; dx \right)\\
  &\lesssim_d M_{2r}|f|(y) + M_{2r}^* |f|(y).
\end{align*}
%
But we verify by rescaling that $\| M_{2r} \| = \| M_{2r}^* \| = \| M_r \|$, so
%
\[ \| M_r \|^2 = \| M_r M_r^* \| \lesssim_d \| M_r \|. \]
%
But this means that $\| M_r \| \lesssim_d 1$, which gives the bound that we required. Thus we find that the Hardy-Littlewood maximal function is bounded from $L^2(\RR^d)$ to $L^2(\RR^d)$.








\section{Lebesgue Density Theorem}

If $E$ is a measurable subset of $\mathbf{R}^d$, and $x \in \mathbf{R}^d$, we say $x$ is a point of \emph{Lebesgue density} of $E$, or has \emph{full metric density} if
%
\[ \lim_{\substack{|B| \to 0\\x \in B}} \frac{|B \cap E|}{|B|} = 1 \]
%
This means that for every $\alpha < 1$, for suitably small balls, we conclude that $|B \cap E| \geq \alpha |B|$, so $E$ asymptotically contains as large a fraction of the local points around $x$ as is possible. Since $\chi_E \in L^1_{\text{loc}}(\mathbf{R}^d)$, we can apply the Lebesgue differentiation theorem to immediately obtain an interesting result.

\begin{theorem}[Lebesgue Density Theorem]
    If $E$ is a measurable subset, then almost every point in $E$ is a point of Lebesgue density, and almost every point in $E$ is not a point of Lebesgue density.
\end{theorem}

The fact that a point is a point of Lebesgue density implies the existence of large sets of rigid patterns in $E$. Note that if $|B \cap E|, |B \cap F| \geq \alpha |B|$, then a union bound gives $|B \cap E \cap F| \geq (2 \alpha - 1)|B|$. As $\alpha \to 1$, $2\alpha - 1 \to 1$, so if $x$ is a point of Lebesgue density for $E$ and $F$, then $x$ is a point of Lebesgue density of $E \cap F$. If $0$ is a point of Lebesgue density for $E$, then $0$ is a point of Lebesgue density for $\alpha E$ for any $\alpha \neq 0$, and so for any nonzero $\alpha_1, \dots, \alpha_n$, $0$ is a point of Lebesgue density for $\alpha_1 E \cap \dots \cap \alpha_n E$, which in particular implies the existence of $x_i \to 0$ with $x_i \in \alpha_1 E \cap \dots \cap \alpha_n E$, hence $\alpha_1^{-1} x_i, \dots, \alpha_n^{-1} x_i \in E$. This is very difficult to prove without the existence of the Lebesgue density theorem, because of the discreteness of the equations. Applying these results with $\alpha_1 = 1$, $\alpha_2 = 1/2$, $\alpha_2 = 1/3$, and so on, we conclude that sets of positive measure in $\mathbf{R}$ contain infinitely many arbitrarily long arithmetic progressions.

If $f$ is locally integrable, the \emph{Lebesgue set} of $f$ consists of all points $x \in \mathbf{R}^d$ such that $f(x)$ is finite and
%
\[ \lim_{\substack{|B| \to 0\\x \in B}} \frac{1}{|B|} \int |f(y) - f(x)|\ dy = 0 \]
%
If $f$ is continuous at $x$, it is obvious to see that $x$ is in the Lebesgue set of $f$, and if $x$ is in the Lebesgue set of $f$, then the averages of $f$ on balls around $x$ coverge to $f(x)$.

\begin{theorem}
    If $f \in L^1_{\text{loc}}(\mathbf{R}^d)$, almost every point is in the Lebesgue set of $f$.
\end{theorem}
\begin{proof}
    For each rational number $p$, the function $|f - p|$ is measurable, so that there is a set $E_p$ of measure zero such that for $x \in E_p^c$,
    %
    \[ \lim_{\substack{|B| \to 0\\x \in B}} \frac{1}{|B|} \int_B |f(y) - p|\ dy \to |f(x) - p| \]
    %
    Taking unions, we conclude that $E = \bigcup E_p$ is a set of measure zero. Suppose $x \in E^c$, and $f(x)$ is finite. For any $\varepsilon$, there is a rational $p$ such that $|f(x) - p| < \varepsilon$, and we know the equation above holds, so
    %
    \begin{align*}
        \lim_{\substack{|B| \to 0\\x \in B}} &\frac{1}{|B|} \int_B |f(y) - f(x)|\ dy\\
        &\leq \limsup_{\substack{|B| \to 0\\x \in B}} \frac{1}{|B|} \int_B |f(y) - p| + |p - f(x)|\ dy \leq 2\varepsilon
    \end{align*}
    %
    we can then let $\varepsilon \to 0$. Since $f(x)$ is finite for almost all $x$ when $f$ is locally integrable, this completes the proof.
\end{proof}

It is interesting to note that if $f = g$ almost everywhere, then the set of points $x$ where the averages of $f$ on balls around $x$ converges is the same as the set of points $x$ where the averages of $f$ on balls around $x$ converges, and so we can in some sense define a `universal' function $h$ from the equivalence class of these functions such that the averages of $h$ on balls around $x$ always converge to $h(x)$ when the limit exists. However, this isn't often done, because it doesn't really help in the analysis of integrable functions. We note, however, that the Lebesgue set of a function does depend on the function chosen from the equivalence class. However, the Lebesgue set of the universal function constructed above is the largest of any function in the equivalence class, which is sometimes taken as the canonical Lebesgue set of the class. Alternatively, this version of the Lebesgue set can be taken as the points $x$ such that there exists $a_x$ with
%
\[ \lim_{\substack{|B| \to 0 \\ x \in B}} \fint_B |f(y) - a_x| = 0 \]
%
Then it is clear that the Lebesgue set of two functions agree if they are equal almost everywhere.

\section{Generalizing The Differentiation Theorem}

The boundedness of the maximal function we considered earlier depends very little on the fact that the sets we are averaging over are balls. In fact, there are only very few properties of $\RR^d$ that we used. To begin with, we can generalize the family of sets we use. A family of sets $U_\alpha$ universally containing a point $x$ is said to \emph{shrink regularly} to $x$, or has \emph{bounded eccentricity} at $x$, if $\inf |U_\alpha| = 0$, and there is a constant $c > 0$ such that for each $U_\alpha$, there is a ball $B$ with $x \in B$, $U_\alpha \subset B$, and $|U_\alpha| \geq c |B|$. Thus $U_\alpha$ contains a large percentage of certain balls $B$ around $x$. In particular, if we define
%
\[ M_U(f) = \sup_{U_\alpha} \fint_{U_\alpha} |f(x)|\; dx \]
%
Then
%
\[ M_U(f) = \sup_{U_\alpha} \fint_{U_\alpha} |f(x)|\; dx \leq c^{-1} \sup_B \fint_B |f(x)|\; dx = c^{-1} (Mf)(x) \]
%
In particular, $M_U \lesssim M$, which implies $M_U$ satisfies the same bounds that the Hardy-Littlewood maximal function satisfies. We therefore conclude that for any locally integrable $f$,
%
\[ \lim_{\substack{U_\alpha \to 0\\x \in U_\alpha}} \fint_{U_\alpha} f(y)\;dy = f(x) \]
%
Thus the differentiation theorem easily generalizes to averages over any sets which don't differ too much from a ball.

\begin{example}
    The set of all open cubes in $\mathbf{R}^d$ containing $x$ shrinks regularly to $x$, because if a cube $U$ centered at $y$ with side lengths $r$ contains $x$, then using the existence of a constant $C$ such that for all $x,y \in \mathbf{R}^d$,
    %
    \[ \| x - y \|_\infty \leq C \| x - y \|_2 \]
    %
    we conclude that the cube is contained within a ball $B$ of radius $2Cr$, and since $|U| = r^d$, and $|B|$ is proportional to $(2Cr)^d$ up to a constant, so that $U$ has bounded eccentricity.
\end{example}

\begin{example}
    The set of all rectangles in $\mathbf{R}^d$ containing $x$ does {\it not} shrink regularly, because we can let the rectangle have one large side length while keeping all other side lengths relatively small, and then a ball containing this rectangle must be incredibly large.
\end{example}

\begin{theorem}
    If $f$ is locally integrable on $\mathbf{R}^d$, and $\{ U_\alpha \}$ shrinks regularly to $x$, then for every point $x$ in the Lebesgue set of $f$,
    %
    \[ \lim_{|U_\alpha| \to 0} \frac{1}{|U_\alpha|} \int_{U_\alpha} f(y)\ dy = f(x) \]
\end{theorem}
\begin{proof}
    We just calculate that for every $x$ in the Lebesgue set of $f$,
    %
    \[ \lim_{|U_\alpha| \to 0} \frac{1}{|U_\alpha|} \int_{U_\alpha} |f(y) - f(x)|\ dy = 0 \]
    %
    This follows because if $U_\alpha \subset B_\alpha$, with $|U_\alpha| \geq C|B_\alpha|$, then
    %
    \[ \frac{1}{|U_\alpha|} \int_{U_\alpha} |f(y) - f(x)|\ dy \leq \frac{1}{C|B_\alpha|} \int_{B_\alpha} |f(y) - f(x)|\ dy \]
    %
    and since $|U_\alpha| \to 0$, $|B_\alpha| \to 0$, giving us the result.
\end{proof}

We can also consider more general ambient spaces than $\RR^d$, which will enable us to obtain maximal type bounds like
%
\[ Mf(n) = \sup_{N > 0} \frac{1}{N} \sum_{m = 1}^N |f(n + m)|. \]
%
for functions $f$ on $\ZZ$, and
%
\[ Mf(x) = \sup_{r > 0} \frac{1}{2r} \int_{-r}^r |f(x + t)|\; dt \]
%
for functions $f$ on $\TT$. TODO FINISH THIS (STEIN'S BOOK?)

One consequence of the integer-domain maximal inequality is a pointwise convergence result in ergodic theory. We recall that a \emph{measure preserving system} is a probability space $X$ together with a measure preserving transformation $T: X \to X$.

\begin{theorem}
  Let $X$ and $T$ form a measure preserving transformation. Then for all $f \in L^1(X)$ and almost every $x \in X$, the limit
  %
  \[ \lim_{N \to \infty} \frac{1}{N} \sum_{n = 1}^N T^n f(x) \]
  %
  exists.
\end{theorem}
\begin{proof}
  Fix $N_0 > 0$ and $f \in L^1(X)$, and define a measurable function $F$ on $X \times [2N_0]$ by defining
  %
  \[ F(x,n) = T^n f(x). \]
  %
  Let
  %
  \[ MF(x,n) = \sup_{1 \leq N \leq N_0} \frac{1}{N} \sum_{m = 1}^N T^{n+m} f(x). \]
  %
  Then the integer-valued maximal inequality implies that
  %
  \[ \| MF \|_{l^{1,\infty}[N_0]} \lesssim \| F \|_{l^1[2N_0]} \]
  %
  and integrating in $X$, that
  %
  \[ \| MF \|_{l^{1,\infty}[N_0] L^1(X)} \lesssim \| F \|_{l^1[2N_0] L^1(X)} = \| F \|_{L^1(X \times [2N_0])} = 2N_0 \| f \|_{L^1(X)}. \]
  %
  TODO FINISH THIS.
\end{proof}

\section{Approximations to the Identity}

We now switch to the study of how we can approximate functions by convolutions of concentrated functions around the origin. In this section we define the various classes of such functions which give convergence results, to various degrees of strength. We say a family $K_\alpha \in L^1(\mathbf{R}^d)$ is a \emph{good kernel} if it is bounded in the $L^1$ norm, for every $\alpha$,
    %
    \[ \int K_\alpha(x)\ dx = 1 \]
    %
    and if for every $\delta > 0$, as $\alpha \to \infty$,
    %
    \[ \int_{|x| \geq \delta} |K_\alpha(x)|\ dx \to 0 \]
    %
It requires only basic analysis to verify good kernel convergence.

\begin{theorem}
    If $K_\alpha$ is a good kernel, then for any absolutely integrable function $f$, $f * K_\alpha \to f$ in the $L^1$ norm, and $(f * K_\alpha)(x) \to f(x)$ for every $x$ which is a point of continuity of $f$.
\end{theorem}
\begin{proof}
    Note that
    %
    \begin{align*}
        \| (f * K_\alpha) - f \|_1 &= \int |(f * K_\alpha)(x) - f(x)|\ dx\\
        &= \int \left| \int K_\alpha(y) [f(x - y) - f(x)]\ dy \right|\ dx\\
        &\leq \int |K_\alpha(y)| \| T_y f - f \|_1\ dy
    \end{align*}
    %
    where $(T_y f)(x) = f(x - y)$. We know that $\| T_y f - f \|_1 \to 0$ as $y \to 0$. Thus, for each $\varepsilon$, we can pick $\delta$ such that if $|y| < \delta$, $\| T_y f - f \|_1 \leq \varepsilon$, and if we pick $\alpha$ large enough that $\int_{|y| \geq \delta} |K_\alpha(y)|\ dy \leq \varepsilon$, and then
    %
    \[ \| (f * K_\alpha) - f \|_1 \leq \varepsilon \int_{|y| < \delta} |K_\alpha(y)|\ dy + 2 \| f \|_1 \int_{|y| \geq \delta} |K_\alpha(y)|\ dy \leq \varepsilon[\| K_\alpha \|_1 + 2 \| f \|_1] \]
    %
    Since $\| K_\alpha \|_1$ is universally bounded over $\alpha$, we can let $\varepsilon \to 0$ to obtain convergence. If $x$ is a fixed point of continuity, and for a given $\varepsilon > 0$, we pick $\delta > 0$ with $|f(y) - f(x)| \leq \varepsilon$ for $|y - x| < \delta$, then
    %
    \begin{align*}
        |(f * K_\alpha)(x) - f(x)| &= \left| \int_{-\infty}^\infty f(y) K_\alpha(x - y)\ dy - f(x) \right|\\
        &= \left| \int_{-\infty}^\infty [f(y) - f(x)] K_\alpha(x-y)\ dy \right|\\
        &= \left| \int_{-\delta}^\delta [f(y) - f(x)] K_\alpha(x-y)\ dy \right|\\
        &\ \ \ \ \ + \left| \int_{|y| \geq \delta} [f(y) - f(x)] K_\alpha(x - y)\ dy \right|\\
        &\leq \varepsilon \| K_\alpha \|_1 + [\| f \|_1 + f(x)] \int_{|y| \geq \delta} |K_\alpha(y)|\ dy
    \end{align*}
    %
    If $\| K_\alpha \|_1 \leq M$ for all $\alpha$, and we choose $\alpha$ large enough that $\int_{|y| \geq \delta} |K_\alpha(y)| \leq \varepsilon$, then we conclude the value about is bounded by $\varepsilon [M + \| f \|_1 + f(x)]$, and we can then let $\varepsilon \to 0$.
\end{proof}

To obtain almost sure pointwise convergence of $f * K_\alpha$ to $f$, we must place stronger conditions on our family. We say a family $K_\delta \in L^1(\mathbf{R}^d)$, is an \emph{approximation to the identity} if $\int K_\delta = 1$, and
%
\[ |K_\delta(x)| \lesssim \frac{\delta}{|x|^{d+1}}\ \ \ \ |K_\delta(x)| \lesssim \frac{1}{\delta^d} \]
%
where the constant bound is independent of $x$ and $\delta$. These assumptions are stronger than being a good kernel, because if $K_\delta$ is an approximation to the identity, then
%
\[ \int_{|x| \geq \varepsilon} |K_\delta(x)| \leq \int_\varepsilon^\infty \int_{S^{d-1}} \frac{C \delta}{r}\ d\sigma dr = C \delta |S^{n-1}| \int_\varepsilon^\infty \frac{dr}{r} \leq \frac{C \delta |S^{n-1}|}{\varepsilon} \]
%
which converges to zero as $\delta \to 0$. Combined with
%
\[ \int_{|x| < \varepsilon} |K_\delta(x)| \leq C \int_0^\varepsilon \int_{S^{d-1}} \frac{r^{d-1}}{\delta^d} d\sigma dr = \frac{C \varepsilon^d |S^{n-1}|}{d \delta^d} \]
%
This calculation also implies
%
\begin{align*}
    \| K_\delta \|_1 &\leq C |S^{n-1}| \left[ \frac{\delta}{\varepsilon} + \frac{\varepsilon^d}{\delta^d} \right]
\end{align*}
%
Setting $\varepsilon = \delta$ optimizes this value, and gives a bound
%
\[ \| K_\delta \|_1 \leq 2C |S^{n-1}| \]
%
So an approximation to the identity is a stronger version of a good kernel.

\begin{example}
    If $\varphi$ is a bounded function in $\mathbf{R}^d$ supported on the closed ball of radius one with $\int \varphi(x)\ dx = 1$, then $K_\delta(x) = \delta^{-d} \varphi(\delta^{-1}x)$ is an approximation to the identity, because by a change of variables, we calculate
    %
    \[ \int_{\mathbf{R}^d} \frac{\varphi(\delta^{-1}x)}{\delta^d} = \int_{\mathbf{R}^d} \varphi(x) = 1 \]
    %
    Because $\varphi$ is bounded, we find
    %
    \[ |K_\delta(x)| \leq \frac{\| \varphi \|_\infty}{\delta^d} \]
    %
    Now $K_\delta$ is supported on a disk of radius $\delta$, this bound also shows
    %
    \[ |K_\delta(x)| \leq \frac{\delta \| \varphi \|_\infty}{|x|^{d+1}} \]
    %
    and so $K_\delta$ is an approximation to the identity. If $\varphi$ is an arbitrary integrable function, then $K_\delta$ will only be a good kernel.
\end{example}

\begin{example}
    The Poisson kernel in the upper half plane is given by
    %
    \[ P_y(x) = \frac{1}{\pi} \frac{y}{x^2 + y^2} \]
    %
    where $x \in \mathbf{R}$, and $y > 0$. It is easy to see that
    %
    \[ P_y(x) = y^{-1} P_1(xy^{-1}) \]
    %
    And
    %
    \[ \int \frac{1}{1 + x^2} = \arctan(\infty) - \arctan(-\infty) = \pi \]
    %
    We easily obtain the bounds
    %
    \[ |P_y(x)| \leq \frac{\| P_1 \|_\infty}{y}\ \ \ \ \ |P_y(x)| \leq \frac{y}{\pi |x|^2} \]
    %
    so the Poisson kernel is an approximation to the identity.
\end{example}

\begin{example}
    The heat kernel in $\mathbf{R}^d$ is defined by
    %
    \[ H_t(x) = \frac{e^{-|x|^2/4t}}{(4 \pi t)^{d/2}} \]
    %
    where $\delta = t^{1/2} > 0$. Then $H_t(x) = \delta^{-d} H_1(x\delta^{-1})$, and
    %
    \[ \int e^{-|x|^2/4} = \frac{1}{2^d} \int e^{-|x|^2} = \frac{|S^{n-1}|}{2^d} \int_0^\infty r^{d-1} e^{-r^2} dr \]
    %
%    By induction, we can prove that if $d$ is odd, then the antiderivative of $r^de^{-r^2}$ is equal to $P_d(r)e^{-r^2}$, where the coefficients of $P_d$ are nonzero only when the coefficient index is even. This follows because the chain rule gives
    %
%    \[ \int re^{-r^2} = -e^{-r^2}/2 \]
    %
%    and an integration by parts gives
    %
%    \[ \int r^{d+2}e^{-r^2} = r^2P_d(r)e^{-r^2} - 2 \int rP_d(r)e^{-r^2} \]
    %
%    Thus
    %
%    \[ \int r^3e^{-r^2} = (-r^2/2)e^{-r^2} + \int re^{-r^2} = (-1/2)(r^2 + 1) e^{-r^2} \]
%    \[ \int r^5e^{-r^2} = -(1/2) r^2(r^2 + 1)e^{-r^2} + \int r(r^2 + 1) e^{-r^2} = (-1/2)[r^4 + 2r^2 + 2] \]
%    \[ \int r^7e^{-r^2} = -(1/2) r^2[r^4 + 2r^2 + 2]e^{-r^2} + \int (r^5 + 2r^3 + 2r) e^{-r^2} = (-1/2) [r^6 + 3r^4 + 6r^2 + ] e^{-r^2} \]
\end{example}

\begin{example}
    The Poisson kernel for the disk is
    %
    \[ \frac{P_r(x)}{2 \pi} = \begin{cases} \frac{1}{2\pi} \frac{1 - r^2}{1 - 2r \cos x + r^2} &: |x| \leq \pi \\ 0 &: |x| > \pi \end{cases} \]
    %
    where $0 < r < 1$, and $\delta = 1-r$.
\end{example}

\begin{example}
    The F\'{e}jer kernel is
    %
    \[ \frac{F_N(x)}{2 \pi} = \begin{cases} \frac{1}{2 \pi N} \frac{\sin^2(Nx/2)}{\sin^2(x/2)} \end{cases} \]
    %
    where $\delta = 1/N$.
\end{example}

As $\delta \to 0$, we may think of the $K_\delta$ as `tending to the unit mass' Dirac delta function $\delta$ at the origin. $\delta$ may be given a precise meaning, either in the theory of Lebesgue-Stieltjes measures or as a `generalized function', but we don't need it to discuss the actual convergence results of the functions $K_\delta$.

\begin{theorem}
    If $\{ K_\delta \}$ is an approximation to the identity, and $f$ is integrable on $L^1(\mathbf{R}^d)$, then $(f * K_\delta)(x) \to f(x)$ for every $x$ in the Lebesgue set of $f$, and $f * K_\delta$ converges to $f$ in the $L^1$ norm.
\end{theorem}
\begin{proof}
    We rely on the fact that if $x$ is in the Lebesgue set, then the function
    %
    \[ A(r) = \frac{1}{r^d} \int_{|y| \leq r} |f(x-y) - f(x)|\ dy \]
    %
    is a bounded continuous function of $r > 0$, converging to $0$ as $r \to 0$. This means that if $\Delta(y) = |f(x-y) - f(x)| |K_\delta(y)|$, then
    %
    \[ \int \Delta(y)\ dy = \int_{|y| \leq \delta} \Delta(y) + \sum_{k = 0}^\infty \int_{2^k \delta \leq |y| \leq 2^{k+1} \delta} \Delta(y) \]
    %
    The first term is easily upper bounded by $CA(\delta)$, and the $k$'th term of the sum by $C'2^{-k}A(2^{k+1}\delta) \leq C''2^{-k}$ for constants $C',C''$ that do not depend on $\delta$. Letting $\delta \to 0$ gives us the convergence result.
\end{proof}

\section{Differentiability of Measurable Functions}

We now switch our object of study to finding a condition on a measurable function $f$ which guarantees differentiability almost everywhere, such that the derivative is absolutely integrable, and
%
\[ f(b) - f(a) = \int_a^b f'(t)\ dt \]
%
holds almost everywhere. One way we can solve our problem is to fix our attention to functions $f$ obtained by indefinite integrals. The results we have established guarantee that this theorem holds. But this leads to the extended problem of considering ways to characterize the properties of functions that arise from these indefinite integrals. We shall find that if $f$ has {\it bounded variation}, then most of these problems are answered.

If $f$ is a complex valued function on $[a,b]$, and $P$ is a partition, we can consider it's variation on a partition $P = a \leq t_0 < \dots < t_n \leq b$ to be
%
\[ V(f,P) = \sum_{k = 1}^n |f(t_k) - f(t_{k-1})| \]
%
we say $f$ has \emph{bounded variation} if there is a constant $M$ such that for any partition $P$, $V(f,P) \leq M$. This implies that, since the net $P \mapsto V(f,P)$ is increasing, the net converges to a value $V(f) = V(f,a,b)$, the \emph{total variation} of $f$ on $[a,b]$. The problem of variation is very connected to the problem of the {\it rectifiability of curves}. If $x: [a,b] \to \mathbf{R}^d$ parameterizes a continuous curve in the plane, then, for a given partition $P = a \leq t_0 \leq \dots \leq t_n$, we can consider an approximate length
%
\[ L_P(x) = \sum_{k = 1}^n |x(t_i) - x(t_{i-1})| \]
%
If $x$ has a reasonable notion of length, then the straight lines between $x(t_{i-1})$ and $x(t_i)$ should be shorter than the length of $x$ between $t_{i-1}$ and $t_i$. It therefore makes sense to define the \emph{length} of $x$ as
%
\[ L(x) = \sup L_P(x) \]
%
The triangle inequality implies that the map $P \mapsto L_P(x)$ is an increasing net, so $L$ is also the limit of the meshes as they become finer and finer. If $L(x) < \infty$, we say $x$ is a \emph{rectifiable curve}. One problem is to determine what analytic conditions one must place on $x$ in order to guarantee regularity, and what further conditions guarantee that, if $x_i$ is differentiable almost everywhere,
%
\[ L(x) = \int_a^b \sqrt{x_1'(t)^2 + \dots + x_n'(t)^2}\ dt \]
%
Considering rectifiable curves leads directly to the notion of a function with bounded variation.

\begin{theorem}
    A curve $x$ is rectifiable iff each $x_i$ has bounded variation.
\end{theorem}
\begin{proof}
    We can find a universal constants $A,B > 0$ such that for any $x,y \in \mathbf{R}^d$,
    %
    \[ A \sum |x_i - y_i| \leq |x-y| \leq B \sum |x_i - y_i| \]
    %
    This means that if $P$ is a partition of $[a,b]$, then
    %
    \[ A \sum_{ij} |x_j(t_i) - x_j(t_{i-1})| \leq \sum |x(t_i) - x(t_{i-1})| \leq B \sum_{ij} |x_j(t_i) - x_j(t_{i-1})| \]
    %
    So $A \sum V(x_i,P) \leq L_P(x) \leq B \sum V(x_i,P)$ gives the required result.
\end{proof}

\begin{example}
    If $f$ is a real-valued, monotonic, increasing function on $[a,b]$, then $f$ has bounded variation, and one can verify that $V(f) = f(b) - f(a)$.
\end{example}

\begin{example}
    If $f$ is differentiable at every point, and $f'$ is bounded, then $f$ has bounded variation. The mean value theorem implies that if $|f'| \leq M$, then for all $x,y \in [a,b]$,
    %
    \[ |f(x) - f(y)| \leq M |x-y| \]
    %
    This implies that $V(f,P) \leq M(b-a)$ for all partitions $P$.
\end{example}

\begin{example}
    Consider the functions $f$ defined on $[0,1]$ with
    %
    \[ f(x) = \begin{cases} x^a \sin(x^{-b}) &: 0 < x \leq 1 \\ 0 &: x = 0 \end{cases} \]
    %
    Then $f$ has bounded variation on $[0,1]$ if and only if $a > b$. The function oscillates from increasing to decreasing on numbers of the form $x = (n \pi)^{-1/b}$, so the total variation is described as
    %
    \begin{align*}
      V(f) &= 1 + \sum_{n = 1}^\infty (n \pi)^{-a/b} + ((n+1) \pi)^{-a/b}
    \end{align*}
    %
    This sum is finite precisely when $a/b > 1$. Thus functions of bounded variation cannot oscillate too widely, too often.
\end{example}

The next result is a decomposition theorem for bounded variation functions into bounded increasing and decreasing functions. We define the \emph{positive variation} of a real valued function $f$ on $[a,b]$ to be
%
\[ P(f,a,b) = \sup_P \sum_{f(t_i) \geq f(t_{i-1})} f(t_i) - f(t_{i-1}) \]
%
The \emph{negative variation} is
%
\[ N(f,a,b) = \sup_P \sum_{f(t_i) \leq f(t_{i-1})} -[f(t_i) - f(t_{i-1})] \]
%
Note that for each partition $P$, the sums of the two values above add up to the variation with respect to the partition.

\begin{lemma}
    If $f$ is real-valued and has bounded variation on $[a,b]$, then for all $a \leq x \leq b$,
    %
    \[ f(x) - f(a) = P(f,a,x) - N(f,a,x) \]
    %
    \[ V(f) = P(f,a,b) + N(f,a,b) \]
\end{lemma}
\begin{proof}
    Given $\varepsilon$, there exists a partition $a = t_0 < \dots < t_n = x$ such that
    %
    \[ \left| P(f,a,x) - \sum_{f(t_i) \geq f(t_{i-1})} f(t_i) - f(t_{i-1}) \right| < \varepsilon \]
    \[ \left| N(f,a,x) + \sum_{f(t_i) \leq f(t_{i-1})} f(t_i) - f(t_{i-1}) \right| < \varepsilon \]
    %
    It follows that
    %
    \[ |f(x) - f(a) - [P(f,a,x) - N(f,a,x)]| < 2 \varepsilon \]
    %
    and we can then take $\varepsilon \to 0$. The second identity follows the same way.
\end{proof}

A real function $f$ on $[a,b]$ has bounded variation if and only if $f$ is the difference of two increasing bounded functions, because if $f$ has bounded variation, then
%
\[ f(x) = [f(a) + P(f,a,x)] - N(f,a,x) \]
%
is the difference of two bounded increasing functions. On the other hand, the difference of two bounded increasing functions is clearly of bounded variation. A complex function has bounded variation if and only if it is the linear combination of four increasing functions in each direction.

\begin{theorem}
    If $f$ is a continuous function of bounded variation, then
    %
    \[ x \mapsto V(f,a,x) \ \ \ \ \ x \mapsto V(x,b) \]
    %
    are continuous functions.
\end{theorem}
\begin{proof}
    $V(f,a,x)$ is an increasing functin of $x$, so for continuity on the left it suffices to prove that for each $x$ and $\varepsilon$, there is $x_1 < x$ such that $V(f,a,x_1) \geq V(f,a,x) - \varepsilon$. If we consider a partition
    %
    \[ P = \{ a = t_0 <  \dots < t_n = x \} \]
    %
    where $|V(f,P) - V(f,a,x)| \leq \varepsilon$, then by continuity of $f$ at $x$, there is $t_{n-1} < x_1 < x$ with $|f(x) - f(x_1)| < \varepsilon$, and then if we modify $P$ to obtain $Q$ by swapping $t_n$ with $x_1$, we find
    %
    \begin{align*}
        V(f,a,x_1) \geq V(f,Q) &= V(f,P) - |f(x) - f(t_{n-1})| + |f(x_1) - f(t_{n-1})|\\
        &\geq V(f,P) - \varepsilon \geq V(f,a,x) - \varepsilon
    \end{align*}
    %
    A similar argument gives continuity on the right, and the continuity as the left bound of the interval changes.
\end{proof}

To obtain the differentiation theorem for functions of bounded variation, we require a lemma of F. Riesz.

\begin{lemma}[Rising Sun lemma]
    If $f$ is real-valued and continuous on $\mathbf{R}$, and $E$ is the set of points $x$ where there exists $h > 0$ such that $f(x+h) > f(x)$, then, provided $E$ is non-empty, it must be open, and can be written as a union of disjoint intervals $(a_n,b_n)$, where $f(b_n) = f(a_n)$. If $f$ is continuous on $[a,b]$, then $E$ is still an open subset of $[a,b]$, and can be written as the disjoint union of countably many intervals, with $f(b_n) = f(a_n)$ except if $a_n = a$, where we can only conclude $f(a_n) \leq f(b_n)$.
\end{lemma}
\begin{proof}
  The openness is clear, and the fact that $E$ can be broken into disjoint intervals follows because of the characterization of open sets in $\mathbf{R}$. If
  %
  \[ E = \bigcup (a_n,b_n) \]
  %
  Then $f(a_n + h) \leq f(a_n)$ and $f(b_n + h) \leq f(b_i)$, implying in particular that $f(b_n) \leq f(a_n)$, If $f(b_n) < f(a_n)$, then choose $f(b_n) < c < f(a_n)$. The intermediate value theorem implies there is $x$ with $f(x) = c$, and we may choose the largest $x \in [a_n,b_n]$ for which this is true. Then since $x \in (a_n,b_n)$, there is $y \in (x,b_i)$ with $f(x) < f(y)$, and by the intermediate value theorem, since $f(b_n) < f(x) < f(y)$, there must be $x' \in (y,b_n)$ with $f(x') = c$, contradicting that $x$ was chosen maximally. The proof for closed intervals operates on the same principles.
\end{proof}

\begin{theorem}
    If $f$ is increasing and continuous on $[a,b]$, then $f$ is differentiable almost everywhere. That is,
    %
    \[ f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h} \]
    %
    exists for almost every $x \in [a,b]$, $f'$ is measurable, and
    %
    \[ \int_a^b f'(x) \leq f(b) - f(a) \]
    %
    In particular, if $f$ is bounded on $\mathbf{R}$, then $f'$ is integrable on $\mathbf{R}$.
\end{theorem}
\begin{proof}the theorem in the 
    It suffices to assume that $f$ is increasing, and we shall start by proving case assuming $f$ is continuous. We define
    %
    \[ \Delta_h f (x) = \frac{f(x+h) - f(x)}{h} \]
    %
    and the four {\it Dini derivatives}
    %
    \[ D_+ f(x) = \liminf_{h \downarrow 0} \Delta_h f(x)\ \ \ \ \ D^+ f(x) = \limsup_{h \downarrow 0} \Delta_h f(x) \]
    \[ D_- f(x) = \liminf_{h \uparrow 0} \Delta_h f(x)\ \ \ \ \ D^- f(x) = \limsup_{h \uparrow 0} \Delta_h f(x) \]
    %
    Clearly, $D_+ f \leq D^+ f$ and $D_- f \leq D^- f$, It suffices to show $D^+ f(x) < \infty$ for almost every $x$, and $D^+ f(x) \leq D_- f(x)$ for almost every $x$, because if we consider the function $g(x) = -g(-x)$, then we obtain $D^- f(x) \leq D_+ f(x)$ for almost every $x$, so
    %
    \[ D^+ f (x) \leq D_- f(x) \leq D^- f(x) \leq D_+ f(x) \leq D^+ f(x) < \infty \]
    %
    for almost every $x$, implying all values are equal, and that the derivative exists at $x$.

    For a fixed $\gamma > 0$, consider $E_\gamma = \{ x: D^+ f (x) > \gamma \}$. Since each $\Delta_h f$ is continuous, the supremum of the $\Delta_h f$ over any index set is lower semicontinuous, and since
    %
    \[ D^+ f(x) = \lim_{h \to 0} \sup_{0 \leq s \leq h} \Delta_h f (x + s) \]
    %
    can be expressed as the countable limit of these lower semicontinuous functions, $D^+ f$ is measurable, hence $E_\gamma$ is measurable. Now consider the shifted function $g(x) = f(x) - \gamma x$. If $\bigcup (a_i,b_i)$ is the set obtainable from $g$ from the rising sun lemma, then $E_\gamma \subset \bigcup (a_i, b_i)$, for if $D^+ f(x) > \gamma$, then there is $h > 0$ arbitrarily small with $\Delta_h f(x) > \gamma$, hence $f(x + h) - f(x) > \gamma h$, hence $g(x+h) > g(x)$. We know that $g(a_k) \leq g(b_k)$, so $f(b_k) - f(a_k) \geq \gamma(b_k - a_k)$, so
    %
    \[ |E_\gamma| \leq \sum (b_k - a_k) \leq \frac{1}{\gamma} \sum f(b_k) - f(a_k) \leq \frac{f(b) - f(a)}{\gamma} \] 
    %
    Thus $|E_\gamma| \to 0$ as $\gamma \downarrow 0$, implying $D^+ f(x) = \infty$ only on a set of measure zero.

    Now for two real numbers $r < R$, we will now show
    %
    \[ E = \{ a \leq x \leq b : D^+ f(x) > R\ \ \ D_-f(x) < r \} \] 
    %
    is a set of measure zero. Letting $r$ and $R$ range over all rational numbers establishes that $D^+ f(x) \leq D_-f(x)$ almost surely. We assume $|E| > 0$ and derive a contradiction. By regularity, we may consider an open subset $U$ in $[a,b]$ containing $E$ such that $|U| < |E| (R/r)$. We can write $U$ as the union of disjoint intervals $I_n$. For a fixed $I_N$, apply the rising sun lemma to the function $rx - f(-x)$ on the interval $-I_N$, yielding a union of intervals $(a_n,b_n)$. If we now apply the rising sun lemma to the function $f(x) - Rx$ on $(a_n, b_n)$, we get intervals $(a_{nm}, b_{nm})$, whose union we denote $U_N$. Then
    %
    \[ R(b_{nm} - a_{nm}) \leq f(b_{nm}) - f(a_{nm})\ \ \ \ \ f(b_n) - f(a_n) \leq r(b_n - a_n) \]
    %
    then, because $f$ is increasing,
    %
    \begin{align*}
      |U_N| &= \sum_{nm} (b_{nm} - a_{nm}) \leq \frac{1}{R} \sum_{nm} (f(b_{nm}) - f(a_{nm}))\\
      &\leq \frac{1}{R} \sum f(b_n) - f(a_n) \leq \frac{r}{R} \sum_n (b_n - a_n) \leq \frac{r}{R} |I_N|
    \end{align*}
    %
    Now $E \cap I_N$ is contained in $U_N$, because if $x \in E \cap I_N$, then $D^+ f(x) > R$ and $D_- f(x) < r$, so we can sum in $N$ to conclude that
    %
    \[ |E| \leq \sum \frac{r}{R} |I_N| = \frac{r}{R} |U_N| < |E| \]
    %
    a contradiction proving the claim.
\end{proof}

\begin{corollary}
  If $f$ is increasing and continuous, then $f'$ is measurable, non-negative, and
  %
  \[ \int_a^b f'(x)\; dx \leq f(b) - f(a) \]
\end{corollary}
\begin{proof}
  The fact the $f'$ is measurable and non-negative results from the fact that the functions $g_n(x) = \Delta_{1/n} f(x)$ are non-negative and continuous, and $g_n \to f'$ almost surely. We know
  %
  \begin{align*}
    \int_a^b f'(x) &\leq \liminf_{n \to \infty} \int_a^b g_n(x) = \liminf_{n \to \infty} n \int_a^b [f(x + 1/n) - f(x)]\\
    &= \liminf_{n \to \infty} n \left[ \int_b^{b+1/n} f(x) - \int_a^{a + 1/n} f(x) \right] = f(b) - f(a)
  \end{align*}
  %
  where the last equality follows because $f$ is continuous.
\end{proof}

Even for increasing continuous functions, the inequality in the theorem above need not be an equality, as the next example shows, so we need something stronger to obtain our differentiation theorem.

\begin{example}
  The Cantor-Lebesgue function is a continuous increasing function $f$ from $[0,1]$ to itself, with $f(0) = 0$, and $f(1) = 1$, but with $f'(x) = 0$ almost everywhere. This means
  %
  \[ \int_0^1 f'(x) = 0 < 1 = f(1) - f(0) \]
  %
  so we cannot obtain equality in general. To construct $f$, consider the Cantor set $C = \bigcap C_k$, where $C_k$ is the disjoint union of $2^k$ closed intervals. Set $f_0 = 0$, and $f_1(0) = 0$, $f_1(x) = 1/2$ on $[1/3,2/3]$, $f_1(1) = 1$, and $f$ linear between $[0,1/3]$ and $[2/3,1]$. Similarily, set $f_2(0) = 0$, $f_2(x) = 1/4$ on $[1/9, 2/9]$, $f_2(x) = 1/2$ on $[1/3,2/3]$, $f_2(x) = 3/4$ on $[7/9,8/9]$, and $f_2(1) = 1$. The functions $f_i$ are increasing and cauchy in the uniform norm, so they converge to a continuous function $f$ called the \emph{Cantor function}. $f$ is constant on each interval in the complement of the cantor set, so $f'(x) = 0$ almost everywhere.
\end{example}

To obtain equality in the integral formula, we require additional conditions on our increasing functions, provided by absolute continuity.

\section{Absolute Continuity}

A function $f: [a,b] \to \mathbf{R}$ is \emph{absolutely continuous} if for every $\varepsilon > 0$, there is $\delta > 0$ such that whenever $(a_1, b_1), \dots, (a_n,b_n)$ are disjoint intervals with $\sum (b_i - a_i) < \delta$, $\sum |f(b_i) - f(a_i)| < \varepsilon$. Thus the function should be `essentially constant' over every set of zero measure. It is easy to see from this that absolutely continuous functions must be uniformly continuous, and have bounded variation. Thus $f$ has a decomposition into the difference of two continuous increasing functions, and one can see quite easily that these functions are also absolutely continuous. Most promising to us, if $f$ is a function defined by $f(x) = \int_a^x g(t)\ dt$, where $g \in L^1[a,b]$, then $f$ is absolutely continuous. This shows that absolute continuity is necessary in order to hope for the integral formula
%
\[ \int_a^b f'(x)\ dx = f(b) - f(a) \]
%
The Cantor function is {\it not} absolutely continuous, since it is constant except on the Cantor set, and we can cover the Cantor set by intervals with total length $(2/3)^n$ for each $n$. Thus it is impossible for the Cantor function to satisfy the fundamental theorem of calculus.

\begin{theorem}
  If $g \in L^1(\mathbf{R})$, and
  %
  \[ f(x) = \int_a^x g(t)\; dt \]
  %
  then $f$ is absolutely continuous.
\end{theorem}
\begin{proof}
  Fix $\varepsilon > 0$. We claim that there is $\delta$ such that if $|E| < \delta$, then $\int_E |g| < \varepsilon$. Otherwise there are sets $E_n$ with $|E_{n+1}| \leq |E_n|/3$ and with $\int_{E_n} |g| \geq \varepsilon$. Thus if we define the sets $E_m' = E_m - \bigcup_{n > m} E_n$ then the $E_m'$ and we have $|E_m| \sim |E_m|'$. Since $g$ is integrable, we must have $\sum \int_{E_n'} |g| < \infty$, so we conclude that as $N \to \infty$,
  %
  \[ \sum_{n \geq N} \int_{E_n'} |g| \to 0 \]
  %
  Yet for any $N$,
  %
  \[ \sum_{n \geq N} \int_{E_n'} |g| = \int_{E_N} |g| \geq \varepsilon \]
  %
  which is an impossibility. Thus such a $\delta$ exists for every $\varepsilon$, and so if we have disjoint intervals $(a_n,b_n)$ with $\sum (b_n - a_n) < \delta$, then
  %
  \[ \sum |f(b_n) - f(a_n)| = \sum \left| \int_{a_n}^{b_n} g(t) \right| \leq \sum \int_{a_n}^{b_n} |g| = \int_{\bigcup (a_n,b_n)} |g| < \varepsilon \]
  %
  which shows the function is absolutely continuous.
\end{proof}

To prove the differentiation theorem, we require a covering estimate not unlike that used to prove the Lebesgue differentiation theorem. We say a collection of balls is a \emph{Vitali covering} of a set $E$ if for every $x \in E$ and every $\eta > 0$, there is a ball $B$ in the cover containing $x$ with $|B| < \eta$. Thus every point is covered by an arbitrary small ball.

\begin{lemma}
    If $E$ is a set of finite measure, and $\{ B_\alpha \}$ is a Vitali covering of $E$, then for any $\delta > 0$, we can find finitely many disjoint balls $B_1, \dots, B_n$ in the covering such that
    %
    \[ \left| \bigcup B_i \right| = \sum |B_i| \geq |E| - \delta \]
\end{lemma}
\begin{proof}
    Without loss of generality, assume $\delta \leq |E|$. By inner regularity, pick a compact set $K \subset E$ with $|K| \geq |E| - \delta/2$. Then $K$ is covered by finitely many balls of radius less than $\eta$ in the covering $\{ B_\alpha \}$, and the elementary Vitali covering lemma gives a disjoint subcollection of balls $B_1, \dots, B_{n_0}$ with
    %
    \[ |K| \leq \left| \bigcup B_\alpha \right| \leq 3^d \sum |B_k| \]
    %
    so $\sum |B_k| \geq 3^{-d} |K|$. If $\sum |B_k| \geq |K| - \delta/2$, we're done. Otherwise, define $E_1 = K - \bigcup \overline{B_k}$. Then
    %
    \[ |E_1| \geq |K| - \sum |\overline{B_k}| = |K| - \sum |B_k| > \delta/2 \]
    %
    If we pick a compact set $K_1 \subset E_1$ with $|K_1| \geq \delta/2$, then if we remove all sets in the Vitali covering which intersect $B_1, \dots, B_{n_0}$, then we still obtain a Vitali covering for $K_1$, and we can repeat the argument above to find a disjoint collection of open sets $B_1^1, \dots, B_{n_1}^1$ with $\sum |B_k^1| \geq 3^{-d} |K_1|$. Then $\sum |B_k| + \sum |B^1_k| \geq 2 (3^{-d} \delta)$. If $\sum |B_k| + \sum |B^1_k| < |K| - \delta/2$, we repeat the same process, finding a disjoint family for $K_2 \subset E_2$, where $\smash{E_2 = K_1 - \bigcup \overline{B^1_k}}$. If this process repeats itself $k$ times, then we obtain a family of open sets with total measure greater than or equal to $k (3^{-d} \delta)$. But then if we eventually have $k \geq (|E| - \delta) 3^d/ \delta$, then the family of open sets satisfies the requirements of the theorem.
\end{proof}

\begin{corollary}
    We can arrange the choice of balls such that
    %
    \[ \left| E - \bigcup B_i \right| < 2\delta \]
\end{corollary}
\begin{proof}
    Let $E \subset U$, where $U$ is an open set with $|U - E| < \delta$. In the algorithm above, we may consider only balls in the Vitali covering as contained within $U$. But then
    %
    \[ \left| E - \bigcup B_i \right| \leq |U| - \sum |B_i| = |U| - \bigcup E_i \leq \delta + |E| - \sum |B_i| \leq 2\delta \]
    %
    and this gives the required bound.
\end{proof}

\begin{theorem}
    If $f: [a,b] \to \mathbf{R}$ is absolutely continuous, then $f'$ exists almost everywhere, and if $f'(x) = 0$ almost surely, then $f$ is constant.
\end{theorem}
\begin{proof}
    It suffices to prove that $f(a) = f(b)$, since we can then apply the theorem on any subinterval. Let $E = \{ x \in (a,b): f'(x) = 0 \}$. Then $|E| = b - a$. Fix $\varepsilon > 0$. Since for each $x \in E$, we have
    %
    \[ \lim_{h \to 0} \frac{f(x+h) - f(x)}{h} = 0 \]
    %
    This implies that the family of intervals $(x,y)$ such that the inequality $|f(y) - f(x)| \leq \varepsilon (y-x)$ holds forms a Vitali covering of $E$, and we may therefore select a family of disjoint intervals $I_i = (x_i,y_i)$ with
    %
    \[ \sum |I_i| \geq |E| - \delta = (b - a) - \delta \]
    %
    But $|f(y_i) - f(x_i)| \leq \varepsilon (y_i - x_i)$, so we conclude
    %
    \[ \sum |f(y_i) - f(x_i)| \leq \varepsilon (b - a) \]
    %
    The complement of $I_i$ is a union of intervals $J_i = (x_i',y_i')$ of total length $\leq \delta$. Applying the absolute continuity of $f$, we conclude
    %
    \[ \sum |f(y_i') - f(x_i')| \leq \varepsilon \]
    %
    so applying the triangle inequality,
    %
    \[ |f(b) - f(a)| \leq \sum |f(y_i') - f(x_i')| + \sum |f(y_i) - f(x_i)| \leq \varepsilon(b - a + 1) \]
    %
    We can then let $\varepsilon \to 0$ to obtain equality.
\end{proof}

\begin{theorem}
    Suppose $f$ is absolutely continuous on $[a,b]$. Then $f'$ exists almost every and is integrable, and
    %
    \[ f(b) - f(a) = \int_a^b f'(y)\ dy \]
    %
    so the fundamental theorem of calculus holds everywhere. Conversely, if $f \in L^1[a,b]$, then there is an absolutely continuous function $g$ with $g' = f$ almost everywhere.
\end{theorem}
\begin{proof}
    Since $f$ is absolutely continuous, we can write $f$ as the difference of two continuous increasing functions on $[a,b]$, and this easily implies $f$ is differentiable almost everywhere and is integrable on $[a,b]$. If $g(x) = \int_a^x f'(x)$, then $g$ is absolutely continuous, hence $g - f$ is also absolutely continuous. But we know that $(g - f)' = g' - f' = 0$ almost everywhere, so the last theorem implies that $g$ differs from $f$ by a constant. Since $g(a) = 0$, $g(x) = f(x) - f(a)$. The converse was proved exactly in our understanding of differentiating integrals.
\end{proof}

We now dwell slightly longer on the properties of absolutely continuous functions, which enables us to generalize other properties of integrals found in the calculus. We begin by noting that it is easy to verify that if $f$ and $g$ are absolutely continuous functions, then $fg$ is also absolutely continuous. We know $f'$, $g'$, and $(fg)'$ exist almost everywhere. But when all three exist simultaneously, the product rule gives $(fg)' = f'g + fg'$. The absolute continuity implies that
%
\[ \int_a^b f'g + fg' = \int_a^b (fg)' = f(b)g(b) - f(a)g(a) \]
%
Thus one can integrate a pair of absolutely continuous functions by parts. Next, we shall show that monotone absolutely continuous functions are precisely those we can use to change variables. One important thing to note is that even if $f$ is a continuous function, and $g$ is measurable, $g \circ f$ need not be measurable. The easy reason to see this is that the inverse image of every open set in $g$ is measurable, so in order to guarantee $g \circ f$ is measurable we need the inverse image of every measurable set under $f$ be measurable.

\begin{example}
  Consider the function $f(x) = \int_0^x \chi_E(x)\; dx$, where $E$ is a thick Cantor set. Then $f$ is absolutely continuous, strictly increasing on $[0,1]$, and maps $E$ to a set of measure zero. This is because $E = \lim E_n$, where $E_n$ is a family of intervals with $|E_n| \downarrow |E|$. Then $f(E_n)$ has total length $|E_n - E|$, so as $n \to \infty$, we see $\lim f(E_n) = f(E)$ has measure zero.  This means that $f(X)$ is measurable for any subset $X$ of $E$, and in particular, if $X$ is non-measurable, then $f^{-1}(f(X))$ cannot be measurable, even though $f(X)$ is measurable. Note that $f$ is strictly increasing even though it's derivatives vanish on a set of positive measure.
\end{example}

The next lemmas will show that even though $g \circ f$ may not be measurable, this does not really bother us too much when changing variables.

\begin{lemma}
  If $f$ is absolutely continuous, then it maps sets of measure zero to sets of measure zero.
\end{lemma}
\begin{proof}
  Let $E$ be a set of measure zero. Then for each $\delta > 0$, $E$ is coverable by a family of open intervals with total length $\delta$. But if $\delta$ is taken small enough, this means that $f(E)$ is coverable by a family of open intervals with total length bounded by $\varepsilon$, for any $\varepsilon$.
\end{proof}

This property of absolutely continuous functions is independant of the properties of the Euclidean domain as it's domain, and is used in the generalization of absolute continuity to more general domains, or even to measures. If $f$ is absolutely continuous, then the image of every interval is an interval, and since $f(\bigcup K_n) = \bigcup f(K_n)$, this implies that the image of a $F_\sigma$ set is measurable. But since every measurable set of $\mathbf{R}$ differs from a $F_\sigma$ set by a set of measure zero, the image of every Lebesgue measurable set is Lebesgue measurable. The reverse is almost true.

\begin{lemma}
  If $f$ is absolutely continuous, and $E$ measurable, then the set
  %
  \[ f^{-1}(E) \cap \{ x : f'(x) > 0 \} \]
  %
  is measurable.
\end{lemma}
\begin{proof}
  If $E$ is an open set, then
  %
  \[ |E| = \int_{f^{-1}(E)} f'(x)\; dx \]
  %
  It suffices to prove this when $E$ is an interval, and then this is just the theorem of differentiation for absolutely continuous functions. But then applying the dominated convergence theorem shows that this equation remains true if $E$ is an $G_\delta$ set. Furthermore, this means the theorem is true if $E$ is a closed set, and so by applying the monotone convergence theorem, the theorem is true if $E$ is an $F_\sigma$ set. But if $E$ is an arbitrary measurable set, then for every $\varepsilon$ there are $F_\sigma$ and $G_\delta$ sets $K \subset E \subset U$ with $|U - K| = 0$. But
  %
  \[ \alpha|f^{-1}(U - K) \cap \{ f' \geq \alpha \}| \leq \int_{f^{-1}(U-K)} f'(x)\; dx = |U - K| = 0 \]
  %
  Thus $f^{-1}(U-K) \cap \{ f' \geq \alpha \}$ is a set of measure zero, and so in particular by completeness, every set contained in this set is measurable, in particular $f^{-1}(U - E) \cap \{ f' \geq \alpha \}$ is measurable. But now this means
  %
  \[ \{ f' \geq \alpha \} - f^{-1}(U-E) \cap \{ f' \geq \alpha \} = f^{-1}(E) \cap \{ f' \geq \alpha \} \]
  %
  is measurable. Taking $\alpha \downarrow 0$ completes the proof.
\end{proof}

Because of this, even though $g \circ f$ is not necessarily measurable, $(g \circ f) f'$ is always measurable if $f$ is absolutely continuous. Thus the expression $\int (g \circ f) f'$ makes sense, and thus we can always interpret the change of variables formula.

\begin{theorem}
  If $f$ is absolutely continuous, and $g$ is integrable, then
  %
  \[ \int g(f(x)) f'(x)\; dx = \int g(y)\; dy \]
\end{theorem}
\begin{proof}
  Using the notation in the last proof, if $E$ is measurable, then
  %
  \[ |K| = \int_{f^{-1}(K)} f'(x)\; dx \leq \int_{f^{-1}(E)} f'(x)\; dx \leq \int_{f^{-1}(U)} f'(x)\; dx = |U| \]
  %
  and $|U| = |K| = |E|$, so that for any measurable set $E$,
  %
  \[ |E| = \int_{f^{-1}(E)} f'(x)\; dx \]
  %
  This imples the theorem we need to prove is true whenever $g$ is the characteristic function of any measurable set. But then by linearity, it is true for any simple function. By monotone convergence, it is then true for any non-negative function, and then by partitioning $g$ into the sum of simple functions, we obtain the theorem in general.
\end{proof}





\section{Differentiability of Jump Functions}

We now consider the differentiability of not necessarily continuous monotonic functions. Set $f$ to be an increasing function on $[a,b]$, which we may assume to be bounded.  Then the left and right limits of $f$ exist at every point, which we will denote by $f(x-)$ and $f(x+)$. Of course, we have $f(x-) \leq f(x) \leq f(x+)$. If there is a discontinuity, this means we are forced to have a `jump discontinuity' where $f$ skips an interval. This implies that $f$ can only have countably many such discontinuities, because a family of disjoint intervals on $\mathbf{R}$ is at most countable. Now define the jump function $\Delta f(x) = f(x^+) - f(x-)$, with $\theta(x) \in [0,1]$ defined such that $f(x_n) = f(x_n-) + \theta(x) \Delta f(x)$. If we define the functions
%
\[ j_y(x) = \begin{cases} 0 & : x < y \\ \theta(y) & : x = y \\ 1 & x > y \end{cases} \]
%
then we can define the \emph{jump function} associated with $f$ by
%
\[ J(x) = \sum_x \Delta f(x) j_n(x) \]
%
Since $f$ is bounded on $[a,b]$, we make the final observation that
%
\[ \sum_{x \in [a,b]} \Delta f(x) \leq f(b) - f(a) < \infty \]
%
so the series defining $J$ converges absolutely and uniformly.

\begin{lemma}
    If $f$ is increasing and bounded on $[a,b]$, then $J$ is discontinuous precisely at the values $x$ with $\Delta f(x) \neq 0$ with $\Delta J(x) = \Delta f(x)$. The function $f - J$ is continuous and increasing.
\end{lemma}
\begin{proof}
    If $x$ is a continuity point of $f$, then $j_y$ is continuous at $x$, and hence, because $\sum_y \Delta f(y) j_y(x) \to J(x)$ uniformly, so we conclude that $J$ is continuous at $x$. On the other hand, for each $y$, $j_y(y-) = 0$ and $j_y(y+) = 1$, and if we label the points of discontinuity of $f$ by $x_1, x_2, \dots$, then
    %
    \[ J(x) = \sum_{i = 1}^k \Delta f(x_i) j_{x_i} + \sum_{i = k+1}^\infty \Delta f(x_i) j_{x_i} \]
    %
    The right hand partial sums are continuous at $x_k$, whereas the left hand sum has a jump discontinuity of the same order as $f$ at $x_k$, we conclude $J$ also has this discontinuity. But this means that
    %
    \[ (f - J)(x_k+) - (f - J)(x_k-) = 0 \]
    %
    so $f - J$ is continuous at every point. $f - J$ is increasing because of the inequality
    %
    \[ J(y) - J(x) \leq \sum_{x < x_n \leq y} \alpha_n \leq f(y) - f(x) \]
    %
    which follows because $J$ is just the sum of jump discontinuities, and the right hand side because $f$ can decrease and increase outside of the jump discontinuities.
\end{proof}

Since $f - J$ is continuous and increasing, it is differentiable almost everywhere. It therefore remains to analyze the differentiability of the jump function $J$.

\begin{theorem}
    $J'$ exists and vanishes almost everywhere.
\end{theorem}
\begin{proof}
    Fix $\varepsilon > 0$, and consider
    %
    \[ E = \left\{ x \in [a,b]: \limsup_{h \to 0} \frac{J(x + h) - J(x)}{h} > \varepsilon \right\} \]
    %
    Then $E$ is measurable, because we can take the $\limsup$ over rational numbers because $J$ is increasing. We want to show it has measure zero. Suppose $\delta = |E|$. Consider $\eta > 0$ to be chosen later, and find $n$ such that $\sum_{k = n}^\infty \alpha_k < \eta$. Write
    %
    \[ J_0(x) = \sum_{n > N} \alpha_n j_n \]
    %
    Then $J_0(b) - J_0(a) < \eta$. Now $E$ differs from the set
    %
    \[ E' = \left\{ x \in [a,b]: \limsup_{h \to 0} \frac{J_0(x + h) - J_0(x)}{h} > \varepsilon \right\} \]
    %
    by finitely many points. Using inner regularity, find a compact set $K \subset E'$ with $|K| \geq \delta/2$. For each $x \in K$, we can find intervals $(\alpha_x, \beta_x)$ upon which $J_0(\beta_x) - J_0(\alpha_x) \geq \varepsilon |\beta_x - \alpha_x|$. But applying the elementary Vitali covering lemma, we can find a disjoint family of such intervals with $\sum (\beta_{x_i} - \alpha_{x_i}) \geq |K|/3 \geq \delta/6$. But now we find
    %
    \[ J_0(b) - J_0(a) \geq \sum J_0(\beta_{x_i}) - J_0(\alpha_{x_i}) \geq \varepsilon \delta/6 \]
    %
    This means $\delta \leq 6 \eta/\varepsilon$, and by letting $\eta \to 0$, we can conclude $\delta = 0$.
\end{proof}

This concludes our argument that {\it every} function of bounded variation has a derivative almost everywhere, because every such function can be uniquely written (up to a shift in the range of the functions) as the sum of a continuous function and a jump function. If $f$ is a function with bounded variation, then the function
%
\[ F(x) = \int_0^x f'(x) \]
%
is absolutely continuous, and $f - F$ is a continuous function with derivative zero almost everywhere. The fact that this decomposition is unique up to a shift as well (which can easily be seen in the case of an increasing function, from which the general case follows) leads us to refer to this as the \emph{Lebesgue decomposition} of a function of bounded variation on the real line.

\section{Rectifiable Curves}

We now consider the validity of the length formula
%
\[ L = \int_a^b (x'(t)^2 + y'(t)^2)^{1/2}\ dt \]
%
where $L$ is the length of the curve parameterized by $(x,y)$ on $[a,b]$. We cannot always expect this formula to hold, because if $x$ and $y$ are both the Cantor devil staircase function, then the formula above gives a length of zero, whereas we know the curve traces a line between $0$ and $1$, hence has length at least $\sqrt{2}$.

\begin{theorem}
    If a curve is parameterized by absolutely continuous functions $x$ and $y$ on $[a,b]$, then the curve is rectifiable, and has length
    %
    \[ \int_a^b (x'(t) + y'(t))^{1/2}\ dt \]
\end{theorem}
\begin{proof}
  This proof can be reworded as saying if $f$ is complex-valued and absolutely continuous, then it's total variation can be expressed as
  %
  \[ V(f,a,b) = \int_a^b |f'(t)|\; dt \]
  %
  If $P = \{ a \leq t_1 < \dots < t_n \leq b \}$ is a partition, then
  %
  \[ \sum |f(t_{n+1}) - f(t_n)| = \sum \left| \int_{t_n}^{t_{n+1}} f'(t)\; dt \right| \leq \sum \int_{t_n}^{t_{n+1}} |f'(t)|\; dt \leq \int_a^b |f'(t)|\; dt \]
  %
  so $V(f,a,b) \leq \int_a^b |f'(t)|\; dt$. To prove the converse inequality, fix $\varepsilon > 0$, and find a step function $g$ with $f' = g + h$, with $\| h \|_1 \leq \varepsilon$. If $G(x) = \int_a^x g(t)\; dt$ and $H(x) = \int_a^x h(t)\; dt$, then $F = G + H$, and $V(f,a,b) \geq V(G,a,b) - V(H,a,b) \geq V(G,a,b) - \varepsilon$, and if we partition $[a,b]$ into $a = t_0 < \dots < t_N$, where $G$ is constant on each $(t_n, t_{n+1})$, then 
  %
  \begin{align*}
    V(G,a,b) &\geq \sum |G(t_n) - G(t_{n-1})| = \sum \left| \int_{t_{n-1}}^{t_n} g(t)\; dt \right|\\
    &= \sum \int_{t_{n-1}}^{t_n} |g(t)|\; dt = \int_a^b |g(t)|\; dt \geq \| f' \|_1 - \varepsilon
  \end{align*}
  %
  Letting $\varepsilon \to 0$ now gives the result.
\end{proof}

It is interesting to note that any rectifiable curve has a special {\it parameterization by arclength}, i.e. a parameterization $(x(t), y(t))$ such that if $L$ is the length function associated to the parameterization, then $L(A,B) = B - A$. This is obtainable by inverting the length function.

\begin{theorem}
  If $z = (x,y)$ is a parameterization of a rectifiable curve by arclength, then $x$ and $y$ are absolutely continuous, and $|z'| = 1$ almost everywhere.
\end{theorem}
\begin{proof}
  For any $s < t$,
  %
  \[ t - s = L(s,t) = V(f,s,t) \geq |z(t) - z(u)| \]
  %
  so it follows immediately that $|z|$ is an absolutely continuous function, and $|z'| \leq 1$ almost surely. But now we know that
  %
  \[ \int_a^b |z'(t)| = b - a \]
  %
  and this equality can now only hold if $|z'(t)| = 1$ almost surely.
\end{proof}

\section{Bounded Variation in Higher Dimensions}

Since the higher dimensional Euclidean domains do not have an ordering, it is impossible to define their length by partitioning their domain, and the meaning of a jump discontinuity is no longer clear. However, there are properties equivalent to having bounded variation which are more extendable to higher dimensions.

\begin{theorem}
  The following properties of $f: \mathbf{R} \to \mathbf{R}$ are equivalent, for some fixed finite constant $A$.
  %
  \begin{itemize}
    \item $f$ can be modified on a set of measure zero so that it has bounded variation not exceeding $A$.
    \item $\int |f(x+h) - f(x)| \leq A|h|$ for all $h \in \mathbf{R}$.
    \item For any $C^1$ function $\varphi$ with compact support, $\left| \int f(x) \varphi'(x) \right| \leq A \| \varphi \|_\infty$.
  \end{itemize}
\end{theorem}
\begin{proof}
  If $V(f) = A$, where $A < \infty$, then we can write $f = f^+ - f^-$, where $f^+$ and $f^-$ are both increasing functions, and with $V(f) = V(f^+) + V(f^-)$. It then follows that $|f(x+h) - f(x)| \leq (f^+(x+h) - f^+(x)) + |f^-(x+h) - f^-(x)|$, so it suffices to prove the second property by assuming $f$ is increasing. But then by the monotone convergence theorem, assuming $h > 0$ without loss of generality,
  %
  \[ \int |f(x+h) - f(x)| = \lim_{y \to \infty} \int_{-y}^y f(x+h) - f(x) = \lim_{y \to \infty} \int_y^{y+h} f(x) - \int_{-y-h}^{-y} f(x) \]
  %
  The first term of the limit converges to $hV(f)$, and the second to zero, completing the first part of the theorem. Now assuming the second point, we prove the third point. Then using the second point, we find
  %
  \begin{align*}
    \left|\int f(x) \varphi'(x) \right| &= \left| \lim_{h \to 0} \int f(x) \frac{\varphi(x+h) - \varphi(x)}{h} \right|\\
    &= \left| \lim_{h \to 0} \int \frac{f(x-h) - f(x)}{h} \varphi(x) \right| \leq A \| \varphi \|_\infty
  \end{align*}
  %
  Finally, we consider the third point being true. The set of all partitions with rational points is countable. Suppose that for each rational $P = \{ t_0 < \dots < t_N \}$ there is a set $E_P$ of measure zero for each rational partition $P$ such that
  %
  \[ \sum_{n = 1}^N \sup_{\substack{x \in [t_{n-1},t_n]\\x \not \in E_P}} f(x) - \inf_{\substack{x \in [t_{n-1},t_n]\\x \not \in E_P}} f(x) \leq A \]
  %
  Then the union of $E_P$ over all rational $P$ has measure zero. We can modify $f$ on $E_P$ by setting $f(x) = \liminf_{y \to 0} f(x+y)$, and then $V(f,P) \leq A$ for all rational partitions $P$. If $Q$ is now any partition, we can find a rational partition $P$ with $V(f,P) \geq V(f,Q) - \varepsilon$, and so $V(f,P) \leq A - \varepsilon$. Taking $\varepsilon \to 0$ completes the argument. Thus if $f$ cannot be modified to have finite variation $A$, there exists a rational partition $P$ such that for any set $E$ of measure zero,
  %
  \[ \sum_{n = 1}^N \sup_{\substack{x \in [t_{n-1},t_n]\\x \not \in E}} f(x) - \inf_{\substack{x \in [t_{n-1},t_n]\\x \not \in E}} f(x) > A \]
  %
  Thus for any $\varepsilon$, there exists $E_n^+, E_n^- \subset [t_{n-1},t_n]$ of positive measure such that
  %
  \[ \sum_{n = 1}^N \inf_{x \in E_n^+} f(x) - \sup_{x \in E_n^-} f(x) > A \]
  %
  If we consider the polygonal function $\phi$ which 
\end{proof}

\section{Minkowski Content}

Given a set $K \in \mathbf{R}^n$, we let $K^\delta$ denote the open set consisting of points $x$ with $d(x,K) < \delta$. The $m$ dimensional \emph{Minkowski content} of $K$ is defined to be
%
\[ \lim_{\delta \to 0} \frac{1}{\alpha(n-m)} \frac{|K^\delta|}{\delta^m} \]
%
where $\alpha(d)$ is the volume of the unit ball in $d$ dimensions. When this limit exists, we denote it by $M^m(K)$. In this section, we mainly discuss the one dimensional Minkowski content in two dimensions, i.e. the values of
%
\[ \lim_{\delta \to 0} \frac{|K^\delta|}{2 \delta^m} \]
%
and it's relation the length of curves. Since we now only care about the one dimensional Minkowski content, we let $M(K)$ denote the one dimension Minkowski content.

\begin{lemma}
  If $\Gamma = \{ z(t): a \leq t \leq b \}$ is a curve, and $\Delta$ is the distance between the endpoints of the curve, then $|\Gamma^\delta| \geq 2 \delta \Delta$.
\end{lemma}
\begin{proof}
  By rotating, we may assume that both endpoints of the curve lie on the $x$ axis, so $z(a) = (A,0)$, $z(b) = (B,0)$ with $A < B$, so $\Delta = B - A$. If $\Delta = 0$, the theorem is obvious. Otherwise, for each point $x \in [A,B]$ there is $t(x)$ such that if $z_1(t(x)) = x$, and so $\Gamma^\delta$ contains $x \times [z_2(t(x)) - \delta, z_2(t(x)) + \delta]$, which has length $2 \delta$. Thus by Fubini's theorem,
  %
  \[ |\Gamma^\delta| = \int_{-\infty}^\infty \int_{-\infty}^\infty \chi_{\Gamma^\delta}(x,y)\; dx \;dy \geq \int_A^B 2 \delta = 2 \delta \Delta \]
  %
  so the theorem is proved.
\end{proof}

\begin{theorem}
  If $\Gamma = \{ z(t): a \leq t \leq b \}$ is a quasi-simple curve (simple except at finitely many points), then the Minkowski content of $\Gamma$ exists if and only if $\Gamma$ is rectifiable, and in this case $M^1(\Gamma)$ is the length of the curve $L$.
\end{theorem}
\begin{proof}
  To prove the theorem, we consider the upper and lower Minkowski contents
  %
  \[ M^*(\Gamma) = \limsup_{\delta\to 0} \frac{|\Gamma|^\delta}{\alpha(n-1) \delta}\ \ \ \ M_*(\Gamma) = \liminf_{\delta \to 0} \frac{|\Gamma|^\delta}{\alpha(n-1) \delta} \]
  %
  First, we prove that $M^*(\Gamma) \leq L$. Consider a partition $P$ of $[a,b]$, and let $L_P$ be the length of the polygonal approximation to the curve. By refining the partition, we may assume that $\Gamma$ is simple, with the repeated points at the boundaries of the intervals. For each interval $I_n$ in the partition, we select a closed subinterval $J_n = [t_n,u_n]$ such that $\Gamma$ is simple on $\bigcup J_n$, and
  %
  \[ \sum |z(u_n) - z(t_n)| \geq L_P - \varepsilon \]
  %
  Since the intervals $J_n$ are disjoint, for suitably small $\delta$ the sets $J_n^\delta$ are disjoint. Applying the previous lemma, we conclude that
  %
  \[ |\Gamma^\delta| \geq \sum |J_n^\delta| \geq 2 \delta \sum |z(u_n) - z(t_n)| = 2 \delta (L_p - \varepsilon) \]
  %
  First, by letting $\varepsilon \to 0$ and then $\delta \to 0$, we conclude that $M_*(\Gamma) \geq \lim_P L_P$. In particular, this shows that if $\Gamma$ has Minkowski content one, then the curve is rectifiable. Conversely, we consider the functions
  %
  \[ F_n(s) = \sup_{0 < |h| < 1/n} \left| \frac{z(s+h) - z(s)}{h} - z'(s) \right| \]
  %
  Because $z$ is continuous, this supremum can be considered over a countable, dense subset, and so each $F_n$ is measurable. Since $F_n(s) \to 0$ for almost every $s$, we can apply Egorov's theorem to show that this limit is uniform except on a singular set $E$ with $|E| < \varepsilon$, so that for some large $N$, for $s \not \in E$ and $|h| < 1/N$, $|z(s+h) - z(s) - hz'(s)| < \varepsilon h$. We now split the interval $[a,b]$ into consecutive intervals $I_1, \dots, I_{M+1}$, with each interval but $I_{M+1}$ having length $1/N$. We let $\Gamma_n$ denote the section of the curve travelled along the interval $I_n$. Thus $|\Gamma^\delta| \leq \sum |\Gamma_n^\delta|$. If an interval $I_n$ contains an element of $E^c$, we say $I_n$ is a `good' interval. Then we can pick an element $x_n \in I_n$ for which for any $x \in I_n$,
  %
  \[ |z(x) - z(x_n) - (x - x_n) z'(x_n)| < \varepsilon |x - x_n| < \varepsilon / N \]
  %
  Thus $\Gamma_n$ is covered by a $\varepsilon / N$ thickening of a length $1/N$ line $J_n$ in $\mathbf{R}^2$ through $z(x_n)$ with slope $z'(x_n)$. Thus if $\varepsilon \leq 1$, we conclude
  %
  \begin{align*}
    |\Gamma_n^\delta| &\leq J_n^{\varepsilon/N + \delta} \leq (1/N + 2\varepsilon/N + 2 \delta)(2\varepsilon/N + 2\delta)\\
    \leq 2 \delta/N + O(\delta \varepsilon / N + \delta^2 + \varepsilon/N^2)
  \end{align*}
  %
  Since $M \leq NL$, if we take the sum of $|\Gamma_n^\delta|$ over all `good' intervals we obtain an upper bound of
  %
  \[ NL \left( 2 \delta/N + O(\delta \varepsilon / N + \delta^2 + \varepsilon/N^2) \right) = 2 \delta L + O(\delta \varepsilon + \delta^2 N + \varepsilon/N) \]
  %
  On the other hand, if $I_n$ is contained within $E$, or if $n = M+1$, we say $I_n$ is a bad interval. Since $E$ has total measure bounded by $\varepsilon$, there can be at most $\varepsilon N + 1$ bad intervals. On these intervals we use the crude estimate $|z(t) - z(u)| \leq |t-u|$ (true because $z$ is an arclength parameterization) to show $\Gamma_n$ is contained in a rectangle with sidelengths $1/N$, so we obtain that $|\Gamma_n^\delta| \leq (1/N + 2\delta)^2 = O(1/N^2 + \delta^2)$. Thus the sum of $|\Gamma_n^\delta|$ over the `bad intervals' is bounded by
  %
  \[ O(\varepsilon/N + 1/N^2 + \varepsilon N \delta^2 + \delta^2) \]
  %
  In particular, the sum of the two bounds gives
  %
  \[ |\Gamma^\delta| \leq 2 \delta L + O(\delta \varepsilon + \delta^2 N + \varepsilon/N + 1/N^2) \]
  %
  Or
  %
  \[ \frac{|\Gamma^\delta|}{2 \delta} \leq L + O(\varepsilon + \delta N + \varepsilon/N + 1/N^2) \]
  %
  If we choose $N \geq 1/\delta$, we get that
  %
  \[ \frac{|\Gamma^\delta|}{2 \delta} \leq L + O(\varepsilon + \delta N + \delta \varepsilon) = L + O(\varepsilon + \delta N) \]
  %
  Letting $\delta \downarrow 0$, we conclude that $M^*(\Gamma) \leq L + O(\varepsilon)$, and we can then let $\varepsilon \downarrow 0$ to conclude $M^*(\Gamma) \leq L$. This completes the proof that if $\Gamma$ is rectifiable, then $\Gamma$ has one dimensional Minkowski content, and $M(\Gamma) = L$.
\end{proof}

If $\Gamma$ is rectifiable, it is parameterizable by a Lipschitz map (the arclength parameterization). If we instead consider a curve parameterizable by a map $z$ which is Lipschitz of order $\alpha$, which may no longer be absolutely continuous, but still has a decay very similar to the Minkowski dimension decay.

\begin{theorem}
  If $z$ is a planar curve which is Lipschitz of order $\alpha > 1/2$, then it's trace $\Gamma$ satisfies $|\Gamma^\delta| = O(\delta^{2-1/\alpha})$. 
\end{theorem}
\begin{proof}
  Since $|z(t) - z(s)| \leq |t - s|^\alpha$, we can cover $z$ by $O(N)$ radius $1/N^\alpha$ balls, so $|\Gamma| \lesssim N^{1-2\alpha}$, and so $|\Gamma^\delta| \lesssim N (1/N^\alpha + \delta)^2$. Setting $N = \delta^{-1/\alpha} + O(1)$ gives $|\Gamma^\delta| \lesssim \delta^{2-\alpha - 1/\alpha}$.
\end{proof}

\section{The Isoperimetric Inequality}

We now use our Minkowski content techniques to prove the isoperimetric inequality, which asks us to find the region in the plane with largest area whose boundary has a bounded length $L$. We suppose $\Omega$ is a bounded region of the plane, whose boundary $\partial \Omega$ is a rectifiable curve with length $L$. In particular, we shall find the region with the largest area whose boundary has a fixed length are balls. A key inequality used in the proof is the Brun Minkowski inequality, which lowers bounds the measure of $A+B$ in terms of $A$ and $B$. If we hope for an estimate $|A+B|^\alpha \gtrsim |A|^\alpha + |B|^\alpha$, then taking $B = \alpha A$, where $A$ is convex and, for which $A + \alpha A = (1 + \alpha)A$, we find $(1 + \alpha)^{d\alpha} \gtrsim (1 + \alpha^{d\alpha})$. Thus $\alpha \geq 1/d$.

\begin{lemma}
  If $A$, $B$, and $A+B$ are measurable, $|A + B|^{1/d} \geq |A|^{1/d} + |B|^{1/d}$.
\end{lemma}
\begin{proof}
  Suppose first that $A$ and $B$ are rectangles with side lengths $x_n$ and $y_n$. Then the Minkowski inequality becomes
  %
  \[ \left( \prod (x_n + y_n) \right)^{1/d} \geq \left( \prod x_n \right)^{1/d} + \left( \prod y_n \right)^{1/d} \]
  %
  Replacing $x_n$ with $\lambda_n x_n$ and $y_n$ with $\lambda_n y_n$, we find that we may assume $x_n + y_n = 1$, and so we must prove that for any $x_n \leq 1$,
  %
  \[ \left( \prod x_n \right)^{1/d} + \left( \prod (1 - x_n) \right)^{1/d} \leq 1 \]
  %
  But this inequality is an immediate consequence of the arithmetic geometric mean inequality. Thus the case is proved. Next, we suppose $A$ and $B$ are unions of disjoint closed rectangles, and we prove the inequality by induction on the number of rectangles. Without loss of generality, by symmetry in $A$ and $B$, we may assume that $A$ has at least two rectangles $R_1$ and $R_2$. Since the inequality is translation invariant separately in $A$ and $B$, and $R_1$ and $R_2$ is disjoint, hence separated by a coordinate axis, we may assume there exists an index $j$ such that every element $x$ of $R_1$ has $x_1 < 0$ and every element $x$ of $R_2$ has $x_1 > 0$. Let $A^+ = A \cap \{ x_j \leq 0 \}$ and $A^- = A \cap \{ x_j \geq 0\}$. Next, we translate $B$ such that if $B^{\pm}$ are defined similarily, then
  %
  \[ \frac{|B^{\pm}|}{|B|} = \frac{|A^{\pm}|}{|A|} \]
  %
  Note that $A+B$ contains the union of $A^+ + B^+$ and $A^- + B^-$, and this union is disjoint. Thus by induction,
  %
  \begin{align*}
    |A+B| &\geq |A^+ + B^+| + |A^- + B^-|\\
    &\geq (|A^+|^{1/d} + |B^+|^{1/d})^d + (|A^-|^{1/d} + |B^-|^{1/d})^d\\
    &= |A^+| \left( 1 + \left( \frac{|B|^+}{|A|^+} \right)^{1/d} \right)^d + |A^-| \left( 1 + \left( \frac{|B|^-}{|A|^-} \right) \right)^d\\
    &= (|A|^{1/d} + |B|^{1/d})^d
  \end{align*}
  %
  Thus the proof is completed for unions of rectangles. The proof then passes to open sets by approximating open sets by closed rectangles contained within. Then we can pass to where $A$ and $B$ are compact sets, since then $A+B$ is compact, and so if we consider the open thickenings $A^\varepsilon$, $B^\varepsilon$, and $(A+B)^\varepsilon$, then
  %
  \[ |A| = \lim |A^\varepsilon|\ \ \ |B| = \lim |B^\varepsilon|\ \ \ |A + B| = \lim |(A + B)^\varepsilon| \]
  %
  and $(A+B)^\varepsilon \subset A^\varepsilon + B^\varepsilon \subset (A + B)^{2\varepsilon}$. Finally, we can use inner regularity to obtain the theorem in full.
\end{proof}

\begin{theorem}
  For any region $\Omega$, $4 \pi |\Omega| \leq L^2$.
\end{theorem}
\begin{proof}
  For $\delta > 0$, consider
  %
  \[ \Omega_+(\delta) = \{ x: d(x,\Omega) < \delta \}\ \ \ \ \Omega_-(\delta) = \{ x : d(x,\Omega^c) \geq \delta \} \]
  %
  Then we have a disjoint union $\Omega_+(\delta) = \Omega_-(\delta) + \Gamma^\delta$, where $\Gamma$ is the boundary curve of $\Omega$. Furthermore, $\Omega_+(\delta)$ contains $\Omega + B_\delta$, and $\Omega$ contains $\Omega_-(\delta) + B_\delta$. Applying the Brun Minkowski inequality, we conclude
  %
  \[ |\Omega_+(\delta)| \geq (|\Omega|^{1/2} + \pi^{1/2} \delta)^2 \geq |\Omega| + 2 \pi^{1/2} \delta |\Omega|^{1/2} \]
  \[ |\Omega| \geq (|\Omega_-(\delta)|^{1/2} + \pi^{1/2} \delta)^2 \geq |\Omega_-(\delta)| + 2 \pi^{1/2} \delta |\Omega_-(\delta)|^{1/2} \]
  %
  But
  %
  \[ |\Gamma^\delta| = |\Omega_+(\delta)| - |\Omega_-(\delta)| \geq 2 \pi^{1/2} \delta \left( |\Omega|^{1/2} + |\Omega_-(\delta)|^{1/2} \right) \]
  %
  Dividing by $2\delta$ and letting $\delta \to 0$, we conclude $L \geq 2 \pi^{1/2} |\Omega|^{1/2}$. This is precisely the inequality we need.
\end{proof}

Using some Fourier analysis, we can prove that the only smooth curves which make this inequality tight are circles. Indeed, if a closed $C^1$ curve $\Gamma = \{ z(t): a \leq t \leq b \}$ is given, then Green's theorem implies the area of its interior is given by
%
\[ \frac{1}{2} \left| \int_\Gamma x\; dy - y\; dx \right| = \frac{1}{2} \left| \int_a^b x(t) y'(t) - y(t) x'(t) \right| \]
%
We then take a Fourier series in $x$ and $y$.

\begin{theorem}
  The only curves $\Gamma$ with rectifiable boundary such that $A = \pi (L/2)^2$ are circles.
\end{theorem}
\begin{proof}
By normalizing, we may assume $z$ is an arcline parameterization, and $\Gamma$ has length $2\pi$, so $z:[0,2\pi] \to \mathbf{R}^2$, and $z$ is absolutely continuous. If $x(t) \sim \sum a_n e^{nit}$ and $y(t) \sim \sum b_n e^{int}$, then $x'(t) \sim \sum i n a_n e^{n i t}$ and $y(t) \sim \sum i n b_n e^{nit}$. Parseval's equality implies
%
\[ \int_0^{2\pi} x(t) y'(t) - y(t) x'(t) = 2 \pi i \sum n (b_n \overline{a_n} - a_n \overline{b_n}) \]
%
Thus the area of the curve is precisely
%
\[ \pi \left| \sum n (b_n \overline{a_n} - a_n \overline{b_n}) \right| \leq \pi \sum 2n|b_na_n| \leq \pi \sum |n|(|a_n|^2 + |b_n|^2) \]
%
On the other hand, the length constraint implies that, since $|z'(t)| = 1$,
%
\[ 1 = \frac{1}{2\pi} \int_0^{2\pi} x'(t)^2 + y'(t)^2 = \sum |n|^2(|a_n|^2 + |b_n|^2) \]
%
If $A = \pi$, then
%
\[ \sum |n| (|a_n|^2 + |b_n|^2) \geq 1 = \sum |n|^2 (|a_n|^2 + |b_n|^2) \]
%
This means we cannot have $|n| < |n|^2$ whenever $a_n$ or $b_n$ is nonzero. Thus the Fourier support of $x$ and $y$ is precisely $\{ -1, 0, 1 \}$. Since $x$ is real valued, $a_1 = \overline{a_{-1}} = a$, $b_1 = \overline{b_{-1}}$. We thus have $2(|a_1|^2 + |b_1|^2) = 1$, and since we must have $a$ a scalar multiple of $b$ so the Cauchy Schwarz inequality application becomes an equality, we must have $|a_1| = |b_1| = 1/2$. If $a_1 = e^{i\alpha}/2$ and $b_1 = e^{i\beta}/2$, the fact that $1 = 2|a_1\overline{b_1} - \overline{a_1}b_1|$ implies $|\sin(\alpha - \beta)| = 1$, hence $\alpha - \beta = k \pi /2$, where $k$ is an odd integer. Thus $x(s) = \cos(\alpha + s)$, and $y(s) = \cos(\beta + s)$, which parameterizes a circle.
\end{proof}





\begin{theorem}
    If $\phi, \psi \in C_c^\infty(\RR^n)$, then $\Lambda * (\phi * \psi) = (\Lambda * \phi) * \psi$.
\end{theorem}
\begin{proof}
  Let $K$ be a compact set containing the supports of $\phi$ and $\psi$. It is simple to verify that for each $x \in \RR^d$,
    %
    \[ (\phi * \psi)^*(x) = \int \phi^*(x + y) \psi(y)\; dy = \int (T_y \phi^*)(x) \psi(y)\; dy \]
    %
    since the map $y \mapsto (T_y \phi)^* \psi(y)$ is continuous, and vanishes out of the compact set $K$, we can consider the $C_c^\infty(K)$ valued integral
    %
    \[ (\phi * \psi)^* = \int_K \psi^*(y) T_y \phi^*\; ds \]
    %
    This means precisely that
    %
    \begin{align*}
        (\Lambda * (\phi * \psi))(0) &= \Lambda((\phi * \psi)^*) = \int_K \psi^*(y) \Lambda(T_y \phi^*)\; dy\\
        &= \int_K \psi^*(y) (\Lambda * \phi)(y)\; dy = ((\Lambda * \phi) * \psi)(0)
    \end{align*}
    %
    The commutativity in general results from applying the commutativity of the translation operators.
\end{proof}

A net $\{ \phi_\alpha \}$ is known as an {\it approximate identity} in the space of distributions if $\Lambda * \phi_\alpha \to \Lambda$ weakly as $\alpha \to \infty$, for every distribution $\Lambda$, and an approximate identity in the space of test functions if $\psi * \phi_\alpha \to \psi$ in $C_c^\infty(\RR^n)$.

\begin{theorem}
    If $\phi_\alpha$ is a family of non-negative functions in $C_c^\infty(\RR^n)$ which are eventually supported on every neighbourhood of the origin, and integrate to one, then $\phi_\alpha$ is an approximation to the identity in the space of test functions and in the space of distributions.
\end{theorem}
\begin{proof}
    It is easy to verify that if $f$ is a continuous function, then $f * \phi_\delta$ converges locally uniformly to $f$ as $\delta \to 0$. But now we calculate that if $f \in C_c^\infty(\RR^n)$, then $D^\alpha(f * \phi_\delta) = (D^\alpha f) * \phi_\delta$ converges locally uniformly to $D^\alpha \phi$, which gives that $f * \phi$ converges to $f$ in $C_c^\infty(\RR^n)$. Now if $\Lambda$ is a distribution, and $\psi$ is a test function, then continuity gives
    %
    \begin{align*}
        \Lambda(\psi^*) &= \lim_{\delta \to 0} \Lambda(\phi_\delta * \psi) = \lim_{\delta \to 0} (\Lambda * (\phi_\delta * \psi))(0)\\
        &= \lim_{\delta \to 0} ((\Lambda * \phi_\delta) * \psi)(0) = \lim_{\delta \to 0} (\Lambda * \phi_\delta)(\psi^*)
    \end{align*}
    %
    and $\psi$ was arbitrary.
\end{proof}

If $\Lambda$ is a distribution on $\RR^n$, then the map $\phi \mapsto \Lambda * \phi$ is a linear transformation from $C_c^\infty(\RR^n)$ into $C^\infty(\RR^n)$, which commutes with translations. It is also continuous. To see this, we consider a fixed compact $K$, and consider the map from $C_c^\infty(K)$ to $C^\infty(\RR^n)$. We can apply the closed graph theorem to prove continuity, so we assume the existence of $\phi_1, \phi_2, \dots$ converging to $\phi$ in $C_c^\infty(K)$ and $\Lambda * \phi_1, \Lambda * \phi_2, \dots$ converges to $f$. It suffices to show $f = \Lambda * \phi$. But we calculate that for each $x \in \RR^d$,
%
\[ f(x) = \lim (\Lambda * \phi_n)(x) = \lim \Lambda(T_x \phi^*_n) = \Lambda (\lim T_x \phi^*_n) = \Lambda(T_x \phi^*) = (\Lambda * \phi)(x). \]
%
Here we have used the fact that $T_x \phi_n^*$ converges to $T_x \phi^*$ in $C_c^\infty(\RR^n)$. Suprisingly, the converse is also true.

\begin{theorem}
    If $L: C_c^\infty(\RR^n) \to C^\infty(\RR^n)$ and commutes with translations, then there is a distribution $\Lambda$ such that $L(\phi) = \Lambda * \phi$.
\end{theorem}
\begin{proof}
    If $L(\phi) = \Lambda * \phi$, then we would have
    %
    \[ \Lambda(\phi) = (\Lambda * \phi^*)(0) = L(\phi^*)(0) \]
    %
    and we take this as the definition of $\Lambda$ for an arbitrary operator $L$. Indeed, it then follows that $\Lambda$ is continuous because all the operations here are continuous, and because $L$ commutes with translations, we conclude
    %
    \[ (\Lambda * \phi)(x) = \Lambda(T_x \phi^*) = L(T_{-x} \phi)(0) = L(\phi)(x) \]
    %
    which gives the theorem.
\end{proof}

We now move onto the case where a distribution $\Lambda$ has compact support. Then $\Lambda$ extends to a continuous functional on $C^\infty(\RR^n)$, and we can define the convolution $\Lambda * \phi$ if $\phi \in C^\infty(\RR^n)$. The same techniques as before verify that translations and derivatives are carried into the convolution.

\begin{theorem}
    If $\phi$ and $\Lambda$ have compact support, then $\Lambda * \phi$ has compact support.
\end{theorem}
\begin{proof}
    Let $\phi$ and $\Lambda$ be supported on $K$. Then $(\Lambda * \phi)(x) = \Lambda(T_x \phi^*)$. Since $T_x \phi^*$ is supported on $x - K$, for $x$ large enough $x-K$ is disjoint from $K$, and so $\Lambda * \phi$ vanishes outside of $K + K$.
\end{proof}

\begin{theorem}
    If $\Lambda$ and $\psi$ have compact support, and $\phi \in C^\infty(\RR^n)$, then
    %
    \[ \Lambda * (\phi * \psi) = (\Lambda * \phi) * \psi = (\Lambda * \psi) * \phi \]
\end{theorem}
\begin{proof}
    Let $\Lambda$ and $\psi$ be supported on some balanced compact set $K$. Let $V$ be a bounded, balanced open set containing $K$. If $\phi_0$ is a function with compact support equal to $\phi$ on $V + K$, then for $x \in V$,
    %
    \[ (\phi * \psi)(x) = \int \phi(x - y) \psi(y)\; dy = \int \phi_0(x - y) \psi(y)\; dy = (\phi_0 * \psi)(x) \]
    %
    Thus
    %
    \[ (\Lambda * (\phi * \psi))(0) = (\Lambda * (\phi_0 * \psi))(0) = ((\Lambda * \psi) * \phi_0)(0) \]
    %
    But $\Lambda * \psi$ is supported on $K + K$, so $((\Lambda * \psi) * \phi_0)(0) = ((\Lambda * \psi) * \phi)(0)$. Now we also calculate
    %
    \[ (\Lambda * (\phi * \psi))(0) = ((\Lambda * \phi_0) * \psi)(0) = ((\Lambda * \phi) * \psi)(0) \int (\Lambda * \phi_0)(-y) \psi(y) \]
    %
    where the last fact follows because $\Lambda * \phi_0$ agrees with $\Lambda * \phi$ on $K$. The general fact follows by applying the translation operators.
\end{proof}

Now we come to the grand finale, defining the convolution of two distributions. Given two distributions $\Lambda$ and $\Psi$, one of which has compact support, we define the linear operator
%
\[ L(\phi) = \Lambda * (\Psi * \phi) \]
%
Then $L$ commutes with translations, and is continuous, because if we have $\phi_1, \phi_2, \dots$ converging to $\phi$ in $C_c^\infty(K)$, then $\Psi * \phi_n$ converges to $\Psi * \phi$ in $C^\infty(\RR^n)$. If $\Psi$ is supported on a compact support $C$, then the $\Psi * \phi_n$ have common compact support $C + K$, and actually converge in $C_c^\infty(C + K)$, hence $\Lambda * (\Psi * \phi_n)$ converges to $\Lambda * (\Psi * \phi)$. Conversely, if $\Lambda$ has compact support, then $\Psi * \phi_n$ converges in $C^\infty(\RR^n)$, which implies $\Lambda * (\Psi * \phi_n)$ converges to $\Lambda * (\Psi * \phi)$ in $C^\infty(\RR^n)$. Thus $L$ corresponds to a distribution, and we define this distribution to be $\Lambda * \Psi$.

\begin{theorem}
    If $\Lambda$ and $\Psi$ are distributions, one of which has compact support, then $\Lambda * \Psi = \Psi * \Lambda$. Let $S_\Lambda$ and $S_\Psi$, and $S_{\Lambda * \Psi}$ denote the supports of $\Lambda$, $\Psi$, and $\Lambda * \Psi$. Then $\Lambda * \Psi = \Psi * \Lambda$, and $S_{\Lambda * \Psi} \subset S_\Lambda + S_\Psi$.
\end{theorem}
\begin{proof}
    We calculate that for any two test functions $\phi$ and $\psi$,
    %
    \[ (\Lambda * \Psi) * (\phi * \psi) = \Lambda * (\Psi * (\phi * \psi)) = \Lambda * ((\Psi * \phi) * \psi) \]
    %
    If $\Lambda$ has compact support, then
    %
    \[ \Lambda * ((\Psi * \phi) * \psi) = (\Lambda * \psi) * (\Psi * \phi) \]
    %
    Conversely, if $\Psi$ has compact support, then
    %
    \[ \Lambda * ((\Psi * \phi) * \psi) = \Lambda * (\psi * (\Psi * \phi)) = (\Lambda * \psi) * (\Psi * \phi) \]
    %
    We also calculate
    %
    \begin{align*}
        \Psi * ((\Lambda * \phi) * \psi) &= \Psi * (\Lambda * (\phi * \psi)) = \Psi * (\Lambda * (\psi * \phi))\\
        &= \Psi * ((\Lambda * \psi) * \phi) = (\Psi * \phi) * (\Lambda * \psi)
    \end{align*}
    %
    But since convolution is commutative, we have
    %
    \[ ((\Lambda * (\Psi * \phi)) * \psi) = \Lambda * ((\Psi * \phi) * \psi) = \Psi * ((\Lambda * \phi) * \psi) = (\Psi * (\Lambda * \phi)) * \psi \]
    %
    Since $\psi$ was arbitrary, we conclude
    %
    \[ (\Lambda * \Psi) * \phi = \Lambda * (\Psi * \phi) = \Psi * (\Lambda * \phi) = (\Psi * \Lambda) * \phi \]
    %
    and now since $\phi$ was arbitrary, we conclude $\Lambda * \Psi = \Psi * \Lambda$. Now we know convolution is commuatative, we may assume $S_\Psi$ is compact. The support of $\Psi * \phi^*$ lies in $S_\Psi - S_\phi$. But this means that if $S_\phi - S_\Psi$ is disjoint from $S_\Lambda$, which means exactly that $S_\phi$ is disjoint from $S_\Lambda + S_\Psi$, then
    %
    \[ (\Lambda * \Psi)(\phi) = (\Lambda * (\Psi * \phi))(0) = 0 \]
    %
    and this gives the support of $\Lambda * \Psi$.
\end{proof}

This means that the convolution of two distributions with compact support also has compact support. This means that if we have three distributions $\Lambda, \Psi$, and $\Phi$, two of which have compact support, then the distributions $\Lambda * (\Psi * \Phi)$ and $(\Lambda * \Psi) * \Phi$ are well defined, so convolution is associative and commutative. We calculate that for any test function $\phi$,
%
\[ (\Lambda * (\Psi * \Phi)) * \phi = \Lambda * (\Psi * (\Phi * \phi)) \]
\[ ((\Lambda * \Psi) * \Phi) * \phi = (\Lambda * \Psi) * (\Phi * \phi) \]
%
If $\Phi$ has compact support, then $\Phi * \phi$ has compact support, and so we can move $(\Lambda * \Psi)$ into the equation to prove equality. If $\Phi$ does not have compact support, then $\Lambda$ and $\Psi$ have compact support, and
%
\[ \Lambda * (\Psi * \Phi) = \Lambda * (\Phi * \Psi) \]
%
and we can apply the previous case to obtain that this is equal to $(\Lambda * \Phi) * \Psi$. Repeatedly applying the previous case brings this to what we want.

\begin{theorem}
    If $\Lambda$ and $\Psi$ are distributions, one of which having compact support, then
    %
    \[ D^\alpha(\Lambda * \Psi) = (D^\alpha \Lambda) * \Psi = \Lambda * (D^\alpha \Psi). \]
\end{theorem}
\begin{proof}
    The Dirac delta function $\delta$ satisfies
    %
    \[ (\delta * \phi)(x) = \int \phi(y) \delta(x-y)\; dy = \phi(x) \]
    %
    so $\delta * \phi = \phi$. Now $D^\alpha \delta$ is also supported at $x$, since
    %
    \[ (D^\alpha \delta)(\phi) = (-1)^{|\alpha|} \int \delta(x) (D^\alpha \phi)(x)\; dx = (-1)^{|\alpha|} (D^\alpha \phi)(0) \]
    %
    which means that for any distribution $\Lambda$, then $(D^\alpha \delta) * \Lambda$ has compact support,
    %
    \[ (((D^\alpha \delta) * \Lambda) * \phi)(0) = (D^\alpha \delta)((\Lambda * \phi)^*) = (-1)^{|\alpha|} D^\alpha (\Lambda * \phi)^* = ((D^\alpha \Lambda) * \phi)(0) \]
    %
    which verifies that $(D^\alpha \delta) * \Lambda = \delta * (D^\alpha \Lambda)$. But now we find
    %
    \[ D^\alpha(\Lambda * \Psi) = (D^\alpha \delta) * \Lambda * \Psi = ((D^\alpha \delta) * \Lambda) * \Psi = D^\alpha \Lambda * \Psi \]
    \[ D^\alpha(\Lambda * \Psi) = D^\alpha(\Psi * \Lambda) = (D^\alpha \Psi) * \Lambda = \Lambda * (D^\alpha \Psi) \]
    %
    which verifies the theorem in general.
\end{proof}




\chapter{Singular Integral Operators}



\section{The Calderon Zygmund Decomposition}

For a fixed integer $n$, we let $\mathcal{B}(n)$ denote the family of all sidelength $1/2^n$ half open cubes with corners on the lattice $(\mathbf{Z}/2^n)^d$, i.e.
%
\[ \mathcal{B}(n) = \{ [a_1,b_1) \times \dots \times [a_d,b_d) : a_i, b_i \in \mathbf{Z}/2^n \} \]
%
Thus $\mathcal{B}(n)$ partitions $\mathbf{R}^d$ for each integer $n$. We refer to $\mathcal{B} = \bigcup \mathcal{B}(n)$ as the family of all \emph{dyadic} cubes. An important property is that if $I$ and $J$ are dyadic, either one cube contains the other, or they are completely disjoint. This makes Vitali type covering arguments redundant, because every union of dyadic cubes can be written as the disjoint union of dyadic cubes (except if the union is $\mathbf{R}^d$). Thus we can obtain weak type bounds for the corresponding `dyadic maximal function' very easily, and ignore the dimensional constants previously required.

\begin{theorem}
  If
  %
  \[ (Mf)(x) = \sup_{\substack{I \in \mathcal{B}\\x \in I}} \fint_I |f(x)|\; dx \]
  %
  Then $\| Mf \|_{(1,\infty)} \leq \| f \|_1$.
\end{theorem}
\begin{proof}
  Fix $\varepsilon > 0$, and let $E_{\alpha,\varepsilon} = \{ x \in \mathbf{R}^d: Mf(x) > \alpha \}$. Since $f$ is integrable, $E_\alpha \neq \mathbf{R}^d$. Then $E_\alpha$ decomposes into union of dyadic cubes $I_1, I_2, \dots \in \mathcal{B}$, which we can assume are disjoint. Thus
  %
  \[ |E_\alpha| = \sum_{k = 1}^\infty |I_k| \leq \frac{1}{\alpha} \sum_{k = 1}^\infty \int_{I_k} |f(y)|\; dy \leq \frac{\| f \|_1}{\alpha}. \qedhere \]
\end{proof}

Thus we find that if we consider the conditional expectation operators
%
\[ E_k f(x) = \sum_{I \in \mathcal{B}(k)} \left( \fint_I f \right) \chi_I \]
%
Then $E_k f(x) \to f(x)$ for almost all $x$, if $f \in L^1_{\text{loc}}(\mathbf{R}^d)$. Using this, we can obtain a very useful way to discretize $f$ on dyadic cubes, known as the Calderon-Zygmund decomposition.

\begin{theorem}
  Given an integrable, non-negative $f$, and $\lambda > 0$, there is a disjoint collection of dyadic cubes $I_1, \dots, I_N$ such that $\sum |I_k| \leq \lambda^{-1} \| f \|_1$, $f(x) \leq \lambda$ for almost every $x \not \in \bigcup I_k$, and for each $k$,
  %
  \[ \int_{I_k} f(x)\; dx = 0 \quad \text{and} \quad \lambda < \fint_{I_k} |f(x)| < 2^d \lambda \]
\end{theorem}
\begin{proof}
  Let $M$ be the dyadic maximal operator. Write $E = \{ x: Mf(x) > \lambda \}$. Because $f$ is integrable, $E \neq \mathbf{R}^d$. Thus $E$ is the disjoint union of dyadic cubes $I_1, \dots, I_N$, and we can assume $N$ is minimal, so that if $I_k$ has sidelength $2^i$, then the unique sidelength $2^{i+1}$ dyadic cube $J_k$ containing $I_k$ is not a subset of $E$. By construction, we know that
  %
  \[ \lambda < \fint_{I_k} f(x) \]
  %
  But also
  %
  \[ |I_k| \fint_{I_k} f(x) \leq |J_k| \fint_{J_k} f(x) \leq (2^d |I_k|) \lambda \]
  %
  which gives the upper bound on the averages. If $x$ is not contained in any of the cubes $I_1, \dots, I_N$, then $(E_k f)(x) \leq \lambda$ for all $k$, and thus for almost every $x$ not in $I_1, \dots, I_N$, $f(x) \leq \lambda$. The weak bound for the maximal function gives that $\sum |I_k| \leq \lambda^{-1} \| f \|_1$, which completes the proof.
\end{proof}

A useful way to think about the Calderon Zygmund decomposition is a way to decompose integrable functions $f = f_0 + f_1$, where
%
\[ f_0(x) = \begin{cases} \fint_{I_k} f(x) & x \in I_k \\ f(x) & x \not \in I_k \end{cases} \]
%
Then $\| f_0 \|_\infty \leq 2^d \lambda$, which combined with the fact that is integrable, implies that $f_0$ is fairly analytically stable. It is the `good part' of $f$. On the other hand, $f_1$ is the `bad part' of $f$, but it is supported on a set with size $\lambda^{-1} \| f \|_1$, and it's average on each of the $I_k$ is equal to zero.




\chapter{Fourier Multiplier Operators}

Our aim in this chapter is to study the boundedness of \emph{Fourier multiplier operators}. Given a function $m: \RR^d \to \CC$, known as a \emph{symbol}, we want to associate a multiplier operator $m(D)$ which when applied to a function $f: \RR^d \to CC$ should be formally given by the equation
%
\[ (m(D)f)(x) = \int_{\RR^d} m(\xi) \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi. \]
%
In maximum generality, if $m$ is a tempered distribution on $\RR^d$ we can consider the continuous operator $m(D): \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$. But often times $m$ will be much more regular, which we would hope can be exploited to give stronger continuity statements. Taking the Fourier transform shows that if $\widehat{K} = m$, then $m(D) f = K * f$. Thus Fourier multiplier operators are the same as convolution operators by tempered distributions. In any case, the map $m \mapsto m(D)$ gives an injective \emph{algebra homomorphism} from the family of all tempered distributions to the family of continuous operators on $\mathcal{S}(\RR^d)$. The main goal, of course, is to determine what properties of the symbol or it's Fourier transform imply boundedness properties of the operator $T$.

\begin{remark}
  In engineering these operators are known as \emph{filters}, and occur in a variety of contexts. Due to the presence of error the regularity of these operators are of utmost importance. The function $m$ is known as the \emph{system-transfer function}, \emph{optical-transfer function}, or \emph{frequency response}, depending on the context, and the function $K$ is known as the \emph{point-spread function}.
\end{remark}

\begin{example}
  Over $\RR$, we consider the Fourier multiplier
  %
  \[ m(\xi) = - i \text{sgn}(\xi). \]
  %
  Then $m(D)$ is the Hilbert transform.
\end{example}

\begin{example}
  In $\RR^d$, we consider the Fourier multiplier
  %
  \[ m_R(\xi) = \mathbf{I}(|\xi| \leq R). \]
  %
  The operator $m_R(D)$ is known as the \emph{ball multiplier operator}. More generally, given any compact set $S$ we can consider the Fourier multiplier $\mathbf{I}_S(D)$. In the engineering literature these multipliers are called \emph{ideal low pass filters}.
\end{example}

\begin{example}
  In this chapter, it is natural to renormalize the differentiation operators $D^\alpha: \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$ so that for $f \in \mathcal{S}(\RR^d)$,
  %
  \[ \widehat{D^\alpha f} = \xi^\alpha \widehat{f}. \]
  %
  In particular, this implies that if $m(\xi) = \xi_i^\alpha$, then $m(D) = D^\alpha$. More generally, if $m(\xi) = \sum_{|\alpha| \leq k} c_\alpha \xi^\alpha$, then
  %
  \[ m(D) = \sum_{|\alpha| \leq k} c_\alpha D^\alpha. \]
  %
  Thus the family of Fourier multiplier operators contains all constant coefficient differential operators.
\end{example}

Fourier multiplier operators have been essential to us in the classical theory. In particular, we have used Fourier multiplier operators to prove a great many results; the convolution operator by the Poisson kernel is a Fourier multiplier given by the symbol $e^{-|x|}$, and the heat kernel is a Fourier multiplier with symbol $e^{- \pi |x|^2}$. This is no coincidence. It is a general heuristic that any well-behaved translation invariant operator is given by convolution with an appropriate function.

For instance, we have already seen in the chapter on distributions that any translation invariant continuous linear operator $T: C_c^\infty(\RR^d) \to C^\infty(\RR^d)$ is given by convolution with a distribution. If the distribution is tempered, we can take the Fourier transform to conclude that the operator is a Fourier multiplier operator. In fact, if $1 \leq p,q \leq \infty$ and $T$ satisfies a bound of the form
%
\[ \| Tf \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
for any $f \in \mathcal{S}(\RR^d)$, then $T$ is a Fourier multiplier operator. To prove this, we rely on a Sobolev-type regularity result.

\begin{lemma}
  Suppose $1 \leq p,q \leq \infty$. If $f \in L^p(\RR^d)$ has a strong derivative $D^\alpha f$ in $L^p(\RR^d)$ for all $|\alpha| \leq d+1$, then $f \in C(\RR^d)$, and
    %
    \[ |f(0)| \lesssim_{d,p} \sum_{|\alpha| \leq d + 1} \| D^\alpha f \|_{L^p(\RR^d)}. \]
\end{lemma}
\begin{proof}
    Let us first suppose $p = 1$. Then
    %
    \begin{align*}
      |\widehat{f}(x)| &\lesssim \frac{\sum_{|\alpha| \leq d+1} |x^\alpha \widehat{f}(x)|}{(1 + |x|)^{d+1}}\\
      &\lesssim \frac{\sum_{|\alpha| \leq d+1} \| D^\alpha f \|_{L^1(\RR^d)}}{(1 + |x|)^{d+1}}
    \end{align*}
    %
    Since $1/(1 + |x|)^{d+1} \in L^1(\RR^d)$, we conclude that $\widehat{f} \in L^1(\RR^d)$, and
    %
    \[ \| \widehat{f} \|_{L^1(\RR^d)} \lesssim \sum_{|\alpha| \leq d+1} \| D^\alpha f \|_{L^1(\RR^d)}. \]
    %
    It follows by the Fourier inversion formula that $f \in C(\RR^d)$, and moreover,
    %
    \[ \| f \|_{L^\infty(\RR^d)} \leq \sum_{|\alpha| \leq d+1} \| D^\alpha f \|_{L^1(\RR^d)}, \]
    %
    which completes the proof for $p = 1$.

    For $p > 1$, any compactly supported bump function $\phi$, and any multi-index $\alpha$ with $|\alpha| \leq d+1$,
    %
    \[ \| D^\alpha(\phi f) \|_{L^1(\RR^d)} \leq \sum_{\beta \leq \alpha} \| D^\beta \phi \cdot D^{\alpha - \beta} f \|_{L^1(\RR^d)} \lesssim_\phi \sum_{\beta \leq d+1} \| D^\beta f \|_{L^p(\RR^d)}. \]
    %
    It follows from the previous case that $\phi f \in C(\RR)$, and
    %
    \[ \phi(0) f(0) \lesssim_\phi \sum_{\beta \leq d+1} \| D^\beta f \|_{L^p(\RR^d)}. \]
    %
    Since $\phi$ was arbitrary, we conclude $f \in C(\RR)$, and that
    %
    \[ f(0) \lesssim \sum_{\beta \leq d+1} \| D^\beta f \|_{L^p(\RR^d)}. \qedhere \]
\end{proof}

\begin{theorem}
  Suppose $1 \leq p,q \leq \infty$, and $T: \mathcal{S}(\RR^d) \to L^q(\RR^d)$ is a linear map commuting with translations and satisfies
  %
  \[ \| Tf \|_{L^q(\RR^d)} \leq \| f \|_{L^p(\RR^d)} \]
  %
  for all $f \in \mathcal{S}(\RR^d)$. Then $T$ is a Fourier multiplier operator.
\end{theorem}
\begin{proof}
  For any $f \in \mathcal{S}(\RR^d)$, $Tf \in W^{q,n}(\RR^d)$ for any $n > 0$. To see this, we note that for any $h > 0$ and $k \in \{ 1, \dots, d \}$, and
  %
  \[ (\Delta_h f)(x) = \frac{f(x + he_k) - f(x)}{h}. \]
  %
  Then $\Delta_h(T f) = T(\Delta_h f)$ because $T$ is translation invariant. Since $f$ is a Schwartz function, $\Delta_h f$ converges to $D^k f$ in $L^p(\RR^d)$. Thus by continuity of $f$, $Tf$ has a strong derivative $T(D^k f)$ in $L^q(\RR^d)$. Induction shows $Tf$ has strong derivatives of all orders. The last lemma shows that $Tf \in C(\RR^d)$, and
  %
  \begin{align*}
    |Tf(0)| &\lesssim \sum_{|\alpha| \leq n+1} \| D^\alpha(Tf) \|_{L^q(\RR^d)}\\
    &= \sum_{|\alpha| \leq n+1} \| T(D^\alpha f) \|_{L^q(\RR^d)}\\
    &\lesssim \sum_{|\alpha| \leq n+1} \| D^\alpha f \|_{L^q(\RR^d)}.
  \end{align*}
  %
  The map $f \mapsto Tf(0)$ is thus continuous on $\mathcal{S}(\RR^d)$, and therefore defines a tempered distribution $\Lambda$. Translation invariance shows that $Tf = \Lambda * f$, and setting $m = \widehat{\Lambda}$ completes the proof.
\end{proof}

\begin{remark}
    It therefore follows that if $T: \mathcal{S}(\RR^d) \to L^q(\RR^d)$ is a linear operator commuting a translation satisfying a bound
    %
    \[ \| Tf \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)}, \]
    %
    then $Tf \in C^\infty(\RR^d)$ and is slowly increasing, as is all of it's derivatives.
\end{remark}

We now wish to know what conditions on $m$ guarantee bounds of the form
%
\[ \| m(D) f \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)}. \]
%
for all $f \in \mathcal{S}(\RR^d)$. Littlewood's principle tells us that the only interesting case occur with `the larger exponent on the left'.

\begin{theorem}
  Fix $1 \leq q < p \leq \infty$, and suppose $m \in \mathcal{S}(\RR^d)'$ with
  %
  \[ \| m(D) f \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
  for all $f \in \mathcal{S}(\RR^d)$. Then $m = 0$.
\end{theorem}
\begin{proof}
  Suppose $m \neq 0$. Then there is $f_0 \in \mathcal{S}(\RR^d)$ with $m(D) f \neq 0$. Thus $m(D) f_0$ lies in $C^\infty(\RR^d) \cap L^q(\RR^d)$. Fix a large integer $N$ and pick $x_1,\dots,x_N \in \RR^d$ separated far enough apart that
  %
  \[ \| \sum_{n = 1}^N \text{Trans}_{x_n} f_0 \|_{L^p(\RR^d)} \gtrsim N^{1/p} \| f_0 \|_{L^p(\RR^d)} \]
  %
  and
  %
  \[ \| \sum_{n = 1}^N \text{Trans}_{x_n} m(D) f_0 \|_{L^q(\RR^d)} \sim N^{1/q} \| m(D) f_0 \|_{L^q(\RR^d)} \lesssim N^{1/q} \| f_0 \|_{L^p(\RR^d)}. \]
  %
  Translation invariance of convolution shows $N^{1/q} \lesssim N^{1/p}$, which is impossible for suitably large $N$. Thus $m = 0$.
\end{proof}

In general, a characterization of the tempered distributions which give bounded convolution operators is unknown except in a few very particular situations. For each $1 \leq p \leq q \leq \infty$, we let $\| m \|_{M^{p,q}(\RR^d)}$ denote the operator norm of the multiplier operator $m(D)$ from $L^p(\RR^d)$ to $L^q(\RR^d)$, i.e. the smallest quantity such that
%
\[ \| m(D) f \|_{L^q(\RR^d)} \leq \| m \|_{M^{p,q}(\RR^d)} \| f \|_{L^p(\RR^d)} \]
%
for all $f \in \mathcal{S}(\RR^d)$. We let $M^{p,q}(\RR^d)$ be the set of tempered distributions for which the bound is finite. For simplicity, we also let $M^p(\RR^d)$ denote $M^{p,p}(\RR^d)$. By symmetries of the Fourier transform, it is easy to check that translations, modulations, and dilations all preserve the $M^{p,q}$. Thus we have a complete set of affine symmetries, as well as a modulation symmetry.

\begin{example}
  A Fourier multiplier operator $T$ corresponding to a tempered distribution $m$ has a bound
  %
  \[ \| m(D)f \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)} \]
  %
  if and only if $m \in L^\infty(\RR^d)$, and then $\| m \|_{M^{2,2}(\RR^d)} = \| m \|_{L^\infty(\RR^d)}$. To see this, let
  %
  \[ \Phi(x) = e^{- \pi |x|^2} \]
  %
  be the Gaussian distribution. Then
  %
  \[ \widehat{m(D) \Phi} = \Phi \cdot m. \]
  %
  Since $\Phi \in L^2(\RR^d)$, $m(D) \Phi \in L^2(\RR^d)$, and so $\Phi \cdot m \in L^2(\RR^d)$. But then we conclude that
  %
  \[ m = \frac{\widehat{m(D) \Phi}}{\Phi}. \]
  %
  Thus $m \in L^1_{\text{loc}}(\RR^d)$. But then the result is obvious.
\end{example}

For any tempered distribution $m$ and $f,g \in \mathcal{S}(\RR^d)$,
%
\begin{align*}
  \langle m(D) f, g \rangle &= \langle m \widehat{f}, \widehat{g} \rangle
  &= \langle \widehat{f}, m^* \widehat{g} \rangle
  &= \langle f, m^*(D) g \rangle.
\end{align*}
%
Thus we have an adjoint relation $m(D)^* = m^*(D)$, which gives a natural duality theory for Fourier multiplier operators.

\begin{theorem}
  For any $1 \leq p,q \leq \infty$ and any tempered distribution $m$,
  %
  \[ \| m \|_{M^{p,q}(\RR^d)} = \| m \|_{M^{q^*,p^*}(\RR^d)}. \]
\end{theorem}
\begin{proof}
  Using the adjoint relation, if
  %
  \[ \| m(D) f \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
  then
  %
  \[ \| m^*(D) f \|_{L^{p^*}(\RR^d)} \lesssim \| f \|_{L^{q^*}(\RR^d)} \]
  %
  But it is easy to calculate that if we set $[\text{Ref} u](x) = u(-x)$, then for any $x \in \RR^d$,
  %
  \[ [m^*(D) f](x) = [m(D)(\text{Ref}f^*)(-x)]^* \]
  %
  and so $\| m^*(D) f \|_{L^{p^*}(\RR^d)} = \| m(D) f \|_{L^{p^*}(\RR^d)}$.
\end{proof}

In particular, if $1 \leq p \leq \infty$ and $m \in M^p(\RR^d)$, then also $m \in M^{p^*,p^*}(\RR^d)$ and so Riesz-interpolation implies $m \in M^{2,2}(\RR^d)$. Thus if we are studying $L^p$ to $L^p$ boundedness for any $1 \leq p \leq \infty$, we may restrict our attention to bounded Fourier multipliers.

\begin{example}
  The only remaining space which is completely understood is the space $M^{1,1}(\RR^d) = M^{\infty,\infty}(\RR^d)$; in this case, a tempered distribution is included if and only if the distribution is the Fourier transform of a finite Borel measure, and moreover, if $\mu \in M(\RR^d)$ is a finite Borel measure, then $\| \widehat{\mu} \|_{M^{1,1}(\RR^d)} = \| \mu \|_{TV(\RR^d)}$. If $\{ \Phi_\delta : \delta > 0 \}$ is the Gauss kernel, set
  %
  \[ m_\delta(x) = e^{- \delta |x|^2} m(\xi) \]
  %
  Then by assumption of $L^1$ boundedness, and the fact that the Fourier transform of $e^{-\delta |x|^2}$ is a constant multiple of $\Phi_\delta$, we conclude that for all $\delta > 0$,
  %
  \[ \| \widecheck{m_\delta} \|_{L^1(\RR^d)} \lesssim 1. \]
  %
  Thus $\{ \widecheck{m_\delta} \}$ are uniformly bounded in $L^1(\RR^d)$, so by Banach Alaoglu theorem, combined with the fact that $L^1(\RR^d)$ embeds in $M(\RR^d)$, which is the dual of $C_0(\RR^d)$, we conclude there is a subsequence $\{ \delta_k \}$ converging to zero such that $\widecheck{m_{\delta_k}}$ converges weakly to some finite Borel measure $\mu$. But this implies that $m_{\delta_k}$ converges weakly to $\widehat{\mu}$, which implies $m = \widehat{\mu}$.
\end{example}

For $1 < p < 2$ and $2 < p < \infty$, characterizing $M^p(\RR^d)$ is a much more subtle task, if not impossible. For instance, it remains an open question to determine for which values of $p$ and $\delta$ for which the multiplier
%
\[ m^\delta(\xi) = \max((1 - |\xi|^2)^\delta,0) \]
%
lies in $M^p(\RR^d)$, a problem known as the \emph{Bochner-Riesz conjecture}.

The difficulty here is that $m^\delta$ is singular on the boundary of the unit sphere, which is a large, curved set. However, mathematicians have developed criteria which implies boundedness of various operators. The most fundamental occurs if the multiplier $m$ has no singularities. For instance, if $m \in \mathcal{S}(\RR^d)$, then $\widecheck{m} \in L^1(\RR^d)$, so $m \in M^{1,1}(\RR^d)$, and thus in $M^p(\RR^d)$ for all $1 \leq p \leq \infty$. Similarily, if $m$ is a bump function adapted to $L(\Omega)$ for a fixed boundary domain $\Omega$, then $\| m \|_{M^p(\RR^d)} \lesssim_{d,\Omega} 1$ for all $1 \leq p \leq \infty$.

If the multiplier $m$ is only singular on a smaller set, we can also do better. For instance, if the Hilbert transform satisfies the bounds
%
\[ \| Hf \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)} \]
%
for all $f \in \mathcal{S}(\RR^d)$ and $1 < p < \infty$. It therefore follows that for $1 < p < \infty$ and any (possibly unbounded interval) $I$,
%
\[ \| \mathbf{I}_{I} \|_{M^p(\RR^d)}, \| \mathbf{I}_{I} \|_{M^p(\RR^d)} \lesssim_p 1. \]
%
Now suppose $m \in L^\infty(\RR^d)$ has \emph{bounded variation}, which means the quantity
%
\[ V(m) = \sup_{\xi_1 < \dots < \xi_N} \sum_{i = 1}^{N-1} |m(\xi_{i+1}) - m(\xi_i)|. \]
%
is finite. Then $m$ has countably many discontinuities, and the variation prevents too much nonsmoothness.

\begin{theorem}
  Suppose $m \in L^\infty(\RR)$ has finite variation. Then for each $1 < p < \infty$,
  %
  \[ \| m \|_{M^p(\RR)} \lesssim_p \| m \|_{L^\infty(\RR)} + V(m) \]
\end{theorem}
\begin{proof}
  For each $n$, pick $\xi_1,\dots,\xi_{N_n}$ such that
  %
  \[ \sum_{i = 1}^{N-1} |m(\xi_{i+1}) - m(\xi_i)| \geq V(m) - 1/n. \]
  %
  If we define
  %
  \[ m_n = m(\xi_1) \mathbf{I}_{(-\infty,\xi_1)} + \sum_{i = 1}^{N-1} m(\xi_i) \mathbf{I}_{(\xi_i,\xi_{i+1})} + m(\xi_N) \mathbf{I}_{(\xi_N,\infty)} \]
  %
  then $m - m_n$ is a finite signed Borel measure with $\| m - m_n \|_{M(\RR)} \leq 1/n$. Thus
  %
  \[ \| m \|_{M^p(\RR)} \leq \limsup_{n \to \infty} \| m_n \|_{M^p(\RR)}. \]
  %
  Now we can rewrite
  %
  \[ m_n(\xi) = m(\xi_1) \mathbf{I}_{(-\infty,\xi_1)} + \sum_{i = 1}^{N-1} [m(\xi_i) - m(\xi_{i+1})] \mathbf{I}_{(\xi_1,\xi_i)}(\xi) + m(\xi_N) \mathbf{I}_{(\xi_N,\infty)}. \]
  %
  Thus we find that for $1 < p < \infty$,
  %
  \[ \| m_n \|_{M^p(\RR)} \lesssim_p |m(\xi_1)| + \sum_{i = 1}^{N-1} |m(\xi_i) - m(\xi_{i+1})| + |m(\xi_N)| \leq \| m \|_{L^\infty(\RR)} + V(m). \]
  %
  But this means that $\| m \|_{M^p(\RR)} \lesssim_p \| m \|_{L^\infty(\RR)} + V(m)$.
\end{proof}

The theory of Fourier multipliers gets more complicated as we increase the dimension of the ambient space we are working in. De Leeuw's theorem shows slices of continuous $d+1$ dimensional multipliers are bounded by the original mutiplier.

\begin{theorem}
  Let $m \in C(\RR^{d+1})$. For each $\xi_0 \in \RR$ define $m_0 \in C(\RR^d)$ by setting
  %
  \[ m_0(\xi) = m(\xi,\xi_0). \]
  %
  Then for any $1 \leq p \leq \infty$, $\| m_0 \|_{M^p(\RR^d)} \leq \| m \|_{M^p(\RR^{d+1})}$.
\end{theorem}
\begin{proof}
  Without loss of generality, assume $\xi_0 = 0$. For $\lambda > 0$ set
  %
  \[ L(\xi_1,\dots,\xi_d) = (\xi_1,\dots,\xi_{d-1},\xi_d/\lambda). \]
  %
  Then
  %
  \[ \| m \circ L_\lambda \|_{M^p(\RR^d)} = \| m \|_{M^p(\RR^d)}. \]
  %
  Take $\lambda \to \infty$. Since $m$ is continuous, $m \circ L_\lambda$ converges to $m \circ L_\infty$ pointwise as $\lambda \to \infty$, where $L_\infty(\xi_1,\dots,\xi_d) = (\xi_1,\dots,\xi_{d-1},0)$. On the other hand,
  %
  \[ \| m \circ L_\infty \|_{M^p(\RR^d)} = \| m_0 \|_{M^p(\RR^d)}. \]
  %
  Thus it suffices to show that
  %
  \[ \| m \circ L_\infty \|_{M^p(\RR^d)} \leq \limsup_{\lambda \to \infty} \| m \circ L_\lambda \|_{M^p(\RR^d)}. \]
  %
  But to do this it suffices to use a weak convergence argument; for any $f,g \in \mathcal{S}(\RR^{d+1})$, we just note that dominated convergence shows that
  %
  \[ \lim_{\lambda \to \infty} |\langle (m \circ L_\lambda)(D) f, g \rangle| = \langle (m \circ L_\infty)(D) f, g \rangle. \qedhere \]
\end{proof}

The theorem of H\"{o}rmander-Mikhlin gives another instance of this phenomenon, giving $L^p$ bounds to Fourier multipliers which decay smoothly and rapidly away from the origin.

\begin{theorem}
  Let $m \in L^\infty(\RR^d)$ and suppose there exists an integer $n > d/2$ such that for any $\beta \in C_c^\infty(\RR^d - \{ 0 \})$ and any multi-index $\alpha$ with $|\alpha| \leq n$,
  %
  \[ \| D^\alpha( (\text{Dil}_{1/\lambda} \beta) \cdot m ) \|_{L^2(\RR^d)} \lesssim_\beta \lambda^{d/2-|\alpha|} \]
  %
  Then for any $1 < p < \infty$ and $f \in \mathcal{S}(\RR^d)$,
  %
  \[ \| m(D) f \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)}. \]
\end{theorem}

\begin{remark}
  The assumptions of the theorem hold for $m \in C^\infty(\RR^d - \{ 0 \})$ any multi-index $\alpha$ and any $\xi \neq 0$, $|D^\alpha m(\xi)| \lesssim_\alpha |\xi|^{-\alpha}$. It then follows that
  %
  \[ D^\alpha((\text{Dil}_{1/\lambda} \beta) \cdot m) = \sum_{\gamma \leq \alpha} \lambda^{-|\gamma|} \cdot (\text{Dil}_{1/\lambda} (D^\gamma \beta)) \cdot D^{\alpha - \gamma} m \]
  %
  Now rescaling shows
  %
  \begin{align*}
    \| \lambda^{-|\gamma|} (\text{Dil}_{1/\lambda} (D^\gamma \beta)) \cdot (D^{\alpha - \gamma} m) \|_{L^2(\RR^d)} \lesssim_{\beta,n} \lambda^{d/2-|\alpha|},
  \end{align*}
  %
  and summing up implies $m(D)$ is a H\"{o}rmander-Mikhlin operator. In particular, this is true if $m \in C^\infty(\RR^d - \{ 0 \})$ is homogenous of degree zero.
\end{remark}

\begin{proof}
  s
\end{proof}







\chapter{Psuedodifferential Operators}

Our goal is to consider more general families of operators that are amenable to analysis, but enable us to simultaneously control spatial and frequency properties of functions. The theory of Fourier multipliers can be used to understand constant coefficient differential operators. The most basic spatial multiplier in Fourier analysis are the \emph{position operators} $X^\alpha: \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$ given by
%
\[ X^\alpha f(x) = x^\alpha f(x) \]
%
and the most basic Fourier multipliers are the \emph{momentum operators}
%
\[ D^\alpha f(x) = \frac{1}{(2\pi i)^{|\alpha|}} \partial^\alpha f(x), \]
%
which have the property that $\widehat{D^\alpha f}(\xi) = \xi^\alpha \widehat{f}(\xi)$. If $m \in C^\infty(\RR^d)$ is given, such that $m$ and all it's derivatives are slowly increasing, then we can define an operator $m(X): \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$ by setting
%
\[ [m(X) f](x) = m(x) f(x). \]
%
We refer to $m$ as the \emph{symbol} of the operator. Similarily, we can define an operator $m(D): \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$ such that
%
\[ \widehat{m(D) f}(\xi) = m(\xi) \widehat{f}(\xi). \]
%
These give two homomorphisms from the ring of functions $m$ to the ring of operators.

Our goal here is to associate with a suitably smooth family of functions $a(x,\xi)$, an operator $a(X,D)$ which extends the theory of spatial and Fourier multipliers. This is useful in a variety of contexts, especially in the theory of variable-coefficient linear operators
%
\[ Lf(x) = \sum_{|\alpha| \leq n} c_\alpha(x) D^\alpha f(x) \]
%
which can be viewed as the operator associated with the function
%
\[ a(x,\xi) = \sum_{|\alpha| \leq n} c_\alpha(x) \xi^k. \]
%
Applying the Fourier inversion formula, we conclude that for any $f \in \mathcal{S}(\RR^d)$,
%
\begin{align*}
  Lf(x) &= \sum_{|\alpha| \leq n} c_\alpha(x) D^\alpha f(x)\\
  &= \sum_{|\alpha| \leq n} c_\alpha(x) \int_{\RR^d} \xi^\alpha \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi\\
  &= \int_{\RR^d} a(x,\xi) \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi.
\end{align*}
%
Now for any smooth function $a(x,\xi)$ such that for any $n,m \geq 0$,
%
\[ |\nabla_x^n \nabla_\xi^m a| \lesssim_{a,n,m} \langle x \rangle^{O_{a,n}(1)} \langle \xi \rangle^{O_{a,n,m}(1)} \]
%
we can thus define an operator $a(X,D): \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$ such that
%
\[ [a(X,D) f](x) = \int_{\RR^d} a(x,\xi) \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi. \]
%
This is known \emph{Kohn-Nirenberg quantization} of the function $a(x,\xi)$. Intuitively, if we think of $f(x,\xi)$ as being represented in `time and frequency space', then intuitively, we have $[a(X,D) f](x,\xi) = a(x,\xi) f(x,\xi)$. But the uncertainty principle prevents us from making this definition precisely, because we cannot localize too precisely in phase and frequency space. However, we hope that this intuition holds at least approximately. In particular, this should imply that $(a_1a_2)(X,D) \approx a_1(X,D) a_2(X,D)$.

\section{Order Theory}

Recall the Sobolev spaces $H^s(\RR^d)$ consisting of functions $f \in L^2(\RR^d)$ such that the quantity
%
\[ \| f \|_{H^s(\RR^d)} = \left( \int_{\RR^d} (1 + |\xi|^2)^s |\widehat{f}(\xi)|^2\; d\xi \right)^{1/2}. \]
%
is finite. Such spaces can be defined for all $s \in \RR$. We say an operator $T: \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$ has \emph{order} $t$ if for each $s \in \RR$,
%
\[ \| Tf \|_{H^s(\RR^d)} \lesssim_s \| f \|_{H^{s+t}(\RR^d)}. \]
%
The \emph{true order} of $T$ is the infinum of the orders for $T$. Recall that if $|m(\xi)| \lesssim (1 + |\xi|^2)^\sigma$, then the Fourier multiplier $m(D)$ has order $2\sigma$. In particular, if $m$ is compactly supported, $m(D)$ has true order equal to $-\infty$.

To begin studying the orders of psuedodifferential operators, let us begin by assuming strong conditions on the function $a$. In particular, we assume $a(x,\xi)$ is homogenous of degree zero in $\xi$, and that moreover, there exists a smooth, homogenous function $b(\xi)$ such that for any integers $n_1,n_2$, and $n_3$,
%
\[ \nabla^{n_1}_x \nabla^{n_2}_\xi[a(x,\xi) - b(\xi)] \lesssim_{n_1,n_2,n_3} \frac{1}{1 + |x|^{n_3}} \]
%
We define $a_0(x,\xi) = a(x,\xi) - b(\xi)$.

\begin{theorem}
  The function $a(X,D)$ has order zero.
\end{theorem}
\begin{proof}
  Since $b \in L^\infty(\RR^d)$ due to it's homogeneity, we conclude that $b(D)$ has order zero, i.e.
  %
  \[ \| b(D) f \|_{H^s(\RR^d)} = \| b \widehat{f} (1 + |\xi|^2)^{s/2} \|_{L^2(\RR^d)} \lesssim \| \widehat{f} (1 + |\xi|^2)^{s/2} \|_{L^2(\RR^d)}. \]
  %
  It suffices to show $a_0^*(X,D)$ has order zero since $a_0^*$ satisfies the same hypothesis as $a_0$. We calculate that the adjoint of $a_0^*(X,D)$ is the operator $a_0^*(X,D)^*$ such that for $g \in \mathcal{S}(\RR^d)$,
  %
  \begin{align*}
    \widehat{a_0^*(X,D)^* g}(\xi) &= \int_{\RR^d} a(x,\xi) g(x) e^{-2 \pi i \xi \cdot x}\; dx.
  \end{align*}
  %
  By duality (noting $H^s(\RR^d)^* = H^{-s}(\RR^d)$), it therefore suffices to show $a_0^*(X,D)^*$ has order zero, which is easier because the manipulations here are in the Fourier domain. For each $\xi$, let $a_{0,\xi}(x) = a_0(x,\xi)$. Then
  %
  \[ \widehat{a_0^*(X,D)^* g}(\xi) = \widehat{a_{0,\xi} g}(\xi) = \int_{\RR^d} \widehat{a_{0,\xi}}(\xi - \eta) \widehat{g}(\eta)\; d\eta. \]
  %
  Thus
  %
  \begin{align*}
    \| a_0^*(X,D)^* g \|_{H^s(\RR^d)} &= \left\| \int_{\RR^d} \left[ \frac{(1 + |\xi|)^{s/2}}{(1 + |\eta|^2)^{s/2}} \widehat{a_{0,\xi}}(\xi - \eta) \right] \left[(1 + |\eta|^2)^{s/2}) \widehat{g}(\eta)\right]\; d\eta \right\|_{L^2_\xi(\RR^d)}.
  \end{align*}
  %
  By Schur's test, it suffices to show that
  %
  \[ \left\| \int_{\RR^d} \left[ \frac{(1 + |\xi|)^{s/2}}{(1 + |\eta|^2)^{s/2}} \widehat{a_{0,\xi}}(\xi - \eta) \right] \right\|_{L^1_\xi L^\infty_\eta}, \left\| \int_{\RR^d} \left[ \frac{(1 + |\xi|)^{s/2}}{(1 + |\eta|^2)^{s/2}} \widehat{a_{0,\xi}}(\xi - \eta) \right] \right\|_{L^1_\eta L^\infty_\xi} < \infty, \]
  %
  for then we find the upper quantity is bounded up to a constant by $\| g \|_{H^s(\RR^d)}$. TODO LATER.
\end{proof}

\begin{remark}
  Instead of the Kohn-Niremberg quantization $a(X,D) = a_{KN}(X,D)$, one can associate the \emph{adjoint Kohn-Niremberg quantization} $a(X,D) = a_{KN^*}(X,D)$ such that for $g \in \mathcal{S}(\RR^d)$,
  %
  \[ \widehat{a_{KN^*}(X,D) g}(\xi) = \int_{\RR^d} a(x,\xi) g(x) e^{-2 \pi i \xi \cdot x}\; dx. \]
  %
  Thus $a_{KN^*}(X,D) = a^*_{KN}(X,D)^*$. For the purposes of order theory, these operators are essentially equivalent. Indeed, in our situation the operator $a_{KN}(X,D) - a_{KN^*}(X,D)$ is an operator of order $-1$. We calculate that
  %
  \[ \widehat{(a_{KN}(X,D) - a_{KN^*}(X,D))(f)}(\xi) = \int_{\RR^d} [\widehat{a_\xi}(\xi - \eta) - \widehat{a_\eta}(\xi - \eta)] \widehat{f}(\eta)\; d\eta. \]
  %
  TODO (we do some singular integral type manipulations).
\end{remark}

\section{An Algebra of Operators}

s











\chapter{Sobolev Spaces}

Let $\Omega$ be an open subset of $\RR^d$. A natural problem when studying smooth functions $\phi \in C_c^\infty(\Omega)$ is to obtain estimates on the partial derivatives of $\phi$. For instance, one can consider the norms
%
\[ \| \phi \|_{C^n(\Omega)} = \max_{|\alpha| \leq n} \| D^\alpha f \|_{L^\infty(\Omega)}. \]
%
The space $C_c^\infty(\Omega)$ is not complete with respect to this norm, but it's completion is the space $C^n_b(\Omega)$ of $n$ times bounded continuously differentiable functions on $\Omega$, which still consists of regular functions. Unfortunately, such estimates are only encountered in the most trivial situations. As in the non-smooth case, one can often get much better estimates using the $L^p$ norms of the derivatives, i.e. considering the norms
%
\[ \| \phi \|_{W^{n,p}(\Omega)} = \left( \sum_{|\alpha| \leq p} \| D^\alpha \phi \|_{L^p(\Omega)}^p \right)^{1/p}. \]
%
As might be expected, $C_c^\infty(\Omega)$ is not complete with respect to the $W^{n,p}(\Omega)$ norm. However, it's completion cannot be identified with a family of $n$ times differentiable functions. Instead, to obtain a satisfactory picture of the compoetion under this norm, a Banach space we will denote by $W^{n,p}(\Omega)$, we must take a distribution approach.

For each multi-index $\alpha$, if $f$ and $f_\alpha$ are locally integrable functions on $\Omega$, we say $f_\alpha$ is a weak derivative for $f$ if for any $\phi \in C_c^\infty(\Omega)$,
%
\[ \int_\Omega f_\alpha(x) \phi(x)\; dx = (-1)^{|\alpha|} \int_\Omega f(x) \phi_\alpha(x)\; dx. \]
%
In other words, this is the same as the derivative of $f$ viewed as a distribution on $\Omega$. We define $W^{n,p}$ to be the space of all functions $f \in L^p(\Omega)$ such that for each $|\alpha| \leq n$, a weak derivative $f_\alpha$ exists and is an element of $L^p(\Omega)$. We then define
%
\[ \| f \|_{W^{n,p}(\Omega)} = \left( \sum_{|\alpha| \leq n} \| f_\alpha \|_{L^p(\Omega)} \right)^{1/p}. \]
%
Where this sum is treated as a maximum in the case $p = \infty$. Later on we will be able to show this space is a complete Banach space.

\begin{example}
  Let $B$ be the open unit ball in $\RR^d$, and let $u(x) = |x|^{-s}$, where $s < n-1$. For which $p$ is $u \in W^{1,p}(B)$? We calculate by an integration by parts that if $\phi \in C_c^\infty(B)$, we fix $\varepsilon > 0$ and write
  %
  \[ \int_B \phi_i(x) u(x)\; dx = \int_{|x| \leq \varepsilon} \phi_i(x) u(x) + \int_{\varepsilon < |x| \leq 1} \phi_i(x) u(x). \]
  %
  The integral on the $\varepsilon$ ball is neglible since $s < n$. Since $u$ is smooth away from the origin, it's distributional derivative agrees with it's standard derivative, which is
  %
  \[ u_i(x) = \frac{- \alpha x_i}{|x|^{s + 2}}. \]
  %
  Thus $|u_i| \lesssim 1/|x|^{s + 1}$. An integration by parts gives
  % in the $i$'th direction, and we calculate $\nabla u(x) = -\alpha x |x|^{-\alpha-2}$. Thus an integration by parts gives
  %
  \[ \int_{\varepsilon < |x| \leq 1} \phi_i(x) u(x) = \int_{|x| = \varepsilon} \phi(x) u(x) \nu_i\ dS + \int_{\varepsilon < |x| \leq 1} \frac{s \phi(x) x_i}{|x|^{s + 2}}\; dx, \]
  %
  where $\nu_i$ is the normal vector to the sphere pointing inward. Since $s < n-1$, the surface integral tends to zero as $\varepsilon \to 0$. Thus the weak derivative of $u$ is equal to the standard derivative. Consequently, $u \in W^{1,p}(B)$ if $s < n/p - 1$.
\end{example}

\begin{example}
  If $\{ r_k \}$ is a countable, dense subset of $B$, then we can define
  %
  \[ u(x) = \sum_{k = 1}^\infty \frac{|x - r_k|^{-s}}{2^k} \]
  %
  Then $u \in W^{1,p}(B)$ if $0 < \alpha < n/p - 1$, yet $u$ has a dense family of singularities, and thus does not behave like any differentiable function we would think of.
\end{example}

\begin{theorem}
  For each $k \in \mathbf{N}$ and $1 \leq p \leq \infty$, $W^{k,p}(\Omega)$ is a Banach space.
\end{theorem}
\begin{proof}
  It is easy to verify that $\| \cdot \|_{W^{k,p}}$ is a norm on $W^{k,p}(\Omega)$. Let $\{ u_n \}$ be a Cauchy sequence in $W^{k,p}(\Omega)$. In particular, this means that $\{ D^\alpha u_n \}$ is a Cauchy sequence in $L^p(\Omega)$ for each multi-index $\alpha$ with $|\alpha| \leq k$. In particular, these are functions $v_\alpha$ such that $D^\alpha u_n$ converges to $v_\alpha$ in the $L^p$ norm for each $\alpha$. Thus it suffices to prove that if $v = \lim u_n$, then $D^\alpha v = v_\alpha$ for each $\alpha$. But this follows because the H\"{o}lder inequality implies that for each fixed $\phi \in C_c^\infty(\Omega)$,
  %
  \begin{align*}
    (-1)^{|\alpha|} \int \phi_\alpha(x) v(x)\; dx &= \lim_{n \to \infty} (-1)^{|\alpha|} \phi_\alpha u_n(x)\; dx\\
    &= \lim_{n \to \infty} \int \phi(x) (D^\alpha u_n)(x)\; dx\\
    &= \int \phi(x) v_\alpha(x)\; dx.
  \end{align*}
  %
  Thus $W^{k,p}(\Omega)$ is complete.
\end{proof}

\section{Smoothing}

It is often useful to be able to approximate elements of $W^{k,p}(\Omega)$ by elements of $C^\infty(\Omega)$. This is mostly possible. If $u \in W^{k,p}(\Omega)$, and $\{ \eta_\varepsilon \}$ is a family of smooth mollifiers, then, viewing $u$ as a function on $\RR^n$ supported on $\Omega$, we can consider the convolution $u^\varepsilon = u * \eta_\varepsilon$, i.e. the function defined by setting
%
\[ u^\varepsilon(x) = \int_\Omega u(x - y) \eta_\varepsilon(y)\; dy. \]
%
This is just normal convolution, where we identify the function $u$ with the function $u \mathbf{I}_\Omega$ on $\RR^d$. Then $u^\varepsilon$ is a smooth function on $\RR^d$ supported on a $\varepsilon$ thickening of $\Omega$. However, $u^\varepsilon$ does not necessarily converge to $u$ in $W^{k,p}(\Omega)$ as $\varepsilon \to 0$, since the behaviour of the convolution can cause issues at the boundary of $\Omega$, where the distributional derivative $D^\alpha(u \mathbf{I}_\Omega)$ does not behave like a locally integrable function. This is the only problem, however.

\begin{theorem}
  If $U \Subset \Omega$, then $\lim_{\varepsilon \to 0} \| u^\varepsilon - u \|_{L^p(U)} = 0$.
\end{theorem}
\begin{proof}
  For each $\varepsilon > 0$, let $U^\varepsilon = \{ x \in \Omega: d(x,\partial \Omega) > \varepsilon \}$. If $x \in \Omega^\varepsilon$, then
  %
  \[ ((D^\alpha u) * \eta_\varepsilon)(x) = (u_\alpha \mathbf{I}_\Omega * \eta_\varepsilon)(x), \]
  %
  since the convolution only depends on the behaviour of $D^\alpha u$ on a $\varepsilon$ ball around $x$, which is contained in the interior of $\Omega$. We can apply standard results about mollifiers to conclude that $u_\alpha \mathbf{I}_\Omega * \eta_\varepsilon$ converges to $u_\alpha \mathbf{I}_\Omega$ in $L^p(\RR^d)$ as $\varepsilon \to 0$. Since $U \Subset \Omega$, we have $U \subset U^\varepsilon$ for small enough $\varepsilon$, and so $(D^\alpha u) * \eta_\varepsilon$ converges to $u_\alpha$ in $L^p(U)$ as $\varepsilon \to 0$. Since this is true for each $\alpha$ with $|\alpha| \leq k$, we obtain the result.
\end{proof}

If we are a little more careful, then we can fully approximate elements of $W^{k,p}(\Omega)$ by smooth functions on $U$.

\begin{theorem}
  $C^\infty_c(\Omega) \cap W^{k,p}(\Omega)$ is dense in $W^{k,p}(\Omega)$.
\end{theorem}
\begin{proof}
  Consider a family of open sets $\{ V_n \}$ such that $V_n \Subset \Omega$ for each $n$, and $U = \bigcup V_n$. Then we can consider a smooth partition of unity $\{ \xi_n \}$ subordinate to the cover $\{ V_n \}$. For each $u \in W^{k,p}(\Omega)$, we can write $u = \sum_n u \xi_n$. In particular, this means that for each $\varepsilon > 0$, there is $N$ such that $\| \sum_{n = N+1}^\infty u \xi_n \|_{W^{k,p}(\Omega)} \leq \varepsilon$. For each $n \in \{ 1, \dots, N \}$, we can find $\delta_n$ small enough that the $\delta_n$ thickening of $V_n$ is compactly contained in $\Omega$. If $\varepsilon_n$ is small enough, we find $(u \xi_n)^{\varepsilon_n}$ is supported on the $\delta_n$ thickening of $V_n$, and $\| (u \xi_n)^{\varepsilon_n} - u \xi_n \|_{W^{k,p}(V_n)} \leq \varepsilon / N$. But we then find
  %
  \begin{align*}
    \| u - \sum_{n = 1}^N (u \xi_n)^{\varepsilon_n} \|_{W^{k,p}(\Omega)} \leq \varepsilon + \sum_{n = 1}^N \| u \xi_n - (u \xi_n)^{\varepsilon_n} \|_{W^{k,p}(\Omega)} \leq 2\varepsilon.
  \end{align*}
  %
  Thus $C_c^\infty(\Omega)$ is dense in $W^{k,p}(\Omega)$.
\end{proof}

Approximation by elements of $C^\infty(\overline{\Omega})$ requires some more care, and additional assumptions on the behaviour of $\partial \Omega$.











\chapter{Basics of Kernel Operators}

We now consider a general family of operators, which can be seen as the infinite dimensional analogue of matrix multiplication. We fix two measure spaces $X$ and $Y$, and consider a function $K: X \times Y \to \CC$, which we call a \emph{kernel}. From this kernel, we obtain an induced operator $T_K$ taking functions on $X$ to functions on $Y$, given, heuristically at least, by the integral formula
%
\[ (T_K f)(y) = \int_X K(x,y) f(x)\; dx. \]
%
Our goal is to relate control on the kernel $K$ to the boundedness of the operator $T_K$ with respect to various norms.

\begin{example}
  Let $X = Y = \RR^d$, equipped with the Lebesgue measure. If we set $K(x,\xi) = e^{2 \pi i \xi \cdot x}$, then using this function as a kernel we can obtain an integral operator
  %
  \[ (T_K f)(\xi) = \int f(x) e^{2 \pi i \xi \cdot x}\; dx. \]
  %
  In the standard theory of Fourier analysis, we find that if $f \in L^1(\RR)$, then for any $\xi$ the integral
  %
  \[ \int f(x) e^{2 \pi i \xi \cdot x} \]
  %
  converges absolutely, and is thus well-defined in the sense of a Lebesgue integral. Moreover, for any $f \in L^1(\RR)$,
  %
  \[ \| T_K f \|_{L^\infty(\RR)} \leq \| f \|_{L^1(\RR)}. \]
  %
  We also know from the classical Hausdorff-Young inequality that if $1 \leq p \leq 2$, then for any $f \in L^1(\RR) \cap L^p(\RR)$,
  %
  \[ \| T_K f \|_{L^{p^*}(\RR)} \leq \| f \|_{L^p(\RR)}. \]
  %
  In particular, this means that there exists a unique extension of $T_K$ to a bounded operator from $L^p(\RR)$ to $L^{p^*}(\RR)$; note, however, that for a general element $f \in L^p(\RR)$, the integral formula
  %
  \[ \int f(x) e^{2 \pi i \xi \cdot x}\; dx \]
  %
  is \emph{not well-defined} in the Lebesgue sense. Thus we can only heuristically view the integral formula as defining the integral operator.
\end{example}

\begin{example}
  Let $X = \{ 1, \dots, N \}$ and $Y = \{ 1, \dots, M \}$, each equipped with the counting measure. Then each kernel $K$ corresponds to an $M \times N$ matrix $A$, with $A_{ij} = K(j,i)$. For any $f: X \to Y$ we can define a vector $v \in \RR^N$ by setting $v_i = f(i)$, and then
  %
  \[ (T_K f)(m) = \sum_{n = 1}^N f(n) K(n,m) = \sum_{n = 1}^N A_{mn} v_n = (Av)_m. \]
  %
  Thus with respect to the standard basis, $T_K$ is just given by matrix multiplication by $A$.
\end{example}

It turns out that if we map \emph{from} $L^1(X)$, or \emph{into} $L^\infty(Y)$, then the conditions on $K$ determining boundedness are trivial to determine for \emph{most} norms. This is one motivation for introduction the intermediate $L^p$ norms, since these norms enable us to extract more features out of the kernel operator $K$.

Without even qualitative knowledge of the kernel $K$ besides it's measurability, it is difficult to know for which functions $f$ the operator $T_K f$ is well-defined, even if $f$ is simple. A natural trick here is to introduce the sublinear analogue of the kernel operator, i.e. the operator $S_K$ defined by setting
%
\[ (S_K f)(y) = \int_X |K(x,y)| |f(x)|; dx \]
%
The flexibility of the theory of non-negative integrals means this operator is well defined for \emph{any} measurable $f$ (though it may take on infinite values). Moreover, if we are to interpret $(T_K f)(y)$ in the Lebesgue sense, then it is necessary and sufficient that $(S_K f)(y) < \infty$.

\begin{theorem}
  Fix $q \geq 1$, and suppose $X$ and $Y$ are $\sigma$ finite. Then the smallest coefficient $C > 0$ such that for any $f \in L^1(X)$,
  %
  \[ \| S_K f \|_{L^q(Y)} \leq C \| f \|_{L^1(X)} \]
  %
  is equal to $\| K \|_{L^q(Y) L^\infty(X)}$. In particular, if $\| K \|_{L^q(Y) L^\infty(X)} < \infty$, then for each $f \in L^1(X)$, $(T_K f)(y)$ is well-defined in the Lebesgue sense for almost every $y \in Y$, and the operator norm of $T_K$ from $L^1(X)$ to $L^q(Y)$ is equal to $\| K \|_{L^q(Y) L^\infty(X)}$.
\end{theorem}
\begin{proof}
  We calculate by Minkowski's inequality that
  %
  \begin{align*}
    \| S_K f \|_{L^q(Y)} &= \| K f \|_{L^1(X) L^q(Y)}\\
    &\leq \| Kf \|_{L^q(Y) L^1(X)}\\
    &= \int \left( \int |K(x,y)|^q\; dy \right)^{1/q} |f(x)|\; dx\\
    &\leq \| K \|_{L^q(Y)L^\infty(X)} \| f \|_{L^1(X)}.
  \end{align*}
  %
  If $\| K \|_{L^q(Y) L^\infty(X)} < \infty$, then $(S_K f)(y) < \infty$ for almost every $y \in Y$, which implies $(T_K f)(y)$ is well-defined for almost every $y \in Y$. Since $(T_K f)(y) \leq (S_K f)(y)$ for such $y$, we conclude that
  %
  \[ \| T_K f \|_{L^q(Y)} \leq \| K \|_{L^q(Y) L^\infty(X)} \| f \|_{L^1(X)}. \]
  %
  Let us now show this constant is tight. By an approximation argument I leave to the end of the discussion, we may assume that we can write
  %
  \[ K = \sum_{i = 1}^N \sum_{j = 1}^M a_{ij} \mathbf{I}_{E_i \times F_j} \]
  %
  where $E_1,\dots,E_N$ and $F_1,\dots,F_N$ are disjoint finite measure sets. Then there exists $i \in \{ 1, \dots, N \}$ such that for each $x \in E_i$,
  %
  \[ \left( \int |K(x,y)|^q\; dy \right)^{1/q} = \left( \sum_{j = 1}^M |a_{ij}|^q |F_j| \right)^{1/q} = \| K \|_{L^q(Y) L^\infty(X)}. \]
  %
  If $f = \mathbf{I}_{E_i}$, then $\| f \|_{L^1(X)} = |E_i|$, and $T_K f = \sum_{j = 1}^M a_{ij} \mathbf{I}_{F_j}$, so
  %
  \[ \| T_K f \|_{L^q(Y)} = \left( \sum_{j = 1}^M |a_{ij}|^q |F_j| \right)^{1/q} = \| K \|_{L^q(Y)L^\infty(X)} \| f \|_{L^1(X)}. \]
  %
  Thus we conclude that for a certain `dense' family of $K$, $T_K$ is tight. Let us now complete the argument to prove the result in general.


  By a simple approximation argument in $\| \cdot \|_{L^q(Y) L^\infty(X)}$, using the fact that $X$ and $Y$ are $\sigma$ finite, we may assume that $K$ is supported on a product of finite measure subsets of $X$ and $Y$, so without loss of generality we can assume $X$ and $Y$ have finite measure.
\end{proof}

\begin{theorem}
  Fix $q \geq 1$. If $\| K \|_{L^q(Y) L^\infty(X)} < \infty$, then $S_K$ is bounded as an operator from $L^1(X)$ to $L^q(Y)$, with operator norm bounded above by $\| K \|_{L^q(Y) L^\infty(X)}$, with equality if $X$ and $Y$ are $\sigma$ finite. Correspondingly, for each $f \in L^1(X)$, we have
  %
  \[ \int K(x,y) f(x)\; dx < \infty\ \text{for almost every $y$}, \]
  %
  and $\| T_K f \|_{L^q(Y)} \leq \| K \|_{L^q(Y) L^\infty(X)} \| f \|_{L^1(X)}$.
\end{theorem}
\begin{proof}
  Applying Minkowski's inequality, we conclude that
  %
  \begin{align*}
    \| S_K f \|_{L^q(Y)} &= \left( \left( \int |f(x)| |K(x,y)|\; dx \right)^q \right)^{1/q}\\
    &\leq \int \left( \int |f(x)|^q |K(x,y)|^q\; dy \right)^{1/q}\; dx\\
    &\leq \int |f(x)| \| K \|_{L^q(Y)}(x)\; dx\\
    &\leq \| f \|_{L^1(X)} \| K \|_{L^q(Y) L^\infty(X)}.
  \end{align*}
  %
  To show tightness, consider the first case where $K$ can be written as
  %
  \[ \sum_{i = 1}^N \sum_{j = 1}^M a_{ij} \mathbf{I}_{E_i \times F_j}, \]
  %
  where $E_1, \dots, E_N$ are disjoint, finite measure sets in $X$, and $F_1, \dots, F_M$ are disjoint, finite measure sets in $Y$. Then there exists $i \in \{ 1, \dots, N \}$ such that for each $x \in E_i$,
  %
  \[ \left( \int |K(x,y)|^q\; dy \right)^{1/q} = \left( \sum_{j = 1}^M |a_{ij}|^q |F_j| \right)^{1/q} = \| K \|_{L^q(Y) L^\infty(X)}. \]
  %
  If $f = \mathbf{I}_{E_i}$, then $\| f \|_{L^1(X)} = |E_i|$, and
  %
  \begin{align*}
    \left( \left( \int |K(x,y) f(x)|\; dx \right)^q dy \right)^{1/q} &= \left( \sum_{j = 1}^M |F_j| |a_{ij}|^q |E_i|^q \right)^{1/q}\\
    &= \| f \|_{L^1(X)} \| K \|_{L^q(Y) L^\infty(X)}.
  \end{align*}
  %
  Thus $f$ is an extremizer for $S_K$.

  To show this inequality is tight. Let us first consider the case where $q < \infty$. By a monotone convergence result if $X$ and $Y$ are $\sigma$ finite, we may assume that $X$ and $Y$ have finite measure. It then follows that for each $\varepsilon > 0$, there are functions $u_1, \dots, u_n \in L^1(X)$ and $v_1, \dots, v_n \in L^1(Y)$ such that $\| K - u_1 \otimes v_1 - \dots - u_n \otimes v_n \|_{L^1(X \times Y)} < \varepsilon$.
\end{proof}

\begin{lemma}
  BLAH
\end{lemma}
\begin{proof}
  Let $\Pi$ be the family of all sets $E \times F \subset X \times Y$, where $E$ is a measurable subset of $X$, and $F$ is a measurable subset of $Y$. Then $\Pi$ is a $\pi$ system, in the sense that if $E_1 \times F_1, E_2 \times F_2 \in \Pi$, then $(E_1 \times F_1) \cap (E_2 \times F_2) = (E_1 \cap E_2) \times (F_1 \cap F_2) \in \Pi$. Now let
  %
  \[ \Delta = \left\{ G \subset X \times Y: \left( \begin{array}{c} \text{for all $\varepsilon > 0$, there are simple $u_1, \dots, u_n$} \\ \text{on $X$ and $v_1,\dots, v_n$ on $Y$ such that} \\ \| \mathbf{I}_G - \sum u_i \otimes v_i \|_{L^q(Y) L^\infty(X)} < \varepsilon \end{array} \right) \right\}. \]
  %
  Our goal is to show that $\Delta$ is a $\lambda$ system. It is easy to see that $\Delta$ contains $\Pi$, so by the $\pi$-$\lambda$ theorem it follows that $\Delta$ contains all measurable subsets of $X \times Y$. Thus it suffices to show $\Delta$ is closed under complements and countable unions of disjoint sets. The complement property follows easily since $\mathbf{I}_{G^c} = 1 - \mathbf{I}_G$ and $1 = \mathbf{I}_X \otimes \mathbf{I}_Y$ is a tensor product. Next, if $G_1, G_2, \dots$ are a disjoint family of sets in $\Delta$, then for each $\varepsilon > 0$, and for each $k$ we can find $u_{k1}, \dots, u_{kN_k}$ and $v_{k1}, \dots, v_{kN_k}$ such that
  %
  \[ \left\| \mathbf{I}_{G_k} - \sum_{i = 1}^{N_k} u_{ki} \otimes v_{ki} \right\|_{L^q(Y) L^\infty(X)} < \varepsilon / 2^k. \]
  %
  \[ \| \mathbf{I}_{G_k} \|_{L^q(Y) L^\infty(X)} = \sup_{x \in X} |G_k(x)|^{1/q} \]
  %
  By monotone convergence, if $G = \bigcup G_k$, then for each fixed $x$,
  %
  \[ \lim_{N \to \infty} \int \mathbf{I}_G(x,y) - \sum_{k = 1}^N \mathbf{I}_{G_k}(x,y)\; dx \]
\end{proof}










\chapter{Riemann Theory of Trigonometric Series}

Using the techniques of measure theory, we can actually prove that the Fourier series is essentially the unique way of representing a function on any part of its domain as a trigonometric series.

\begin{lemma}
  For any sequence $u_n$ and set $E$ of finite measure,
  %
  \[ \lim_{n \to \infty} \int_E \cos^2(nx + u_n)\; dx = |E|/2 \]
\end{lemma}
\begin{proof}
  We have
  %
  \[ \cos^2(nx + u_n) = \frac{1 + \cos(2nx + 2u_n)}{2} = \frac{1}{2} + \frac{\cos(2nx) \cos(2u_n) - \sin(2nx) \sin(2u_n)}{2} \]
  %
  Since $\cos(2u_n)$ and $\sin(2u_n)$ are bounded, we have $\int \chi_E(x) \cos(2nx)$ and $\int \chi_E(x) \sin(2nx) \to 0$ as $n \to \infty$, and the same is true for the latter component of the sum since $\cos(2u_n)$ and $\sin(2u_n)$ are bounded, we conclude that
  %
  \[ \int_E \cos^2(nx + u_n) = \int \chi_E(x) \cos^2(nx + u_n) = |E|/2 \]
  %
  completing the proof.
\end{proof}

\begin{theorem}[Cantor-Lebesgue Theorem]
  If, for some pair of sequences $a_0, a_1, \dots$ and $b_0, b_1, \dots$ are chosen such that
  %
  \[ \sum_{n = 0}^\infty a_n \cos(2 \pi nx) + b_n \sin(2 \pi nx) \]
  %
  converges on a set of positive measure in $[0,1]$, then $a_n, b_n \to 0$.
\end{theorem}
\begin{proof}
  Let $E$ be the set of points upon which the trigonometric series converges. We write $a_n \cos(2 \pi n x) + b_n \sin(2 \pi n x) = r_n \cos(nx + c_n)$. The result of the theorem is then precisely that $r_n \to 0$. If this is not true, then we must have $\cos(nx + c_n) \to 0$ for every $x \in E$. In particular, the dominated convergence theorem implies that
  %
  \[ \lim_{n \to \infty} \int_E \cos(nx + c_n)^2\; dx = 0 \]
  %
  Yet we know this tends to $|E|/2$ as $n \to \infty$, which is a contradiction.
\end{proof}

TODO: EXPAND ON THIS FACT.






\section{Convergence in $L^p$ and the Hilbert Transform}

We now move onto a more 20th century viewpoint on Fourier series, namely, those to do with operator theory. Under this viewpoint, the properties of convergence are captured under the boundedness of certain operators on function spaces, allowing us to use the modern theory of functional analysis to it's full extent on our problems. However, unlike in most of basic functional analysis, where we assume all operators we encounter are bounded to begin with, in harmonic analysis we more often than not are given an operator defined only on a subset of spaces, and must prove the continuity of such an operator to show it is well defined on all of space. We will illustrate this concept through the theory of the circular Hilbert transform, and its relation to the norm convergence of Fourier series.

A \emph{Fourier multiplier} is a linear transform $T$ associated with a given sequence of scalars $\lambda_n$, for $n \in \ZZ$. It is defined for any trigonometric polynomial $f = \sum_{|n| \leq N} c_n e_n$ as $Tf = \sum_{|n| \leq N} \lambda_n c_n e_n$. The trigonometric polynomials are dense in $L^p(\mathbf{T})$, for each $p < \infty$. An important problem is determining whether $T$ is therefore figuring out whether the operator can be extended to a {\it continuous operator} on the entirety of $L^p$. Because the trigonometric polynomials are dense in $L^p$, in the light of the Hahn Banach theorem it suffices to prove an inequality of the form $\| Tf \| \lesssim \| f \|$. Here are some examples of Fourier operators we have already seen.

\begin{example}
    The truncation operator $S_N$ is the transform associated with the scalars $\lambda_n = [|n| \leq N]$. The truncation is continuous, since for any integrable function $f$, the Fourier coefficients are uniformly bounded by $\| f \|_1$, so $\| S_N f \|_1 \leq N \| f \|_1$. Similarily, the F\'{e}jer truncation $\sigma_N$ associated to the multipliers $\lambda_N = [|n| \leq N](1 - |n|/N)$ is continuous on all integrable functions. These operators are easy to extend precisely because the nonzero multipliers have finite support.
\end{example}

\begin{example}
    In the case of the Abel sum, $A_r$, associated with $\lambda_n = r^{|n|}$, $A_r$ extends in a continuous way to all integrable functions, since
    %
    \[ |A_r f| = \left| \sum r^{|n|} \widehat{f}(n) e_n(t) \right| \leq \| f \|_1 \sum r^{|n|} = \| f \|_1 \left( 1 + \frac{2}{1 - r} \right) \]
    %
    Thus the map is bounded.
\end{example}

To understand whether the truncations $S_N f$ of $f$ converge to $f$ in the $L^p$ norms, rather than pointwise, we turn to the analysis of an operator which is the core of the divergence issue, known as the \emph{Hilbert transform}. It is a Fourier multiplier operator $H$ associated with the coeficients
%
\[ \lambda_n = \frac{\text{sgn}(n)}{i} = \begin{cases} +1/i & n > 0 \\ 0 & n = 0 \\ -1/i & n < 0 \end{cases} \]
%
Because
%
\[ [|n| \leq N] = \frac{\text{sgn}(n + N) - \text{sgn}(n-N)}{2} + \frac{[n = N] + [n = -N]}{2} \]
%
we conclude
%
\[ S_n f = \frac{i \left( e_{-n} H(e_n f) - e_n H(e_{-n} f) \right)}{2} + \frac{\widehat{f}(n) e_n + \widehat{f}(-n) e_{-n}}{2} \]
%
Since the operators $f \mapsto \widehat{f}(n) e_n$ are bounded in all the $L^p$ spaces since they are continuous in $L^1(\mathbf{T})$, we conclude that the operators $S_n$ are uniformly bounded as endomorphisms on $L^p(\mathbf{T})$ provided that $H$ is bounded as an operator from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$. Since $S_n f$ converges to $f$ in $L^p$ whenever $f$ is a trigonometric polynomial, this would establish that $S_n f$ converges to $f$ in the $L^p$ norm for any function $f$ in $L^p(\mathbf{T})$. Later on, as a special case of the Hilbert transform on the real line, we will be able to prove that $H$ is a bounded operator on $L^p(\mathbf{T})$ for all $1 < p < \infty$, and as a result, we find that $S_N f \to f$ in $L^p$ for all such $p$. Unfortunately, $H$ is not bounded from $L^1(\mathbf{T})$ to itself, and correspondingly, $S_N f$ does not necessarily converge to $f$ in the $L^1$ norm for all integrable $f$.

For now, we explore some more ideas in how we can analyze the Hilbert transform via convolution, the dual of Fourier multipliers. The fact that $\smash{\widehat{f * g} = \widehat{f} \widehat{g}}$ implies that if their is an integrable function $g$ whose Fourier coefficients corresponds to the multipliers of an operator $T$, then $f * g = Tf$ for any trigonometric polynomial $f$, and by the continuity of convolution, this is the unique extension of the Fourier multiplier operator. In the theory of distributions, one generalizes the family of objects one can take the Fourier series from integrable functions to a more general family of objects, such that every sequence of Fourier coefficients is the Fourier series of some {\it distribution}. One can take the convolution of any such distribution $\Lambda$ with a $C^\infty$ function $f$, and so one finds that $\Lambda * f = Tf$ for any trigonometric polynomial $f$. There is a theorem saying that {\it all} continuous translation invariant operators from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$ are given by convolution with a Fourier multiplier operator. In practice, we just compute the convolution kernel which defines the Fourier multiplier, but it is certainly a satisfying reason to justify the study of Fourier multipliers. For instance, a natural question is to ask which Fourier multipliers result in bounded operations in space.

\begin{theorem}
    A Fourier multiplier is bounded from $L^2(\mathbf{T})$ to itself if and only if the coefficients are bounded.
\end{theorem}
\begin{proof}
    If a Fourier multiplier is given by $\lambda_n$, then for some trigonometric polynomial $f$,
    %
    \[ \| Tf \|_2^2 = \sum \left|\widehat{Tf}(n) \right|^2 = \sum |\lambda_n|^2 \left| \widehat{f}(n) \right|^2 \]
    %
    If the $\lambda_n$ are bounded, then we can obtain from this formula the bound
    %
    \[ \| Tf \|_2^2 \leq \max |\lambda_n| \| f \|_2^2 \]
    %
    Conversely, if $Tf$ is bounded, then
    %
    \[ |\lambda_n^2| = \| T(e_n) \|_2^2 \leq \| T \|^2 \]
    %
    so the $\lambda_n$ are bounded.
\end{proof}

\begin{corollary}
    The Hilbert transform is a bounded endomorphism on $L^2(\mathbf{T})$. Note that we already know that $S_N f \to f$ in the $L^2$ norm.
\end{corollary}

The terms of the Hilbert transform cannot be considered the Fourier coefficients of any integrable function. Indeed, they don't vanish as $n \to \infty$. Nonetheless, we can use Abel summation to treat the Hilbert transform as convolution with an appropriate operator. For $0 < r < 1$, consider, for $z = e^{it}$,
%
\[ K_r(z) = \sum_{n \in \ZZ} \frac{\text{sgn}(n)}{i} r^{|n|} z^n = K * P_r \]
%
Since we know the Hilbert transform is continuous in $L^2(\mathbf{T})$, we can conclude that, in particular, for any $C^\infty$ function $f$,
%
\[ H f = \lim_{r \to 1} K * (P_r * f) = \lim_{r \to 1} (K * P_r) * f = \lim_{r \to 1} K_r * f \]
%
So it suffices to determine the limit of the $K_r$. We find that
%
\begin{align*}
    \sum_{n = 1}^\infty \frac{(rz)^n - (r \overline{z})^n}{i} &= \frac{r}{i} \left( \frac{1}{\overline{z} - r} - \frac{1}{z - r} \right) = \frac{r}{i} \frac{z - \overline{z}}{|z|^2 - 2r \text{Re}(z) + r^2}\\
    &= \frac{2r \sin(t)}{1 - 2r \cos(t) + r^2} = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r \sin^2(t/2)}\\
    &= \cot(t/2) + O \left( \frac{(1 - r)^2}{t^3} \right)
\end{align*}
%
Thus $K_r(t)$ tends to $\cot(t/2)$ locally uniformly away from the origin. But
%
\[ K_r(t) = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r\sin^2(t/2)} = O \left( \frac{t}{(1 - r)^2} \right) \]
%
If $f$ is any $C^\infty$ function on $\mathbf{T}$, then
%
\[ \left| \int_{|t| \geq \varepsilon} [K_r(t) - \cot(t/2)] f(t) \right| \lesssim (1 - r)^2 \| f \|_\infty \int_{|t| \geq \varepsilon} \frac{dt}{|t|^3} \lesssim \frac{(1 - r)^2 \| f \|_\infty}{\varepsilon^2} \]
%
\begin{align*}
    \left| \int_{|t| < \varepsilon} K_r(t) f(t)\; dt \right| &\leq \int_0^\varepsilon |K_r(t)||f(t) - f(-t)|\\
    &\lesssim \int_0^\varepsilon |tK_r(t)||f'(0)| \lesssim \frac{|f'(0)|}{(1 - r)^2} \int_0^\varepsilon t^2 \lesssim \| f' \|_\infty \frac{\varepsilon^3}{(1 - r)^2}
\end{align*}
%
\[ \left| \int_{|t| < \varepsilon} \cot(t/2) f(t)\; dt \right| \lesssim \int_0^\varepsilon \frac{|f(t) - f(-t)|}{t} \lesssim \varepsilon f'(0) \]
%
Thus
%
\[ \left| \int K_r(t) f(t)\; dt - \int \cot(t/2) f(t)\; dt \right| \lesssim \frac{(1 - r)^2}{\varepsilon^2} \| f \|_\infty + \left( \frac{\varepsilon^3}{(1 - r)^2} + \varepsilon \right) \| f' \|_\infty \]
%
Choosing $\varepsilon = (1 - r)^\alpha$ for some $2/3 < \alpha < 1$ shows that for sufficiently smooth $f$,
%
\[ (Hf)(x) = \lim_{r \to 1} \int \cot(t/2) f(x - t)\; dt \]


\section{A Divergent Fourier Series}

Analysis was built to analyze continuous functions, so we would hope the method of fourier expansion would work for all continuous functions. Unfortunately, this is not so. The behaviour of the Dirichlet kernel away from the origin already tells us that the convergence of Fourier series is subtle. We shall take advantage of this to construct a continuous function with divergent fourier series at a point.

To start with, we shall consider the series
%
\[ f(t) \sim \sum_{n \neq 0} \frac{e_n(t)}{n} \]
%
where $f$ is an odd function equaling $i(\pi - t)$ for $t \in (0,\pi]$. Such a function is nice to use, because its Fourier representation is simple, yet very close to diverging. Indeed, if we break the series into the pair
%
\[ \sum_{n = 1}^\infty  \frac{e_n(t)}{n}\ \ \ \ \ \ \ \ \ \ \sum_{n = -\infty}^{-1} \frac{e_n(t)}{n} \]
%
Then these series no longer are the Fourier representations of a Riemann integrable function. For instance, if $g(t) \sim \sum_{n = 1}^\infty \frac{e_n(t)}{n}$, then the Abel means

$A_r(f)(t) = $

\section{Conjugate Fourier Series}

When $f$ is a real-valued integrable function, then $\overline{\widehat{f}(-n)} = \widehat{f}(n)$. Thus we formally calculate that
%
\[ \sum_{n = -\infty}^\infty \widehat{f}(n) e_n(t) = \text{Re} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) \]
%
This series defines an analytic function in the interior of the unit circle since the coefficients are bounded. Thus the sum is a harmonic function in the interior of the unit circle. The imaginary part of this sum is
%
\[ \text{Im} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) = \Re \left( -i \sum_{n = -\infty}^\infty \text{sgn}(n) \widehat{f}(n) e_n(t) \right) \]
%
The right hand side is known as the conjugate series to the Fourier series $\widehat{f}(n)$. It is closely related to the study of a function $\tilde{f}$ known as the {\it conjugate function}.







\chapter{Oscillatory Integrals}

The goal of the theory of oscillatory integrals is to obtain estimates of integrals with highly oscillatory integrands, where standard techniques such as taking in absollute values, or various spatial decomposition strategies, fail completely to give tight estimates. A typical oscillatory integral is of the form
%
\[ I(\lambda) = \int e^{\lambda i \phi(x)} \psi(x)\; dx, \]
%
where $\phi$ and $\psi$ are scalar valued functions, known as the \emph{phase} and \emph{amplitude} functions. The value $\lambda$ is a parameter measuring the degree of oscillation. As $\lambda$ increases, oscillation increases, which implies more cancellation should occur on average, hence we should expect $I(\lambda)$ to decay as $\lambda \to \infty$. One of the main problems in the study of oscillatory integrals is to measure the asymptotic decay more precisely.

\begin{example}
    The most basic example of an oscillatory integral is the Fourier transform, where for each function $f \in L^1(\RR)$, and each $\xi \in \RR$, we consider the quantity
    %
    \[ \widehat{f}(\xi) = \int_{-\infty}^\infty e(-\xi x) f(x)\; dx. \]
    %
    Thus $f$ plays the role of the amplitude, the phase function is $\phi(x) = x$, and $\xi$ takes the role of $\lambda$. The basic theory of the Fourier transform hints that we can obtain decay in this integral as $\xi \to \infty$ by exploiting the smoothness of the function $f$.
\end{example}

There are two main tools to estimate oscillatory integrals. The first, the method of steepest descent, uses complex analysis to shift the integral to a domain where less oscillation occurs, so that standard estimation strategies can be exmployed. However, this method seems to have limited applicability to oscillatory integrals over multivariable domains. The second method, known as the method of stationary phase, states that if $\phi$ is smooth, and $\nabla \phi$ has an isolated family of zeroes, then the oscillatory integral asymptotics can be localized to regions around the values $x_0$ with $\nabla \phi(x_0) = 0$. Heuristically, each zero $x_0$ contributes $\psi(x_0) e ( \lambda \phi(x_0) )$, times the volume of the region around $x_0$ where $\phi$ deviates by $O(1/\lambda)$ to the overall asymptotics.

\section{One Dimensional Theory}

Let us begin with a simple example of an oscillatory integral, i.e.
%
\[ I(\lambda) = \int_J e^{i \lambda \phi(x)}\; dx, \]
%
where $J$ is a closed interval, and $\phi: J \to \RR$ is Borel measurable. Taking in absolute values shows that $|I(\lambda)| \leq |J|$ for all $\lambda$. If $\phi$ is constant, then $I(\lambda) = |J| e^{i \lambda \phi}$, so in this case the estimate is sharp. But if $\phi$ varies, we expect $I(\lambda)$ to decay as $\lambda \to \infty$. For instance, the Esse\'{e}n concentration inequality shows that if we are to expect \emph{average} decay in the integral $I$ over a range of $\lambda$, then $\phi$ must not be concentrated around any point.

\begin{theorem}[Esse\'{e}n Concentration Inequality]
  Let $\phi: J \to \RR$ be Borel measurable, and for each $\lambda \in \RR$, set
  %
  \[ I(\lambda) = \int_J e^{i \lambda \phi(x)}\; dx. \]
  %
  Then for any $\varepsilon > 0$,
  %
  \[ \sup_{\phi_0 \in \RR} |\{ x \in [0,1]: |\phi(x) - \phi_0| \leq \varepsilon \}| \lesssim \varepsilon \int_0^{1/\varepsilon} |I(\lambda)|\; d\lambda, \]
  %
  where the implicit constant is independant of $\phi$.
\end{theorem}
\begin{proof}
  By rescaling, we may assume that $J = [0,1]$. Moreover, for any choice of $\phi_0$, we may replace $\phi$ with $\phi - \phi_0$, reducing the analysis to the case where $\phi_0 = 0$. Similarily, replacing $\phi$ with $\phi/\varepsilon$ reduces us to the situation where $\varepsilon = 1$. Thus we must show
  %
  \[ |\{ x \in [0,1]: |\phi(x)| \leq 1 \}| \lesssim \int_0^1 |I(\lambda)|\; d\lambda, \]
  %
  where the implicit constant is independant of the function $\phi$. If $\psi$ is an integrable function supported on $[0,1]$, then Fubini's theorem implies
  %
  \begin{align*}
    \int_0^1 \psi(\lambda) I(\lambda)\; d\lambda &= \int_0^1 \int_0^1 \psi(\lambda) e^{\lambda i \phi(x)}\; d\lambda\; dx\\
    &= \int_0^1 \widehat{\psi}(- \phi(x) / 2 \pi)\; dx.
  \end{align*}
  %
  In particular, this means that
  %
  \[ \left| \int_0^1 \widehat{\psi}(- \phi(x) / 2\pi)\; dx \right| \leq \| \psi \|_{L^\infty[0,1]} \int_0^1 |I(\lambda)|\; d\lambda. \]
  %
  If we choose a bounded function $\psi$ such that $\widehat{\psi}$ is non-negative, and bounded below on $[-2\pi,2\pi]$, then
  %
  \[ \left| \int_0^1 \widehat{\psi}(- \phi(x) / 2 \pi)\; dx \right| \gtrsim |\{ x \in [0,1]: |\phi(x)| \leq 1 \}|, \]
  %
  and so the claim follows easily.
\end{proof}

Thus if large cancellation happens in $I(\lambda)$ for the average $\lambda$, this automatically implies that $\phi$ cannot be concentrated around any particular point.  Conversely, we want to show that if $\phi$ varies significantly, then $I$ exhibits cancellation as $\lambda \to \infty$. The condition that $\phi'$ is bounded below is not sufficient to guarantee cancellation independant of the function $\phi$, as the next example shows, if the integrand oscillated at a wavelength $1/\lambda$.

\begin{example}
  Fix $\lambda_0 \in \ZZ$, and let $\phi(x) = 2 \pi x + f(\lambda_0 x) / \lambda_0$, where $f$ is smooth and 1-periodic, $\| f' \|_{L^\infty(\RR)} \leq \pi$, and
  %
  \[ \int_0^1 e^{2 \pi i x + i f(x)}\; dx \neq 0. \]
  %
  Then for each $x \in \RR$, $\pi \leq |\phi'(x)| \leq 3\pi$, and in particular, is bounded independently of $\lambda_0$. Since $\phi(x + 1/\lambda_0) = \phi(x) + 2 \pi / \lambda_0$, we find $e^{i \lambda_0 \phi(x)}$ is $1/\lambda_0$ periodic. In particular, this means
  %
  \[ I(\lambda_0) = \int_0^1 e^{\lambda_0 i \phi(x)} = \int_0^1 e^{2 \pi i x + i f(x)}\; dx. \]
  %
  which is comparable to 1, independantly of $\lambda_0$.
\end{example}

Controlling $\phi''$ in addition to $\phi'$, however, is sufficient.

\begin{theorem}
  Let $\phi: J \to \RR$ be smooth, and suppose there exists constants $A,B > 0$ with $|\phi'(x)| \geq A$ and $|\phi''(x)| \leq B$ for all $x \in J$. Then for all $\lambda > 0$, we find
  %
  \[ |I(\lambda)| \lesssim \frac{1}{\lambda} \left( \frac{1}{A} + \frac{B}{A^2} |J| \right). \]
\end{theorem}
\begin{proof}
  A dimensional analysis shows that the inequality is invariant under rescalings in $x$ and $\lambda$, so we may assume that $J = [0,1]$, and $\lambda = 1$. An integration by parts shows that
  %
  \begin{align*}
    \int_0^1 e^{i \phi(x)}\; dx &= \int_0^1 \frac{1}{i \phi'(x)} \frac{d}{dx} \left( e^{i \phi(x)} \right)\; dx\\
    &= \left( \frac{e^{i \phi(1)}}{i \phi'(1)} - \frac{e^{i \phi(0)}}{i \phi'(0)} \right) - \int_0^1 \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) e^{i \phi(x)}.
  \end{align*}
  %
  Now
  %
  \[ \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) = - \frac{\phi''(x)}{\phi'(x)^2}, \]
  %
  so taking in absolute values completes the proof.
\end{proof}

One can keep applying absolute values to obtain further bounds in terms of higher order derivatives of $\phi$. For instance, another integration by parts shows that if there is $A,B,C > 0$ such that for $x \in J$, if $\phi'(x) \geq A$, $\phi''(x) \leq B$, and $\phi'''(x) \leq C$, then
%
\[ |I(\lambda)| \lesssim \frac{1}{\lambda} \left( \frac{1}{A} \right) + \frac{1}{\lambda^2} \left( \frac{B}{A^3} + \frac{C}{A^3} |J| + \frac{B^2}{A^4} |J| \right). \]
%
One can keep taking in absolute values, but the $1/\lambda$ decay will still remain. This is to be expected, for instance, if $\phi(x) = x$ and $J = [0,1]$ then
%
\[ \limsup_{\lambda \to \infty} |I(\lambda) \cdot \lambda| = 2, \]
%
so we cannot obtain any better decay than $1/\lambda$ here.

Another option is to not require control on the second derivative of the phase, but instead to assume that $\phi'$ is monotone, which prevents the kind of oscillation present in our counterexample. 

\begin{lemma}[Van der Corput]
  Let $\phi: \RR \to \RR$ be a smooth phase such that $|\phi'(x)| \geq A$ for all $x \in J$, and $\phi'$ is monotone. Then for all $\lambda > 0$ we have
  %
  \[ |I(\lambda)| \lesssim \frac{1}{A \lambda}, \]
  %
  where the implicit constant is independent of $J$.
\end{lemma}
\begin{proof}
  The same integration by parts as before shows that if $J = [a,b]$,
  %
  \begin{align*}
    \int_J e^{\lambda i \phi(x)}\; dx &= \left( \frac{e^{i \phi(b)}}{\lambda i \phi'(b)} - \frac{e^{i \phi(a)}}{i \phi'(a)} \right) + \frac{1}{i\lambda} \int_J \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) e^{i \phi(x)}\; dx.
  \end{align*}
  %
  The two endpoints are $O(1/A \lambda)$. For the second sum, we perform a simple trick. Since $\phi'$ is monotone, so too is $1/\phi'$, so in particular, it's derivative has a constant sign. Thus by the fundamental theorem of calculus,
  %
  \begin{align*}
    \left| \int_J \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) e^{i \phi(x)}\; dx \right| &\leq \int_J \left| \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right)  \right|\; dx\\
    &= \left| \int_J \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) \right|\; dx\\
    &= \frac{1}{\phi'(b)} - \frac{1}{\phi'(a)}.
  \end{align*}
  %
  Combining these inequalities completes the proof.
\end{proof}

Since the Van der Corput bound does not depend on $|J|$, it can be easily iterated to give a theorem about higher derivatives of a function $\phi$.

\begin{lemma}
  Let $\phi: \RR \to \RR$ be smooth, and suppose there is some $k \geq 2$ such that $|\phi^{(k)}(x)| \geq A$ for all $x \in J$. Then for all $\lambda > 0$, we find
  %
  \[ |I(\lambda)| \lesssim_k \frac{1}{(A \lambda)^{1/k}}, \]
  %
  where the implicit constant is independant of $J$.
\end{lemma}
\begin{proof}
  We perform an induction on $k$, the case $k = 1$ already proven. By scale invariance, we may assume $\lambda = 1$. Now $\phi^{(k-1)}$ is monotone, so for each $\alpha > 0$, outside an interval of length at most $O(\alpha/A)$, $|\phi^{(k-1)}(x)| \geq \alpha$. Thus applying the trivial bound in the excess region, and the case $k - 1$ on the other intervals, we conclude
  %
  \[ |I(\lambda)| \lesssim_k \frac{\alpha}{A} + \alpha^{-1/(k-1)} \]
  %
  Optimizing over $\alpha$, we find $|I(\lambda)| \lesssim_k A^{-1/k}$.
\end{proof}

Let us now consider a one dimensional oscillatory integral with a varying amplitude $\psi$, i.e.
%
\[ I(\lambda) = \int_{-\infty}^\infty e^{i \lambda \phi(x)} \psi(x)\; dx. \]
%
The Van der Corput lemma also applies here.

\begin{lemma}
  Fix $k \geq 1$. Suppose $\psi$ is supported on $[a,b]$, and suppose $|\phi^{(k)}(x)| \geq A$ for all $x \in [a,b]$, with $\phi'$ monotone if $k = 1$. Then 
  %
  \[ |I(\lambda)| \lesssim_k \frac{\| \psi \|_{L^\infty(\RR)} + \| \psi' \|_{L^1(\RR)}}{(A \lambda)^{1/k}}. \]
\end{lemma}
\begin{proof}
  Fix $c_0 \in [a,b]$, and define
  %
  \[ I_0(x) = \int_{c_0}^x e^{i \lambda \phi(t)}\; dt. \]
  %
  The standard Van-der Corput lemma implies that for all $x$,
  %
  \[ |I_0(x)| \lesssim_k \frac{1}{(A \lambda)^{1/k}}. \]
  %
  An integration by parts gives that for any $a < b$,
  %
  \begin{align*}
    \int_a^b \psi(x) e^{i \lambda \phi(x)}\; dx &= \int_a^b \psi(x) I_0'(x)\; dx\\
    &= [\psi(b) I_0(b) - \psi(a) I_0(a)] - \int_a^b \psi'(x) I_0(x)\; dx.
  \end{align*}
  %
  Now
  %
  \[ |\psi(b) I_0(b) - \psi(a) I_0(a)| \lesssim \frac{\| \psi \|_{L^\infty(\RR)}}{(A \lambda)^{1/k}} \]
  %
  and
  %
  \[ \left| \int_a^b \psi'(x) I_0(x)\; dx \right| \lesssim_k \frac{\| \psi' \|_{L^1(\RR)}}{(A \lambda)^{1/k}}. \]
  %
  Putting these two estimates together completes the proof.
\end{proof}

If $\psi$ is smooth and compactly supported, integration by parts is very successful because there are no boundary terms.

\begin{theorem}
    If $\phi$ and $\psi$ are smooth, with $\psi$ compactly supported, and $\phi'(x) \neq 0$ for all $x$ in the support of $\psi$, then for all $N > 0$,
    %
    \[ I(\lambda) \lesssim_N 1/\lambda^N, \]
    %
    where the implicit constants depend on the functions $\phi$ and $\psi$.
\end{theorem}
\begin{proof}
  A single integration by parts gives
  %
  \begin{align*} I(\lambda) &= \frac{1}{\lambda} \int \frac{\psi(x)}{i \phi'(x)} \frac{d}{dx} \left( e^{\lambda i \phi(x)} \right)\\
  &= - \frac{1}{i \lambda} \int \frac{d}{dx} \left( \frac{\psi(x)}{\phi'(x)} \right) e^{i \phi(x)}\\
  &= \frac{1}{i \lambda} \int \frac{\phi'(x) \psi'(x) - \psi(x) \phi''(x)}{\phi'(x)^2}.
  \end{align*}
  %
  Further integration by parts give, for each $N$, that
  %
  \[ I(\lambda) = \lambda^{-N} \int \frac{P(x)}{\phi'(x)^{2N}} e^{i \phi(x)}, \]
  %
  where $P(x)$ is a polynomial function in the derivatives of $\phi$ and $\psi$ up to order $N+1$, in particular, with the same support as $\psi$. Thus we can take in absolute values and integrate to conclude $|I(\lambda)| \lesssim_{\psi,N} \lambda^{-N}$.
\end{proof}

\begin{remark}
  We note that the implicit constants in the theorem for a particular $N$ can be upper bounded uniformly, given uniform upper bounds on the measure of the support of $\psi$, upper bounds on the derivatives of $\phi$ and $\psi$ of order up to $N+1$, and lower bounds on $\phi'$ over the support of $\psi$.
\end{remark}

Let us now move onto a `stationary phase', i.e. a phase $\phi$ whose derivative vanishes at a point. The simplest example of such a phase is the integral
%
\[ I(\lambda) = \int_{-\infty}^\infty e^{i \lambda x^2} \psi(x)\; dx. \]
%
Our heuristics tell us $I(\lambda)$ decays on the order of $\lambda^{-1/2}$, which agrees with the asymptotics we now find.

\begin{theorem}
  Let $\psi \in \mathcal{S}(\RR)$ be a Schwartz amplitude. Then for each $N \geq 0$,
  %
  \[ \int_{-\infty}^\infty \psi(x) e^{\lambda i x^2}\; dx = e^{i \pi / 4} \cdot \pi^{1/2} \cdot \sum_{n = 0}^N \frac{i^n \psi^{(2n)}(0)}{4^n \lambda^{n + 1/2}} + O_{N,\psi}(1/\lambda^{N + 3/2}). \]
\end{theorem}
\begin{comment}
\begin{proof}
  Rescaling, it suffices to prove the theorem when $\psi(x) = 1$ whenever $|x| < 1$. Let $\alpha(x)$ be a smooth function with $\alpha(x) = 1$ for $|x| \geq 1/2$, and with $\alpha(x) = 0$ for $|x| < 1/4$. Then for each $k \geq 1$, define
  %
  \[ \beta_k(x) = \alpha(2^k x) - \alpha(2^{k-1} x). \]
  %
  Then $\beta_k$ is supported on $1/2^{k+2} \leq |x| \leq 1/2^k$, and moreover, for each $x \in \RR$,
  %
  \[ \alpha(x) + \sum_{k = 1}^\infty \beta_k(x) = 1. \]
  %
  It is simple to see that
  %
  \begin{align*}
    \int_{-\infty}^\infty \psi(x) e^{\lambda i x^2}\; dx &= \int_{-\infty}^\infty \alpha(x) \psi(x) e^{\lambda i x^2}\; dx\\
    &\ \ \ \ + \sum_{k = 1}^\infty \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx.
  \end{align*}
  %
  Now $\alpha \psi$ is a compactly supported amplitude supported away from the origin, so for each $N$,
  %
  \[ \left| \int_{-\infty}^\infty \alpha(x) \psi(x) e^{\lambda i x^2}\; dx \right| \lesssim_{\alpha,\psi,N} \lambda^{-N}. \]
  %
  The same argument works for $\beta_1$, and so by rescaling, for each $k$ and $M$,
  %
  \begin{align*}
    \left| \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx \right| &\lesssim_{\alpha,\psi,M} 2^{(2M-1)k} \lambda^{-M}.
  \end{align*}
  %
  In particular, we may sum the inequality for small $k$, and with $M$ an appropriate multiple of $N$, to conclude
  %
  \[ \sum_{k = 1}^{\lg(\lambda^{1/2-\varepsilon})} \left| \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx \right| \lesssim_{\alpha,\psi,N,\varepsilon} \lambda^{-N}. \]
  %
  If we set
  %
  \[ \gamma(x) = \sum_{k = \lg(\lambda^{1/2-\varepsilon})}^\infty \beta_k(x), \]
  %
  then $\gamma(x) = 0$ for $|x| \geq 1/\lambda^{3/4}$, and $\gamma(x) = 1$ for $|x| \leq 1/4\lambda^{3/4}$. Rescaling, we have
  %
  \[ \int_{-\infty}^\infty \gamma(x) e^{\lambda i x^2} = \lambda^{-3/4} \int_{-\infty}^\infty \gamma(x \cdot \lambda^{3/4}) e^{ix^2 / \lambda^{1/2}}. \]
\end{proof}


IDEA: Sum up dyadically on intervals $|x| \sim 2^k \lambda^{-1/2}$, for $k = 1$ to $k = \lfloor \log( \lambda^{1/2} \varepsilon) - 2 \rfloor$, then hopefully the oscillatory integral with phase $x^2$ and amplitude $\psi(x) \sum_{k = \lfloor \lg(\lambda^{1/2} \varepsilon) - 2 \rfloor}^\infty \beta_k(x/\lambda^{1/2})$ decays arbitrarily fast in $\lambda$?


Then for each $n$, define $\beta_n(x) = \alpha(x/2^n) - \alpha(x/2^{n-1})$. Thus we have $\alpha(x) + \sum_{k = 1}^\infty \beta_k(x) = 1$ for all $x \in \RR$. Moreover, $\beta_k$ is supported on $[-2^n, -$

\end{comment}
\begin{proof}
  Applying the multiplication formula for the Fourier transform, noting that the distributional Fourier transform of $e^{i \lambda x^2}$ is
  %
  \[ e^{i \pi / 4} (\pi/\lambda)^{1/2} e^{-i \pi^2 \xi^2 / \lambda}, \]
  %
  we conclude that
  %
  \[ I(\lambda) = e^{i \pi / 4} (\pi/\lambda)^{1/2} \int_{-\infty}^\infty e^{-i \pi^2 \xi^2 / \lambda} \widehat{\psi}(\xi)\; d\xi. \]
  %
  Now for any $N$, we can write
  %
  \[ e^{-i \pi^2 \xi^2 / \lambda} = \sum_{n = 0}^N \frac{1}{n!} \left( \frac{-i \pi^2 \xi^2}{\lambda} \right)^n + O_N \left( (\xi^2 / \lambda)^{N+1} \right). \]
  %
  Thus substituting in the Taylor series, and then applying the Fourier inversion formula, we find
  %
  \begin{align*}
    I(\lambda) &= e^{i \pi / 4} (\pi/\lambda)^{1/2} \sum_{n = 0}^N \frac{1}{n!} \int_{-\infty}^\infty \left( \frac{-i \pi^2 \xi^2}{\lambda} \right)^n \widehat{\psi}(\xi)\; d\xi + O_{\psi,N} \left( 1/\lambda^{N+3/2}  \right)\\
    &= e^{i \pi / 4} (\pi/\lambda)^{1/2} \sum_{n = 0}^N \frac{i^n}{4^n n!} \frac{1}{\lambda^n} \int_{-\infty}^\infty (2\pi i \xi)^{2n} \widehat{\psi}(\xi)\; d\xi + O_{\psi,N} \left( 1 / \lambda^{N+3/2} \right)\\
    &= e^{i \pi / 4} (\pi/\lambda)^{1/2} \sum_{n = 0}^N \frac{i^n \psi^{(2n)}(0)}{4^n n!} \frac{1}{\lambda^n} + O_{\psi,N} \left( 1 / \lambda^{N+3/2} \right). \qedhere
  \end{align*}
\end{proof}

\begin{remark}
  The implicit constant can be made independent of $\psi$ given uniform upper bounds on
  %
  \[ \int_{-\infty}^\infty |\widehat{\psi}(\xi)| |\xi|^{2(N+1)}\; d\xi. \]
  %
  In particular, this can be obtained by uniform upper bounds on the support of $\psi$, upper bounds on the magnitude of $\psi$, and upper bounds on the magnitude of the $(2N+4)$th derivative of $\psi$.
\end{remark}

It requires only a simple change of variables to extend this theorem to arbitrary quadratic phases. We say a critical point of a function is \emph{non-degenerate} if the second derivative at that point is nonzero.

\begin{theorem}
  Let $\phi$ be a smooth phase with finitely many non-degenerate critical points, and let $\psi$ be a smooth compactly supported amplitude function. Then there exists a sequence of constants $\{ a_n \}$, depending on the derivatives of $\phi$ and $\psi$ at the critical points, such that for each $N \geq 0$,
  %
  \[ I(\lambda) = \lambda^{-1/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_{\phi,\psi,N} ( 1/\lambda^{N+3/2} ). \]
  %
  In particular, if $\phi$ has a single critical point at some $x_0$, then
  %
  \[ a_0 = \sqrt{ \frac{2\pi}{-i \phi''(x_0)} } \cdot e^{\lambda i \phi(x_0)} \psi(x_0). \]
\end{theorem}
\begin{proof}
  By a partition of unity argument, it suffices to prove this theorem assuming that $\phi$ has only a single stationary point, which by translation we may assume to be at the origin, with $\phi(0) = 0$, and that $\phi(x)$ and $\phi'(x)$ are nonzero for all nonzero $x$ in the support of $\psi$. Moreover, rescaling enables us to assume $\phi''(0) = 2$. We can define a function
  %
  \[ y(x) = \text{sgn}(x) \cdot \phi(x)^{1/2}. \]
  %
  Then $y$ is a smooth function in the support of $\phi$. By the change of variables formula, there exists a smooth, compactly supported function $\psi_0(y)$ such that
  %
  \[ I(\lambda) = \int \psi(x) e^{\lambda i \phi(x)}\; dx = \int \psi_0(y) e^{\lambda i y^2}\; dy. \]
  %
  Thus we can apply the previous theorem to conclude that there exists a sequence of constants $\{ a_n \}$ such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-1/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_{\phi,\psi,N}(1/\lambda^{N+3/2}). \]
  %
  The existence in this theorem is a \emph{constructive} existence statement. The proof gives an effective algorithm to produce the constants $a_n$ for any particular phase $\phi$. In particular,
  %
  \[ a_0 = e^{i\pi/4} \pi^{1/2} \psi_0(0) = e^{i\pi/4} \pi^{1/2} \left( \frac{\psi(0)}{y'(0)} \right). \]
  %
  Since
  %
  \begin{align*}
    y'(0) &= \lim_{x \to 0} y'(x) = \lim_{x \to 0} \frac{\phi'(x)}{2 \text{sgn}(x) \phi(x)^{1/2}}\\
    &= \frac{1}{2} \lim_{x \to 0} \frac{\phi'(x)}{x} \left( \frac{x^2}{\phi(x)} \right)^{1/2} = \frac{\phi''(0)}{2 \phi''(0)^{1/2}} = \phi''(0)^{1/2}/2 = 2^{1/2}.
  \end{align*}
  %
  Thus $a_0 = 2^{1/2} e^{i\pi/4} \pi^{1/2} \psi(0)$.
\end{proof}

\begin{remark}
  If we incorporate $\lambda$ into the phase, considering the oscillatory integral
  %
  \[ \int e^{i \phi(x)} \psi(x)\; dx, \]
  %
  then if $\phi$ has a nondegenerate stationary point at $x_0$, the last theorem says that
  %
  \[ \int e^{i \phi(x)} \psi(x)\; dx \approx \left( \frac{2\pi}{-i \phi''(x_0)} \right)^{1/2} e^{i \phi(x_0)} \psi(x_0), \]
  %
  where this approximation gets better and better for larger and larger $\lambda$.
\end{remark}

If the phase $\phi$ has a critical point of order greater than two, than the asymptotics of the oscillatory integral get worse. In particular, if $\phi$ has a zero of order $k$, then around this region $\phi$ differs by $1/\lambda$ on an interval of length $1/\lambda^{1/k}$, so we might $I(\lambda)$ to be proportional to $\lambda^{1/k}$. This is precisely what happens, but our proof will not rely on the Fourier transform since the computation of the Fourier transform of $e^{\lambda ix^k}$ is quite difficult to calculate when $k > 2$. The next proof also works for the case $k = 2$, but the proof is different.

\begin{lemma}
  For any non-negative integers $l$ and $k$, there is a positive constant $A_{kl} > 0$ such that for any $\lambda \in \RR$ and $\varepsilon > 0$,
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-\varepsilon x^k} x^l\; dx = A_{kl} (\varepsilon - i \lambda)^{-(l+1)/k}, \]
  %
  where the $k$th root is the principal root for non-negative complex numbers.
\end{lemma}
\begin{proof}
  If $z = (\varepsilon - i \lambda)^{1/k} x$, and if $\alpha_N$ is the ray between the origin and the point $N (\varepsilon - i \lambda)^{1/k}$, then
  %
  \[ \int_0^N e^{\lambda i x^k} e^{- \varepsilon x^k} x^l\; dx = (\varepsilon - i \lambda)^{-(l+1)/k} \int_{\alpha_N} e^{-z^k} z^l\; dz. \]
  %
  Let $\theta \in (-\pi/2,0]$ be the argument of $(\varepsilon - i \lambda)^{1/k}$, and set $\beta_N$ to be the arc between $N ( \varepsilon - i \lambda)^{1/k}$ and $N (\varepsilon^2 + \lambda^2)^{1/2}$. Then $\beta_N$ has length $O(N)$, with implicit constant depending on $\lambda$ and $\varepsilon$. Moreover, any point $z$ on $\beta_N$ has modulus $N (\varepsilon^2 + \lambda^2)^{1/2}$ and argument less than or equal to $\theta / k$. But this implies that $\text{Re}(z^k) \geq N^k (\varepsilon^2 + \lambda^2)^{k/2} \cos(\theta)$, and so there exists a constant $c$ depending on $\varepsilon$ and $\lambda$ such that $|e^{-z^k}| \leq e^{c N^k}$. But this means that $|z^l e^{-z^k}| \leq N^l e^{-cN^k}$. Thus taking in absolute values gives that
  %
  \[ \lim_{N \to \infty} \int_{\beta_N} e^{-z^k} z^l\; dz = 0. \]
  %
  In particular, applying Cauchy's theorem, we conclude that
  %
  \[ \lim_{N \to \infty} \int_{\gamma_N} e^{-z^k} z^l\; dz = \int_0^\infty e^{-x^k} x^l\; dx. \]
  %
  If we denote the latter integral by $A_{kl} > 0$, then we have shown that
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-\varepsilon x^k} x^l\; dx = A_{kl} \cdot (\varepsilon - i \lambda)^{-(l+1)/k}, \]
  %
  as was required to be shown.
\end{proof}

\begin{remark}
  In particular, this implies that for each $\varepsilon$, there exists constants $A_{kln}$ such that
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-x^k} x^l\; dx = \lambda^{-(l+1)/k} \sum_{n = 0}^\infty A_{kln} \lambda^{-n}. \]
  %
  This is obtained by taking the Laurent series of
  %
  \[ (1 - i\lambda)^{-(l+1)/k} = \lambda^{-(l+1)/k} (\lambda^{-1} - i)^{-(l+1)/k}, \]
  %
  which converges absolutely for $\lambda > 1$. In particular, for each $N$ and for each $\lambda$, we conclude
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-x^k} x^l\; dx = \lambda^{-(l+1)/k} \sum_{n = 0}^N A_{kln} \lambda^{-n} + O_N \left(1/\lambda^{n + 1 + 1/k} \right). \]
\end{remark}

\begin{lemma}
  If $\eta$ is compactly supported and smooth, then
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx \right| \lesssim_{l,k,\eta} \lambda^{-(l + 1)/k}. \]
\end{lemma}
\begin{proof}
  Let $\alpha$ be a bump function supported on $[-2,2]$ with $\alpha(x) = 1$ for $|x| \leq 1$. For each $\varepsilon > 0$, write
  %
  \begin{align*}
    \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx &= \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) \alpha(x/\varepsilon)\; dx\\
    &\ \ \ \ + \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx,
  \end{align*}
  %
  where we will bound each term and optimize for a small $\varepsilon$. We trivially have
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) \alpha(x/\varepsilon)\; dx \right| \lesssim_\eta \varepsilon^{l+1}, \]
  %
  We apply an integration by parts to the second integral, noting that $e^{\lambda i x^k}$ is a fixed point of the differential operator
  %
  \[ Df = \frac{1}{\lambda i k x^{k-1}} \frac{df}{dx}. \]
  %
  If we consider the differential operator
  %
  \[ D^*g = \frac{d}{dx} \left( \frac{-f}{\lambda i k x^{k-1}} \right) = \left( \frac{i}{\lambda k} \right) \left( \frac{f'(x)}{x^{k-1}} - \frac{(k-1) f(x)}{x^k} \right), \]
  %
  then for any smooth $f$ and compactly supported $g$,
  %
  \[ \int_{-\infty}^\infty (Df)(x) g(x) = \int_{-\infty}^\infty f(x) (D^* g)(x). \]
  %
  In particular,
  %
  \begin{align*}
    \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx &= \int_{-\infty}^\infty D^N(e^{\lambda i x^k})\; x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx\\
    &= \int_{-\infty}^\infty e^{\lambda i x^k}\; (D^*)^N \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \}\; dx.
  \end{align*}
  %
  Write $g_N(x) = (D^*)^N \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \}$. Since $x^l \eta(x) (1 - \alpha(x/\varepsilon))$ vanishes for $|x| \leq \varepsilon$, so too does $g_N(x)$. For $N \geq l/(k-1)$, and $|x| \geq \varepsilon$, we have
  %
  \[ |g_N(x)| \lesssim_{N,\eta} \lambda^{-N} \varepsilon^{-N} |x|^{l - N(k-1)}, \]
  %
  where the implicit constant depends on upper bounds for the derivatives of $\eta$ of order to $N$. We can thus take in absolute values after integrating by parts to conclude that if $N > (l+1)/(k-1)$, then
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx \right| \lesssim_{N,\eta} \lambda^{-N} \varepsilon^{l + 1 - Nk} \]
  %
  Thus we can put the two bounds together to conclude that
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx \right| \lesssim_{N,\eta} \varepsilon^{l+1} + \lambda^{-N} \varepsilon^{l+1-Nk}. \]
  %
  Picking $\varepsilon = \lambda^{-1/k}$ gives
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx \right| \lesssim_{N,\psi} \lambda^{-(l+1)/k}. \qedhere \]
  %
  But $N$ was chosen depending only on $k$ and $l$, so the implicit constants depend on the correct variables.
%  \[ D^* \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \} = c x^{l-k} \eta(x) (1 - \alpha(x/\varepsilon)) + x^{l+1-k} \eta'(x) (1 - \alpha(x/\varepsilon) - \varepsilon^{-1} x^{l+1-k} \eta(x) \alpha'(x/\varepsilon) \]
%  \[ (D^*)^2 \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \} = x^{l-2k} (1 - \alpha(x/\varepsilon))
  %  (d/dx) \{ x^{l+1-2k} \eta(x) (1 - \alpha(x/\varepsilon)) + x^{l+2-2k} \eta'(x) (1 - \alpha(x/\varepsilon) - \varepsilon^{-1} x^{l+2-2k} \eta(x) \alpha'(x/\varepsilon) \} \]
\end{proof}

\begin{remark}
  The implicit constants can be bounded uniformly given uniform upper bounds on the magnitude of the derivatives of $\eta$ of order up to
  %
  \[ \lceil (l+1)/(k-1) \rceil, \]
  %
  and upper bounds on the measure of the support of $\eta$.
\end{remark}

We can now prove the asymptotics for the model case $\phi(x) = x^k$.

\begin{theorem}
  Suppose $\psi$ is a smooth compactly supported amplitude, and $\phi$ is a smooth phase with $\phi'(x) \neq 0$ on the support of $\psi$ except at some point $x_0$, where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, and $\phi^{(k)}(x_0) \neq 0$. Then there is a sequence $\{ a_n \}$ such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-n/k} + O_{\psi,k,N} \left( 1/\lambda^{(N+2)/k} \right). \]
\end{theorem}
\begin{proof}
  Let us begin with the model case $\phi(x) = x^k$. Let $\tilde{\psi}$ be a bump function with $\tilde{\psi}(x) = 1$ for all $x$ with $\psi(x) > 0$. Then
  %
  \[ I(\lambda) = \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} [e^{x^k} \psi(x)] \tilde{\psi}(x)\; dx. \]
  %
  For each $N$, perform a Taylor expansion, writing
  %
  \[ e^{x^k} \psi(x) = \sum_{n = 0}^N a_n x^n + x^{N+1} R_N(x). \]
  %
  Thus if $P_N(x) = \sum_{n = 0}^N a_n x^n$,
  %
  \begin{align*}
    \int_{-\infty}^\infty &e^{\lambda i x^k} e^{-x^k} [e^{x^k} \psi(x)] \tilde{\psi}(x)\; dx\\
    & = \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} P_N(x)\; dx\\
    & + \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} P_N(x) (\tilde{\psi}(x) - 1)\; dx\\
    & + \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} x^{N+1} R_N(x) \tilde{\psi}(x)\; dx.
  \end{align*}
  %
  The first integral can be expanded in the required power series. The second integral, since it is supported away from the origin, is $O_M(\lambda^{-M})$ for any $M > 0$. And in the last lemma we showed the third integral is $O(\lambda^{-(N+2)/k})$, so combining these three terms gives the required result. The general case follows from a change of variables.
\end{proof}

\begin{remark}
  As we saw in the case $k = 2$, if $k$ is even and $n$ is odd then
  %
  \[ \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} x^n = 0. \]
  %
  Thus we can actually improve the asymptotics to the existence of a sequence $\{ a_n \}$ such that
  %
  \[ I(\lambda) = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-2n/k} + O_{\phi,\psi,N} \left( 1 / \lambda^{(2N + 3)/k} \right). \]
\end{remark}

\begin{comment}

Changing variables then proves the result for general $k$'th order phases.

\begin{lemma}
  Let $\psi$ is a compactly supported and smooth amplitude, and $\phi'(x) \neq 0$ on the support of $\psi$, except at some point $x_0$ where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, with $\phi^{(k)}(x_0) \neq 0$, then there exists constants $\{ a_n \}$ depending on the derivatives of $\phi$ and $\psi$ at $x_0$, such that for each $N$,
  %
  \[ \int_{-\infty}^\infty e^{\lambda i \phi(x)} \psi(x)\; dx = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-n/k} + O_{\phi,\psi,N} \left( 1/\lambda^{(N+2)/k} \right). \]
\end{lemma}

\begin{lemma}
  Let $\psi$ is a compactly supported and smooth amplitude, and $\phi'(x) \neq 0$ on the support of $\psi$, except at some point $x_0$ where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, with $\phi^{(k)}(x_0) \neq 0$, then there exists constants $\{ a_n \}$ depending on the derivatives of $\phi$ and $\psi$ at $x_0$, such that for each $N$,
  %
  \[ \int_{-\infty}^\infty e^{\lambda i \phi(x)} \psi(x)\; dx = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-n/k} + O_{\phi,\psi,N} \left( 1/\lambda^{(N+2)/k} \right). \]
\end{lemma}
\begin{proof}
  Without loss of generality, we may rescale our integral so that $\phi^{(k)}(x_0) = k!$. Then we can write $\phi(x) = x^k + x^{k+1} R(x)$, where $R(x)$ is a smooth function. A Taylor series approach tells us that
  %
  \[ e^{\lambda i \phi(x)} = e^{\lambda i x^k} \left[ \sum_{n = 0}^M \frac{(\lambda i x^{k+1} R(x))^n}{n!} + Q(x) \right], \]
  %
  where
  %
  \[ Q(x) = \frac{(i\lambda)^{M+1}}{(M+1)!} x^{(k+1)(M+1)} R(x)^{M+1} \int_0^1 e^{\lambda i x^{k+1} R(x) s} (1 - s)^M\; ds \]
  %
  For each $n$, we let
  %
  \[ I_n(\lambda) = \frac{(\lambda i)^n}{n!} \int e^{\lambda i x^k} R(x)^n x^{n(k+1)} \psi(x)\; dx, \]
  %
  and let
  %
  \[ J(\lambda) = \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} R(x)^{M+1} e^{\lambda i x^{k+1} R(x) s} (1 - s)^M \psi(x)\; ds\; dx. \]
  %
  Then
  %
  \[ I(\lambda) = I_1(\lambda) + \dots + I_M(\lambda) + \frac{(i\lambda)^{M+1}}{(M+1)!} J(\lambda), \]
  %
  and so it suffices to obtain asymptotics on each term separately. From the previous argument, we know there are are constants $\{ a_{nm} \}$ such that for each $M$,
  %
  \[ I_n(\lambda) = \lambda^{-1/k} \sum_{m = 1}^M a_{nm} \lambda^{n-m/k} + O_{\psi,R,k,n} \left( 1/ \lambda^{(M+2)/k} \right). \]
  %
  Moreover, we can write
  %
  \[ I_n(\lambda) = \int e^{\lambda i x^k} x^{n(k+1)} \psi_n(x)\; dx, \]
  %
  where $\psi_n(x) = R(x)^n \psi(x)$ is smooth. But then we know
  %
  \[ |I_n(\lambda)| \lesssim_{n,k,\psi,R} 1/\lambda^{n + (n+1)/k}. \]
  %
  In particular, this means that $a_{nm} = 0$ for $m \leq (2k+1)n$. Thus we conclude $I_n(\lambda)$ can be expanded in positive powers of $\lambda^{1/k}$, up to an error $O(1/\lambda^{(M+2)/k})$. If we split the integrand for $J(\lambda)$ using a bump function into values $x$ with $|x| \leq \varepsilon$ and values $|x| \geq \varepsilon$, bound the former by bringing in absolute values, bound the latter using integration by parts, and then optimizing over $\varepsilon$ yields

  To complete the argument, we show that for sufficiently large $M$, we can treat $J$ as an error term. If we define
  %
  \[ \psi_M(x,s) = \psi(x) (1 - s)^M R(x)^{M+1}, \]
  %
  then
  %
  \[ J(\lambda) = \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s)\; dx\; ds. \]
  %
  We introduce a bump function $\alpha$ such that $\alpha(x) = 1$ for $|x| \leq 1$, and vanishes outside for $|x| \geq 2$. For $\varepsilon > 0$, we write
  %
  \begin{align*}
    J(\lambda) &= \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s) \alpha(x/\varepsilon)\; dx\\
    &\ \ \ + \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s) (1 - \alpha(x/\varepsilon))\; dx.
  \end{align*}
  %
  The first integral is $O_{\psi,R,M}(\varepsilon^{(k+1)(M+1)+1})$. For the second, we employ an integration by parts in $x$. The value $e^{\lambda i x^k}$ is a fixed point of the differential operator $Df = f' / \lambda i x^{k-1}$, whose adjoint is
  %
  \[ D^* g = \frac{d}{dx} \left( \frac{g}{\lambda i x^{k-1}} \right). \]
  %
  For each $L$, there exists constants $c_n$ such that
  %
  \[ (D^*)^L g = \frac{1}{\lambda^L} \sum_{n = 0}^L \frac{c_n g^{(n)}}{x^{Lk - n}}. \]
  %
  If we write
  %
  \[ g_n(\lambda,x,s) = \frac{1}{x^{Lk-n}} \frac{d^n}{dx^n} \left\{ x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi(x,s) (1 - \alpha(x/\varepsilon)) \right\}, \]
  %
  then our oscillatory integral is bounded by an implicit constant depending on $L$ and $k$, and
  %
  \[ \sum_{n = 0}^L \frac{1}{\lambda^L} \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} g_n(x)\; dx. \]
  %
  Now $g_n$ has compact support depending on $\psi$, and vanishes for $|x| \leq \varepsilon$. For $|x| \geq \varepsilon$, we find that
  % \lambda \lesssim_{k,\phi} 1/\varepsilon
  \[ |g_n(\lambda,x,s)| \lesssim_{L,M,k,\alpha,\psi,n} \sum_{m = 0}^n \lambda^m \varepsilon^{m-n} x^{n-Lk+(k+1)(M+1) + km}. \]
  %
  Thus we conclude that for sufficiently large $L$
  %
  \[ |J(\lambda)| \lesssim_{\psi,R,M,L,k,\alpha} \varepsilon^{(k+1)(M+1) + 1} \left( 1 + \varepsilon^{- Lk} \sum_{m = 0}^L \lambda^{m-L} \varepsilon^{(k+1)m} \right). \]
  %
  TODO.
\end{proof}

\end{comment}

Let us now consider some examples of the method of stationary phase in one dimension.

\begin{example}
  The Bessel function of order $m$, denoted $J_m(r)$, is defined to be the oscillatory integral
  %
  \[ J_m(r) = \frac{1}{2\pi} \int_0^{2\pi} e^{i r \sin(\theta)} e^{-i m \theta} d\theta. \]
  %
  We want to use the method of stationary phase to determine the decay of $J_m(r)$ as $r \to \infty$. The amplitude is $\psi(\theta) = (1/2\pi) e^{-im \theta}$, and the phase is $\phi(\theta) = \sin(\theta)$. We note that the phase $\phi(\theta) = \sin(\theta)$ is stationary when $\theta = \pi/2$ and $\theta = 3\pi/2$, and that these stationary points are nondegenerate. Thus we might expect $|J_m(r)| = O_m(r^{-1/2})$. More precisely, we write $1 = \psi_1 + \psi_2 + \psi_3$, where $\psi_1$ is supported in a small neighbourhood of $\pi/2$, $\psi_2$ in a neighbourhood of $3\pi/2$, and $\psi_3$ is supported away from $\pi/2$ and $3\pi/2$. This oscillatory integral is defined over an integral, but the integrand is periodic, so an integration by parts verifies that since $\psi_3$ is supported away from stationary points, for any $N > 0$,
  %
  \[ \frac{1}{2\pi} \int_0^{2\pi} e^{i r \sin(\theta)} e^{-i m \theta} \psi_3(\theta)\; d\theta = O_N(r^{-N}). \]
  %
  Next, we verify using our formula for the stationary phase that
  %
  \begin{align*}
    \frac{1}{2\pi} \int & e^{i r \sin(\theta)} e^{-i m \theta} \psi_1(\theta)\; d\theta\\
    &= \left( \frac{2\pi}{-i \phi''(\pi/2)} \right)^{1/2} \cdot (1/2\pi) e^{i r \sin(\pi/2)} e^{-i m (\pi/2)} \cdot r^{-1/2} + O_m(r^{-3/2})\\
    &= (2\pi)^{-1/2} e^{i(r - m\pi/2 - \pi/4)} r^{-1/2} + O_m(r^{-3/2}).
  \end{align*}
  %
  Similarily,
  %
  \begin{align*}
    \frac{1}{2\pi} \int & e^{i r \sin(\theta)} e^{-i m \theta} \psi_2(\theta)\; d\theta\\
    &= \left( \frac{2\pi}{-i \phi''(3\pi/2)} \right)^{1/2} \cdot (1/2\pi) e^{i r \sin(3\pi/2)} e^{-i m (3\pi/2)} \cdot r^{-1/2} + O_m(r^{-3/2})\\
    &= (2\pi)^{-1/2} e^{-i(r - m\pi/2 - \pi/4)} r^{-1/2} + O_m(r^{-3/2}).
  \end{align*}
  %
  Summing up the three estimates, we conclude
  %
  \[ J_m(r) = (2/\pi r)^{1/2} \cos(r - m\pi/2 - \pi/4) + O_m(r^{-3/2}). \]
\end{example}

\begin{example}
  Consider the Airy function
  %
  \[ \text{Ai}(x) = \int_{-\infty}^\infty e^{i(x \xi + \xi^3/3)}\; d\xi, \]
  %
  which arises as a solution to the differential equation $y'' = xy$. Again, this integral is not defined absolutely. Nonetheless, for a large $N$, an integration by parts shows that for any finite interval $I$ containing only points $x$ with $|x| \geq N$,
  %
  \[ \int_I e^{i(x \xi + \xi^3/3)}\; d\xi = O(1/N), \]
  %
  where the implicit constant is independant of $I$. Thus we can interpret the integral as
  %
  \[ \lim_{n \to \infty} \int_{a_n}^{b_n} e^{i(x \xi + \xi^3/3)}\; d\xi, \]
  %
  where $\{ a_n \}$ and $\{ b_n \}$ are any sequences with $a_n \to -\infty$, $b_n \to \infty$.

  Now consider the phase $\phi(\xi) = x \xi + \xi^3/3$. Then $\phi'(\xi) = x + \xi^2$. When $x$ is negative, there are two stationary points. Thus we can rescale the integral, writing $\nu = x^{-1/2} \xi$, so that
  %
  \[ \text{Ai}(-x) = x^{1/2} \int_{-\infty}^\infty e^{i x^{3/2}(\nu^3/3 - \nu)}\; d\nu. \]
  %
  If we write $\phi_0(\nu) = \nu^3/3 - \nu$, then $\phi_0$ has two stationary points, at $\nu = \pm 1$. These stationary points are non-degenerate, so if we write $1 = \psi_1 + \psi_2 + \psi_3 + \psi_4$, where $\psi_1$ equal to one in a neighbourhood of $1$, $\psi_2$ equal to one in a neighbourhood of $-1$, and $\psi_3$ is supported in the region between $-1$ and $1$, and $\psi_4$ vanishes in all such regions, then we decompose $\text{Ai}(-x)$ as $I_1 + I_2 + I_3 + I_4$. Now the principle of stationary phase tells us that
  %
  \[ I_1 = \pi^{1/2} x^{-1/4} e^{i \pi/4} e^{-2i x^{3/2}/3} + O(x^{-1}) \]
  %
  and
  %
  \[ I_2 = \pi^{1/2} x^{-1/4} e^{-i\pi/4} e^{2i x^{3/2}/3} + O(x^{-1}). \]
  %
  Moreover, $I_3 = O_N(x^{-N})$ for all $N \geq 0$. It remains to show $I_4 = O(x^{-1})$. Indeed, an integration by parts shows that
  %
  \begin{align*}
    I_4 &= x^{1/2} \int_{-\infty}^\infty e^{i x^{3/2} \phi_0(\nu)} \psi_4(\nu)\; d\nu\\
    &= \frac{i}{x} \int_{-\infty}^\infty e^{i x^{3/2} \phi_0(\nu)} \frac{d}{d\nu} \left( \frac{\psi_4(\nu)}{\nu^2 - 1} \right)\; d\nu.
  \end{align*}
  %
  Taking in absolute values shows $|I_4| \lesssim 1/x$. Thus as $x \to \infty$,
  %
  \[ \text{Ai}(-x) = 2 \pi^{1/2} x^{-1/4} \cos((2/3) x^{3/2} - \pi/4) + O(1/x), \]
  %
  which gives the first order asymptotics of the integral.

  On the other hand, let us consider large positive $x$. Then the phase $\phi$ has no critical points, and we therefore expect very fast decay. To achieve this decay, we employ a contour shift, replacing the oscillatory integral with a different oscillatory integral which \emph{has} a stationary point, so we can obtain asymptotics here. If we write $\phi(z) = xz + z^3/3$, then $\phi'(z) = 0$ when $z = \pm i x^{1/2}$. A simple contour shift argument to the line $\RR + i x^{1/2}$ gives
  %
  \begin{align*}
    \text{Ai}(x) &= \int_{-\infty}^\infty e^{i \phi(\xi + ix^{1/2})}\; d\xi\\
    &= e^{-(2/3)x^{3/2}} \int_{-\infty}^\infty e^{-\xi^2 x^{1/2}} e^{i \xi^3/3}\; d\xi.
  \end{align*}
  %
  We have
  %
  \[ \int_{-\infty}^\infty e^{-\xi^2 x^{1/2}} e^{i \xi^3/3}\; d\xi \approx x^{-1/4} \int_{-\infty}^\infty e^{-\xi^2} e^{i x^{-3/4} \xi^3/3}\; d\xi. \]
  %
  Now a Taylor series shows
  %
  \[ e^{i x^{-3/4} \xi^3/3} = 1 + O(x^{-3/4} \xi^3/3), \]
  %
  so, plugging in, we conclude
  %
  \[ \text{Ai}(x) = \pi^{1/2} x^{-1/4} e^{-(2/3) x^{3/2}} + O(x^{-3/4} e^{-(2/3) x^{3/2}}). \]
  %
  Thus Airy's function decreases exponentially as $x \to \infty$.
\end{example}

\begin{example}
  Let us consider the integral quantities
  %
  \[ \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx \]
  %
  where to avoid technicalities we assume $0 \leq \gamma < 2$. These integral quantities are not defined absolutely, so we actually interpret this integral as
  %
  \[ \lim_{\varepsilon \to 0} \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx \]
  %
  If we write $\phi(x) = x \xi + 1/x$, then
  %
  \[ \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx = \int_0^1 e^{i\phi(x)} x^{-\gamma}\; dx. \]
  %
  For $0 < \varepsilon_1 < \varepsilon_2 < \varepsilon$, since $\phi'(x) = \xi - 1/x^2$, an easy integration by parts shows that for $\varepsilon \leq \xi^{-1/2}/2$,
  %
  \begin{equation} \label{riemannsingularityibp}
  \begin{aligned} 
    \int_{\varepsilon_1}^{\varepsilon_2} e^{i\phi(x)} x^{-\gamma}\; dx &= \frac{1}{i \xi} \int_{\varepsilon_1}^{\varepsilon_2} \frac{d}{dx} \left( e^{i \phi(x)} \right) \frac{x^{2-\gamma}}{x^2 - 1/\xi}\; dx\\
    &= \frac{-1}{i \xi} \int_{\varepsilon_1}^{\varepsilon_2} e^{i \phi(x)} \frac{d}{dx} \left( \frac{x^{2-\gamma}}{x^2 - 1/\xi} \right) + O(\varepsilon^{2-\gamma})\\
    &= O(\varepsilon^{2-\gamma}),
  \end{aligned}
  \end{equation}
  %
  where the constant is independent of $\xi$. This implies the limit we study certainly exist. We wish to prove an asymptotic formula for this integral as $\xi \to \infty$. If we write $\phi(x) = x \xi + 1/x$, then
  %
  \[ \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx = \int_0^1 e^{i \phi(x)} x^{-\gamma}. \]
  %
  Since $\phi$ has a nondegenerate stationary point when $x = \xi^{-1/2}$, our heuristics might suggest that if the phase and amplitude were smooth at the origin, then as $\gamma \to \infty$,
  %
  \begin{align*}
    \int_0^1 e^{i\phi(x)} x^{-\gamma} &\approx \left( \frac{2\pi}{-i \phi''(\xi^{-1/2})} \right)^{1/2} e^{i\phi(\xi^{-1/2})} \xi^{\gamma/2}\\
    &= \pi^{1/2} e^{i(2 \xi^{1/2} + \pi/4)} \xi^{\gamma/2 - 3/4}.
  \end{align*}
  %
  We shall show that these heuristics continue to hold, up to an error of $O(\xi^{\gamma/2 - 1})$.

  In an attempt to isolate the critical point, we split the interval $[0,1]$ into three parts, $[0,0.5 \xi^{-1/2}]$, $[0.5 \xi^{-1/2},1.5 \xi^{-1/2}]$, and $[1.5 \xi^{-1/2},1]$, obtaining three integrals $I_1$, $I_2$, and $I_3$. The calculation \eqref{riemannsingularityibp} shows that $|I_1| \lesssim \xi^{\gamma/2 - 1}$, and thus is neglible to our asymptotic formula. To obtain a bound on $I_3$, we use the Van der Corput lemma, noting that $\phi'(x) = \xi - 1/x^2$ is monotone, and $|\phi'(x)| \gtrsim \xi$ for $x \geq 1.5 \xi^{-1/2}$. Thus we find $|I_1| \lesssim \xi^{-1}$, and thus is also neglible to our formula. Thus we are left with the trick part of calculating $I_2$ accurately. It will easiest to do this by renormalizing the integral, i.e. writing $y = \xi^{1/2} x$, and calculating
  %
  \[ I_2 = \int_{0.5 \xi^{-1/2}}^{1.5 \xi^{-1/2}} e^{i \phi(x)} x^{-\gamma}\; dx = \xi^{\gamma/2 - 1/2} \int_{0.5}^{1.5} e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma}\; dy. \]
  %
  We consider a smooth amplitude function $\psi(x)$ supported on the interior of $[0.5,1.5]$. Then since $y + 1/y$ is stationary at $y = 1$, but non-degenerate, we can write
  %
  \[ \int e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma} \psi(y)\; dy = \xi^{-1/4} \pi^{1/2} e^{i(2\xi^{1/2} + 1/4)} + O(\xi^{-1/2}), \]
  %
  from which we obtain our main term. On the other hand, we can apply the Van der Corput lemma to show that
  %
  \[ \int_{0.5}^{1.5} e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma} (1 - \psi(y))\; dy = \int e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma} \psi(y)\; dy = O(\xi^{-1/2}). \]
  %
  Combining all these estimates gives the theorem.

  On the other hand, consider the integral
  %
  \[ I(\xi) = \int_0^1 e^{-i \xi x} e^{i/x} x^{-\gamma}\; dx = \int_0^1 e^{i \phi(x)} x^{-\gamma}, \]
  %
  where $\phi(x) = 1/x - \xi x$ is the phase. Then the phase has no critical points so we can assume that we can large decay for large $\xi$. We decompose the integral onto the intervals $[0,\xi^{-1/2}]$ and $[\xi^{-1/2},1]$, inducing the two quantities $I_1$ and $I_2$. Now applying the Van der Corput lemma to $I_2$ with $|\phi'(x)| = |1/x^2 + \xi| \geq \xi$ for $x \geq 0$, gives $|I_2| \lesssim \xi^{\gamma/2 - 1}$. On the other hand, renormalizing with $y = \xi^{1/2} x$, we have
  %
  \[ I_1 = \xi^{\gamma/2 - 1/2} \int_0^1 e^{i \xi^{1/2} (1/y - y)} y^{-\gamma}\; dy. \]
  %
  For each $n$, we note that for the phase $\phi_0(x) = 1/y - y$, for $1/2^{n+1} \leq y \leq 1/2^n$, we have $|\phi_0'(x)| \gtrsim 4^n$. Thus we can apply the Van der Corput lemma to conclude
  %
  \[ \left| \int_{1/2^{n+1}}^{1/2^n} e^{i \phi_0(x)} y^{-\gamma}\; dy \right| \lesssim \frac{2^{\gamma n}}{4^n \xi^{1/2}}. \]
  %
  Summing up over all $n \geq 0$, we conclude $|I_1| \lesssim \xi^{\gamma/2 - 1}$. Thus $|I(\xi)| \lesssim \xi^{\gamma/2 - 1}$.

  One way to interpret this asymptotic formula is through a \emph{Riemann singularity}, i.e. a tempered distribution $\Lambda$ supported on the half-life $x \geq 0$, that agrees with the oscillatory function $e^{i/x} x^{-\gamma}$ for small $x$, but is compactly supported and smooth away from the origin. We consider the case $0 \leq \gamma < 2$ for simplicity. Thus for Schwartz $f \in \mathcal{S}(\RR)$, we have
  %
  \[ \Lambda(f) = \lim_{\varepsilon \to 0^+} \int_\varepsilon^\infty f(x) e^{i/x} x^{-\gamma} \psi(x)\; dx, \]
  %
  where $\psi$ is smooth and compactly supported, and equals one in a neighbourhood of the origin. An easy integration by parts shows that for a fixed Schwartz $f$, and for $0 < \varepsilon_1 < \varepsilon_2 < \varepsilon$,
  %
  \[ \left| \int_{\varepsilon_1}^{\varepsilon_2} f(x) e^{i/x} x^{-\gamma}\; dx \right| = O\left(\varepsilon^{2-\gamma} \right), \]
  %
  where the implicit constants depend on upper bounds for $f$ and $f'$ in a neighbourhood of the origin. Thus we find $\Lambda(f)$ is well defined, and moreover, $\Lambda$ is a distribution of order one. Since $\Lambda$ is compactly supported, the Paley-Weiner theorem implies that $\widehat{\Lambda}$ is a distribution represented by a locally integrable function, and
  %
  \[ \widehat{\Lambda}(\xi) = \int_0^\infty e^{i/x} x^{-\gamma} \psi(x) e^{-2 \pi \xi i x}\; dx. \]
  %
  Our asymptotics under some small modifications tell us that if $\xi$ is large, then
  %
  \[ \widehat{\Lambda}(-\xi) = 2^{\gamma/2 - 3/4} \pi^{\gamma/2-1/2} e^{i(2^{3/2} \pi^{1/2} \xi^{1/2} + \pi/4)} \xi^{\gamma/2 - 3/4} + O(\xi^{\gamma/2 - 1}). \]
  %
  On the other hand,
  %
  \[ \widehat{\Lambda}(\xi) = O(\xi^{\gamma/2 - 1}), \]
  %
  so the Fourier transform of $\Lambda$ decays much faster to the right than to the left.
\end{example}

\section{Stationary Phase in Multiple Variables}

When we move from a single variable oscillatory integral to a multivariable oscillatory integrals. Thus we consider the oscillatory integral
%
\[ I(\lambda) = \int_{\RR^d} \psi(x) e^{\lambda i \phi(x)}\; dx. \]
%
for large $\lambda$. The method of stationary phase becomes significantly more complicated in this setting because the stationary points of the phase function are no longer necessarily isolated. In certain basic situations, however, we can obtain simple results.

\begin{theorem}
  Let $\phi$ and $\psi$ be smooth functions on $\RR^d$, with $\psi$ compactly supported. If $\nabla \phi$ is nowhere vanishing on the support of $\psi$, then for each $N$, $|I(\lambda)| \lesssim_N \lambda^{-N}$ for all $N$.
\end{theorem}

\begin{proof}
    Set $a = (\nabla \phi)/|\nabla \phi|^2$. Note that $\nabla e^{\lambda i \phi(x)} = (i\lambda) e^{\lambda i \phi(x)} \nabla \phi(x)$ is an eigenfunction of the differential operator $D$ defined such that
    %
    \[ Df(x) = \frac{a \cdot \nabla f}{i \lambda}. \]
    %
    The adjoint operator of $D$ is the operator $D^*$ defined by setting
    %
    \[ D^*f(x) = \frac{\nabla \cdot (af)}{-i\lambda}, \]
    %
    i.e. for any smooth $f$ and $g$, with one of these functions compactly supported,
    %
    \[ \int Df(x) g(x)\; dx = \int f(x) (D^*g)(x)\; dx. \]
    %
    Thus
    %
    \[ I(\lambda) = \int D^N(e^{i \lambda \phi(x)}) \psi(x)\; dx = \int e^{i \lambda \phi(x)} ((D^*)^N\psi)(x)\; dx. \]
    %
    Taking absolute values in the last integral gives that
    %
    \[ |I(\lambda)| \leq \int |(D^*)^N \psi(x)|\; dx \lesssim_{\phi,\psi,N} \frac{1}{\lambda^N}. \qedhere \]
\end{proof}

\begin{remark}
  The implicit constants for a fixed $N$ can be uniformly bounded given a uniform lower bound on $|\nabla \phi|$, and upper bounds on the derivatives of $\phi$ up to order $N+1$, on $\psi$ up to order $N$, and on the measure of the support of $\psi$.
\end{remark}

A tensorization argument establishes the result for a quadratic phase.

\begin{theorem}
  Let $A$ be an invertible $d \times d$ matrix, fix $x_0 \in \RR^d$, and consider the phase $\phi(x) = A(x - x_0) \cdot (x - x_0)$. Then for any compactly supported smooth amplitude $\psi$, there exists constants $\{ a_n \}$ depending only on the derivatives of $\psi$ at the origin, such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-d/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_N(1/\lambda^{N+d/2 +1}). \]
  %
  Moreover,
  %
  \[ a_0 = \frac{(2\pi)^{d/2} \psi(x_0)}{(-i \mu_1)^{1/2} \dots (-i \mu_d)}, \]
  %
  where $\mu_1, \dots, \mu_d$ are the eigenvalues of $A$.
\end{theorem}
\begin{proof}
  Suppose first that $\psi$ is a tensor product of $d$ compactly supported functions in $\RR$. The constant $a_0$ is invariant under affine changes of coordinates. Thus we may assume that $A$ is a diagonal matrix. But then the oscillatory integral splits into the product of single variable integrals, to which we can apply our one-dimensional asymptotics. Since the asymptotics here depend only on the support of $\psi$, and upper bounds on the magnitude of $\psi$ on derivatives up to order $2N + 4$. A density argument then shows the argument generalizes to any smooth $\psi$, with implicit constants depending on upper bounds on the measure of the support of $\psi$, and upper bounds on the derivative of $\psi$ of order up to $2N + (d + 4)$.
\end{proof}

Morse's theorem says that if $x_0$ is a non-degenerate critical point of a smooth function $\phi$, then there exists a coordinate system around $x_0$ and $a_1, \dots, a_d \in \{ \pm 1 \}$ such that, in this coordinate system,
%
\[ \phi(x_0 + t) = a_1 t_1^2 + \dots + a_d t_d^2. \]
%
In one dimension, the same is true if $x_0$ has a higher order critical point, but this does not generalize to higher dimensions, which reflects the lack of as nice a theory in this case. But in the case of functions with finitely many non-degenerate critical points, we can obtain nice asymptotics. Applying Morse's theorem gives the following theorem.

\begin{theorem}
  Let $\phi$ and $\psi$ be smooth functions, with $\psi$ compactly supported. Suppose $\phi$ has only finitely many critical points on the support of $\psi$, each of which being nondegenerate. Then there exists constants $\{ a_n \}$ depending only on finitely many derivatives of $\Phi$ and $\psi$ at the points $x_1, \dots, x_n$, such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-d/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_N(1/\lambda^{N+d/2 +1}). \]
  %
  Moreover, if the critical points of $\psi$ are $x_1, \dots, x_m$, then
  %
  \[ a_0 = \sum_{k = 1}^m \frac{(2\pi)^{d/2} \psi(x_k)}{\prod_{l = 1}^m (-i \mu_l(x_k))^{1/2}}, \]
  %
  where $\mu_1(x_k), \dots, \mu_d(x_k)$ are the eigenvalues of the Hessian of $\phi$ at $x_k$.
\end{theorem}

\section{Surface Carried Measures}

Let us consider oscillatory integrals on a `curved' version of Euclidean space. One most basic example is the Fourier transform of the surface measure of the sphere, i.e.
%
\[ \widehat{\sigma}(\xi) = \int_{S^{d-1}} e^{-2 \pi i \xi x} d\sigma(x). \]
%
Studying the decay of this surface measure is of much interest to many problems in analysis. One can reduce the study of this Fourier transform to the study of Bessel functions, to which we have already developed an asymptotic theory.

\begin{theorem}
  If $\sigma$ is the surface measure on the sphere $S^{d-1}$, then
  %
  \[ \widehat{\sigma}(\xi) = \frac{2\pi \cdot J_{d/2 - 1}(2 \pi |\xi|)}{|\xi|^{d/2 - 1}}. \]
  %
  In particular,
  %
  \[ \widehat{\sigma}(\xi) = \frac{2 \cos(2\pi |\xi| - (d/2 - 1)(\pi/2) - \pi/4)}{|\xi|^{(d-1)/2}} + O_d(1/|\xi|^{(d+1)/2}). \]
\end{theorem}
\begin{proof}
  Since $\sigma$ is rotationally symmetric, so too is $\widehat{\sigma}$. In particular, we can apply Fubini's theorem to conclude that if $V_{d-2}$ is the surface area of the unit sphere in $\RR^{d-2}$, then
  %
  \begin{align*}
    \widehat{\sigma}(\xi) &= \int_{S^{d-1}} e^{-2 \pi |\xi| x_1} d\sigma(x)\\
    &= V_{d-2} \int_{-1}^1 e^{-2 \pi |\xi| t} (1 - t^2)^{d/2-1} dt.
  \end{align*}
  %
  Setting $r = 2 \pi |\xi|$ completes the argument.
\end{proof}

Since the multivariate stationary phase approach is essentially `coordinate independant', we can also generalize the approach to manifolds. If $M$ is a $d$ dimensional Riemmannian manifold, and $\phi$ and $\psi$ are complex-valued functions on the manifold, we can consider the oscillatory integral
%
\[ I(\lambda) = \int_M e^{\lambda i \phi(x)} \psi(x) d\sigma(x), \]
%
where $\sigma$ is the surface measure induced by the metric on $M$. If $\phi$ and $\psi$ are compactly supported, then this integral is well defined in the Lebesgue sense.

\begin{theorem}
  Suppose that $\psi$ is a compactly supported smooth amplitude on a Riemannian manifold $M$, $\phi$ is a smooth phase, and $\nabla \phi$ vanishes on at most finitely many points $x_1, \dots, x_m$ on the support of $\psi$, upon each of which the Hessian $H\phi$ is non-degenerate at each point. Then there exists constants $\{ a_n \}$ such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-d/2} \sum_{n = 0}^N a_n \lambda^{-n} + O(1/\lambda^{N + d/2 + 1}). \]
  %
  Moreover,
  %
  \[ a_0 = \sum_{k = 1}^m \frac{(2\pi)^{d/2} \psi(x_k)}{\prod_{l = 1}^m (-i \mu_l(x_k))^{1/2}}, \]
  %
  where $\mu_1, \dots, \mu_d$ are the eigenvalues of the Hessian $H\phi$.
\end{theorem}

The theorem is proved by a simple partition of unity approach which reduces to the Euclidean case. It has the following important corollary.

\begin{theorem}
  If a surface $\Sigma$ is a smooth submanifold of $\RR^{d+1}$, and has non-vanishing Gauss curvature, and if $\psi$ is a smooth, compactly supported function on $\Sigma$, then
    %
    \[ |\widehat{\psi \sigma}(\xi)| \lesssim_{\psi,\sigma} \frac{1}{|\xi|^{d/2}}, \]
    %
    where $\sigma$ is the surface measure of $\Sigma$.
\end{theorem}
\begin{proof}
  For each $\xi \in S^d$,
  %
  \[ I_\xi(\lambda) = \int_M e^{\lambda i \phi_\xi(x)} \psi(x)\; d\sigma, \]
  %
  where $\phi_\xi(x) = -2 \pi i \xi \cdot x$. The derivatives of $\phi_\xi$ of order $\leq N$ on $M$ are $O_N(1)$, independently of $\xi$. Similarily, $H_M \phi_\xi$ is uniformly non-degenerate, in the sense that the operator norm of $(H_M \phi_\xi)^{-1}(x)$ is $O(1)$, independently of $\xi$. Working with $\Sigma$ as a local graph, and then applying the curvature condition on $\Sigma$ implies that for each $\xi \in S^d$, $\phi_\xi$ has $O(1)$ stationary points on the support of $\psi$. There also exists a constant $r$ such that if $x$ does not lie in any ball of radius $r$ around a stationary point, then $|\nabla_M \phi_\xi| \gtrsim 1$. Moreover, the Hessian $H_M \phi_\xi$ is uniformly non-degenerate in the radius $r$ balls around the critical point, independently of $\xi$. Thus we can apply the last result to conclude
  %
  \[ I_\xi(\lambda) \lesssim \lambda^{-d/2}, \]
  %
  where the implicit constant is independent of $\xi$, because all the required derivatives are uniformly bounded.
\begin{comment}

  Working locally, since the support of $\mu$ is precompact, we may consider a finite partition of unity $\{ \psi_\alpha \}$ with respect to an open family of sets $\{ U_\alpha \}$ covering $U$, such that for each $\alpha$, there exists a transformation $T$ composed of a rotation, translation, and dilation such that if $B$ is the open unit ball, then there is a smooth function $u: B \to \RR$ with $\nabla u(0) = 0$, such that
  %
  \[ T(U_\alpha) = \left\{ (x,u(x)): x \in B \right\}. \]
  %
  The fact that $\Sigma$ has non-vanishing Gauss curvature implies that the Hessian of $u$ is non-zero at each point, so in particular we may assume that $\nabla u$ does not equal to zero anywhere else on $B$. The asymptotics of the Fourier transform of $\mu \psi_\alpha$ is the same as the Fourier transform of the measure $T_*(\mu \psi_\alpha)$, so we may assume without loss of generality that $U_\alpha$ takes the form $T(U_\alpha)$. Then
  %
  \[ d\sigma = (1 + |\nabla u|^2)^{1/2}\; dx^1 \dots dx^d, \]
  %
  which can be incorporated into $\psi_\alpha$. Thus it suffices to show that for each $\xi = (\xi_0, \xi_1) \in \RR^d$,
  %
  \[ \left| \int_B e^{-2 \pi i(\xi_0 \cdot x + \xi_1 u(x))} \psi(x)\; dx \right| \lesssim_{\psi,u} \frac{1}{(|\xi_0|^2 + \xi_1^2)^{d/4}}. \]
  %
  Let us fix $\xi \in S^d$, and consider the oscillatory integral
  %
  \[ I_\xi(\lambda) = \int_B e^{\lambda i \phi_\xi(x)} \psi(x)\; dx, \]
  %
  where
  %
  \[ \phi_\xi(x) = -2\pi \left( \xi_0 \cdot x + \xi_1 u(x) \right). \]
  %
  Note that
  %
  \[ \nabla \phi_\xi(x) = -2\pi(\xi_0 + \xi_1 \nabla u(x)) \]
  %
  The inverse function theorem combined with our curvature condition tells us that if we choose our neighbourhoods $U_\alpha$ small enough, the map $x \mapsto \nabla u(x)$ is a smooth diffeomorphisms on $B$. In particular, for each $\xi$, there is at most one $x \in B$ such that $\phi_\xi$ is stationary at $x$. Even without the curvature condition, we can conclude that for each $x$, there is at most one $\xi \in S^d$, up to a negation, such that $\phi_\xi$ is stationary at $x$.

  Because of the curvature condition, one can verify that for each $\xi \in \RR^d$, there are $O(1)$ stationary points for the phase $\phi_\xi$. Moreover, if 

  In particular, we conclude that for each $\xi$, there are $O(1)$ stationary points for the phase $\phi(\cdot | \xi)$ on the support of $\psi$.

  The curvature condition implies that, if we have chosen are neighbourhoods small enough, for each $\xi$ there is at most one $x \in B$ such $\phi(\cdot|\xi)$ is stationary at $x$.

  Then $\nabla_x \phi(x|\xi) = -2\pi( \xi_0 + \xi_1 \nabla u(x) )$. In particular, $\phi(\cdot|(0,1))$ has a stationary point at $0$. If we consider $D_x[\nabla_x \phi(x|\xi)] = -2\pi  \xi_1 H_x u(x)$, which is nonsingular by assumption in a neighbourhood of $(0,1)$. Thus there exists a relatively open set $V_\alpha \subset S^d$


  Applying the implicit function theorem, having chosen our sets $\psi_\alpha$ small enough, there exists a relatively open set $V_\alpha \subset S^d$ containing $(0,1)$ such that for each $\xi = (\xi_0,\xi_1) \in V_\alpha$, there is a unique $x(\xi) \in B$ such that $\nabla_x \phi(x(\xi)|\xi) = 0$

  such that for each $\xi \in \RR^d$ and $\alpha$, there is at most one point $x \in U_\alpha$ such that $\xi$ is orthogonal to $T_x(M)$. Moreover, we can find a relatively open subset $V_\alpha$ of $S^{d-1}$ such that for each $\xi \in V_\alpha$, there exists a unique $x \in U_\alpha$ such that $\xi$ is orthogonal to $T_x(M)$.

  we can write
  %
  \[ \widehat{\mu}(\xi) = \sum_\alpha \int e^{-2 \pi i \xi \cdot x} \psi_\alpha(x)\; d\mu. \]
  %


  $\Sigma$ is the smooth graph of a function $f: B \to \RR$, where $B$ is the closed unit ball in $\RR^d$, i.e.
  %
  \[ \Sigma = \{ (x,t) : x \in B, t = f(x) \}. \]
  %
  Then $d\sigma = (1 + |\nabla f|^2)^{1/2} dx^1 \dots dx^d$, and the fact that $\Sigma$ has non-vanishing Gauss curvature implies that the Hessian of $f$ is non-degenerate. It thus suffices to obtain a bound of the form
  %
  \[ \int e^{i (\xi \cdot x) + \eta f(x)} \psi(x)\; dx \lesssim_{\psi} \frac{1}{\sqrt{|\xi|^2 + \eta^2}}. \]
  %
  where $\psi$ is a compactly supported, smooth function on $B$. Fix $(\xi_0, \eta_0)$ such that $\xi_0^2 + \eta_0^2 = 1$, and consider the oscillatory integral
  %
  \[ I(\lambda) = \int_B e^{\lambda i (\xi_0 \cdot x) + \eta_0 f(x)} \psi(x)\; dx \]
  %
  This is an oscillatory integral with phase $\phi(x;\xi_0,\eta_0) = (\xi_0 \cdot x) + \eta_0 f(x)$.

  We are considering the oscillatory integral
  %
  \[ \int e^{-2 \pi i \xi x} d\Sigma(x). \]
  %
  If $\phi(x) = x \cdot \xi$. The nondegeneracy of the Hessian of $\phi$ on the support of $\mu$ corresponds precisely to the nonvanishing of the curvatures of $\Sigma$ on $\mu$. Then we may find a family of 
\end{comment}
\end{proof}

If $\Omega$ is a bounded open subset of $\RR^{d+1}$ whose boundary is a Riemannian manifold with non-zero Gaussian curvature at each point, then it's Fourier transform has decay one order better than the Fourier transform of it's boundary.

\begin{corollary}
  If $\Omega$ is a bounded open subset of $\RR^d$ whose boundary is a Riemannian manifold $\Sigma$ with non-zero Gaussian curvature at each point. If $I_\Omega$ is the indicator function on $\Omega$, then
  %
  \[ |\widehat{I_\Omega}(\xi)| \lesssim_\Omega |\xi|^{-d/2}. \]
\end{corollary}
\begin{proof}
  We have
  %
  \[ \widehat{I_\Omega}(\xi) = \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx \]
  % u div(V) dV = u (V . n) dS - Grad(u) . V dV
  % As long as V is smooth and div(V) is fine
  % If u = e^{-2 \pi i \xi . x}, Grad(u) = (-2\pi i \xi) e^{-2 \pi i \xi . x}
  % If V(x) = x_1
  %
  Then we can apply Stoke's theorem for each $1 \leq k \leq d+1$ to conclude
  %
  \[ \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx = \frac{(-1)^k}{2 \pi i \xi_k} \int_\Sigma e^{-2 \pi i \xi \cdot x} (dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n). \]
  %
  For each $k$, there is a smooth function $\psi_k$ such that
  %
  \[ dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n = \psi_k d\sigma. \]
  %
  Thus applying the last case, we find
  %
  \[ \left| \frac{(-1)^k}{2 \pi i \xi_k} \int_\Sigma e^{-2 \pi i \xi \cdot x} (dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n) \right| \lesssim \xi_k^{-1} |\xi|^{-(d-1)/2}. \]
  %
  At each point $\xi$, if we choose $\xi_k$ with the largest value, then $|\xi_k| \sim |\xi|$, so
  %
  \[ \left| \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx \right| \lesssim |\xi|^{-(d+1)/2}. \qedhere \]
\end{proof}

The fact that curved surfaces have Fourier decay has many consequences in harmonic analysis.

\begin{example}
  If $M$ is a hypersurface in $\RR^d$, and $\psi$ is a smooth, compactly supported function on $M$, and $f$ is a smooth, compactly supported function on $\RR^d$, we can define a function $Af$ on $\RR^d$ by defining
  %
  \[ (Af)(y) = \int_M f(y - x) \psi(x)\; d\sigma(x). \]
  %
  We note that $Af$ is really the convolution of $f$ with $\psi \sigma$. Thus
  %
  \[ \widehat{Af}(\xi) = \widehat{f}(\xi) \widehat{\psi d\sigma}(\xi). \]
  %
  For each multi-index $\alpha$, the derivative $(Af)_\alpha$ is equal to
  %
  \[ \int_M f_\alpha(y-x) \psi(x)\; d\sigma(x) = f_\alpha * (\psi \sigma). \]
  %
  In particular, we have
  %
  \[ \widehat{(Af)_\alpha} = (2 \pi i \xi)^\alpha \widehat{f}(\xi) \widehat{\psi \sigma}(\xi). \]
  %
  Since we have shown
  %
  \[ |\widehat{\psi \sigma}(\xi)| \lesssim |\xi|^{-(d-1)/2}, \]
  %
  we conclude that if $|\alpha| \leq k$, where $k = (d-1)/2$,
  %
  \[ \| (Af)_\alpha \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)}. \]
  %
  In particular, this implies that $A$ extends to a unique bounded operator from $L^2(\RR^d)$ to $L^2_k(\RR^d)$, i.e. to a map such that for each $f \in L^2(\RR^d)$, $Af$ is a square integrable function which has square integrable weak derivatives of all orders less than or equal to $k$, and moreover, $\| (Af)_\alpha \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)}$ for all $|\alpha| \leq k$. Thus the operator $A$ is `smoothening', in a certain sense.

  The operator $A$ is obviously bounded from $L^1(\RR^d)$ to $L^1(\RR^d)$ and $L^\infty(\RR^d)$ to $L^\infty(\RR^d)$, purely from the fact that $\psi \sigma$ is a finite measure. Using curvature and some analytic interpolation, we will now also show that $A$ is bounded from $L^p(\RR^d)$ to $L^q(\RR^d)$, where $p = (d+1)/d$, and $q = d+1$. Interpolation thus yields a number of intermediate estimates. The trick here is to obtain an $(L^1,L^\infty)$ bound for an `improved' version of $A$, and an $(L^2,L^2)$ bound for a `worsened' version of $A$. Interpolating between these two results gives a bound for precisely $A$. It suffices to prove this bound `locally' on $M$, since we can then sum up these bounds, so we may assume that $M$ is given as the graph of some function, i.e. there exists $u$ such that
  %
  \[ M = \{ (x,u(x)):  \} \]


  For each $s$, we write $A_sf = K_s * f$, where
  %
  \[ K_s(x) = \gamma_s |x_d - \phi(x')|_+^{s-1} \psi_0(x). \]
  %
  Here $\gamma_s = s \dots (s + N) e^{s^2}$, where $N$ is some large parameter to be fixed in a moment. The $e^{s^2}$ parameter is to mitigate the growth of $\gamma_s$ as $|\text{Im}(s)| \to \infty$, which allows us to interpolate. The quantity $|u|_+^{s-1}$ is equal to $u^{s-1}$ where $u > 0$, and is equal to 0 when $u \leq 0$. And $\psi_0(x) = \psi(x) (1 + |\nabla_{x'} \phi(x')|^2)^{1/2}$.
\end{example}





\section{Restriction Theorems}

If $f \in L^p(\RR^n)$, then the Hausdorff Young theorem says that $\widehat{f}$ is a function in $L^q(\RR^n)$, where $q$ is the dual of $p$. If $f \in L^1(\RR^n)$, then $\smash{\widehat{f}}$ is actually continuous, so you can meaningfully discuss the behaviour of the Fourier transform when restricted to low dimensional hypersurfaces, for instance, on a sphere of a fixed radius. However, in general $\widehat{f}$ will only be defined almost everywhere, and so it is unclear whether one can form a well defined restriction of the Fourier transform.

The general situation is as follows. If $\mu$ is a measure carried on a compact surface $M$, for a fixed $p$, does there exist an estimate 
%
\[ \| \widehat{f} \|_{L^q(M,\mu)} \lesssim \| f \|_{L^p(\RR^n)} \]
%
for Schwartz functions $f$. If this is true, we can apply a density argument to show that the restriction operator $\smash{R(f) = \widehat{f}|_M}$ uniquely extends to a well defined continuous linear operator from $L^p(\RR^n)$ to $L^q(M,\mu)$.

We begin by determining a duality result to the restriction calculation. Assuming our functions are suitably regular, we calculate
%
\begin{align*}
    \int_M (Rf)(\xi) \overline{g(\xi)}\; d\mu(\xi) &= \int_M \left( \int_{\RR^n} f(x) e(- \xi \cdot x)\; dx \right) \overline{g(\xi)}\; d\mu(\xi)\\
    &= \int_{\RR^n} f(x) \overline{\int_M g(\xi) e(\xi \cdot x)\; d\mu(\xi)}\; dx 
\end{align*}
%
which implies the formal adjoint of the map $R$ is the \emph{extension operator}
%
\[ (R^* f)(x) = \int_M e(\xi \cdot x) f(\xi) d\mu(\xi) \]
%
which extends a function in frequency space supported on $M$ to a function on the entirety of phase space. By duality properties, $R$ is continuous as an operator from $L^p(\RR^n)$ to $L^q(M,\mu)$ if and only if $R^*$ is continuous as an operator from $L^{q^*}(M,\mu)$ to $L^{p^*}(\RR^n)$. We also calculate
%
\[ ((R^* R)f)(x) = \int_{\RR^n} \left( \int_M e(\xi \cdot (x-y))\; d\mu(\xi) \right) f(y)\; dy = \left( f * \widecheck{\mu} \right)(x) \]
%
So if $R$ is $(p,2)$ continuous, $R^*$ is $(2,p^*)$ continuous, and so $R^*R$ is $(p,p^*)$ continuous. Conversely, if we know that $R^*R$ is $(p,p^*)$ continuous, then we find that for $f \in L^p(\RR^n)$, H\"{o}lder's inequality implies
%
\[ \| Rf \|_{L^2(M,\mu)}^2 = (Rf,Rf)_M = ((R^* R)f, f)_{\RR^d} \leq \| R^*R \|_{p \to p^*} \| f \|_p^2 \]
%
and so we conclude that $\| R \|_{p \to 2} \leq \sqrt{\| R^* R\|_{p \to p^*}}$.

We now prove that $R$ is $(2n+2/n+3, 2)$ continuous, assuming that $M$ has non-zero Gaussian curvature at each point. The previous paragram implies that it suffices to show that it is enough to show that $R^*R$ is $(p,p^*)$ continuous, where $p = (2n+2)/(n+3)$ and $p^* = (2n+2)/(n-1)$. Since
%
\[ (R^*R)(f) = f * \widecheck{\mu} \]
%
We shall verify this using Stein's interpolation theorem. Consider the family of kernels $k_s$, where $\smash{k_s = \widecheck{K_s}}$, and $K_s = \gamma_s |x_n - \varphi(x')|^{s-1}_+ \varphi_0(x)$, where $\gamma_s = s(s+1) \dots (s + N) e^{s^2}$








\chapter{Maximal Averages Over Curves}

\section{Averages over a Parabola}

Given any measurable function $f: \RR^2 \to \CC$ we can consider the maximal average
%
\[ (Mf)(x,y) = \sup_{\varepsilon > 0} \frac{1}{2\varepsilon} \int_{-\varepsilon}^\varepsilon|f(x+t,y+t)|\; dt. \]
%
Thus $Mf$ gives a maximal average over parabolas. Our goal is to show $\| Mf \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)}$ for $1 < p < \infty$.

It will be convenient to look at the operator
%
\[ \tilde{M} f(x,y) = \sup_{\varepsilon > 0} \frac{1}{2\varepsilon} \int_{\varepsilon/2}^{\varepsilon} |f(x+t,y+t^2)|\; dt. \]
%
A dyadic decomposition shows that $L^p$ bounds for $\tilde{M}$ imply $L^p$ bounds for $M$.

For each $k \in \ZZ$, let $\tilde{M_k} f(x,y) = 2^{-k} \int_{2^k}^{2^{k+1}} f(x+t,y+t^2)\; dt$. Rescaling shows that
%
\[ \| \tilde{M}_k \|_{L^p(\RR^2) \to L^p(\RR^2)} = \| \tilde{M}_0 \|_{L^p(\RR^2) \to L^p(\RR^2)} \]
%
so it suffices to focus on $\tilde{M}_0$. The operator is translation invariant and therefore has a Fourier multiplier
%
\[ \tilde{m}(\xi,\eta) = \int_1^2 e^{2 \pi i (\xi t + \eta t^2)}\; dt. \]
%
Note that $\tilde{m}$ is defined by an oscillatory integral with phase $\phi(t) = \xi t + \eta t^2$. We note that $\phi'(t) = \xi + 2 \eta t$, so Van der Corput's lemma implies that for $|\xi| \geq 10|\eta|$,
%
\[ |\tilde{m}(\xi,\eta)| \lesssim \frac{1}{|\xi|}. \]
%
Similarily, $\phi''(t) = 2 \eta$, so we find
%
\[ |\tilde{m}(\xi,\eta)| \lesssim \frac{1}{|\eta|^{1/2}}. \]
%
If $f \in L^2(\RR^2)$ and $\widehat{f}$ is supported on the region
%
\[ E_0 = \{ (\xi,\eta) : |\eta| \geq 1\ \text{or}\ |\xi| \leq 1\ \text{and} |\eta| \geq 10 \} \]
%
then $\| \tilde{m} \|_{L^\infty(E_0)} \lesssim 1$ and so
%
\[ \| \tilde{M}_0 f \|_{L^2(\RR^2)} = \| \tilde{m} \widehat{f} \|_{L^2(\RR^2)} \lesssim \| \widehat{f} \|_{L^2(\RR^2)} = \| f \|_{L^2(\RR^2)}. \]
%
On the other hand, we can decompose $\RR^2 - E_0$ into 

suppose $\widehat{f}$ is supported on the region
%
\[ E_1 = \{ (\xi,\eta) : |\xi| \leq 1\ \text{and}\ |\eta| \leq 10 \}. \]
%
Then the uncertainty principle implies that $f$ is roughly constant on scales $|\Delta x| \leq 1$ and $|\Delta y| \leq 1/10$, which should imply good bounds for the maximal average. More precisely, $\widehat{f}$ is supported on the ellipsoid
%
\[ \left\{ (\xi,\eta) \in \RR^2 : \xi^2/2 + \eta^2/20 \leq 1 \right\}. \]
%
Thus the uncertainty principle implies that $f$ is roughly constant on scales $|\Delta x|^2 \leq 1/2$ and $|\Delta y|^2 \leq 1/20$,
%
\[ s \]
%
\[ \phi(x) = \frac{1}{( 1 + 2 x^2 + 20 y^2 )^N} \]