\documentclass[12pt,reqno]{article}

%\documentclass[dvipsnames,letterpaper,12pt]{article}

\usepackage[margin = 1in]{geometry}
\usepackage{amsmath,amssymb,graphicx,mathabx,accents}
\usepackage{enumerate,mdwlist}

%\setlist[enumerate]{label*={\normalfont(\Alph*)},ref=(\Alph*)}

\numberwithin{equation}{section}

\usepackage{amsthm}
\usepackage{verbatim}

\usepackage{nag}

\DeclareMathOperator{\minkdim}{\dim_{\mathbf{M}}}
\DeclareMathOperator{\hausdim}{\dim_{\mathbf{H}}}
\DeclareMathOperator{\lowminkdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\upminkdim}{\overline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\fordim}{\dim_{\mathbf{F}}}

\DeclareMathOperator{\lhdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\lmbdim}{\underline{\dim}_{\mathbf{MB}}}

\DeclareMathOperator{\RR}{\mathbf{R}}
\DeclareMathOperator{\ZZ}{\mathbf{Z}}
\DeclareMathOperator{\QQ}{\mathbf{Q}}
\DeclareMathOperator{\TT}{\mathbf{T}}

\DeclareMathOperator{\B}{\mathcal{B}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem*{remark}{Remark}

\DeclareMathOperator{\EE}{\mathbf{E}}
\DeclareMathOperator{\PP}{\mathbf{P}}

\DeclareMathOperator{\DQ}{\mathcal{Q}}
\DeclareMathOperator{\DR}{\mathcal{R}}

\newcommand{\psitwo}[1]{\| {#1} \|_{\psi_2(L)}}
\newcommand{\TV}[2]{\| {#1} \|_{\text{TV}({#2})}}








\title{Salem Sets Avoiding Rough Configurations}
\author{Jacob Denson}

\begin{document}

\maketitle

\section{Introduction}

Geometric measure theory explores the relationship between the geometry of a subset of Euclidean space, and regularity properties of the family of Borel measures supported on that set. From the perspective of harmonic analysis, it is often popular to explore what structural information can be gathered from the Fourier analytic properties of measures supported on a set. In this paper, we study the relationship between the Fourier analytic properties of a set and the existence of patterns on the set. In particular, given a `rough pattern', in the sense of \cite{OurPaper}, we construct a family of sets which generically avoids this pattern, and which supports measures with fast Fourier decay.

A useful statistic associated with any Borel set $E \subset \RR^d$ is it's \emph{Fourier dimension}. Given a finite Borel measure $\mu$ on $\RR^d$, we define it's Fourier dimension, $\fordim(\mu)$, to be the supremum of all $s \in [0,d]$ such that
%
\begin{equation} \label{fordim}
    \sup \left\{ |\widehat{\mu}(\xi)| |\xi|^{s/2} : \xi \in \RR^d \right\} < \infty.
\end{equation}
%
The Fourier dimension of a Borel set $E \subset \RR^d$, denoted $\fordim(E)$, is then the supremum of $\fordim(\mu)$, over all Borel probability measures $\mu$ supported on $E$. A particularly tractable family of sets in this scheme are \emph{Salem sets}, those sets whose Fourier dimension agrees with their Hausdorff dimension. Most classical fractal sets are not Salem, often having Fourier dimension zero. Nonetheless, the sets we construct in this paper are Salem.

\begin{theorem} \label{maintheorem}
    Let $0 \leq \alpha < dn$, and let $Z \subset \RR^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Then there exists a compact Salem set $X \subset [0,1]^d$ with dimension
    %
    \[ \beta = \min \left( \frac{nd - \alpha}{n-1}, d \right) \]
    %
    such that for any distinct points $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

\begin{remark}
    Theorem \ref{maintheorem} strengthens the main result of \cite{OurPaper}. Unlike in \cite{OurPaper}, the case of the problem $0 \leq \alpha < d$ is still interesting, since the trivial construction $[0,\pi]^d - \pi(Z)$ is not necessarily a Salem set, where $\pi(x_1, \dots, x_n) = x_1$ is projection onto the first coordinate. For instance, $[0,1] - \QQ$
\end{remark}

A well-known result in this pattern avoidance setting is that sets with large Fourier dimension satisfy many algebraic relations. More precisely, if integer coefficients $m_1, \dots, m_n \in \ZZ$ are fixed, and we consider a compact set $X \subset \RR$ with $\fordim(X) > 2/n$, then the sum set $m_1 X + \dots + m_n X$ contains an open interval. It follows by a slight modification of these coefficients that if $X \subset \RR$ and $\fordim(X) > 2/n$, then there exists $m_1, \dots, m_n \in \ZZ$, distinct points $x_1, \dots, x_n \in X$, and an additional integer $a \in \ZZ$, such that
%
\begin{equation} \label{intequation}
    m_1 x_1 + \dots + m_n x_n = a.
\end{equation}
%
It is an interesting to determine how tight this result is. In \cite{Korner2}, T.W. K\"{o}rner constructs a Salem set $X$ with Fourier dimension $1/(n-1)$ such that for non-zero $m \in \ZZ^n$, and $a \in \ZZ$, $X$ does not contain distinct points $x_1, \dots, x_n$ solving \eqref{intequation}. If, for each nonzero $m \in \ZZ^n$ and $a \in \ZZ$, we consider the set
%
\[ Z_{m,a} = \left\{ (x_1, \dots, x_n) \in [0,1]^n : m_1x_1 + \dots + m_n x_n = a \right\}, \]
%
then $Z_{m,a}$ is a subset of an $n-1$ dimensional hyperplane, and thus can be easily seen to have Minkowski dimension $n-1$. It follows that we can apply Theorem \ref{maintheorem} to $Z = \bigcup \{ Z_{m,a} : m \neq 0, a \in \ZZ \}$ to obtain a Salem set $X \subset [0,1]$ with dimension
%
\[ \frac{n - (n-1)}{n - 1} = \frac{1}{n-1}, \]
%
such that $(x_1, \dots, x_n) \not \in Z$ for each distinct $x_1, \dots, x_n \in X$. Thus $X$ avoids solutions to $\eqref{intequation}$ for all nonzero $m \in \ZZ^n$ and $a \in \ZZ$. Thus we see Theorem \ref{maintheorem} generalizes K\"{o}rner's result, and thus shows the result depends little on the arithmetic properties of the pattern K\"{o}rner avoids, but rather, depends only on the `thickness' of the family of tuples $(x_1, \dots, x_n)$ satisfying the pattern. Since we expect Theorem \ref{maintheorem} to be tight for general sets, an improvement to K\"{o}rner's construction must rely more heavily on the algebraic properties of the pattern involved.

Since we are working with \emph{compact} sets avoiding patterns, working in $\RR^d$ is not significantly different from working in a periodic domain $\TT^d = \RR^d / \ZZ^d$, and working in this space has several advantages over the Euclidean case. For a finite measure $\mu$ on $\TT^d$, we can define it's Fourier dimension $\fordim(\mu)$ as the supremum of all $0 \leq s \leq d$ such that
%
\begin{equation} \label{fordimtorus}
    \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{s/2} < \infty.
\end{equation}
%
We can then define the Fourier dimension of any Borel set $E \subset \TT^d$ as the supremum of $\fordim(\mu)$, over all Borel measures $\mu$ supported on $E$. Similarily, $\TT^d$ has a natural quotient metric induced from $\RR^d$, so we can consider open balls $B_\varepsilon(x + \ZZ^d)$, and thus define the Hausdorff dimension of finite Borel measures and sets on $\TT^d$. It is a simple consequence of the Poisson summation formula that if $\mu$ is a compactly supported measure on $\RR^d$, then \eqref{fordim} is equivalent to the more discrete condition
%
\begin{equation} \label{discretefordim}
    \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{s/2} < \infty.
\end{equation}
%
A proof is given in \cite[Lemma 39]{myThesis}. In particular, if $\mu^*$ is the \emph{periodization} of $\mu$, i.e. the measure on $\TT^d$ such that for any $f \in C(\TT^d)$,
%
\[ \int_{\TT^d} f(x)\; d\mu^*(x) = \int_{\RR^d} f(x + \ZZ^d)\; d\mu(x), \]
%
then \eqref{discretefordim} implies $\fordim(\mu^*) = \fordim(\mu)$. Since $\mu$ is compactly supported, it is also simple to see that $\hausdim(\mu^*) = \hausdim(\mu)$. Thus Theorem \ref{maintheorem} is clearly equivalent to it's periodic variant, introduced below.

\begin{theorem} \label{periodictheorem}
    Let $0 \leq \alpha < dn$, and let $Z \subset \TT^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Then there exists a compact Salem set $X \subset \TT^d$ with dimension
    %
    \[ \beta = \min \left( \frac{nd - \alpha}{n-1}, d \right) \]
    %
    such that for any distinct points $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in Z$. Moreover, for any sequence $\{ B(\xi) : \xi \in \ZZ^d \}$ of positive numbers such that $B(\xi) \to \infty$ as $|\xi| \to \infty$, there is a measure $\mu$ supported on $X$ such that for each nonzero $\xi \in \ZZ^d$,
    %
    \[ |\widehat{\mu}(\xi)| \leq B(\xi) \log(1 + |\xi|)^{1/2} |\xi|^{-\beta}. \]
\end{theorem}

To construct our set, we rely on a Baire-category argument for the purpose of our construction. Thus we consider a complete metric space $\mathcal{X}$, whose elements consist of pairs $(E,\mu)$, where $E$ is a subset of $\TT^d$, and $\mu$ is a probability measure supported on $E$. We then show that for \emph{quasi-all} elements $(E,\mu) \in \mathcal{X}$, the set $E$ is Salem and pattern avoiding, and for each $\xi \in \ZZ^d$,
%
\[ |\widehat{\mu}(\xi)| \lesssim B(\xi) \log(1 + |\xi|)^{1/2} |\xi|^{-\beta}, \]
%
in the sense that the set of pairs $(E,\mu)$ which do not satisfy these properties is a set of first category in $\mathcal{X}$. It follows that Theorem \ref{periodictheorem} holds in a `generic' sense for elements of $\mathcal{X}$.

Once we have setup the appropriate metric space $\mathcal{X}$, our approach is quite similar to the construction in \cite{OurPaper}, relying on a random selection procedure, which is now exploited to give high probability bounds on the Fourier transform of the measures we study. The use of the Baire category approach in this paper, rather than an algorithmic, `nested set' approach, is mostly of an aesthetic nature, avoiding the complex queuing method and dyadic decomposition strategy required in the nested set approach; our approach can, with some care, be converted into a queuing procedure like in \cite{OurPaper}. But the Baire category argument makes our proof simpler to read, giving us the `infinitisimal argument' for free from the discrete case analysis, and has the advantage that it indicates that Salem sets of a specified dimension `generically' avoid a given rough pattern. Moreover, the proof of the Baire category theorem is in some senses, `hidden' in the queuing method, so the two methods are, aside from small technical differences, equivalent to one another.

\section{Notation} \label{notationSection}

\begin{itemize}
    \item For a positive integer $N$, we let $[N] = \{ 1, \dots, N \}$.

    \item We let $\ZZ^d_0 = \ZZ^d_0 - \{ 0 \}$.

    \item Given a metric space $\Omega$, $x \in \Omega$, and $\varepsilon > 0$, we shall let $B_\varepsilon(x)$ denote the open ball of radius $\varepsilon$ around $x$. For a given set $E \subset \Omega$ and $\varepsilon > 0$, we let
    %
    \[ E_\varepsilon = \bigcup_{x \in E} B_\varepsilon(x), \]
    %
    denote the \emph{$\varepsilon$-thickening} of the set $E$. A subset of $\Omega$ is of \emph{first category} in $\Omega$ if it is the countable union of closed sets with nonempty interior. We say a property holds \emph{quasi-always}, or a property is \emph{generic} in $\Omega$ if the set of points in $\Omega$ failing to satisfy that property form a set of first category.

    \item We let $\TT^d = \RR^d/\ZZ^d$. Given $x \in \TT$, we let
    %
    \[ |x| = \min \{ |x + n| : n \in \ZZ \}, \]
    %
    and for $x \in \TT^d$, we let
    %
    \[ |x| = \sqrt{|x_1|^2 + \dots + |x_d|^2}. \]
    %
    The canonical metric on $\TT^d$ is then $d(x,y) = |x - y|$, for $x,y \in \TT^d$.

    \item Suppose $\mathbf{E} = \TT^d$ or $\mathbf{E} = \RR^d$. For $\alpha \in [0,d]$ and $\delta > 0$, we define the Hausdorff content of a Borel set $E \subset \mathbf{E}$ as
    %
    \[ H^\alpha_\delta(E) = \inf \left\{ \sum_{i = 1}^\infty \varepsilon_i^\alpha : E \subset \bigcup_{i = 1}^\infty B_{\varepsilon_i}(x_i)\ \text{and $\varepsilon_i \leq \delta$ for all $i \in \mathbf{N}$} \right\}. \]
    %
    The $\alpha$ dimensional Hausdorff measure of $E$ is equal to
    %
    \[ H^\alpha(E) = \lim_{\delta \to 0} H^\alpha_\delta(E). \]
    %
    The Hausdorff dimension $\hausdim(E)$ of a Borel set $E$ is then the infinum over all $s \in [0,d]$ such that $H^s(E) = \infty$, or alternatively, the supremum over all $s \in [0,d]$ such that $H^s(E) = 0$. Frostman's lemma says that if we define the Hausdorff dimension $\hausdim(\mu)$ of a finite Borel measure $\mu$ as the supremum of all $s \in [0,d]$ such that
    %
    \begin{equation} \label{hausdim}
        \sup \left\{ \mu(B_\varepsilon(x)) \cdot \varepsilon^{-\alpha} : x \in \RR^d, \varepsilon > 0 \right\} < \infty,
    \end{equation}
    %
    then $\hausdim(E)$ is the supremum of $\hausdim(\mu)$, over all Borel probability measures $\mu$ supported on $E$, analogous to the definition of the Fourier dimension of a set $E$ given in the introduction.

    \item For $\mathbf{E} = \RR^d$ or $\mathbf{E} = \TT^d$, and for a measurable set $E$, we let $|E|$ denote it's standard Lebesgue measure. We define the lower and upper Minkowski dimension of a compact Borel set $E \subset \mathbf{E}$ as
    %
    \[ \lowminkdim(E) = \liminf_{\varepsilon \to 0} \log_\varepsilon|E_\varepsilon| \quad\text{and}\quad \upminkdim(E) = \limsup_{\varepsilon \to 0} \log_\varepsilon |E_\varepsilon| \]
    %
    respectively.

    \item We will make several uses of \emph{Hoeffding's Inequality} to control the deviations of independent families of random variables. The version of Hoeffding's inequality we use states that if $\{ X_1, \dots, X_N \}$ is an independent family of mean-zero random variables, such that for each $i$, there exists a constant $A_i \geq 0$ such that $|X_i| \leq A_i$ almost surely, then for each $t \geq 0$,
    %
    \[ \PP \left( |X_1 + \dots + X_N| \geq t \right) \leq 2 \exp \left(\frac{-t^2}{2(A_1^2 + \dots + A_N^2)} \right). \]
    %
    Proofs are given in many probability textbooks, for instance, in Chapter 2 of \cite{Vershynin}.
    \begin{comment}

    \item Our random construction involves a probabilistic concentration of measure argument. Define a convex function $\psi_2: [0,\infty) \to [0,\infty)$ by setting
    %
    \[ \psi_2(t) = e^{t^2} - 1, \]
    %
    The function $\psi_2$ induces an Orlicz norm on the family of scalar valued random variables over a probability space by setting, for each random variable $X$,
    %
    \[ \psitwo{X} = \inf \left\{ A \in (0,\infty) : \EE(\psi_2(|X|/A)) \leq 1 \right\}. \]
    %
    The family of random variables with $\psitwo{X} < \infty$ are known as \emph{subgaussian random variables}. Here are the important properties of subgaussian random variables which we use in this paper:
    %
    \begin{itemize}
        \item If $\psitwo{X} \leq A$, then for each $t \geq 0$,
        %
        \[ \PP \left( |X| \geq t \right) \leq 10 \exp \left( -t^2/10A^2 \right). \]
        %
        Thus Subgaussian random variables have Gaussian tails.

        \item If $|X| \leq A$ almost surely, then $\psitwo{X} \leq 10 A$. Thus bounded random variables are subgaussian.

    %\item (Centering) For any random variable $X$,
    %
    %\[ \psitwo{X - \EE(X)} \lesssim \psitwo{X}. \]
    
    %\item (Union Bound) If $X_1, \dots, X_N$ are random variables, then
    %
    %\[ \psitwo{X_1 + \dots + X_N} \leq \psitwo{X_1} + \dots + \psitwo{X_N}. \]
    
        \item If $X_1, \dots, X_N$ are \emph{independent}, then
        %
        \[ \psitwo{X_1 + \dots + X_N} \leq 10 \left( \psitwo{X_1}^2 + \dots + \psitwo{X_N}^2 \right)^{1/2}. \]
        %
        This is an equivalent way to state \emph{Hoeffding's Inequality}, and we refer to an application of this inequality as an application of Hoeffding's inequality.
    \end{itemize}
    %
    Roughly speaking, if $X$ is a random variable with $\psitwo{X} \leq A$, we can think of $X$ as being sharply concentrated in the region $[-A,A]$. The Orlicz norm thus provides a convenient way to quantify concentration phenomena.
    %
    \begin{remark}
        The constants involved in these statements are suboptimal, but will suffice for our purposes. Proofs can be found in Chapter 2 of \cite{Vershynin}.
    \end{remark}

    \end{comment}
\end{itemize}

\section{Technical Setup}

Throughout this paper, we will need to consider a standard mollifier. The next theorem gives the existence of a mollifier with the properties we require; in the remainder of the paper, we fix a single instance of such a mollifier. The proofs are not particular enlightening or novel, and thus for most it will suffice to read the statements of the theorems as a setup for later sections.

\begin{theorem} \label{equationASFGCISIX}
    There exists a smooth probability density $\phi \in C^\infty(\TT^d)$ such that $\phi(x) = 0$ for $|x| \geq 2/5$, and such that for each $x \in \TT^d$
    %
    \[ \sum_{k \in \{ 0, 1 \}^d} \phi(x + k/2) = 2^d. \]
\end{theorem}
\begin{proof}
    Let $\psi$ be a non-negative smooth function on $\TT$ such that $\psi(x) = \psi(- x)$ for all $x \in \TT$, $\psi(x) = 1$ for $|x| \leq 1/10$, $\psi(x) = 0$ for $|x| \geq 2/10$, and $0 \leq \psi(x) \leq 1$ for all $x \in \TT$. Then define $\eta$ to be the non-negative, $C^\infty$ function
    %
    \[ \eta(x) = \frac{1}{2} - \frac{\psi(x) + \psi(x + 1/2)}{2}. \]
    %
    If we define
    %
    \[ \phi_0(x) = 2(\psi(x) + \eta(x)), \]
    %
    then $\phi_0(x) + \phi_0(x + 1/2) = 2$ for all $x \in \TT$. Moreover, if $|x| \geq 2/5$, then $\psi(x) = 0$, and since this implies $|x + 1/2| \leq 1/10$, we find $\eta(x) = 0$. Thus $\phi_0(x) = 0$ for $|x| \geq 2/5$. But the condition $\phi_0(x) + \phi_0(x + 1/2) = 2$ implies that $\phi_0$ is a probability density function. Thus it suffices to define
    %
    \[ \phi(x_1, \dots, x_d) = \phi_0(x_1) \dots \phi_0(x_d). \qedhere \]
\end{proof}

For each $\varepsilon \in (0,1)$, we can then define $\phi_\varepsilon \in C^\infty(\TT^d)$ by writing
%
\[ \phi_\varepsilon(x) = \begin{cases} \varepsilon^{-d} \phi(x/\varepsilon) &: |x| < \varepsilon, \\ 0 &: \text{otherwise}. \end{cases} \]
%
Then the following properties hold:
%
\begin{enumerate}
    \item For each $\varepsilon \in (0,1)$, $\phi_\varepsilon$ is a smooth probability density, and $\phi_\varepsilon(x) = 0$ for $|x| \geq \varepsilon$.

    \item For any positive integer $N$, if $\varepsilon = 1/N$ and $x \in \TT^d$,
    %
    \begin{equation} \label{equation5550002352124124512}
        \sum_{k \in [2N]^d} \phi_{1/N}(x + k/2N) = (2N)^d.
    \end{equation}

    \item For each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{approximationtoidentitypointwiseconvergence}
        \lim_{\varepsilon \to 0} \widehat{\phi_\varepsilon}(\xi) = 1.
    \end{equation}
        
    \item For each $T > 0$, and for all $\varepsilon > 0$ and non-zero $k \in \ZZ^d$,
    %
    \begin{equation} \label{molificationdecaybound}
        |\widehat{\phi_\varepsilon}(k)| \lesssim_T \varepsilon^{-T} |k|^{-T}.
    \end{equation}
\end{enumerate}

Though Theorem \ref{periodictheorem} works for a very general family of sequences $\{ B(\xi) \}$, it will be convenient to make several assumptions on the sequence in our proof. In particular, we can assume that for any $n$, and for any $\xi_1,\xi_2$ with $n \leq |\xi_1|, |\xi_2| \leq 2n$,
%
\begin{equation} \label{equationGGPASOC}
    2^{-1} B(\xi_1) \leq B(\xi_2) \leq 2B(\xi_1),
\end{equation}
%
that
%
\begin{equation} \label{equationFSSXPS}
    \sup_{\xi \in \ZZ^d} B(\xi) \log(1 + |\xi|)^{1/2} |\xi|^{-\beta} \leq 1,
\end{equation}
%
and that $B$ is \emph{monotone}, i.e. if $|\xi_1| \leq |\xi_2|$, then $B(\xi_1) \leq B(\xi_2)$. The next lemma shows \eqref{equationGGPASOC}, \eqref{equationFSSXPS}, and monotonicity can be assumed without loss of generality.

\begin{lemma}
    Given any sequence $\{ \tilde{B}(\xi) \}$ of positive numbers such that as $|\xi| \to \infty$, $\tilde{B}(\xi) \to \infty$, we can find a sequence $\{ B(\xi) \}$ satisfying \eqref{equationGGPASOC} and \eqref{equationFSSXPS} such that $B(\xi) \to \infty$ as $|\xi| \to \infty$, and such that $B(\xi) \leq \tilde{B}(\xi)$ for each $\xi \in \ZZ^d$.
\end{lemma}
\begin{proof}
    For each nonzero $\xi \in \ZZ^d$, simultaneously define
    %
    \[ C_1(\xi) = \min \left\{ \tilde{B}(\xi') : \xi' \in \ZZ^d, 2^{-1}|\xi| \leq |\xi'| \leq \infty \right\}, \]
    %
    %
    \[ C_2(\xi) = \inf \left\{ \frac{|\xi'|^\beta}{\log(1 + |\xi'|)^{1/2}} : \xi' \in \ZZ^d, |\xi'| \geq |\xi| \right\}, \]
    %
    \[ C_3(\xi) = \inf \left\{ 2 B(\xi') : \xi' \in \ZZ^d, |\xi|/2 \leq |\xi'| < |\xi| \right\}, \]
    %
    and
    %
    \[ B(\xi) = \min(C_1(\xi), C_2(\xi), C_3(\xi)). \]
    %
    These quantities are all well defined by an inductive definition on the magnitude of $|\xi|$. Now for each $\xi \in \ZZ^d$,
    %
    \[ B(\xi) \leq C_1(\xi) \leq \tilde{B}(\xi). \]
    %
    Clearly $C_1$ and $C_2$ are monotone, and one can see $C_3$ and $B$ are monotone by a simple inductive argument. To verify \eqref{equationGGPASOC}, fix $n$, and consider $\xi_1, \xi_2$ with $n \leq |\xi_1|, |\xi_2| \leq 2n$. Without loss of generality, we may assume $|\xi_1| < |\xi_2|$, since the case $|\xi_1| = |\xi_2|$ is obvious. We then find
    %
    \begin{equation} \label{equationPPDSCOAAPDOE}
        B(\xi_2) \leq C_3(\xi_2) \leq 2 B(\xi_1).
    \end{equation}
    %
    But the monotonicity of $B$ implies
    %
    \begin{equation} \label{equationYYUSCCSPA}
        B(\xi_2) \geq B(\xi_1).
    \end{equation}
    %
    A combination of \eqref{equationPPDSCOAAPDOE} and \eqref{equationYYUSCCSPA} shows
    %
    \[ 2^{-1} B(\xi_1) \leq B(\xi_2) \leq 2 B(\xi_1) \]
    %
    and
    %
    \[ 2^{-1} B(\xi_2) \leq B(\xi_1) \leq 2 B(\xi_2). \]
    %
    Thus the sequence $\{ B(\xi) \}$ satisfies \eqref{equationGGPASOC}. The fact that $B(\xi) \leq C_2(\xi)$ for each $\xi$ implies that the sequence $\{ B(\xi) \}$ satisfies \eqref{equationFSSXPS}. All that remains is to show that $B(\xi) \to \infty$ as $|\xi| \to \infty$. It is certainly true that $C_1(\xi), C_2(\xi) \to \infty$. Fix $N$, and choose $M$ large enough that for $|\xi| \geq M$,
    %
    \[ C_1(\xi), C_2(\xi) \geq 10N. \]
    %
    To prove that $B(\xi) \geq N$ for sufficiently large $\xi$, it thus suffices to show that $C_3(\xi) \geq N$ for sufficiently large $\xi$. Assume that $C_3(\xi) \leq N$ for all $\xi$. Then for all $|\xi| \geq M$, $B(\xi) = C_3(\xi)$. Thus we conclude that for any $|\xi| \geq 2M$,
    %
    \begin{equation} \label{equationGGGAS}
        C_3(\xi) \geq 2 C_3(\xi/2).
    \end{equation}
    %
    Since $C_3(\xi) \geq \varepsilon$ for any $|\xi| \geq M$, repeated applications of \eqref{equationGGGAS} show that for each positive integer $n$, if $|\xi| \geq 2^n M$, then $C_3(\xi) \geq 2^n \varepsilon$. Taking $n$ large enough that $2^n \varepsilon \geq N$ gives a clear contradiction, so for sufficiently large $\xi$, we must have $B(\xi) \geq N$. Since $N$ was arbitrary, this proves our claim.
\end{proof}

\begin{remark}
    Notice in particular that if we define, for each $\xi \in \ZZ^d$,
    %
    \[ A(\xi) = B(\xi) \log(1 + |\xi|)^{1/2} |\xi|^{-\beta}, \]
    %
    and set $A(0) = 1$. Then \eqref{equationGGPASOC} implies that for any positive integer $n$, and any $\xi_1, \xi_2 \in \ZZ^d$ with $n \leq |\xi_1|, |\xi_2| \leq 2n$,
    %
    \begin{equation} \label{equationASADSDSCGGGGG}
        A(\xi_1) \sim A(\xi_2).
    \end{equation}
\end{remark}

\section{A Metric Space Controlling Fourier Dimension}

In order to work with a Baire category type argument, we must construct an appropriate metric space appropriate for our task. We proceed as in \cite{Korner2}, forming our metric space as a combination of two simpler metric spaces:
%
\begin{itemize}
    \item We let $\mathcal{E}$ denote the family of all compact subsets of $\TT^d$. If, for two compact sets $E,F \in \mathcal{E}$, we consider their Hausdorff distance
    %     
    \[ d_H(E,F) = \inf \{ \varepsilon > 0 : E \subset F_\varepsilon\ \text{and}\ F \subset E_\varepsilon \}, \]
    %
    then $(\mathcal{E},d_H)$ forms a complete metric space.

    \item We let $M(A)$ consist of the class of all finite Borel measures $\mu$ supported on $\TT^d$ such that the quantity
    %
    \[ \| \mu \|_{M(A)} =  \sup_{\xi \in \ZZ^d_0} \frac{|\widehat{\mu}(\xi)|}{|A(\xi)|}, \]
    %
    is finite. Then $\| \cdot \|_A$ is a norm, and $(M(A), \| \cdot \|_A)$ is a Banach space.
\end{itemize}
%
We then define $\mathcal{X}$ be the collection of all pairs $(E,\mu) \in \mathcal{E} \times M(A)$, where $\mu$ is a probability measure with $\text{supp}(\mu) \subset E$, and
%
\[ \lim_{|\xi| \to \infty} \frac{|\widehat{\mu}(\xi)|}{A(\xi)} = 0. \]
%
It is easy to see $\mathcal{X}$ is a closed subset of $\mathcal{E} \times M(A)$ under the product topology, and thus if we consider the product metric
%
\[ d_{\mathcal{X}}((E,\mu),(F,\nu)) = \max \left( d_H(E,F), \| \mu - \nu \|_A \right), \]
%
then $(\mathcal{X},d_\mathcal{X})$ is a complete metric space. The advantage of considering the problem quantitatively is that we can work with smooth measures.

\begin{lemma} \label{smoothdensitylemma}
    The set of all $(E,\mu)$ with $\mu \in C^\infty(\TT^d)$ is dense in $\mathcal{X}$.
\end{lemma}
\begin{proof}
    We just apply a mollification strategy. Consider $(E,\mu) \in \mathcal{X}$ and $\varepsilon > 0$. For each $\delta > 0$, consider $\mu_\delta = \mu * \phi_\delta$. Then $\mu_\delta \in C^\infty(\TT^d)$, and if $\delta \leq \varepsilon$, then $\mu_\delta$ is supported on $\overline{E_\varepsilon}$, so
    %
    \begin{equation} \label{equation9019412094192041}
        d_H(E,\overline{E_\varepsilon}) \leq \varepsilon.
    \end{equation}
    %
    Since $(E,\mu) \in \mathcal{X}$, there is $N$ depending on $\mu$ such that for $|\xi| \geq N$,
    %
    \[ |\widehat{\mu}(\xi)| \leq \varepsilon A(k). \]
    %
    For $|\xi| \geq N$, we thus find that
    %
    \begin{equation} \label{equation12}
        |\widehat{\mu_\delta}(\xi) - \widehat{\mu}(\xi)| = |\widehat{\mu}(k)||\widehat{\phi_\delta}(\xi) - 1| \leq 2 |\widehat{\mu}(k)| \leq 2\varepsilon A(\xi).
    \end{equation}
    %
    On the other hand, for suitably small $\delta > 0$, \eqref{approximationtoidentitypointwiseconvergence} implies that for $|\xi| \leq N$,
    %
    \[ |\widehat{\phi_\delta}(\xi) - 1| \leq \varepsilon A(\xi). \]
    %
    But this implies that for $|\xi| \leq N$,
    %
    \begin{equation} \label{equation124}
        |\widehat{\mu_\delta}(\xi) - \widehat{\mu}(\xi)| = |\widehat{\mu}(\xi)| |\widehat{\phi_\delta}(\xi) - 1| \leq \varepsilon A(\xi).
    \end{equation}
    %
    Thus we conclude that for suitably small $\delta$, $\| \widehat{\mu_\delta} - \widehat{\mu} \|_A \leq 2 \varepsilon$. But combining \eqref{equation9019412094192041}, \eqref{equation12}, and \eqref{equation124}, we conclude
    %
    \[ d_{\mathcal{X}}((E,\mu), (\overline{E_\varepsilon}, \mu_\delta)) \leq 2 \varepsilon. \]
    %
    Since $\varepsilon > 0$ was arbitrary, this completes the proof.
\end{proof}

Our main way of constructing approximations to $(E_0,\mu_0) \in \mathcal{X}$ is to multiply $\mu_0$ by a smooth function $f$. For instance, we might choose $f$ in such a way as to remove certain points from the support of $\mu_0$ which may form parts of a given pattern. As long as $\mu_0$ is fixed, and $f$ is small enough in the $M(A)$ metric, this introduces a neglible amount of error.

\begin{lemma} \label{LemmaTTSICICS}
    Consider a smooth finite measure $\mu_0$ on $\TT^d$, as well as a smooth probability density function $f$. If we define $\mu = f \mu_0$, then
    %
    \[ \| \mu - \mu_0 \|_{M(A)} \lesssim_{A,d,\mu_0} \| f \|_{M(A)}. \]
\end{lemma}
\begin{proof}
    Since $\widehat{\mu} = \widehat{f} * \widehat{\mu_0}$, and $\widehat{f}(0) = 1$, for each $\xi \in \ZZ^d$ we have
    %
    \begin{equation} \label{equationPPYTUECUUCS}
    \begin{split}
        |\widehat{\mu}(\xi) - \widehat{\mu_0}(\xi)| &= \left| \sum_{\eta \neq \xi} \widehat{f}(\xi - \eta) \widehat{\mu_0}(\eta) \right|.
    \end{split}
    \end{equation}
    %
    If $|\eta| \leq |\xi|/2$, then $|\xi|/2 \leq |\xi - \eta| \leq 2 |\xi|$, so we can conclude from \eqref{equationASADSDSCGGGGG} that
    %
    \begin{equation} \label{equationPPDOSO}
        |\widehat{f}(\xi - \eta)| \lesssim_A \| f \|_{M(A)} \cdot A(\xi).
    \end{equation}
    %
    Since $\mu_0$ is smooth, for any $T > 0$,
    %
    \begin{equation} \label{equationGGIDISCXJIX}
        |\widehat{\mu_0}(\xi)| \lesssim_{T,\mu_0} |\xi|^{-T} A(\xi).
    \end{equation}
    %
    Thus we can combine the bounds \eqref{equationPPDOSO} and \eqref{equationGGIDISCXJIX}, with $T = d+1$, to conclude that
    %
    \begin{equation} \label{equationGGPSOVVCSI}
    \begin{split}
        \left| \sum_{0 \leq |\eta| \leq |\xi|/2} \widehat{f}(\eta) \widehat{\mu_0}(\xi - \eta) \right| &\lesssim_{A,\mu_0,d} \left( 1 + \sum_{0 < |\eta| \leq |\xi|/2} \frac{1}{|\xi|^{d+1}} \right) \| f \|_{M(A)} \cdot A(\xi)\\
        &\lesssim_d \| f \|_{M(A)} \cdot A(\xi).
    \end{split}
    \end{equation}
    %
    On the other hand, we note that \eqref{equationPPDOSO} implies that for all nonzero $\eta \neq \xi$,
    %
    \begin{equation} \label{equationGGDPSOX}
    \begin{split}
        |\widehat{f}(\xi - \eta)| \lesssim_A \| f \|_{M(A)},
    \end{split}
    \end{equation}
    %
    Thus applying \eqref{equationGGIDISCXJIX} and \eqref{equationGGDPSOX}, with $T = 3d/2 + 1$ we conclude that
    %
    \begin{equation} \label{equationGGHOODPPS}
    \begin{split}
        \left| \sum_{\substack{|\eta| > |\xi|/2\\ \eta \neq \xi}} \widehat{f}(\xi - \eta) \widehat{\mu_0}(\eta) \right| &\lesssim_{A,d,\mu_0} \sum_{|\eta| > |\xi|/2} \frac{\| f \|_{M(A)}}{|\eta|^{3d/2+1}}\\
        &\lesssim_d \frac{\| f \|_{M(A)}}{|\xi|^{d/2 + 1}}\\
        &\lesssim_{A,d} \| f \|_{M(A)} \cdot A(\xi). 
    \end{split}
    \end{equation}
    %
    Combining \eqref{equationPPYTUECUUCS}, \eqref{equationGGPSOVVCSI} and \eqref{equationGGHOODPPS} completes the proof.
\end{proof}

Thus if $\| f \|_{M(A)}$ is small

The next lemma shows that provided that, for $K$ points $x_1, \dots, x_K \in \TT^d$, that if enough square root cancellation occurs in the exponential sum
%
\[ \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i (x_i \cdot \xi)}, \]
%
then a smooth function $f$ localized to these $K$ points has the appropriate Fourier decay that might be expected by the mass of it's support.

\begin{lemma} \label{Lemma65493}
    Fix $\beta \in [0,d]$, $C > 0$, and $\varepsilon > 0$, and consider $K$ points $x_1, \dots, x_K \in \TT^d$ such that if
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Then for any $\delta > 0$, there exists $K_0$, depending on $C$, $\beta$, $d$, $\delta$, $\varepsilon$, and the sequence $\{ A(\xi) \}$, such that if $K \geq K_0$ and $\varepsilon_0 \geq C^{-1} K^{-1/\beta}$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{\varepsilon_0}(x - x_i), \]
    %
    then $\| f \|_{M(A)} \leq \delta$.
\end{lemma}
\begin{proof}
%    For any $\varepsilon > 0$, we get the result without $D$ for $|\xi| \gtrsim 1/\varepsilon^{1 + \varepsilon}$. If $\widehat{D}(\xi) \leq K^{-1/2} \log(1 + K)^{1/2}$
%
% Last bound: |\xi| \gtrsim_T K^{1/\beta + O(1/T)} / \delta^{O(1/T)}
% Second Bound: |\xi| \gtrsim_T K^{1/\beta} \log(1 + K)^{O(1/T)}
% First Bound: 
%
% K^{-1/2} \log(1 + K)^{1/2} \leq 
%
%    $\varepsilon^{-T} \lesssim B(\xi) |\xi|^{T-\beta/2} \log(1 + |\xi|)^{1/2}$
%
    Noting that $f = D * \phi_{\varepsilon_0}$, we find that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_{\varepsilon_0}}|.
    \end{equation}
    %
    The standard $(L^1,L^\infty)$ bound for the Fourier transform implies that
    %
    \begin{equation} \label{equationGGHOUSUSXXCCX}
        \| \widehat{\phi_{\varepsilon_0}} \|_{L^\infty(\ZZ^d)} \leq \| \phi_{\varepsilon_0} \|_{L^1(\TT^d)} = 1.
    \end{equation}
    %
    Thus for $0 < |\xi| \leq K^{1/2\beta}$, we employ \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationGGHOUSUSXXCCX} to conclude that
    %
    \begin{equation} \label{equationGGOHDS82456}
        |\widehat{f}(\xi)| \lesssim_B \left[ C K^{-1/4} \log(K)^{1/2} \right] B(\xi) |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2}.
    \end{equation}
    %
    Since the implicit constant here is absolute, \eqref{equationGGOHDS82456} implies there exists $K_0$ depending only on $C$, the sequence $\{ A(\xi) \}$, and $\delta$, such that for $K \geq K_0$, and $|\xi| \leq K^{1/2\beta}$,
    %
    \begin{equation} \label{equationYYYUFUSSCS}
        |\widehat{f}(\xi)| \leq \delta |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2} B(\xi) = \delta A(\xi).
    \end{equation}
    %
    For $K^{1/2\beta} \leq |\xi| \leq K^{1/\beta}$, we again combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationGGHOUSUSXXCCX} to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
        |\widehat{f}(\xi)| \lesssim_\beta C |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2}.
    \end{equation}
    %
    Since the constants here also do not depend on $K$, and as $|\xi | \to \infty$, $B(\xi) \to \infty$, we conclude from \eqref{equationGGIOHISI99234} there exists $K_0$ depending on $\beta$, the sequence $\{ A(\xi) \}$, $C$, and $\delta$, such that for $K \geq K_0$ and $K^{1/2\beta} \leq |\xi| \leq K^{1/\beta}$,
    %
    \begin{equation} \label{equation663sdDDDCC}
        |\widehat{f}(\xi)| \leq \delta B(\xi) |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2} = \delta A(\xi).
    \end{equation}
    %
    If $K^{1/\beta} \leq |\xi| \leq K^{1/\beta + \varepsilon}$, we note that \eqref{molificationdecaybound} implies $\widehat{\phi_\varepsilon}(\xi) \lesssim \varepsilon_0^{-\beta/2} |\xi|^{-\beta/2}$, which together with \eqref{equationFFOSOXPFFGHI} and \eqref{equation6666GGCIS} implies
    %
    \begin{equation} \label{equationGGOOSC66341}
        |\widehat{f}(\xi)| \leq C K^{-1/2} \log(K)^{1/2} \varepsilon^{-\beta/2} |\xi|^{-\beta/2} \lesssim_\beta \left( C K^{-1/2} \varepsilon_0^{-\beta/2} \right) |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2}.
    \end{equation}
    %
    If $\varepsilon_0 \geq C^{-1} K^{-1/\beta}$, again using the fact that $B(\xi) \to \infty$ as $|\xi| \to \infty$, we conclude from \eqref{equationGGOOSC66341} that there exists $K_0$ depending only on $\delta$, $C$, $\beta$, and the sequence $\{ A(\xi) \}$, such that if $K \geq K_0$, then
    %
    \begin{equation} \label{equationUUUDDDCII777}
        |\widehat{f}(\xi)| \leq \delta B(\xi) |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2} = \delta A(\xi).
    \end{equation}
    %
    If $|\xi| \geq K^{1/\beta + \varepsilon}$, we apply \eqref{molificationdecaybound} for $T \geq \beta/2$ together with the bound $\varepsilon_0 \geq C^{-1} K^{-1/\beta}$ to conclude
    %
    \begin{equation} \label{equationGGUSCCCYVSSXX998723}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_T \varepsilon_0^{-T} |\xi|^{-T}\\
        &\leq \left[ \frac{C^T K^{T/\beta} |\xi|^{\beta/2 - T}}{\log(1 + |\xi|)^{1/2}} \right] |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2}\\
        &\leq \left[ \frac{C^T K^{1/2 + (\beta/2 - T) \varepsilon}}{\log(1 + K^{1/\beta + \varepsilon})^{1/2}} \right] |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2}.
    \end{split}
    \end{equation}
    %
    If we choose $T > \beta/2 + 1/2 \varepsilon$, then the value in the brackets in \eqref{equationGGUSCCCYVSSXX998723} decays as $K \to \infty$. In particular, we conclude that there exists a constant $K_0$ depending on $C$, $\delta$, $\beta$, and $\varepsilon$ such that for $K \geq K_0$,
    %
    \begin{equation} \label{equationBBCDSGDCC77}
        |\widehat{f}(\xi)| \leq \delta B(\xi) |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2} = \delta A(\xi).
    \end{equation}
    %
    Combining \eqref{equationYYYUFUSSCS}, \eqref{equation663sdDDDCC}, \eqref{equationUUUDDDCII777}, and \eqref{equationBBCDSGDCC77} gives $\| f \|_{M(A)} \leq \delta$.
\end{proof}

Independence of random variables is sufficient to obtain square root cancellation.

\begin{lemma} \label{LemmaGISCICS1}
    Fix a large integer $K$, let $X_1, \dots, X_K$ be independant uniformly distributed random variables on $\TT^d$. Set
    %
    \[ D(x) = \sum_{k = 1}^K \delta(x - x_k) \]
    %
    and
    %
    \[ B = \{ \xi \in \ZZ^d: |\xi| \leq K^{1/\beta + 1} \}. \]
    %
    Then there exists a constant $C$, depending only on $d$ and $\beta$, such that
    %
    \[ \PP \left( \| \widehat{D} \|_{L^\infty(B)} \leq C K^{-1/2} \log(K)^{1/2} \right) \leq 1/10. \]
\end{lemma}
\begin{proof}
    For each $\xi \in \ZZ^d$ and $k \in \{ 1, \dots, K \}$, consider the random variable $C(\xi,k) = K^{-1} e^{2 \pi i (\xi \cdot X_k)}$. Then for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationPPDOCS999223}
        \sum_{k = 1}^K C(\xi,k) = \widehat{D}(\xi).
    \end{equation}
    %
    We also note that for each $\xi$ and $k$,
    %
    \begin{equation} \label{equationGFDSCSXAOOO99}
        |C(\xi,k)| = K^{-1},
    \end{equation}
    %
    Moreover, for $\xi \neq 0$,
    %
    \begin{align*}
        \EE(C(\xi,k)) = K^{-1} \int_{\TT^d} e^{2 \pi i (\xi \cdot x)}\; dx = 0.
    \end{align*}
    %
    Since the family of random variables $\{ C(\xi,1), \dots, C(\xi,K) \}$ is independent for a fixed non-zero $\xi$, we can apply Hoeffding's inequality together with \eqref{equationPPDOCS999223} and \eqref{equationGFDSCSXAOOO99} to conclude that for all $t \geq 0$,
    %
    \begin{equation} \label{equationDDISCCOXOSPP998323}
        \PP \left( |\widehat{D}(\xi)| \geq t \right) \leq 2 e^{-Kt^2/2}.
    \end{equation}
    %
    A union bound obtained by applying \eqref{equationDDISCCOXOSPP998323} over all $|\xi| \leq K^{1/\beta+1}$, combined with \eqref{equationDDISCCOXOSPP998323}, shows that if
    %
    \[ B = \{ \xi \in \ZZ^d : |\xi| \leq K^{1/\beta + 1} \}, \]
    %
    then there exists a constant $C \geq 1$ depending only on $d$ and $\beta$, such that
    %
    \begin{equation} \label{equationPPDOCS2424}
        \PP \left( \| \widehat{D} \|_{L^\infty(B)} \geq t \right) \leq \exp \left( C \log(K) - \frac{5K t^2}{C} \right).
    \end{equation}
    %
    But then, setting $t = CK^{-1/2} \log(K)^{1/2}$ in \eqref{equationPPDOCS2424} completes the proof.
\end{proof}

It is a general heuristic that quasi-all sets are as `thin as possible' with respect to the Hausdorff metric. In particular, we should expect the Hausdorff dimension and Fourier dimension of a generic element of $\mathcal{X}$ to be as low as possible. For each $(E,\mu) \in \mathcal{X}$, the condition that $\mu \in M(A)$ implies that $\fordim(\mu) \geq \beta$, so $\fordim(E) \geq \beta$. Thus we might expect that for quasi-all $(E,\mu) \in M(A)$, the set $E$ has both Hausdorff dimension and Fourier dimension equal to $\beta$. This turns out to be the correct assumption.

\begin{lemma}
    For quasi-all $(E,\mu) \in \mathcal{X}$, $E$ is a Salem set of dimension $\beta$.
\end{lemma}
\begin{proof}
    We shall assume $\beta < d$ in the proof, since the case $\beta = d$ is trivial. Since the Hausdorff dimension of a measure is an upper bound for the Fourier dimension, it suffices to show that quasi-all $\mu \in M(A)$ have Hausdorff dimension at most $\beta$. For each $\alpha > \beta$ and $\delta, s > 0$, and let $A(\alpha,\delta,s) = \{ (E,\mu) \in \mathcal{G}: H^\alpha_\delta(E) < s \}$. Then $A(\alpha,\delta,s)$ is an open set, and
    %
    \[ \bigcap_{n = 1}^\infty \bigcap_{m = 1}^\infty \bigcap_{k = 1}^\infty A(\beta + 1/n, 1/m, 1/k) \]
    %
    is precisely the family of $(E,\mu) \in \mathcal{X}$ such that $E$ has Hausdorff dimension at $\beta$.
%
    %Certainly any $E$ in this family must have $H^\alpha(E) = 0$ for all $\alpha > \beta$, so $\hausdim(E) \leq \beta$. But the condition that $\mu \in M(A)$ implies $\fordim(\mu) \geq \beta$. Thus
    %
    %\[ \beta \leq \fordim(\mu) \leq \fordim(E) \leq \hausdim(E) \leq \beta, \]
    %
    %hence all these quantities are equal to $\beta$.
    Thus it suffices to show that $A(\alpha,\delta,s)$ is dense in $\mathcal{X}$ for $\alpha \in (\beta,d)$ and $\delta, s > 0$. Fix $(E,\mu_0) \in \mathcal{X}$, $\alpha \in (\beta,d)$, $\delta > 0$, and $s > 0$, and consider $\varepsilon > 0$. We aim to show that for each $(E_0,\mu_0) \in \mathcal{X}$, there is $(E,\mu) \in A(\alpha,\delta,s)$ such that $d_{\mathcal{X}}((E_0,\mu_0),(E,\mu)) \leq \varepsilon$. Without loss of generality, in light of Lemma \ref{smoothdensitylemma}, we may assume without loss of generality that $\mu_0 \in C^\infty(\TT^d)$.

    Fix a large integer $K$. Lemma \ref{LemmaGISCICS1} shows that there exists a constant $C$ depending only on $d$ and $\beta$ and $K$ points $x_1, \dots, x_K \in \TT^d$ such that if
    %
    \[ D(x) = \sum_{k = 1}^K \delta(x - x_k), \]
    %
    then for each $|\xi| \leq K^{1/\beta + 1}$,
    %
    \begin{equation} \label{equationDDVVIXXSX23}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Using \eqref{equationDDVVIXXSX23} to apply Lemma \ref{Lemma65493}, and then applying Lemma \ref{LemmaTTSICICS}, we conclude that there exists $K_0$ depending on $\beta$, $d$, $\varepsilon$, and the sequence $\{ A(\xi) \}$, such that if $K \geq K_0$, if $\varepsilon_0 = K^{-1/\beta}$, and if
    %
    \[ \mu(x) = \left( \sum_{k = 1}^K \phi_{\varepsilon_0}(x - x_k) \right) \mu_0(x), \]
    %
    then
    %
    \begin{equation} \label{equationYYUDUSC4434}
        \| \mu - \mu_0 \|_{M(A)} \leq \varepsilon.
    \end{equation}
    %
    Since $\mu$ is supported on $K$ balls of radius $\varepsilon_0$, and for $K$ suitably large, $\varepsilon_0 \leq \delta$, we find that
    %
    \begin{equation} \label{equationGGSCPXX22}
        H^\alpha_\delta(\text{supp}(\mu)) \leq K \varepsilon_0^\alpha = K^{1 - \alpha/\beta}.
    \end{equation}
    %
    Since $\alpha > \beta$, \eqref{equationGGSCPXX22} implies that for suitably large $K$,
    %
    \begin{equation} \label{equationGGSXSOF9923}
        H^\alpha_\delta(\text{supp}(\mu)) \leq s.
    \end{equation}
    %
    Now let
    %
    \[ E = \text{supp}(\mu) \cup \{ y_1, \dots, y_N \}, \]
    %
    where $\{ y_1, \dots, y_N \} \subset E_0$ is a $\varepsilon$ net of $E_0$. Equation \eqref{equationGGSXSOF9923} implies that $H^\alpha_\delta(E) \leq s$ for sufficiently large $K$, so $(E,\mu) \in A(\alpha,\delta,s)$. Since $\text{supp}(\mu) \subset E$,
    %
    \begin{equation} \label{equationGGISIICV222}
        d_H(E,E_0) \leq \varepsilon.
    \end{equation}
    %
    Combining \eqref{equationYYUDUSC4434} with \eqref{equationGGISIICV222} shows $d_{\mathcal{X}}((E_0,\mu_0),(E,\mu)) \leq \varepsilon$, which completes the proof.
\end{proof}

\begin{comment}

\section{Random Segments of Measures}

Several times, in this paper, we rely on a simple random segmentation applied to a given smooth measure. Here we collect some simple calculations we use quite often to bound the Fourier transforms of these random segmentations. We begin with a general result that enables us to control the high frequency terms of a smooth measure.

\begin{theorem} \label{lemma6213}
    Consider a smooth measure $\mu_0$ on $\TT^d$, $K$ points $x_1, \dots, x_K \in \TT^d$, $\varepsilon_0, \varepsilon_1 > 0$, and $T > 0$. Then there exists a constant $C$ depending solely on $\mu_0$, $d$, $\varepsilon_1$, and $T$, such that if
    %
    \[ \nu(x) = \left( \frac{1}{K} \sum_{i = 1}^K \phi_{\varepsilon_0}(x - x_i) \right) \cdot \mu_0(x), \]
    %
    then for $|\xi| \geq (1/\varepsilon_0)^{1+\varepsilon_1}$, $|\widehat{\nu}(\xi)| \leq C |\xi|^{-T}$.
\end{theorem}
\begin{proof}
    Define a finite measure
    %
    \begin{equation} \label{equationAAA}
        \alpha(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i).
    \end{equation}
    %
    Then $\nu = (\alpha * \phi_{\varepsilon_0}) \mu_0$, so
    %
    \begin{equation} \label{equation3AFVV43}
        \widehat{\nu} = (\widehat{\alpha} \widehat{\phi_{\varepsilon_0}}) * \widehat{\mu_0}.
    \end{equation}
    %
    The standard $(L^1,L^\infty)$ bound for the Fourier transform shows that
    %
    \begin{equation} \label{equation2191294fAA}
        \| \widehat{\alpha} \|_{L^\infty(\ZZ^d)} \leq \alpha(\TT^d) = 1.
    \end{equation}
    % If random enough, $|\alpha^| \leq K^{-1/2}$
    %
    Combining \eqref{equation3AFVV43} with \eqref{equation2191294fAA} shows that for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationBGQPS23}
        |\widehat{\nu}(\xi)| \leq \sum_{\eta \in \ZZ^d} |\widehat{\phi_{\varepsilon_0}}(\eta)| |\widehat{\mu_0}(\xi-\eta)|.
    \end{equation}
    %
    Since $\mu_0$ is smooth, for any $S > 0$ and $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equation78234125}
        |\widehat{\mu_0}(\xi)| \lesssim_S |\xi|^{-S}.
    \end{equation}
    %
    If $|\eta| \leq |\xi|/2$, $|\xi - \eta| \geq |\xi|/2$, so \eqref{equation78234125} implies that $|\widehat{\mu_0}(\xi - \eta)| \lesssim_S |\eta|^{-S}$ for all $S > 0$. Combined with the trivial bound $\| \widehat{\phi_{\varepsilon_0}} \|_{L^\infty(\ZZ^d)} \leq 1$ we find that
    %
    \begin{equation} \label{equation12412AGEIVOOV}
        \sum_{0 \leq |\eta| \leq |\xi|/2} |\widehat{\phi_{\varepsilon_0}}(\eta)| |\widehat{\mu_0}(\xi-\eta)| \lesssim_{d,S} \frac{1}{|\xi|^{S-d}}.
    \end{equation}
    %
    Conversely, if $|\eta| \geq 2 |\xi|$, then $|\xi - \eta| \geq |\eta|/2$, so a simple dyadic partition of the sum onto annular regions where $|\eta| \sim 2^k |\xi|$, each bounded using \eqref{equation78234125}, combined with the trivial bound $\| \widehat{\phi_{\varepsilon_0}} \|_{L^\infty(\ZZ^d)} \leq 1$, shows that for each $S > d$,
    %
    \begin{equation} \label{equationADWCP124}
        \sum_{|\eta| \geq 2 |\xi|} |\widehat{\phi_{\varepsilon_0}}(\eta)| |\widehat{\mu_0}(\xi-\eta)| \lesssim_{d,S} \frac{1}{|\xi|^{S-d}}.
    \end{equation}
    %
    Finally, if $|\xi|/2 \leq |\eta| \leq 2|\xi|$, then we employ \eqref{molificationdecaybound} together with the bound $\| \widehat{\mu_0} \|_{L^\infty(\ZZ^d)} \leq 1$, to conclude that
    %
    \begin{equation} \label{equationAFVGUREWIS}
        \sum_{|\xi|/2 \leq |\eta| \leq 2 |\xi|} |\widehat{\phi_{\varepsilon_0}}(\eta)| |\widehat{\mu_0}(\xi-\eta)| \lesssim_{d,S} \frac{(1/\varepsilon_0)^S}{|\xi|^{S-d}} = \frac{1}{|\xi|^d} \frac{(1/\varepsilon_0)^S}{|\xi|^{S-T-2d}} \frac{1}{|\xi|^T}.
    \end{equation}
    %
    If $|\xi| \geq (1/\varepsilon_0)^{S/(S - T - 2d)} = (1/\varepsilon_0)^{1 + O_T(1/S)}$, we conclude from \eqref{equationAFVGUREWIS} that
    %
    \begin{equation} \label{equationTTCCSSDWETF}
        \sum_{|\xi|/2 \leq |\eta| \leq 2 |\xi|} |\widehat{\phi_{\varepsilon_0}}(\eta)| |\widehat{\mu_0}(\xi-\eta)| \lesssim_{d,T} \frac{1}{|\xi|^d} \frac{1}{|\xi|^T}.
    \end{equation}
    %
    Taking $S$ suitably large relative to $\varepsilon_1$ and $T$, and then combining \eqref{equation12412AGEIVOOV}, \eqref{equationADWCP124}, and \eqref{equationTTCCSSDWETF} with \eqref{equationBGQPS23}, the claim is proved.
%    we conclude that for each $\varepsilon_1 > 0$, if $S$ is taken suitably large relative to $\varepsilon_1$ and $T$, there exists a constant $C$ depending only on $\mu_0$, $d$, and $\varepsilon_1$, such that if $|\xi| \geq (1/\varepsilon_0)^{1 + \varepsilon_1}$, then
    %
%    \[ |\widehat{\nu}(\xi)| \leq \frac{CK}{|\xi|^d} \frac{1}{|\xi|^T}. \qedhere \]
\end{proof}

Next, we produce a theorem that enables us to control low frequency terms using Hoeffding's inequality to control the deviation of a random variable from it's expectation.

\begin{theorem} \label{randomFourierTheorem}
    Let $\mu_0$ be a smooth measure on $\TT^d$. Consider a positive integer $K$, and some $\varepsilon_0 > 0$, and take any independant family of $K$ random vectors $\{ X_1, \dots, X_K \}$ in $\TT^d$ such that for each $x$ in the support of $\mu_0$,
    %
    \begin{equation} \label{equationA}
        \EE \left( \frac{1}{K} \sum_{i = 1}^K \phi_{\varepsilon_0}(x - X_i) \right) = 1.
    \end{equation}
    %
    Define a smooth measure
    %
    \[ \nu(x) = \left( \frac{1}{K} \sum_{i = 1}^K \phi_{\varepsilon_0}(x - X_i) \right) \cdot \mu_0(x), \]
    %
    and a set of frequencies
    %
    \[ D_\alpha = \{ \xi \in \ZZ^d : |\xi| \leq K^{1/\alpha} \}. \]
    %
    Then for each $\alpha > 0$, there exists a constant $C$, depending only on $\mu_0$, $d$, and $\alpha$, such that with probability greater than or equal to $4/5$,
    %
    \begin{equation} \label{equationBCCGWDASCI}
        |\nu(\TT^d) - 1| \leq C K^{-1/2},
    \end{equation}
    %
    and
    %
    \begin{equation} \label{equationBBEOFIDOAOXXS}
        \| \widehat{\mu_0} - \widehat{\nu} \|_{L^\infty(D_\alpha)} \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
\end{theorem}

\begin{remark}
    The measure constructed in Theorem \ref{randomFourierTheorem} is `essentially' a probability measure, with total mass equal to one plus a small error term. In particular, normalizing, defining a probability measure
    %
    \[ \mu(x) = \frac{\nu(x)}{\nu(\TT^d)}, \]
    %
    then if \eqref{equationBCCGWDASCI} and \eqref{equationBBEOFIDOAOXXS} hold, they also imply that there exists a constant $C$ depending only on $\mu_0$, $d$, and $\alpha$, such that
    %
    \begin{equation}
        \| \widehat{\mu_0} - \widehat{\mu} \|_{L^\infty(D_\alpha)} \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
\end{remark}

%\begin{remark}
%    The simplest example of inputs to which this lemma applies is obtained by fixing two integers $N$ and $M$, letting $I = [2N]^d$ (so $K = N^d$, and for each $i \in [2N]^d$, defining $X_i = i/N + j(i)/NM$, where $j(i)$ is chosen from $[M]^d$ uniformly at random, such that the family $\{ j(i) : i \in [2N]^d \}$ is independant. Equation \eqref{equationA} is then justified by \eqref{equation5550002352124124512}.
%\end{remark}

%\begin{remark}
%    Another example is obtaing by considering $K$ independant and uniformly distributed random variables $\{ X_1, \dots, X_K \}$ on $\TT^d$. Here the choice of $\varepsilon_0$ is arbitrary.
%\end{remark}

Theorem \ref{randomFourierTheorem} follows by taking a union bound to the results of the following two lemmas.

\begin{lemma} \label{nuboundlemma}
    There exists a constant $C$ depending only on $\mu_0$ and $d$ such that
    %
    \[ \PP \left( |\nu(\TT^d) - 1 | \geq C K^{-1/2} \right) \leq 1/10. \]
\end{lemma}
\begin{proof}
    For each $i \in \{ 1, \dots, K \}$, set
    %
    \[ Y_i = \frac{1}{K} \int_{\TT^d} \phi_{\varepsilon_0}(x - X_i)\; d\mu_0(x). \]
    %
    Then
    %
    \begin{equation} \label{equation2194012512905}
        |Y_i| \leq \frac{\| \mu_0 \|_{L^\infty(\TT^d)}}{K} \lesssim_{\mu_0} 1/K.
    \end{equation}
    %
    Moreover,
    %
    \begin{equation} \label{equation12931029}
        \sum_{i = 1}^K Y_i = \nu(\TT^d).
    \end{equation}
    %
    The family of random variables $\{ Y_1, \dots, Y_K \}$ are independant, so we can apply Hoeffding's inequality together with \eqref{equation2194012512905} and \eqref{equation12931029} to conclude that there exists a constant $C$ depending only on $\mu_0$ and $d$, such that for any $t \geq 0$,
    %
    \begin{equation} \label{equation190609190249019}
        \PP \left( |\nu(\TT^d) - \EE(\nu(\TT^d))| \geq t \right) \leq 2 \exp \left( - \frac{5 K t^2}{C^2} \right).
    \end{equation}
    %
    Noting that \eqref{equationA} implies $\EE(\nu(\TT^d)) = 1$, it suffices to set $t = CK^{-1/2}$ in \eqref{equation190609190249019}.
\end{proof}

\begin{lemma} \label{lemma532952}
    For each $\alpha > 0$, there exists a constant $C$, depending only on $\mu_0$, $d$, and $\alpha$, such that
    %
    \[ \PP \left( \| \widehat{\nu} - \widehat{\mu_0} \|_{L^\infty(D_\alpha)} \geq C K^{-1/2} \log(K)^{1/2} \right) \leq 1/10. \]
\end{lemma}
\begin{proof}
    For each $i \in \{ 1, \dots, K \}$, let $\nu_i(x) = K^{-1} \phi_{\varepsilon_0}(x - X_i) \mu_0(x)$. Then for each $\xi \in \ZZ^d$, define $Y_i(\xi) = \widehat{\nu_i}(\xi)$. For each $i$ and $\xi$, the standard $(L^1,L^\infty)$ bound on the Fourier transform implies
    %
    \begin{equation} \label{equation123102}
    \begin{split}
        |Y_i(\xi)| \leq \frac{\nu_i(\TT^d)}{K} \leq \frac{\| \mu_0 \|_{L^\infty(\TT^d)}}{K} \lesssim_{\mu_0} \frac{1}{K}.
    \end{split}
    \end{equation}
    %
    For a fixed $\xi \in \ZZ^d$, the family of random variables $\{ Y_1(\xi), \dots, Y_K(\xi) \}$ are independant and moreover,
    %
    \begin{equation} \label{equation998321521422}
        \sum_{i = 1}^K Y_i(\xi) = \widehat{\nu}(\xi).
    \end{equation}
    %
    Thus Hoeffding's inequality together with \eqref{equation123102} and \eqref{equation998321521422} imply that
    %
    \begin{equation} \label{equation19041209}
        \PP \left( \left| \widehat{\nu}(\xi) - \EE(\widehat{\nu}(\xi)) \right| \geq t \right) \leq 2 \exp \left( - K t^2 /\; \| \mu_0 \|_{L^\infty(\TT^d)}^2 \right)
    \end{equation}
    %
    for all $t \geq 0$. Applying a union bound to \eqref{equation19041209} over all $|\xi| \leq K^{1/\alpha}$, we conclude that there exists a constant $C$, depending only on $\alpha$, $d$, and $\mu_0$, such that for each $t \geq 0$,
    %
    \begin{equation} \label{equation1290419205129051920}
        \PP \left( \| \widehat{\nu} - \EE(\widehat{\nu}) \|_{L^\infty(D_\alpha)} \geq t \right) \leq \exp \left( C \log(K) - \frac{5 K t^2}{C} \right).
    \end{equation}
    %
    We can make $C$ as large as we want, so in particular, we assume $C \geq 1$. Noting that \eqref{equationA} implies $\EE(\widehat{\nu}) = \widehat{\mu_0}$ and setting $t = C K^{-1/2} \log(K)^{1/2}$ in \eqref{equation1290419205129051920} completes the proof.
\end{proof}

Combining Theorem \ref{lemma6213} and Theorem \ref{randomFourierTheorem}, we can control both large and small frequency terms in the Fourier series of a smooth random measure.

\begin{theorem}
    Fix $A > 0$, $\alpha \in (0,d]$, and $\varepsilon > 0$, and a sequence of positive integers $\{ B(\xi) : \xi \in \ZZ^d \}$ such that $B(\xi) \to \infty$ as $|\xi| \to \infty$. Then consider a smooth measure $\mu_0$ on $\TT^d$. Consider the measure $\nu$ as defined in Theorem \ref{randomFourierTheorem}, where
    %
    \[ \varepsilon \geq (AK)^{-1/\alpha}, \]
    %
    and define
    %
    \[ \mu(x) = \nu(x) / \nu(\TT^d). \]
    %
    Then there exists a constant $C$, depending on $\mu_0$, $d$, $A$, and $\varepsilon$ such that for all $\xi \in \ZZ^d$,
    %
    \[ |\widehat{\mu}(\xi) - \widehat{\mu_0}(\xi)| \leq B(\xi) |\xi|^{-\alpha/2} \log(1 + |\xi|)^{1/2}. \]
    %

\end{theorem}
\begin{proof}
    

    Fix $\alpha_2 \in (\alpha_1, \alpha_0)$ and $\alpha_3 \in (\alpha_1,\alpha_2)$, pick $\varepsilon_1$ such that $(1 + \varepsilon_1)/\alpha_0 = 1/\alpha_2$, and let $T = 1 + \alpha_1/2$. Then Theorem \ref{lemma6213} and Theorem \ref{randomFourierTheorem} imply that there exists a constant $C > 0$, depending only on $\mu_0$, $d$, $\alpha_0$, and $\alpha_1$, such that with probability greater than or equal to $4/5$,
    %
    \begin{equation} \label{equationGHLHPOX}
        |\nu(\TT^d) - 1| \leq C K^{-1/2},
    \end{equation}
    %
    \begin{equation} \label{equationGGLAPSOCCXXS}
        \| \widehat{\mu_0} - \widehat{\nu} \|_{L^\infty(D_{\alpha_3})} \leq C K^{-1/2} \log(K)^{1/2},
    \end{equation}
    %
    and for $|\xi| \geq (1/\varepsilon_0)^{1 + \varepsilon_1} = (A K^{1/\alpha_0})^{1 + \varepsilon_1} = A^{\alpha_0 / \alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPFOSOXIS}
        |\widehat{\nu}(\xi)| \leq C |\xi|^{-T}.
    \end{equation}
    %
    Now \eqref{equationGHLHPOX} and \eqref{equationGGLAPSOCCXXS} imply that
    %
    \begin{equation} \label{equationPPGOSIZZAAS}
    \begin{split}
         \| \widehat{\mu_0} - \widehat{\mu} \|_{L^\infty(D_{\alpha_3})} &\leq \| \widehat{\mu_0} - \widehat{\nu} \|_{L^\infty(D_{\alpha_3})} + \| \widehat{\nu} - \widehat{\mu} \|_{L^\infty(D_{\alpha_3})}\\
         &\lesssim_{\mu_0, d, \alpha_0, \alpha_1} K^{-1/2} \log(K)^{1/2} + \left( 1 - \frac{1}{\nu(\TT^d)} \right)\\
         &\lesssim_{\mu_0, d,\alpha_0,\alpha_1} K^{-1/2} \log(K)^{1/2}.
    \end{split}
    \end{equation}
    %
    Thus \eqref{equationPPGOSIZZAAS} implies that for $|\xi| \leq K^{1/\alpha_3}$,
    %
    \[ |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \lesssim_{\mu_0,d,\alpha_0,\alpha_1} K^{-1/2} \log(K)^{1/2} \leq |\xi|^{-\alpha_1/2} K^{[\alpha_1/\alpha_3-1]/2} \log(K)^{1/2}. \]
    %
    Since $\alpha_1/\alpha_3 - 1 < 0$, and the implicit constants do not depend on $K$, we conclude there is $K_0$, depending on $\mu_0$, $d$, $\alpha_0$, $\alpha_1$, and $\varepsilon$, such that for $K \geq K_0$, and $|\xi| \leq K^{1/\alpha_3}$,
    %
    \begin{equation} \label{equationDFCSPSOA}
        |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \leq \varepsilon \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Similarily, \eqref{equationGHLHPOX} and \eqref{equationPPFOSOXIS} imply that for $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPSDSXSA}
        |\widehat{\mu}(\xi)| \lesssim_{\mu_0, d, \alpha_0, \alpha_1} |\xi|^{-1} |\xi|^{-\alpha_1/2} \lesssim_{A,\alpha_0,\alpha_2} K^{-1/\alpha_2} |\xi|^{-\alpha_1/2} \leq K^{-1/\alpha_1} |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Since the implicit constants in \eqref{equationPPSDSXSA} do not depend on $K$, there exists $K_0$, depending on $\mu_0, d, \alpha_0, \alpha_1$, $\alpha_3$, $A$, and $\varepsilon > 0$, such that for $K \geq K_0$ and $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationGGPCOSPS}
        |\widehat{\mu}(\xi)| \leq (\varepsilon/2) \cdot |\xi|^{-\alpha_1/2}.
    \end{equation} 
    %
    Since $\mu_0$ is smooth, there exists $K_0$, depending on $A$, $\mu_0$, $\varepsilon$, $\alpha_0$, and $\alpha_2$, such that if $K \geq K_0$, and $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPPOSXSVIII}
        |\widehat{\mu_0}(\xi)| \leq (\varepsilon/2) \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Combining \eqref{equationGGPCOSPS} and \eqref{equationPPPOSXSVIII}, we conclude that if $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationGGDCISIXXS}
        |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \leq \varepsilon \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    If $K_0$ is large enough, depending on $A$, $\alpha_0$, and $\alpha_2$, such that $A^{\alpha_0/\alpha_2} K_0^{1/\alpha_2} \leq K_0^{1/\alpha_3}$, \eqref{equationDFCSPSOA} and \eqref{equationGGDCISIXXS} are sufficient to prove the required bounds. All that remains is to remove the explit reliance of $K_0$ on $\alpha_2$ and $\alpha_3$, but this can be done by making $\alpha_2$ and $\alpha_3$ explicit functions of $\alpha_0$ and $\alpha_1$, i.e. setting $\alpha_2 = \alpha_0/2 + \alpha_1/2$ and $\alpha_3 = \alpha_0/4 + 3\alpha_1/4$.
\end{proof}

\begin{theorem}
    Fix $A > 0$, $\alpha_0 \in (0,d]$, and a smooth measure $\mu_0$ on $\TT^d$. Consider the measure $\nu$ as defined in Theorem \ref{randomFourierTheorem}, where
    %
    \[ (AK)^{-1/\alpha_0} \leq \varepsilon_0 \leq 2 (AK)^{-1/\alpha_0}, \]
    %
    and define
    %
    \[ \mu(x) = \frac{\nu(x)}{\nu(\TT^d)}. \]
    %
    Then, for any $\alpha_1 \in (0,\alpha_0)$ and $\varepsilon > 0$, there exists $K_0$ depending on $\mu_0$, $\alpha_1$, and $d$, such that for $K \geq K_0$, with probability greater than or equal to $4/5$,
    %
    \[ \sup_{\xi \in \ZZ^d} \left( |\widehat{\mu}(\xi) - \widehat{\mu_0}(\xi)| \right) |\xi|^{\alpha_1/2} \leq \varepsilon. \]
\end{theorem}
\begin{proof}
    Fix $\alpha_2 \in (\alpha_1, \alpha_0)$ and $\alpha_3 \in (\alpha_1,\alpha_2)$, pick $\varepsilon_1$ such that $(1 + \varepsilon_1)/\alpha_0 = 1/\alpha_2$, and let $T = 1 + \alpha_1/2$. Then Theorem \ref{lemma6213} and Theorem \ref{randomFourierTheorem} imply that there exists a constant $C > 0$, depending only on $\mu_0$, $d$, $\alpha_0$, and $\alpha_1$, such that with probability greater than or equal to $4/5$,
    %
    \begin{equation} \label{equationGHLHPOX}
        |\nu(\TT^d) - 1| \leq C K^{-1/2},
    \end{equation}
    %
    \begin{equation} \label{equationGGLAPSOCCXXS}
        \| \widehat{\mu_0} - \widehat{\nu} \|_{L^\infty(D_{\alpha_3})} \leq C K^{-1/2} \log(K)^{1/2},
    \end{equation}
    %
    and for $|\xi| \geq (1/\varepsilon_0)^{1 + \varepsilon_1} = (A K^{1/\alpha_0})^{1 + \varepsilon_1} = A^{\alpha_0 / \alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPFOSOXIS}
        |\widehat{\nu}(\xi)| \leq C |\xi|^{-T}.
    \end{equation}
    %
    Now \eqref{equationGHLHPOX} and \eqref{equationGGLAPSOCCXXS} imply that
    %
    \begin{equation} \label{equationPPGOSIZZAAS}
    \begin{split}
         \| \widehat{\mu_0} - \widehat{\mu} \|_{L^\infty(D_{\alpha_3})} &\leq \| \widehat{\mu_0} - \widehat{\nu} \|_{L^\infty(D_{\alpha_3})} + \| \widehat{\nu} - \widehat{\mu} \|_{L^\infty(D_{\alpha_3})}\\
         &\lesssim_{\mu_0, d, \alpha_0, \alpha_1} K^{-1/2} \log(K)^{1/2} + \left( 1 - \frac{1}{\nu(\TT^d)} \right)\\
         &\lesssim_{\mu_0, d,\alpha_0,\alpha_1} K^{-1/2} \log(K)^{1/2}.
    \end{split}
    \end{equation}
    %
    Thus \eqref{equationPPGOSIZZAAS} implies that for $|\xi| \leq K^{1/\alpha_3}$,
    %
    \[ |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \lesssim_{\mu_0,d,\alpha_0,\alpha_1} K^{-1/2} \log(K)^{1/2} \leq |\xi|^{-\alpha_1/2} K^{[\alpha_1/\alpha_3-1]/2} \log(K)^{1/2}. \]
    %
    Since $\alpha_1/\alpha_3 - 1 < 0$, and the implicit constants do not depend on $K$, we conclude there is $K_0$, depending on $\mu_0$, $d$, $\alpha_0$, $\alpha_1$, and $\varepsilon$, such that for $K \geq K_0$, and $|\xi| \leq K^{1/\alpha_3}$,
    %
    \begin{equation} \label{equationDFCSPSOA}
        |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \leq \varepsilon \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Similarily, \eqref{equationGHLHPOX} and \eqref{equationPPFOSOXIS} imply that for $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPSDSXSA}
        |\widehat{\mu}(\xi)| \lesssim_{\mu_0, d, \alpha_0, \alpha_1} |\xi|^{-1} |\xi|^{-\alpha_1/2} \lesssim_{A,\alpha_0,\alpha_2} K^{-1/\alpha_2} |\xi|^{-\alpha_1/2} \leq K^{-1/\alpha_1} |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Since the implicit constants in \eqref{equationPPSDSXSA} do not depend on $K$, there exists $K_0$, depending on $\mu_0, d, \alpha_0, \alpha_1$, $\alpha_3$, $A$, and $\varepsilon > 0$, such that for $K \geq K_0$ and $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationGGPCOSPS}
        |\widehat{\mu}(\xi)| \leq (\varepsilon/2) \cdot |\xi|^{-\alpha_1/2}.
    \end{equation} 
    %
    Since $\mu_0$ is smooth, there exists $K_0$, depending on $A$, $\mu_0$, $\varepsilon$, $\alpha_0$, and $\alpha_2$, such that if $K \geq K_0$, and $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPPOSXSVIII}
        |\widehat{\mu_0}(\xi)| \leq (\varepsilon/2) \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Combining \eqref{equationGGPCOSPS} and \eqref{equationPPPOSXSVIII}, we conclude that if $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationGGDCISIXXS}
        |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \leq \varepsilon \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    If $K_0$ is large enough, depending on $A$, $\alpha_0$, and $\alpha_2$, such that $A^{\alpha_0/\alpha_2} K_0^{1/\alpha_2} \leq K_0^{1/\alpha_3}$, \eqref{equationDFCSPSOA} and \eqref{equationGGDCISIXXS} are sufficient to prove the required bounds. All that remains is to remove the explit reliance of $K_0$ on $\alpha_2$ and $\alpha_3$, but this can be done by making $\alpha_2$ and $\alpha_3$ explicit functions of $\alpha_0$ and $\alpha_1$, i.e. setting $\alpha_2 = \alpha_0/2 + \alpha_1/2$ and $\alpha_3 = \alpha_0/4 + 3\alpha_1/4$.
\end{proof}

\section{A Complete Metric Space of Generically Salem Sets}

\begin{comment}

\begin{lemma}
    For quasi-all $(E,\mu) \in \mathcal{X}$, $\text{supp}(\mu) = E$.
\end{lemma}
\begin{proof}
    For each closed set $K \subset \TT^d$ with nonempty interior, let $A(K)$ be the family of all $(E,\mu) \in X$ such that $E \cap K \neq \emptyset$ and $\mu(K) = 0$. The set $A(K)$ is clearly closed in $X$. Moreover, this set is nowhere dense; Fix $(E,\mu) \in A(K)$ and $\varepsilon > 0$. Then we can find a smooth probability density $\psi \in C^\infty(\TT^d)$ supported on $K^\circ \cap E_\varepsilon$. We then define $\mu_\varepsilon = (1 - \varepsilon) \mu + \varepsilon \psi$. Now
    %
    \[ \| \mu - \mu_\varepsilon \|_A \leq \varepsilon \left( \| \mu \|_A + \| \psi \|_A \right) \lesssim \varepsilon. \]
    %
    Moreover, $\mu_\varepsilon$ is supported on $\overline{E_\varepsilon}$, so
    %
    \[ d_X((E,\mu), (\overline{E_\varepsilon}, \mu_\varepsilon)) \lesssim \varepsilon. \]
    %
    If we let $A = \bigcup_{n = 1}^\infty A(K_n)$, where $\{ K_n \}$ is the family of all closed cubes in $\TT^d$ whose corners have rational coordinates, then quasi-all $(E,\mu) \in X$ belong to $A^c$. But $A^c$ is precisely the family of pairs $(E,\mu)$ with $\text{supp}(\mu) = E$.
\end{proof}

\end{comment}

All that now remains is to show that quasi-all elements of $\mathcal{X}$ avoid the given set $Z$; just as with the proof above, the advantage of the Baire category approach is that we can reduce our calculations to discussing only a couple scales at once, which allows us to focus solely on the discrete, quantitative question at the heart of the problem.

\section{Random Avoiding Sets} 

\begin{lemma}
    For quasi-all $(E,\mu)$, for any distinct points $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$.
\end{lemma}
\begin{proof}
    Let us fix a set $W \subset \RR^{nd}$, and $\varepsilon_0 > 0$ such that
    %
    \begin{equation} \label{equationGGSCSAS}
        |W_{\varepsilon_0}| \leq \varepsilon_0^{nd - \alpha}.
    \end{equation}
    %
    Fix a large integer $K$, and consider a family
    %
    \[ \{ X_{ij} : 1 \leq i \leq n, 1 \leq j \leq K \} \]
    %
    of independant, uniformly distributed random variables on $\TT^d$. Set $E_i = \{ X_{i1}, \dots, X_{iK} \}$. We wish to determine the density of a uniformly distributed $X \in \TT^d$, subject to the condition that $X \in (\TT \times E_2 \times \dots \times E_n) \cap W_{\varepsilon_0}$. If $E_2, \dots, E_n$ are fixed, non-random sets, then the distribution of $X$ is constant on $(E_2 \times \dots \times E_n) \cap W_{\varepsilon_0}$.

    Fix a large integer $K$, and let $X_1, \dots, X_K$ be independent and uniformly distributed on $\TT^d$. For each distinct set of indices $i_1, \dots, i_n \in \{ 1, \dots, K \}$, the random vector $X_i = (X_{i_1}, \dots, X_{i_n})$ is uniformly distributed on $\TT^{nd}$, and so \eqref{equationGGSCSAS} implies
    %
    \begin{equation} \label{equationGGASDCJWIJSFGGGG}
        \PP(d(X_i,W) \leq \varepsilon_0) \leq |W_{\varepsilon_0}| \leq \varepsilon_0^{nd - \alpha}.
    \end{equation}
    %
    If $M$ denotes the number of indices $i$ such that $d(X_i,W) \leq \varepsilon_0$, then by linearity of expectation we conclude from \eqref{equationGGASDCJWIJSFGGGG} that
    %
    \begin{equation} \label{equationDDASGVV}
        \EE(M) \leq K^n \varepsilon_0^{nd - \alpha}.
    \end{equation}
    %
    Applying Markov's inequality to \eqref{equationDDASGVV}, we conclude that
    %
    \begin{equation} \label{equationFGGGSC}
        \PP(M \geq 10 K^n \varepsilon_0^{nd - \alpha}) \leq 1/10.
    \end{equation}
    %
    Taking a union bound to \eqref{equationFGGGSC} and the result of Lemma \ref{LemmaGISCICS1}, we conclude that there exists $K$ points $x_1, \dots, x_K \in \TT^d$ and a constant $C$ depending on $d$ and $\beta$ such that if
    %
    \[ D_0(x) = \frac{1}{K} \sum_{k = 1}^K \delta(x - x_k) \]
    %
    then for $|\xi| \leq K^{1/\beta + 1}$,
    %
    \begin{equation} \label{equationGGGISCI11242}
        |\widehat{D_0}(\xi)| \leq C K^{-1/2} \log(K)^{1/2},
    \end{equation}
    %
    and if $S$ is the set of indices $k_1 \in \{ 1, \dots, K \}$ such that we can find distinct $k_1, k_2, \dots, k_n \in \{ 1, \dots, K \}$ such that $d((x_{k_1}, \dots, x_{k_n}), W) \leq \varepsilon_0$, then
    %
    \begin{equation} \label{equationGGSC99124}
        \#(S) \leq 10 K^n \varepsilon_0^{nd-\alpha}.
    \end{equation}
    %
    In particular, if we set $C_1 = 10^{1/(nd-\alpha)}$, and we set $\varepsilon_0 = C_1^{-1} K^{-1/\beta}$ (TODO: WHERE $\beta = (nd - \alpha)/(n-1/2)$), then
    %
    \[ \#(S) \leq K^{1/2}. \]
    %
    In particular, this means that if we set
    %
    \[ D_1(x) = \sum_{k \not \in S} \delta(x - x_k), \]
    %
    then for each $|\xi| \leq K^{1/\beta + 1}$,
    %
    \[ |\widehat{D_1}(\xi)| \leq (C+1) K^{-1/2} \log(K). \]
    %
    Applying Lemmas \ref{LemmaTTSICICS} and \ref{Lemma65493}, we conclude that there is $K_0$ such that if
    %
    \[ \mu(x) = \left( \sum_{k \not \in S} \phi_{0.5 \varepsilon_0}(x - x_k) \right) \mu_0(x) \]
    %
    and $K \geq K_0$, then
    %
    \[ \| \mu - \mu_0 \|_{M(A)} \leq \varepsilon. \]
    %
    Notice that $\text{supp}(\mu) = \text{supp}(D_1)_{0.5 \varepsilon_0}$. For any distinct $x_1, \dots, x_n \in \text{supp}(D_1)$,
    %
    \[ d((x_1, \dots, x_n), W) \geq \varepsilon_0. \]
    %
    Thus if $x_1', \dots, x_n' \in \text{supp}(\mu)$ are $s$-separated, and $\varepsilon_0 \leq s$, then
    %
    \[ d((x_1', \dots, x_n'),W) \geq 0.5 \varepsilon_0. \]
    %
    Thus
\end{proof}

This gives the result for $\beta = (nd-\alpha)/(n-1/2)$. Let's see if we can improve this to $(nd-\alpha)/(n-1)$.

\begin{proof}
    The set $Z \subset \RR^{nd}$ is the countable union of sets with Minkowski dimension at most $\alpha$. Consider $n$ open sets $U_1, \dots, U_n$ with $d(U_i,U_j) \geq 1/N$ for $i \neq j$. For a closed set $W$ with Minkowski dimension at most $\alpha$, consider the set
    %
    \[ B(W,U_1,\dots,U_n) = \left\{ (E,\mu) \in \mathcal{X} : \text{for $x_1 \in E \cap U_1, \dots, x_n \in E \cap U_n$, $(x_1, \dots, x_n) \not \in W$} \right\}. \]
    %  
    It thus suffices to show that $B(W,s)$ is dense in $\mathcal{X}$ for any $W$ and $s$. Thus fix $(E_0,\mu_0) \in \mathcal{X}$ and $\varepsilon > 0$. We will construct $(E,\mu) \in \mathcal{X}$ with $(E,\mu) \in B(W,s)$ and $d_{\mathcal{X}}((E_0,\mu_0),(E,\mu)) \leq \varepsilon$.

    If we fix a set $W \subset \RR^{nd}$ with Minkowski dimension at most $\alpha$, then there exists arbitrarily small $\varepsilon_0 > 0$ such that
    %
    \begin{equation} \label{equationGGSCSAS}
        |W_{\varepsilon_0}| \leq \varepsilon_0^{nd - \alpha}.
    \end{equation}
    %
    Fix a large integer $K$, and let $X_1, \dots, X_K$ be independent and uniformly distributed on $\TT^d$. For each distinct set of indices $i_1, \dots, i_n \in \{ 1, \dots, K \}$, the random vector $X_i = (X_{i_1}, \dots, X_{i_n})$ is uniformly distributed on $\TT^{nd}$, and so \eqref{equationGGSCSAS} implies
    %
    \begin{equation} \label{equationGGASDCJWIJSFGGGG}
        \PP(d(X_i,W) \leq \varepsilon_0) \leq |W_{\varepsilon_0}| \leq \varepsilon_0^{nd - \alpha}.
    \end{equation}
    %
    If $M$ denotes the number of indices $i$ such that $d(X_i,W) \leq \varepsilon_0$, then by linearity of expectation we conclude from \eqref{equationGGASDCJWIJSFGGGG} that
    %
    \begin{equation} \label{equationDDASGVV}
        \EE(M) \leq K^n \varepsilon_0^{nd - \alpha}.
    \end{equation}
    %
    Applying Markov's inequality to \eqref{equationDDASGVV}, we conclude that
    %
    \begin{equation} \label{equationFGGGSC}
        \PP(M \geq 10 K^n \varepsilon_0^{nd - \alpha}) \leq 1/10.
    \end{equation}
    %
    Taking a union bound to \eqref{equationFGGGSC} and the result of Lemma \ref{LemmaGISCICS1}, we conclude that there exists $K$ points $x_1, \dots, x_K \in \TT^d$ and a constant $C$ depending on $d$ and $\beta$ such that if
    %
    \[ D_0(x) = \frac{1}{K} \sum_{k = 1}^K \delta(x - x_k) \]
    %
    then for $|\xi| \leq K^{1/\beta + 1}$,
    %
    \begin{equation} \label{equationGGGISCI11242}
        |\widehat{D_0}(\xi)| \leq C K^{-1/2} \log(K)^{1/2},
    \end{equation}
    %
    and if $S$ is the set of indices $k_1 \in \{ 1, \dots, K \}$ such that we can find distinct $k_1, k_2, \dots, k_n \in \{ 1, \dots, K \}$ such that $d((x_{k_1}, \dots, x_{k_n}), W) \leq \varepsilon_0$, then
    %
    \begin{equation} \label{equationGGSC99124}
        \#(S) \leq 10 K^n \varepsilon_0^{nd-\alpha}.
    \end{equation}
    %
    In particular, if we set $C_1 = 10^{1/(nd-\alpha)}$, and we set $\varepsilon_0 = C_1^{-1} K^{-1/\beta}$ (TODO: WHERE $\beta = (nd - \alpha)/(n-1/2)$), then
    %
    \[ \#(S) \leq K^{1/2}. \]
    %
    In particular, this means that if we set
    %
    \[ D_1(x) = \sum_{k \not \in S} \delta(x - x_k), \]
    %
    then for each $|\xi| \leq K^{1/\beta + 1}$,
    %
    \[ |\widehat{D_1}(\xi)| \leq (C+1) K^{-1/2} \log(K). \]
    %
    Applying Lemmas \ref{LemmaTTSICICS} and \ref{Lemma65493}, we conclude that there is $K_0$ such that if
    %
    \[ \mu(x) = \left( \sum_{k \not \in S} \phi_{0.5 \varepsilon_0}(x - x_k) \right) \mu_0(x) \]
    %
    and $K \geq K_0$, then
    %
    \[ \| \mu - \mu_0 \|_{M(A)} \leq \varepsilon. \]
    %
    Notice that $\text{supp}(\mu) = \text{supp}(D_1)_{0.5 \varepsilon_0}$. For any distinct $x_1, \dots, x_n \in \text{supp}(D_1)$,
    %
    \[ d((x_1, \dots, x_n), W) \geq \varepsilon_0. \]
    %
    Thus if $x_1', \dots, x_n' \in \text{supp}(\mu)$ are $s$-separated, and $\varepsilon_0 \leq s$, then
    %
    \[ d((x_1', \dots, x_n'),W) \geq 0.5 \varepsilon_0. \]
    %
    Thus
\end{proof}

\begin{thebibliography}{9}

\bibitem{Korner1}
    T.W. K\"{o}rner,
    \textit{Measures on Independent Sets, A Quantitative Version of Rudin's Theorem}.

\bibitem{Korner2}
    T.W. K\"{o}rner,
    \textit{Fourier Transforms of Measures and Algebraic Relations on Their Supports}.

\bibitem{OurPaper}
    Jacob Denson, Malabika Pramanik, Joshua Zahl,
    \textit{Large Sets Avoiding Rough Patterns}.

\bibitem{myThesis}
    Jacob Denson,
    \textit{Cartesian Products Avoiding Patterns}.

\bibitem{Vershynin}
    Roman Vershynin,
    \textit{High Dimensional Probability},
    Cambridge Series in Statistical and Probabilistic Mathematics,
    2018.

\end{thebibliography}

\end{document}