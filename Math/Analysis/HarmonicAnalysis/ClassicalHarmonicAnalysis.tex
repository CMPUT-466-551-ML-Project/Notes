%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = HarmonicAnalysis.tex

\part{Classical Fourier Analysis}

Deep mathematical knowledge often arises hand in hand with the characterization of symmetry. Nowhere is this more clear than in the foundations of harmonic analysis, where we attempt to understand mathematical `signals' by the `frequencies' from which they are composed. In the mid 18th century, problems in mathematical physics led D. Bernoulli, D'Alembert, Lagrange, and Euler to consider $2 \pi$ periodic functions representable as a trigonometric series
%
\[ f(t) = A + \sum_{m = 1}^\infty B_n \cos(mt) + C_n \sin(mt). \]
%
In his book, Th\'{e}orie Analytique de la Chaleur, published in 1811, Joseph Fourier had the audacity to announce that {\it all} functions were representable in this form, and used it to solve linear partial differential equations in physics. His conviction is the reason the classical theory of harmonic analysis is often named Fourier analysis, where we analyze the degree to which Fourier's proclamation holds, as well as it's paired statement on the real line, that a function $f$ on the real line can be written as
%
\[ f(t) = \int_{-\infty}^\infty A(\xi) \cos(\xi t) + B(\xi) \sin(\xi t)\; d\xi. \]
%
for some functions $A$ and $B$.

In the 1820s, Poisson, Cauchy, and Dirichlet all attempted to form rigorous proofs that `Fourier summation' holds for all functions. Their work is responsible for most of the modern subject of analysis we know today. And in order to interpret the validity of Fourier summation, we will need to utilize all the convergence techniques developed during this time. Under pointwise convergence, the representation of a function by Fourier series need not be unique. Uniform convergence is useful, but a function is not uniformly summable for all functions, even if they are continuous! This means we must introduce more subtle methods to measure convergence.

\chapter{Introduction}

The classic oscillatory functions are the trigonometric ones, given by
%
\[ f(t) = A \cos(st) + B \sin(st) = C \cos(st + \phi). \]
%
We have names for some of these parameters:
%
\begin{itemize}
    \item $\phi$ is the \emph{phase} of the oscillation.
    \item $C$ is the \emph{amplitude}.
    \item $s/2\pi$ is the \emph{frequency} of the oscillation.
\end{itemize}
%
Fourier analysis is the topic of understanding the representations of a function as an analytical combination of these functions. In the discrete, periodic setting, we fix a $2\pi$ periodic function $f: \mathbf{R} \to \mathbf{C}$, and try and find coefficients $\{ A_m \}$ and $\{ B_m \}$ such that
%
\[ f(t) \sim C + \sum_{m = 1}^\infty A_m \cos(mt) + B_m \sin(mt). \]
%
In the continuous setting, we fix a function $f: \mathbf{R} \to \mathbf{C}$, trying to find values $A(s)$ and $B(s)$ such that
%
\[ f(t) \sim C + \int_0^\infty A(s) \cos(st) + B(s) \sin(st)\; ds. \]
%
The main contribution of Fourier was a method to formally find a reliable choice of $A(s)$ and $B(s)$, $A_m$ and $B_m$, which represents $f$. This choice is given by the \emph{Fourier transform} of $f$ in the continuous case, and the \emph{Fourier series} in the discrete case.

\section{Obtaining the Fourier Coefficients}

A \emph{formal trigonometric series} is a formal sum of the form
%
\[ C + \sum_{m = 1}^\infty A_m \cos(mt) + B_m \sin(mt). \]
%
Our goal is to find $\{ A_m \}$, $\{ B_m \}$, and $C$ which `represents' a given function $f$. In particular, we say a $2\pi$ periodic function $f$ \emph{admits a trigonometric expansion} if there is a series such that for each $t \in \mathbf{R}$,
%
\[ f(t) = C + \sum_{m = 1}^\infty A_m \cos(mt) + B_m \sin(mt). \]
%
It is a \emph{very difficult question} to characterize which functions $f$ admit a trigonometric expansion. Nonetheless, in the next chapter we will show that all differentiable functions have a trigonometric expansion, in terms of the Fourier series we will define.

\section{Orthogonality}

The key technique Fourier realized could be used to come up with a canonical trigonometric series for a function is \emph{orthogonality}. Note that the various frequencies of sine functions are orthogonal to one another, in the sense that
%
\[ \int_{-\pi}^\pi \sin(mt) \sin(nt) = \int_{-\pi}^\pi \cos(mt) \cos(nt) = \begin{cases} 0 & : m \neq n, \\ \pi & : m = n. \end{cases} \]
%
and for any $m$ and $n$,
%
\[ \int_{-\pi}^\pi \sin(mt) \cos(nt) = 0. \]
%
This means that for a finite trigonometric sum
%
\[ f(t) = C + \sum_{m = 1}^N A_m \cos(mt) + B_m \sin(mt), \]
%
we have
%
\[ C = \frac{1}{2\pi} \int_{-\pi}^\pi f(t)\; dt, \]
\[ A_m = \frac{1}{\pi} \int_{-\pi}^\pi f(t) \cos(mt)\; dt, \quad\text{and}\quad B_m = \frac{1}{\pi} \int_{-\pi}^\pi f(t) \sin(mt)\; dt. \]
%
These values can be defined even if $f$ is not a trigonometric polynomial. Thus given \emph{any} $2\pi$ periodic function $f$, a reasonable candidate for the coefficients is given by the values $A_m$, $B_m$, and $C$ above.

There is an additional choice of oscillatory functions, which replaces the sine and cosine with a single family of trigonometric functions. Given an integer $m$, we consider the $2\pi$ periodic function complex-valued function $e_m(t) = e^{mit}$. Applying orthogonality again, we find
%
\[ \frac{1}{2\pi} \int_{-\pi}^\pi e_n(t) e_m(-t)\; dt = \frac{1}{2\pi} \int_{-\pi}^\pi e_{n-m}(t) = \begin{cases} 0 & : m \neq n, \\ 1 & : m = n. \end{cases}  \]
%
Thus a natural choice of an expansion
%
\[ f(t) \sim \sum_{m \in \mathbf{Z}} C_m e^{mit}, \]
%
is given by
%
\[ C_m = \frac{1}{2\pi} \int_{-\pi}^\pi f(t) e_m(-t)\; dt. \]
%
Euler's formula $e^{mit} = \cos(mt) + i \sin(mt)$ shows this is the same as the Fourier expansion in sines and cosines. Thus the values $\{ A_m, B_m, C : m \geq 0 \}$ can be recovered from the values of $\{ C_m : m \in \mathbf{Z} \}$. Because of it's elegance, unifying the three families of coefficients, the expansion by complex exponentials is the most standard in modern Fourier analysis.

To summarize, we have shown a $2 \pi$ periodic function $f: \mathbf{R} \to \mathbf{C}$ gives rise to a formal trigonometric series
%
\[ \sum_{m \in \mathbf{Z}} C_m e_m(t). \]
%
Because we will be concentrating on the values $C_m$, it is worth reserving a special notation for them. Given a function $f$, we define the \emph{Fourier coefficients}
%
\[ \widehat{f}(m) = (\mathcal{F} f)(m) = C_m = \frac{1}{2\pi} \int_{-\pi}^\pi f(t) e_m(-t)\; dt. \]
%
The Fourier series representation in terms of complex exponentials will be our choice throughout the rest of these notes. No deep knowledge of the complex numbers is used here. For most purposes, the exponential is just a simple way to represent sums of sines and cosines.

\section{The Fourier Transform}

For a general function $f: \mathbf{R} \to \mathbf{C}$, we cannot \emph{just} on orthogonality, because the functions $\sin(mx)$ are not integrable on the entirety of $\mathbf{R}$. Nonetheless, we can consider the functions $g_N: [-\pi,\pi] \to \mathbf{C}$ by setting $g_N(t) = f(Nt)$, then for $|t| \leq N \pi$, we find
%
\begin{align*}
    f(t) &= g_N(t/N)\\
    &\sim \sum_{m \in \mathbf{Z}} \widehat{g_N}(m) e^{(m/N) it}\\
    &= \frac{1}{2\pi} \sum_{m \in \mathbf{Z}} \left( \int_{-\pi}^\pi f(Ns) e^{-mis}\; ds \right) e^{(m/N) it}\\
    &= \sum_{m \in \mathbf{Z}} \frac{1}{2\pi N} \left( \int_{-\pi N}^{\pi N} f(s) e^{-(m/N)is}\; ds \right) e^{(m/N)it}.
\end{align*}
%
If we take $N \to \infty$, the exterior sum operates like a Riemann sum, and the interior integral becomes unbounded, so we find that, in a sense,
%
\[ f(t) \sim \frac{1}{2\pi} \int_{-\infty}^\infty \left( \int_{-\infty}^\infty f(s) e^{-\xi is}\; ds \right) e^{\xi i t}\; d\xi. \]
%
The interior is the \emph{Fourier transform} of the function $f$, denoted
%
\[ \widehat{f}(\xi) = (\mathcal{F} f)(\xi) = \int_{-\infty}^\infty f(s) e^{- \xi is}\; ds. \]
%
Thus the resultant \emph{Fourier inversion formula} takes the form
%
\[ f(t) \sim \frac{1}{2\pi} \int_{-\infty}^\infty \widehat{f}(\xi) e^{\xi i s}\; ds. \]
%
As the \emph{limit} of a discrete series defined in terms of orthogonality, the Fourier transform possesses many of the same properties at the Fourier series. But the limit does cause technical issues which are not present in the case of Fourier series, and so we begin by concentrating on the Fourier series.

%
%\begin{example}
%    This method can be used to find all harmonic functions $f$ on a rectangle $[0,\pi] \times [0,1]$, such that $f(0,y) = f(\pi,y) = 0$. Let us first attempt to find all separable solutions $f(x,y) = u(x) v(y)$. Then the equations defining harmonic functions tell us that
%    %
%    \[ u''v + v''u = 0 \]
%    %
%    or
%    %
%    \[ \frac{u''}{u} = - \frac{v''}{v} = - \lambda^2 \]
%    %
%    (we assume the constant factor is negative, since the constraints on $u$ would force $f$ to be trivial otherwise). Then we have
%    %
%    \[ u'' = - \lambda^2 u \]
%    %
%    so $u(x) = A \cos(\lambda x) + B \sin(\lambda x)$. The constraints that $u(0) = u(\pi) = 0$ force $A = 0$, and $\lambda \in \mathbf{Z}$. We may similarily solve the equation
%    %
%    \[ v'' = \lambda^2 v \]
%    %
%    to conclude $v(y) = M e^{\lambda y} + N e^{- \lambda y}$, so we obtain the solution set
%    %
%    \[ f(x,y) = \sin(n x) (Ae^{n y} + Be^{-ny}) \]
%    %
%    where $n \in \mathbf{Z}$, $A,B \in \RR$.

%    Now suppose we can write
%    %
%    \[ f(x,y) = \sum_{n = -\infty}^\infty \sin(nx) (A_n e^{ny} + B_n e^{-ny}) \]
%    %
%    Then
%    %
%    \[ f_0(x) = \sum_{n = -\infty}^\infty (A_n + B_n) \sin(nx) \]
%    \[ f_1(x) = \sum_{n = -\infty}^\infty (A_n e^n + B_n e^{-n}) \sin(nx) \]
%    %
%    So if $\widehat{f_0}$ and $\widehat{f_1}$ denote the sine coefficients of $f_0$ and $f_1$, then
%    %
%    \[ A_n + B_n = \widehat{f_0}(n)\ \ \ \ \ A_n e^n + B_n e^{-n} = \widehat{f_1}(n) \]
%    %
%    \[ A_n = \frac{\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}}{e^{n} - e^{-n}} \]
%    %
%    \[ B_n = \widehat{f_0}(n) - \frac{\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}}{e^{n} - e^{-n}} = \frac{e^n \widehat{f_0}(n) - \widehat{f_1}(n)}{e^n - e^{-n}} \]
%    %
%    Thus
%    %
%    \begin{align*}
%        f(x,y) &= \sum_{n = -\infty}^\infty \sin(nx) \left( \frac{(\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}) e^{ny} + (e^n \widehat{f_0}(n) - \widehat{f_1}(n)) e^{-ny}}{e^n - e^{-n}} \right)\\
%        &= \sum_{n = -\infty}^\infty \frac{\sin(nx)}{e^n - e^{-n}} [(e^{n(1-y)} - e^{n(y-1)}) \widehat{f_0}(n) + (e^{ny} - e^{-ny}) \widehat{f_1}(n)]\\
%        &= \sum_{n = -\infty}^\infty \left( \frac{\sinh n(1-y)}{\sinh n} \widehat{f_0}(n) + \frac{\sinh ny}{\sinh n} \widehat{f_1}(n) \right) \sin(nx)
%    \end{align*}
%\end{example}

%
%First, define the circle group $\mathbf{T}$ to be the set of complex numbers $z$ with $|z| = 1$. Functions from $\mathbf{T}$ to $\RR$ naturally correspond to $2 \pi$-periodic functions; given $g: \mathbf{T} \to \RR$, the correspondence is given by the equation $f(t) = g(e^{it})$. Thus, when defining $2\pi$ periodic functions, we shall make no distinction between a function `defined in terms of $t$' and a function `defined in terms of $z$', after making the explicit identification $z = e^{it}$. Then an expansion of the form
%
%\[ f(t) = \sum_{k = 0}^\infty A_k \cos(kt) + \sum B_k \sin(kt) \]
%
%leads to an expansion
%
%\begin{align*}
%    f(z) &= \sum_{k = 0}^\infty A_k \Re[z^k] + B_k \Im[z^k]\\
%    &= \sum_{k = 0}^\infty A_k \left( \frac{z^k + z^{-k}}{2} \right) - i B_k \left( \frac{z^k - z^{-k}}{2} \right) = \sum_{k = -\infty}^\infty C_k z^k
%\end{align*}
%
%so a Fourier expansion on $[0,2\pi]$ is really just a power series expansion on the circle in disguise.
%
%Thus expanding a real-valued function in the exponentials $e_n(t) = e^{nit}$ is the same as expanding the function in terms of sines and cosines. The complex exponentials $e_n$ have the same orthogonality properties as $\sin$ and $\cos$, so given a function $f$, the coefficients $C_n$ can be found by the expansion
%
%\[ C_n = \frac{1}{2\pi} \int_{-\pi}^\pi f(t) e_n(-t) dt \]

\section{Basic Properties of Fourier Series}

One of the most important properties of the Fourier series is that the coefficients are controlled by reasonable transformations. A basic, but unappreciated property of the Fourier transform is \emph{linearity}: For any two functions $f$ and $g$,
%
\[ \widehat{f+g} = \widehat{f} + \widehat{g}. \]
%
Linearity is \emph{essential} to most methods in this book, and the field of non-linear functionals still has many fundamental underanswered problems. Fourier series are also stable under various other transformations which occur in analysis, which makes the transform useful. We summarize these properties here:
%
\begin{itemize}
    \item If we define $f^*(x) = \overline{f(x)}$, then $\widehat{f^*}(n) = \overline{\widehat{f}(-n)}$.

    \item If $f$ is real-valued, then
    %
    \[ \widehat{f}(-n) = \overline{\widehat{f}(n)}. \]
    %
    Formally, if $f$ is periodic, and $\widehat{f}(m) = A_m + i B_m$, then
    %
    \begin{align*}
        f(t) &\sim \widehat{f}(0) + \sum_{m = 1}^\infty \widehat{f}(n) e_n(t) + \overline{\widehat{f}(n) e_n(t)}\\
        &= \widehat{f}(0) + \sum_{m = 1}^\infty 2 \text{Re}(\widehat{f}(n) e_n(t))\\
        &= \widehat{f}(0) + \sum_{m = 1}^\infty (2A_m) \cos(mt) + (-2B_m) \sin(mt).
    \end{align*}
    %
    If $\widehat{f}(\xi) = A(\xi) + i B(\xi)$, then
    %
    \begin{align*}
        f(t) &\sim \int_0^\infty \widehat{f}(\xi) e^{\xi i t} + \overline{\widehat{f}(\xi) e^{\xi i t}}\\
        &= \int_0^\infty [(2A(\xi)) \cos(\xi t) + (-2 B(\xi)) \sin(\xi t)]\; d\xi.
    \end{align*}
    %
    Thus we get a real-coefficient expansion in sines and cosines.

    \item Define the translation and frequency modulation operators by
    %
    \[ (T_s f)(t) = f(t-s) \quad\text{and}\quad (M_\xi f)(s) = e_\xi(s) f(s). \]
    %
    Then we have
    %
    \[ \widehat{T_s f} = M_{-s} \widehat{f} \quad\text{and}\quad \widehat{M_\xi f} = T_\xi \widehat{f}. \]
    %
    Thus a translation in the spatial domain corresponds to a modulation in the frequency domain, and vice versa. One can see this using the Fourier summation formula, by the formal calculation
    %
    \[ (T_s f)(t) = \sum_{n \in \mathbf{Z}} A_n e_n(t-s) = \sum_{n \in \mathbf{Z}} (A_n e_n(-s)) e_n(t), \]
    \[ (M_s f)(t) = e_s(t) \sum_{n \in \mathbf{Z}} A_n e_n(t) = \sum_{n \in \mathbf{Z}} A_n e_{n+s}(t) = \sum_{n \in \mathbf{Z}} A_{n - s} e_n(t), \]
    %
    and correspondingly, for the Fourier inversion formula.

    \item If $f$ is odd, then $\widehat{f}$ is odd, so formally we have a sine expansion
    %
    \[ f(t) \sim \sum_{m = 1}^\infty \widehat{f}(m) [e_m(t) - e_{-m}(t)] = 2i \sum_{m = 1}^\infty \widehat{f}(m) \sin(mt). \]

    \item If $f$ is even, then $\widehat{f}(-n) = \widehat{f}(n)$, so formally,
    %
    \[ f(t) \sim \widehat{f}(0) + \sum_{m = 1}^\infty \widehat{f}(m) [e_m(t) + e_{-m}(t)] = \widehat{f}(0) + 2 \sum_{m = 1}^\infty \widehat{f}(m) \cos(mt). \]

    \item If $f$ has a derivative $f'$, then for periodic $f$, $\mathcal{F}(f')(n) = in \widehat{f}(n)$, and for nonperiodic $f$, $\mathcal{F}(f')(\xi) = i\xi \widehat{f}(\xi)$. A formal calculation using the Fourier summation formula hints at this, by letting
    %
    \[ \frac{d}{dt} \sum_{n = -\infty}^\infty A_n e_n(t) = \sum_{n = -\infty}^\infty A_n \frac{de_n(t)}{dt} = \sum_{n = -\infty}^\infty (ni A_n) e_n(t). \]
\end{itemize}

All but the last relation can be proved by easy exercises in manipulating periodic integrals, when $f$ is a $2\pi$ periodic measurable function with
%
\[ \int_{-\pi}^\pi |f(x)|\; dx < \infty. \]
%
The space of all such functions will be denoted by $L^1(\mathbf{T})$, which is a Banach space under the norm
%
\[ \| f \|_{L^1(\mathbf{T})} = \frac{1}{2\pi} \int_{-\pi}^\pi |f(x)|\; dx. \]
%
The latter property involving the derivative of $f$ holds by an easy integration by parts. This proof therefore holds whenever $f$ has a weak derivative in $L^1(\mathbf{T})$.

\section{Examples of Expansions}

Before we get to the real work, let's start by computing some Fourier series, to use as examples. We also illustrate the convergence properties of these series, which we shall look at in more detail later.

\begin{example}
    Consider the function $f: [0,\pi] \to \RR$ defined by $f(x) = x(\pi - x)$. Then a series of integration by parts gives that
    %
    \[ \int x(\pi - x) \sin(nx) = \frac{x(\pi - x) \cos(nx)}{n} + \frac{(\pi - 2x) \sin(nx)}{n^2} - \frac{2\cos(nx)}{n^3}. \]
    %
    Thus
    %
    \[ \frac{2}{\pi} \int_0^\pi x(\pi - x) \sin(nx) = \frac{4(1 - \cos(n\pi))}{n^3} = \begin{cases} \frac{8}{\pi n^3} & n\ \text{odd}, \\ 0 & n\ \text{even}. \end{cases}  \]
    %
    Thus we have a formal representation
    %
    \[ f(x) = \sum_{n\ \text{odd}} \frac{8}{\pi n^3} \sin(nx). \]
    %
    This sum converges absolutely and uniformly for $x \in [0,\pi]$. If we extend the domain of $f$ to $[-\pi,\pi]$ by making $f$ odd, then
    %
    \[ \widehat{f}(n) = \begin{cases} \frac{4}{\pi i n^3} & : n\ \text{odd}, \\ 0 & : n\ \text{even}. \end{cases} \]
    %
    In this case, we still have
    %
    \[ f(x) = \sum_{\substack{n\ \text{odd}\\ n > 0}} \frac{4}{\pi i n^3} [e_n(x) - e_n(-x)] = \sum_{n\ \text{odd}} \frac{8}{\pi n^3} \sin(nx). \]
    %
    This sum converges absolutely and uniformly on the entire real line.
\end{example}

\begin{example}
    The tent function
    %
    \[ f(x) = \begin{cases} 1 - \frac{|x|}{\delta} & : |x| < \delta, \\ 0 & : |x| \geq \delta. \end{cases} \]
    %
    is even, and therefore has a purely real Fourier expansion
    %
    \[ \widehat{f}(0) = \frac{\delta}{2\pi},\quad\widehat{f}(n) = \frac{1 - \cos(n\delta)}{\delta \pi n^2}. \]
    %
    Thus we obtain an expansion
    %
    \[ f(x) = \frac{\delta}{2\pi} + \sum_{n \neq 0} \frac{1 - \cos(n\delta)}{\delta \pi n^2} e_n(x) = \frac{\delta}{2 \pi} + 2 \sum_{n = 1}^\infty \frac{1 - \cos(n\delta)}{\delta \pi n^2} \cos(nx). \]
    %
    This sum also converges absolutely and uniformly.
\end{example}

\begin{example}
    Consider the characteristic function
    %
    \[ \chi_{(a,b)}(x) = \begin{cases} 1 & : x \in (a,b), \\ 0 & : x \not \in (a,b). \end{cases} \]
    %
    Then
    %
    \[ \widehat{\chi}_{(a,b)}(n) = \frac{1}{2\pi} \int_a^b e_n(-x) = \frac{e_n(-a) - e_n(-b)}{2\pi i n}. \]
    %
    Hence we may write
    %
    \begin{align*}
        \chi_{(a,b)}(x) &= \frac{b-a}{2\pi} + \sum_{n \neq 0} \frac{e_n(-a) - e_n(-b)}{2 \pi i n} e_n(x)\\
        &= \frac{b-a}{2\pi} + \sum_{n = 1}^\infty \frac{\sin(nb) - \sin(na)}{\pi n} \cos(nx) + \frac{\cos(na) - \cos(nb)}{\pi n} \sin(nx).
    \end{align*}
    %
    This sum does not converge absolutely for any value of $x$ (except when $a$ and $b$ are chosen trivially). To see this, note that
    %
    \[ \left|\frac{e_n(-b) - e_n(-a)}{2 \pi n}\right| = \left| \frac{1 - e_n(b-a)}{2 \pi n} \right| \geq \left| \frac{\sin(n(b-a))}{2 \pi n} \right|, \]
    %
    so that it suffices to show $\sum |\sin(nx)| n^{-1} = \infty$ for every $x \not \in \pi \mathbf{Z}$. This follows because the values of $|\sin(nx)|$ are often large, so that we may apply the divergence of $\sum n^{-1}$. First, assume $x \in (0,\pi/2)$. If
    %
    \[ m \pi - x/2 < nx < m \pi + x/2 \]
    %
    for some $m \in \mathbf{Z}$, then
    %
    \[ m \pi + x/2 < (n+1)x < m \pi + 3x/2 < (m+1) \pi - x/2. \]
    %
    Thus if $nx \in (-x/2,x/2) + \pi \mathbf{Z}$, $(n+1)x \not \in (-x/2,x/2) + \pi \mathbf{Z}$. For $y$ outside of $(-x/2,x/2) + \pi \mathbf{Z}$, we have $|\sin(y)| > |\sin(x/2)|$, and therefore for any $n$,
    %
    \[ \frac{|sin(nx)|}{n} + \frac{|\sin((n+1)x)|}{n+1} > \frac{|\sin(x/2)|}{n+1}. \]
    %
    This means
    %
    \begin{align*}
        \sum_{n = 1}^\infty \frac{|\sin(nx)|}{n} &= \sum_{n = 1}^\infty \frac{|\sin(2nx)|}{2n} + \frac{|\sin((2n+1)x)|}{2n+1}\\
        &> |\sin(x/2)| \sum_{n = 1}^\infty \frac{1}{2n+1} = \infty
    \end{align*}
    %
    In general, we may replace $x$ with $x - k \pi$, with no effect to the values of the sum, so we may assume $0 < x < \pi$. If $\pi/2 < x < \pi$, then
    %
    \[ \sin(nx) = \sin(n(\pi - x)), \]
    %
    and $0 < \pi - x < \pi/2$, completing the proof, except when $x = \pi$, in which case
    %
    \[ \sum_{n = 1}^\infty \left| \frac{1 - e_n(\pi)}{2 \pi n} \right| = \sum_{n\ \text{even}} \left| \frac{1}{\pi n} \right| = \infty. \]
    %
    Thus the convergence of a Fourier series need not be absolute.
\end{example}

\begin{example}
    We can often find formulas for certain Fourier summations from taking the corresponding power series. This is because if we set $z = e^{it}$, then
    %
    \[ \sum_{n = -\infty}^\infty a_n e^{nit} = \sum_{n = -\infty}^\infty a_n z^n \]
    %
    becomes a Laurent series in $z$. For instance, we have a power series expansion
    %
    \[ \log \left( \frac{1}{1-x} \right) = \sum_{k = 1}^\infty \frac{z^k}{k}. \]
    %
    This converges pointwise for every $z \in \mathbf{D}$ but $z = 1$. Thus for $x \not \in 2 \pi \mathbf{Z}$,
    %
    \begin{align*}
        \sum_{k = 1}^\infty \frac{\cos(kx)}{k} &= \Re \left( \log \left( \frac{1}{1 - e(x)} \right) \right) = -\frac{1}{2} \log(2 - 2\cos(x)),\\
        \sum_{k = 1}^\infty \frac{\sin(kx)}{k} &= \Im \left( \log \left( \frac{1}{1 - e(x)} \right) \right) = \arctan \left( \frac{\sin(x)}{1 - \cos(x)} \right).
    \end{align*}
    %
    Here we agree that $\arctan(\pm \infty) = \pm \pi/2$. One can check that, indeed, the Fourier series of these two functions corresponds precisely to these summations. If a power series' radius of convergence exceeds $1$, then it is likely that the corresponding Fourier series taken on the circle will be pleasant, whereas if the power series' radius is equal to $1$, we can expect nasty behaviour on the boundary. In Complex analysis, one avoids talking about the boundary of the holomorphic function's definition, whereas in Fourier analysis we have to embrace the boundary points because this is the domain we are interested in. This makes the theory a little more pathological.
\end{example}

\chapter{Fourier Series}

Let's focus in on the problem we introduced in the last chapter. We write $\mathbf{T} = \RR / 2 \pi \mathbf{Z}$, so that a function $f: \mathbf{T} \to \mathbf{C}$ is a complex-valued $2 \pi$ periodic function on the real line. We then have an induced translation invariant norm on $\mathbf{T}$, given by setting $|t| = \min_{n \in \mathbf{Z}} |t + 2\pi n|$. The Lebesgue measure on $\RR$ induces a natural Borel measure on $\mathbf{T}$, such that for any periodic function $f: \mathbf{T} \to \mathbf{C}$,
%
\[ \int_{\mathbf{T}} f(t)\; dt = \frac{1}{2\pi} \int_{-\pi}^\pi f(t)\; dt. \]
%
For each integrable $f: \mathbf{T} \to \mathbf{C}$, we then have a \emph{formal trigonometric series}
%
\[ \sum_{n = -\infty}^\infty \widehat{f}(n) e_n(t). \]
%
In some sense, $f$ should be able to be approximated by the trigonometric polynomials obtained by truncating this series. However, at this point, we haven't deduced any reason for these sums to converge to $f$ analytically.

To understand the convergence, we define the partial sums
%
\[ S_Nf = \sum_{|n| \leq N} \widehat{f}(n) e_n. \]
%
If $f$ is real-valued, then the complex parts of $\widehat{f}(n)$ and $\widehat{f}(-n)$ cancel out, so $S_N f$ is a real-valued sum of cosines and sines, as in classical Fourier analysis.

An initial hope is that the Fourier series of a function converges pointwise, i.e. that for every $t$, $\lim_{N \to \infty} S_N(f)(t) = f(t)$. This is true if $f$ is periodic and differentiable everywhere. But even if we try and look at continuous periodic functions, the $S_N f$ can diverge. Thus we look for more exotic forms of convergence, and different quantitative descriptions which determine how the Fourier series represents the function $f$.

\section{Unique Representation of a Function?}

If the Fourier series of every function converged pointwise, we could conclude that if $f$ and $g$ have the same Fourier coefficients, they must necessarily be equal. This is clearly not true, for if we alter a function at a point, the Fourier series, defined by averaging over the entire region, remains the same. Nonetheless, if a function is continuous, editing the function at a point will break continuity, so we may have some hope of uniqueness of the expansion.

\begin{theorem}
    If $\widehat{f}(n) = 0$ for all $n$, then $f$ vanishes wherever it is continuous.
\end{theorem}
\begin{proof}
    We shall prove, without loss of generality, that if $f$ is continuous at the origin, then $f(0) = 0$. We treat the real-valued case first. For every trigonometric polynomial $g(x) = \sum a_n e_n(-x)$, we have
    %
    \[ \int_{-\pi}^\pi f(x) g(x) dx = 2 \pi \sum a_n \widehat{f}(n) = 0. \]
    %
    Suppose that $f$ is continuous at zero, and assume without loss of generality assume $f(0) > 0$. Pick $\delta$ such that if $|x| < \delta$, $|f(x)| > f(0)/2$. Consider the trigonometric polynomial
    %
    \[ g(x) = \varepsilon + \cos x = \varepsilon + \frac{e(x) + e(-x)}{2}. \]
    %
    where $\varepsilon$ is small enough that $g(x) > A > 1$ for $|x| < \delta/2$, $P(x) > 0$ for $\delta/2 \leq |x| < \delta$, and $g(x) < B < 1$ for $|x| \geq \delta$. The series of trigonometric polynomials $g_n(x) = (\varepsilon + \cos x)^n$ satisfy
    %
    \begin{align*}
        \left| \int_{\mathbf{T}} g_n(x) f(x) dx \right| &\geq \int_{|x| < \delta} g_n(x) f(x) dx - \left| \int_{\delta \leq |x|} g_n(x) f(x) dx \right|.
    \end{align*}
    %
    H\"{o}lder's inequality then guarantees that as $n \to \infty$,
    %
    \[ \left| \int_{\delta \leq |x|} g_n(x) f(x) dx \right| \lesssim B^n = o(1). \]
    %
    whereas
    %
    \[ \left| \int_{|x| < \delta} g_n(x) f(x) dx \right| \geq \int_{|x| < \delta/2} g_n(x) f(x) \gtrsim A^n. \]
    %
    which increases exponentially fast as $n \to \infty$. Thus we conclude
    %
    \[ 0 = \left| \int_{-\pi}^\pi g_n(x) f(x) dx \right| \gtrsim A^n - o(1). \]
    %
    For suitably large values of $n$, the right hand side is positive, whereas the left hand side is zero, which is impossible. By contradiction, we conclude $f(0) = 0$. In general, if $f$ is complex valued, then we may write $f = u + iv$, where
    %
    \[ u(x) = \frac{f(x) + \overline{f(x)}}{2}\ \ \ \ v(x) = \frac{f(x) - \overline{f(x)}}{2i}. \]
    %
    The Fourier coefficients of $\overline{f}$ all vanish, because the coefficients of $f$ vanish, and so we conclude the coefficients of $u$ and $v$ vanish. $f$ is continuous at $x$ if and only if it is continuous at $u$ and $v$, and we know from the previous case this means that both $u$ and $v$ vanish at that point.
\end{proof}

\begin{corollary}
    If $f,g \in C(\mathbf{T})$ and $\widehat{f} = \widehat{g}$, then $f = g$.
\end{corollary}
\begin{proof}
    Then $f - g$ is continuous with vanishing Fourier coefficients.
\end{proof}

\begin{corollary}
    If $f \in C(\mathbf{T})$ and $\widehat{f} \in L^1(\mathbf{Z})$, $S_N f \to f$ uniformly as $N \to \infty$.
\end{corollary}
\begin{proof}
    If $\sum |\widehat{f}(n)| < \infty$, then we calculate
    %
    \[ |(S_{N + M} f)(x) - (S_N f)(x)| \leq \sum_{k = N+1}^M |\widehat{f}(k)|. \]
    %
    Since the series $\widehat{f}$ is absolutely summable, for any $\varepsilon$, there is sufficiently large $N$, such that the quantity above is bounded uniformly by $\varepsilon$. Thus the functions $\{ S_N f \}$ are a Cauchy sequence in $L^\infty(\mathbf{T})$, and therefore converge uniformly to some function $Sf$, which necessarily must be continuous. Uniform convergence also implies we can interchange integrals to conclude
    %
    \[ \widehat{Sf}(n) = \lim_{N \to \infty} \frac{1}{2\pi} \int_{-\pi}^\pi S_N(f)(t) e_n(-t) = \widehat{f}(n). \]
    %
    Thus $\widehat{Sf} = \widehat{f}$, so $Sf = f$ since both functions are continuous.
\end{proof}

Later we show that if $f \in C^m(\mathbf{T})$, then $\widehat{f}(n) = O(1/|n|^m)$. In particular, if $m \geq 2$, then $S_N f \to f$ uniformly. If $f \in C^\infty(\mathbf{T})$, then this means $\widehat{f}(n) = O(1/|n|^m)$, which implies $S_N f \to f$ uniformly, and moreover, $(S_N f)^{(k)} \to f^{(k)}$ uniformly as well for any $k$. Conversely, take a sequence $a_n$, for $n \in \mathbf{Z}$, with $a_n = O_m(1/|n|^m)$ for all $m$. If we set $f_N = \sum_{|n| \leq N} a_n e_n$, then $f_N$ converges uniformly to some function $f$. But one can verify that the $m$'th derivative of the $f_N$ also converge uniformly to some function, which therefore must be the $m$'th derivative of $f$. Thus $f \in C^\infty(\mathbf{T})$, and $\smash{\widehat{f}(n)} = a_n$. This means there is a perfect duality between infinitely differentiable functions and arbitrarily fast decaying sequences of coefficients. In more advanced contexts, like the theory of distributions, this duality is very useful for studying the Fourier transform.

\section{Quantitative Bounds on Fourier Coefficients}

Using classical analysis, the last section essentially details all the results we can obtain about the Fourier series of a function. Of course, in practical contexts most of the functions dealt with are arbitrarily smooth, so the picture seems rather complete. Nonetheless, we still want to study the qualitative properties of the Fourier series in terms of the qualitative properties of functions. For instance, does the Fourier series of functions which are globally small converge faster than functions which are only small on average. In modern terms, do we get faster convergence rates if $\| f \|_{L^\infty(\mathbf{T})}$ is small rather than just if $\| f \|_{L^1(\mathbf{T})}$ is small. Does the convergence get faster if we consider the convergence with respect to an $L^p$ norm rather than an $L^\infty$ norm? Thus we want to understand the behaviour of the Fourier series with respect to a family of \emph{norm spaces}. Of course, these norms are defined in a more general space of measurable functions, and to apply functional analysis arguments it is essential to `complete' the picture of these norms, so we will find that many of our arguments, initially invented to study smooth functions, also work naturally with arbitrarily integrable functions.

These quantitative estimates are still interesting even if we knew everything there was to know about the pointwise convergence of Fourier series. A series of functions may converge to a function pointwise, whereas none of these individual functions may look like the function they converge to at all. So we may want to look at quantitative measures of how globally similar two functions are. For instance, we might want to know how the Fourier series of a function changes under a small pertubation, and this correponds to understanding quantitative estimates about the operators $S_N$, or the rate of convergence of $S_N f$ to $f$, which might be required if we want to determine how large $N$ must be to approximate $f$.

\begin{example}
    If we consider a square wave $\chi_I$ for some interval $I$, then the techniques of the following section allow us to prove that
    %
    \[ \| \chi_I - S_N \chi_I \|_{L^2(\mathbf{T})} = O(1/\sqrt{N}), \]
    %
    independently of $I$. This means that if we want to simulate square waves with a musical instrument up to some square mean error $\varepsilon$, then we will need $\Omega(\varepsilon^{-2})$ different notes to represent the sound accurately. Thus a piano with 88 keys can only approximate square waves slightly better than a keyboard with 20 keys. If $f$ is $C^{m+1}(\mathbf{T})$, then
    %
    \[ \| f - S_N f \|_{L^2(\mathbf{T})} = O(1/N^{m/2}), \]
    %
    so we require significantly less notes to simulate this sound, i.e. $\Omega(\varepsilon^{-2/m})$. In this case a piano can simulate these sounds much more accurately.
\end{example}

One initial equation which might summarize how well behaved the Fourier series is with respect to suitable norms would be to obtain an estimate of the form $\smash{\| \widehat{f} \|_{L^q(\mathbf{Z})} \lesssim \| f \|_{L^p(\mathbf{T})}}$ for particular values of $p$ and $q$. If this was established, we could conclude that the Fourier series is stable in the $L^q$ norm under small pertubations in the $L^p$ norm. The first inequality we give is trivial, but is certainly tight, i.e. for $f(t) = e_n(t)$.

\begin{theorem}
    For any $f$, $\| \widehat{f} \|_{L^\infty(\mathbf{T})} \leq \| f \|_{L^1(\mathbf{T})}$.
\end{theorem}
\begin{proof}
    We just take absolute values into the oscillatory integral defining the Fourier coefficients, calculating that for any $n$,
    %
    \[ |\widehat{f}(n)| = \left| \int_{\mathbf{T}} f(t) e_n(-t) \right| \leq \frac{1}{2\pi} \int_{\mathbf{T}} |f(t)| = \| f \|_{L^1(\mathbf{T})}, \]
    %
    which was the required bound.
\end{proof}

This proof doesn't really take any deep features of the Fourier coefficients. The same bound holds for any integral
%
\[ \frac{1}{2\pi} \int_{\mathbf{T}} f(t) K(t)\; dt, \]
%
where $|K(t)| \leq 1$ for all $t$. But the bound is still tight, which might be explained by the fact that the Fourier series gives oscillatory information which is not immediately present in the $L^p$ norms of the phase spaces, other than by taking a naive absolute bound into the $L^p$ norm. The only $L^p$ space where we can get a completely satisfactory bound is for $p = 2$, where we can use Hilbert space technique; this should be expected since orthogonality was used to define the Fourier series.

\begin{theorem}
    For any function $f$, $\| \widehat{f} \|_{L^2(\mathbf{Z})} = \| f \|_{L^2(\mathbf{T})}$.
\end{theorem}
\begin{proof}
    With respect to the normalized inner product on the space $L^2(\mathbf{T})$,the calculations of the last chapter tell us that the exponentials are an orthonormal family of functions, in the sense that for distinct $n$ and $m$, $(e_n,e_m) = 0$, and $(e_n,e_n) = 1$. Since $\smash{\widehat{f}(n) = (f,e_n)}$, we apply Bessel's inequality to conclude
    %
    \[ \| \widehat{f} \|_{L^2(\mathbf{Z})} \leq \| f \|_{L^2(\mathbf{T})}. \]
    %
    The exponentials $\{ e_n \}$ are actually an orthonormal basis for $L^2(\mathbf{T})$; This can be seen from the Stone Weirstrass theorem, since trigonometric polynomials separate points, or by results we prove independently, later on in these notes. Thus Parsevel's equality tells us
    %
    \[ \| \widehat{f} \|_{L^2(\mathbf{Z})} = \| f \|_{L^2(\mathbf{T})}. \qedhere \]
\end{proof}

This equality makes the Hilbert space $L^2(\mathbf{T})$ often the best place to understand Fourier expansion techniques, and general results are often achieved by reduction to this well understood case. For instance, the inequality above, combined with the trivial inequality, is easily interpolated using the Riesz-Thorin technique to give the Hausdorff Young inequality.

\begin{theorem}
    If $1 \leq p \leq 2$, $\| \widehat{f} \|_{L^q(\mathbf{Z})} \leq \| f \|_{L^p(\mathbf{T})}$.
\end{theorem}

It might be surprising to note that the Hausdorff Young inequality essentially completes the bounds on the Fourier series with respect to the $L^p$ norms. There is no interesting result one can obtain for $p > 2$ other than the obvious inequality
%
\[ \| \widehat{f} \|_{L^2(\mathbf{Z})} \leq \| f \|_{L^2(\mathbf{T})} \leq \| f \|_{L^p(\mathbf{T})}. \]
%
Thus we can control the magnitude of the Fourier coefficients in terms of the width of the original function, but we are limited in our ability to control the width of the Fourier coefficients in terms of the magnitudes of the original function. This makes sense, because the $L^p$ norm of $f$ measures fairly different aspects of the function than the $L^q$ norm of the Fourier transform of $f$. It is only in the case of the $L^2$ norm where results are precise, and where $p$ is small that we can take a trivial bound, that we get an inequality like the Hausdorff Young result.

\section{Asymptotic Decay of Fourier Series}

The next result, known as Riemann-Lebesgue lemma, shows that the Fourier series of any integrable function decays, albeit arbitrarily slowly. The proof we give is an instance of an important principle in Functional analysis that we will use over and over again. Suppose for each $n$, we have a bounded operator $T_n: X \to Y$ between Banach spaces, and we want to show that for each $x \in X$, $\lim T_n(x) = T(x)$, where $T$ is another bounded operator. Suppose that it is obvious that $\lim T_n(x') = T(x')$ for a dense family of points $X' \subset X$, and the operators $T_n$ are {\it uniformly} bounded. Then for any $x \in X$,
%
\begin{align*}
    \| T_n(x) - T(x) \| &\leq \| T_n(x) - T_n(x') \| + \| T_n(x') - T(x') \| + \| T(x') - T(x) \|.
\end{align*}
%
If we choose $x'$ such that $\| x - x' \| \leq \varepsilon$, then for $n$ large enough we find that $\| T_n(x) - T(x) \| \lesssim \varepsilon$. Since $\varepsilon$ was arbitrary, this means that $\lim_{n \to \infty} T_n(x) = T(x)$. The advantage of the principle is that it is suitably abstract, and can thus be used very flexibly. But the disadvantage is that it is a very soft analytical argument, and cannot be used to obtain results on the rate of convergence of $T_n(x)$ to $T(x)$.

\begin{lemma}[Riemann-Lebesgue]
    If $f \in L^1(\mathbf{T})$, then $\widehat{f}(n) \to 0$ as $|n| \to \infty$.
\end{lemma}
\begin{proof}
    We claim the lemma is true for the characteristic function of an interval $\chi_I$. If $I = [a,b]$, then
    %
    \[ \widehat{\chi_I}(n) = \frac{1}{2\pi} \int_a^b e_n(-t) = \frac{i(e_n(-b) - e_n(-a))}{2 \pi n} = O(1/n). \]
    %
    By linearity of the integral, the Fourier transform of any step function vanishes at $\infty$. But if $\smash{\Lambda_n(f) = \widehat{f}(n)}$, then $|\Lambda_n f| \leq \| \widehat{f} \|_{L^\infty(\mathbf{T})} \leq \| f \|_{L^1(\mathbf{T})}$, which shows that the sequence of functionals $\{ \Lambda_n \}$ are uniformly bounded as maps from $L^1(\mathbf{T})$ to $L^\infty(\mathbf{Z})$. Since $\lim_{|n| \to \infty} \Lambda_n(f) = 0$ for any step function $f$, and the step functions are dense in $L^1(\mathbf{T})$, we conclude that $\lim_{|n| \to \infty} \Lambda_n(f) = 0$ for all $f \in L^1(\mathbf{T})$.
\end{proof}

Even though the Fourier series of any step function decays at a rate $O(1/n)$, it is {\it not} true that a general Fourier series decays at a rate of $O(1/n)$. And in fact, one can provide examples of functions whose Fourier series decay at an arbitrarily slow rate. This is the penalty for using a soft type analytical argument.

Nonetheless, for smooth functions, we can obtain a decay rate. This is an instance of a general result related to the duality between decay and smoothness in phase and frequency space.

\begin{theorem}
    If $f \in C^m(\mathbf{T})$, then $|\widehat{f}(n)| \leq |n|^{-m} \| f^{(m)} \|_{L^1(\mathbf{T})}$.
\end{theorem}
\begin{proof}
    Applying the derivative law for Fourier series $m$ times, we find that
    %
    \[ |\widehat{f}(n)| = |n|^{-m} |\widehat{f^{m}}(n)| \leq |n|^{-m} \| f^{(m)} \|_{L^1(\mathbf{T})}. \qedhere \]
\end{proof}

\begin{remark}
    Suppose that $\mu$ is a measure on $\mathbf{T}$ with finite variation, for which we write $\mu \in M(\mathbf{T})$. Then one can define the Fourier series of $\mu$ by
    %
    \[ \widehat{\mu}(n) = \int_{-\pi}^\pi e_n(-x) d\mu(x). \]
    %
    If $\mu$ is absolutely continuous with respect to the normalized Lebesgue measure on $\mathbf{T}$, and $d\mu = f dx$, then $\widehat{\mu} = \widehat{f}$, so this is an extension of the Fourier series to measures. One can verify that
    %
    \[ \| \widehat{\mu} \|_{L^\infty(\mathbf{Z})} \leq \| \mu \|_{M(\mathbf{T})}. \]
    %
    If $\delta$ is the Dirac delta measure at the origin, i.e. $\mu(E) = 1$ if $0 \in E$, and $\mu(E) = 0$ otherwise, then for all $n$,
    %
    \[ \widehat{\delta}(n) = 1. \]
    %
    Thus the Fourier series of $\delta$ has no decay at all. Once can view this as saying functions are `smoother' than measures, and therefore have a Fourier decay, albeit one that is qualitative rather than quantitative.
\end{remark}

\section{Convolution and Kernel Methods}

The notion of the convolution of two functions $f$ and $g$ is a key tool in Fourier analysis, both as a way to regularize functions, and as an operator that transforms nicely when we take Fourier series. Given two integrable functions $f$ and $g$, we define
%
\[ (f * g)(t) = \int_{\mathbf{T}} f(s) g(t-s)\; ds. \]
%
Thus we smear the values of $g$ with respect to a density function $f$.

\begin{lemma}
    For any $1 \leq p < \infty$, and $f \in L^p(\mathbf{T})$, $\lim_{h \to 0} T_h f = f$ in $L^p(\mathbf{T})$.
\end{lemma}
\begin{proof}
    If $f$ is $C^1(\mathbf{T})$, then $|f(x + h) - f(x)| \lesssim h$ uniformly in $x$, implying that $\| T_h f - f \|_{L^p(\mathbf{T})} \leq \| T_hf - f \|_{L^\infty(\mathbf{T})} \lesssim h$, and so $T_h f \to f$ in all the spaces $L^p(\mathbf{T})$. We have $\| T_h f \|_{L^p(\mathbf{T})} = \| f \|_{L^p(\mathbf{T})}$, so the $T_h$ are a bounded family of operators, and since $C^1(\mathbf{T})$ is dense in $L^p(\mathbf{T})$ for $1 \leq p < \infty$, we conclude that $\lim_{h \to 0} T_h f = f$ for all $f \in L^p(\mathbf{T})$.
\end{proof}

\begin{theorem}
    Convolution has the following properties:
    %
    \begin{itemize}
        \item If $f \in L^p(\mathbf{T})$ and $g \in L^q(\mathbf{T})$, for $1/p + 1/q = 1$, then $f * g$ is uniformly continuous.

        \item If $f \in L^p(\mathbf{T})$ and $g \in L^q(\mathbf{T})$, and if we define $r$ so that $1/r = 1/p + 1/q - 1$, with $1 \leq r \leq \infty$, then $f * g$ is defined by the integral formula almost everywhere, and
        %
        \[ \| f * g \|_{L^r(\mathbf{T})} \leq \| f \|_{L^p(\mathbf{T})} \| g \|_{L^q(\mathbf{T})}. \]
        %
        This is known as {\it Young's inequality} for convolutions.

        \item Convolution is a commutative, associative, bilinear operation.

        \item If $f,g \in L^1(\mathbf{T})$, then $\widehat{f * g} = \widehat{f} \widehat{g}$.

        \item If $f$ has a weak derivative $f'$ in $L^1(\mathbf{T})$, then $f * g$ has a weak derivative in $L^1(\mathbf{T})$, and $(f * g)' = f' * g$. Thus convolution is `additively smoothing'. In particular, if $f \in C^k(\mathbf{T})$ and $g \in C^l(\mathbf{T})$, then $f * g \in C^{k+l}(\mathbf{T})$.

        \item If $f$ is supported on $E$, and $g$ on $F$, then $f * g$ is supported on $E + F$.
    \end{itemize}
\end{theorem}
\begin{proof}
    Suppose $f \in L^p(\mathbf{T})$, and $g \in L^q(\mathbf{T})$, then
    %
    \begin{align*}
        |(f * g)(t - h) - (f * g)(t)| &\leq \int |f(t-h-s) - f(t-s)| |g(s)|\; ds\\
        &\leq \| f_h - f \|_{L^p(\mathbf{T})} \| g \|_{L^q(\mathbf{T})}.
    \end{align*}
    %
    The right hand side is a bound independant of $t$ and converges to zero as $h \to 0$, so $f * g$ is uniformly continuous. Applying H\"{o}lder's inequality again gives that $\| f * g \|_{L^\infty(\mathbf{T})} \leq \| f \|_{L^p(\mathbf{T})} \| g \|_{L^q(\mathbf{T})}$. If $f \in L^p(\mathbf{T})$, and $g \in L^1(\mathbf{T})$, we use Minkowski's inequality to conclude that
    %
    \begin{align*}
        \| f * g \|_{L^p(\mathbf{T})} &= \left( \int \left| \int f(t-s)g(s)\; ds \right|^p\; dt \right)^{1/p}\\
        &\leq \int \left( \int |f(t-s)g(s)|^p\; dt \right)^{1/p}\; ds\\
        &= \int g(s) \| f \|_{L^p(\mathbf{T})}\; ds = \| f \|_{L^p(\mathbf{T})} \| g \|_{L^1(\mathbf{T})}.
    \end{align*}
    %
    Thus $f * g$ is finite almost everywhere. The inequality also implies that
    %
    \[ \| f * g \|_{L^p(\mathbf{T})} \leq \| f \|_{L^1(\mathbf{T})} \| g \|_{L^p(\mathbf{T})} \]
    %
    if $f \in L^1(\mathbf{T})$, and $g \in L^p(\mathbf{T})$. But now implying Riesz-Thorin interpolation gives the general Young's inequality. Elementary applications of change of coordinates and Fubini's theorem establish the commutativity and associativity of convolution for functions $f, g \in L^1(\mathbf{T})$. But $L^1(\mathbf{T}) \cap L^p(\mathbf{T})$ is dense in $L^p(\mathbf{T})$. Since $f * g = g * f$ for a dense family of functions, and convolution is continuous from $L^p(\mathbf{T}) \times L^q(\mathbf{T}) \to L^r(\mathbf{T})$, we obtain the identity holds everywhere. Similarily, one can apply Fubini's theorem to obtain associativity for $f,g,h \in L^1(\mathbf{T})$, and then apply density. To obtain the product identity for the Fourier series, we can apply Fubini's theorem to write
    %
    \begin{align*}
        \widehat{f * g}(n) &= \frac{1}{2\pi} \int_{-\pi}^\pi (f * g)(t) e_n(-t)\ dt\\
        &= \frac{1}{(2\pi)^2} \int_{-\pi}^\pi \int_{-\pi}^\pi f(s)g(t-s) e_n(-t)\ ds\ dt\\
        &= \frac{1}{2 \pi} \int_{-\pi}^\pi f(s) \int_{-\pi}^\pi (L_{-s}g)(t) e_n(-t)\ dt\ ds\\
        &= \frac{1}{2\pi} \int_{-\pi}^\pi f(s) e_n(-s) \widehat{g}(n)\ ds\\
        &= \widehat{f}(n) \widehat{g}(n),
    \end{align*}
    %
    and this is exactly the identity required. To calculate the weak derivative of $f * g$, we fix $\phi \in C^\infty(\mathbf{T})$, and calculate using two applications of Fubini's theorem that
    %
    \begin{align*}
        \int_{\mathbf{T}} (f' * g)(t) \phi(t)\; dt &= \int_\mathbf{T} \int_{\mathbf{T}} f'(t-s) g(s) \phi(t)\; ds\; dt\\
        &= \int_{\mathbf{T}} g(s) \int_{\mathbf{T}} f'(t-s) \phi(t)\; dt\; ds\\
        &= - \int_{\mathbf{T}} g(s) \int_{\mathbf{T}} f(t-s) \phi'(t)\; dt\; ds\\
        &= - \int_{\mathbf{T}} \left( \int_{\mathbf{T}} g(s) f(t-s)\; ds \right) \phi'(t)\; dt\\
        &= - \int_{\mathbf{T}} (f * g)(t) \phi'(t)\; dt.
    \end{align*}
    %
    If $f = 0$ a.e outside $E$, and $g = 0$ a.e. outside $F$, then $(f * g)(t)$ can be nonzero only when there is a set $G$ of positive measure such that for any $s \in G$, $f(s) \neq 0$ and $g(t-s) \neq 0$. But this means that $E \cap G \cap (t-F)$ has positive measure, so that there is $s \in E$ such that $t-s \in F$, meaning that $t \in E + F$.
\end{proof}

We know that suitably smooth functions have convergent Fourier series. The advantage of convolution is if we want to study the properties of a function $f$, convolution with a smooth function $g$ gives a smooth function, and provided $\smash{\widehat{g}}$ is close to 1, $\smash{\widehat{f*g}}$ will be close to $\widehat{f}$. If we can establish the convergence properties on the convolution $f * g$, then we can probably obtain results about $f$. From the frequency side, $\sum \widehat{f}(n) e_n$ might not converge, but $\sum a_n \widehat{f}(n) e_n$ might converge for a suitably fast decaying sequence $a_n$. But if $a_n$ is close to one, this sequence might still reflect properties of the original sequence.

To make rigorous the idea of approximating the Fourier series of a function, we introduce families of \emph{good kernels}. A good kernel is a sequence of integrable functions $\{ K_n \}$ on $\mathbf{T}$ bounded in $L^1$ norm, for which
%
\[ \frac{1}{2\pi} \int_{\mathbf{T}} K_n(t) = 1. \]
%
so that integration against $K_n$ operates essentially like an average, and for any $\delta > 0$,
%
\[ \lim_{n \to \infty} \int_{|t| > \delta} |K_n(t)| \to 0. \]
%
Thus the functions $\{ K_n \}$ become concentrated at the origin as $n \to \infty$. If in addition, we have an estimate $\| K_n \|_{L^\infty(\mathbf{T})} \lesssim n$, we say it is an {\bf approximation to the identity}.

\begin{theorem}
    Let $\{ K_n \}$ be a good kernel. Then
    %
    \begin{itemize}
        \item $(K_n * f)(t) \to f(t)$ for any continuity point $t$ of $f$.
        \item $(K_n * f) \to f$ uniformly if $f \in C(\mathbf{T})$, and $K_n * f$ converges to $f$ in $L^p(\mathbf{T})$ if $f \in L^p(\mathbf{T})$, for $1 \leq p < \infty$.
        \item If $K_n$ is an approximation to the identity, $(K_n * f)(t) \to f(t)$ for all $t$ in the Lebesgue set of $f$.
    \end{itemize}
\end{theorem}
\begin{proof}
    The operators $T_nf = K_n * f$ are uniformly bounded as operators on $L^p(\mathbf{T})$. Basic analysis shows that $(K_n * f)(t) \to f(t)$ at each point $t$ where $f$ is continuous, and converges uniformly to $f$ if $f$ is in $C(\mathbf{T})$. But a density argument allows us to conclude that $K_n * f \to f$ in $L^p(\mathbf{T})$ for each $f \in L^p(\mathbf{T})$, for $1 \leq p < \infty$. To obtain pointwise convergence, we calculate
    %
    \[ |(K_n * f)(t) - f(t)| \leq \frac{1}{2\pi} \int_{\mathbf{T}} |f(t - s) - f(t)| |K_n(s)|\; ds. \]
    %
    Let $A(\delta) = \delta^{-1} \int_{|s| < \delta} |f(t-s) - f(t)|$. Then as $\delta \to 0$, $A(\delta) \to 0$ because $t$ is in the Lebesgue set of $f$. And we find that for each $k$, since $|K_n(s)| \lesssim n$,
    %
    \[ \int_{2^k/n < |t| < 2^{k+1}/n} |f(t-s) - f(t)| |K_n(s)| \lesssim \frac{A(2^{k+1}/n)}{2^{k+1}}. \]
    %
    Thus we have a bound
    %
    \[ |(K_n * f)(t) - f(t)| \lesssim \sum_{k = 0}^\infty \frac{A(2^k/n)}{2^k}. \]
    %
    Because $f$ is integrable, $A$ is continuous, and hence bounded. This means that for each $m$,
    %
    \[ |(K_n * f)(t) - f(t)| \lesssim \sum_{k = 0}^m \frac{A(2^k/n)}{2^k} + \| A \|_\infty \sum_{k = m}^\infty \frac{1}{2^k} = \sum_{k = 0}^m \frac{A(2^k/n)}{2^k} + O\left( 1/2^m \right). \]
    %
    For any fixed $m$, the finite sum tends to zero as $n \to \infty$, so we obtain that $|(K_n * f)(t) - f(t)| = o(1) + O(1/2^m)$. Taking $m \to \infty$ proves the result.
\end{proof}

\section{The Dirichlet Kernel}

We calculate that
%
\[ (S_Nf)(t) = \sum_{|n| \leq N} \widehat{f}(n) e_n(t) = \frac{1}{2\pi} \int f(x) \left( \sum_{|n| \leq N} e_n(t - x) \right)\; dx.  \]
%
The bracketed part of the final term in the equation is independant of the function $f$, and is therefore key to understanding the behaviour of the sums $S_N$. We call it the Dirichlet kernel $D_N$, defined as
%
\[ D_N(t) = \sum_{n = -N}^N e_n(t). \]
%
Thus $S_N f = f * D_N$, so analyzing convolution with this kernel gives results about the sums of Fourier series.

\begin{theorem}
    For any integer $N$ and $t \in \RR$,
    %
    \[ D_N(t) = \frac{\sin((N+1/2)t)}{\sin(t/2)}. \]
\end{theorem}
\begin{proof}
    By the geometric series summation formula, we may write
    %
    \begin{align*}
        D_N(t) &= 1 + \sum_{n = 1}^N e_n(t) + e_n(-t) = 1 + e(t) \frac{e_N(t) - 1}{e(t) - 1} + e(-t) \frac{e_N(-t) - 1}{e(-t) - 1}\\
        &= 1 + e(t) \frac{e_N(t) - 1}{e(t) - 1} + \frac{e_N(-t) - 1}{1 - e(t)} = \frac{e_{N+1}(t) - e_N(-t)}{e(t) - 1}\\
        &= \frac{e_{N+1/2}(t) - e_{N+1/2}(-t)}{e_{1/2}(t) - e_{1/2}(-t)} = \frac{\sin((N + 1/2)t)}{\sin(t/2)}.
    \end{align*}
    %
    Thus as $N \to \infty$, $D_N$ oscillates highly rapidly.
\end{proof}


If $D_N$ was a good kernel, then we would obtain that the partial sums of $S_N$ converge uniformly. This initially seems a good strategy, because $(2\pi)^{-1} \int D_N(t) = 1$. However, we find
%
\begin{align*}
    \int_{-\pi}^\pi |D_N(t)| &= \int_{-\pi}^\pi \left| \frac{\sin((N + 1/2)t)}{\sin(t/2)} \right|\\
    &\gtrsim \int_0^\pi \frac{|\sin((N+1/2) t)|}{\sin(t/2)}\\
    &\gtrsim \int_0^\pi \frac{|\sin((N+1/2) t)|}{t}\; dt\\
    &= \int_0^{(N+1/2)\pi} \frac{|\sin(t)|}{t}\\
    &\gtrsim \sum_{n = 0}^N \frac{1}{t} \gtrsim \log(N).
\end{align*}
%
Thus the $L^1$ norm of $D_N$ grows, albeit slowly, to $\infty$. This reflects the fact that $D_N$ oscillates very frequently, and also that the pointwise convergence of the Fourier series is much more subtle than that provided by good kernels. In fact, a simple functional analysis argument shows that pointwise convergence of Fourier series fails for continuous functions.

\begin{theorem}
    There exists $f \in C(\mathbf{T})$ such that $(S_N f)(0)$ diverges as $N \to \infty$.
\end{theorem}
\begin{proof}
    If we consider the linear operators $\Lambda_N f = (S_N f)(0) = (f * D_N)(0)$ as maps from $C(\mathbf{T})$ to $L^1(\mathbf{T})$, and if we let $f$ be a continuous function approximating $\text{sgn}(D_N)$, then we can obtain a sequence $f_N$ such that $|\Lambda_N f_N| = \Omega(\log N) \| f_N \|_\infty$. This implies that $\| \Lambda_N \| \to \infty$ as $N \to \infty$. The uniform boundedness principle thus implies that there exists a {\it single} function $f \in C(\mathbf{T})$ such that $\sup |\Lambda_N f| = \infty$, so $(S_N f)(0)$ diverges as $N \to \infty$.
\end{proof}

\section{Countercultural Methods of Summation}

We now interpret our convergence of series according to a different kernel, so we do get a family of good kernels, and therefore we obtain pointwise convergence for suitable reinterpretations of partial sums. One reason why the Dirichlet kernel fails to be a good kernel is that the Fourier coefficients of the kernel have a sharp drop -- the coefficients are either equal to one or to zero. If we mollify, then we will obtain a family of good kernels. And the best way to do this is to alter our summation methods slightly.

The standard method of summation suffices for much of analysis. Given a sequence $a_0, a_1, \dots$, we define the infinite sum as the limit of partial sums. Some sums, like $\sum_{k = 1}^\infty k$, obviously diverge, whereas other sums, like $\sum 1/n$, `just' fail to converge because they grow suitably slowly towards infinity over time. Since the time of Euler, a new method of summation developed by Cesaro was introduced which `regularized' certain terms by considering averaging the sums over time. Rather than considering limits of partial sums, we consider limits of averages of sums, known as Cesaro means. Letting $s_n = \sum_{k = 0}^n a_k$, we define the Cesaro means
%
\[ \frac{s_0 + \dots + s_n}{n+1}, \]
%
A sequence is Cesaro summable to some value if these averages converge. If the normal summation exists, then the Cesaro limit exists, and is equal to the original sum. However, the Cesaro summation is stronger than normal convergence.

\begin{example}
In the sense of Cesaro, we have $1 - 1 + 1 - 1 + \dots = 1/2$, which reflects the fact that the partials sums do `converge', but to two different numbers $0$ and $1$, which the series oscillates between, and the Cesaro means average these two points of convergence out to give a single method of convergence.
\end{example}

Another notion of regularization sums emerged from Complex analysis, called Abel summation. Given a sequence $\{ a_i \}$, we can consider the power series $\sum a_k r^k$. If this is well defined for $|r| < 1$, we can consider the Abel means $A_r = \sum a_k r^k$, and ask if $\lim_{r \to 1} A_r$ exists, which should be `almost like' $\sum a_k$. If this limit exists, we call it the Abel sum of the sequence.

\begin{example}
    In the Abel sense, we have $1 - 2 + 3 - 4 + 5 - \dots = 1/4$, because
    %
    \[ \sum_{k = 0}^\infty (-1)^k (k + 1) z^k = \frac{1}{(1 + z)^2}. \]
    %
    The coefficients here are $\Omega(N)$, so they can't be Cesaro summable.
\end{example}

%Abel summation is even more general than Cesaro summation.

%\begin{theorem}
%    A Cesaro summable sequence is Abel summable.
%\end{theorem}
%\begin{proof}
%    Let $\{ a_i \}$ be a Cesaro summable sequence, which we may without loss of generality assume converges to $0$. Now $(n + 1)\sigma_n - n \sigma_{n-1} = s_n$, so
    %
%    \[ (1 - r)^2 \sum_{k = 0}^n (k + 1) \sigma_k r^k = (1 - r) \sum_{k = 0}^n s_k r^k = \sum_{k = 0}^n a_k r^k \]
    %
%    As $n \to \infty$, the left side tends to a well defined value for $r < 1$, hence the same is true for $\sum_{k = 0}^n a_k r^k$. Given $\varepsilon > 0$, let $N$ be large enough that $|\sigma_n| < \varepsilon$ for $n > N$, and let $M$ be a bound for all $|\sigma_n|$. Then
    %
%    \begin{align*}
%        \left| (1 - r)^2 \sum_{k = 0}^\infty (k + 1) \sigma_k r^k \right| &\leq (1 - r)^2 \left( \sum_{k = 0}^N (k + 1) |\sigma_k| r^k + \varepsilon \sum_{k = N+1}^\infty (k + 1) r^k \right)\\
%        &= (1 - r)^2 \left( \sum_{k = 0}^N (k + 1) (|\sigma_k| - \varepsilon) r^k + \varepsilon \left[ \frac{r^{n+1}}{1-r} + \frac{1}{(1 - r)^2} \right] \right)\\
%        &\leq (1 - r)^2 M \sum_{k = 0}^N (k + 1) r^k + \varepsilon r^{n+1} (1 - r) + \varepsilon\\
%        &\leq (1 - r)^2 M \frac{(N+1)(N+2)}{2} + \varepsilon r^{n+1} (1 - r) + \varepsilon
%    \end{align*}
    %
%    Fixing $N$, and letting $r \to 1$, we may make the complicated sum on the end as small as possible, so the absolute value of the infinite sum is less than $\varepsilon$. Thus the Abel limit converges to zero.
%\end{proof}

\section{Fejer's Theorem}

Note that the Cesaro means of the Fourier series of $f$ are given by
%
\[ \sigma_N(f) = \frac{S_0(f) + \dots + S_{N-1}(f)}{N} = f * \left( \frac{D_0 + \dots + D_{N-1}}{N} \right) = f * F_N. \]
%
The convergence properties of the Cesaro means therefore relate to the properties of the {\bf Fej\'{e}r kernel} $F_N$. We find that
%
\[ F_N(x) = \sum_{n = -N}^N \left( 1 - \frac{|n|}{N} \right) e_n(t) = \frac{1}{N} \frac{\sin^2(Nx/2)}{\sin^2(x/2)}. \]
%
so the oscillations of the Dirichlet kernel are slightly dampened, and as a result, $F_N$ is an approximation to the identity.

\begin{theorem}[Fej\'{e}r's Theorem] For any $f \in L^1(\mathbf{T})$,
    \begin{itemize}
        \item $(\sigma_N f)(x) \to f(x)$ for all $x$ in the Lebesgue set of $f$.
        \item $\sigma_N f \to f$ uniformly if $f \in C(\mathbf{T})$.
        \item $\sigma_N f \to f$ in the $L^p$ norm for $1 \leq p < \infty$, if $f \in L^p(\mathbf{T})$.
    \end{itemize}

\end{theorem}

\begin{corollary}
    If $\widehat{f} = 0$, then $f = 0$ almost everywhere.
\end{corollary}
\begin{proof}
    If $\widehat{f} = 0$, then $\sigma_N f = 0$ for all $N$. But $\sigma_N f \to f$ in $L^1$, which means that $f = 0$ in $L^1(\mathbf{T})$, so $f = 0$ almost everywhere.
\end{proof}

If we look at the Fourier expansion of the trigonometric polynomial $\sigma_N(f)$, we see that
%
\[ \sigma_N f = \sum_{n = -N}^N \frac{N-|n|}{N} \widehat{f}(n) e_n. \]
%
Thus the Fourier coefficients are slowly added to the expansion, rather than a sharp cutoff as with ordinary Dirichlet summation. This is one reason for the nice convergence properties the kernel has as compared to the Dirichlet kernel.

\section{Abel Summation and Harmonics on the Disk}

Relating Abel summations to Fourier series requires a little bit more careful work, since we do not consider limits of finite sums. Note that the Abel sum is
%
\[ A_r(f) = \sum_{n = -\infty}^\infty \widehat{f}(n) r^n e_n(t). \]
%
Thus, if we define the {\it Poisson kernel}
%
\[ P_r(t) = \sum_{n = -\infty}^\infty r^{|n|} e_n(t) \]
%
which is defined by a uniformly convergent series over $\mathbf{T}$, we calculate that $A_r(f) = P_r * f$. Thankfully, we find $P_r$ is a good kernel. To see this, we can apply an infinite geometric series summation to obtain that
%
\begin{align*}
    \sum r^{|n|} e_n(t) &= 1 + \frac{re(t)}{1 - re(t)} + \frac{re(-t)}{1 - re(-t)} = 1 + \frac{2r \cos t - 2r^2}{(1 - re(t))(1 - re(-t))}\\
    &= 1 + \frac{2r \cos t - 2r^2}{1 - 2r \cos t + r^2} = \frac{1 - r^2}{1 - 2r \cos t + r^2}.
\end{align*}
%
As $r \to 1$, the function concentrates at the origin, because as $r \to 1$, if $\delta \leq |t| \leq \pi$, then $1 - \cos t$ is bounded away from the origin, so
%
\begin{align*}
    \left| \frac{1 - r^2}{1 - 2r \cos t + r^2} \right| &= \left| \frac{1 + r}{(1+(1-2\cos t)r) + 2(1 - \cos t) r^2/(1-r)} \right|\\
    &= O \left( \frac{1 - r}{1 - \cos t} \right) = O_\delta(1 - r).
\end{align*}
%
Thus the oscillation in the Poisson kernel cancels out as $r \to 1$, and so the Poisson kernel is a good kernel.

\begin{theorem}
    For any $f \in L^1(\mathbf{T})$,
    %
    \begin{itemize}
        \item $(A_r f)(t) \to f(t)$ for all $x$ in the Lebesgue set of $f$.
        \item $A_r f \to f$ uniformly if $f \in C(\mathbf{T})$.
        \item $A_r f \to f$ in the $L^p$ norm for $1 \leq p < \infty$, if $f \in L^p(\mathbf{T})$.
    \end{itemize}
\end{theorem}

The Poisson kernel is not a trigonometric polynomial, and therefore not quite as easy to work with as the F\'{e}jer kernel. However, it is the real part of the Cauchy kernel
%
\[ \frac{1 + re(t)}{1 - re(t)}. \]
%
and therefore links the study of trigonometric series and the theory of analytic functions. 

\begin{theorem}
    $u(r e^{it}) = (A_r f)(t)$ is $C^\infty(\mathbf{T})$, and harmonic for $r < 1$. Moreover, the function $u$ is the \emph{unique} $C^2(\mathbf{T})$ harmonic function such that as $r \to 1$, $u(re^{it}) \to f$ in the $L^1$ norm.
\end{theorem}
\begin{proof}
    The function $u$ is infinitely differentiable, because of the rapid convergence of the series defining the Poisson kernel. In particular, we note that
    %
    \[ \frac{\partial^2 u}{\partial \theta^2} = - \sum_{n = -\infty}^\infty \widehat{f}(n) |n|^2 r^{|n|} e_n(t), \]
    %
    \[ \frac{\partial u}{\partial r} = \sum_{n = -\infty}^\infty \widehat{f}(n) |n| r^{|n| - 1} e_n(t), \]
    %
    and
    %
    \[ \frac{\partial^2 u}{\partial r^2} = \sum_{n = -\infty}^\infty \widehat{f}(n) |n|(|n| - 1) r^{|n| - 2} e_n(t). \]
    %
    But in polar coordinates, we have
    %
    \begin{align*}
        \Delta u &= \frac{\partial^2 u}{\partial r^2} + \frac{1}{r} \frac{\partial u}{\partial r} + \frac{1}{r^2} \frac{u}{\theta^2}\\
        &= \sum_{|n| \geq 2} \widehat{f}(n) |n|(|n|-1) r^{|n|-2} e_n(t)\\
        &\ \ \ + \sum_{n \neq 0} \widehat{f}(n) |n| r^{|n|-2} e_n(t) - \sum_{n = -\infty}^\infty \widehat{f}(n) |n|^2 r^{|n|-2} e_n(t) = 0.
    \end{align*}
    %
    Thus $u$ is harmonic.

    Conversely, suppose $u \in C^2(\mathbf{T})$ is harmonic. Then we can find $a_n(t)$ such that
    %
    \[ u(re^{it}) = \sum_{n = -\infty}^\infty a_n(r) e_n(t), \]
    %
    where
    %
    \[ a_n(r) = \int_{\mathbf{T}} u(re^{it}) e_n(-t)\; dt. \]
    %
    Then
    %
    \[ \int_{\mathbf{T}} \frac{\partial^2 u}{\partial \theta^2}(re^{it}) e_n(-t)\; dt = -n^2 a_n(r), \]
    %
    and so $a_n''(r) + (1/r) a_n'(r) - (n^2/r^2) a_n(r) = 0$. This is an ordinary differential equation, whose only bounded solutions are given by $a_n(r) = A_n r^{|n|}$. If $u(re^{it}) \to f$ in the $L^1$ norm as $r \to 1$, then we conclude
    %
    \[ A_n = \lim_{r \to 1} \int_{\mathbf{T}} u(re^{it}) e_n(-t)\; dt = \int_{\mathbf{T}} f(t) e_n(-t) = \widehat{f}(n), \]
    %
    so
    %
    \[ u(re^{it}) = \sum \widehat{f}(n) r^{|n|} e_n(t) = g(re^{it}). \qedhere \]
\end{proof}

Thus we can represent any function on $\mathbf{T}$ as a harmonic function on the interior of the unit disk, which is often a useful analysis. The theory of Hardy spaces is a natural extension of this idea.

%If $u$ is only required to converge to $f$ {\it pointwise} on the boundary, then the function we found is no longer required to be unique. Below is an example of a function $u$ which tends to zero pointwise on the boundary, yet does not vanish on the interior of the unit disk.

%\begin{example}
%    If $P_r$ is the Poisson kernel, define $u(r,\theta) = P_r(\theta)$. Then $u$ is harmonic in the unit disk, because $\Delta u = (\Delta P_r)'' = 0$. We calculate
    %
%    \begin{align*}
%        u(r,t) &= \sum_{n = 1}^\infty in r^n [e_n(t) - e_n(-t)]\\
%        &= i \left[ \frac{r e(t)}{(re(t) - 1)^2} - \frac{r e(-t)}{(re(-t) - 1)^2} \right]\\
%        &= i \left[ \frac{re(-t) + r^{-1}e(t) - re(t) - r^{-1}e(-t)}{(re(t) - 1)^2(re(-t) - 1)^2} \right]\\
%        &= \frac{(r - r^{-1}) \sin(t)}{(re(t) - 1)^2(re(-t) - 1)^2}\\
%        &= \frac{(r^2 - 1) \sin(t)}{r (re(t) - 1)^2(re(-t) - 1)^2}
%    \end{align*}
    %
%    In this form, it is easy to see that for a fixed $t$, as $r \to 1$, $u(r,t) \to 0$. However, the denominator tells us this convergence isn't uniform.
%\end{example}

\section{The De la Valle\'{e} Poisson Kernel}

By taking a kernel halfway between the Dirichlet kernel and the Fejer kernel, we can actually obtain important results about ordinary summation. For two integers $M > N$, we define
%
\[ \sigma_{N,M}(f) = \frac{M\sigma_M(f) - N\sigma_N(f)}{M-N}. \]
%
If we take a look at the Fourier expansion of $\sigma_{n,m} f$, we find
%
\[ \sigma_{N,M} f = \sum_{n = -M}^M \frac{M - |n|}{M-N} e_n - \sum_{n = -N}^N \frac{N - |n|}{M-N} e_n = S_N f + \sum_{|n| = N+1}^M \frac{M - |n|}{M - N} e_n. \]
%
So we still have a slow decay in the Fourier coefficients. And as a result, if we look at the associated De la Velle\'{e} Poisson kernel, we find that a suitable subsequence is an approximation to the identity. In particular, for any fixed integer $k$, the sequence $\sigma_{kN,(k+1)N}$ leads to a good kernel. More interestingly, if the Fourier coefficients of $f$ have some decay, then the De la Vall\'{e}e does not differ that much from the ordinary sum, which gives useful results.

\begin{theorem}
    If $\widehat{f}(n) = O(|n|^{-1})$, then for any integers $N$ and $k$, if
    %
    \[ kN \leq M < (k+1)N, \]
    %
    then
    %
    \[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\mathbf{T})} \lesssim 1/k. \]
    %
    Where the implicit constant is independant of $N$ and $k$.
\end{theorem}
\begin{proof}
    We just calculate that, since the Poisson sum has essentially the same weight for low term coefficients as the sum $S_M f$,
    %
    \[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\mathbf{T})} \lesssim \sum_{kN \leq |n| < (k+1)N} |\widehat{f}(n)| \lesssim \sum_{n = kN}^{(k+1)N} \frac{1}{n} \leq \frac{N}{kN} = \frac{1}{k}. \qedhere \]
\end{proof}

\begin{corollary}
    If $f$ is a function with $\widehat{f}(n) = O(|n|^{-1})$,
    %
    \begin{itemize}
        \item $S_Nf$ converges to $f$ in the $L^p$ norm for $1 \leq p < \infty$.
        \item $S_Nf$ converges uniformly to $f$ if $f \in C(\mathbf{T})$.
        \item $(S_N f)(x) \to f(x)$ for each Lebesgue point $x$ of $f$.
    \end{itemize}
\end{corollary}
\begin{proof}
    The idea is quite simple. Fix $N$. Given any $\varepsilon$, we can use the last theorem to find $k$ large enough such that if $kN \leq M < k(N+1)$,
    %
    \[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\mathbf{T})} \leq \varepsilon. \]
    %
    But this gives the first and second result, up to perhaps a $\varepsilon$ of error. The latter result is given by similar techniques.
\end{proof}

\section{Pointwise Convergence}

One way around around the blowup in the $L^1$ norm of $D_N$ is to consider only functions $f$ which provide a suitable dampening condition on the oscillation of $D_N$ near the origin. This is provided by smoothness of $f$, manifested in various ways. The first thing we note is that the convergence of $(S_N f)(t)$ for a \emph{fixed} $x_0$ depends only \emph{locally} on the function $f$.

\begin{lemma}[Riemann Localization Principle]
    If $f_0$ and $f_1$ agree in an interval around $t_0$, then
    %
    \[ (S_N f_0)(t_0) = (S_N f_1)(t_0) + o(1). \]
\end{lemma}
\begin{proof}
    Let
    %
    \[ X = \{ f \in L^1(\mathbf{T}) : f(x) = 0\ \text{for almost every $x \in (t_0 - \varepsilon, t_0 + \varepsilon$)} \}. \]
    %
    Then $X$ is a closed subset of $L^1(\mathbf{T})$. Note that for all $x \in [-\pi,\pi]$,
    %
    \[ \sin(t/2) \gtrsim t \quad\text{and}\quad \sin((N+1/2)t) \leq 1. \]
    %
    Thus if $|t| \geq \varepsilon$,
    %
    \[ |D_N(t)| = \frac{|\sin((N+1/2)t)|}{|\sin(t/2)|} \lesssim 1/\varepsilon. \]
    %
    In particular, by H\"{o}lder's inequality, the functionals $T_Nf = (S_N f)(t_0)$ are uniformly bounded on $X$, i.e. $\| T_N \| \lesssim 1/\varepsilon$. If $f$ is smooth, and vanishes on $(t_0 - \varepsilon, t_0 + \varepsilon)$, then $T_N f \to 0$ as $N \to \infty$. But the space of such functions is dense in $X$, which implies that $T_N f \to 0$ for \emph{any} $f \in X$. Thus if $f_0, f_1$ are two functions that agree in $(t_0 - \varepsilon, t_0 + \varepsilon)$, then $f_0 - f_1 \in X$, so $(S_N f_0)(t_0) = (S_N f_1)(t_0) + o(1)$. In particular, the pointwise convergence properties of $f_0$ and $f_1$ are equivalent at $t_0$.
\end{proof}

Thus any result about the pointwise convergence of Fourier series must depend on the local properties of a function $f$. Here, we give two of the main criteria, which corresponds to the smoothness of a function about a point $x$: either $f$ is in a sense, `locally Lipschitz', or `locally of bounded variation'.

\begin{theorem}[Dini's Criterion]
    If there exists $\delta$ such that
    %
    \[ \int_{|t| < \delta} \left| \frac{f(x+t) - f(x)}{t} \right|\; dt < \infty, \]
    %
    then $(S_N f)(x) \to f(x)$.
\end{theorem}
\begin{proof}
    Assume without loss of generality that $x = 0$ and $f(x) = 0$. Fix $\varepsilon > 0$, and pick $\delta_0$ such that
    %
    \[ \int_{|t| < \delta_0} \left| \frac{f(t)}{t} \right|\; dt < \varepsilon. \]
    %
    We have
    %
    \begin{align*}
        |(S_N f)(0)| &= \left| \left( \int_{|t| < \delta_0} + \int_{|t| \geq \delta_0} \right) f(t) D_N(t)\; dt \right|.
    \end{align*}
    %
    Now
    %
    \[ \int_{|t| \geq \delta_0} f(t) D_N(t)\; dt = (D_N * \left( \mathbf{I}_{|t| \geq \delta_0} f \right))(0) = S_N( \mathbf{I}_{|t| \geq \delta_0} f )(0) = o(1) \]
    %
    since $f \mathbf{I}_{|t| \geq \delta_0}$ vanishes in a neighbourhood of the origin. On the other hand, we note that $t/\sin(t/2)$ is a bounded function on $\mathbf{T}$, so
    %
    \begin{align*}
        \int_{|t| < \delta_0} f(t) D_N(t)\; dt &= \int_{|t| < \delta_0} \left( \sin((N + 1/2)t) \frac{f(t)}{t} \right) \left( \frac{t}{\sin(t/2)} \right)\; dt\\
        &\lesssim \| f(t)/t \|_{L^1[-\delta_0,\delta_0]} \leq \varepsilon.
    \end{align*}
    %
    Thus, for suitably large $N$, $|(S_N f)(0)| \lesssim \varepsilon$. Since $\varepsilon$ was arbitrary, the proof is complete.
\end{proof}

This proof applies, in particular, if $f$ is locally Lipschitz at $x$. Note the application of the Riemann Lebesgue lemma to show that to analyze the pointwise convergence of $(S_N f)(x)$, it suffices to analyze
%
\[ \lim_{N \to \infty} \int_{|t| < \delta} f(x+t) D_N(t)\; dt \]
%
for any fixed $\delta > 0$.

\begin{lemma}[Jordan's Criterion]
    If $f \in L^1(\mathbf{T})$ locally has bounded variation about $x$, then
    %
    \[ (S_N f)(x) \to \frac{f(x^+) + f(x^-)}{2}. \]
\end{lemma}
\begin{proof}
    By Riemann's localization principle, we may assume $f$ has bounded variation everywhere. Then without loss of generality, we may assume $f$ is an increasing function, since a bounded variation function is the difference of two monotonic functions. Since
    %
    \[ \frac{1}{2\pi} \int_{-\pi}^\pi f(x+t) D_N(t)\; dt = \int_0^\pi [f(x + t) + f(x - t)] D_N(t), \]
    %
    it suffices without loss of generality to show that
    %
    \[ \lim_{N \to \infty} \frac{1}{2\pi} \int_0^\pi f(x+t) D_N(t)\; dt = \frac{f(x+)}{2}. \]
    %
    Since $\int_0^\pi D_N(t) = \pi$, this is equivalent to
    %
    \[ \lim_{N \to \infty} \frac{1}{2\pi} \int_0^\pi [f(x + t) - f(x+)] D_N(t)\; dt = 0. \]
    %
    Because of this, we may assume without loss of generality that $x = 0$ and $f(x+) = 0$. Then by the mean value theorem for integrals (which only applies for monotonic functions), for each $N$, there exists $0 \leq \nu_N \leq \delta$ such that
    %
    \begin{align*}
        \int_0^\pi f(t) D_N(t)\; dt &= \| f \|_\infty \int_{\nu_N}^\pi D_N(t)\; dt.
    \end{align*}
    %
    Now an integration by parts gives
    %
    \begin{align*}
        \int_{\nu_N}^\pi D_N(t) &\lesssim \int_{\nu_N}^\pi \frac{\sin((N + 1/2) t)}{t}\; dt = \int_{\nu_N/(N + 1/2)}^{\pi/(N + 1/2)} \frac{\sin(t)}{t}\; dt \lesssim \frac{1}{N+1/2}.
    \end{align*}
    %
    Thus
    %
    \[ \int_0^\pi f(t) D_N(t) \lesssim \frac{1}{N + 1/2} \to 0. \qedhere \]
\end{proof}

Of course, applying various better decay rates leads to a more uniform version of this theorem. The decay of the Fourier series depends on the decay of the Fourier coefficients of $yg(y)$ and $g(y) \cos(y/2)(y/\sin(y/2))$. In particular, if these coefficients is $O(|n|^{-m})$, then the convergence rate is also $O(|n|^{-m})$. If this decay rate is independent of $x$ for suitable values of $x$, the convergence will be uniform over these values of $x$.

\begin{example}
    Consider the sawtooth function defined on $[-\pi,\pi]$ by $s(t) = t$, and then made periodic on the entire real line. We can easily calculate the Fourier series here, obtaining that
    %
    \[ s(t) = i \sum_{n \neq 0} \frac{(-1)^n e_n(t)}{t} = -2 \sum_{n = 1}^\infty (-1)^n \frac{\sin(nt)}{n}. \]
    %
    Thus for any $t \in (-\pi,\pi)$,
    %
    \[ \sum_{n = 1}^\infty (-1)^n \frac{\sin(nt)}{n} = -t/2 \]
    %
    and
    %
    \[ \sum_{n = 1}^\infty (-1)^n \frac{\sin(n\pi)}{n} = \frac{s(-\pi) + s(\pi)}{2} = 0. \]
\end{example}

\begin{theorem}
    If $\widehat{f}(n) = O(|n|^{-1})$, and $f(t_0-)$ and $f(t_0+)$ exist, then
    %
    \[ (S_N f)(t_0) \to \frac{f(t_0-) + f(t_0+)}{2}. \]
\end{theorem}
\begin{proof}
    The idea of our proof is to break $f$ into a nice continuous function, and the sawtooth function, where we already understand the convergence of Fourier series. Without loss of generality, let $t_0 = \pi$. Define $g(t) = f(t) + (2\pi)^{-1} (f(\pi+) - f(\pi-)) s(t)$ on $(-\pi,\pi)$, where $s$ is the sawtooth function. Then
    %
    \[ \lim_{t \uparrow \pi} g(t) = \lim_{t \downarrow -\pi} g(t) = \frac{f(\pi+) + f(\pi-)}{2}. \]
    %
    Thus $g$ can be defined at $\pi + 2 \pi \mathbf{Z}$ so it is continuous there. Now we find $|\widehat{g}| \lesssim |\widehat{f}| + |\widehat{g}| = O(|n|^{-1})$, and so
    %
    \[ (S_N g)(\pi) \to \frac{f(\pi+) + f(\pi-)}{2}. \]
    %
    We also have $(S_N s)(\pi) \to 0$. Thus
    %
    \[ (S_N f)(\pi) = (S_N g)(\pi) - (S_N s)(\pi) \to \frac{f(\pi+) + f(\pi-)}{2}. \qedhere \]
\end{proof}

% Another way to fix the convergence is to use a more quantitative argument in terms of $L^p$ spaces. It is obvious that $S_N f \to f$ in any feasible norm if $f$ is a trigonometric polynomial, because if $f$ has degree $M$, then $S_N f = f$ for $N \geq M$. The Stone-Weirstrass theorem says that we can uniformly approximate any continuous function on $\mathbf{T}$ by a trigonometric polynomial, so provided we can show that the operators $S_N$ are uniformly bounded in the $L^p$ norm for $1 \leq p < \infty$, we obtain convergence for all $f \in L^p(\mathbf{T})$. The fact that the $S_N$ are not bounded in the $L^\infty$ norm is why the Fourier series can diverge pointwise for continuous functions. In fact, the $S_N$ are not bounded as operators on $L^1(\mathbf{T})$, and as such, Fourier series do not converge in the $L^1$ norm. The reason for this is that if $\{ K_M \}$ is a good kernel, then $S_N(K_M) = D_N * K_M \to D_N$ as $M \to \infty$, and so as $M \to \infty$, we find $\| S_N(K_M) \|_{L^1(\mathbf{T})} = \Omega(\log N)$, hence $\| S_N \|_{L^1(\mathbf{T})}$ is unbounded. Later on, using the theory of conjugate functions, we will show that the operators $S_N$ are uniformly bounded in all $L^p(\mathbf{T})$ for $1 < p < \infty$, and so the Fourier series of any function $f \in L^p(\mathbf{T})$ converges to $f$ in the $L^p$ norm.

\section{Pointwise Behaviour at Discontinuity Points}

This isn't the end of our discussion about points of discontinuity. There is an interesting phenomenon which occurs locally around the point of discontinuity. If $f$ is continuous locally around a discontinuity point $t_0$, $S_N f \to f$ pointwise locally around $t_0$. Thus, being continuous, $S_N f$ must `jump' from $(S_N f)(t_0-)$ to $(S_N f)(t_0+)$ locally around $t_0$. Interestingly enough, we find that the jump is not precise, the jump is overshot and then must be corrected to the left and right of $t_0$. This is known as the {\it Gibb's phenomenon}, after the man who clarified the reason for why this phenomenon occured in physical measurements where first thought to be a defect in the equipment used to take the measurements.

\begin{theorem}
    Given $f$ with finitely many discontinuity points and with $\widehat{f}(n) = O(|n|^{-1})$, in particular one at $t_0$, we find
    %
    \[ \lim_{N \to \infty} (S_N f)(t_0 \pm \pi/N) = f(t_0+) \pm C \cdot \frac{f(t_0+) - f(t_0-)}{2}, \]
    %
    where
    %
    \[ C = 2 \pi \int_0^\pi (\sin x)/x \approx 16.610. \]
\end{theorem}
\begin{proof}
    First consider the jump function $s$. Then
    %
    \begin{align*}
        (S_N s)(\pi + \pi/N) &= -2 \sum_{n = 1}^N \frac{\sin(n\pi/N)}{n} = -2\pi \sum_{n = 1}^N \frac{1}{N} \left( \frac{\sin(n\pi/N)}{\pi n/N} \right).
    \end{align*}
    %
    Here we're just taking averages of values of $\sin(x)/x$ at $x = \pi/N$, $x = 2\pi/N$, and so on and so forth. Thus is a Riemann sum, so as $N \to \infty$, we get that
    %
    \[ (S_N s)(\pi + \pi/N) \to - 2\pi \int_0^\pi \frac{\sin x}{x}. \]
    %
    The same calculations give
    %
    \[ (S_N s)(\pi - \pi/N) \to 2 \pi \int_0^\pi \frac{\sin x}{x}. \]
    %
    In general, given $f$, we can write $f = g + \sum \lambda_j h_j$, where $g$ is continuous, and $h_j$ is a translate of the sawtooth function. Then $S_N g$ converges to $g$ uniformly, and $S_N h_j \to 0$ for all $h_j$ uniformly in an interval outside of their discontinuity point. To see this, we note that an integration by parts gives
    %
    \[ \left| \int_{-\pi}^\pi D_N(y)[s(x-y) - s(x)]\; dy \right| \leq |G_N(x - \pi)|, \]
    %
    where $G_N(y) = -i \sum_{|n| \leq N} e_n(t)/n$, so $G_N' = D_N$. It now suffices to show $G_N(x - \pi) \to 0$ outside a neighbourhood of $\pi$. But if $A(u,t) = \sum_{|n| \leq u} e_n(t)$, summation by parts gives
    %
    \[ \sum_{|n| \leq N} \frac{e_n(t)}{n} = \frac{A(N,t)}{N} + \int_1^N \frac{A(u,t)}{u^2}. \]
    %
    Now a simple geometric sum shows $A(u,t) \lesssim 1/|e(t) - 1|$, so provided $d(t, 2 \pi \mathbf{Z})$ is bounded below, the quantity above tends to zero uniformly. This gives the required result.
\end{proof}

\chapter{Applications}

\section{Tchebychev Polynomials}

If $f$ is everywhere continuous, then for every $\varepsilon$, Fej\'{e}r's theorem says that we can find $N$ such that $\| \sigma_N(f) - f \| \leq \varepsilon$. But $\sigma_N f$ is just a trigonometric polynomial, and so we have shown that with respect to the $L^\infty$ norm, the space of trigonometric polynomials is dense in the space of all continuous functions.  Now if $f$ is a continuous function on $[0,\pi]$, then we can extend it to be even and $2\pi$ periodic, and then the trigonometric series $S_N(f)$ of $f$ will be a cosine series, hence $\sigma_N(f)$ will also be a cosine series, and so for each $\varepsilon$, we can find $N$ and coefficients $a_1, \dots, a_N$ such that
%
\[ \left| f(x) - \sum_{n = 1}^N a_n \cos(nx) \right| < \varepsilon. \]
%
Now we use a surprising fact. For each $n$, there exists a degree $n$ polynomial $T_n$ such that $\cos(nx) = T_n(\cos x)$. This is clear for $n = 0$ and $n = 1$. More generally, we can write
%
\begin{align*}
    \cos((m+1)x) &= \cos((m+1)x) + \cos((m-1)x) - \cos((m-1)x)\\
    &= \cos(mx + x) + \cos(mx - x) - \cos((m-1)x)\\
    &= 2 \cos x \cos(mx) - \cos((m-1)x).
\end{align*}
%
Thus we have the relation  $T_{m+1}(x) = 2xT_m(x) - T_{m-1}(x)$. These polynomials are known as {\bf Tchebyshev polynomials}, enabling us to move between `periodic coordinates' and standard Euclidean coordinates.

\begin{corollary}[Weirstrass]
    The polynomials are uniformly dense in $C[0,1]$.
\end{corollary}
\begin{proof}
    If $f$ is a continuous function on $[0,1]$, we can define $g(t) = f(|\cos(t)|)$. Then $g$ is even, and so for every $\varepsilon > 0$, we can find $a_1, \dots, a_N$ such that
    %
    \[ \left|g(t) - \sum_{n = 1}^N a_n \cos(nt) \right| = \left| g(t) - \sum_{n = 1}^N a_n T_n(\cos t) \right| < \varepsilon. \]
    %
    But if $x = \cos t$, for $\cos t \geq 0$, this equation says
    %
    \[ \left| f(x) - \sum_{n = 1}^N a_n T_n(x) \right| < \varepsilon, \]
    %
    and so we have uniformly approximated $f$ by a polynomial.
\end{proof}

\section{Exponential Sums and Equidistribution}

The next result uses Fourier analysis to characterize the asymptotic distribution of a certain sequence $a_1, a_2, \dots$. In particular, it is most useful in determining when this distribution is distributed when we consider $2 \pi a_1, 2 \pi a_2, \dots$ as elements of $\mathbf{T}$, i.e. so we only care about the fractional part of the numbers, or in other terms their behaviour modulo one. We say the sequence is {\it uniformly distributed} if for any interval $I \subset \mathbf{T}$, $\# \{ 2 \pi a_n \in I : n \leq N \} \sim N |I|$ as $N \to \infty$. By approximating continuous functions by step functions, this implies that if $f: \mathbf{T} \to \mathbf{C}$ is continuous, then
%
\[ \frac{f(2 \pi a_1) + \dots + f(2 \pi a_N)}{N} \to \frac{1}{2\pi} \int_{\mathbf{T}} f(t)\; dt. \]
%
It is the right hand side to which we can apply Fourier summation to obtain a very useful condition. We let $S_Nf$ denote the left hand side of the equation, and $Tf$ the right hand side.

\begin{theorem}[Weyl Condition]
    A sequence $a_1, a_2, \dots \in \mathbf{T}$ is uniformly distributed if and only if for every $n$, as $N \to \infty$, $e_n(2 \pi a_1) + \dots + e_n(2 \pi a_N) = o(N)$.
\end{theorem}
\begin{proof}
    The condition in the theorem implies that for any trigonometric polynomial $f$, $S_Nf \to Tf$. The $S_N$ are uniformly bounded as functions on $L^\infty(\mathbf{T})$, and $T$ is a bounded functional on this space as well. But this means that $\lim S_N f = T f$ for all $f$ in $C(\mathbf{T})$, since this equation holds on the dense subset of trigonometric polynomials.
\end{proof}

This technique enables us to completely characterize the equidistribution behaviour of arithmetic sequences. Given a particular $\gamma$, we consider the equidistribution of the sequence $\gamma, 2 \gamma, \dots$, which depends on the irrationality of $\gamma$.

\begin{example}
    Let $\gamma$ be an arbitrary real number. Then for any $n$, if $e_n(2 \pi \gamma) \neq 1$,
    %
    \[ \sum_{m = 1}^N e_n(2 \pi m \gamma) = \frac{e_n(2 \pi (N + 1) \gamma) - 1}{e_n(2 \pi \gamma) - 1} \lesssim 1 = o(N). \]
    %
    If $\gamma$ is an irrational number, then $e_n(2 \pi \gamma) \neq 1$ for all $n$, which implies that $\gamma, 2\gamma, \dots$ is equidistributed. Conversely, if $e_n(2 \pi \gamma) = 1$ for some $n$, we have
    %
    \[ \sum_{m = 1}^N e_n(a_m) = N. \]
    %
    which is not $o(N)$, so the sequence $\gamma, 2\gamma, \dots$ is {\it not} equidistributed. If $\gamma$ is rational, there certainly is $n$ such that $n \gamma \in \mathbf{Z}$, and so $e_n(2 \pi \gamma) = 1$.
\end{example}

On the other hand, it is still an open research to characterize, for which $\gamma$ the sequence $\gamma, \gamma^2, \gamma^3, \dots$ is equidistributed. Here is an example showing that there are $\gamma$ for which the sequence is not equidistributed.

\begin{example}
    Let $\gamma$ be the golden ratio $(1 + \sqrt{5})/2$. Consider the sequence
    %
    \[ a_n = \left( \frac{1 + \sqrt{5}}{2} \right)^n + \left( \frac{1 - \sqrt{5}}{2} \right)^n = b_n + c_n. \]
    %
    Then one checks that $a_n$ is a kind of Fibonacci sequence, with $a_{n+1} = a_n + a_{n-1}$, and initial conditions $a_0 = 2$, $a_1 = 1$. One checks that $c_n$ is always negative for odd $n$, and positive for even $n$, and tends to zero as $n \to \infty$. Since $a_n$ is an integer, this means that $d(b_n, \mathbf{Z}) = d(\gamma^n, \mathbf{Z}) \to 0$. But this means that the average distribution of the $\gamma^n$ modulo one is concentrated at the origin.
\end{example}

\section{The Isoperimetric Inequality}



\chapter{Physics}

\section{Heat Propagation Into the Ground}

Let us consider an application of the Fourier series taken from Fourier's original work. Consider heat moving from above ground to below ground, and vice versa. If we let $H(t,y)$ denote the temperature at a depth $y$ into the ground at time $t$, for $y > 0$. Assuming that the material of the ground is homogenous, by choosing appropriate units, the differential equation becomes $H_t = H_{yy}$, a variant of the heat equation. We assume that the heat at the surface changes periodically over the days and seasons, so
%
\[ H(t,0) = A \cos(2\pi t / D) + B \cos(2 \pi t/Y) + C, \]
%
where $A,B,C$ are arbitrary constants, $D$ is the length of a day, and $Y$ is the length of a year, so $Y = 365 D$. In our calculation, we assume the regularity condition that $H \in L^\infty [0,\infty)^2$, so the temperature does not magnify infinitely at large depths or large times.

To solve this equation, we use two tricks: linearity, and Fourier series. We can solve the heat equation by solving the three heat equations with initial conditions $H_D(t,0) = \cos(2\pi t/D)$, $H_Y(t,0) = \cos(2 \pi t/Y)$, and $H_C(t,0) = 1$, and then obtain a general solution by letting $H = A H_D + B H_Y + C H_C$. The third equation is easiest: we let $H_C(t,y) = 1$ for all $t$ and $y$. To solve the other equations, we can use variable separation. Assuming $H_D$ and $H_Y$ are bounded, this forces
%
\[ H_D(t,y)\; \propto\; \cos((2 \pi /D) t - (\pi / D)^{1/2} y) e^{- (\pi / D)^{1/2} y}, \]
\[ H_Y(t,y)\; \propto\; \cos((2\pi/Y)t - (\pi/Y)^{1/2} y) e^{- (\pi/Y)^{1/2} y}. \]
%
Thus the temperature in the ground splits into the daily heating effect, the seasonal heating effect, and a constant temperature. From these equations we get several interesting qualitative properties. As we go deeper into the ground, the temperature decays at a rate inversely dependant on the length of time, so even at small depths, the daily temperature becomes neglible, and only the seasonal temperature is important. Experimently, determining the constants in our equation, we determine this happens about half a foot into the ground. Next, the deeper we go in the ground, the more a `time lag' exists, where the seasonal temperature back in time has now travelled to the temperature at the current point in the ground. Experimentally, we determine that about 2-3 metres below ground, the temperature lags by six months. Fourier mentions this is a good depth to build a wine cellar.

\section{Seafaring with Fourier}

Here we discuss two problems in seafaring that can be solved quite accurately with Fourier analysis, first done by Kelvin in the late 1800s. Consider first the problem in determining the error of compass measurement on a ship when taking an initial bearing at harbor travelling. Thus for each angle $\theta$, we consider an error $g(\theta)$ such that if, at an angle $\theta$, we take a measurement $f(\theta)$, then $f(\theta) = \theta + g(\theta)$. Often $g$ is up to 20 degrees, but it will suffice to know $g$ up to an angle of two or three degrees, since other systematic errors in travel disturb the angle the ship actually travels by this amount anyway. And thus experimentally we find it suffices to approximate $g$ by a degree four trigonometric polynomial, i.e. we subtitute $g$ for an approximate value
%
\[ g_1(\theta) = A_0 + A_1 \cos \theta + B_1 \sin \theta + A_2 \cos(2\theta) + B_2 \sin(2\theta). \]
%
We can obtain measurements $g(\theta)$ for certain values of $\theta$ by locating landmarks, and 6 measurements suffice to uniquely identify $g_1$ from all other degree five trigonometric polynomials.

Another seafaring problem is to determine the future height of the tide. We expect the height of the tides to be due to periodic forces in nature. If $h(t)$ is the height of the tide, we might expect by linearity of the wave equation that $h(t) = h_1(t) + h_2(t) + \dots$, where $h_1(t)$ is the height with relation to the rotation of the earth and the moon, $h_2(t)$ the rotation of the earth and the sun, and so on and so forth to more neglible values. Each $h_k$ is periodic with some period $\omega_k$. If we assume that each $h_k$ is a trigonometric polynomial, then there is a way to reduce the calculation of the coefficients to a certain integral formula which one can approximate by taking samples of the height of the tides over time. Unfortunately, one must take a large number of samples to obtain this integral formula, but Kelvin designed one of the first automated calculators to approximate this.

\begin{theorem}
    If $h(t) = \sum_{n = 1}^N A_n \cos(\omega_n t)$, where the $\omega_n$ are all different periods, then for any $S$,
    %
    \[ A_n = \frac{2}{T} \lim_{n \to \infty} \int_S^{S + T} h(t) \cos(\omega_n t)\; dt. \]
\end{theorem}
\begin{proof}
    We just change variables. If $2 \pi N / \omega_n < T \leq 2 \pi (N + 1)/\omega_n$,
    %
    \begin{align*}
        \int_S^{S+T} h(t) \cos(\omega_n t)\; dt &= N \int_0^{2 \pi/ \omega_n} h(t) \cos(\omega_n t)\; dt + O(1)\\
        &= \frac{N}{\omega_n} \int_0^{2 \pi} \frac{1}{N} \sum_{k = 1}^N h(S + t/\omega_n + 2 \pi k / \omega_n) \cos(t)\; dt + O(1).
    \end{align*}
    %
    The average in the integral causes all oscillation not corresponding to $\omega_n$ to cancel out, so
    %
    \[ \frac{2}{T} \int_S^{S+T} h(t) \cos(\omega_n t)\; dt \to \frac{2}{\omega_n} \left( A_n \int_0^{2\pi} \cos^2(t) + B_n \int_0^{2\pi} \cos(t) \sin(t) \right). \qedhere \]
\end{proof}








\chapter{The Fourier Transform}

In the last few chapters, we discussed the role of analyzing the frequency decomposition of a periodic function on the real line. In this chapter, we explore the ways in which we may extend this construction to perform frequency analysis for not necessarily periodic functions on the real line, and more generally, in higher dimensional Euclidean space. The only periodic trigonometric functions on $[0,1]$ on the real line had integer frequencies of the form $2\pi n$, whereas on the real line periodic functions can have frequencies corresponding to any real number. The analogue of the discrete Fourier series formula
%
\[ f(x) = \sum_{k = -\infty}^\infty \widehat{f}(k) e(kx) \]
%
is the Fourier inversion formula
%
\[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e(\xi x)\; d\xi, \]
%
where for each real number $\xi$, we define
%
\[ \widehat{f}(\xi) = \int_{-\infty}^\infty f(x) e(- \xi x)\; dx. \]
%
The function $\widehat{f}$ is known as the {\bf Fourier transform} of the function $f$. It is also denoted by $\mathcal{F}(f)$. The role to which we can justify this formula is the main focus of this chapter. Without too much more work, we will also analyze the Fourier transform on $\RR^n$, which, given $f: \RR^n \to \RR^n$, considers the quantities
%
\[ f(x) \sim \int_{\RR^n} \widehat{f}(\xi) e(\xi \cdot x)\ d\xi,\quad\text{where}\quad \widehat{f}(\xi) = \int_{\RR^n} f(x) e(- \xi \cdot x)\ dx \]
%
for $\xi \in \RR^n$, where $e(t) = \exp(2 \pi i t)$ for any $t \in \RR$.

Later, we will interpret the Fourier transform in a very general manner for a very arbitrary class of functions. But first we must interpret the Fourier transform as a Lebesgue integral, and the weakest assumptions we can make in order to do this are that $f$ is an integrable function, i.e. that $f \in L^1(\RR^d)$. During arguments, we can often assume additional regularity properties of $f$, and then apply density arguments to get the result in general. Most of the properties of the Fourier transform are exactly the same as for Fourier series. The only new phenomenon in the basic theory is that the Fourier transform of an integrable function is continuous.

\begin{theorem}
    For any $f \in L^1(\RR^d)$, $\smash{\| \widehat{f} \|_{L^\infty(\RR^d)} \leq \| f \|_{L^1(\RR^d)}}$, and $\widehat{f} \in C_0(\RR^d)$.
\end{theorem}
\begin{proof}
    For any $\xi \in \RR^d$,
    %
    \[ |\widehat{f}(\xi)| = \left| \int f(x) e(- \xi \cdot x)\; dx \right| \leq \int |f(x)| |e(- \xi \cdot x)|\; dx = \| f \|_{L^1(\RR^d)}. \]
    %
    If $\chi_I$ is the characteristic function of an $n$ dimensional box, i.e.
    %
    \[ I = [a_1,b_1] \times \dots \times [a_n,b_n] = I_1 \times \dots \times I_n, \]
    %
    then
    %
    \[ \widehat{\chi_I}(\xi) = \int_I e(- \xi \cdot x) = \prod_{k = 1}^n \int_{a_k}^{b_k} e(- \xi_k x_k) = \prod_{k = 1}^n \widehat{\chi_{I_k}}(\xi_k). \]
    %
    where
    %
    \[ \widehat{\chi_{I_k}}(\xi_k) = \begin{cases} \frac{e(- \xi_k a_k) - e(- \xi_k b_k)}{2 \pi i \xi_k} & \xi_k \neq 0, \\ b_k - a_k & \xi_k = 0. \end{cases} \]
    %
    L'Hopital's rule shows $\widehat{\chi_{I_k}}$ is a continuous function. We also have the upper bound
    %
    \[ \widehat{\chi_{I_k}}(\xi_k) \lesssim_{I_k} (1 + |\xi_k|)^{-1} \]
    %
    for all $\xi_k \in \RR$, which implies that
    %
    \[ \widehat{\chi_I}(\xi) = \prod \widehat{\chi_{I_k}}(\xi_k) \lesssim_I \prod \frac{1}{1 + |\xi_k|} \lesssim_n \frac{1}{1 + |\xi|}. \]
    %
    Thus $\widehat{\chi_I}(\xi) \to 0$ as $|\xi| \to \infty$. But this implies the Fourier transform of any step function is continuous and vanishes at $\infty$. Since step functions are dense in $L^1(\RR^d)$, a density argument then gives the result for all integrable functions.
\end{proof}

\begin{remark}
    The space
    %
    \[ \mathbf{A}(\RR^d) = \left\{ \widehat{f}: f \in L^1(\RR^d) \right\} \]
    %
    is called the \emph{Fourier algebra}. The last theorem shows $\mathbf{A}(\RR^d) \subset C_0(\RR^d)$, but it is {\it not} the case that $\mathbf{A}(\RR^d) = C_0(\RR^d)$. As of yet, current research cannot give a satisfactory description of the elements of $\mathbf{A}(\RR^d)$.
\end{remark}

\begin{lemma}
    For any $0 \leq a < b < \infty$, independantly of $a$ and $b$,
    %
    \[ \left| \int_a^b \frac{\sin x}{x} \right| = O(1). \]
\end{lemma}
\begin{proof}
    Since $|\sin(x)/x| \leq 1$ for all $x$, we may assume $b > 1$, for otherwise we obtain a trivial bound. This also implies
    %
    \begin{align*}
        \left| \int_a^b \frac{\sin x}{x}\; dx \right| \leq 1 + \left| \int_1^b \frac{\sin x}{x}\; dx \right|.
    \end{align*}
    %
    An integration by parts then shows that
    %
    \[ \left| \int_1^b \frac{\sin x}{x}\; dx \right| \leq \left| \left( \cos 1 - \frac{\cos b}{b} \right) \right| + \left| \int_1^b \frac{\cos x}{x^2}\; dx \right| \lesssim 1. \qedhere \]
\end{proof}

\begin{theorem}
    $\mathbf{A}(\RR) \neq C_0(\RR)$. In particular, $\mathbf{A}(\RR)$ does not contain any odd functions $g$ in $C_0(\RR)$ such that
    %
    \[ \limsup_{b \to \infty} \left| \int_1^b \frac{g(\xi)}{\xi}\; d\xi \right| = \infty. \]
\end{theorem}
\begin{proof}
    Suppose $f \in L^1(\RR)$, and $\widehat{f} \in C_0(\RR)$ is an odd function. Then we know
    %
    \[ \widehat{f}(\xi) = -i \int_{-\infty}^\infty f(x) \sin(2 \pi \xi x)\; dx. \]
    %
    Thus an application of Fubini's theorem shows that
    %
    \[ \left| \int_1^b \frac{\widehat{f}(\xi)}{\xi}\; d\xi \right| = \left| \int_{-\infty}^\infty f(x) \left( \int_1^b \frac{\sin(2 \pi \xi x)}{\xi}\; d\xi \right)\; dx \right|. \]
    %
    But
    %
    \[ \left| \int_1^b \frac{\sin(2 \pi \xi x)}{\xi}\; d\xi \right| = \left| \int_{2 \pi x}^{2 \pi b x} \frac{\sin \xi}{\xi}\; d\xi \right| \lesssim 1. \]
    %
    Thus we obtain that
    %
    \[ \left| \int_1^b \frac{\widehat{f}(\xi)}{\xi}\; d\xi \right| \lesssim \| f \|_{L^1(\RR)}. \qedhere \]
\end{proof}

Elementary properties of integration give the following relations among the Fourier transforms of functions on $\RR^d$. They are strongly related to the translation invariance of the Lebesgue integral on $\RR^d$:
%
\begin{itemize}
    \item If $\overline{f}(x) = \overline{f(x)}$ is the conjugate of a function $f$, then
    %
    \[ (\overline{f})^\ft(\xi) = \int \overline{f(x)} e(- x \cdot \xi)\; dx = \overline{\int f(x) e(x \cdot \xi)} = \overline{\widehat{f}(-\xi)}. \]
    %
    If $f$ is real, the formula above says $\widehat{f}(\xi) = \overline{\widehat{f}(-\xi)}$, and so if we define $a(\xi) = \text{Re}(\widehat{f}(\xi))$, $b(\xi) = \text{Im}(\widehat{f}(\xi))$, then formally we have
    %
    \[ \int_{-\infty}^\infty \widehat{f}(\xi) e(\xi x)\; d\xi = 2 \int_0^\infty a(\xi) \cos(2 \pi \xi x) - b(\xi) \sin(2 \pi \xi x)\; d\xi. \]
    %
    Thus the Fourier representation formula expresses the function $f$ as an integral in sines and cosines.
    
    \item There is a duality between translation and frequency modulation. For $y \in \RR^d$, we define $(T_y f)(x) = f(x - y)$. If $\xi \in \RR^d$, then we define $(M_\xi f)(x) = e(\xi \cdot x) f(x)$. We then find that
    %
    \begin{align*}
        \widehat{T_y f}(\xi) &= \int f(x - y) e(- \xi \cdot x)\; dx\\
        &= e(- \xi \cdot y) \int f(x) e(- \xi \cdot x)\; dx = (M_{-y} \widehat{f})(\xi).
    \end{align*}
    %
    and
    %
    \begin{align*}
        \widehat{M_\xi f}(\eta) = \int e(\xi \cdot x) f(x) e(- \eta \cdot x)\; dx = \widehat{f}(\eta - \xi) = (T_\xi \widehat{f})(\eta).
    \end{align*}
    %
    Thus we conclude $\mathcal{F} \circ T_y = M_{-y} \circ \mathcal{F}$, and $\mathcal{F} \circ M_\xi = T_\xi \circ \mathcal{F}$.

    \item Let $T: \RR^d \to \RR^d$ be an invertible linear transformation. Then a change of variables $y = Tx$ gives
    %
    \begin{align*}
        \widehat{f \circ T}(\xi) &= \int f(Tx) e(-\xi \cdot x)\; dx\\
        &= \frac{1}{|\det(T)|} \int f(y) e(- \xi \cdot T^{-1}y)\; dy\\
        &= \frac{1}{|\det(T)|} \int f(y) e(- T^{-t} \xi \cdot y)\; dy\\
        &= \frac{1}{|\det(T)|} (\widehat{f} \circ T^{-t})(\xi).
    \end{align*}
    %
    Thus we conclude that if $T^*(f) = f \circ T$, then $\mathcal{F} \circ T^* = |\det(T)|^{-1} (T^{-t})^* \circ \mathcal{F}$.

    \item As a special case of the theorem above, if $a \in \RR$ and $(D_a f)(x) = f(ax)$, then
    %
    \[ \widehat{D_a f}(\xi) = a^{-d} \widehat{f}(\xi/a) \]
    %
    If we dilate by a small value of $a$, then the values of $f$ are traced over more slowly, so $D_a f$ has smaller frequencies. But the magnitude of these frequencies is increase to compensate.

    \item If $R \in O_n(\RR)$, then $\widehat{f \circ R}(\xi) = \widehat{f}(R \xi)$, i.e. $\mathcal{F} \circ R^* = R^* \circ \mathcal{F}$. In particular, if $f$ is a radial function, so $f \circ R = f$ for any $R$, then $\widehat{f}(R \xi) = \widehat{f}(\xi)$ for any $R \in O_n(\RR)$, so $\widehat{f}$ is also a radial function. If $f$ is even, so $f(x) = f(-x)$ for all $x$, then $\widehat{f}(\xi) = \widehat{f}(-\xi)$ for all $\xi$, so $\widehat{f}$ is even. Similarily, if $f$ is odd, then $\widehat{f}$ is odd.

    \item Given $f,g \in L^1(\RR^d)$, we define the convolution
    %
    \[ (f * g)(x) = \int f(y) g(x-y)\; dy. \]
    %
    This convolution possesses precisely the same properties as convolution on $\mathbf{T}$. Most importantly for us,
    %
    \[ \mathcal{F}(f * g) = \mathcal{F}(f) \cdot \mathcal{F}(g), \]
    %
    so convolution in phase space is just a product in frequency space.
\end{itemize}

Just as with Fourier series, we have a duality between decay of a function and smoothness of it's transform. We say $f$ has a {\bf strong derivative} $f_k$ in $L^p(\RR^d)$ if the family of functions
%
\[ (\Delta_h f)(x) = \frac{f(x + h e_k) - f(x)}{h} \]
%
converge in $L^p(\RR^d)$ to $f_k$. Essentially, this means that the approximations of $f$ to it's derivative quantitatively converge in the mean. If $f$ has a strong derivative in $L^p(\RR^d)$, then $f_k$ is actually differentiable almost everywhere. However, even if $f$ has a pointwise partial derivative $f_k$, the differences $\Delta_h f$ may not converge to $f_k$ fast enough to conclude that $f$ has a strong derivative. It is fairly easy to prove using the mean value theorem that if $f$ converges to $f_k$ in the $L^\infty$ norm, and $f$ has compact support, then $f$ has a strong derivative in all other $L^p$ spaces. If $f$ is not compactly supported, but decays rapidly at $\infty$, then it is often the case that the $L^p$ derivative will be the same as the classical derivative. In particular, this is true of a Schwartz function.

\begin{theorem}
    If $f \in L^1(\RR^d)$, and $x_k f \in L^1(\RR^d)$, then $\widehat{f}$ has a strong derivative in the $L^\infty$ norm, and $\widehat{f}_k(\xi) = - 2 \pi i (x_k f)^\ft(\xi)$.
\end{theorem}
\begin{proof}
    Note that a change of variables implies
    %
    \[ (\Delta_h \widehat{f})(\xi) = \int f(x) \frac{e(-h x_k) - 1}{h} e(- \xi \cdot x)\; dx = \widehat{g_h}(\xi), \]
    %
    where
    %
    \[ g_h(x) = f(x) \frac{e(h x_k) - 1}{h}. \]
    %
    Note that
    %
    \[ \left| \frac{e(h x_k) - 1}{h} \right| = O(1 + |x_k|). \]
    %
    Since $x_k f$ is integrable, we can apply the dominated convergence theorem. Because $(e(h x_k) - 1)/h$ tends to $-2 \pi i x_k f(x)$ as $h \downarrow 0$, the function $g_h$ tends to $-2\pi i x_k f$ in $L^1(\RR^d)$. Taking Fourier transforms, we conclude that $\Delta_h \widehat{f} = \widehat{g_h}$ converges uniformly to $(-2 \pi i x_k f)^\ft(\xi)$.
\end{proof}

\begin{remark}
    In particular, the Fourier transform of a compactly supported function lies in $C^\infty(\RR^d)$, and has strong derivatives of all orders.
\end{remark}

%\begin{remark}
%   If $f$ no longer has compact support, but $D_k f$ vanishes rapidly at infinity, then we can normally still establish that $D_k f$ is the derivative of $f$ in $L^1(\RR^n)$. Indeed, suppose $|(D_k f)(x)| \leq g(|x|)$, where $g$ is an increasing function with $\int_0^\infty t^{n-1} g(t) < \infty$, then surely $\Delta_h f$ converges to $D_k f$ in $L^1$ on any compact set, which implies that for any $M$, using the mean value theorem again,
    %
%   \begin{align*}
%       \int_{\RR^n} &|(\Delta_h f)(x) - D_k f(x)|\; dx \leq o_M(1) + \int_{|x| > M} |(\Delta_h f)(x)| + |D_k f(x)| \\
%       &\leq o_M(1) + O \left( \int_{|x| > M} g(|x| + |h|)\; dx \right) = o_M(1) + O \left( \int_M^\infty t^{n-1}g(t)\; dt \right)\\
%   \end{align*}
    %
%   If we choose $M$ large enough that the big $O$ term is $\leq \varepsilon$, then we find $\| \Delta_h f - D_k f \|_1 \leq \varepsilon + o_M(1)$, and taking $\varepsilon \to 0$ shows the convergence. This shows the derivatives exist if, for instance, $f$ is a Schwarz function, since then $|D_k f(x)| \lesssim 1/(1 + |x|^{n+1})$.
%\end{remark}

\begin{theorem}
    If $f$ has a strong derivative $f_k$ in the $L^1$ norm, $\widehat{f_k}(\xi) = 2 \pi i \xi_k \widehat{f}(\xi)$.
\end{theorem}
\begin{proof}
    It suffices to note that
    %
    \[ \widehat{\Delta_h f}(\xi) = \frac{e(h \xi_k) - 1}{h} \widehat{f}(\xi). \]
    %
    Since $\Delta_h f \to f_k$ in $L^1$, $\widehat{\Delta_h f} \to \widehat{f_k}$ uniformly, and in particular, converges to $\widehat{f_k}$ pointwise. But we know $\widehat{\Delta_h f}$ converges pointwise to $2 \pi i \xi_k \widehat{f}(\xi)$.
\end{proof}

%\begin{theorem}
%   If $X$ is a homogenous space of functions, the $f * K_\delta$ converges to $f$ in the norm associated with $X$.
%\end{theorem}
%\begin{proof}
%   Given a continuous function function $F: \mathbf{T} \to X$, we define the formal Riemann integral of functions as
    %
%   \[ \int_{\mathbf{T}} F(x)\; dx = \lim_{N \to \infty} \frac{1}{N} \sum_{n = 1}^N F(2 \pi /N) \]
    %
%   which exists for the same reason the Riemann integral of a continuous real valued function exists. Now we can consider the formal function theoretic convolution
    %
%   \[ \int_{\mathbf{T}} K_\delta(x) f_x\; dx \]
    %
%   This is equal to $K_\delta * f$, because the $L^1$ norm lower bounds the norm on $X$, so that the limit with respect to the $L^1$ norm is the same as with respect to the norm on $X$, and
    %
%   \[ s \]
    %
%   \[ \int_{\mathbf{T}} K_\delta(x) f_x\; dx - f = \int_0^{2\pi} K_\delta(x)[f_x - f]\; dx \]
    %
%   If we choose 
%\end{proof}
%
%More generally, if we equip a translation invariant subspace of $L^1(\RR^n)$ with a norm lower bounded up to a constant by the $L^1$ norm which turns the space into a Banach space, then $f * K_\delta$ converges to $f$ in that norm. If in addition, the $K_\delta$ satisfy $|K_\delta(x)| \lesssim \delta^{-n}$, and $|K_\delta(x)| \lesssim \delta/|x|^{n+1}$, then $f * K_\delta$ converges to $f$ almost everywhere. 

\section{Convergence Using Alternative Summation}

As we might expect from the Fourier series theory, the formula
%
\[ f(x) = \int \widehat{f}(\xi) e(\xi \cdot x)\; dx \]
%
does not hold for every integrable $f$, nor even for all continuous $f$. In particular, the Fourier transform of $f$ need not even lie in $L^1(\RR^d)$, so the integral formula may not even make sense. Nonetheless, just as with Fourier series, one can obtain general results by `dampening' the integration.

\begin{example}
    Even if $f$ is a non integrable function, the functions $f(x) e^{-\delta |x|}$ may be integrable for $\delta > 0$. We say $f$ is \emph{Abel summable} to a value $A$ if
    %
    \[ \lim_{\delta \to 0} \int f(x) e^{-\delta |x|}\; dx = A \]
    %
    For each $\delta > 0$ and $f \in L^1(\RR^d)$, we let
    %
    \[ (A_\delta f)(x) = \int \widehat{f}(\xi) e(\xi \cdot x) e^{-\delta |\xi|}\; d\xi. \]
\end{example}

If $f \in L^1(\RR^d)$, then the dominated convergence theorem implies that
%
\[ \int f(x) e^{-\delta |x|}\; dx \to \int f(x)\; dx. \]
%
so $f$ is Abel summable. However, $f$ may be Abel summable even if $f$ is not integrable. For instance, if $f(x) = \sin(x)/x$, then $f$ is not integrable, yet $f$ is Abel summable to $\pi$ over the real line.

\begin{example}
    Similarily, we can consider the Gauss sums
    %
    \[ \int f(x) e^{-\delta |x|^2}\; dx \]
    %
    We say $f$ is Gauss summable to if these values converge as $\delta \to 0$. For $f \in L^1(\RR^d)$, we let
    %
    \[ (G_\delta f)(x) = \int \widehat{f}(\xi) e(\xi \cdot x) e^{-\delta |\xi|^2}\; d\xi. \]
\end{example}

\begin{example}
    For $d = 1$, we can also consider the Fej\'{e}r sums
    %
    \[ (\sigma_\delta f)(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e(\xi \cdot x) \left( \frac{\sin(\delta \pi \xi)}{\delta \pi \xi} \right)^2\; d\xi. \]
\end{example}

\begin{example}
    In basic calculus, the integral of a function $f$ over the entire real line is defined as
    %
    \[ \int_{-\infty}^\infty f(x)\; dx = \lim_{t \to \infty} \int_{-t}^t f(x)\; dx. \]
    %
    These integrals can be written as the integral of $f \chi_{[-t,t]}$, and so in a generalized sense, we can integrate a function $f$ if $f \chi_{[-t,t]}$ is integrable for each $N$, and the integrals of these functions converge as $t \to \infty$. Thus we study
    %
    \[ (S_R f)(x) = \int_{-R}^R \widehat{f}(\xi) e(\xi \cdot x)\; d\xi. \]
\end{example}

Abel summability is more general than the piecewise limit integral considered in the last example, as the next lemma proves.

\begin{lemma}
    Suppose $f \in L^1_{\text{loc}}(\RR^d)$, that
    %
    \[ \lim_{t \to \infty} \int_{-t}^t f(x)\; dx \]
    %
    exists, and that $f(x) e^{-\delta x^2}$ is absolutely integrable for each $\delta > 0$. Then $f$ is Abel summable, and
    %
    \[ \lim_{\delta \to 0} \int_{-\infty}^\infty f(x) e^{-\delta |x|^2} = \lim_{t \to \infty} \int_{-t}^t f(x)\; dx. \]
\end{lemma}
\begin{proof}
    Let
    %
    \[ \lim_{t \to \infty} \int_{-t}^t f(x)\; dx = A. \]
    %
    For each $x \geq 0$, write
    %
    \[ F(x) = \int_{-x}^x f(x)\; dx. \]
    %
    Then $F$ is continuous, and $F(x) \to A$ as $x \to \infty$. We know that $F'(x) = f(x) + f(-x)$, and an integration by parts gives for each $s > 0$,
    %
    \begin{align*}
        \int_{-s}^s f(x) e^{-\delta x^2}\; dx &= \int_0^s [f(x) + f(-x)] e^{-\delta x^2}\; dx = F(s) e^{-\delta s^2} + 2 \delta \int_0^s x F(x) e^{-\delta x^2}\; dx.
    \end{align*}
    %
    Taking $s \to \infty$, using the fact that $F$ is bounded so that $F(s) e^{-\delta s^2} \to 0$, we conclude
    %
    \[ \int f(x) e^{-\delta x^2}\; dx = 2 \delta \int_0^\infty x F(x) e^{-\delta x^2}\; dx. \]
    Given $\varepsilon > 0$, fix $t$ such that $|F(s) - A| \leq \varepsilon$ for $s \geq t$. Then
    %
    \begin{align*}
        \left| \int f(x) e^{-\delta x^2}\; dx - A \right| &\leq 2 \delta \left| \int_0^t x F(x) e^{-\delta x^2}\; dx \right|\\
        &\quad + 2 \delta \varepsilon \left| \int_t^\infty x e^{-\delta x^2} \right|\\
        &\quad + \left| 2 \delta A \int_t^\infty x e^{-\delta x^2}\; dx - A \right|.
    \end{align*}
    %
    The first and second components of this upper bound can each be made smaller than $\varepsilon$ for small enough $\delta$. And
    %
    \[ 2 \delta \int_t^\infty x e^{-\delta x^2}\; dx = e^{-\delta t^2} \]
    %
    So the 3rd term is equal to
    %
    \[ |A| |1 - e^{-\delta t^2}| \]
    %
    and for small enough $\delta$, we can also bound this by $\varepsilon$. Thus we have shown for small enough $\delta$ that
    %
    \[ \left| \int f(x) e^{-\delta x^2}\; dx - A \right| \leq 3 \varepsilon. \]
    %
    It now suffices to take $\varepsilon \to 0$.
\end{proof}

Abel summation is even more general than Gauss summation.

\begin{lemma}
    If $f$ is Gauss summable, and $f(x) e^{-\delta |x|}$ is absolutely integrable for each $\delta > 0$, then $f$ is Abel summable, and
    %
    \[ \lim_{\delta \to 0} \int f(x) e^{-\delta |x|^2}\; dx = \lim_{\delta \to 0} \int f(x) e^{-\delta |x|}\; dx. \]
\end{lemma}
\begin{proof}
    Let
    %
    \[ \lim_{\delta \to 0} \int f(x) e^{-\delta |x|^2}\; dx = A. \]
    %
    If there existed constants $c_n$ and $\lambda_n$ such that $e^{-\delta |x|} = \sum c_n e^{-(\lambda_n \delta |x|)^2}$, this theorem would be easy. This is not exactly true, but we do have the {\it subordination principle}, which says
    %
    \[ e^{-\delta |x|} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\delta^2 |x|^2/4u}\; du. \]
    %
    This formula, which is proved using basic complex analysis, is shown later on in this chapter. Applying Fubini's theorem, this means that
    %
    \[ \int f(x) e^{-\delta |x|} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; dx\; du. \]
    %
    For any fixed $t > 0$, we certainly have
    %
    \[ \lim_{\delta \to 0} \int_t^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; dx\; du = A \int_t^\infty \frac{e^{-u}}{\sqrt{\pi u}} \]
    %
    And this is equal to $A(1 + o(1))$ as $t \to 0$. And now we calculate
    %
    \[ \int_0^t \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; du \leq \left\| \frac{e^{-u}}{\sqrt{\pi u}} \right\|_{L^1[0,t]} \left\| \int f(x) e^{-\delta^2 |x|^2/4u} \right\|_{L^\infty[0,t]} \]
    %
    The left norm tends to zero as $t \to 0$. And as $u \downarrow 0$, the dominated convergence theorem implies that
    %
    \[ \int f(x) e^{-\delta |x|^2/4u} \to 0. \]
    %
    This completes the proof.
\end{proof}

For any family of functions $\Phi_\delta$, we can consider the `$\Phi$ sums'
%
\[ \int f(x) \Phi_\delta(x)\; d\xi \]
%
and the corresponding Fourier transform operators
%
\[ S_\delta(f,\Phi)(x) = \int \widehat{f}(x) e(\xi \cdot x) \Phi_\delta(\xi)\; d\xi. \]
%
We say $f$ is $\Phi$ summable to a value if
%
\[ \int f(x) \Phi_\delta(x)\; d\xi \]
%
converges. In all the examples we will consider, we construct $\Phi$ sums by fixing a function $\Phi \in C_0(\RR^n)$ with $\Phi(0) = 1$, and defining $\Phi_\delta(x) = \Phi(\delta x)$. When this is the case $f(x) \Phi_\delta(x)$ converges to $f(x)$ pointwise for each $x$ as $\delta \to 0$. Thus if $f \in L^1(\RR^d)$, the dominated convergence theorem implies that $f$ is $\Phi$ summable to it's usual integral. We now use these summability kernels to understand the Fourier summation formula.

\begin{theorem}[The Multiplication Formula]
    If $f,g \in L^1(\RR^n)$,
    %
    \[ \int f(x) \widehat{g}(x)\; dx = \int \widehat{f}(\xi) g(\xi)\; dx. \]
\end{theorem}
\begin{proof}
    If $f, g \in L^1(\RR^n)$, then $\widehat{f}$ and $\widehat{g}$ are bounded, continuous functions on $\RR^n$. In particular, $\widehat{f} g$ and $f \widehat{g}$ are integrable. A simple use of Fubini's theorem gives
    %
    \[ \int f(x) \widehat{g}(x)\; dx = \int \int f(x) g(\xi) e(- \xi \cdot x)\; dx\; d\xi = \int g(\xi) \widehat{f}(\xi)\; d\xi. \qedhere \]
\end{proof}

If $\Phi$ is integrable, then the multiplication formula shows
%
\begin{align*}
    S_\delta(f,\Phi) &= \int \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta \xi) d\xi\\
    &= \int f(x) (M_x (\delta_\delta \Phi))^\ft(x)\; dx = \delta^{-n} \int f(x) \cdot \widehat{\Phi} \left( \frac{x - y}{\delta} \right)\; dx.
\end{align*}
%
Thus if we define $K^\Phi_\delta(x) = \delta^{-n} \widehat{\Phi}(-x/\delta)$, then $S_\delta(f,\Phi) = K^\Phi_\delta * f$. Thus we have expressed the summation operators as convolution operations.

We now recall some notions of convolution kernels that help us approximate functions. Recall that if a family of kernels $\{ K_\delta \}$ satisfies
%
\begin{itemize}
    \item For any $\delta > 0$,
    %
    \[ \int K_\delta(\xi)\; d\xi = 1. \]

    \item The values $\{ \| K_\delta \|_{L^1(\RR^n)} \}$ are uniformly bounded in $\delta$.

    \item For any $\varepsilon > 0$,
    %
    \[ \lim_{\delta \to 0} \int_{|\xi| \geq \varepsilon} |K_\delta(\xi)|\; d\xi \to 0. \]
\end{itemize}
%
then the family forms a \emph{good kernel}. If this is the case, then $f * K_\delta$ converges to $f$ in the $L^p$ norms if $f \in L^p(\RR^n)$, and converges to $f$ uniformly if $f$ is continuous and bounded. If we have the stronger conditions that
%
\begin{itemize}
    \item For any $\delta > 0$,
    %
    \[ \int K_\delta(\xi)\; d\xi = 1. \]

    \item $\| K_\delta \|_{L^\infty(\RR^d)} \lesssim 1/\delta^d$.
    \item For any $\delta > 0$ and $\xi \in \RR^d$,
    %
    \[ |K_\delta(\xi)| \lesssim \frac{\delta}{|x|^{d+1}}. \]
\end{itemize}
%
then the family $\{ K_\delta \}$ is an approximation to the identity, and so $(K_\delta * f)(x)$ converges to $f(x)$ for any $x$ in the Lebesgue set of $f$.

\begin{example}
    We obtain the {\it Fej\'{e}r kernel} $F_\delta$ from the initial function
    %
    \[ F(x) = \left( \frac{\sin \pi x}{\pi x} \right)^2 \]
    %
    Using contour integration, we now show
    %
    \[ \widehat{F}(\xi) = \begin{cases} 1 - |\xi| & : |\xi| \leq 1\\ 0 &: |\xi| > 1 \end{cases} \]
    %
    Since this functions is compactly supported, with total mass one, it is easy to see the corresponding Kernel $K^F_\delta$ are an approximation to the identity. Thus $\sigma_\delta f$ converges to $f$ in all the manners described above.

    Since $F$ is an even function, $\widehat{F}$ is even, and so we may assume $\xi \geq 0$. We initially calculate
    %
    \[ \widehat{F}(\xi) = \int_{-\infty}^\infty \left( \frac{\sin(\pi x)}{\pi x} \right)^2 e(- \xi x)\; dx = \frac{1}{\pi} \int_{-\infty}^\infty \left( \frac{\sin x}{x} \right)^2 e(- 2 \xi x) \; dx. \]
    %
    Now we have
    %
    \[ (\sin z)^2 = \left( \frac{e(z) - e(-z)}{2i} \right)^2 = \frac{(2 - e^{2iz}) - e^{-2iz}}{4}. \]
    %
    This means
    %
    \begin{align*}
        \frac{(\sin z)^2}{z^2} e^{- 2 i \xi z} &= \frac{2e^{-2 i \xi z} - e^{-2(\xi + 1) i z}) - e^{-2(\xi - 1)iz}}{4z^2 } = \frac{f_\xi(z) + g_\xi(z)}{4}.
    \end{align*}
    %
    For $\xi \geq 0$, $f_\xi(z)$ is $O_\xi(1/|z|^2)$ in the lower half plane, because if $\text{Im}(z) \leq 0$,
    %
    \[ |2e^{-2 i \xi z} - e^{-2(\xi + 1) z}| \leq 2e^{2\xi} + e^{2(\xi + 1)} = O_\xi(1). \]
    %
    For $\xi \geq 1$, $g_\xi(z)$ is also $O_\xi(1/|z|^2)$ in the lower half plane, because
    %
    \[ |e^{-2(\xi - 1)iz}| \leq e^{2(\xi - 1)}.  \]
    %
    Now since $(\sin x/x)^2 e^{-2 i \xi x}$ can be extended to an entire function on the entire complex plane, which is bounded on any horizontal strip, we can apply Cauchy's theorem and take limits to conclude that
    %
    \begin{align*}
        \widehat{F}(\xi) = \frac{1}{\pi} \int_{-\infty}^\infty \frac{(\sin x)^2}{x^2} e^{-2 i \xi x}\; dx &= \frac{1}{\pi} \int_{-\infty}^{\infty} \frac{(\sin (x - iy)^2}{(x - iy)^2} e^{-2 i \xi x  -2 \xi y}\; dx\\
        &= \frac{1}{4 \pi} \int_{-\infty}^\infty f_\xi(x - iy) + g_\xi(x - iy)\; dx.
    \end{align*}
    %
    If $\xi \geq 1$, the functions $f_\xi$ and $g_\xi$ are both negligible in the lower half plane, and have no poles in the lower half plane, so if we let $\gamma$ denote the curve of length $2 \pi n$ travelling anticlockwise along the lower semicircle with vertices $-n - iy$ and $n - iy$, then because $|z| \geq n$ on $\gamma$,
    %
    \begin{align*}
        \int_{-n}^n f_\xi(x - iy) + g_\xi(x - iy)\; dx &= \int_\gamma f_\xi(z) + g_\xi(z)\; dz\\
        &= \text{length}(\gamma) \| f_\xi + g_\xi \|_{L^\infty(\gamma)}\\
        &= (2 \pi n) O_\xi(1/n^2) = O_\xi(1/n),
    \end{align*}
    %
    and so we conclude that
    %
    \[ \int_{-\infty}^\infty f_\xi(x - iy) + g_\xi(x - iy)\; dx = 0. \]
    %
    This means $\widehat{F}(\xi) = 0$. If $0 \leq \xi \leq 1$, then $f_\xi$ is still small in the lower half plane, so we can conclude that
    %
    \[ \int_{-\infty}^\infty f_\xi(x - iy)\; dx = 0. \]
    %
    But $g_\xi$ is now small in the upper half plane. For $\text{Im}(z) \geq -y$,
    %
    \[ |e^{-2(\xi - 1)iz}| = |e^{2(1 - \xi)iz}| \leq e^{2(1 - \xi)y}, \] 
    %
    so $g_\xi(z) = O_\xi(1/|z|^2)$ in the half plane above the line $\RR - iy$. The only problem now is that $g_\xi$ has a pole in this upper half plane, at the origin. Taking Laurent series here, we find that the residue at this point is $2i(\xi - 1)$. Thus, if we let $\gamma$ be the curve obtained from travelling anticlockwise about the upper semicircle with vertices $-n - iy$ and $n - iy$, then $|z| \geq n - y$ on this curve, and the residue theorem tells us that
    %
    \[ \int_{-n}^n g_\xi(x - iy)\; dx + \int_\gamma g_\xi(z)\; dz = 2\pi i (2i(\xi - 1)) = 4 \pi (1 - \xi), \]
    %
    and we now find that, as with the evaluation of the previous case,
    %
    \[ \int_\gamma g_\xi(z)\; dz \leq (2 \pi n) O_{\xi,y}(1/n^2) = O_{\xi,y}(1/n). \]
    %
    Taking $n \to \infty$, we conclude
    %
    \[ \int_{-\infty}^\infty g_\xi(x - iy)\; dx = 4 \pi (1 - \xi), \]
    %
    and putting this all together, we conclude that $\widehat{F}(\xi) = 1 - \xi$.
%   It is interesting in this particular case to note that
    %
%   \begin{align*}
%       \int_{-1}^1 (1 - |\xi|) e^{2 \pi i\xi x}\; d\xi &= 2 \int_0^1 (1 - \xi) \cos(2 \pi \xi x)\; d\xi\\
%       &= 2 \left( \left. \frac{(1 - \xi) \sin(2 \pi \xi x)}{2 \pi x} - \frac{\cos(2 \pi \xi x)}{(2 \pi x)^2} \right|_0^1 \right)\\
%       &= 2 \frac{1 - \cos(2 \pi x)}{(2 \pi x)^2} = \frac{\sin^2(\pi x)}{(\pi x)^2} = F(x)
%   \end{align*}
    %
%   which is exactly the inversion formula we want for all $L^1$ functions.
\end{example}

\begin{example}
    In the next paragraph, we calculate that if $\Phi(x) = e^{-\pi |x|^2}$, then $\widehat{\Phi} = \Phi$. Thus if we define the \emph{Weirstrass kernel} by
    %
    \[ W_\delta(\xi) = \delta^{-d} e^{-\pi |x|^2/\delta^2}, \]
    %
    then $G_\delta(f) = W_\delta * f$. Since the family $\{ W_\delta \}$ is an approximation to the identity, this shows $G_\delta(f)$ converges to $f$ in all the appropriate senses.

    Since $\Phi$ breaks onto products of exponentials over each coordinate, it suffices to calculate the Fourier transform in one dimension, from which we can obtain the general transform by taking products. In the one dimensional case, since $\Phi'(x) = -2 \pi x e^{- \pi x^2}$ is integrable, we conclude that $\widehat{\Phi}$ is differentiable, and
    %
    \[ (\widehat{\Phi})'(\xi) = (- 2 \pi i \xi \Phi)^\ft(\xi) = i (\Phi')^\ft(\xi) = i (2 \pi i \xi) \widehat{\Phi}(\xi) = - 2 \pi \xi \widehat{\Phi}(\xi) \]
    %
    The uniqueness theorem for ordinary differential equations says that since
    %
    \[ \widehat{\Phi}(0) = \int_{-\infty}^\infty e^{- \pi x^2} = 1 = \Phi(0) \]
    %
    Thus we must have $\widehat{\Phi} = \Phi$.
\end{example}

\begin{example}
    The Fourier transform of the function $e^{- |x|}$ is the \emph{Poisson kernel}
    %
    \[ P(\xi) = \frac{\Gamma((d+1)/2)}{(\pi(1 + |\xi|^2))^{(d+1)/2}} \]
    %
    Later on we show the corresponding scaled kernel $\{ P_\delta \}$ is an approximation to the identity, and thus $A_\delta f = P_\delta * f$ converges to $f$ in all appropriate senses.

    The Abel kernel $A_\delta$ on $\RR^n$ is obtained from the initial function $A(x) = e^{-2 \pi |x|}$. The calculation of the Fourier transform of this function indicates a useful principle in Fourier analysis: one can reduce expressions involving $e^{-x}$ into expressions involving $\smash{e^{-x^2}}$ using the subordination principle. In particular, for $\beta > 0$ we have the formula
    %
    \[ e^{-\beta} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\beta^2/4u}\; du \]
    %
    We establish this by letting $v = \sqrt{u}$, so
    %
    \[ \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\beta^2/4u}\; du = \frac{2}{\sqrt{\pi}} \int_0^\infty e^{-v^2 - \beta^2/4v^2}\; dv = \frac{2e^{-\beta}}{\sqrt{\pi}} \int_0^\infty e^{-(v - \beta/2v)^2}\; dv \]
    %
    But the map $v \mapsto v - \beta/2v$ is measure preserving by Glasser's master theorem, so this integral is
    %
    \[ \frac{2e^{-\beta}}{\sqrt{\pi}} \int_0^\infty e^{-v^2}\; dv = e^{-\beta} \]
    %Because using the theory of residues,
    %
    %\begin{align*}
    %   e^{-\beta} &= \frac{2}{\pi} \int_0^\infty \frac{\cos \beta x}{1 + x^2} = \frac{1}{\pi} \int_{-\infty}^\infty \frac{e^{\beta i x}}{1 + x^2}\; dx\; du\\
    %   &= \frac{1}{\pi} \int_{-\infty}^\infty e^{\beta i x} \int_0^\infty e^{-u} e^{-ux^2}\; du\; dx\\
    %   &= \frac{1}{\pi} \int_0^\infty e^{-u} \int_{-\infty}^\infty e^{-ux^2} e^{\beta i x}\; dx\; du\\
    %   &= \frac{1}{\pi} \int_0^\infty \sqrt{\pi/u} e^{-u} e^{-\beta^2/4u}\; du
    %\end{align*}
    %
    In tandem with Fubini's theorem, this formula implies
    %
    \begin{align*}
        \widehat{A}(\xi) &= \int e^{-2 \pi |x|} e^{- 2 \pi i \xi \cdot x}\; dx = \int \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{- |\pi x|^2/u} e^{-2 \pi i \xi \cdot x}\; du\; dx\\
        &= \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int e^{-|\pi x|^2/u} e^{-2 \pi i \xi \cdot x}\; dx\; du = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} (\delta_{\sqrt{\pi/u}} \Phi)^\ft(\xi)\; du\\
        &= \frac{1}{\pi^{(n + 1)/2}} \int_0^\infty e^{-u} u^{(n-1)/2} e^{- u|\xi|^2}\; du
    \end{align*}
    %
    Setting $v = (1 + |\xi|^2) u$, we conclude that since by definition,
    %
    \[ \int_0^\infty e^{-v} v^{(n-1)/2} = \Gamma \left( \frac{n+1}{2} \right) \]
    %
    \[ \widehat{A}(\xi) = \frac{\Gamma((n+1)/2)}{[\pi(1 + |\xi|^2)]^{(n+1)/2}} \]
    %
    Thus the Abel mean is the Fourier inverse of the Poisson kernel on the upper half plane $\mathbf{H}^{n+1}$.

    In order to conclude $\{ P_\delta \}$ is a good kernel, it now suffices to verify that
    %
    \[ \int_{\RR^n} \frac{d\xi}{(1 + |\xi|^2)^{(n+1)/2}} = \frac{\pi^{(n+1)/2}}{\Gamma((n+1)/2)} \]
    %
    The right hand side is half the surface area of the unit sphere in $\RR^{n+1}$. Denoting this quantity by $S_n$, and switching to polar coordinates, we find that
    %
    \[ \int_{\RR^n} \frac{d\xi}{(1 + |\xi|^2)^{(n+1)/2}} = S_{n-1} \int_0^\infty \frac{r^{n-1}}{(1 + r^2)^{(n+1)/2}}\; dr \]
    %
    Setting $r = \tan u$, we find
    %
    \[ \int_0^\infty \frac{r^{n-1}}{(1 + r^2)^{(n+1)/2}}\; dr = \int_0^{\pi/2} (\sin u)^{n-1} du \]
    %
    The theorem now follows from noticing that $S_{n-1} (\sin u)^{n-1}$ is the surface area of the $n-1$ sphere obtained by slicing $S^n$ with the hyperplane $x_n = \cos u$. Fubini's theorem implies that the integral is $S_n/2$, which is what we wanted to verify.
\end{example}

\begin{example}
    We note that
    %
    \[ \int_{-R}^R e(- \xi x)\; dx = \frac{e(- \xi R) - e(\xi R)}{-2 \pi i \xi} = \frac{\sin(2 \pi \xi R)}{\pi \xi}. \]
    %
    so the Fourier transform of $\chi_{[-R,R]}$ is the \emph{Dirichlet kernel}
    %
    \[ D_R(\xi) = \frac{\sin(2 \pi \xi R)}{\pi \xi} \]
    %
    We note that $D_R \not \in L^1(\mathbf{R})$. Thus $D_R$ is {\it not} a good kernel, which makes the convergence rates of $S_R f$ more subtle. Nonetheless, $D_R$ does lie in $L^p(\mathbf{R})$ for all $p > 1$, and is \emph{uniformly bounded} in $L^p(\mathbf{R})$ for all $1 < p < \infty$. This is enough to conclude that for all $1 < p < \infty$, $S_R f \to f$ in $L^p(\mathbf{R})$.
\end{example}

Thus we now know there are a large examples of functions $\Phi \in C_0(\RR^d)$ with $\Phi(0) = 1$, and such that for any $x$ in the Lebesgue set of $f$,
%
\[ f(x) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta x). \]
%
If $\widehat{f}$ is integrable, then the bound $| \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta \xi) | \leq \| \Phi \|_\infty | \widehat{f}(\xi) |$ implies that we can use the dominated convergence theorem to conclude that for any point $x$ in the Lebesgue set of $f$,
%
\[ f(x) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta x) = \int \widehat{f}(\xi) e(\xi \cdot x) \]
%
Thus the inversion theorem holds pointwise almost everywhere.

\begin{theorem}
    If $f$ and $\widehat{f}$, then for any $x$ in the Lebesgue set of $f$,
    %
    \[ f(x) = \int \widehat{f}(\xi) e(\xi \cdot x)\; d\xi. \]
\end{theorem}

We define, for any integrable $f: \RR^n \to \RR$, the \emph{inverse} Fourier transform
%
\[ \widecheck{f}(x) = \int f(\xi) e(\xi \cdot x)\; d\xi \]
%
The inverse transform is also denoted by $\mathcal{F}^{-1}(f)$. The last theorem says that $\mathcal{F}^{-1}$ really is the inverse operator to the operator $\mathcal{F}$, at least on the set of functions $f$ where $\widehat{f}$ is integrable. In particular, this is true if $f$ has strong derivatives in the $L^1$ norm for any multi-index $|\alpha| \leq n+1$, and so the Fourier inversion formula holds for sufficiently smooth functions.

\begin{corollary}
    If $f \in C(\RR)$ is integrable and $\widehat{f} \in L^1(\RR)$, $S_R f \to f$  uniformly.
\end{corollary}
\begin{proof}
    Since $f \in C(\RR$
    The dominated convergence theorem implies that for each $x \in\RR$,
    %
    \[ f(x) = \int_{\RR^n} \widehat{f}(\xi) e(\xi \cdot x) = \lim_{R \to \infty} \int_{-R}^R \widehat{f}(\xi) e(\xi \cdot x) = \lim_{R \to \infty} (S_R f)(x). \]
    %
    And
    %
    \[ \int_{|x| \geq R} \widehat{f}(\xi) e(\xi \cdot x) \leq \| \widehat{f} \|_{L^1(\RR)}. \]
    %
    so the pointwise convergence is uniform.
\end{proof}

\begin{remark}
    This theorem also generalizes to $\RR^n$. Here, the operators $S_R$ are no longer canonically defined, but if we consider any increasing nested family of sets $B_R$ with $\lim B_R = \RR^n$, then the corresponding operators
    %
    \[ S_R f = \int_{B_R} \widehat{f}(\xi) e(\xi \cdot x) \]
    %
    also converge uniformly to $f$.
\end{remark}

\begin{corollary}
    The map $\mathcal{F}: L^1(\RR^d) \to C_0(\RR^d)$ is injective.
\end{corollary}
\begin{proof}
    If $\widehat{f} = 0$, then $\widehat{f}$ is certainly integrable. But this means that the Fourier inversion theorem can apply, giving that for almost every point $x$,
    %
    \[ f(x) = \int_{-\infty}^\infty \widehat{f}(x) e(\xi \cdot x) = 0. \]
    %
    Thus $f = 0$ almost everywhere.
\end{proof}

This corollary is underestimated in utility. Even if the Fourier inversion theorem doesn't hold, we can still view the Fourier transform as another way to represent a function, since the Fourier transform does not lose any information. For instance, it can be used very easily to verify identities involving convolutions.

\begin{corollary}
    For any $\delta_1, \delta_2$,
    %
    \[ W_{\delta_1 + \delta_2} = W_{\delta_1} * W_{\delta_2}\quad\text{and}\quad P_{\delta_1 + \delta_2} = P_{\delta_1} * P_{\delta_2}. \]
\end{corollary}
\begin{proof}
    We recall that
    %
    \[ W_{\delta_1 + \delta_2} = \mathcal{F}(e^{-(\delta_1 + \delta_2) |x|^2}). \]
    %
    But $e^{-(\delta_1 + \delta_2) |x|^2} = e^{-\delta_1 |x|^2} e^{-\delta_2 |x|^2}$ breaks into a product, which allows us to calculate
    %
    \[ \mathcal{F}(e^{-\pi \delta_1 |x|^2} e^{-\pi \delta_2 |x|^2}) = \mathcal{F}(e^{-\pi \delta_1 |x|^2}) * \mathcal{F}(e^{-\pi \delta_2 |x|^2}) = W_{\delta_1} * W_{\delta_2}.  \]
    %
    Thus $W_{\delta_1} * W_{\delta_2} = W_{\delta_1 + \delta_2}$. Similarily, $P_{\delta_1 + \delta_2}$ is the Fourier transform of $e^{-(\delta_1 + \delta_2)|x|}$, which breaks into a product, whose individual Fourier transforms are $P_{\delta_1}$ and $P_{\delta_2}$.
\end{proof}

% TODO: Prove using De la Vallee Poisson that if f^(xi) = O(1/|xi|), then S_R f converges uniformly.

%\begin{theorem}
%   If $f$ is an integrable, function continuous at the origin, and $\widehat{f} \geq 0$, then $\widehat{f}$ is integrable.
%\end{theorem}
%\begin{proof}
%   This follows because
    %
%   \[ f(0) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e^{-\delta |x|} \]
    %
%   By Fatou's lemma,
    %
%   \[ f(0) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e^{-\delta |x|} \geq \int \liminf_{\delta \to 0} \widehat{f}(\xi) e^{-\delta |x|} = \int \widehat{f}(\xi) \]
    %
%   so $\widehat{f}$ is finitely integrable.
%\end{proof}

%Note that this implies that we obtain the general inversion theorem, so in particular, it is only continuous functions, and functions almost everywhere equal to continuous functions, which can have non-negative Fourier transforms.

\section{The $L^2$ Theory}

One integral component of Fourier series on $L^2(\mathbf{T})$ is Plancherel's equality
%
\[ \sum |\widehat{f}(n)|^2 = \frac{1}{2\pi} \int_0^{2\pi} |f(x)|^2 \]
%
On $\RR^n$, we would like to justify that
%
\[ \int |\widehat{f}(\xi)|^2\; d\xi = \int |f(x)|^2\; dx \]
%
However, on the non-compact Euclidean space, a general element of $L^2(\RR^n)$ is not necessarily integrable, so we cannot take it's Fourier transform using the integral formula. Nonetheless, we can take the Fourier transform of an element of $L^1(\RR^n) \cap L^2(\RR^n)$, and we find the equation holds.

\begin{theorem}
    If $f \in L^1(\RR^n) \cap L^2(\RR^n)$, then $\| \widehat{f} \|_2 = \| f \|_2$.
\end{theorem}
\begin{proof}
    The theorem is an easy consequence of the multiplication formula, since
    %
    \[ |\widehat{f}(\xi)| = \widehat{f}(\xi) \overline{\widehat{f}}(\xi), \]
    %
    and
    %
    \[ \left( \overline{\widehat{f}} \right)^\ft(\xi) = \overline{(f^\ft)^\ft(-\xi)} = \overline{f(\xi)}. \]
    %
    This implies
    %
    \[ \int |\widehat{f}(\xi)|^2\; d\xi = \int \widehat{f}(\xi) \overline{\widehat{f}(\xi)}\; d\xi = \int f(x) \overline{f(x)}\; dx = \int |f(x)|^2\; dx. \qedhere \]
\end{proof}

A simple interpolation argument leads to the following corollary, which is a variant of the Hausdorff-Young inequality for functions on $\RR^n$.

\begin{corollary} If $f \in L^1(\RR^n) \cap L^p(\RR^n)$ for $1 \leq p \leq 2$, then
    %
    \[ \| \widehat{f} \|_{L^q(\RR^n)} \leq \| f \|_{L^p(\RR^n)}. \]
    %
    where $2 \leq q \leq \infty$ is the conjugate of $p$.
\end{corollary}

Though the integral formula of an element of $L^2(\RR^n)$ does not make sense, the bounds above provide a canonical way to define the Fourier transform of an element of $L^p(\RR^n)$, for $1 \leq p \leq 2$. The space $L^1(\RR^n) \cap L^p(\RR^n)$ is a dense subset of $L^p(\RR^n)$, so we can use the Hahn-Banach theorem to define the Fourier transform $\mathcal{F}: L^p(\RR^n) \to L^q(\RR^n)$ as the {\it unique} bounded operator agreeing with the integral formula on the common domain. The extended Fourier transform on $L^2(\RR^n)$ is still unitary, because the multiplication formula extends to $L^2(\RR^n)$, so that
%
\[ (\mathcal{F}(f),g) = \int \widehat{f}(\xi) \overline{g(\xi)}\; d\xi = \int f(x) \overline{\widehat{g}(-\xi)}\; dx = (f,\mathcal{F}^{-1}(g)). \]
%
Thus the adjoint of $\mathcal{F}$ is $\mathcal{F}^{-1}$, which means exactly that $\mathcal{F}$ is unitary.

\begin{remark}
    Later on, we will justify the definition of the Fourier transform on an element of $L^p(\RR^n)$, for $2 \leq p \leq \infty$, using the theory of distributions.
\end{remark}


\section{The Hausdorff-Young Inequality}

For functions on $\mathbf{T}$, it is unclear how to provide examples which show why the Hausdorff-Young inequality cannot be extended to give results for $p > 2$. Over $\RR$, we can provide examples which explicitly indicate the tightness of the appropriate constants.

\begin{example}
    Given an integrable function $f$, let $f_r(x) = f(rx)$. Then we find $\widehat{f_r}(\xi) = r^{-n} \widehat{f}(\xi/r)$, and so
    %
    \[ \| f_r \|_{L^p(\RR^n)} = r^{-n/p} \| f \|_{L^p(\RR^n)} \quad \text{and} \quad \| \widehat{f_r} \|_{L^q(\RR^n)} = r^{n/q-n} \| \widehat{f} \|_{L^q(\RR^n)}. \]
    %
    In order for a bound to hold in terms of $p$ and $q$ uniformly for all values of $r$, we need $r^{-n/p} = r^{n/q-n}$, which means $1/q + 1/p = 1$, so $p$ and $q$ must be conjugates of one another.
\end{example}

\begin{example}
    Consider the family of functions $f_s(x) = s^{-n/2} e^{- \pi |x|^2/s}$, where $s = 1 + it$ for some $t \in \RR$. One can easily calcluate that $\widehat{f_s}(\xi) = e^{- \pi s |\xi|^2}$. We calculate
    %
    \[ \| f_s \|_{L^p(\RR^n)} = |s|^{-n/2} \left( \int e^{- (p/|s|^2) \pi |x|^2}\; dx \right)^{1/p} = |s|^{n/p - n/2} p^{-n/p} \]
    %
    whereas $\| \widehat{f_s} \|_q = q^{-n/2}$. Thus to be able  compare the two quantities as $t \to \infty$, we need $n/p - n/2 \leq 0$, so $p \leq 2$. As $t \to \infty$, $\smash{|f_s(x)| \sim t^{-n/2} e^{-\pi |x/t|^2}}$, so the $t$ gives us a decay in $f_s$. However, when we take the Fourier transform the $t$ only corresponds to oscillatory terms. Thus we need $p \leq 2$ so that the decay in $t$ isn't too important in relation to the overall width of the function.
\end{example}

The Hausdorff-Young inequality shows that the Fourier transforms narrowly supported functions into a function with small magnitude. But the example above shows that the Fourier transform is not so good at transforming functions with small magnitude into functions which are narrowly supported, because the Fourier transform can absorb the small magnitude into an oscillatory property not reflected in the norms. Some kind of way of measuring oscillation needs to be considered to get a tighter control on the function. Of course, in hindsight, we should have never expected too much control of the Fourier transform in terms of the $L^p$ norms, since the Fourier transform measures the oscillatory nature of the input function, and oscillatory properties of a function in phase space are not very well reflected in the $L^p$ norms, except when applying certain orthogonality properties with an $L^2$ norm, or destroying the oscillation with an $L^\infty$ norm.

\section{The Poisson Summation Formula}

\section{The Gibbs Phenomenon}

\section{Sums of Random Variables}

We now switch to an application of harmonic analysis to studying sums of random variables probability theory. If $X$ is a random vector, it's probabilistic information is given by it's distribution on $\RR^n$, which can be seen as a measure $\mathbf{P}_X$ on $\RR^n$, with $\mathbf{P}_X(E) = \mathbf{P}(X \in E)$. Given two independant random vectors $X$ and $Y$, $\mathbf{P}_{X+Y}$ is the convolution $\mathbf{P}_X * \mathbf{P}_Y$ between the measures $\mathbf{P}_X$ and $\mathbf{P}_Y$, in the sense that
%
\[ \mathbf{P}_{X+Y}(E) = \int \chi_E(x+y)\; d\mathbf{P}_X(x)\; d\mathbf{P}_Y(y) \]
%
If $d\mathbf{P}_X = f_X \cdot dx$ and $d\mathbf{P}_Y = f_Y \cdot dx$, then $d(\mathbf{P}_X * \mathbf{P}_Y) = (f_X * f_Y) \cdot dx$ is just the normal convolution of functions. This is why harmonic analysis becomes so useful when analyzing sums of independant random variables.

It is useful to express the Fourier transform in a probabilistic language. Given a random variable $X$,
%
\[ \widehat{\mathbf{P}_X}(\xi) = \int e^{i \xi \cdot x} d\mathbf{P}_X(x) \]
%
Thus the natural Fourier transform of a random vector $X$ is the {\bf characteristic function} $\varphi_X(\xi) = \mathbf{E}(e^{i \xi \cdot X})$. It is a continuous function for any random variable $X$. We can also express the properties of the Fourier transform in a probabilistic language.

\begin{lemma}
    Let $X$ and $Y$ be independant random variables. Then
    %
    \begin{itemize}
        \item $\varphi_X(0) = 1$, and $|\varphi_X(\xi)| \leq 1$ for all $\xi$.

        \item (Symmetry) $\varphi_X(\xi) = \overline{\varphi_X(-\xi)}$.

        \item (Convolution) $\varphi_{X+Y} = \varphi_X \varphi_Y$.

        \item (Translation and Dilation) $\varphi_{X+a}(\xi) = e^{i a \cdot \xi} \varphi_X(\xi)$, and $\varphi_{\lambda X}(\xi) = \varphi_X(\lambda \xi)$.

        \item (Rotations) If $R \in O(n)$ is a rotation, then $\varphi_{R(X)}(\xi) = \varphi_X(R(X))$.
    \end{itemize}
\end{lemma}

Using the Fourier inversion formula, if $\varphi_X$ is integrable, then $X$ is a continuous random variable, with density
%
\[ f(x) = \int e^{- i \xi x} \varphi_X(\xi)\; d\xi \]
%
In particular, if $\varphi_X = \varphi_Y$, then $X$ and $Y$ are identically distributed. This already gives interesting results.

\begin{theorem}
    If $X$ and $Y$ are independant normal distributions, then $aX + bY$ is normally distributed.
\end{theorem}
\begin{proof}
    Since $\varphi_{aX+bY}(\xi) = \varphi_X(a \xi) \varphi_Y(b \xi)$, it suffices to show that the product of two such characteristic functions is the characteristic function of a normal distribution. If $X$ has mean $\mu$ and covariance matrix $\Sigma$, then $X \cdot \xi$ has mean $\mu \cdot \xi$ and variance $\xi^T \Sigma \xi$, and one calculates that $\mathbf{E}[e^{i \xi \cdot X}] = e^{- i \mu \cdot \xi - \xi^T \Sigma \xi / 2}$ using similar techniques to the Fourier transform of a Gaussian. One verifies that the class of functions of the form $e^{-i \mu \cdot \xi - \xi^T \Sigma \xi / 2}$ is certainly closed under multiplication and scaling, which completes the proof. 
\end{proof}

Now we can prove the celebrated central limit theorem. Note that if

\begin{theorem}
    Let $X_1, \dots, X_N$ be independant and identically distributed with mean zero and variance $\sigma^2$. If $S_N = X_1 + \dots + X_N$, then
    %
    \[ \mathbf{P}(S_N \leq \sigma \sqrt{N} t) \to \Phi(t) = \frac{1}{\sqrt{2x}} \int_{-\infty}^t e^{-y^2/2}\; dy \]
\end{theorem}
\begin{proof}
    We calculate that
    %
    \[ \varphi_{S_N/\sigma \sqrt{N}}(\xi) = \varphi_X(\xi/\sigma \sqrt{N})^N \]
    %
    Define $R_n(x) = e^{ix} - 1 - (ix) - (ix)^2/2 - \dots - (ix)^n/n!$. Then because of oscillation and the fundamental theorem of calculus,
    %
    \[ |R_0(x)| = \left| i \int_0^x e^{iy}\; dy \right| \leq \min(2,|x|) \]
    %
    Next, since $R_{n+1}'(x) = i R_n$,
    %
    \[ R_{n+1}(x) = i  \int_0^x R_n(y)\; dy \]
    %
    This gives that $|R_n(x)| \leq \min(2|x|^n/n!,|x|^{n+1}/(n+1)!)$. In particular, we conclude
    %
    \[ |\varphi_X(\xi) - 1 - \sigma^2 \xi^2/2| = |\mathbf{E}(R_2(\xi X))| \leq \mathbf{E}|R_2(\xi X)| \leq |\xi|^2 \mathbf{E} \left( \min \left( |X|^2, |\xi X|^3/6 \right) \right) \]
    %
    By the dominated convergence theorem, as $\xi \to 0$, $\varphi_X(\xi) = 1 - \xi^2 \sigma^2/2 + o(\xi^2)$. But this means that
    %
    \[ \varphi_{S_N/\sigma \sqrt{N}}(\xi) = (1 - \xi^2 / 2 N + o(\xi^2/\sigma^2 N))^N = \exp(-\xi^2/2) \]
    %
    This implies the random variables converge weakly to a normal distribution.
\end{proof}

\section{Transforms of Holomorphic Functions}

An interesting thing about the Fourier transform on the real line is that we can apply both real-variable techniques and complex analytic techniques to the study. Just as smoothness of a function corresponded to polynomial decay in it's Fourier transform, we will find that analyticity corresponds to an exponential decay. We let $S_a = \{ z \in \mathbf{C}: |\text{Im}(z)| < a \}$ denote the horizontal strip.

\begin{theorem}
    Let $f$ be holomorphic on $S_a$, integrable on each horizontal line contained in the strip, and such that $f(z) \to 0$ as $|\text{Re}(z)| \to \infty$. Then we find $|\widehat{f}(\xi)| \lesssim_b e^{-2\pi b |\xi|}$ for any $b < a$.
\end{theorem}
\begin{proof}
    For any $b < a$, $R$, and $\xi > 0$, consider the contour $\gamma_R$ obtained from the rectangle $-R$, $R$, $-R-ib$, and $R-ib$. As $R \to \infty$, the integral along the vertical lines of the rectangle tends to zero as $R \to \infty$, so we conclude that
    %
    \begin{align*}
        \int_{-\infty}^\infty f(x)e^{-2\pi i x \xi}\; dx &= \int_{-\infty}^\infty f(x-ib)e^{- 2 \pi i (x - ib) \xi}\; dx\\
        &= e^{-2 \pi i b \xi} \int_{-\infty}^\infty f(x-ib) e^{- 2 \pi i \xi x}\; dx = e^{-2 \pi i b \xi} \widehat{f_b}(\xi)
    \end{align*}
    %
    where $f_b(x) = f(x - ib)$. Thus it suffices to show $|\widehat{f_b}(\xi) - \widehat{f}(\xi)| \lesssim_b 1$. But this follows because we certainly have $\| f_b - f \|_\infty < \infty$ since both functions are bounded, which completes the proof in this case. A similar estimate for $\xi < 0$ also gives the general result.
\end{proof}

It follows that $\widehat{f}$ has exponential decay if $f$ satisfies the hypothesis of the theorem. Thus we can always apply the inverse Fourier transform to conclude
%
\[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e(\xi x)\; d\xi \]
%
In this case, we can actually {\it prove} the equation using complex analysis. 

\begin{theorem}
    A
\end{theorem}
\begin{proof}
    As in the last theorem, the sign of $\xi$ matters. We write
    %
    \[ \int_{-\infty}^\infty \widehat{f}(\xi) e^{2} \]
\end{proof}

\section{Characteristic Functions}




\chapter{Finite Character Theory}

Let us review our achievements so far. We have found several important families of functions on the spaces we have studied, and shown they can be used to approximate arbitrary functions. On the circle group $\mathbf{T}$, the functions take the form of the power maps $\phi_n: z \mapsto z^n$, for $n \in \mathbf{Z}$. The important properties of these functions is that
%
\begin{itemize}
    \item The functions are orthogonal to one another.
    \item A large family of functions can be approximated by linear combinations of the power maps.
    \item The power maps are multiplicative: $\phi_n(zw) = \phi_n(z) \phi_n(w)$.
\end{itemize}
%
The existence of a family with these properties is not dependant on much more than the symmetry properties of $\mathbf{T}$, and we can therefore generalize the properties of the fourier series to a large number of groups. In this chapter, we consider a generalization to any finite abelian group.

The last property of the power maps should be immediately recognizable to any student of group theory. It implies the exponentials are homomorphisms from the circle group to itself. This is the easiest of the three properties to generalize to arbitrary groups; we shall call a homomorphism from a finite abelian group to $\mathbf{T}$ a {\bf character}. For any abelian group $G$, we can put all characters together to form the character group $\Gamma(G)$, which forms an abelian group under pointwise multiplication $(fg)(z) = f(z)g(z)$. It is these functions which are `primitive' in synthesizing functions defined on the group.

\begin{example}
    If $\mu_N$ is the set of $N$th roots of unity, then $\Gamma(\mu_N)$ consists of the power maps $\phi_n: z \mapsto z^n$, for $n \in \mathbf{Z}$. Because
    %
    \[ \phi(\omega)^N = \phi(\omega^N) = \phi(1) = 1 \]
    %
    we see that any character on $\mu_N$ is really a homomorphism from $\mu_N$ to $\mu_N$. Since the homomorphisms on $\mu_N$ are determined by their action on this primitive root, there can only be at most $N$ characters on $\mu_N$, since there are only $N$ elements in $\mu_N$. Our derivation then shows us that the $\phi_N$ enumerate all such characters, which completes our proof. Note that since $\phi_n \phi_m = \phi_{n+m}$, and $\phi_n = \phi_m$ if and only if $n - m$ is divisible by $N$, this also shows that $\Gamma(\mu_N) \cong \mu_N$.
\end{example}

\begin{example}
    The group $\mathbf{Z}_N$ is isomorphic to $\mu_N$ under the identification $n \mapsto \omega^n$, where $\omega$ is a primitive root of unity. This means that we do not need to distinguish functions `defined in terms of $n$' and `defined in terms of $\omega$', assuming the correspondance $n = \omega^n$. This is exactly the same as the correspondence between functions on $\mathbf{T}$ and periodic functions on $\RR$. The characters of $\mathbf{Z}_n$ are then exactly the maps $n \mapsto \omega^{kn}$. This follows from the general fact that if $f: G \to H$ is an isomorphism of abelian groups, the map $f^*: \phi \mapsto \phi \circ f$ is an isomorphism from $\Gamma(H)$ to $\Gamma(G)$.
\end{example}

\begin{example}
    If $K$ is a finite field, then the set $K^*$ of non-zero elements is a group under multiplication. A rather sneaky algebraic proof shows the existence of elements of $K$, known as primitive elements, which generate the multiplicative group of all numbers. Thus $K$ is cyclic, and therefore isomorphic to $\mu_N$, where $N = |K| - 1$. The characters of $K$ are then easily found under the correspondence.
\end{example}

\begin{example}
    For a fixed $N$, the set of invertible elements of $\mathbf{Z}_N$ form a group under multiplication, denoted $\mathbf{Z}_N^*$. Any character from $\mathbf{Z}_N^*$ is valued on the $\varphi(N)$'th roots of unity, because the order of each element in $\mathbf{Z}_N^*$ divides $\varphi(N)$. The groups are in general non-cyclic. For instance, $\mathbf{Z}_8^* \cong \mathbf{Z}_2^3$. However, we can always break down a finite abelian group into cyclic subgroups to calculate the character group; a simple argument shows that $\Gamma(G \times H) \cong \Gamma(G) \times \Gamma(H)$, where we identify $(f,g)$ with the map $(x,y) \mapsto f(x)g(y)$.
\end{example}

\section{Fourier Analysis on Cyclic Groups}

We shall start our study of abstract Fourier analysis by looking at Fourier analysis on $\mu_N$. Geometrically, these points uniformly distribute themselves over $\mathbf{T}$, and therefore $\mu_N$ provides a good finite approximation to $\mathbf{T}$. Functions from $\mu_N$ to $\mathbf{C}$ are really just functions from $[n] = \{ 1, \dots, n \}$ to $\mathbf{C}$, and since $\mu_N$ is isomorphic to $\mathbf{Z}_N$, we're really computing the Fourier analysis of finite domain functions, in a way which encodes the translational symmetry of the function relative to translational shifts on $\mathbf{Z}_N$.

There is a trick which we can use to obtain quick results about Fourier analysis on $\mu_N$. Given a function $f: [N] \to \mathbf{C}$, consider the $N$-periodic function on the real line defined by
%
\[ g(t) = \sum_{n = 1}^N f(n) \chi_{(n-1/2,n+1/2)}(t) \]
%
Classical Fourier analysis of $g$ tells us that we can expand $g$ as an infinite series in the functions $e(n/N)$, which may be summed up over equivalence classes modulo $N$ to give a finite expansion of the function $f$. Thus we conclude that every function $f: [N] \to \mathbf{C}$ has an expansion
%
\[ f(n) = \sum_{m = 1}^N \widehat{f}(m) e(nm) \]
%
where $\widehat{f}(m)$ are the coefficients of the {\bf finite Fourier transform} of $f$. This method certainly works in this case, but does not generalize to understand the expansion of general finite abelian groups.

The correct generalization of Fourier analysis is to analyze the set of complex valued `square integrable functions' on the domain $[N]$. We consider the space $V$ of all maps $f: [N] \to \mathbf{C}$, which can be made into an inner product space by defining
%
\[ \langle f, g \rangle = \frac{1}{N} \sum_{n = 1}^N f(n) \overline{g(n)} \]
%
We claim that the characters $\phi_n: z \mapsto z^n$ are orthonormal in this space, since
%
\[ \langle \phi_n, \phi_m \rangle = \frac{1}{N} \sum_{k = 1}^N \omega^{k(n-m)} \]
%
If $n = m$, we may sum up to find $\langle \phi_n, \phi_m \rangle = 1$. Otherwise we use a standard summation formula to find
%
\[ \sum_{k = 1}^N \omega^{k(n-m)} = \omega^{n-m} \frac{\omega^{N(n-m)} - 1}{\omega^{n-m} -1} \]
%
Since $\omega^{N(n-m)} = 1$, we conclude the sum is zero. This implies that the $\phi_n$ are orthonormal, hence linearly independent. Since $V$ is $N$ dimensional, this implies that the family of characters forms an orthogonal basic for the space. Thus, for any function $f: [N] \to \mathbf{C}$, we have, if we set $\widehat{f}(m) = \langle f, \phi_m \rangle$, then
%
\[ f(n) = \sum_{m = 1}^N \langle f, \phi_m \rangle \phi_m(n) = \sum_{m = 1}^N \widehat{f}(m) e(mn/N) \]
%
This calculation can essentially be applied to an arbitrary finite abelian group to obtain an expansion in terms of Fourier coefficients.

\section{An Arbitrary Finite Abelian Group}

It should be easy to guess how we proceed for a general finite abelian group. Given some group $G$, we study the character group $\Gamma(G)$, and how $\Gamma(G)$ represents general functions from $G$ to $\mathbf{C}$. We shall let $V$ be the space of all such functions from $G$ to $\mathbf{C}$, and on it we define the inner product
%
\[ \langle f, g \rangle = \frac{1}{|G|} \sum_{a \in G} f(a) \overline{g(a)} \]
%
If there's any justice in the world, these characters would also form an orthonormal basis.

\begin{theorem}
    The set $\Gamma(G)$ of characters is an orthonormal set.
\end{theorem}
\begin{proof}
    If $e$ is a character of $G$, then $|e(a)| = 1$ for each $a$, and so
    %
    \[ \langle e, e \rangle = \frac{1}{|G|} \sum_{a \in G} |e(a)| = 1 \]
    %
    If $e \neq 1$ is a non-trivial character, then $\sum_{a \in G} e(a) = 0$. To see this, note that for any $b \in G$, the map $a \mapsto ba$ is a bijection of $G$, and so
    %
    \[ e(b) \sum_{a \in G} e(a) = \sum_{a \in G} e(ba) = \sum_{a \in G} e(a) \]
    %
    Implying either $e(b) = 1$, or $\sum_{a \in G} e(a) = 0$. If $e_1 \neq e_2$ are two characters, then
    %
    \[ \langle e_1, e_2 \rangle = \frac{1}{|G|} \sum_{a \in G} \frac{e_1(a)}{e_2(a)} = 0 \]
    %
    since $e_1/e_2$ is a nontrivial character.
\end{proof}

Because elements of $\Gamma(G)$ are orthonormal, they are linearly independent over the space of functions on $G$, and we obtain a bound $|\Gamma(G)| \leq |G|$. All that remains is to show equality. This can be shown very simply by applying the structure theorem for finite abelian groups. First, note it is true for all cyclic groups. Second, note that if it is true for two groups $G$ and $H$, it is true for $G \times H$, because
%
\[ \Gamma(G \times H) \cong \Gamma(G) \times \Gamma(H) \]
%
since a finite abelian group is a finite product of cyclic groups, this proves the theorem. This seems almost like sweeping the algebra of the situation under the rug, however, so we will prove the statement only using elementary linear algebra. What's more, these linear algebraic techniques generalize to the theory of unitary representations in harmonic analysis over infinite groups.

\begin{theorem}
    Let $\{ T_1, \dots, T_n \}$ be a family of commuting unitary matrices. Then there is a basis $v_1, \dots, v_m \in \mathbf{C}^m$ which are eigenvectors for each $T_i$.
\end{theorem}
\begin{proof}
    For $n = 1$, the theorem is the standard spectral theorem. For induction, suppose that the $T_1, \dots, T_{k-1}$ are simultaneously diagonalizable. Write
    %
    \[ \mathbf{C}^m = V_{\lambda_1} \oplus \dots \oplus V_{\lambda_l} \]
    %
    where $\lambda_i$ are the eigenvalues of $T_k$, and $V_{\lambda_i}$ are the corresponding eigenspaces. Then if $v \in V_{\lambda_i}$, and $j < k$,
    %
    \[ T_k T_j v = T_j T_k v = \lambda_i T_j v \]
    %
    so $T_j(V_{\lambda_i}) = V_{\lambda_i}$. Now on each $V_{\lambda_i}$, we may apply the induction hypotheis to diagonalize the $T_1, \dots, T_{k-1}$. Putting this together, we simultaneously diagonalize $T_1, \dots, T_k$.
\end{proof}

This theorem enables us to prove the character theory in a much simpler manner. Let $V$ be the space of complex valued functions on $G$, and define, for $a \in G$, the map $(T_a f)(b) = f(ab)$. $V$ has an orthonormal basic consisting of the $\chi_a(b) = N [a = b]$, for $a \in G$. In this basis, we comcpute $T_a \chi_b = \chi_{ba^{-1}}$, hence $T_a$ is a permutation matrix with respect to this basis, hence unitary. The operators $T_a$ commute, since $T_aT_b = T_{ab} = T_{ba} = T_b T_a$. Hence these operators can be simultaneously diagonalized. That is, there is a family $e_1, \dots, e_n \in V$ and $\lambda_{an} \in \mathbf{T}$ such that for each $a \in G$, $T_a e_n = \lambda_{an} f_n$. We may assume $e_n(1) = 1$ for each $n$ by normalizing. Then, for any $a \in G$, we have $f_n(a) = f_n(a \cdot 1) = \lambda_{an} f_n(1) = \lambda_{an}$, so for any $b \in G$, $f_n(ab) = \lambda_{an} f_n(b) = f_n(a) f_n(b)$. This shows each $f_n$ is a character, completing the proof. We summarize our discussion in the following theorem.

\begin{theorem}
    Let $G$ be a finite abelian group. Then $\Gamma(G) \cong G$, and forms an orthonormal basis for the space of complex valued functions on $G$. For any function $f: G \to \mathbf{C}$,
    %
    \[ f(a) = \sum_{e \in \Gamma(G)} \langle f, e \rangle\ e(a) = \sum_{e \in \Gamma(G)} \hat{f}(e) e(a)\ \ \ \ \ \langle f, g \rangle = \frac{1}{|G|} \sum_{a \in G} f(a) \overline{g(a)} \]
    %
    In this context, we also have Parseval's theorem
    %
    \[ \| f(a) \|^2 = \sum_{e \in \hat{G}} |\widehat{f}(e)|^2\ \ \ \ \ \langle f, g \rangle = \sum_{e \in \hat{G}} \widehat{f}(e) \overline{\widehat{g}(e)} \]
\end{theorem}

\section{Convolutions}

There is a version of convolutions for finite functions, which is analogous to the convolutions on $\RR$. Given two functions $f,g$ on $G$, we define a function $f * g$ on $G$ by setting
%
\[ (f * g)(a) = \frac{1}{|G|} \sum_{b \in G} f(b) g(b^{-1} a) \]
%
The mapping $b \mapsto ab^{-1}$ is a bijection of $G$, and so we also have
%
\[ (f * g)(a) = \frac{1}{|G|} \sum_{b \in G} f(ab^{-1}) g(b) = (g * f)(a) \]
%
For $e \in \Gamma(G)$,
%
\begin{align*}
    \widehat{f * g}(e) &= \frac{1}{|G|} \sum_{a \in G} (f*g)(a) \overline{e(a)}\\
    &= \frac{1}{|G|^2} \sum_{a,b \in G} f(ab) g(b^{-1}) \overline{e(a)}
\end{align*}
%
The bijection $a \mapsto ab^{-1}$ shows that
%
\begin{align*}
    \widehat{f*g}(e) &= \frac{1}{|G|^2} \sum_{a,b} f(a) g(b^{-1}) \overline{e(a)} \overline{e(b^{-1})}\\
    &= \frac{1}{|G|} \left( \sum_a f(a) \overline{e(a)} \right) \frac{1}{|G|} \left( \sum_b g(b) \overline{e(b)} \right)\\
    &= \widehat{f}(e) \widehat{g}(e)
\end{align*}
%
In the finite case we do not need approximations to the identity, for we have an identity for convolution. Define $D: G \to \mathbf{C}$ by
%
\[ D(a) = \sum_{e \in \Gamma(G)} e(a) \]
%
We claim that $D(a) = |G|$ if $a = 1$, and $D(a) = 0$ otherwise. Note that since $|G| = |\Gamma(G)|$, the character space of $\Gamma(G)$ is isomorphic to $G$. Indeed, for each $a \in G$, we have the maps $\widehat{a}: e \mapsto e(a)$, which is a character of $\Gamma(G)$. Suppose $e(a) = 1$ for all characters $e$. Then $e(a) = e(1)$ for all characters $e$, and for any function $f: G \to \mathbf{C}$, we have $f(a) = f(1)$, implying $a = 1$. Thus we obtain $|G|$ distinct maps $\widehat{a}$, which therefore form the space of all characters. It therefore follows from a previous argument that if $a \neq 1$, then
%
\[ \sum_{e \in \Gamma(G)} e(a) = 0 \]
%
Now $f * D = f$, because
%
\[ \widehat{D}(e) = \frac{1}{|G|} \sum_{a \in G} D(a) \overline{e(a)} = \overline{e}(1) = 1 \]
%
$D$ is essentially the finite dimensional version of the Dirac delta function, since it has unit mass, and acts as the identity in convolution.

\section{The Fast Fourier Transform}

The main use of the fourier series on $\mu_n$ in applied mathematics is to approximate the Fourier transform on $\mathbf{T}$, where we need to compute integrals explicitly. If we have a function $f \in L^1(\mathbf{T})$, then $f$ may be approximated in $L^1(\mathbf{T})$ by step functions of the form
%
\[ f_n(t) = \sum_{k = 1}^{n} a_k \mathbf{I}(x \in (2 \pi (k-1) / n, 2 \pi k / n)) \]
%
And then $\widehat{f_n} \to \widehat{f}$ uniformly. The Fourier transform of $f_n$ is the same as the Fourier transform of the corresponding function $k \mapsto a_k$ on $\mathbf{Z}_n$, and thus we can approximate the Fourier transform on $\mathbf{T}$ by a discrete computation on $\mathbf{Z}_n$. Looking at the formula in the definition of the discrete transform, we find that we can compute the Fourier coefficients of a function $f: \mathbf{Z}_n \to \mathbf{C}$ in $O(n^2)$ addition and multiplication operations. It turns out that there is a much better method of computation which employs a divide and conquer approach, which works when $n$ is a power of 2, reducing the calculation to $O(n \log n)$ multiplications. Before this process was discovered, calculation of Fourier transforms was seen as a computation to avoid wherever possible.

To see this, consider a particular division in the group $\mathbf{Z}_{2n}$. Given $f: \mathbf{Z}_{2n} \to \mathbf{C}$, define two functions $g,h: \mathbf{Z}_n \to \mathbf{C}$, defined by $g(k) = f(2k)$, and $h(k) = f(2k + 1)$. Then $g$ and $h$ encode all the information in $f$, and if $\nu = e(\pi/n)$ is the canonical generator of $\mathbf{Z}_{2n}$, we have
%
\[ \hat{f}(m) = \frac{\hat{g}(m) + \hat{h}(m) \nu^m}{2} \]
%
Because
%
\begin{align*}
    \frac{1}{2n} \sum_{k = 1}^{n} \left( g(k) \omega^{-km} + h(m) \omega^{-km} \nu^m \right) &= \frac{1}{2n} \sum_{k = 1}^n f(2k) \nu^{-2km} + f(2k + 1) \nu^{-(2k+1)m}\\
    &= \frac{1}{2n} \sum_{k = 1}^{2n} f(k) \nu^{-km}
\end{align*}
%
This is essentially a discrete analogue of the Poission summation formula, which we will generalize later when we study the harmonic analysis of abelian groups. If $H(m)$ is the number of operations needed to calculate the Fourier transform of a function on $\mu_{2^n}$ using the above recursive formula, then the above relation tells us $H(2m) = 2H(m) + 3 (2m)$. If $G(n) = H(2^n)$, then $G(n) = 2G(n-1) + 3 2^n$, and $G(0) = 1$, and it follows that
%
\[ G(n) = 2^n + 3 \sum_{k = 1}^n 2^{k} 2^{n-k} = 2^n(1 + 3n) \]
%
Hence for $m = 2^n$, we have $H(m) = m(1 + 3 \log (m)) = O(m \log m)$. Similar techniques show that one can compute the inverse Fourier transform in $O(m \log m)$ operations (essentially by swapping the root $\nu$ with $\nu^{-1}$).

\section{Dirichlet's Theorem}

We now apply the theory of Fourier series on finite abelian groups to prove Dirichlet's theorem.

\begin{theorem}
    If $m$ and $n$ are relatively prime, then the set
    %
    \[ \{ m + kn : k \in \mathbf{N} \} \]
    %
    contains infinitely many prime numbers.
\end{theorem}

An exploration of this requries the Riemann-Zeta function, defined by
%
\[ \zeta(s) = \sum_{n = 1}^\infty \frac{1}{n^s} \]
%
The function is defined on $(1,\infty)$, since for $s > 1$ the map $t \mapsto 1/t^s$ is decreasing, and so
%
\[ \sum_{n = 1}^\infty \frac{1}{n^s} \leq 1 + \int_{1}^\infty \frac{1}{t^s} = 1 + \lim_{n \to \infty} \frac{1}{s-1} \left[1 - 1/n^{s-1} \right] = 1 + \frac{1}{s-1} \]
%
The series converges uniformly on $[1+\varepsilon, N]$ for any $\varepsilon > 0$, so $\zeta$ is continuous on $(1,\infty)$. As $t \to 1$, $\zeta(t) \to \infty$, because $n^s \to n$ for each $n$, and if for a fixed $M$ we make $s$ close enough to $1$ such that $|n/n^s - 1|<  1/2$ for $1 \leq n \leq M$, then
%
\[ \sum_{n = 1}^\infty \frac{1}{n^s} \geq \sum_{n = 1}^M \frac{1}{n^s} = \sum_{n = 1}^M \frac{1}{n} \frac{n}{n^s} \geq \frac{1}{2} \sum_{n = 1}^M \frac{1}{n} \]
%
Letting $M \to \infty$, we obtain that $\sum_{n = 1}^\infty \frac{1}{n^s} \to \infty$ as $s \to 1$.

The Riemann-Zeta function is very good at giving us information about the prime integers, because it encodes much of the information about the prime numbers.

\begin{theorem}
    For any $s > 1$,
    %
    \[ \zeta(s) = \prod_{p\ \text{prime}} \frac{1}{1 - p^s} \]
\end{theorem}
\begin{proof}
    The general idea is this -- we may write
    %
    \[ \prod_{p\ \text{prime}} \frac{1}{1 - p^s} = \prod_{p\ \text{prime}} (1 + 1/p^{s} + 1/p^{2s} + \dots) \]
    %
    If we expand this product out formally, enumating the primes to be $p_1, p_2, \dots$, we find
    %
    \[ \prod_{p \leq n} (1 + 1/p^s + 1/p^{2s} + \dots) = \sum_{n_1, n_2, \dots = 0}^\infty \frac{1}{p_1^{n_1}} \]
\end{proof}
















\chapter{Applications}

\section{The Wirtinger Inequality on an Interval}

\begin{theorem}
    Given $f \in C^1[-\pi,\pi]$ with $\int_{-\pi}^\pi f(t) dt = 0$,
    %
    \[ \int_{-\pi}^\pi |f(t)|^2 \leq \int_{-\pi}^\pi |f'(t)|^2 \]
\end{theorem}
\begin{proof}
    Consider the fourier series
    %
    \[ f(t) \sim \sum a_n e_n(t)\ \ \ \ \ f'(t) \sim \sum in a_n e_n(t) \]
    %
    Then $a_0 = 0$, and so
    %
    \[ \int_{-\pi}^\pi |f(t)|^2\ dt = 2 \pi \sum |a_n|^2 \leq 2 \pi \sum n^2 |a_n|^2 = \int_{-\pi}^\pi |f'(t)|^2\ dt \]
    %
    equality holds here if and only if $a_i = 0$ for $i > 1$, in which case we find
    %
    \[ f(t) = A e_n(t) + \overline{A} e_n(-t) = B \cos(t) + C \sin(t) \]
    %
    for some constants $A \in \mathbf{C}$, $B,C \in \RR$.
\end{proof}

\begin{corollary}
    Given $f \in C^1[a,b]$ with $\int_a^b f(t)\ dt = 0$,
    %
    \[ \int_a^b |f(t)|^2 dt \leq \left(\frac{b-a}{\pi}\right)^2 \int_a^b |f'(t)|^2\ dt \]
\end{corollary}

\section{Energy Preservation in the String equation}

Solutions to the string equation are

If $u(t,x)$

\section{Harmonic Functions} 

The study of a function $f$ defined on the real line can often be understood by extending it's definition holomorphically to the complex plane. Here we will extend this tool, establishing that a large family of functions $f$ defined on $\RR^n$ can be understood by looking at a {\it harmonic} function on the upper half plane $\mathbf{H}^{n+1}$, which approximates $f$ at it's boundary. This is a form of the Dirichlet problem, which asks, given a domain and a function on the domain's boundary, to find a function harmonic on the interior of the domain which `agrees' with the function on the boundary, in one of several senses. As we saw in our study of harmonic functions on the disk in the study of Fourier series, we can study such harmonic functions by convolving $f$ with an appropriate approximation to the identity which makes the function harmonic in the plane. In this case, we shall use the Poisson kernel for the upper half plane.

\begin{theorem}
    If $f \in L^p(\RR^n)$, for $1 \leq p \leq \infty$, and $u(x,y) = (f * P_y)(x)$, where
    %
    \[ P_y(x) = \frac{\Gamma((n+1)/2)}{\pi^{(n+1)/2}} \frac{1}{(1 + |x|^2)^{(n+1)/2}} \]
    %
    then $u$ is harmonic in the upper half plane, $u(x,y) \to f(x)$ for almost every $x$, and $u(\cdot,y)$ converges to $f$ in $L^p$ as $y \to 0$, with $\| u(\cdot,y) \|_{L^p(\RR^n)} \leq \| f \|_{L^p(\RR^n)}$. If, instead, $f$ is a continuous and bounded function, then $u(\cdot,y)$ converges to $f$ locally uniformly as $y \to 0$.
\end{theorem}
\begin{proof}
    The almost everywhere convergence and convergence in norm follow from the fact that $P_y$ is an approximation to the identity. The fact that $u$ is harmonic follows because
    %
    \[ u_{xx}(x,y) = (f * P_y'')(x)\ \ \ \ \ u_{yy} = (f * ) \]
\end{proof}














