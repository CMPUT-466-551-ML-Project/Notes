\documentclass{article}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{amssymb}
\usepackage{mathabx}
\usepackage{accents}
%\usepackage[margin=0.7in]{geometry}
\usepackage[english]{babel}
\usepackage{blindtext}

\theoremstyle{plain}
\newtheorem{lemma}{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem*{example}{Example}
\newtheorem*{fact}{Fact}
\newtheorem{corollary}{Corollary}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem*{remark}{Remark}

\def\changemargin#1#2{\list{}{\rightmargin#2\leftmargin#1}\item[]}
\let\endchangemargin=\endlist 

\DeclareMathOperator{\codim}{codim}
\DeclareMathOperator{\lhdim}{\underline{\dim}_{\mathbf{M}}}

\title{Fractals Avoiding Fractal Sets}

\author{Jacob Denson\\ \and Malabika Pramanik\\ \and Josh Zahl}

\begin{document}

\maketitle

%\begin{multicols}{2}

%\begin{abstract}
%	\blindtext[1]
%\end{abstract}

% Ergodic Theoretic Connections: Furstenberg Katznelson and Weiss. Ziegler sets of positive density.

Ramsey theory is built on the principle that large structures contain certain configurations. It is interesting to apply the principle in the continuum setting, to compare and contrast the resultant phenomena. For instance, we might believe that suitably large subsets of the plane contain the vertices of an isoceles triangles. And Lebesgue's density theorem shows this for any set of positive measure. A finer tuned notion of size than area is given by the Hausdorff dimension of a set. So we can make things much more difficult by asking how large the Hausdorff dimension of a set must be to guarantee isoceles triangles, and more generally, other point configurations.

One difficulty in avoiding isoceles triangles is that they occur in arbitrarily small sets of space. This paper quantifies how the relative `sparsity' of a general point configuration obstructs one from guaranteeing high Hausdorff dimension sets from possessing a copy of that point configuration. More precisely, we construct high dimensional sets avoiding sparse configurations.

An interesting perspective is obtained by viewing an $n$ point configuration in $\mathbf{R}^d$ as a subset of $(\mathbf{R}^d)^n$. As an example, the isoceles triangle configuration in the plane can be modelled as the set $\{ (x,y,z) \in (\mathbf{R}^2)^3 : d(x,y) = d(x,z) \}$, where we ignore degenerate configurations with two or more points are equal. Viewing a configuration as a geometric set is a useful perspective to have, because geometric properties of the configuration are often used to construct avoiding sets. In this case, we use the fractal dimension of the configuration.

\begin{theorem}
	Let $Z \subset (\mathbf{R}^d)^n$ be an $n$ point configuration formed from a countable union of compact sets, each with lower Minkowski dimension upper bounded by $\alpha$. Then there exists a set $X \subset [0,1]^d$ with
	%
	\[ \dim_{\mathbf{H}}(X) = \min \left( \frac{nd - \alpha}{n-1}, d \right) \]
	%
	such that if $x_1, \dots, x_n$ are distinct points in $X$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

There are already general pattern avoidance methods in the literature. We compare our method to them in section 6. But these rely on the non-singular nature of the configurations. The novel feature of our method is that by looking at configurations in the geometric way introduced above, and identifying the fractal dimension as a useful quantity in the avoidance problem, we can consider configurations which have an {\it arbitrary} fractal quality to them. Meanwhile, the Hausdorff dimension of $X$ is still comparable to the more restricted techniques.

A key idea to our method is the geometric perspective for pattern avoidance problems, we just introduced. We believe trying to characterize solution sets in terms of the geometric properties of the configuration set is a useful perspective to making further progress in the field. The second idea is that when it comes to avoiding sparse configurations, the best strategy is a random mass assignment. This is applied to a discretized version of the problem, described in section 2, and then applied successively at many scales in the remainder of the argument to obtain the result.

%\section{A Fractal Avoidance Framework}

%One way to think about generic pattern avoidance methods is to specify the pattern as the zero set of a function. For example,
%
%\begin{itemize}
%	\item A set $X \subset \mathbf{R}$ contains no three term arithmetic progressions if and only if for any distinct $x,y,z \in X$,
	%
%	\[ f(x,y,z) = x + z - 2y \neq 0  \]
	%
%	This function vanishes if and only if there exists $b$ and $t$ such that $x = b$, $y = b+t$, and $z = b+2t$.

%	\item A set $X \subset \mathbf{R}^d$ contains the vertices of no isosceles triangles if and only if for any three distinct $x,y,z \in X$,
	%
%	\[ f(x,y,z) = d(x,y) - d(y,z) \neq 0 \]
	%
%	If $f(x,y,z) = 0$, then the line segments $xy$ and $zy$ form the legs of the isoceles triangle.
	%The problem of avoiding this function is similar to the last example, since isosceles triangles are planar variants of three term arithmetic progressions.

%	\item A set $X \subset \mathbf{R}^d$ does not contain a family of angles $\{ \alpha \}$ if and only if for any distinct $x,y,z \in X$, and $\alpha$,
	%
%	\[ f(x,y,z) = \frac{(x - z) \cdot (y - z)}{|x - z||y - z|} \neq \cos(\alpha) \]
	%
%	where the cosine formula for the dot product is used.

%	\item A set $X \subset \mathbf{R}^d$ does not contain $d+1$ points in a lower dimensional hyperplane if and only if for any distinct $x_0, \dots, x_d \in X$,
	%
%	\[ f(x_0, \dots, x_d) = \det(x_1 - x_0, \dots, x_d - x_0) \neq 0 \]
	%
%	If $\det(x_1 - x_0, \dots, x_d - x_0) = 0$, the vectors $x_1 - x_0, \dots, x_d - x_0$ are not linearly independant, and thus span a plane of dimension smaller than $d$.
%\end{itemize}
%
%This method of description is summarized by a general framework.

%\begin{changemargin}{0.5em}{0em}
%{\bf The Configuration Avoidance Problem:} Given a function $f: (\mathbf{R}^d)^n \to \mathbf{R}$, find $X \subset \mathbf{R}^d$ such that for any {\it distinct} $x_1, \dots, x_n \in X$, $f(x_1, \dots, x_n) \neq 0$, with as high a Hausdorff dimension as possible.
%\end{changemargin}

%The functional framework is common in the literature. For instance, it is the viewpoint behind the methods of \cite{MalabikaRob} and \cite{Mathe}, who give results assuming various regularity conditions on the function $f$. Here, we take the perspective that $f$ gives extraneous information irrelevant to the problem at hand. It's real importance is suggesting geometric properties of the zero set $Z$. Once $Z$ is taken as the primary object to study, the configuration avoidance problem becomes equivalent to another framework. It is the viewpoint of this paper that this framework is more flexible to work with, and thinking in terms of this framework leads to new general avoidance methods.

%\begin{changemargin}{0.5em}{0em}
%	{\bf The Fractal Avoidance Problem:} Given $Z \subset (\mathbf{R}^d)^n$, find $X \subset \mathbf{R}^d$ such that if $x_1, \dots, x_n \in X$ are {\it distinct}, $(x_1, \dots, x_n) \not \in Z$, with as high a Hausdorff dimension as possible.
%\end{changemargin}

%As is suggested by the fact that only the Cartesian product of distinct values of $x_1, \dots, x_n \in X$ are required to avoid $Z$, the diagonal set $\Delta$ of points $(x_1, \dots, x_n) \in (\mathbf{R}^d)^n$ such that $x_i = x_j$ for some $i \neq j$ plays a crucial role in the problem. If a point in $\Delta$ has a neighbourhood not intersecting $Z$, then by placing $X^n$ in this neighbourhood we find a full dimensional solution to the fractal avoidance problem. So in order for the problem to be nontrivial, $Z$ must be dense in a neighbourhood of $\Delta$. The structure of $Z$ around $\Delta$ therefore plays a major part in finding solutions to the fractal avoidance problem.

%We are free to pick any subset of $X$ we want. Because Hausdorff dimension is a local property of the set, we can always assume $X$ lies in a bounded region of space. Once this region is fixed, only a bounded portion of $Z$ could ever intersect $X^n$, allowing us to use compactness arguments. This is necessary to our method, and because of this, we work with a local version of the fractal avoidance framework, to which the general fractal avoidance problem can always be reduced by fixing a region, and changing coordinates.

%\begin{changemargin}{0.5em}{0em}
%	{\bf The Local Fractal Avoidance Problem:} Given $Z \subset ([0,1]^d)^n$, find $X \subset [0,1]^d$ such that if $x_1, \dots, x_n \in X$ are {\it distinct}, $(x_1, \dots, x_n) \not \in Z$.
%\end{changemargin}

%Since we are the first to introduce the fractal avoidance problem, a natural goal is to solve the general problem with minimal assumptions on $Z$. Here the only restriction we place on $Z$ is it's fractal dimension. Here we use the {\it lower Minkowski dimension} of a compact set $E$, defined as
%
%\[ \lhdim(E) = \liminf_{L \to 0} \frac{\log |\mathcal{B}(E,L)|}{\log(1/L)} \]
%
%Thus there is $L_k \to 0$ with $|\mathcal{B}(E,L_k)| = (1/L_k)^{\lhdim(E) + o(1)}$

%\begin{theorem}
%	If $Z$ is the countable union of sets with lower Minkowski dimension upper bounded by $\alpha$, with $\alpha \geq d$, then there is $X$ solving the local fractal avoidance problem for $Z$ with
	%
%	\[ \dim_{\mathbf{H}}(X) = \frac{dn - \alpha}{n - 1} = \frac{\codim_{\mathbf{H}}(Z)}{n - 1} \]
	%
	%See section 2 for a precise definition of lower Minkowski dimension we use.
%	One can view $dn - \alpha$ as the fractal codimension of $Z$ in $(\mathbf{R}^d)^n$.
%\end{theorem}

%\begin{remark}
%	If $Z$ is the union of sets with dimension $\alpha < d$, the set obtained from $[0,1]^d$ by removing the projections of $Z$ onto each coordinate has full Hausdorff dimension and trivially solves the local fractal avoidance problem. Thus we need not consider these parameters in our theorem.
%\end{remark}

%The aim of the theorem is to explore a general method for solving configuration avoidance problems. For particular configurations, it is highly likely that additional geometric features can be exploited to obtain avoiding sets with a much larger Hausdorff dimension. But our goal is not to find tight results for particular configurations. Instead, we want to show how much a single geometric feature of the configuration, in this case a bound on the dimension of the set $Z$, can be exploited. Other general results focus on other geometric features of the problem. For instance, the method of \cite{Mathe} explores what happens when $Z$ is a low dimensional algebraic variety. As more and more methods are revealed which exploit various features of the problem, we will be able to obtain tight results for particular configurations with ease, by synthesizing various approaches which exploit the most important geometric features of the configuration.

\section{Nonstandard Notation and Terminology}

\begin{itemize}
	\item For a length $L$, $\mathcal{B}(L,d)$ denotes the partition of $\mathbf{R}^d$ into the family of all half open cubes of sidelength $L$, with corners on the lattice $(L \cdot \mathbf{Z})^d$, i.e.
	%
	\[ \mathcal{B}(L,d) = \{ [a_1,a_1 + L) \times \dots \times [a_d, a_d + L) : a_i \in L \cdot \mathbf{Z} \} \]
	%
	If the dimension $d$ is clear, or it's emphasis is unnecessary, we abbreviate $\mathcal{B}(L,d)$ as $\mathcal{B}(L)$.

	\item By a {\it $\mathcal{B}(L)$ cube}, we mean an element of $\mathcal{B}(L)$, and by a {\it $\mathcal{B}(L)$ set}, we mean a union of $\mathcal{B}(L)$ cubes.

	\item If $E \subset \mathbf{R}^d$, then $\mathcal{B}(E,L)$ is the family of $\mathcal{B}(L)$ cubes intersecting $E$, i.e.
	%
	\[\mathcal{B}(E,L) = \{ I \in \mathcal{B}(L): I \cap E \neq \emptyset \} \]
	%
	For instance, $\mathcal{B}(\mathbf{R}^d,L) = \mathcal{B}(L,d)$.

	\item The {\it lower Minkowski dimension} of a compact set $E$ is
	%
	\[ \lhdim(E) = \liminf_{L \to 0} \frac{\log |\mathcal{B}(E,L)|}{\log(1/L)} \]
	%
	Thus there is $L_k \to 0$ with $|\mathcal{B}(E,L_k)| = (1/L_k)^{\lhdim(E) + o(1)}$

	\item Adopting the terminology of \cite{KatzTao}, we say a collection of sets $U_1, U_2, \dots$ is a {\it strong cover} of some set $E$ if $E \subset \limsup U_k$, which means every element of $E$ is contained in infinitely many of the sets $U_k$.

	\item Given a cube $I \in \mathcal{B}(L, dn)$, there are unique cubes $I_1, \dots, I_n \in \mathcal{B}(L,d)$ such that $I = I_1 \times \dots \times I_n$. We say $I$ is {\it non diagonal} if the intervals $I_1, \dots, I_n$ are pairwise distinct.
\end{itemize}

\section{Avoidance at Discrete Scales}

We avoid $Z$ by considering an infinite sequence of scales. At each scale, we solve a discretized version of the problem, and combining these solutions gives a real solution to the fractal avoidance problem. This section describes the discretized avoidance technique. It forms the {\it core} of our construction.

Let us formulate the discretized problem we aim to solve. Fix two dyadic sidelengths $L > S$. The fractal set $Z$ is then replaced by a union of cubes $K$ with sidelength $S$. Our goal is to take a set $E$, which is a union of cubes with coarse sidelength $L$ cubes, and carve out a union of sidelength $S$ cubes $F$ such that $F^n$ is disjoint from the non-diagonal cubes of $K$.

In order to ensure the Hausdorff dimension calculations for $X$ go through smoothly, it is crucial in the discrete setting that the mass of $F$ is spread uniformly over $E$. We can achieve this by trying to include a equal portion of mass in each sidelength $R$ subcube of $E$, for some intermediary scale $L > R > S$. The next lemma shows this is almost possible.

\begin{lemma}
	Fix three dyadic lengths $L > R > S$. Let $E$ be a $\mathcal{B}(L)$ set in $\mathbf{R}^d$, and $K$ a $\mathcal{B}(S)$ set in $(\mathbf{R}^d)^n$. Then there exists a $\mathcal{B}(S)$ set $F \subset E$ containing a single $\mathcal{B}(S)$ subcube from all but at most $|\mathcal{B}(K,S)| (S/R)^{dn}$ of the cubes in $\mathcal{B}(E,R)$, and for any distinct $I_1, \dots, I_n \in \mathcal{B}(F,S)$, $I_1 \times \dots \times I_n \not \in \mathcal{B}(K,S)$.
\end{lemma}
\begin{proof}
	Form a random $\mathcal{B}(S)$ set $U \subset E$ by selecting, from each $\mathcal{B}(R)$ subcube of $E$, a single $\mathcal{B}(S)$ subcube and adding it to $U$. Thus the probability that any element in $\mathcal{B}(E,S)$ is added to $U$ is $(S/R)^d$. Since any two $\mathcal{B}(S)$ subcubes of $U$ lie in distinct elements of $\mathcal{B}(R)$, the only chance that a {\it non-diagonal} $\mathcal{B}(S)$ subcube $I$ of $K$ is a subset of $U^n$ is if $I_1, \dots, I_n$ all lie in separate cubes in $\mathcal{B}(R)$. Then they each have an independant chance of being added to $U$, and so
	%
	\begin{align*}
		\mathbf{P}(I \subset U^n) &= \mathbf{P}(I_1 \subset U) \dots \mathbf{P}(I_n \subset U) = (S/R)^{dn}
	\end{align*}
	%
	If $M$ denotes the number of $\mathcal{B}(S)$ subcubes $I$ of $K$ contained in $U^n$, then
	%
	\begin{align*}
		\mathbf{E}(M) &= \sum_{\substack{I \in \mathcal{B}(K,S)}} \mathbf{P}(I \subset U^n) = |\mathcal{B}(K,S)| (S/R)^{dn}
	\end{align*}
	%
	In particular, this means that out of all possible random choices of $U$, there is at least one {\it particular}, nonrandom $U_0$ for which the corresponding $M_0$ satisfies $M_0 \leq \mathbf{E}(M) = |\mathcal{B}(K,S)| (S/R)^{dn}$. If, for each $\mathcal{B}(S)$ subcube $I$ of $K$ contained in $U_0^n$, we remove $I_1$ from $U_0$, we obtain a set $F$ with $I_1 \times \dots \times I_n$ disjoint from $K$ for any distinct $I_1, \dots, I_n \in \mathcal{B}(F,S)$. The set $F$ contains a cube from all but $M_0$ sidelength $R$ cubes, which means $F$ satisfies the requirements of the theorem.
\end{proof}

\begin{remark}
	As mentioned, this discrete lemma is the core of our avoidance technique. The remaining argument is fairly modular, and can be applied with any other discrete avoidance technique to yield a solution to the fractal avoidance problem (Indeed, it is adapted from the dimension calculations of \cite{MalabikaRob}). In particular, if the geometry of $Z$ yields properties about it's discretization strong enough that one can obtain an argument like the lemma above but discarding fewer intervals, then one can likely apply the remaining parts of our paper near unmodified to yield a set $X$ with a larger Hausdorff dimension.
\end{remark}

Because the choice of $F$ is uniform over $E$, in our construction we can allow the gap between $L$ and $R$ to be arbitrarily large. However, the gap between $R$ and $S$ can only be `polynomially large', i.e. we can only have $R = S^\lambda$ for some fixed $\lambda \in (0,1)$. The size of $\lambda$ is directly related to the Hausdorff dimension of the set $X$ we construct (the larger the better!). If the set we are trying to avoid has fractal dimension $\alpha$, we will be able to obtain a bound $|\mathcal{B}(Z,S)| \leq S^{-\gamma}$ for some $\gamma$ converging to $\alpha$ in the limit. In the next corollary, we calculate precisely how large we can let $\lambda$ be given this bound on the number of cubes we have to avoid, so that we include a $\mathcal{B}(S)$ cube in $F$ for more than half of the $\mathcal{B}(R)$ cubes.

\begin{corollary}
	Consider the last lemma's setup, in addition to three additional parameters $\lambda \in (0,1)$, $\gamma \in (d,dn)$, and $A > 0$. Suppose $R$ is the closest dyadic number to $S^\lambda$, $|E| \leq 1/2$, and $|\mathcal{B}(K,S)| \leq S^{-\gamma}$ for some $\gamma \geq d$. If
	%
	\[ 0 < \lambda \leq \frac{dn - \gamma}{d(n-1)} - O \left( A \log_S |E| \right) \]
	%
	then $E$ contains a $\mathcal{B}(S)$ cube from all but a fraction $1/2^A$ of the cubes in $\mathcal{B}(E,R)$.
\end{corollary}
\begin{proof}
	The inequality for $\lambda$ implies
	%
	\begin{align*}
		dn - \gamma - \lambda d(n-1) &\geq O \left( \log_S |E| \right)% + \log_{L_{N+1}}(O(A))
	\end{align*}
	%
	Since $R$ is within a factor of two from $S^\lambda$, we compute
	%
	\begin{align*}
		&\frac{|\{ I \in \mathcal{B}(E,R): \mathcal{B}(I,S) \cap \mathcal{B}(F,S) = \emptyset \}|}{|\mathcal{B}(E,R)|}\\
		&\ \ \ \ \ \leq \frac{|\mathcal{B}(K,S)| (S/R)^{dn}}{|E|R^{-d}} \leq |E|^{-1} S^{dn - \gamma} R^{-d(n-1)}\\
		&\ \ \ \ \ \leq |E|^{-1} S^{dn - \gamma} (S/2)^{- \lambda d(n-1)} \leq 2^{\lambda d (n-1)}|E|^{-1} S^{O(A \log_S|E|)}\\
		&\ \ \ \ \ = 2^{\lambda d} |E|^{O(1) - 1} \leq 2^{\lambda d + 1 - O(A)} \leq 1/2^A
	\end{align*}
	%
	The last inequality was obtained by picking the $O(A) \geq 2d A$, which is equivalent to making the $O(A \log_S |E|)$ term in the statement of the corollary on the order of $2d A \log_S |E|$.
\end{proof}

\section{Fractal Discretization}

Now we apply the discrete technique we just described to obtain an actual fractal avoidance set. We consider a decreasing sequence of dyadic scales $L_k$. The fact that $Z$ is the countable union of sets with Minkowski dimension $\alpha$ implies that we can find an efficient {\it strong cover} of $Z$ by cubes restricted to lie at the dyadic scales $L_k$.

\begin{lemma}
	Let $Z$ be a countable union of sets, each with lower Minkowski dimension at most $\alpha$, and consider any positive sequence $\varepsilon_k$ converging to zero. Then there is a decreasing sequence of lengths $L_1, L_2, \dots$, and $\mathcal{B}(L_k)$ sets $Z_k$ such that $Z$ is strongly covered by the sets $Z_k$ and $|\mathcal{B}(Z_k, L_k)| \leq 1/L_k^{\alpha + \varepsilon_k}$.
\end{lemma}
\begin{proof}
	Let $Z$ be the union of sets $Y_i$ with $\lhdim(Y_i) \leq \alpha$ for each $i$. Consider any sequence $m_1, m_2, \dots$ of integers which repeats each integer infinitely often. If, at the $k$th step of the argument, we find a $\mathcal{B}(L_k)$ set $Z_k$ covering $Y_{m_k}$, then we will have found a strong cover for $Z$. Doing this is quite simple. Since $\lhdim(Y_{m_k}) \leq \alpha$, there are arbitrarily small lengths $L$ such that $|\mathcal{B}(Y_{m_k},L)| \leq 1/L^{\alpha + \varepsilon_k}$. In particular, we may fix such a length $L$ smaller than the choices of $L_1, \dots, L_{k-1}$. This length will then be our point $L_k$, and the union of the cubes in $\mathcal{B}(Y_{m_k},L)$ will form $Z_k$.
\end{proof}

\begin{remark}
	In the proof, we are free to make $L_k$ arbitrarily small in relation to the previous parameters $L_1, \dots, L_{k-1}$ we have chosen. For instance, later on when calculating the Hausdorff dimension, we will assume that $L_{k+1} \leq L_k^{k^2}$, and the argument above can be easily modified to incorporate this inequality.
\end{remark}

We can now construct $X$ by avoiding the various discretizations of $Z$ at each scale. The aim is to find a nested family of discretized sets $X_0 \supset X_1 \supset X_2 \supset \dots$ with $X = \lim X_k$. One condition that guarantees that $X$ solves the fractal avoidance problem is that $X_k^n$ is disjoint from {\it non diagonal} cubes in $Z_k$.

\begin{lemma}
	If for each $k$, $X_k^n$ avoids non-diagonal cubes in $Z_k$, then $X$ solves the fractal avoidance problem for $Z$.
\end{lemma}
\begin{proof}
	Let $z \in Z$ be given with $z_1, \dots, z_n$ are distinct. Set
	%
	\[ \Delta = \{ w \in (\mathbf{R}^d)^n : \text{there exists}\ i,j\ \text{such that}\ w_i = w_j \} \]
	%
	Then $d(\Delta,z) > 0$. The point $z$ is covered by cubes in infinitely many of collections $Z_{k_m}$. For suitably large $N$, the cube $I$ in $\mathcal{B}(L_{k_N})$ containing $z$ is disjoint from $\Delta$. But this means that $I$ is non diagonal, and so $z \not \in X_N^d$. In particular, $z$ is not an element of $X^n$.
\end{proof}

It is now simple to see how we must work at the discrete scales. First, we see $X_0 = [0,1/2]^d$, so that $|X_0| \leq 1/2$. To obtain $X_{k+1}$ from $X_k$, we apply the discrete argument. We set $E = X_k$ and $W = Z_{k+1}$, with scales $L = L_k$ and $S = L_{k+1}$. We know that we can choose $\gamma = \alpha + \varepsilon_k$, and also pick $R = R_{k+1}$ the closest dyadic number to $L_{k+1}^\lambda$, where
%
\[ \lambda = \beta_{k+1} = \frac{dn - \alpha}{d(n-1)} - \frac{\varepsilon_{k+1}}{d(n-1)} - O(k \log_{L_{k+1}} |X_k|) \]
%
The discrete lemma then constructs a set $F$ with $F^n$ avoiding non diagonal cubes in $Z_{k+1}$, and containing a $\mathcal{B}(L_{k+1})$ subcube from all but a fraction $1/2^{2k + d+2}$ of the $\mathcal{B}(R_{k+1})$ cubes in $I$. We set $X_{k+1} = F$. Repeatedly doing this builds an infinite sequence of the $X_k$. Since $X_k^n$ avoids $Z_k$, $X$ is a solution to the fractal avoidance problem. It now remains to calculate the Hausdorff dimension of $X$.

%\section{Construction of Avoiding Set}

%To construct a set $X$ solving the fractal avoidance problem, we fix a decreasing series of dyadic scales $L_1, L_2, \dots$, which enable us to discretize the problem. We will specify the exact values of these scales later. The fact that $Z$ has Minkowski dimension $\alpha$ implies that we can find a strong cover of $Z$ by sets of the appropriate size.

%Given this setup, we construct a decreasing nested family of discretized sets $X_N$, with $X = \lim X_N$. One condition that guarantees that $X$ solves the fractal avoidance problem is that $X_N^n$ is disjoint from {\it non diagonal} cubes in $Z_N$. By a non-diagonal cube, we mean a cube $I \subset \mathcal{B}(L_N,dn)$ such that the projections $I_i \in \mathcal{B}(L_N,d)$ onto the $d$ dimensional coordinate axis of $(\mathbf{R}^d)^n$ are distinct.

%As an initial set, for lack of an interesting choice, we let $X_0 = [0,1]^d$. Given $X_{N-1}$, we define $X_N$ recursively. To do this, we apply the discrete corollary of the last section. The parameters we use are $I = X_{N-1}$, $K = Z_N$, $L = L_{N-1}$, $S = L_N$, and $R$ the closest dyadic number to $L_N^{\beta_N}$, which from now on we denote by $R_N$. The exponent $\beta_N$ is defined as
%
%\[ \frac{dn - \alpha - \varepsilon_N - \log_{L_N} |X_{N-1}| - \log_{L_N}(O(1/2^{2N+2}))}{(n-1)d} \]
%
%For suitably small choices of $L_N$ relative to $|X_{N-1}|$, $0 < \beta_N < 1$. Furthermore, Thus the discrete corollary we described in the last section constructs a set $J$ avoiding nondiagonal cubes in $\mathcal{Z}_N$, and containing a sidelength $L_N$ portion from all but a fraction $1/2^{2N+2}$ of the $\mathcal{B}(R_N)$ cubes in $X_N$. Naturally, we set $X_N = J$. The resulting $X = \lim X_N$ is therefore a solution to the fractal avoidance problem.

\section{Dimension Bounds}

We now show that the set $X$ has the expected Hausdorff dimension we need. At the discrete scale $L_k$, $X$ looks like a $d \beta_k$ dimensional set. If the lengths $L_k$ rapidly converge to zero, then we can ensure $\beta_k \to \beta$, where
%
\[ \beta = \frac{dn - \alpha}{d(n - 1)} \]
%
Then, in the limit $X$ looks $d \beta$ dimensional on the discrete scales, which is the Hausdorff dimension we want. It then suffices to interpolate this result to get a $d\beta$ dimensional behaviour at all intermediary scales. We won't be penalized here by making the gaps between discrete scales too large, because the uniform way that we have selected cubes in consecutive scales implies that between the scales $L_k$ and $L_{k+1}^\beta$, $X$ behaves like a full dimensional set. The remainder of this section fills in the details to this argument.

\begin{lemma}
	$\beta_k \to \beta$.
\end{lemma}
\begin{proof}
	It suffices to show that the error terms in $\beta_k$ become neglible over time, i.e. we must show
	%
	\[ \frac{\varepsilon_{k+1}}{d(n-1)} + O(k \log_{L_{k+1}} |X_k|) = o(1) \]
	%
	Since $\varepsilon_{k+1} \to 0$, the term corresponding to it converges to zero for free. On the other hand, we need the lengths to tend to zero rapidly to make the other error term decay to zero. Since $L_{k+1} \leq L_k^{k^2}$, we find
	%
	\[ k \log_{L_{k+1}} |X_k| \leq \frac{k \log L_k}{\log L_{k+1}} \leq \frac{k \log L_k}{k^2 \log L_k} = \frac{1}{k} \]
	%
	Thus both error terms tend to zero.
\end{proof}

The most convenient way to look at the dimension of $X$ at various scales is to use Frostman's lemma. To understand the behaviour of $X$, we construct a non-zero measure $\mu$ supported on $X$ such that for all $\varepsilon > 0$, for all lengths $L$, and for all $I \in \mathcal{B}(L)$, $\mu(I) \leq L^{d\beta - \varepsilon}$. We can then understand the behaviour of $X$ at the scale $L$ by looking at $\mu$'s behaviour when restricted to cubes at the particular scale, i.e. cubes in $\mathcal{B}(L)$.

To construct a measure $\mu$ naturally reflecting the dimension of $X$, we rely on a variant of the mass distribution principle. This means we take a sequence of measures $\mu_k$, supported on $X_k$, and then take a weak limit to form a measure $\mu$. We initialize this construction by setting $\mu_0$ to be the uniform measure on $X_0 = [0,1/2]^d$. We then define $\mu_{k+1}$, supported on $X_{k+1}$, by modifying the distribution of $\mu_k$. First, we throw away the mass of the $\mathcal{B}(L_k)$ cubes $I$ for which over half of the $\mathcal{B}(I,R_{k+1})$ cubes fail to contain a part of $X_{k+1}$. For the cubes $I$ for which more than half of the cubes $\mathcal{B}(I,R_{k+1})$ contain a part of $X_{k+1}$, we distribute the mass of $\mu_k(I)$ uniformly over the subcubes of $I$ in $X_{k+1}$. This gives a mass function $\mu_{k+1}$. It is easy to see from the cumulative distribution functions of the $\mu_k$ that these measures converge to a function $\mu$ such that for any $I \in \mathcal{B}(L_k)$, $\mu(I) \leq \mu_k(I)$, which is useful for passing from bounds on the discrete measures to bounds on the final measure.

\begin{lemma}
	If $I \in \mathcal{B}(L_k)$, then
	%
	\[ \mu(I) \leq \mu_k(I) \leq 2^{d + k} \left[ \frac{R_k R_{k-1} \dots R_1}{L_{k-1} \dots L_1} \right]^d \]
\end{lemma}
\begin{proof}
	Consider $I \in \mathcal{B}(L_{k+1})$, $J \in \mathcal{B}(L_k)$. If $\mu_k(I) > 0$, this means that $J$ contains a $\mathcal{B}(L_k)$ cube in at least half of the $\mathcal{B}(R_N)$ cubes it contains. Thus the mass of $J$ distributes itself evenly over at least $2^{-1} (L_{k-1}/R_k)^d$ cubes, which gives that $\mu_k(I) \leq 2(R_k/L_k)^d \mu_{k-1}(J)$. But then expanding this recursive inequality, we obtain exactly the result we need.
\end{proof}

\begin{corollary}
	The measure $\mu$ is positive.
\end{corollary}
\begin{proof}
	To prove this result, it suffices to show that the total mass of $\mu_k$ is bounded below, independantly of $k$. At each stage $k$, $X_k$ consists of at most
	%
	\[ \left[ \frac{L_{k-1} \dots L_1}{R_k \dots R_1} \right]^d \]
	%
	$\mathcal{B}(L_k)$ cubes. Since only a fraction $1/2^{2k+d+2}$ of the $\mathcal{B}(R_k)$ cubes do not contain an interval in $X_{k+1}$, it is only for at most a fraction $1/2^{2k+d+1}$ of the $\mathcal{B}(L_k)$ cubes that $X_{k+1}$ fails to contain a $\mathcal{B}(L_{k+1})$ cube from more than half of the $\mathcal{B}(R_{k+1})$ cubes. But this means that we discard a total mass of at most
	%
	\[ \left( \frac{1}{2^{2k + d + 1}} \left[ \frac{L_{k-1} \dots L_1}{R_k \dots R_1} \right]^d \right) \left( 2^{d+k} \left[ \frac{R_k \dots R_1}{L_{k-1} \dots L_1} \right]^d \right) \leq 1/2^{k+1} \]
	%
	Thus
	%
	\[ \mu_k(\mathbf{R}^d) \geq 1 - \sum_{i = 0}^k \frac{1}{2^{i+1}} \geq 1/2 \]
	%
	This implies $\mu(\mathbf{R}^d) \geq 1/2$, and in particular, $\mu \neq 0$.
\end{proof}

Ignoring all parameters in the inequality for $I$ which depend on indices $< k$, we `conclude' that $\mu_k(I) \lesssim R_k^d \lesssim L_k^{\beta_k d}$. The fact that $L_{k+1} \leq L_k^{k^2}$ has such a rapid decay essentially enables us to ignore quantities depending on previous indices, and obtain a true inequality.

\begin{corollary}
	For all $I \in \mathcal{B}(L_k)$, $\mu(I) \leq \mu_k(I) \lesssim L_k^{d \beta_k - k^{-1/2}}$.
\end{corollary}
\begin{proof}
	Given $\varepsilon$, we find
	%
	\begin{align*}
		\mu_k(I) &\leq 2^{d + k} \left[ \frac{R_k \dots R_1}{L_{k-1} \dots L_1} \right]^d \leq \left( \frac{2^{2d + k}}{L_{k-1}^{d(1 - \beta_{k-1})} \dots L_1^{d(1 - \beta_1)}} \right) L_k^{d \beta_k}\\
		&\leq \left( 2^{2d + k} L_k^\varepsilon / L_{k-1}^{d(k-1)} \right) L_k^{d \beta_k - \varepsilon} \leq \left( 2^{2d + k} L_{k-1}^{\varepsilon k^2 - d(k - 1)} \right) L_k^{d \beta_k - \varepsilon}
	\end{align*}
	%
	The open bracket term converges to zero so fast that it still tends to zero if $\varepsilon$ is not fixed, but is instead equal to $k^{-1/2}$, giving the required inequality.
\end{proof}

%It is intuitive that the mass on $\mu$ will distribute more thinly at each stage the fatter the cubes we keep on each iteration of the discrete scale argument. Quantifying this leads directly to our result. We will prove that for each length $L$ interval $I$, $\mu(I) \lesssim_N L^{\beta_N}$. Thus Frostman's lemma guarantees that $\dim_{\mathbf{H}}(X) \geq \beta_N$, and taking $\beta_N \to \beta$ will complete the proof.

%We now rely on a covering argument to show $X$ looks $d \beta$ dimensional at all the intermediary scales. Here we won't be penalized by the fact that the $L_k$ rapidly tend to zero, because the uniformity property implies $X$ looks {\it full} dimensional between the scales $L_k$ and $R_{k+1}$. We fix an increasing sequence $\beta_k'$ with $\beta_k' < \beta_k$, and $\beta_k' \to \beta$ as $k \to \infty$. This gives us slightly more room to bound mass when obtaining the Frostman's lemma result. We set $\beta_k' - \beta_k = 1/k$ to obtain the choice of $L_N$ given as an example.

%\begin{corollary}
%	If $L_k \ll 1$, $\mu(I) \leq L_k^{d \beta_k'}$ for $I \in \mathcal{B}(L_k)$.
%\end{corollary}
%\begin{proof}
%	We can rewrite the inequality in the last problem as
	%
%	\[ \mu(I) \leq \left[ 2^k \left( \frac{R_{k-1} \dots R_1}{L_{k-1} \dots L_1} \right)^d R_k^d L_k^{- d \beta_k'} \right] L_k^{d\beta_k'} \]
	%
%	Now $R_k^d L_k^{-d\beta_k'} \leq (2L_k^{\beta_k})^d L_k^{-d\beta_k'} \leq 2^d L_k^{d(\beta_k - \beta_k')}$, which tends to zero as $L_k \to \infty$, while the remaining parameters are fixed. Thus if $L_k$ is sufficiently small, we can bound the constant in the square brackets by $1$, which is sufficient to obtain the inequality.
%\end{proof}

This is close to the cleanest expression of the $d \beta$ dimensional behaviour at discrete scales. To get a general inequality of this form, we use the fact that our construction distributes uniformly across all intervals.

\begin{theorem}
	If $L \leq L_k$ is dyadic and $I \in \mathcal{B}(L)$, then $\mu(I) \lesssim L^{d\beta_k - k^{-1/2}}$.
\end{theorem}
\begin{proof}
	We break our analysis into three cases, depending on the size of $L$ in proportion to $L_k$ and $R_k$:
	%
	\begin{itemize}
		\item If $R_{k+1} \leq L \leq L_k$, we can cover $I$ by $(L/R_{k+1})^d$ cubes in $\mathcal{B}(R_{k+1})$. For each of these cubes, because the mass is uniformly distributed over $R_{k+1}$ cubes, we know the mass is bounded by at most $2(R_{k+1}/L_{k+1})^d$ times the mass of a $\mathcal{B}(L_k)$ cube. Thus
		%
		\begin{align*}
			\mu(I) &\lesssim [(L/R_{k+1})^d] [2(R_{k+1}/L_k)^d] [L_k^{d \beta_k - k^{-1/2}}]\\
			&\leq 2 L^d / L_k^{d + k^{-1/2} - d \beta_k} \leq 2 L^{d \beta_k - k^{-1/2}}
		\end{align*}

		\item If $L_{k+1} \leq L \leq R_{k+1}$, we can cover $I$ by a single cube in $\mathcal{B}(R_{k+1})$. Each cube in $\mathcal{B}(R_{k+1},d)$ contains at most one cube in $\mathcal{B}(L_{k+1},d)$ which is also contained in $X_{k+1}$, so
		%
		\[ \mu(I) \lesssim L_{k+1}^{d\beta_{k+1} - (k+1)^{-1/2}} \leq L^{d \beta_k - k^{-1/2}} \]

		\item If $L \leq L_{k+1}$, there certainly exists $M$ such that $L_{M+1} \leq L \leq L_M$, and one of the previous cases yields that
		%
		\[ \mu(I) \lesssim 2 L^{d \beta_M - M^{-1/2}} \leq 2 L^{d \beta_k - k^{-1/2}} \]
	\end{itemize}
	%
	The three bulletpoints address all cases considered in the theorem.
\end{proof}

To use Frostman's lemma, we need the result $\mu(I) \lesssim L^{d \beta_k - k^{-1/2}}$ for an {\it arbitrary} interval, not just one with $L \leq L_k$. But this is no trouble; it is only the behavior of the measure on arbitrarily small scales that matters. This is because if $L \geq L_k$, then $\mu(I)/L^{d \beta_k - k^{-1/2}} \leq 1/L_k^{d \beta_k - k^{-1/2}} \lesssim_k 1$, so $\mu(I) \lesssim_k L^{d \beta_k - k^{-1/2}}$ holds automatically for all sufficiently large intervals. Thus we have shown that $\dim_{\mathbf{H}}(X) \geq d \beta_k - k^{-1/2}$, and letting $k \to \infty$ gives $\dim_{\mathbf{H}}(X) \geq d \beta$. It is also easy to see $X$ has {\it precisely} this dimension.

\begin{theorem}
	$\dim_{\mathbf{H}}(X) = (dn - \alpha)/(n-1)$.
\end{theorem}
\begin{proof}
	$X_k$ is covered by at most
	%
	\[ \left[ \frac{L_{k-1} \dots L_1}{R_k \dots R_1} \right]^d \]
	%
	sidelength $L_k$ cubes. It follows that if $\gamma > \beta_k$, then
	%
	\[ H^{d\gamma}_{L_k}(X) \leq \left[ \frac{L_{k-1} \dots L_1}{R_k \dots R_1} L_k^\gamma \right]^d \lesssim \left[ \frac{L_{k-1} \dots L_1}{R_{k-1} \dots R_1} L_k^{\gamma - \beta_k} \right]^d \leq L_k^{d(\gamma - \beta_k)} \]
	%
	Since $L_k \to 0$ as $k \to \infty$, $H^\gamma(X) = 0$. Since $\gamma$ was arbitrary, taking it to $\beta$ allows us to conclude that $\dim_{\mathbf{H}}(X) \leq d \beta$. We have already justified that $\dim_{\mathbf{H}}(X) \geq d\beta$, and so $\dim_{\mathbf{H}}(X) = d \beta$.
\end{proof}

%\section{Low Rank Projection Method}

%We now introduce a method which enables us to find a higher dimensional subset $X$, under some `low rank' assumptions about the set $Z$. The theorem below should be compared to Theorem 3. We will substitute the theorem below in the construction of our solutions to the fractal avoidance problem to improve the Hausdorff dimension.

%\begin{theorem}
%	Let $\mathcal{I}_1, \dots, \mathcal{I}_n$ be disjoint collections of cubes in $\mathcal{B}(1/N,d)$, with $|\mathcal{I}_i| \gtrsim N^d$. If there is a linear transformation $T: \mathbf{R}^{nd} \to \mathbf{R}^{nk}$ with rational coefficients such that the Minkowski dimension of $T(Z)$ is bounded above by $\alpha$, and $\beta$ is a rational parameter such that $\beta > d(k-1)/(dk - \alpha - k)$, then for arbitrarily large $N$ such that $N^\beta$ is an integer, there exists collections of cubes $\mathcal{J}_1, \dots, \mathcal{J}_n \in \mathcal{B}(1/N^\beta,d)$ with each cube in $\mathcal{J}_1 \times \dots \times \mathcal{J}_n \subset \mathcal{B}(1/N^\beta,nd)$ disjoint from $Y$, and as $N \to \infty$, each $\mathcal{J}_i$ contains cubes in all but a fraction $o(1)$ of cubes in $\mathcal{I}_i$.
%\end{theorem}
%\begin{proof}
%	Since for any integer $M$, $M \cdot T(Z)$ has the same Minkowski dimension as $T(Z)$, we may without loss of generality assume by multiplying by a large enough $M$ that $T$ has integer coefficients. Write $T(x) = S(x_1) + U(x_2)$, where $x_1$ is a subset of $kd$ coordinates of $x$, $x_2$ are the remaining $(n-k)d$ coordinates, and $S$ is invertible. Let $\mathcal{J}_{k+1}, \dots, \mathcal{J}_n \subset \mathcal{B}(1/N^\beta,d)$ be the set of cubes contained in a cube in $\mathcal{I}_{k+1}, \dots, \mathcal{I}_n$ and also containing a point in the lattice $(\mathbf{Z}/N)^{d(n-k)}$. We then consider the set $\mathcal{K}$ of cubes in $\mathcal{B}(1/N^\beta,kd)$ intersecting the image of some cube in $U(\mathcal{J}_{k+1}, \dots, \mathcal{J}_n)$. Because $U$ is integral, if $x \in (\mathbf{Z}/N)^{d(n-k)}$, then $U(x) \in (\mathbf{Z}/N)^{dk}$. Since all points in cubes in $\mathcal{J}_{k+1}, \dots, \mathcal{J}_n$ are contained in a $1/N^\beta$ thickening of the lattice $(\mathbf{Z}/N)^{d(n-k)}$, their image under $U$ is contained in a $\lesssim 1/N^\beta$ thickening of the lattice $(\mathbf{Z}/N)^{dk}$. Since the image of the cubes $U(\mathcal{J}_{k+1}, \dots, \mathcal{J}_n)$ is a bounded set, this implies $|\mathcal{K}| \lesssim N^{dk}$. If we let
	%
%	\begin{align*}
%		\mathcal{Z} = &\{ I \in \mathcal{B}(1/N^\beta,dk):\\
%		&\ \ \ \text{there is}\ J \in \mathcal{K}\ \text{s.t.}\ (S(I) + J) \cap T(Z) \neq \emptyset \}
%	\end{align*}
	%
%	and we form a graph $G$ on the side length $1/N^\beta$ cubes in $\mathcal{J}_1, \dots, \mathcal{J}_k$ where there is an edge between $I_1, \dots, I_k$ if their Cartesian product lies in $\mathcal{Z}$, then an independent set $\mathcal{J}_1, \dots, \mathcal{J}_k$ gives a candidate solution $\mathcal{J}_1, \dots, \mathcal{J}_n$ for the entire theorem. Since $T(Z)$ intersects $O(N^{\alpha \beta})$ cubes in $\mathcal{B}(1/N^\beta,dk)$, $|\mathcal{K}| \lesssim N^{dk}$, and $S$ is invertible, $\mathcal{Z}$ contains $O(N^{dk + \alpha \beta})$ cubes. Then $G$ has $\Omega(N^{d \beta})$ vertices, $O(N^{dk + \alpha \beta})$ edges, and if we consider the coloring as in the previous problem, an $\Omega(N^{d(\beta - 1)})$ uniform coloring. Thus when applying the discrete corollary, we have $a = d \beta$, $b = dk + \alpha \beta$, and $c = d(\beta - 1)$. The inequality
	%
%	\[ \beta > d \cdot \frac{2k - 1}{dk - \alpha} \]
	%
%	is equivalent to the equality $b < a + c(k-1)$, which allows us to use the corollary to obtain the required result.
%\end{proof}

%Following our proof constructing $X$, as well as proving it's Hausdorff dimension, but using the lemma above instead of the standard lemma, and replacing the $\beta$ in this proof with the $\beta$ in the lemma above, we obtain $X$ solving the fractal avoidance problem for $Z$ with
%
%\[ \dim_{\mathbf{H}}(X) = \frac{dk - \alpha}{2k - 1} \]
%
%The fact that the dimension is independent of $n$ has some interesting consequences. In particular, it can be used to solve problems involving infinitely many variables.

%\begin{theorem}
%	Let $Z$ be a zero set, and let $f: \mathbf{R}^{nd} \to \mathbf{R}^{kd}$ be a polynomial map with degree at most $m$ such that $f(Z)$ is $\alpha$ dimensional. Then can we improve our result?
%\end{theorem}

\section{Applications}

%\begin{example}
%	Consider $Z = \{ (x,y): \mathbf{R}^{m+1}: y = f(Sx) \}$, where $S: \mathbf{R}^m \to \mathbf{R}^l$. If we consider the map $T(x,y) = (Sx,y)$, then $T(Z) = \{ (a,b) \in \mathbf{R}^{l+1}: b = f(a) \}$. This is a hypersurface of dimension $l$. Applying the result above with $k = l+1$, $d = 1$, and $\alpha = l$, we find a set $X$ with Hausdorff dimension $1/(2l + 1)$. This isn't exactly what we want, so maybe the proof can be fine tuned.
%\end{example}

The most interesting applications of our method occur when the configurations truly are a fractal set. This can be obtained in a natural way by taking classical point configurations, and then smudging the configuration by a fractal set.

\begin{example}
	Let $Y \subset \mathbf{R}^d$ be the countable union of sets with lower Minkowski dimension upper bounded by $\alpha$. Then the set $Y_0 = \{ (x,y): x + y \in Y \}$ is a countable union of sets with lower Minkowski dimension upper bounded by $d + \alpha$. Applying our lemma then gives a set $X$ with Hausdorff dimension $d - \alpha$ such that for any distinct $x_1, x_2 \in X$, $x_1 + x_2 \not \in Y$. If we consider
	%
	\[ Y_1 = \{ (x,y) : x + y \in Y \} \cup \{ (x,y): x \in Y/2 \} \]
	%
	Then $Y_1$ is also the countable union of sets with lower Minkowski dimension bounded by $1 + \alpha$, and the resultant $X$ also avoids $Y/2$, and thus $X + X$ is disjoint from $Y$.
\end{example}

We have ideas on fusing our result with inspiration from the result of \cite{Mathe} to obtain the more impressive result which will show, given a set $Y$ with fractal dimension $\alpha$, how to construct a set $X$, which is a $\mathbf{Q}$ vector space, disjoint from $Y$, with Hausdorff dimension $d - \alpha$. Thus given a $\mathbf{Q}$ subspace $V$ of $\mathbf{R}^d$, we can always find a complementary $\mathbf{Q}$ vector space $W$ with a complementary fractal dimension. The issue here isn't in the rational multiplication, but rather that the dimension in our method decreases as we consider the higher dimension sums $X + X + X$, $X + X + X + X$, and so on.

\begin{example}
	Let 
\end{example}

\section{Relation to Literature, and Future Work}

The technical skeleton of our construction are heavily modelled after $\cite{MalabikaRob}$. Reading this paper in tandem with ours provides an interesting contrast between the techniques of the function oriented configuration avoidance result, and the fractal avoidance result we use. Because of it's heavy influence on our result, we begin our discussion of the literature with an in depth comparison of our method to theirs.

Our result is a direct generalization of the main result of \cite{MalabikaRob}, which says that if $Z \subset (\mathbf{R}^d)^n$ is a smooth surface of dimension $nd - d$, then we can find $X$ with dimension $(n-1)^{-1}$ solving the fractal avoidance problem. Of course, such a $Z$ has Minkowski dimension $nd - d$, and our result achieves the same dimension for $X$. In response to $\cite{MalabikaRob}$, our result says that the only really necessary feature of a smooth hypersurface to the avoidance problem, aside from other geometric features, is it's dimension. Not only is our result more flexible, enabling the surface $Z$ to have non smooth points, but we can also take advantage of the fact that the surface might have dimension different from $nd - d$. Better yet, we can `thicken' or `thin' $Z$ by slightly increasing or decrease the Minkowski dimension, while stably affecting the Hausdorff dimension of the solution $X$ we construct.

The technique leading to this generalization can be compared to a phenomenon that has recently been noticed in the discrete setting, i.e. \cite{BaloghMorrisSamotij}. There, certain combinatorial problems can be rephrased as abstract problems on hypergraphs, and by doing this one can often generalize the solutions of these problems into analogues on `sparse versions' of these hypergraphs. One can see our result as a continuous analogue to this phenomenon, where sparsity is represented by the dimension of the set $Z$ we are trying to avoid. One can even view Lemma 1 as a solution to a problem about independant sets in hypergraphs. In particular, we can form a hypergraph by taking the intervals $\mathcal{B}(F,S)$ as vertices, and adding an edge $(I_1, \dots, I_n)$ between $n$ distinct cubes if $I_1 \times \dots \times I_n$ intersects $W$. Then the union of an independant set of cubes in this graph is precisely a set $F$ with $F^n$ disjoint except on the discretization of the diagonal. And so the goal of Lemma 1 is essentially to find a `uniformly chosen' independant set in this graph. Thus we even applied the discrete phenomenon at many scales to obtain the continuous version of the phenomenon.

A useful technique used in \cite{MalabikaRob}, and it's predecessor \cite{KeletiDimOneSet}, is a Cantor set construction `with memory'; a queue in their construction algorithm allows storage of particular configurations, to be retrieved and avoided at a much, much later step of the building process. The fact that our result is more general, yet we can discard the queueing method from our proof, is an interesting anomoly. Adding memory to the queueing set is certainly an important trick to remember when thinking of new constructions for fractal avoiding sets. It enables one to restrict the requirements of an analogy to Lemma 1 from carving out an avoiding set $F$ from a single set $E$, to carving $F_1, \dots, F_n$ out of disjoint sets $E_1, \dots, E_n$, such that $F_1 \times \dots \times F_n$ avoids $W$. Nonetheless, it makes the construction much more complicated to describe, which makes understanding dimension bounds slightly more complicated, because it's hard to `grasp' precisely what configuration we are avoiding at each step of the construction. The fact that our algorithm is more general than \cite{MalabikaRob}, yet we can discard the queueing method, is an interesting anomoly. We have ideas on how to exploit the fact that we do not use queueing to generalize our theorem to much more wide family of `dimension $\alpha$' sets $Z$, which we plan to publish in a later result.

Aside from \cite{MalabikaRob}, another paper that takes the perspective of solving a generic fractal avoidance problem is \cite{Mathe}, who finds a solution $X$ to an avoidance problem with $Z$ a degree $k$ hypersurface with Hausdorff dimension $d/k$. If $k \geq n-1$, then our result does better than Mathe's result, so where Mathe's result excels is when $Z$ is a low dimensional hypersurface. Just like how the result of this paper is a sparse analogue of \cite{MalabikaRob}, we would like to publish a follow up result giving a sparse analogue to \cite{Mathe}. Just as our result is obtained by assuming $Z$ is covered by a sparse family of cubes, a sprase analogue of \cite{Mathe} would give a result if $Z$ is covered by a sparse family of thickened varieties from a pencil of low degree surfaces. We already have ideas we are refining on how to achieve this.

\begin{thebibliography}{9}

%TODO: MAKE INTO MATHSCINET. AND REMOVE EXTRANEOUS REFERENCES.
%TODO: LOOK UP STANDARDIZED MATH JOURNAL ABBREVIATION.

\bibitem{KeletiDimOneSet}
Tam\'{a}s Keleti
\textit{A 1-Dimensional Subset of the Reals that Intersects Each of its Translates in at Most a Single Point}

\bibitem{MalabikaRob}
Robert Fraser, Malabika Pramanik
\textit{Large Sets Avoiding Patterns}

\bibitem{Mathe}
A. Math\'{e}
\textit{Sets of Large Dimension Not Containing Polynomial Configurations}

\bibitem{BaloghMorrisSamotij}
J\'{o}zsef Balogh, Robert Morris, Wojceich Samotij
\textit{Independent Sets in Hypergraphs}

%\bibitem{David}
%Guy David
%\textit{Bounded singular integrals on a Cantor set}

%\bibitem{Vasilis}
%Vasilis Chousionis
%\textit{Singular Integrals On Sierpinski Gaskets}

%\bibitem{Bennett}
%Michael Bennett, Alex Iosevich, Krystal Taylor
%\textit{Finite Chains Inside Thin Subsets of $\mathbf{R}^d$}

\bibitem{KatzTao}
Nets Hawk Katz, Terence Tao
\textit{Some connections between Falconer's distance set conjecture, and sets of Furstenburg type}

\end{thebibliography}

%\end{multicols}

\end{document}

Once we have discretized the problem, the Euclidean structure of the setting becomes irrelevant. As such, we rephrase our single scale avoidance method as a combinatorial problem on graphs. Here we prove a form of Tur\'{a}n's theorem, which quantifies the idea that graphs with few edges contain large independant sets. In the next section, we apply this theorem to find large discretized sets avoiding a discretization of the fractal we are required to avoid. Exploiting this repeatedly at an infinite series of discretizations then gives a set completely avoiding the required fractal.

Recalling notation, we consider a fixed set of $V$ elements, whose points we call {\it vertices}. A set of $n$ {\it distinct} vertices will be called an {\it $n$ vertex hyperedge}. The structure consisting of a set of vertices, and a family of $n$ vertex hyperedges on those vertices, will be called an {\it $n$ uniform hypergraph}. We let $E$ denote the number of edges in such a graph. A subset of vertices which does not contain any hyperedge as a subset is known as an {\it independent set}. We will consider partitions of the vertex set, and we say a partition is {\it $K$ spread} if there are at least $K$ vertices in each equivalence class.

\begin{lemma}
	Every $n$ uniform hypergraph with a $K$ spread partition contains an independent set with elements selected from all but at most $E/K^n$ equivalence classes.
\end{lemma}
\begin{proof}
	Let $X$ be a random vertex set chosen by selecting a representative vertex from every equivalence class uniformly at random. Then every vertex occurs in $X$ with probability at most $1/K$. If an edge $e = \{ v_1, \dots, v_n \}$ satisfies $\mathbf{P}(v_1, \dots, v_n \in X) > 0$, then the $v_1, \dots, v_n$ are distinct, and lie in separate equivalence classes of the partition. This implies that $v_1, \dots, v_n$ each occur in $X$ with independant likelihood, so a bound on the probability that all vertices in $e$ lie in $X$ is
	%
	\begin{align*}
		\mathbf{P}(v_1, \dots, v_n \in X) = \mathbf{P}(v_1 \in V) \dots \mathbf{P}(v_n \in X) \leq 1/K^n
	\end{align*}
	%
	If $E_0$ denotes the number of edges $e = \{ v_1, \dots, v_n \}$ with $v_1, \dots, v_n \in X$, then
	%
	\begin{align*}
		\mathbf{E}(E_0) = \sum_{e \in E} \mathbf{P}(e \in E_0) \leq \sum_{e \in E} 1/K^n = E/K^n
	\end{align*}
	%
	This means we may choose a particular, {\it nonrandom} $X$ for which $E_0 \leq E/K^n$. If we form a vertex set $W \subset V$ by removing, for each $e \in E_0$, a vertex in $X$ adjacent to $e$, then $W$ is an independent set containing representatives from all but $E_0 \leq E/K^n$ equivalence classes of the partition.
\end{proof}

%\begin{corollary}
%	If $|V| \gtrsim N^a$, $|E| \lesssim N^b$, and $K \gtrsim N^c$, where $b < a + c(n-1)$, then as $N \to \infty$ we can find an independent set containing all but a fraction $o(1)$ of the colors.
%\end{corollary}
%\begin{proof}
%	A simple calculation on the quantities of the previous lemma yields
	%
%	\begin{align*}
%		\frac{\# ( \text{colors removed} )}{\# ( \text{all colors} )} = \frac{|E|/K^n}{|V|/K} = \frac{|E|}{|V|K^{n-1}} \lesssim \frac{N^b}{N^{a + c(n-1)}}
%	\end{align*}
	%
%	This is $o(1)$ if $b < a + c(n-1)$.
%\end{proof}

%To apply the theorem to fractals, we will take cubes in the Euclidean plane as our vertices, and connect an edge between cubes if their cartesian product intersects a portion of $Y$. For technical reasons, we require that the cubes are essentially uniformly chosen across the candidate set of choices, and this is the reason for the introduction of partitions of vertices in the graph theory result above.

An important feature of our bound on the independant set selected is the ratio between the number of equivalence classes we choose versus the total number of equivalence classes. Since each class contains $K$ elements, there are $V/K$ equivalence classes. We calculate
%
\[ \frac{\# (\text{classes not chosen})}{\# (\text{total classes})} \leq \frac{E/K^n}{V/K} \leq \frac{E/V}{K^{n-1}} \]
%
To make this ratio small, we upper bound $E$, and lower bound $V$ and $K$.

%In our case, $E$ will be dependant on the Hausdorff dimension of $Y$, $V$ will depend on the sidelength

%In our case, we get few edges if our set $Y$ has low Hausdorff dimension, and we have lots of vertices if we choose a proportionally small sidelengths for our cubes.

%We now apply these constructions to a problem clearly related to the fractal avoidance problem. It will form our key method to construct fractal avoidance solutions. Given a real number $L$, we subdivide $\mathbf{R}^d$ into a lattice of side length $L$ cubes with corners on $L \cdot \mathbf{Z}^d$, the collection of such cubes we will denote by $\mathcal{B}(L,d)$. This grid is used to granularize configuration avoidance.

%\begin{theorem}
%	Suppose $\mathcal{I}_1, \dots, \mathcal{I}_n$ are disjoint collections of cubes in $\mathcal{B}(L,d)$, with $|\mathcal{I}_i| \gtrsim (1/L)^d$. If $\alpha$ strictly bounds the lower Minkowski dimension of $Z$ from above, and a rational parameter
	%
%	\[ \beta > \max \left(1, d \cdot \frac{n-1}{nd-\alpha} \right) \]
	%
%	is fixed, then there exists collections of cubes $\mathcal{J}_1, \dots, \mathcal{J}_n \in \mathcal{B}(L^\beta,d)$ with each cube in $\mathcal{J}_1 \times \dots \times \mathcal{J}_n$ disjoint from $Z$, and each $\mathcal{J}_i$ containing cubes in all but a fraction $o(1)$ of cubes in $\mathcal{I}_i$ as $L \to 0$.
%\end{theorem}
%\begin{proof}
%	We reduce this problem to the independent set problem we just proved a result about. We define the discretization of $Z$ to be
	%
%	\[ \mathcal{Z} = \{ I \in \mathcal{B}(L^\beta,nd) : I \cap Z \neq \emptyset \} \]
	%
%	For each $i$, we set
	%
%	\[ \mathcal{I}_i' = \{ I \in \mathcal{B}(L^\beta,d) : \text{there is}\ J \in \mathcal{I}_i\ \text{s.t.}\ I \subset J \} \]
	%
%	We obtain an $n$ uniform hypergraph $G$ by taking the cubes in $\mathcal{I}_1', \dots, \mathcal{I}_n'$ as vertices, with a hyperedge between $I_1 \in \mathcal{I}'_1, \dots, I_n \in \mathcal{I}'_n$ if $I_1 \times \dots \times I_n \in \mathcal{Z}$. We then take a coloring on $G$ by declaring two cubes in $\mathcal{I}_i'$ to be the same color if they are contained in a common cube in $\mathcal{I}_i$. In particular, this gives us a true coloring because every color occurs solely in $\mathcal{I}_i$ for some index $i$, and every edge in the hypergraph contains exactly one vertex from each index. An independent set in this graph can be written as $\mathcal{J}_1, \dots, \mathcal{J}_n$, where the $\mathcal{J}_i$ are collections of cubes which are sub-cubes of cubes in $\mathcal{I}_i$ and no cube in $\mathcal{J}_1 \times \dots \times \mathcal{J}_n \subset \mathcal{B}(1/N^\beta,nd)$ intersects $Z$. Thus to prove the theorem it suffices to find a large independent set in this graph.

%	We employ the corollary we just proved to do this, by bounding the number of vertices and edges in $G$. Since a cube in $\mathcal{B}(L,d)$ contains $\Omega(1/L^{d(\beta-1)})$ cubes in $\mathcal{B}(L^\beta,d)$, we conclude that $|\mathcal{I}'_i| \gtrsim (1/L)^{d(\beta - 1)} |\mathcal{I}_i| \gtrsim (1/L)^{d \beta}$. But then the number of vertices of $G$ is $\sum |\mathcal{I}'_i| \gtrsim (1/L)^{d \beta}$. The Minkowski dimension bound on $Z$ implies that the number of edges in $G$ is bounded above by $|\mathcal{Z}| \lesssim (1/L)^{\alpha \beta}$,Finally, the coloring is $N^{d(\beta - 1)}$ uniform. Thus in the terminology of the previous corollary, $a = d \beta$, $b = \alpha \beta$, and $c = d(\beta - 1)$. The inequality $\beta > d(n-1)/(nd - \alpha)$, is equivalent to the inequality $b < a + c(n-1)$, and so the corollary applies to give the required result.
%\end{proof}

%The value $d \cdot (n-1)/(n-\alpha)$ in the theorem is directly related to the dimension $(n-\alpha)/(n-1)$ we get in our main result. If, for a specific $Z$, we can prove a variant of this lemma with $d \cdot (n-1)/(n-\alpha)$ replaced with $d/\lambda$, then going through the rest of our proof will immediately yield $X$ with Hausdorff dimension $\lambda$. In particular, to prove our second result it will suffice to prove the theorem above given that $Z$ has a low rank assumption and $d \cdot (n-1)/(n-\alpha)$ is replaced with $d \cdot(2k-1)/(dk - k - \alpha)$.

% TODO: Include Tightness Calculation?