%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = HarmonicAnalysis.tex

\part{Calderon-Zygmund Theory}

Here, we try and describe the more modern approaches to real-variable harmonic analysis, as developed by the \emph{Calderon-Zygmund school} in the 1960s and 1970s. Almost all of the problems we consider can be phrased as showing some operator is bounded as a map between functions spaces. Given some function $f$ lying in a space $V$, we have an associated function $Tf$ lying in some space $W$. The main goal of the techniques in this part of the book attempt to understand how quantitative control on certain properties of $f$ imply quantitative control on properties of $Tf$. In particular, given some quantity $A(f)$ associated with each $f \in V$, and a quantity $B(g)$ defined for all $g \in W$, our goal is to understand whether a general bound $B(Tf) \lesssim A(f)$ is possible for all functions $f \in V$, i.e. whether these exists a universal constant $C > 0$ such that $B(Tf) \leq C \cdot A(f)$ for all $f \in V$.

A core technique we employ here is the method of \emph{decomposition}. We write $f = \sum_k f_k$, where the function $f_k$ have particular properties, perhaps being concentrated in a particular region of space, or having a Fourier transform concentrated in a particular region. These concentration properties often simplify the analysis of the operator $T$, enabling us to obtain bounds $B(Tf_k) \lesssim A(f_k)$ for each $n$. Provided that the operator $T$, and the quantities $A$ and $B$ are `stable under addition', we can then obtain the bound $B(Tf) \leq A(f)$ by `summing' up the related quantities. The stability of $A$ and $B$ is often obtained by assuming these quantities are \emph{norms} on their respective function spaces, i.e. that there exists norms $\| \cdot \|_V$ and $\| \cdot \|_W$ such that $A(f) = \| f \|_V$ for each $f \in V$ and $B(g) = \| g \|_W$ for each $g \in W$. The stability of $T$ under addition is obtained by assuming linearity, or at least sub-linearity, in the sense that for each $f_1, f_2 \in V$,
%
\[ \| T(f_1 + f_2) \|_W \leq \| T f_1 \|_W + \| Tf_2 \|_W. \]
%
We can then use the triangle inequality to conclude that
%
\[ \| Tf \|_W \leq \sum_k \| Tf_k \|_W \lesssim \sum_k \| f_k \|_V. \]
%
Thus if $\sum_k \| f_k \|_V \lesssim \| f \|_V$, our argument is complete. This will be true, for instance, if there exists $\varepsilon > 0$ such that $\| f_k \|_V \lesssim 2^{- \varepsilon k} \| f \|_V$. This can often be obtained if we employ a \emph{dyadic decomposition technique}. For such decompositions, it is also possible to generalize are technique not only to norms, but also to \emph{quasinorms}, i.e. maps $\| \cdot \|$ which are homogeneous and satisfy a \emph{quasi-triangle inequality} $\| v + w \| \lesssim \| v \| + \| w \|$.

\begin{lemma}
    Suppose $\| \cdot \|_V$ is a quasi-norm on a vector space $V$, and under the topology induced by $\| \cdot \|_V$, we can write $f = \sum_{k = 1}^\infty f_k$, where there is $\varepsilon > 0$ and $C > 0$ such that for each $n$, $\| f_k \|_V \leq C \cdot 2^{-\varepsilon k}$. Then $\| f \|_V \lesssim_\varepsilon C$.
\end{lemma}

\begin{remark}
	Thus if $T$ is sublinear and we have $\| Tf_k \|_W \lesssim \| f_k \|_V$ and $\| f_k \|_V \lesssim 2^{- \varepsilon k} \| f \|_V$, we conclude $\| Tf_k \|_W \lesssim 2^{-\varepsilon k} \| f \|_V$, and then by sublinearity and the lemma applied to $\| \cdot \|_W$, we conclude
	%
	\[ \| Tf \|_W \leq \| \sum_k Tf_k \|_W \lesssim_\varepsilon \| f \|_V. \]
	%
	A slight modification of the proof below even gives this claim provided $T$ is \emph{quasi sublinear}, in the sense that for all $f_1, f_2 \in V$, $\| T(f_1 + f_2) \|_W \lesssim \| Tf_1 \|_V + \| Tf_2 \|_V$ for all $f_1, f_2 \in V$. However, such operators occur so rarely in practice that it isn't worth concentrating on them.
\end{remark}

\begin{proof}
	Pick $A > 0$ such that $\| f_1 + f_2 \|_V \leq A \cdot (\| f_1 \|_V + \| f_2 \|_V)$ for all $f_1$ and $f_2$. If $A < 2^{\varepsilon}$, we can write apply the quasitriangle inequality iteratively to conclude
    %
    \begin{align*}
        \| f \| &\leq C \cdot \sum_{k = 1}^\infty A^k \| f_k \|_V \leq C \cdot \left( \sum_{k = 1}^\infty (A 2^{-\varepsilon})^k \right) \leq C \cdot \left( \frac{1}{1 - A 2^{-\varepsilon}} \right) \lesssim_\varepsilon C.
    \end{align*}
    %
    In general, fix $N$, and write $f = f^1 + \dots + f^N$, where $f^m = \sum_{k = 0}^\infty f_{m + Nk}$. Then $\| f_{m + Nk} \|_V \leq C \cdot 2^{- N \varepsilon k}$, and if $N$ is chosen large enough that $A < 2^{N \varepsilon}$, we can apply the previous case to conclude that $\| f^m \|_V \lesssim_\varepsilon C$. Then we can apply the quasi-triangle inequality to conclude that $\| f \| \lesssim_\varepsilon C$.
\end{proof}

We can even apply the method of decomposition in the presence of suitably large polynomial decay.

\begin{lemma}
    Suppose $\| \cdot \|_V$ is a quasinorm on a function space $V$. Then there exists $t$ such that for all $s > t$, if $f = \sum_{k = 1}^\infty f_k$, and if $\| f_k \|_V \leq C \cdot k^{-s}$, for $s > t$, then $\| f \|_V \lesssim_s C$.
\end{lemma}
\begin{proof}
    As in the previous lemma, pick $A > 0$ such that $\| f_1 + f_2 \|_V \leq A (\| f_1 \|_V + \| f_2 \|_V)$ for all $f_1,f_2 \in V$. We perform a decomposition of dyadic type, writing $f = \sum_{m = 0}^\infty f^m$, where
    %
    \[ f^m = \sum_{k = 2^m}^{2^{m+1} - 1} f_k. \]
    %
    By splitting up the sum into a binary tree, we can ensure that
    %
    \[ \| f^m \|_V \lesssim A^{m+1} \sum_{k = 2^m}^{2^{m+1} - 1} \| f_k \|_V \leq C \cdot A^{m+1} \sum_{k = 2^m}^{2^{m+1} - 1} k^{-s} \lesssim C (A 2^{1-s})^m. \]
    %
    If $s > 1 + \lg(A)$, the previous lemma applies that $\| f \|_V \lesssim C$.
\end{proof}

In this part of the notes, we define the various classes of quasi-norms we will study, describe the general methods which make up the Calderon-Zygmund theory, and find applications to geometric measure theory, complex analysis, partial differential equations, and analytic number theory.





\chapter{Monotone Rearrangement Invariant Norms}

In this chapter, we discuss common families of \emph{monotone, rearrangement invariant quasinorms} that occur in harmonic analysis. The general framework is as follows. For each function $f$, we associate it's \emph{distribution function} $F: [0,\infty) \to [0,\infty]$ given by $F(t) = |\{ x : |f(x)| > t \}|$. A \emph{rearrangement invariant space} is a subspace $V$ of the collection of measurable complex-valued functions on some measure space $X$, equipped with a quasi-norm $\| \cdot \|$, satisfying the following two properties:
%
\begin{itemize}
    \item \emph{Monotonicity}: If $|f(x)| \leq |g(x)|$ for all $x \in X$, then $\| f \| \leq \| g \|$.

    \item \emph{Rearrangement-Invariance}: If $f$ and $g$ have the same distribution function, then $\| f \| = \| g \|$.
\end{itemize}
%
A monotone rearrangement-invariant norm essentially provides a way of quantifying the height and width of functions on $X$. It has no interest in the `shape' of the objects studied, because of the property of rearrangement invariance. In a particular problem, one picks the norm best emphasizing a particular family of features useful in the problem.

There are two very useful classes of functions useful for testing the behaviour of translation invariant norms:
%
\begin{itemize}
    \item The \emph{indicator functions} $\mathbf{I}_E(x) = \mathbf{I}(x \in E)$, for a measurable set $E$.
    \item The \emph{simple functions} $f = \sum_{i = 1}^n a_i \mathbf{I}_{E_i}$, for disjoint sets $E_i$.
\end{itemize}
%
The class of all simple functions forms a vector space, and for almost all the monotone rearrangement invariant norm we consider in this section, this vector space will form a dense subspace of the class of all functions. This means that when we want to study how an operator transforms the height and width of functions, the behaviour of the operator on simple functions often reflects the behaviour of an arbitrary function.

\section{The $L^p$ norms}

We begin by introducing the most fundamental monotone, rearrangement invariant norms. For $p \in (0,\infty)$, we define the $L^p$ norm of a measurable function $f$ on a measure space $X$ by
%
\[ \| f \|_{L^p(X)} = \left( \int_X |f(x)|^p\; dx \right)^{1/p}. \]
%
For $p = \infty$, we define
%
\[ \| f \|_{L^\infty(X)} = \min \left\{ t \geq 0: |f(x)| \leq t\ \text{almost surely} \right\}, \]
%
a quantity often called the \emph{essential} supremum. If the measure space $X$ is implicit, these quantities are also denoted by $\| f \|_p$, as we do often in this chapter. The space of functions $f$ with $\| f \|_p < \infty$ is denoted by $L^p(X)$. The most important spaces to consider here are the space $L^1(X)$, consisting of absolutely square integrable functions, $L^\infty(X)$, consisting of almost-everywhere bounded functions, and $L^2(X)$, consisting of square integrable functions. The main motivation for the introduction of the other $L^p$ spaces is that much of the quantitative theory in harmonic analysis for $p = 1$ and $p = \infty$ is rather trivial, in the sense that for most operators that occur in practice, it is simple to determine whether these operators are bounded on these spaces; obtaining $L^p$ bounds of an operator for $1 < p < \infty$ reflects a deeper understanding of the quantitative properties of an operator.

As $p$ increases, the $L^p$ norm of a particular function $f$ gives more control over the height of the function $f$, and weaker control on values where $f$ is particular small. At one extreme, $L^\infty(X)$ only has control over the height of a function, and no control over it's width. Conversely, as $p \to 0$, $L^p(X)$ has more control over the width of functions. It is therefore natural to introduce the space $L^0(X)$ as the space of measurable functions with finite measure support. But there is no natural norm on $L^0(X)$ which can classify the width of functions. After all, such a quantity couldn't be homogenous, since the width of $f$ and $\alpha f$ are the same for each $\alpha \neq 0$.

\begin{example}
  If $f(x) = |x|^{-s}$ for $x \in \RR^d$ and $s > 0$, then integration by radial coordinates shows that
  %
  \[ \int_{\varepsilon \leq |x| \leq M} \frac{1}{|x|^{s p}}\; dx \approx \int_\varepsilon^M r^{d-1 - ps}\; dr = \frac{M^{d - p s} - \varepsilon^{d - p s}}{d - p s}. \]
  %
  This quantity remains finite as $\varepsilon \to 0$ if and only if $d > p s$, and finite as we let $M \to \infty$ if and only if $d < p s$. Thus if $p < d/s$, $f$ is \emph{locally} in $L^p$, in the sense that $f \in L^p(B)$ for every bounded $B \in \RR^d$. The class of functions for which this condition holds is denoted $L^p_{\text{loc}}(X)$. Conversely, if $p > d/s$, then for every closed set $B$ not containing the origin, $f \in L^p(B)$. For $p = d/s$, the function $f$ fails to be $L^p(\RR^d)$, but only `by a logarithm', which manifests in the fact that
  %
  \[ \int_{\varepsilon \leq |x| \leq M} \frac{1}{|x|^{s p}}\; dx \approx \int_\varepsilon^M \frac{dr}{r} = \log(M/\varepsilon). \]
  %
  We will later introduce norms that differ from the standard $L^p$ norms by a logarithmic factor, and the norm of $f$ with respect to these norms can be made finite.
\end{example}

The last example shows that, roughly speaking, control on the $L^p$ norm of a function for large values of $p$ prevents the formation of sharp singularities, and control of an $L^p$ norm for small values of $p$ ensures that functions have large decay at infinity.

\begin{example}
  If $s = A \chi_E$, and we set $H = |A|$ and $W = |E|$, then $\| s \|_p = W^{1/p} H$. As $p \to \infty$, the value of $\| s \|_p$ depends more and more on $H$, and less on $W$, and in fact $\lim_{p \to \infty} \| s \|_p = H$. If $s = \sum A_n \chi_{E_n}$, and $|A_m|$ is the largest constant from all other values $A_n$, then as $p$ becomes large, $|A_m|^p$ overwhelms all other terms. We calculate that as $p \to \infty$,
  %
  \[ \| s \|_p = \left( \sum |E_n| |A_n|^p \right)^{1/p} = |A_m|^p (|E_m| + o(1))^{1/p} = |A_m| (1 + o(1)). \]
  %
  This implies $\| s \|_p \to |A_m|$ as $p \to \infty$. But as $p \to 0$, $\lim_{p \to 0} \| f \|_p$ does not in general exist, even for step functions with finite measure support. Nonetheless, we can conclude that $\lim_{p \to 0} \| s \|_p^p = \sum |E_n|$.
\end{example}

As $p \to \infty$, the last example shows the width of a function is disregarded completely by the $L^p$ norm, from which it follows that $\| s \|_{L^p(X)} \to \| s \|_{L^\infty(X)}$ as $p \to \infty$. The same is true for more general functions, which we can prove using a density argument.

\begin{theorem}
    Let $p \in (0,\infty)$. If $f \in L^p(X) \cap L^\infty(X)$, then
    %
    \[ \lim_{t \to \infty} \| f \|_t = \| f \|_\infty. \]
\end{theorem}
\begin{proof}
    Without loss of generality, assume $p \geq 1$. Consider the norm $\| \cdot \|$ on $L^p(X) \cap L^\infty(X)$ given by
    %
    \[ \| f \| = \| f \|_p + \| f \|_\infty. \]
    %
    Then $L^p(X) \cap L^\infty(X)$ is complete with respect to this metric. For each $t \in [p,\infty)$, define $T_t(f) = \| f \|_t$. Then the functions $\{ T_t \}$ are uniformly bounded in the norm $\| \cdot \|$, since if $p = \theta t$, then
    %
    \[ |T_t(f)| = \| f \|_t \leq \| f \|_p^\theta \| f \|_\infty^{1-\theta} \leq \| f \|^\theta \| f \|^{1-\theta} = \| f \|. \]
    %
    For any $\varepsilon > 0$, we can find a step function $s$ with $\| s - f \|_p, \| s - f \|_\infty \leq \varepsilon$. This means that for all $t \in (p,\infty)$,$\| s - f \|_t \leq \varepsilon$. And so
    %
    \begin{align*}
        \Big| T_t(f) - \| f \|_\infty \Big| &\leq |T_t(f) - T_t(s)| + |T_t(s) - \| s \|_\infty| + |\| s \|_\infty - \| f \|_\infty| \leq 2\varepsilon + o(1).
    \end{align*}
    %
    Taking $\varepsilon \to 0$ gives the result.
\end{proof}

Abusing notation, we define $\| f \|_0^0 = | \text{supp} f | = | \{ x: f(x) \neq 0 \} |$, and let $L^0(X)$ be the space of functions with finite support. We know that for any simple function $s$, $\| s \|_p^p \to \| s \|_0^0$ as $p \to 0$. If $f \in L^0(X) \cap L^p(X)$ for some $p \in (0,\infty)$, then the monotone and dominated convergence theorems implies that
%
\[ \| f \|_0^0 = \int \mathbf{I}(f(x) \neq 0) = \int \left( \lim_{t \to 0} |f(x)|^t \right)\; dx = \lim_{t \to 0} \int |f(x)|^t\; dx = \lim_{t \to 0} \| f \|_t^t. \]
%
Thus the space $L^0(X)$ lies at the opposite end of the spectrum to $L^\infty$.

The fact that $\| f \|_0^0$ is a norm taken to the `power of zero' implies that many nice norm properties of the $L^p$ spaces fail to hold for $L^0(X)$. For instance, homogeneity no longer holds; in fact, for each $\alpha \neq 0$,
%
\[ \| \alpha f \|_0^0 = \| f \|_0^0. \]
%
It does, however, satisfy the triangle inequality $\| f + g \|_0^0 \leq \| f \|_0^0 + \| g \|_0^0$, which follows from a union bound on the supports of the functions.

\begin{example}
  Let $p < q$, and suppose $f \in L^p(X) \cap L^q(X)$. For any $r \in (p,q)$, the $L^r$ norm emphasizes the height of $f$ less than the $L^q$ norm, and emphasizes the width of $f$ less than the $L^p$ norm. In particular, we find that for any $\lambda \geq 0$,
  %
  \begin{align*}
    \| f \|_r^r = \int_{\RR} |f(x)|^r\; dx &= \int_{|f(x)| \leq 1} |f(x)|^r\; dx + \int_{|f(x)| > 1} |f(x)|^r\; dx\\
    &\leq \int_{|f(x)| \leq 1} |f(x)|^p\; dx + \int_{|f(x)| > 1} |f(x)|^q\; dx\\
    &\leq \| f \|_p^p + \| f \|_q^q < \infty.
  \end{align*}
  %
  In particular, this shows $f \in L^r(X)$.
\end{example}

\begin{remark}
    The bound obtained in the last example can be improved by using scaling symmetries. For any $A > 0$,
    %
    \[ \| f \|_r^r = \frac{\| Af \|_r^r}{A^r} \leq \frac{\| Af \|_p^p + \| Af \|_q^q}{A^r} \leq \frac{A^p \| f \|_p^p + A^q \| f \|_q^q}{A^r}. \]
    %
    If $1/r = \theta/p + (1 - \theta)/q$, and we set $A = \| f \|_q^{q/(p-q)} / \| f \|_p^{p/(p-q)}$, then the above inequality implies $\| f \|_r \leq 2 \| f \|_p^\theta \| f \|_q^{1 - \theta}$, which is a homogenous equality. The constant 2 can be removed in the equation using the {\it tensor power trick}. If we consider the function on $X^n$ defined by $f^{\otimes n}(x_1, \dots, x_n) = f(x_1) \dots f(x_n)$, then $\| f^{\otimes n} \|_r = \| f \|_r^n$, and so
    %
    \[ \| f \|_r = \| f^{\otimes n} \|_r^{1/n} \leq \left( 2 \| f^{\otimes n} \|_p^\theta \| f^{\otimes n} \|_q^{1-\theta} \right)^{1/n} = 2^{1/n} \| f \|_p^\theta \| g \|_q^{1-\theta}. \]
    %
    We can then take $n \to \infty$ to conclude that $\| f \|_r \leq \| f \|_p^\theta \| f \|_q^{1-\theta}$.
\end{remark}

The argument in the last remark is an instance of \emph{real interpolation}; In order to conclude some fact about a function which lies `between' two other functions we know how to deal with, we split the function up into two parts lying in the other spaces, deal with them separately, and then put them back together to get some equality. One can then apply various symmetry considerations (homogeneity and the tensor power trick being two examples) to eliminate extraneous constants. We now also show how to prove this inequality using convexity, which illustrates another core technique. In the next theorem, $1/\infty = 0$.

\begin{theorem}[H\"{o}lder]
  If $0 < p,q \leq \infty$ and $1/p + 1/q = 1/r$,
  %
  \[ \| f g \|_r \leq \| f \|_p \| g \|_q. \]
\end{theorem}
\begin{proof}
  The case where $p$ or $q$ is $\infty$ is left as an exercise to the reader. In the other case, by moving around exponents, we may simplify to the case where $r = 1$. The theorem depends on the log convexity inequality, such that for $A,B \geq 0$ and $0 \leq \theta \leq 1$, $A^\theta B^{1 - \theta} \leq \theta A + (1 - \theta) B$. But since the logarithm is concave, we calculate
  %
  \[ \log(A^\theta B^{1 - \theta}) = \theta \log A + (1 - \theta) \log B \leq \log(\theta A + (1 - \theta) B), \]
  %
  and we can then exponentiate. To prove H\"{o}lder's inequality, by scaling $f$ and $g$, which is fine by homogeneity, we may assume that $\| f \|_p = \| g \|_q = 1$. Then we calculate
  %
  \begin{align*}
    \| f g \|_1 &= \int |f(x)| |g(x)| = \int |f(x)|^{p/p} |g(x)|^{q/q}\\
    &\leq \int \frac{|f(x)|^p}{p} + \frac{|g(x)|^q}{q} = \frac{1}{p} + \frac{1}{q} = 1 = \| f \|_p \| g \|_q.
  \end{align*}
  %
  If $p = \infty$, $q = 1$, then the inequality is trivial, since we have the pointwise inequality $|f(x) g(x)| \leq \| f \|_\infty |g(x)|$ almost everywhere, which we can then integrate.
\end{proof}

\begin{remark}
  Note that $A^\theta B^{1-\theta} \leq \theta A + (1 - \theta) B$ is an \emph{equality} if and only if $A = B$, or $\theta \in \{ 0, 1 \}$. In particular, following through the proof above shows that if $\| f \|_p = \| g \|_q = 1$, we must have $|f(x)|^{1/p} = |g(x)|^{1/q}$ almost everywhere. In general, this means H\"{o}lder's inequality is sharp if and only if $|f(x)|^{1/p}$ is a constant multiple of $|g(x)|^{1/q}$.
\end{remark}

The next inequality is known as the \emph{triangle inequality}.

\begin{corollary} \label{lptriangleinequality}
  Given $f$,$g$, and $p \geq 1$, $\| f + g \|_p \leq \| f \|_p + \| g \|_p$.
\end{corollary}
\begin{proof}
  The inequality when $p = 1$ is obtained by integrating the inequality $|f(x) + g(x)| \leq |f(x)| + |g(x)|$, and the case $p = \infty$ is equally trivial. When $1 < p < \infty$, by scaling we can assume that $\| f \|_p + \| g \|_p = 1$. Then we can apply H\"{o}lder's inequality combined with the $p = 1$ case to conclude
  %
  \begin{align*}
    \int |f(x) + g(x)|^p &\leq \int |f(x)| |f(x) + g(x)|^{p-1} + |g(x)| |f(x) + g(x)|^{p-1}\\
    &\leq \| f \|_p \| (f + g)^{p-1} \|_q + \| g \|_p \| (f + g)^{p-1} \|_q = \| f + g \|_{p}^{p-1}
  \end{align*}
  %
  Thus $\| f + g \|_p^p \leq \| f + g \|_p^{p-1}$, and simplifying gives $\| f + g \|_p \leq 1$.
\end{proof}

\begin{remark}
  Suppose $\| f + g \|_p = \| f \| + \| g \|_p$. Following through the proof given above shows that both applications of H\"{o}lder's inequality must be sharp. And this is true if and only if $|f(x)|^p$ and $|g(x)|^p$ are scalar multiples of $|f(x) + g(x)|^p$ almost everywhere. But this means $|f(x)|$ and $|g(x)|$ are scalar multiples of $|f(x) + g(x)|$. If $|f(x)| = A|f(x) + g(x)|$ and $|g(x)| = B|f(x) + g(x)|$. If $g \neq 0$, this implies there is $C$ such that $|f(x)| = C |g(x)|$ for some $C > 0$. Thus we can write $f(x) = C e^{i \theta(x)} g(x)$, and we must have
  %
  \[ \| f + g \|_p^p = \int |1 + C e^{i \theta(x)}|^p |g(x)|^p = (1 + C)^p \int |g(x)|^p \]
  %
  so $|1 + Ce^{i \theta(x)}| = |1 + C|$ almost everywhere but this can only be true if $e^{i \theta(x)} = 1$ almost everywhere, so $f = C g$. Thus the triangle inequality is only sharp is $f$ and $g$ are positive scalar multiples of one another.
\end{remark}

This discussion leads to a useful heuristic: Unless $f$ and $g$ are `aligned' in a certain way, the triangle inequality is rarely sharp. For instance, if $f$ and $g$ have disjoint support, we calculate that
%
\[ \| f + g \|_p = \left( \| f \|_p^p + \| g \|_p^p \right)^{1/p} \]
%
For $p > 1$, this is always sharper than the triangle inequality.

If $p < 1$, then the proof of Corollary \ref{lptriangleinequality} no longer works, and in fact, is no longer true. In fact, if $f$ and $g$ are non-negative functions, then we actually have the \emph{anti} triangle inequality
%
\[ \| f + g \|_p \geq \| f \|_p + \| g \|_p, \]
%
as proved in the next theorem.

\begin{theorem}
    If $p \geq 1$, then for any functions $f_1, \dots, f_N \geq 0$,
    %
    \begin{equation} \label{triangleInequality} ( \| f_1 \|_p^p + \dots + \| f_N \|_p^p )^{1/p} \leq \| f_1 + \dots + f_N \|_p \leq \| f_1 \|_p + \dots + \| f_N \|_p. \end{equation}
    %
    If $p \leq 1$, then the inequality reverses, i.e. for any positive functions $f_1, \dots, f_N$,
    %
    \begin{equation} \label{antiTriangleInequality} \| f_1 \|_p + \dots + \| f_N \|_p \leq \| f_1 + \dots + f_N \|_p \leq (\| f_1 \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \end{equation}
\end{theorem}
\begin{proof}
    The upper bound in \eqref{triangleInequality} is just obtained by applying the triangle inequality iteratively. To obtain the lower bound, we note that for $A_1, \dots, A_N \geq 0$,
    %
    \[ (A_1 + \dots + A_N)^p \geq A_1^p + \dots + A_N^p, \]
    %
    One can prove this from induction from the inequality $(A_1 + A_2)^p \geq A_1^p + A_2^p$, which holds when $A_2 = 0$, and the derivative of the left hand side is greater than the right hand side for all $A_2 \geq 0$. But then setting $A_k = f_k$ and then integrating gives
    %
    \[ \| f_1 + \dots + f_N \|_p^p \geq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \]
    %
    Now assume $0 < p < 1$. We begin by proving the lower bound in \ref{antiTriangleInequality}. We can assume $N = 2$, and $\| f_1 \|_p + \| f_2 \|_p = 1$, and then it suffices to show $\| f_1 + f_2 \|_p \geq 1$. For any $\theta \in (0,1)$, and $A,B \geq 0$, concavity implies
    %
    \[ (A + B)^p = (\theta (A/\theta) + (1 - \theta) (B/(1-\theta)))^p \geq \theta^{1-p} A^p + (1 - \theta)^{1-p} B^p. \]
    %
    Thus setting $A = f_1(x)$, $B = f_2(x)$, and $\theta = \| f_1 \|_p$, so that $1 - \theta = \| f_2 \|_p$, and then integrating, we find
    %
    \[ \| f_1 + f_2 \|_p^p \geq \theta + (1 - \theta) = 1. \]
    %
    On the other hand, the inequality $(A_1 + \dots + A_N)^p \leq A_1^p + \dots + A_N^p$, which holds for $A_1, \dots, A_N \geq 0$, can be applied with $f_k = A_k$ and integrated to yield
    %
    \[ \| f_1 + \dots + f_N \|_p^p \leq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \qedhere \]
\end{proof}

Thus the triangle inequality is not satisfied for the $L^p$ norms when $p < 1$. This is one of the deficiencies which leads the $L^p$ theories for $0 < p < 1$ to be rather deficient when compared to the case with $p \geq 1$. One way to fix this is to use the theory of Hardy spaces. However, for $p < 1$, we do have a \emph{quasi} triangle inequality.

\begin{theorem} \label{quasitriangleinequalitylp}
    For $f_1, \dots, f_N \in L^p(X)$, with $0 < p < 1$,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \]
\end{theorem}
\begin{proof}
    By H\"{o}lder's inequality applied to sums,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq (\| f \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \qedhere \]
\end{proof}

This result is sharp, i.e. if we take a disjoint family of sets $\{ E_1, E_2, \dots \}$ with $|E_i| = 1$ for each $i$, and then set $f_i = \mathbf{I}_{E_i}$, then the inequality is sharp for each $N$.

\begin{remark}
    When $p < 1$, the space $L^p(X)$ is \emph{not} normable. To see why, we look at the topological features of $L^p(X)$. Fix $\varepsilon > 0$, and let $C$ be a convex set containing all functions $f$ with $\| f \|_p < \varepsilon$. Thus, in particular, $C$ contains all step functions $H \mathbf{I}_E$ where $H |E|^{1/p} < \varepsilon$. But if we now find a countable sequence of disjoint sets $\{ E_k \}$, each with positive measure, and for each $k$, define $H_k = (\varepsilon/2) |E_k|^{-1/p}$, then for any $N$, the function
    %
    \[ f_N = (H_1/N) \mathbf{I}_{E_1} + \dots + (H_N/N) \mathbf{I}_{E_N} \]
    %
    lies in $C$, and
    %
    \[ \| f_N \|_p = (1/N) (H_1^p |E_1| + \dots + H_N^p |E_N|)^{1/p} = (\varepsilon/2) N^{1/p - 1} \]
    %
    as $N \to \infty$, the $L^p$ norm of $f_N$ becomes unbounded. In particular, this means that we have proven that every bounded convex subset of $L^p(X)$ has empty interior, and a norm space certainly does not have this property.
\end{remark}

As we have mentioned, as $p \to \infty$, the $L^p$ norm excludes functions with large peaks, or large height, and as $p \to 0$, the $L^p$ norm excludes functions with large tails, or large width. They form a continuously changing family of functions as $p$ ranges over the positive numbers. In general, there is no inclusion of $L^p(X)$ in $L^q(X)$ for any $p,q$, except in two circumstances which occur often enough to be mentioned.

\begin{example}
  If $X$ is a finite measure space, and $0 < p \leq q \leq \infty$, $L^p(X) \subset L^q(X)$. H\"{o}lder's inequality implies $\| f \|_p = \| f \chi_X \|_p \leq \| f \|_q |X|^{1/p-1/q}$. Taking $q \to \infty$, we conclude $\| f \|_p \leq | X |^{1/p} \| f \|_\infty$. One can best remember the constants here by the formula
  %
  \[ \left( \fint |f(x)|^p \right)^{1/p} \leq \left( \fint |f(x)|^q \right)^{1/q}. \]
  %
  In particular, when $X$ is a probability space, the $L^p$ norms are increasing.
\end{example}

\begin{example}
  On the other hand, suppose the measure space is {\it granular}, in the sense that there is $\varepsilon > 0$ such that either $|E| = 0$ or $|E| \geq \varepsilon$ for any measurable set $E$. Then $L^q(X) \subset L^p(X)$ for $0 < p \leq q \leq \infty$. First we check the $q = \infty$ case, which follows by the trivial estimate
  %
  \[ \int |f(x)|^p \geq \varepsilon \| f \|_\infty, \]
  %
  so $\| f \|_\infty \leq \| f \|_p \varepsilon^{-1/p}$. But then applying log convexity, if $p \leq q < \infty$, we can write $1/q = \theta/p$ for $0 < \theta \leq 1$, and then log convexity shows
  %
  \[ \| f \|_q = \| f \|_p^\theta \| f \|_\infty^{1-\theta} \leq \varepsilon^{-(1 - \theta)/p} \| f \|_p = \varepsilon^{-1/p - 1/q} \| f \|_p. \]
  %
  If $\varepsilon = 1$, which occurs if $X = \ZZ$, then the $L^p$ norms are decreasing in $p$. This gives the best way to remember the constants involved, since the measure $\mu(E) = |E|/\varepsilon$ is one granular, and so
  %
  \[ \left( \frac{1}{\varepsilon} \int |f(x)|^q\; dx \right)^{1/q} \leq \left( \frac{1}{\varepsilon} \int |f(x)|^p\; dx \right)^{1/p}. \]
\end{example}

%\begin{example}
%  Controlling additional properties of the function offers similar properties as for control on the measure space. If $|f(x)| \leq M$ for almost all $x$, then for $p \leq q$,
  %
%  \[ \| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}. \]
  %
%  Conversely, if $|f(x)| \geq M$ whenever $f(x) \neq 0$, then
  %
%  \[ \| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}. \]
  %

%\end{example}

\begin{remark}
  We can often use such results in spaces which are not granular by coarsening the sigma algebra. For instance, the Lebesgue measure is $\varepsilon^d$ granular over the sigma algebra generated by the length $\varepsilon$ cubes whose corner's lie on the lattice $(\ZZ/\varepsilon)^d$, and if a function is measurable with respect to such a $\sigma$ algebra we call the function $\varepsilon$ granular.
\end{remark}

\begin{remark}
  If we let $X = \{ 1, \dots, N \}$, then $X$ is both finite and granular, so all $L^p$ norms are comparable. In particular, if $p \leq q$,
  %
  \[ \| f \|_q \leq \| f \|_p \leq N^{1/p - 1/q} \| f \|_q. \]
  %
  The left hand side of this inequality becomes sharp when $f$ is concentrated at a single point, i.e. $f(n) = \mathbf{I}(n = 1)$. On the other hand, the right hand side becomes sharp when $f$ is constant, i.e. $f(n) = 1$ for all $n$.
\end{remark}

\begin{example}
    We can obtain similar $L^p$ bounds by controlling the functions $f$ involved, rather than the measure space. For instance, if $|f(x)| \leq M$, and $p \leq q$, then then $\| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}$, which follows by log convexity. On the other hand, if $|f(x)| \geq M$ on the support of $f$, then $\| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}$.
\end{example}

\begin{theorem}
  If $p_\theta$ lies between $p_0$ and $p_1$, then
  %
  \[ L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X) \subset L^{p_0}(X) + L^{p_1}(X) \]
\end{theorem}
\begin{proof}
  If $\| f \|_{p_0}, \| f \|_{p_1} < \infty$, then for any $p_\theta$ between $p_0$ and $p_1$,
  %
  \[ \| f \chi_{|f| \leq 1} \|_{p_\theta}^{p_\theta} = \int_{|f| \leq 1} |f|^{p_\theta} \leq \int_{|f| \leq 1} |f|^{p_0} < \infty \]
  \[ \| f \chi_{|f| > 1} \|_{p_\theta}^{p_\theta} = \int_{|f| > 1} |f|^{p_\theta} \leq \int_{|f| > 1} |f|^{p_1} < \infty \]
  %
  Applying the triangle inequality, we conclude that $\| f \|_{p_\theta} < \infty$. In the case where $p_1 = \infty$, then $f \chi_{|f| > 1}$ is bounded, and must have finite support if $p_0 < \infty$, which shows this integral is bounded. Note the inequalities above show that we can split any function with finite $L^{p_\theta}$ norm into the sum of a function with finite $L^{p_0}$ norm and another with finite $L^{p_1}$ norm.
\end{proof}

\begin{remark}
  This theorem is important in the study of interpolation theory, because if we have two linear operators $T_{p_0}$ defined on $L^{p_0}(X)$ and $T_{p_1}$ on $L^{p_1}(X)$, and they agree on $L^{p_0}(X) \cap L^{p_1}(X)$, then there is a unique linear operator $T_{p_\theta}$ on $L^{p_\theta}(X)$ which agrees with these two functions, and we can consider the boundedness of such a function with respect to the $L^{p_\theta}$ norms.
\end{remark}

The last property of the $L^p$ norms we want to focus on is the principle of \emph{duality}. Given any values of $p$ and $q$ with $1/p + 1/q = 1$, H\"{o}lder's inequality implies that if $f \in L^p(X)$ and $g \in L^q(X)$, then $fg \in L^1(X)$. In particular, for each function $g \in L^q(X)$, the map
%
\[ \lambda: f \mapsto \int f(x)g(x)\; dx \]
%
is a linear functional on $L^p(X)$. H\"{o}lder's inequality implies that $\| \lambda \| \leq \| g \|_q$. But this is actually an \emph{equality}. In particular, if $1 < p < \infty$, one can show these are \emph{all} linear functionals. For $p \in \{ 1, \infty \}$, the dual space of $L^p(X)$ is more subtle. But, since in harmonic analysis we concentrate on quantitative bounds, the following theorem often suffices as a replacement.

\begin{theorem}
    If $1 \leq p < \infty$, and $f \in L^p(X)$, then
    %
    \[ \| f \|_p = \sup \left\{ \int f(x)g(x) : \| g \|_q = 1 \right\}. \]
    %
    If the underlying measure space is $\sigma$ finite, then this claim also holds for $p = \infty$.
\end{theorem}
\begin{proof}
    Suppose that $1 \leq p < \infty$. Given $f$, we define
    %
    \[ g(x) = \frac{1}{\| f \|_p^{p-1}} \text{sgn}(f(x)) |f(x)|^{p-1}. \]
    %
    If $\| f \|_p < \infty$, then
    %
    \[ \| g \|_q^q = \frac{1}{\| f \|_p^{pq - q}} \int |f(x)|^{pq-q} = \frac{1}{\| f \|_p^p} \| f \|_p^p = 1, \]
    %
    and
    %
    \[ \int f(x) g(x) = \frac{1}{\| f \|_p^{p-1}} \int |f(x)|^p = \| f \|_p. \]
    %
    On the other hand, suppose $\| f \|_p = \infty$. Then there exists a sequence of step functions $s_1 \leq s_2 \leq \dots \to |f|$. Each $s_k$ lies in $L^p(X)$, but the monotone convergence theorem implies that $\| s_k \|_p \to \infty$. For each $k$, find a function $g_k \geq 0$ with $\| g_k \|_q = 1$, and $\int g_k(x) s_k(x) \geq \| s_k \|_p / 2$. Then
    %
    \[ \int g_k(x) \text{sgn}(f(x)) f(x) = \int g_k(x) |f(x)| \geq \int g_k(x) s_k(x) \geq \| s_k \|_p / 2 \to \infty, \]
    %
    this completes the proof in this case.

    Now we take the case $p = \infty$. Given any $f$, fix $\varepsilon > 0$. Then we can find a set $E$ with $0 < |E| < \infty$ such that $|f(x)| \geq \| f \|_\infty - \varepsilon$ for $x \in E$. If $g(x) = \text{sgn}(f(x)) \mathbf{I}_E / |E|$, then $\| g \|_1 = 1$, and
    %
    \[ \int f(x) g(x) = \frac{1}{|E|} \int_E |f(x)| \geq \| f \|_\infty - \varepsilon. \]
    %
    Taking $\varepsilon \to 0$ completes the claim.
\end{proof}

\section{Decreasing Rearrangements}

 The properties of a functions distribution are best reflected quite simply in the \emph{distribution function} of the function $f$, i.e. the function $F: [0,\infty) \to [0,\infty)$ given by $F(t) = |\{ x : |f(x)| > t \}|$, and any rearrangement invariant norm on $f$ should be a function of $F$. The function $F$ is right-continuous and decreasing, but has a jump discontinuity whenever $\{ x : |f(x)| = t \}$ is a set of positive measure. We denote distributions of functions $g$ and $h$ by $G$ and $H$.

\begin{lemma}
  Given a function $f$ and $g$, $\alpha \in \mathbf{C}$, and $t,s > 0$, then
  %
  \begin{itemize}
    \item If $|g| \leq |f|$, then $G \leq F$.
    \item If $g = \alpha f$, then $G(t) = F(t/|\alpha|)$.
    \item If $h = f + g$, then $H(t+s) \leq F(t) + G(s)$.
    \item If $h = fg$, then $H(ts) \leq F(t) + G(s)$.
  \end{itemize}
\end{lemma}
\begin{proof}
    The first point follows because $\{ x : |g(x)| > t \} \subset \{ x : |f(x)| > t \}$, and the second because $\{ x : |\alpha f(x)| > t \} = \{ x : |f(x)| > t/|\alpha| \}$. The third point follows because if $|f(x) + g(x)| \geq t + s$, then either $|f(x)| \geq t$ or $|g(x)| \geq s$. Finally, if $|f(x) g(x)| \geq ts$, then $|f(x)| \geq t$ or $|g(x)| \geq s$.
\end{proof}

We can simplify the study of the distribution of $f$ even more by defining the \emph{decreasing rearrangement} of $f$, a decreasing function $f^*: [0,\infty) \to [0,\infty)$ such that $f^*(s)$ is the \emph{smallest} number $t$ such that $F(t) \leq s$. Effectively, $f^*(s)$ is the inverse of $F$:
%
\begin{itemize}
    \item If there is a unique $t$ with $F(t) = s$, then $f^*(s) = t$.
    \item If there are multiple values $t$ with $F(t) = s$, let $f^*(s)$ be the \emph{smallest} such value.
    \item If there are no values $t$ with $F(t) = s$, then we pick the first value $t$ with $F(t) < s$.
\end{itemize}
%
We find
%
\[ \{ s : f^*(s) > t \} = \{ s : s < F(t) \} = [0,F(t)), \]
%
which has measure $F(t)$. This is the most important property of $f^*$; it is a decreasing function on the line which has the same distribution as the function $|f|$. It is also the unique such function which is right continuous. Thus our intuition when analyzing monotone, rearrangement invariant norms is not harmed if we focus on right continuous decreasing functions.

\begin{theorem}
    The function $f^*$ is right continuous.
\end{theorem}
\begin{proof}
    We note that $F(t) > s$ if and only if $t < f^*(s)$. Since $f^*$ is decreasing, for any $s \geq 0$, we automatically have $f^*(s^+) \leq f^*(s)$. If $f^*(s^+) < f^*(s)$, then
    %
    \[ s < F \left( f^*(s^+) \right) \leq F(f^*(s)) \leq s, \]
    %
    which gives a contradiction, so $f^*(s) = f^*(s^+)$.
\end{proof}

\begin{remark}
    We have a jump discontinuity at a point $s$ wherever $F$ is flat, and $f^*$ is flat wherever $F$ has a jump discontinuity.
\end{remark}

In particular, when understanding intuition about monotone rearrangement invariant norms, one is allowed to focus on non-increasing, right continuous functions on $(0,\infty)$. For instance, this means that these norms do not care about the number of singularities that a function has, since all these singularities `pile up' in the decreasing rearrangement.

\section{Weak Norms}

The weak $L^p$ norms are obtained as a slight `refinement' of the $L^p$ norms.

\begin{theorem}
  If $\phi$ is an increasing, differentiable function on the real line with $\phi(0) = 0$, then
  %
  \[ \int_X \phi(|f(x)|) = \int_0^\infty \phi'(t) F(t)\; dt \]
\end{theorem}
\begin{proof}
  An application of Fubini's theorem is all that is needed to show
  %
  \begin{align*}
    \int_X \phi(|f(x)|)\; dx &= \int_X \int_0^{|f(x)|} \phi'(t)\; dt\; dx\\
    &= \int_0^\infty \phi'(t) \int_{|f(x)| > t}\; dx\; du\\
    &= \int_0^\infty \phi'(t) F(t)\; dt. \qedhere
  \end{align*}
\end{proof}

As a special case we find
%
\[ \| f \|_p = \left( p \int_0^\infty F(t) t^p \frac{dt}{t} \right)^{1/p}. \]
%
For this to be true, $F(t)$ must tend to zero `logarithmically faster' than $1/t^p$. Indeed, we find
%
\[ F(t) = |\{ |f|^p > t^p \}| \leq \frac{1}{t^p} \int |f|^p = \frac{\| f \|_p^p}{t^p}, \]
%
a fact known as \emph{Chebyshev's inequality}. But a bound $F(t) \lesssim 1/t^p$ might be true even if $f \not \in L^p(\RR^d)$. This leads to the \emph{weak $L^p$ norm}, denoted by $\| f \|_{p,\infty}$, which is defined to be the smallest value $A$ such that $F(t) \leq (A/t)^p$ for all $t$. We let $L^{p,\infty}(X)$ denote the space of all functions $f$ for which $\| f \|_{p,\infty} < \infty$. By Chebyshev's inequality, $\| f \|_{p,\infty} \leq \| f \|_p$ for any function $f$. The reason that the value $A$ occurs within the brackets is so that the norm is homogenous; if $g = \alpha f$, and $\| f \|_{p,\infty} = A$, then
%
\[ G(t) = F(t/|\alpha|) \leq \left( \frac{A |\alpha|}{t} \right)^p, \]
%
so $\| \alpha f \|_{p,\infty} = |\alpha| \| f \|_p$. The weak norms do not satisfy a triangle inequality, but they do satisfy a quasitriangle inequality. This can be proven quite simply from the property that if $f = f_1 + \dots + f_N$, and $\alpha_1, \dots, \alpha_N \in [0,1]$ satisfy $\alpha_1 + \dots + \alpha_N = 1$, then
%
\[ F(t) = F_1(\alpha_1 t) + \dots + F_N(\alpha_N t). \]
%
Thus if $f = g + h$, then
%
\[ F(t) \leq G(t/2) + H(t/2) \leq \frac{\| g \|_{p,\infty}^p + \| h \|_{p,\infty}^p}{t^p} \lesssim_p \left( \frac{\| g \|_{p,\infty} + \| h \|_{p,\infty}}{t} \right)^p. \]
%
Thus $\| f + g \|_{p,\infty} \lesssim \| f \|_{p,\infty} + \| g \|_{p,\infty}$. We can measure the degree to which the weak $L^p$ norm fails to be a norm by determining how much the triangle inequality fails for the sum of $N$ functions, instead of just one function.

\begin{theorem}[Stein-Weiss Inequality]
  Let $f_1, \dots, f_N$ be functions. If $p > 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty}. \]
  %
  If $p = 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{1,\infty} \lesssim \log N \left[ \| f_1 \|_{1,\infty} + \dots + \| f_N \|_{1,\infty} \right]. \]
  %
  If $0 < p < 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \left( \| f_1 \|_{p,\infty}^p + \dots + \| f_N \|_{p,\infty}^{1/p} \right)^{1/p} \]
\end{theorem}
\begin{proof}
    Begin with the case $p \geq 1$. Without loss of generality, assume $\| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty} = 1$. Fix $t > 0$. For each $k \in [1,N]$, define
    %
    \[ g_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \geq t/2, \\ 0 &: \text{otherwise}, \end{cases} \]
    %
    and
    %
    \[ h_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \leq \| f_k \|_{p,\infty} \cdot (t/2), \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    Also define $j_k = f_k - g_k - h_k$. Then write $f = f_1 + \dots + f_N$, $g = g_1 + \dots + g_N$, $h = h_1 + \dots + h_N$, and $j = j_1 + \dots + j_N$. Note that $\| h \|_\infty \leq t/2$, so
    %
    \[ \{ x : |f(x)| \geq t \} \subset \{ x : |g(x)| \geq t/4 \} \cup \{ x : |j(x)| \geq t/4 \}. \]
    %
    Each $g_k$ is supported on a set of measure at most $\| f_k \|_{p,\infty}^p \cdot (2/t)^p$. We conclude that $g$ is supported on a set of measure at most
    %
    \[ (2/t)^p \sum_{k = 1}^N \| f_k \|_{p,\infty}^p \leq (2/t)^p. \]
    %
    If $p > 1$, then the measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded by
    %
    \begin{align*}
        \frac{4}{t} \int |j(x)|\; dx &\leq \frac{4}{t} \sum_{k = 1}^N \int |j_k(x)|\\
        &= \frac{4}{t} \sum_{k = 1}^N \int_{\| f_k \|_{p,\infty} (t/2)}^{t/2} \frac{\| j_k \|_{p,\infty}^p}{s^p}\; ds\\
        &= \frac{2^{p+1}}{p-1} \frac{1}{t^p} \sum_{k = 1}^N \| j_k \|_{p,\infty}^p \left( \frac{1}{\| f_k \|_{p,\infty}^{p-1}} - 1 \right) \\
        &\leq \frac{2^{p+1}}{p-1} \frac{1}{t^p} \sum_{k = 1}^N \| f_k \|_{p,\infty}^p \left( \frac{1}{\| f_k \|_{p,\infty}^{p-1 }} - 1 \right)\\
        &\leq \frac{2^{p+1}}{p-1} \frac{1}{t^p}.
    \end{align*}
    %
    Thus in total, we conclude the measure of $\{ x: |f(x)| \geq t \}$ is at most
    %
    \[ \frac{2^p}{t^p} + \frac{2^{p+1}}{p - 1} \frac{1}{t^p} \lesssim_p \frac{1}{t^p}. \]
    %
    If $p = 1$, then the measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded
    %
    \begin{align*}
        (4/t) \int |j(x)|\; dx &\leq (4/t) \sum_{k = 1}^N \int |j_k(x)|\\
        &= (4/t) \sum_{k = 1}^N \int_{\| f_k \|_{1,\infty} (t/2)}^{t/2} \frac{\| j_k \|_{1,\infty}}{s}\; ds\\
        &= (4/t) \sum_{k = 1}^N \| f_k \|_{1,\infty} \log(1/\| f_k \|_{1,\infty}).
    \end{align*}
    %
    Now the maximum of $x_1 \log(1/x_1) + \dots + x_N \log(1/x_N)$, subject to the constraint that $x_1 + \dots + x_N = 1$, is maximized by taking $x_k = 1/N$ for all $N$, which gives a maximal bound of $\log(N)$. In particular, we find that
    %
    \[ (2/t) \sum_{k = 1}^N \| f_k \|_{1,\infty} \log(1/\| f_k \|_{1,\infty}) \leq (2 \log N)/t. \]
    %
    Thus in total, we conclude the measure of $\{ x: |f(x)| \geq t \}$ is at most
    %
    \[ 2(1 + \log N)/t \lesssim \log N / t. \]
    %
    If $p < 1$, we may assume without loss of generality that
    %
    \[ \| f_1 \|_{p,\infty}^p + \dots + \| f_N \|_{p,\infty}^p = 1. \]
    %
    Then, we perform the same decomposition as before, with functions $\{ g_k \}$, $\{ h_k \}$, and $\{ j_k \}$, defined the same as before, except that
    %
    \[ h_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \leq \| f_k \|_{p,\infty}^p \cdot (t/2), \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    The function $g_k$ has support at most $\| f_k \|_{p,\infty}^p \cdot (2/t)^p$, and thus $g$ has total support
    %
    \[ \sum \| f_k \|_{p,\infty}^p (2/t)^p = (2/t)^p. \]
    %
    The measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded by
    %
    \begin{align*}
      \frac{4}{t} \int |j(x)|\; dx &\leq \frac{4}{t} \sum_{k = 1}^N \int_{\| f_k \|_{p,\infty}^p (t/2)}^{t/2} \frac{\| f_k \|_{p,\infty}^p}{s^p}\; ds\\
      &\leq \frac{2^{p+1}}{t^p} \frac{1}{1 - p} \sum_{k = 1}^N \| f_k \|_{p,\infty}^{p + p(1-p)}\\
      &= \frac{2^{p+1}}{t^p} \frac{1}{1 - p} \max \| f_k \|_{p,\infty}^{p(1-p)} \lesssim_p \frac{1}{t^p},
    \end{align*}
    %
    Combining the two bounds gives that $\| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p 1$.
\end{proof}

\begin{remark}
  For $p = 1$, compare this \emph{logarithmic} failure to be a norm with the \emph{polynomial} failure to be a norm found in the norms $\| \cdot \|_p$, when $p < 1$, in Theorem \ref{quasitriangleinequalitylp}.
\end{remark}

For $p = 1$, the Stein-Weiss inequality is asymptotically tight in $N$.

\begin{example}
  Let $X = \RR$. For each $k$, let
  %
  \[ f_k(x) = \frac{1}{|x - k|}. \]
  %
  Then $\| f_k \|_{1,\infty} \lesssim 1$ is bounded independantly of $k$. If $|x| \leq N$, there are integers $k_1, \dots, k_N > 0$ such that $|x - k_i| \leq 2i$, so
  %
  \[ f(x) \geq \sum_{i = 1}^N \frac{1}{|x - k_i|} \geq \sum_{i = 1}^N \frac{1}{2i} \gtrsim \log(N). \]
  %
  Thus $\| f \|_{1,\infty} \gtrsim N \log N \gtrsim \log N \sum \| f_k \|_{1,\infty}$.
\end{example}

The weak $L^p$ norms provide another monotone translation invariant norm, and it oftens comes up when finer tuning is needed in certain interpolation arguments, especially when dealing with maximal functions.

\begin{example}
  If $f = H \mathbf{I}_E$, with $|E| = W$, then
  %
  \[ F(t) = W \cdot \mathbf{I}_{[0,H)}. \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \sup_{0 \leq t < H} W t^p \right)^{1/p} = W^{1/p} H^p = \| f \|_p. \]
  %
  If $f = H_1 \mathbf{I}_{E_1} + H_2 \mathbf{I}_{E_2}$, with $|E_1| = W_1$ and $|E_2| = W_2$, with $H_1 \leq H_2$, then
  %
  \[ F(t) = \begin{cases} W_1 + W_2 &: t < H_1, \\ W_2 &: t < H_2, \\ 0 &: \text{otherwise.} \end{cases} \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \max((W_1 + W_2) H_1^p, W_2 H_2^p) \right)^{1/p} = \max((W_1 + W_2)^{1/p} H_1, W_2^{1/p} H_2). \]
\end{example}

\begin{example}
    The function $f(x) = 1/|x|^s$ does not lie in any $L^p(\RR^d)$, but lies in $L^{p,\infty}$ precisely when $p = d/s$, since
    %
    \[ \left| \{ 1/|x|^{ps} > t \} \right| = \left| \left\{ |x| \leq \frac{1}{t^{1/ps}} \right\} \right|\ \propto_d\ \frac{1}{t^{d/ps}}. \]
\end{example}

Before we move on, we consider a form of duality for the weak $L^p$ norm, at least when $p > 1$.

\begin{theorem}
	If $p > 1$, and $X$ is $\sigma$-finite, then
	%
	\[ \| f \|_{p,\infty} \sim_p \sup_{|E| < \infty} \frac{1}{|E|^{1-1/p}} \int_E |f(x)|\; dx \]
\end{theorem}
\begin{proof}
	Suppose $\| f \|_{p,\infty} < \infty$. If we write $f = \sum f_k$, where $f_k = \mathbf{I}_{F_k} f$, and $F_k = \{ x: 2^{k-1} < |f(x)| \leq 2^k \}$, then $|F_k| \leq \| f \|_{p,\infty}^p 2^{-kp}$. Thus
	%
	\[ \left| \int_E |f_k(x)| \right| \leq 2^k \| f \|_{p,\infty}^p 2^{-kp} = \| f \|_{p,\infty}^p 2^{k(1-p)}. \]
	%
	Fix some integer $n$. Then
	%
	\begin{align*}
		\int_E |f(x)|\; dx &\leq \sum_{k = -\infty}^{n-1} \int_E |f_k(x)|\; dx + \sum_{k = n}^\infty \int_E |f_k(x)|\; dx\\
		&\leq |E| 2^{n-1} + \| f \|_{p,\infty}^p \sum_{k = n}^\infty 2^{k(1-p)}\\
		&\lesssim_p |E| 2^n + \| f \|_{p,\infty}^p 2^{-k(1-p)}.
	\end{align*}
	%
	If we let $2^n \sim \| f \|_{p,\infty} |E|^{1/p}$, then we conclude
	%
	\[ \int_E |f(x)|\; dx \lesssim_p |E|^{1 - 1/p} \| f \|_{p,\infty}. \]
	%
	Conversely, write
	%
	\[ A = \sup_{|E| < \infty} \frac{1}{|E|^{1-1/p}} \int_E |f(x)|\; dx/ \]

	%
	If $G_t = \{ x: |f(x)| \geq t \}$, then
	%
	\[ |G_t| \leq \frac{1}{t} \int_{G_t} |f(x)|\; dx \leq \frac{A |G_t|^{1 - 1/p}}{t}, \]
	%
	so
	%
	\[ |G_t| \leq \frac{A^p}{t}, \]
	%
	which gives $\| f \|_{p,\infty} \leq A$.
\end{proof}

For $p \leq 1$, the spaces $L^{p,\infty}(X)$ are not normable, as seen by the tightness of the Stein-Weiss inequality. Nonetheless, we still have a certain `duality' property, that is often useful in the analysis of operators on these spaces. Most useful is it's application when $p = 1$.

\begin{theorem} \label{weakdualitytheorem}
  Let $0 < p < \infty$, and let $f \in L^{p,\infty}(X)$, and let $\alpha \in (0,1)$. Then the following are equivalent:
  %
  \begin{itemize}
    \item $\| f \|_{p,\infty} \lesssim_{\alpha,p} A$.

    \item For any set $E \subset X$ with finite measure, there is $E' \subset E$ with $|E'| \geq \alpha |E|$ such that
    %
    \[ \int_{E'} |f(x)|\; dx \lesssim_{\alpha,p} A |E'|^{1 - 1/p}. \]
  \end{itemize}
\end{theorem}
\begin{proof}
  By homogeneity, assume $\| f \|_{p,\infty} \leq 1$, so that if $F$ is the distribution of $f$, $F(t) \leq 1/t^p$. If $|E| = (1-\alpha)^{-1} / t_0^p$, and we set
  %
  \[ E' = \{ x: |f(x)| \leq t_0 \}, \]
  %
  then
  %
  \[ |E'| \geq |E| - F(t_0) = \frac{(1 - \alpha)^{-1} - 1}{t_0^p} = \alpha |E|, \]
  %
  and
  %
  \[ \int_{E'} |f(x)| \leq t_0 |E'| \lesssim_\alpha |E'|^{1-1/p}. \]
  %
  Conversely, suppose Property (2) holds. For each $k$, set
  %
  \[ E_k = \{ x: 2^k \leq |f(x)| < 2^{k+1} \}. \]
  %
  Then there exists $E_k'$ with $|E_k'| \geq \alpha |E_k|$ and
  %
  \[ \int_{E_k'} |f(x)|\; dx \leq |E_k'|^{1 - 1/p} \]
  %
  On the other hand,
  %
  \[ \int_{E_k'} |f(x)|\; dx \geq 2^k |E_k'|. \]
  %
  Rearranging this equation gives $|E_k'| \leq 2^{-pk}$, and so $|E_k| \lesssim_\alpha 2^{-pk}$. But this means
  %
  \[ F(2^N) = \sum_{k = N}^\infty |E_k| \lesssim_{\alpha,p} 2^{-Np}, \]
  %
  and this implies $\| f \|_{p,\infty} \lesssim_{\alpha,p} 1$.
\end{proof}

\section{Lorentz Spaces}

Recall that we can write
%
\[ \| f \|_p = \left( p \int_0^\infty F(t) t^p \frac{dt}{t} \right)^{1/p}. \]
%
Thus $F(t) t^p$ is integrable with respect to the Haar measure on $\RR^+$. But if we change the integrality condition to the condition that $F(t) t^p \in L^q(\RR^+)$ for some $0 < q \leq \infty$, we obtain a different integrability condition, giving rise to a monotone, translation-invariant norm. Thus leads us to the definition of the \emph{Lorentz norms}. For each $0 < p,q < \infty$, we define the Lorentz norm
%
\[ \| f \|_{p,q} = p^{1/q} \| t F^{1/p} \|_{L^q(\RR^+)} \]
%
The \emph{Lorentz space} $L^{p,q}(X)$ as the space of functions $f$ with $\| f \|_{p,q} < \infty$. We can define the norm in terms of $f^*$ as well.

\begin{lemma}
  For any measurable $f: X \to \RR$, $\| f(t) \|_{p,q} = \| s^{1/p} f^*(s) \|_{L^q(\RR^+)}$.
\end{lemma}
\begin{proof}
  First, assume $f^*$ has non-vanishing derivative on $(0,\infty)$, and that $f$ is bounded, with finite support. An integration by parts gives
  %
  \[ \| f \|_{p,q} = p^{1/q} \left( \int_0^\infty t^{q-1} F(t)^{q/p}\; dt \right)^{1/q} = \left( \int_0^\infty t^q F(t)^{q/p - 1} (-F'(t))\; dt \right)^{1/q}. \]
  %
  If we set $s = F(t)$, then $f^*(s) = t$, and $ds = F'(t) dt$, and so
  %
  \[ \left( \int_0^\infty t^q F(t)^{q/p - 1} F'(t)\; dt \right)^{1/q} = \left( \int_0^\infty f^*(s)^q s^{q/p - 1} ds \right)^{1/q} = \| s^{1/p} f^* \|_{L^q(\RR^+)}. \]
  %
  This gives the result in this case. The general result can then be obtained by applying the monotone convergence theorem to an arbitrary $f^*$ with respect to a family of smooth functions.
\end{proof}

The definition of the Lorentz space may seem confusing, but we really only require various special cases in most applications. Aside from the weak $L^p$ norms $\| \cdot \|_{p,\infty}$ and the $L^p$ norms $\| \cdot \|_p = \| \cdot \|_{p,p}$, the $L^{p,1}$ norms and $L^{p,2}$ norms also occur, the first, because of the connection with integrability, and the second because we may apply orthogonality techniques. As $q \to 0$, the norms $\| \cdot \|_{p,q}$ give stronger control over the function $f$.

\begin{theorem}
    For $q < r$, $\| f \|_{p,r} \lesssim_{p,q,r} \| f \|_{p,q}$.
\end{theorem}
\begin{proof}
    First we treat the case $r = \infty$. We have
    %
    \begin{align*}
        s_0^{1/p} f^*(s_0) &= \left( (p/q) \int_0^{s_0} [s^{1/p} f^*(s_0)]^q \frac{ds}{s} \right)^{1/q}\\
        &\leq \left( (p/q) \int_0^{s_0} [s^{1/p} f^*(s)]^q \frac{ds}{s} \right)\\
        &\leq (p/q)^{1/q} \| f \|_{p,q}.
    \end{align*}
    %
    When $r < \infty$, we can interpolate, calculating
    %
    \begin{align*}
      \| f \|_{p,r} &= \left( \int_0^\infty [s^{1/p} f^*(s)]^r \frac{ds}{s} \right)^{1/r}\\
    &\leq \| f \|_{p,\infty}^{1 - q/r} \| f \|_{p,q}^{q/r} \leq (p/q)^{p(1/q - 1/r)} \| f \|_{p,q}. \qedhere
    \end{align*}
\end{proof}

The fact that multiplying a function by a constant dilates the distribution implies that the Lorentz norm is homogeneous. We do not have a triangle inequality for the Lorentz norms, but we have a quasi triangle inequality.

\begin{theorem}
	For each $p,q > 0$, $\| f_1 + f_2 \|_{p,q} \lesssim_{p,q} \| f_1 \|_p + \| f_2 \|_q$.
\end{theorem}
\begin{proof}
    We calculate that if $g = f_1 + f_2$,
    %
    \begin{align*}
    \| g \|_{p,q} &= \left( q \int_0^\infty \left[t G(t)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\leq \left( q \int_0^\infty \left[ t (F_1(t/2) + F_2(t/2))^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\lesssim \left( q \int_0^\infty \left[ t \left( F_1(t) + F_2(t) \right)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\lesssim_p \left( q \int_0^\infty t^q \left( F_1(t)^{q/p} + F_2(t)^{q/p} \right) \frac{dt}{t} \right)^{1/q}\\
    &\lesssim_q  \left( q \int_0^\infty t^q F_1(t)^{q/p} \frac{dt}{t} \right)^{1/q} +  \left( q \int_0^\infty t^q F_2(t)^{q/p} \frac{dt}{t} \right)^{1/q}\\
    &= \| f_1 \|_{p,q} + \| f_2 \|_{p,q}. \qedhere
  \end{align*}
\end{proof}

An important trick to utilizing Lorentz norms is by utilizing a dyadic layer cake decomposition. The dyadic layer cake decompositions enable us to understand a function by breaking it up into parts upon which we can control the height or width of a function. We say $f$ is a \emph{sub step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \leq W$, and $|f(x)| \leq H$. A \emph{quasi step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \sim W$ and on $E$, $|f(x)| \sim H$.

\begin{remark}
  It might seem that sub step functions of height $H$ and width $W$ can take on a great many different behaviours, rather than that of a step function with height $H$ and width $W$. However, from the point of view of monotone, translation invariant norms, this isn't so. This is because using the binary expansion of real numbers, for every sub-step function $f$ of height $H$ and width $W$, we can find sets $\{ E_k \}$ such that
  %
  \[ f(x) = H \sum_{k = 1}^\infty 2^{-k} \mathbf{I}_{E_k}, \]
  %
  where $|E_k| = 1$. Thus bounds on step functions that are stable under addition tend to automatically imply bounds on substep functions.
\end{remark}

We start by discussing the \emph{vertical dyadic layer cake decomposition}. We define, for each $k \in \ZZ$,
%
\[ f_k(x) = f(x) \mathbf{I}(2^{k-1} < |f(x)| \leq 2^k) \]
%
Then we set $f = \sum f_k$. Each $f_k$ is a quasi step function with height $2^k$ and width $F(2^{k-1}) - F(2^k)$. We can also perform a \emph{horizontal layer cake decomposition}. If we define $H_k = f^*(2^k)$, and set
%
\[ f_k(x) = f(x) \mathbf{I}(H_{k-1} < |f(x)| \leq H_k), \]
%
then $f_k$ is a substep function with height $H_k$ and width $2^k$. These decompositions are best visualized with respect to the representation $f^*$ of $f$, in which case the decomposition occurs over particular intervals.

\begin{theorem}
    The following values $A_1, \dots, A_4$ are all comparable up to absolute constant depending only on $p$ and $q$:
    %
    \begin{enumerate}
        \item \label{onebound} $\| f \|_{p,q} \leq A_1$.

        \item \label{twobound} We can write $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a quasi-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[ 2^k W_k^{1/p} \right]^q \right)^{1/q} \leq A_2. \]

        \item \label{threebound} We can write $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a sub-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[2^{k} W_k^{1/p} \right]^q \right)^{1/q} \leq A_3. \]

        \item \label{fourbound} We can write $f(x) = \sum_{k \in \ZZ} f_k$, where $f_k$ is a sub-step function with width $2^k$ and height $H_k$, where $\{ H_k \}$ is decreasing in $k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[H_k 2^{k/p} \right]^q \right)^{1/q} \leq A_4. \]
    \end{enumerate}
\end{theorem}
\begin{proof}
    It is obvious that we can always select $A_3 \leq A_2$. Next, we bound $A_2$ in terms of $A_1$ by performing a vertical layer cake decomposition on $f$. If we write $f = \sum_{k \in \ZZ} f_k$, then $f_k$ is supported on a set with measure $W_k = F(2^{k-1}) - F(2^k) \leq F(2^{k-1})$, and so
    %
    \begin{align*}
        \sum_{k \in \ZZ} [2^k W_k^{1/p}]^q &\leq \sum_{k \in \ZZ} [2^k F(2^{k-1})^{1/p}]^q\\
        &\lesssim_q \sum_{k \in \ZZ} [2^{k-1} F(2^k)^{1/p}]^q\\
        &\lesssim \sum_{k \in \ZZ} \int_{2^{k-1}}^{2^k} [tF(t)^{1/p}]^q\; \frac{dt}{t} \lesssim_q \| f \|_{p,q}^q \leq A_1^q.
    \end{align*}
    %
    Thus $A_2 \lesssim_q A_1$. Next, we bound $A_4$ in terms of $A_1$. Perform a horizontal layer cake decomposition, writing $f = \sum f_k$, where $f_k$ is supported on a set with measure $W_k \leq 2^k$, and $H_{k+1} \leq |f_k(x)| \leq H_k$. Then a telescoping sum shows
    %
    \begin{align*}
        H_k 2^{k/p} &= \left( \sum_{m = 0}^\infty (H_{k+m}^q - H_{k+m+1}^q) 2^{kq /p} \right)^{1/q}\\
        &\lesssim_q \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t 2^{k/p}]^q \frac{dt}{t} \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q}
    \end{align*}
    %
    Thus
    %
    \[ \left( \sum_{k \in \ZZ} [H_k 2^{k/p}]^q \right)^{1/q} \leq \left( \int_0^\infty [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q} \lesssim_q A_1. \]
    %
    Thus $A_4 \lesssim_q A_1$. It remains to bound $A_1$ by $A_4$ and $A_3$. Given $A_3$, we can write $|f(x)| \leq \sum 2^k \mathbf{I}_{E_k}$, where $|E_k| \leq W_k$. We then find
    %
    \[ F(2^k) \leq \sum_{m = 1}^\infty W_{k+m}. \]
    %
    Thus
    %
    \[ \int_{2^{k-1}}^{2^k} [t F(t)^{1/p}]^q \frac{dt}{t} \lesssim \left[ 2^k \left(\sum_{m = 0}^\infty W_k \right)^{1/p} \right]^q. \]
    %
    Thus if $q \leq p$,
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \ZZ} \left[2^k \left( \sum_{m = 0}^\infty W_{k+m} \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{k \in \ZZ} \sum_{m = 0}^\infty \left[ 2^k W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty 2^{-qm} \sum_{k \in \ZZ} \left[ 2^{k+m} W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( A_3^q \sum_{m = 0}^\infty 2^{-mq} \right)^{1/q} \lesssim_q A_3.
    \end{align*}
    %
    If $q \geq p$, we can employ the triangle inequality for $l^{q/p}$ to write
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \ZZ} \left[2^k \left( \sum_{m = 0}^\infty W_{k + m}  \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \left( \sum_{k \in \ZZ} 2^{kq} W_{k+m}^{q/p} \right)^{p/q} \right)^{1/p}\\
        &\leq \left( A_3^p \sum_{m = 0}^\infty 2^{-mq} \right)^{1/p} \lesssim_{p,q} A_3.
    \end{align*}
    %
    The bound of $A_1$ in terms of $A_4$ involves the same `shifting' technique, and is left to the reader.
\end{proof}

\begin{remark}
    Heuristically, the theorem above says that if $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a quasi-step function with width $H_k$ and width $W_k$, and if either $\{ H_k \}$ and $\{ W_k \}$ grow faster than powers of two, then
    %
    \[ \| f \|_{p,q} \sim_{p,q} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}. \]
    %
    Thus the $L^{p,q}$ norm has little interaction between elements of the sum when the sum occurs over dyadically different heights or width. This is one reason why we view the $q$ parameter as a `logarithmic' correction of the $L^p$ norm. In particular, if we can write $f = f_1 + \dots + f_N$, and $q_1 < q_2$, then the last equation, combined with a $l^{q_1}$ to $l^{q_2}$ norm bound, gives
    %
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^{q_1} \right)^{1/q_1} \leq N^{1/q_1 - 1/q_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^{q_2} \right)^{1/q_2} \]
    %
    This implies
    %
    \[ \| f \|_{p,q_2} \lesssim_{p,q_1,q_2} \| f \|_{p,q_1} \lesssim_{p,q_1,q_2} N^{1/q_1 - 1/q_2} \| f \|_{p,q_2}. \]
    %
    In particular, this occurs if there exists a constant $C$ such that $C \leq |f(x)| \leq C \cdot 2^N$ for all $x$. On the other hand, if we vary the $p$ parameter, we find that for $p_1 < p_2$,
    %
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} \leq \max(W_k)^{1/p_1 - 1/p_2} \left( \sum_{k \in \ZZ} \left[H_k W_k^{1/p_2} \right]^q \right)^{1/q}, \]
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} \leq \left( \frac{1}{\min(W_k)} \right)^{1/p_1 - 1/p_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q}. \]
    %
    which gives
    %
    \[ \min(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q} \lesssim_{p_1,p_2,q} \| f \|_{p_1,q} \lesssim_{p_1,p_2,q} \max(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q}. \]
    %
    Both of these inequalities can be tight. Because of the dyadic decomposition of $f$, we find $\max(W_k) \geq 2^N \min(W_k)$, so these two norms can differ by at least $2^{N(1/p_1 - 1/p_2)}$, and at \emph{most} if the $f_k$ occur over consecutive dyadic values, which is \emph{exponential} in $N$. Conversely, if the heights change dyadically, we find that
    % q = q'p_2/p-1
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} &\leq \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^{qp_2/p_1} \right)^{(p_1/p_2)/q}\\
        &\leq \max(H_k)^{1 - p_1/p_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{(p_1/p_2)/q}
    \end{align*}
    %
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} &\lessapprox \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^{qp_1/p_2} \right)^{(p_2/p_1)/q}\\
        &\leq \left( \frac{1}{\min(H_k)} \right)^{p_2/p_1 - 1} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{(p_2/p_1)/q}
    \end{align*}
    %
    where $\lessapprox$ denotes a factor ignoring polynomial powers of $N$ occuring from the estimate. Thus
    %
    \[ \min(H_k)^{p_2 - p_1} \| f \|_{p_1,q}^{p_1} \lessapprox_{p_1,p_2,q} \| f \|_{p_2,q}^{p_2} \lesssim_{p_1,p_2,q} \max(H_k)^{p_2-p_1} \| f \|_{p_1,q}^{p_1} \]
    %
    again, these inequalities can be both tight, and $\max(H_k) \geq 2^N \min(H_k)$, with equality if the quasi step functions from which $f$ is composed occur consecutively dyadically.
\end{remark}

\begin{example}
    Consider the function $f(x) = |x|^{-s}$. For each $k$, let
    %
    \[ E_k = \{ x : 2^{-(k+1)/s} \leq |x| < 2^{-k/s} \} \]
    %
    and define $f_k = f \mathbf{I}_{E_k}$. Then $f_k$ is a quasi-step function with height $2^k$, and width $1/2^{dk/s}$. We conclude that if $p = d/s$, and $q < \infty$,
    %
    \[ \| f \|_{p,q} \sim_{p,q,d} \left( \sum_{k = -\infty}^\infty 2^{qk(1 - d/ps)} \right)^{1/q} = \infty. \]
    %
    Thus the function $f$ lies exclusively in $L^{p,\infty}(\RR^d)$.
\end{example}

A simple consequence of the layer cake decomposition is H\"{o}lder's inequality for Lorentz spaces.

\begin{theorem}
    If $0 < p_1,p_2,p < \infty$ and $0 < q_1,q_2,q < \infty$ with
    %
    \[ 1/p = 1/p_1 + 1/p_2 \quad \text{and} \quad 1/q \geq 1/q_1 + 1/q_2, \]
    %
    then
    %
    \[ \| f g \|_{p,q} \lesssim_{p_1,p_2,q_1,q_2} \| f \|_{p_1,q_1} \| g \|_{p_2,q_2}. \]
\end{theorem}
\begin{proof}
    Without loss of generality, assume $\| f \|_{p_1,q_1} = \| g \|_{p_2, q_2} = 1$ and that $1/q = 1/q_1 + 1/q_2$. Perform horizontal layer cake decompositions of $f$ and $g$, writing $|f| \leq \sum_{k \in \ZZ} H_k \mathbf{I}_{E_k}$ and $|g| \leq \sum_{k \in \ZZ} H_k' \mathbf{I}_{F_k}$, where $|E_k|, |F_k| \leq 2^k$. Then
    %
    \[ |fg| \leq \sum_{k,k' \in \ZZ} H_k H_k' \mathbf{I}_{E_k \cap F_{k'}} \]
    %
    For each fixed $k$, $|E_{k + m} \cap F_m| \leq 2^m$, and so
    %
    \begin{align*}
        \left\| \sum_{m \in \ZZ} H_{k + m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q} &\lesssim_{p,q} \left( \sum_{m \in \ZZ} [H_{k+m} H_m' 2^{m/p}]^q \right)^{1/q}\\
        &= \left( \sum_{m \in \ZZ} \left[ (H_{k+m} 2^{m/p_1}) (H_m 2^{m/p_2}) \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m \in \ZZ} [H_{k+m} 2^{m/p_1} ]^{q_1} \right)^{1/q_1} \left( \sum_{m \in \ZZ} [H_m' 2^{m/p_2}]^{q_2} \right)^{1/q_2}\\
        &\lesssim_{p,q,p_1,q_1,p_2,q_2} 2^{-k/p_1}\\
    \end{align*}
    %
    Summing over $k > 0$ gives that
    %
    \[ \left\| \sum_{k \geq 0} \sum_{m \in \ZZ} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\| \lesssim_{p,q,p_1,q_1,p_2,q_2} 1 \]
    %
    By the quasitriangle inequality, it now suffices to obtain a bound
    %
    \[ \left\| \sum_{k < 0} \sum_{m \in \ZZ} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q}. \]
    %
    This is done similarily, but using the bound $|E_{k+m} \cap F_m| \leq 2^{k+m}$ instead of the other bound.
\end{proof}

\begin{corollary}
    If $p > 1$ and $q > 0$, $L^{p,q}(X) \subset L^1_{\text{loc}}(X)$.
\end{corollary}
\begin{proof}
    Let $E$ have finite measure and let $f \in L^{p,q}(X)$. Then the H\"{o}lder's inequality for Lorentz spaces shows
    % 1 = 1/p + 1/p_2 = 1/q + 1/q_2
    %
    \[ \| f \|_{L^1(E)} = \| \mathbf{I}_E f \|_{L^1(X)} \lesssim_{p,q} |E|^{1 - 1/p} \| f \|_{p,q} < \infty. \qedhere \]
\end{proof}

A consequence of H\"{o}lder's inequality is a duality of the $L^{p,q}$ norms. If $1 < p < \infty$, and $1 < q < \infty$, then $L^{p,q}(X)^* = L^{p',q'}(X)$. When $q = 1$ or $q = \infty$, things are more complex, but the following theorem often suffices. When $p = 1$, things get more tricky, so we leave this case out.

\begin{theorem}
    Let $1 < p < \infty$ and $1 \leq q < \infty$. Then if $f \in L^{p,q}(X)$,
    %
    \[ \| f \|_{p,q} \sim \sup \left\{ \int fg : \| g \|_{p',q'} \leq 1 \right\}. \]
\end{theorem}
\begin{proof}
    Without loss of generality, we may assume $\| f \|_{p,q} = 1$. We may perform a vertical layer cake decomposition, writing $f = \sum_{k \in \ZZ} f_k$, where $2^{k-1} \leq |f_k(x)| \leq 2^k$, is supported on a set with width $W_k$, and
    %
    \[ \left( (2^k W_k^{1/p})^q \right) \sim_{p,q} 1. \]
    %
    Define $a_k = 2^k W_k^{1/p}$, and set $g = \sum_{k \in \ZZ} g_k$, where $g_k(x) = a_k^{q-p} \text{sgn}(f_k(x)) |f_k(x)|^{p-1}$. Then
    %
    \begin{align*}
        \int f(x) g(x) &= \sum_{k \in \ZZ} \int f_k(x) g_k(x) = \sum_{k \in \ZZ} a_k^{q-p} \int |f_k(x)|^p\\
        &\gtrsim_p \sum_{k \in \ZZ} a_k^{q-p} W_k 2^{kp} = \sum_{k \in \ZZ} a_k^q \gtrsim_{p,q} 1.
    \end{align*}
    %
    We therefore need to show that $\| g \|_{p',q'} \lesssim 1$. We note $|g_k(x)| \lesssim a_k^{q-p} 2^{kp}$, and has width $W_k$. The gives a decomposition of $g$, but neither the height nor the widths necessarily in powers of two. Still, we can fix this since the heights increase exponentially; define
    %
    \[ H_k = \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2}. \]
    %
    Then $|g_k(x)| \lesssim_{p,q} H_k$, and $H_{k+1} \geq 2^{p/2} H_k$. In particular, if we pick $m$ such that $2^{mp/2} \geq 1$, then for any $l \leq m$, the sequence $H_{km + l}$, as $k$ ranges over values, increases dyadically, and so by the quasitriangle inequality for the $L^{p',q'}$ norm, and then the triangle inequality in $l^q$, we find
    % W_k = a_k^p/ 2^{kp}
    \begin{align*}
        \| g \|_{p',q'} &\lesssim_{m,p,q} \left( \sum [H_k W_k^{1/p'}]^{q'} \right)^{1/q'}\\
        &\lesssim \left( \sum_{k \in \ZZ} \left[ \left( \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2} \right) (a_k 2^{-k})^{p-1} \right]^{q'} \right)^{1/q'}\\
        &\lesssim_p \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} \sum_{l = 0}^\infty a_{k-l}^{q-p} 2^{-lp/2} \right]^{q'} \right)^{1/q'}\\
        &\lesssim \sum_{l = 0}^\infty 2^{-lp/2} \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'}.
    \end{align*}
    %
    Applying's H\"{o}lder's inequality shows
    %
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'} &\leq  \left( \sum_{k \in \ZZ} a_k^q \right)^{(p-1)/q} \left( \sum_{k \in \ZZ} a_{k-l}^q \right)^{(q-p)/q}\\
        &\lesssim_{p,q} \| f \|_{p,q}^{q-1} \lesssim_{p,q} 1. \qedhere
    \end{align*}
\end{proof}

\begin{remark}
    This technique shows that if $f = \sum f_k$, where $f_k$ is a quasi-step function with measure $W_k$ and height $2^{ck}$, then we can find $m$ such that $cm > 1$, and then consider the $m$ functions $f^1, \dots, f^m$, where $f_i = \sum f_{km + i}$. Then the functions $f_{km + i}$ have heights which are separated by powers of two, and so the quasi-triangle inequality implies
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_m \sum_{i = 1}^m \| f^i \|_{p,q}\\
        &\lesssim_{p,q} \sum_{i = 1}^m \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\lesssim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}
    \end{align*}
    %
    On the other hand,
    %
    \begin{align*}
        \| f \|_{p,q} &\gtrsim \max_{1 \leq i \leq m} \| f^i \|_{p,q}\\
        &\sim \max_{1 \leq i \leq m} \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\gtrsim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}.
    \end{align*}
    %
    Thus the dyadic layer cake decomposition still works in this setting.
\end{remark}

We remark that if $1 < p < \infty$ and $1 \leq q \leq \infty$, then for each $f \in L^{p,q}$, the value
%
\[ \sup \left\{ \int fg : \| g \|_{p',q'} \leq 1 \right\} \]
%
gives a norm on $L^{p,q}(X)$ which is comparable with the $L^{p,q}$ norm. In particular, this implies that for $p > 1$ and $q \geq 1$,
%
\[ \| f_1 + \dots + f_N \|_{p,q} \lesssim_{p,q} \| f_1 \|_{p,q} + \dots + \| f_N \|_{p,q}, \]
%
so that the triangle inequality has constants independent of $N$. We can also use a layer cake decomposition to get a version of the Stein-Weiss inequality for Lorentz norms.

\begin{theorem}
	For each $1 < q < \infty$, there is $\alpha(q) > 0$ such that for any functions $f_1, \dots, f_N$,
	%
	\[ \| f_1 + \dots + f_N \|_{1,q} \lesssim (\log N)^{\alpha(q)} \left( \| f_1 \|_{1,q} + \dots + \| f_N \|_{1,q} \right). \]
\end{theorem}
\begin{proof}
	For values $A$ and $B$ in this argument, we write $A \lessapprox B$ if there exists $\alpha$ such that $A \lesssim (\log N)^\alpha B$. Given $f_1, \dots, f_N$, write $f_i = \sum_{j = -\infty}^\infty f_{ij}$, where $f_{ij}$ has width $W_{ij}$ and height $2^j$. If we assume, without loss of generality, that $\| f_1 \|_{1,q} + \dots + \| f_N \|_{1,q} = 1$, then
	%
	\[ \sum_{i = 1}^N \left( \sum_{j = -\infty}^\infty (2^j W_{ij})^q \right)^{1/q} \lesssim_q 1 \]
	%
	Thus we want to show $\| f_1 + \dots + f_N \|_{1,q} \lessapprox_q 1$. Our first goal is to upper bound the measure of the set
	%
	\[ E = \{ x: 2^{k-1} < |f_1(x) + \dots + f_N(x)| \leq 2^k  \} \]
	%
	The measure of the set $E$ is upper bounded by the measure of the set
	%
	\[ E' = \left\{ x: 2^{k-2} < \left|\sum_{j = k - \lg(N)}^k f_{1j}(x) + \dots + f_{Nj}(x) \right| \leq 2^{k+1} \right\} \]
	%
	Applying the usual Stein-Weiss inequality, we have
	%
	\[ \left\| \sum_{i = 1}^N \sum_{j = k - \lg N}^k f_{ij} \right\|_{1,\infty} \lessapprox \sum_{i = 1}^N \sum_{j = k - \lg N}^k \| f_{ij} \|_{1,\infty} \lesssim \sum_{i = 1}^N \sum_{j = k - \lg N}^k \| f_{ij} \|_{1,\infty} \lesssim_q \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \]
	%
	Thus we conclude
	%
	\[ |E'| \lessapprox_q 2^{-k} \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \]
	%
	This implies that
	%
	\[ \| f_1 + \dots + f_N \|_{1,q} \lessapprox_q \left( \sum_{k = -\infty}^\infty \left( \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \right)^q \right)^{1/q}. \]
	%
	Applying Minkowski's inequality, we conclude
	%
	\begin{align*}
		\left( \sum_{k = -\infty}^\infty \left( \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \right)^q \right)^{1/q} &\lesssim \sum_{i = 1}^N \left( \sum_{k = -\infty}^\infty \left( \sum_{j = k - \lg N}^k W_{ij 2^j} \right)^q \right)^{1/q}\\
		&\lessapprox \sum_{i = 1}^N \left( \sum_{k = -\infty}^\infty \sum_{j = k - \lg N}^k W_{ij}^q 2^{qj} \right)^{1/q}\\
		&\lessapprox \sum_{i = 1}^N \left( \sum_{j = -\infty}^\infty W_{ij}^q 2^{qj} \right)^{1/q} \lesssim 1. \qedhere
	\end{align*}
\end{proof}

\begin{comment}

\section{Normability of the Lorentz Spaces}

Though the Lorentz norms do not satisfy the triangle inequality, the space $L^{p,q}(X)$ is still a `Banach-able' space when $p > 1$, and $q \geq 1$. First off, the standard proof shows the norm gives a complete quasimetric, since a Cauchy sequence in the $L^{p,q}$ norm converges to a function almost everywhere, which is easily verified to have finite $L^{p,q}$ norm. The easiest way to define a norm is to through the decreasing rearrangement.

\begin{lemma}
    For any measurable set $E$,
    %
    \[ \int_E |f(x)|\; dx \leq \int_0^{|E|} f^*(t)\; dt. \]
    %
    and
    %
    \[ \int_{\{ |f(x)| > t \}} |f(x)|\; dx = \int_0^{F(t)} f^*(t)\; dt. \]
\end{lemma}
\begin{proof}
    If $g \leq f$, $g^* \leq f^*$. Thus $(\chi_E f)^* \leq f^*$, so
    %
    \[ \int_E |f(x)|\; dx = \int \chi_E |f(x)| = \int_0^\infty (\chi_E f)^*(t)\; dt = \int_0^{|E|} (\chi_E f)^*(t)\; dt \leq \int_0^{|E|} f^*(t)\; dt. \]
    %
    On the other hand, $(\chi_E f)^* = f^*$ when $E = \{ |f(x)| > t \}$, which gives the second equality.
\end{proof}

For a function $f$ and $t > 0$, we define a family of averages
%
\[ m(t) = \frac{1}{t} \int_0^t f^*(t)\; dt. \]
%
For any fixed $t > 0$, the map $f \mapsto m(t)$ is a norm. Provided our measure space is non-atomic, we have
%
\[ m(t) = \sup_{|E| \leq t} \int_E |f(x)|\; d\mu. \]
%
We define
%
\[ \vvvert f \vvvert_{p,q} = \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} \]
and
%
\[ \vvvert f \vvvert_{p,\infty} = \sup t^{1/p} m(t). \]
%
For $q \geq 1$, each of these functions is a norm, simply because the function $m$ is a norm. On the other hand, since $f^*$ is decreasing, $f^*(t) \leq m(t)$ for all $t$, which shows $\vvvert f \vvvert_{p,q} \geq \| f \|_{p,q}$. If $p = 1$ and $q < \infty$, if $\vvvert f \vvvert_{1,q} < \infty$, then $f = 0$, so these norms are effectively useless. If $q = \infty$, then
%
\[ \vvvert f \vvvert_{1,\infty} = \| f^* \|_{L^1[0,\infty)} = \| f \|_1, \]
%
and therefore doesn't measure the correct norm. But in all other cases, i.e. for $p > 1$ and $q \geq 1$, the norm is comparable to the $L^{p,q}$ norm.

\begin{theorem}
    If $p > 1$,
    %
    \[ \vvvert f \vvvert_{p,q} \leq \frac{p}{p-1} \| f \|_{p,q}. \]
\end{theorem}
\begin{proof}
    We utilize a \emph{Hardy's inequality} technique, which shows that the $L^p$ norm of the averages of a function are comparable to the $L^p$ norm of the function. Applying Minkowski's integral inequality, we conclude that
    %
    \begin{align*}
        \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} &= \left( \frac{q}{p} \int_0^\infty \left( \int_0^1 t^{1/p} f^*(ts)\; ds \right)^q\; \frac{dt}{t} \right)^{1/q}\\
        &\leq \int_0^1 \left( \int_0^\infty \frac{q}{p} (t^{1/p} f^*(ts))^q\; \frac{dt}{t} \right)^{1/q}\; ds\\
        &\leq \left( \int_0^1 s^{- 1/p}\; ds \right) \left( \frac{q}{p} \int_0^\infty (t^{1/p} f^*(t))^q\; \frac{dt}{t} \right)^{1/q}\\
        &\leq \frac{1}{1 - 1/p} \| f \|_{p,q} = \frac{p}{p - 1} \| f \|_{p,q}.
    \end{align*}
    %
    For $q = \infty$, and $t > 0$, we have
    %
    \begin{align*}
        t^{1/p} m(t) &= t^{1/p - 1} \int_0^t f^*(t)\\
        &\leq (\sup_{s > 0} s^{1/p} f^*(s)) t^{1/p - 1} \int_0^t t^{-1/p}\\
        &= \frac{1}{1 - 1/p} \| f \|_{p,\infty} = \frac{p}{p-1} \| f \|_{p,\infty}.
    \end{align*}
    %
    since $t$ was arbitrary, this gives the required bound.
\end{proof}

\end{comment}

Here is an interesting weighted inequality whose proof utilizes the layer cake decomposition. I first encountered this inequality in Heo, Nazarov, and Seeger's paper \emph{Radial Fourier Multipliers in High Dimensions}.

\begin{theorem}
  Suppose that $\{ f_n \}$ is a family of functions, fix $p_0 < p_\theta < p_1$. Then
  %
  \[ \| \sum_n f_n \|_{L^p(X)} \lesssim_{p_0,p,p_1} \left( \sum_n \max_i \left\{ 2^{n(p - p_i)} \| f_n \|_{p_i,\infty}^{p_i} \right\} \right)^{1/p} \]
  %
  In particular, if $\| f_n \|_{p_i,\infty} \leq C 2^n W_n^{1/p_i}$ for each $n$, then
  %
  \[ \| \sum_n f_n \|_{L^p(X)} \lesssim_{p_0,p,p_1} C \left( \sum_n 2^{pn} W_n \right)^{1/p}. \]
  %
  This might hold, for instance, if $f_n$ is a sub step function with height $2^n$ and width $W_n$ for each $n$.
\end{theorem}
\begin{proof}
  Define $f_{nm} = f_n \cdot \mathbf{I}(2^{n+m} \leq |f_n| < 2^{n+m+1})$. Then $f_n = \sum_m f_{nm}$. For each fixed $m$, define $\tilde{f}_m = \sum_n f_{nm}$. Since $f_{nm} \approx 2^{n+m}$, $f_m$ is defined by a sum over different dyadic scales, and so we have a pointwise bound
  %
  \[ |\sum_n f_{nm}| \sim \max \{ 2^m : f_{nm} \neq 0 \} \sim_p \left( \sum_n |f_{nm}|^p \right)^{1/p}. \]
  %
  Thus we find
  %
  \[ \| \tilde{f}_m \|_{L^p(X)} \lesssim_p \left\| \left( \sum_n |f_{nm}|^p \right)^{1/p} \right\|_{L^p(X)} = \left( \sum_n \| f_{nm} \|_{L^p(X)}^p \right)^{1/p}. \]
  %
  Chebyshev's inequality implies that
  %
  \begin{align*}
    \| f_{nm} \|_{L^p(X)}^p &\leq 2^{(n+m)p} \cdot \min_i \{ 2^{-(n+m) p_i} \| f_n \|_{L^{p_i,\infty}(X)}^{p_i} \}\\
    &\lesssim \min_i \{ 2^{(n+m)(p - p_i)} \| f_n \|_{L^{p_i,\infty}(X)}^{p_i} \}.
  \end{align*}
  %
  But this means that if $m \geq 0$,
  %
  \[ \| \tilde{f}_m \|_{L^p(X)} \lesssim_p 2^{-|m|(p_1/p - 1)} \left( \sum_n 2^{-n(p_1 - p)} \| f_n \|_{L^{p_1,\infty}(X)}^{p_1} \right)^{1/p} \]
  %
  and for $m \leq 0$,
  % 
  \[ \| \tilde{f}_m \|_{L^p(X)} \lesssim_p 2^{-|m|(1 - p_0/p)} \left( \sum_n 2^{n(p - p_0)} \| f_n \|_{L^{p_0,\infty}(X)}^{p_0} \right)^{1/p} \]
  %
  Applying the triangle inequality to $\| \sum f_n \|_{L^p(X)} = \| \sum \tilde{f}_m \|_{L^p(X)}$ and summing over $m$ completes the proof.
\end{proof}

\section{Mixed Norm Spaces}

Given two measure spaces $X$ and $Y$, we can form the product measure space $X \times Y$. If we have a norm space $V$ of functions on $X$, with norm $\| \cdot \|_V$ and a norm space $W$ of functions on $Y$, with norm $\| \cdot \|_W$, we can consider a `product norm'; for each function $f$ on $X \times Y$, we can consider the function $y \mapsto \| f(\cdot,y) \|_V$, and take the norm of this function over $Y$, i.e. $\| \| f(\cdot,y) \|_V \|_W$. The most important case of this process is where we fix $0 < p,q \leq \infty$, and consider
%
\[ \| f \|_{L^p(X) L^q(Y)} = \left( \int \left( \int |f(x,y)|^p \; dx \right)^{q/p}\; dy \right)^{1/q}. \]
%
Similarly, we can define $\| f \|_{L^q(Y) L^p(X)}$. We have a duality theory here; for each $1 \leq p,q < \infty$ and any $f$ with $\| f \|_{L^p(X) L^q(Y)} < \infty$, the standard $L^p$ and $L^q$ duality gives
%
\[ \| f \|_{L^p(X) L^q(Y)} = \sup \left\{ \int_{X \times Y} f(x,y) h(x,y)\; dx\;dy : \| h \|_{L^{p^*}(X) L^{q^*}(Y)} \leq 1 \right\}. \]
%
It is often important to interchange norms, and we find the biggest quantity obtained by interchanging norms is always obtained with the largest exponents on the inside.

\begin{theorem}
	If $q \geq p \geq 1$, $\| f \|_{L^p(X) L^q(Y)} \leq \| f \|_{L^q(Y) L^p(X)}$.
\end{theorem}
\begin{proof}
  If $p = q$, then the Fubini-Tonelli theorem implies that
  %
  \[ \| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)}. \]
  %
  If $p = 1$, then this result is precisely the Minkowski inequality. We now apply complex interpolation to obtain the result in general. In fact, a simple variation of the proof of Riesz-Thorin using the duality established above gives the result.
\end{proof}

Let us consider two special case. Firstly, bounds for the pointwise maxima of functions dominate the maximum $L^p$ norms
%
\[ \sup_n \| f_n \|_{L^p(X)} \leq \left\| \sup_n f_n \right\|_{L^p(X)}. \]
%
Secondly, a special case is the triangle inequality
%
\[ \left\| \sum_n f_n \right\|_{L^p(X)} \leq \sum_n \| f_n \|_{L^p(X)} \]
%
for $p \geq 1$.

It turns out that if $q > p$ and $\| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)}$, then $|f|$ is a tensor product. Thus switching mixed norms is likely only efficient if the functions we are working with are close to tensor products.

\begin{theorem}
  Suppose $q > p$, $f$ is a function on $X \times Y$, and
  %
  \[ \| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)} < \infty. \]
  %
  Then there exists $f_1(x)$ and $f_2(y)$ such that for any $x \in X$ and $y \in Y$, $|f(x,y)| = |f_1(x)| |f_2(y)|$.
\end{theorem}
\begin{proof}
  Expanding this equation out, we conclude
  %
  \[ \left( \int_Y \left( \int_X |f(x,y)|^p\; dx \right)^{q/p}\; dy \right)^{1/q} = \left( \int_X \left( \int_Y |f(x,y)|^q\; dy \right)^{p/q}\; dx \right)^{1/p}. \]
  %
  Setting $g(x,y) = |f(x,y)|^p$, we see that Minkowski's integral inequality is tight for $g$, i.e.
  %
  \[ \left( \int_Y \left( \int_X |g(x,y)|\; dx \right)^{q/p}\; dy \right)^{p/q} = \left( \int_X \left( \int_Y |g(x,y)|^{q/p}\; dy \right)^{p/q}\; dx \right). \]
  %
  Thus it suffices to show that to show the theorem for $p = 1$ and $q > 1$. Recall the standard proof of Minkowski's inequality, i.e. that by H\"{o}lder's inequality
  %
  \begin{align*}
    \int_Y \left( \int_X |f(x,y)|\; dx \right)^p\; dy &= \int_X \left[ \int_Y |f(x_1,y)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^{p-1}\; dy \right]\; dx_1\\
    &\leq \int_X \left[ \left( \int_Y |f(x_1,y)|^p\; dy \right)^{1/p} \left( \int_Y \left( \int_X |f(x_2,y)|\; dx_2 \right)^{(p-1)p^*}\; dy \right)^{1/p^*} \right]\; dx_1 \\
    &= \left[ \int_X \left( \int_Y |f(x_1,y)|^p\; dy \right)^{1/p}\; dx_1 \right] \left[ \int_Y \left( \int_X |f(x_2,y)|\; dx_2 \right)^p \right]^{1/p^*}.
  \end{align*}
  %
  and rearranging gives Minkowski's inequality. If this inequality is tight, then our application of H\"{o}lder's inequality is tight for almost every $x_1 \in X$. Since $\int |f(x_2,y)|\; dx_2 \neq 0$ for all $y$ unless $f = 0$, it follows that there exists $\lambda(x_1)$ for almost every $x_1 \in X$ such that for almost every $y \in Y$,
  %
  \[ |f(x_1,y)|^p = |\lambda(x_1)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^{p^*(p-1)} = |\lambda(x_1)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^p. \]
  %
  Setting $f_1(x) = |\lambda(x)|^{1/p}$ and $f_2(y) = \int_X |f(x,y)|\; dx$ thus completes the proof.
\end{proof}

\section{Orlicz Spaces}

To develop the class of Orlicz spaces, we note that if $\| f \|_p \leq 1$, and we set $\Phi(t) = t^p$, then
%
\[ \int \Phi \left( |f(x)| \right)\; dx = 1. \]
%
More generally, given any function $\Phi: [0,\infty) \to [0,\infty)$, we might ask if we can define a norm $\| \cdot \|_\Phi$ such that if $\| f \|_\Phi \leq 1$, then
%
\[ \int \Phi \left( |f(x)| \right)\; dx = 1. \]
%
Since a norm would be homogenous, this would imply that if $\| f \|_\Phi \leq A$, then
%
\[ \int \Phi \left( \frac{|f(x)|}{A} \right)\; dx \leq 1. \]
%
If we want these norms to be monotone, we might ask that if $A < B$, then
%
\[ \int \Phi \left( \frac{|f(x)|}{B} \right)\; dx \leq \int \Phi \left( \frac{|f(x)|}{A} \right), \]
%
and the standard way to ensure this is to ask the $\Phi$ is an increasing function. To deal with the property that $\| 0 \| = 0$, we set $\Phi(0) = 0$. In order for $\| \cdot \|_\Phi$ to be a norm, the set of functions $\{ f : \| f \|_\Phi \leq 1 \}$ needs to be convex, and the standard way to obtain this is to assume that $\Phi$ is convex.

In short, we consider an increasing, convex function $\Phi$ with $\Phi(0) = 0$. We then define
%
\[ \| f \|_\Phi = \inf \left\{ A > 0 : \int \Phi \left( \frac{|f(x)|}{A} \right)\; dx \leq 1 \right\}. \]
%
This function is a norm on the space of all $f$ with $\| f \|_\Phi < \infty$. It is easy to verify that $\| f \|_\Phi = 0$ if and only if $f = 0$ almost everywhere, and that $\| \alpha f \|_\Phi = |\alpha| \| f \|_\Phi$. To justify the triangle inequality, we note that if
%
\[ \int \Phi \left( \frac{|f(x)|}{A} \right) \leq 1 \quad\text{and} \quad \int \Phi \left( \frac{|f(x)|}{B} \right) \leq 1, \]
%
then applying convexity gives
%
\begin{align*}
    \int \Phi \left( \frac{|f(x) + g(x)|}{A + B} \right) &\leq \int \Phi \left( \frac{|f(x)| + |g(x)|}{A + B} \right)\\
    &\leq \int \left( \frac{A}{A + B} \right) \Phi \left( \frac{|f(x)|}{A} \right) + \left( \frac{B}{A + B} \right) \Phi \left( \frac{|g(x)|}{B} \right) \leq 1.
\end{align*}
%
Thus we obtain the triangle inequality.

The spaces $L^p(X)$ for $p \in [1,\infty)$ are Orlicz spaces with $\Phi(t) = t^p$. The space $L^\infty(X)$ is not really an Orlicz space, but it can be considered as the Orlicz function with respect to the `convex' function
%
\[ \Phi(t) = \begin{cases} \infty & t > 1, \\ t & t \leq 1. \end{cases} \]
%
More interesting examples of Orlicz spaces include
%
\begin{itemize}
    \item $L \log L$, given by the Orlicz norm induced by $\Phi(t) = t \log(2 + t)$.
    \item $e^L$, defined with respect to $\Phi(t) = e^t - 1$.
    \item $e^{L^2}$, defined with respect to $\Phi(t) = e^{t^2} - 1$.
\end{itemize}
%
One should not think too hard about the constants in the functions defined above, which are included to make $\Phi(0) = 0$. When we are dealing with a finite measure space (often the case, since these norms often occur in probability theory), they are irrelevant.

\begin{lemma}
  If $\Phi(x) \lesssim \Psi(x)$ for all $x$, then $\| f \|_{\Phi(L)} \lesssim \| f \|_{\Psi(L)}$. If $X$ is finite, and $\Phi(x) \lesssim \Psi(x)$ for sufficiently large $x$, then $\| f \|_{\Phi(L)} \lesssim \| f \|_{\Psi(L)}$.
\end{lemma}
\begin{proof}
  The first proposition is easy, and we now deal with the finite case. We note that the condition implies that for each $\varepsilon > 0$, there exists $C_\varepsilon$ such that $\Phi(x) \leq C_\varepsilon \Psi(x)$ if $|x| \geq \varepsilon$. Assume that $\| f \|_{\Psi(L)} \leq 1$, so that
  %
  \[ \int \Psi(|f(x)|)\; dx \leq 1. \]
  %
  Then convexity implies that for each $A > 0$,
  %
  \[ \int \Psi \left( \frac{|f(x)|}{A} \right) \leq \frac{1}{A}. \]
  %
  Thus
  %
  \begin{align*}
    \int \Phi\left( \frac{|f(x)|}{A} \right)\; dx &\leq \Phi(\varepsilon) |X| + C_\varepsilon \int \Psi \left( \frac{|f(x)|}{A} \right)\\
    &\lesssim \Phi(\varepsilon) |X| + \frac{C_\varepsilon}{A}.
  \end{align*}
  %
  If $\Phi(\varepsilon) \leq 2/|X|$, and $A \geq 2C_\varepsilon$, then we conclude that
  %
  \[ \int \Phi\left( \frac{|f(x)|}{A} \right)\; dx \leq 1. \]
  %
  Thus $\| f \|_{\Phi(L)} \lesssim 1$.
\end{proof}

The Orlicz spaces satisfy an interesting duality relation. Given a function $\Phi$, which we assume is \emph{superlinear}, in the sense that $\Phi(x)/x \to \infty$ as $x \to \infty$, define it's \emph{Young dual}, for each $y \in [0,\infty)$, by
%
\[ \Psi(y) = \sup \{ xy - \Phi(x) : x \in [0,\infty) \}. \]
%
Then $\Psi$ is the smallest function such that $\Phi(x) + \Psi(y) \geq xy$ for each $x,y$. This quantity is finite for each $y$ because $\Phi$ is superlinear; for each $y \geq 0$, there exists $x(y)$ such that $\Phi(x(y)) \geq xy$, and thus the maximum of $xy - \Phi(x)$ is attained for $x \leq x(y)$. In particular, since $\Phi$ is continuous, the supremum is actually attained. Conversely, for each $x_0 \in [0,\infty)$, convexity implies there exists a largest $y$ such that the line $y(x - x_0) + f(x_0) \leq f(x)$ for all $x \in [0,\infty)$. This means that $\Psi(y) = x_0y - x_0$.

We note also that $\Psi(0) = 0$, and $\Psi$ is increasing. Most importantly, the function is convex. Given any $y,z \in [0,\infty)$, and any $x \in [0,\infty)$,
%
\begin{align*}
  x (\alpha y + (1 - \alpha) z) - \Phi(x) &\leq \alpha(xy - \Phi(x)) + (1 - \alpha)(xz - \Phi(x))\\
  &\leq \alpha \Psi(y) + (1 - \alpha) \Psi(z).
\end{align*}
%
Taking infimum over all $x$ gives convexity. The function $\Psi$ is also superlinear, since for any $x \in [0,\infty)$,
%
\[ \lim_{y \to \infty} \frac{\Psi(y)}{y} \geq \lim_{y \to \infty} \frac{xy - \Phi(x)}{y} = x. \]
%
In particular, we can consider the Young dual of $\Psi$.

\begin{lemma}
  If $\Psi$ is the Young dual of $\Phi$, then $\Phi$ is the Young dual of $\Psi$.
\end{lemma}
\begin{proof}
  $\Pi$ is the smallest function such that $\Pi(x) + \Psi(y) \geq xy$. Since $\Phi(x) + \Psi(y) \geq xy$ for each $x$ and $y$, we conclude that $\Pi(x) \leq \Phi(x)$ for each $x$. For each $x$, there exists $y$ such that $\Psi(y) = yx - \Phi(x)$. But this means that $\Phi(x) = yx - \Psi(y) \leq \Pi(x)$.
\end{proof}

Given the Orlicz space $\Phi(L)$ for superlinear $\Phi$, we can consider the Orlicz space $\Psi(L)$, where $\Psi$ is the Young dual of $\Phi$. The inequality $xy \leq \Phi(x) + \Psi(y)$, then
%
\[ |f(x) g(x)| \leq \Phi(|f(x)|) + \Psi(|g(x)|), \]
%
so if $\| f \|_{\Phi(L)}, \| g \|_{\Psi(L)} \leq 1$, then
%
\[ \left| \int f(x) g(x) \right| \leq \int |f(x)| |g(x)| \leq \int \Phi(|f(x)|) + \int \Psi(|g(x)|) \leq 2. \]
%
Thus in general, we have
%
\[ \left| \int f(x) g(x) \right| \leq 2 \| f \|_{\Phi(L)} \| g \|_{\Psi(L)}, \]
%
a form of H\"{o}lder's inequality. The duality between convex functions extends to a duality between the Orlicz spaces.

\begin{theorem}
  For any superlinear $\Phi$ with Young dual $\Psi$,
  %
  \[ \| f \|_{\Phi(L)} \sim \sup \left\{ \int fg : \| g \|_{\Psi(L)} \leq 1 \right\}. \]
\end{theorem}
\begin{proof}
  Without loss of generality, assume $\| f \|_{\Phi(L)} = 1$. The version of H\"{o}lder's inequality proved above shows that
  %
  \[ \| f \|_{\Phi(L)} \lesssim 1. \]
  %
  Conversely, for each $x$, we can find $g(x)$ such that $f(x) g(x) = \Phi(|f(x)|) + \Psi(|g(x)|$. Provided $\| g \|_{\Psi(L)} < \infty$, we have
  %
  \[ \int fg = \int \Phi(|f(x)|) + \int \Psi(|g(x)|) \geq 1 + \| g \|_{\Psi(L)}. \]
  %
  Assuming $f \in L^\infty(X)$, we may choose $g \in L^\infty(X)$. For such a choice of function, $\| g \|_{\psi(L)} < \infty$, which implies the result. Taking an approximation argument then gives the result in general.
\end{proof}

Let us now consider some examples of duality.

\begin{example}
  If $\Phi(x) = x^p$, for $p \geq 1$, and $1 = 1/p + 1/q$, then it's Young dual $\Psi$ satisfies
  % q = p/(p-1)
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - x^p = y^{1 + q/p} / p^{q/p} - y^q / p^q = y^q [p^{-q/p} - p^{-q}].
  \end{align*}
  %
  Thus the Young dual corresponds, up to a constant, to the conjugate dual in the $L^p$ spaces.
\end{example}

\begin{example}
  Suppose $X$ has finite measure. If $\Phi(t) = e^t - 1$, then it's dual satisfies, for large $y$,
  %
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - (e^x - 1)\\
    &= y \log y - (y - 1) \sim y \log y.
  \end{align*}
  %
  This is comparable to $y \log (y + 2)$ for large $y$. Thus $L \log L$ is dual to $e^L$.
\end{example}

\begin{example}
  Suppose $X$ has finite measure. If $\Phi(x) = e^{x^2} - 1$, then for $y \geq 2$,
  %
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - (e^{x^2} - 1) \sim y \log(y/2)^{1/2}.
  \end{align*}
  %
  Thus the dual of $e^{L^2}$ is the space $L (\log L)^{1/2}$.
\end{example}

There is a generalization of both the Lorentz spaces and the Orlicz spaces, known as the Lorentz-Orlicz spaces, but these come up so rarely in analysis that we do not dwell on these norms.
















\chapter{Interpolation Theory}

One of the most fundamental tools in the `hard style' of mathematical analysis, involving explicit quantitative estimates on quantities that arises in basic methods of mathematics, is the theory of interpolation. The main goal of interpolation is to take two estimates, and blend them together to form a family of intermediate estimates. Often each estimate will focus on one component of the problem at hand (an estimate in terms of the decay of the function at $\infty$, an estimate involving the growth of the derivative, or the low frequency the function is, etc). By interpolating, we can optimize and obtain an estimate which simultaneously takes into account multiple features of the function. As should be expected, our main focus will be on the \emph{interpolation of operators}.

\section{Interpolation of Functions}

The most basic way to interpolate is using the notion of convexity. Given two inequalities $A_0 \leq B_0$ and $A_1 \leq B_1$, for any parameter $0 \leq \theta \leq 1$, if we define the additive weighted averages $A_\theta = (1 - \theta) A_0 + \theta A_1$ and $B_\theta = (1 - \theta) B_0 + \theta B_1$, then we conclude $A_\theta \leq B_\theta$ for all $\theta$. Similarily, we can consider the weighted multiplicative averages $A_\theta = A_0^{1 - \theta} A_1^\theta$ and $B_\theta = B_0^{1 - \theta}B_1^\theta$, in which case we still have $A_\theta \leq B_\theta$. Note that the additive averages are obtained by taking the unique linear function between two values, and the multiplicative averages are obtained by taking the unique log-linear function between two values. In particular, if $A_\theta$ is defined to be any convex function, then $A_\theta \leq (1 - \theta) A_0 + \theta A_1$, and if $B_\theta$ is logarithmically convex, so that $\log B_\theta$ is convex, then $B_\theta \leq B_0^{1 - \theta} B_1^\theta$. Thus convexity provides us with a more general way of interpolating estimates, which is what makes this property so useful in analysis, enabling us to simplify estimates.

\begin{example}
    For a fixed, measurable function $f$, the map $p \mapsto \| f \|_p$ is a log convex function. This statement is precisely H\"{o}lder's inequality, since the inequality
    %
    \[ \| f \|_{\theta p + (1 - \theta) q} \leq \| f \|_p^\theta \| f \|_{q}^{1-\theta} \]
    %
    says
    %
    \[ \| |f|^{\theta p} |f|^{(1 - \theta) q} \|_1^{1/(\theta p + (1 - \theta) q)} \leq \| f^{\theta p} \|_{1/\theta}^{\theta} \| f^{(1-\theta)q} \|_{1/(1-\theta)}^{1-\theta} \]
    %
    which is precisely H\"{o}lder's inequality. Note this implies that if $p_0 < p_\theta < p_1$, then $L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X)$.
\end{example}

\begin{example}
    The weak $L^p$ norm is log convex, because if $F(t) \leq A_0^{p_0}/t^{p_0}$, and $F(t) \leq A_1^{p_1}/t^{p_1}$, then we can apply scalar interpolation to conclude that if $p_\theta = (1 - \alpha) p_0 + \alpha p_1$,
    %
    \[ F(t) \leq \frac{A_0^{(1 - \alpha) p_0}A_1^{\alpha p_1}}{t^{(1 - \alpha)p_0 + \alpha p_1}} = \frac{A_\theta^{p_\theta}}{t^{p_\theta}} \]
    %
    where $p_\theta$ is the harmonic weighted average between $p_0$ and $p_1$, and $A_\theta$ the geometric weighted average. Using this argument, interpolating slightly to the left and right of $p_\theta$, we can conclude that if $p_0 < p_\theta < p_1$, then $L^{p_0,\infty}(X) \cap L^{p_1,\infty}(X) \subset L^{p_\theta}(X)$.
\end{example}

\section{Complex Interpolation}

Another major technique to perform an interpolation is to utilize the theory of complex analytic functions to obtain estimates. The core idea of this technique is to exploit the maximum principle, which says that bounding an analytic function at its boundary enables one to obtain bounds everywhere in the domain of the function. The next result, known as Lindel\"{o}f's theorem, is one of the fundamental examples of the application of complex analysis.

\begin{theorem}[The Three Lines Lemma]
    If $f$ is a holomorphic function on the strip $S = \{ z : \text{Re}(z) \in [a,b] \}$ and there exists constants $A,B,\delta > 0$ such that for all $z \in S$,
    %
    \[ |f(z)| \leq Ae^{Be^{(\pi - \delta)|z|}}. \]
    %
    Then the function $M: [a,b] \to [0,\infty]$ given by
    %
    \[ M(s) = \sup_{s \in \RR} |f(s + it)| \]
    %
    is log convex on $[a,b]$.
\end{theorem}
\begin{proof}
    By a change of variables, we can assume that $a = 0$, and $b = 1$, and we need only show that if there are $A_0, A_1 > 0$ such that
    %
    \[ |f(it)| \leq A_0 \quad\text{and}\quad |f(1 + it)| \leq A_1 \quad \text{for all $t \in \RR$}, \]
    %
    then for any $s \in [a,b]$ and $t \in \RR$,
    %
    \[ |f(s + it)| \leq A_0^{1 - s} A_1^s. \]
    %
    By replacing $f(z)$ with the function $A_0^{1-z} A_1^z f(z)$, we may assume without loss of generality that $A_0 = A_1 = 1$, and we must show that $\| f \|_{L^\infty(S)} \leq 1$. If $|f(s + it)| \to 0$ as $|t| \to \infty$, then for large $N$, we can conclude that $|f(s + it)| \leq 1$ for $s \in [a,b]$ and $|t| \geq N$. But then the maximum principle entails that $|f(s + it)| \leq 1$ for $s \in [a,b]$ and $|t| \leq N$, which completes the proof in this case. In the general case, for each $\varepsilon > 0$, define
    %
    \[ u_\varepsilon(z) = \exp(- 2 \varepsilon \sin((\pi - \varepsilon) z + \varepsilon/2)). \]
    %
    Then if $z = s + it$,
    %
    \[ |u_\varepsilon(z)| = \exp(- \varepsilon [e^{(\pi - \varepsilon) t} + e^{-(\pi - \varepsilon) t}] \sin((\pi - \varepsilon) s + \varepsilon/2)), \]
    %
    So, in particular, $|u_\varepsilon(z)| \leq 1$, and there exists a constant $C$ such that if $z \in S$,
    %
    \[ |u_\varepsilon(z)| \leq e^{- C \varepsilon^2 e^{(\pi - \varepsilon) |z|}} \]
    %
    Note that if $\varepsilon < \delta$, then as $|\text{Im}(z)| \to \infty$,
    %
    \[ |f(z) u_\varepsilon(z)| \leq A e^{B e^{(\pi - \delta) |z|} - C \varepsilon^2 e^{(\pi - \varepsilon) |z|} } \to 0. \]
    %
    Applying the previous case to the function $|f(z) u_\varepsilon(z)|$, we conclude that for any $\varepsilon > 0$,
    %
    \[ |f(z)| \leq \frac{1}{|u_\varepsilon(z)|}. \]
    %
    Thus
    %
    \[ |f(z)| \leq \lim_{\varepsilon \to 0} \frac{1}{|u_\varepsilon(z)|} = 1, \]
    %
    which completes the proof.
\end{proof}

\begin{remark}
    The function $e^{-ie^{\pi i s}}$ shows that the assumption of the three lines lemma is essentially tight. In particular, this means there is no family of holomorphic functions $g_\varepsilon$ which decays faster than double exponentially, and pointwise approximates the identity as $\varepsilon \to 0$.
\end{remark}

\begin{remark}
    Similar variants can be used to show that if $f$ is a holomorphic function on an annulus, then the supremum over circles centered around the origin is log convex in the radius of the circle (a result often referred to as the three circles lemma).
\end{remark}

\begin{example}
    Here we show how we can use the three lines lemma to prove that the $L^p$ norms are log convex. If $f = \sum a_n \chi_{E_n}$ is a simple function, then the function
    %
    \[ g(s) = \int |f|^s = \sum |a_n|^s |E_n| \]
    %
    is analytic in $s$, and satisfies the growth condition of the three lines lemma because each term of the sum is exponential in growth. Since $|g(s)| \leq |g(\sigma)|$, the three lines lemma implies that $g$ is log convex on the real line. By normalizing the function $f$ and the underlying measure, given $p_0$, $p_1$, we may assume $\| f \|_{p_0} = \| f \|_{p_1} = 1$, and it suffices to prove that $\| f \|_{p_\theta} \leq 1$ for all $p_\theta \in [p_0, p_1]$. But the log convexity of $g$ guarantees this is true, since $|g(p)| = \| f \|_p^p$. A standard limiting argument then gives the inequality for all functions $f$.
\end{example}

\begin{example}
    Let $f$ be a holmomorphic function on a strip $S = \{ z : \text{Re}(z) \in [a,b] \}$, such that if $z = a + it$, or $z = b + it$, for some $t \in \RR$,
    %
    \[ |f(z)| \leq C_1 (1 + |z|)^\alpha. \]
    %
    Then there exists a constant $C'$ such that for any $z \in S$,
    %
    \[ |f(z)| \leq C_2 (1 + |z|)^\alpha. \]
\end{example}
\begin{proof}
    The function
    %
    \[ g(z) = \frac{f(z)}{(1 + z)^\alpha} \]
    %
    is holomorphic on $S$, and if $z = a + it$ or $z = b + it$,
    %
    \[ |g(z)| \leq \frac{C_1 (1 + |z|)^\alpha}{|1 + z|^\alpha} \lesssim 1. \]
    %
    Thus the three lines lemma implies that $|g(z)| \lesssim 1$ for all $z \in S$, so
    %
    \[ |f(z)| \lesssim |1 + z|^\alpha \lesssim (1 + |z|)^\alpha. \qedhere \]
\end{proof}

\section{Interpolation of Operators}

A major part of modern harmonic analysis is the study of operators, i.e. maps from function spaces to other function spaces. We are primarily interested in studying \emph{linear operators}, i.e. operators $T$ such that $T(f + g) = T(f) + T(g)$, and $T(\alpha f) = \alpha T(f)$, and also \emph{sublinear operators}, such that $|T(\alpha f)| = |\alpha| |T(f)|$ and $|T(f + g)| \leq |Tf| + |Tg|$. Even if we focus on linear operators, it is still of interest to study sublinear operators because one can study the \emph{uniform boundedness} of a family of operators $\{ T_k \}$ by means of the function $T^*(f)(x) = \max (T_k f)(x)$. This is the method of \emph{maximal functions}. Another important example are the $l^p$ sums
%
\[ (S^p f)(x) = \left( \sum |T_k(x)|^p \right). \]
%
These two examples are specific examples where we have a family of operators $\{ T_y \}$, indexed by a measure space $Y$, and we define an operator $S$ by taking $Sf$ to be the norm of $\{ T_y f \}$ in the variable $y$.

Here we address the most basic case of operator interpolation. As we vary $p$, the $L^p$ norms provide different ways of measuring the height and width of functions. Let us consider a simple example. Suppose that for an operator $T$, we have a bound
%
\[ \| Tf \|_{L^1(Y)} \leq \| f \|_{L^1(X)} \quad\text{and}\quad \| Tf \|_{L^\infty(Y)} \leq \| f \|_{L^\infty(X)}. \]
%
The first inequality shows that the width of $Tf$ is controlled by the width of $f$, and the second inequality says the height of $Tf$ is controlled by the height of $f$. If we take a function $f \in L^p(X)$, for some $p \in (1,\infty)$, then we have some control over the height of $f$, and some control of the width. In particular, this means we might expect some control over the width and height of $Tf$, i.e. for each $p$, a bound
%
\[ \| Tf \|_{L^p(Y)} \leq \| f \|_{L^p(X)}. \]
%
This is the idea of interpolation on the $L^p(X)$ spaces.

\section{Complex Interpolation of Operators}

The first theorem we give is the Riesz-Thorin theorem, which utilizes complex interpolation to give such a result. In the next theorem, we work with a linear operator $T$ which maps simple functions $f$ on a measure space $X$ to functions on a measure space $Y$. For the purposes of applying duality, we make the mild assumption that for each simple function $g$,
%
\[ \int |(Tf)(y)| |g(y)|\; dy < \infty. \]
%
Our goal is to obtain $L^p$ bounds on the function $T$. The Hahn-Banach theorem then guarantees that $T$ has a unique extension to a map defined on all $L^p$ functions.

\begin{theorem}[Riesz-Thorin]
    Let $p_0,p_1 \in (0,\infty]$ and $q_0,q_1 \in [1,\infty]$. Suppose that
    %
    \[ \| Tf \|_{L^{q_0}(Y)} \leq A_0 \| f \|_{L^{p_0}(X)} \quad \text{and} \| Tf \|_{L^{q_1}(Y)} \leq A_1 \| f \|_{L^{p_1}(X)}.  \]
    %
    Then for any $\theta \in (0,1)$, if
    %
    \[ 1/p_\theta = (1 - \theta)/p_0 + \theta/p_1 \quad\text{and}\quad 1/q_\theta = (1 - \theta)/q_0 + \theta/q_1, \]
    %
    then
    %
    \[ \| Tf \|_{L^{q_\theta}(Y)} \leq A_\theta \| f \|_{L^{p_\theta}(X)}, \]
    %
    where $A_\theta = A_0^{1 - \theta} A_1^\theta$.
\end{theorem}
\begin{proof}
    If $p_0 = p_1$, the proof follows by the log convexity of the $L^p$ norms of a function. Thus we may assume $p_0 \neq p_1$, so $p_\theta$ is finite in any case of interest. By normalizing the measures on both spaces, we may assume $A_0 = A_1 = 1$. By duality and homogeneity, it suffices to show that for any two simple functions $f$ and $g$ such that $\| f \|_{q_\theta} = \| g \|_{q_\theta^*} = 1$,
    %
    \[ \left| \int_Y (Tf) g\; dy \right| \leq 1. \]
    %
    Our challenge is to make this inequality complex analytic so we can apply the three lines lemma. We write $f = F_0^{1 - \theta} F_1^\theta a$, where $F_0$ and $F_1$ are non-negative simple functions with $\| F_0 \|_{L^{p_0}(X)} = \| F_1 \|_{L^{p_1}(X)} = 1$, and $a$ is a simple function with $|a(x)| = 1$. Similarily, we can write $g = G_0^{1-\theta} G_1^\theta b$. We now write
    %
    \[ H(s) = \int_Y T(F_0^{1 - s} F_1^s a) G_0^{1-s} G_1^s b\; dy. \]
    %
    Since all functions involved here are simple, $H(s)$ is a linear combination of positive numbers taken to the power of $1-s$ or $s$, and is therefore obviously an entire function in $s$. Now for all $t \in \RR$, we have
    %
    \[ \| F_0^{1-it} F_1^{it} a \|_{L^{p_0}(X)} = \| F_0 \|_{L^{p_0}(X)} = 1, \]
    \[ \| G_0^{1-it} G_1^{it} b \|_{L^{q_0}(Y)} = \| G_0 \|_{L^{q_0}(X)} = 1. \]
    %
    Therefore
    %
    \begin{align*}
      |H(it)| &= \left| \int T(F_0^{1 - it} F_1^{it} a) G_0^{1-it} G_1^{it} b\; dy \right| \leq 1.
    \end{align*}
    %
    Similarily, $|H(1 + it)| \leq 1$ for all $t \in \RR$. An application of Lindel\"{o}f's theorem implies $|H(s)| \leq 1$ for all $s$. Setting $s = \theta$ completes the argument.
\end{proof}

If, for each $p,q$, we let $F(1/p,1/q)$ to be the operator norm of a linear operator $T$ viewed as a map from $L^p(X)$ to $L^q(Y)$, then the Riesz-Thorin theorem says that $F$ is a log-convex function. In particular, the set of $(1/p,1/q)$ such that $T$ is bounded as a map from $L^p(X)$ to $L^q(Y)$ forms a convex set. If this is true, we often say $T$ is of \emph{strong type} $(p,q)$.

\begin{example}
  For any two integrable functions $f,g \in L^1(\RR^d)$, we can define an integrable function $f * g \in L^1(\RR^d)$ almost everywhere by the integral formula
  %
  \[ (f * g)(x) = \int f(y) g(x-y)\; dy. \]
  %
  If $f \in L^1(\RR^d)$ and $g \in L^p(\RR^d) \cap L^1(\RR^d)$, for some $p \geq 1$, then Minkowski's integral inequality implies
  %
  \begin{align*}
      \| f * g \|_p &= \left( \int |(f * g)(x)|^p\; dx \right)^{1/p} \leq \int \left( \int |f(y)g(x-y)|^p dx\; \right)^{1/p} dy\\
      &= \int |f(y)| \| g \|_{L^p(\RR^d)} = \| f \|_{L^1(\RR^d)} \| g \|_{L^p(\RR^d)}.
  \end{align*}
  %
  H\"{o}lder's inequality implies that if $f \in L^p(\RR^d)$ and $g \in L^q(\RR^d)$, where $p$ and $q$ are conjugates of one another, then
  %
  \begin{align*}
    \left| \int f(y) g(x-y)\; dy \right| \leq \int |f(y-x)| |g(x)| \leq \| f \|_{L^p(\RR^d)} \| g \|_{L^q(\RR^d)}.
  \end{align*}
    %
    Thus we have the bound
    %
    \[ \| f * g \|_{L^\infty(\RR^d)} \leq \| f \|_{L^p(\RR^d)} \| g \|_{L^q(\RR^d)}. \]
    %
    Now that these mostly trivial results have been proved, we can apply convolution. For each $f \in L^1(\RR^d) \cap L^p(\RR^d)$, we have a convolution operator $T: L^1(\RR^d) \to L^1(\RR^d)$ defined by $Tg = f * g$. We know that $T$ is of strong type $(1,p)$, and of type $(q,\infty)$, where $q$ is the harmonic conjugate of $p$, and $T$ has operator norm $1$ with respect to each of these types. But the Riesz Thorin theorem then implies that if $1/r = \theta + (1 - \theta)/q$, then $T$ is bounded as a map from $L^r(\RR^d)$ to $L^{p/\theta}(\RR^d)$ with operator norm one. Reparameterizing gives \emph{Young's convolution inequality}. Note that we never really used anything about $\RR^d$ here other than it's translational structure, and as such Young's inequality continues to apply in the theory of any modular locally compact group. In particular, the Haar measure $\mu$ on such a group is only defined up to a scalar multiple, and if we swap $\mu$ with $\alpha \mu$, for some $\alpha > 0$, then Young's inequality for this measure implies
    %
    \[ \lambda^{1 + 1/r} \| f * g \|_r = \lambda^{1/p + 1/q} \| f \|_p \| g \|_p \]
    %
    which is a good way of remembering that we must have $1 + 1/r = 1/p + 1/q$.
\end{example}

\begin{example}
Let $X$ be a measure space with $\sigma$ algebra $\Sigma_0$, and let $\Sigma \subset \Sigma_0$ be a $\sigma$ finite sub $\sigma$ algebra. Then $L^2(X,\Sigma)$ is a closed subspace of $L^2(X,\Sigma_0)$, and so there is an orthogonal projection operator $\EE(\cdot|\Sigma): L^2(X,\Sigma_0) \to L^2(X,\Sigma)$, which we call the \emph{conditional expectation operator}. The properties of the projection operator imply that for any $f,g \in L^2(X, \Sigma_0)$,
%
\[ \int \EE(f|\Sigma) \overline{g} = \int f \overline{g} = \int \EE(f|\Sigma) \overline{\EE(g|\Sigma)}. \]
%
If $g \in L^2(X,\Sigma)$, then
%
\[ \int \EE(f|\Sigma) \overline{g} = \int f \overline{g}. \]
%
This gives a full description of $\EE(f|\Sigma)$. In particular, if $u \in L^\infty(X,\Sigma_0)$, then for each $g \in L^2(X,\Sigma)$
%
\[ \int \EE(uf|\Sigma) \overline{g} = \int f [u\overline{g}] = \int u \EE(f|\Sigma) \overline{g}. \]
%
Since this is true for all $g \in L^2(X,\Sigma)$, we find $\EE(uf|\Sigma) = u \EE(f|\Sigma)$. Moreover, if $0 \leq f \leq g$, then $\EE(f|\Sigma) \leq \EE(g|\Sigma)$. This is easy to see because if $f \geq 0$, and $F = \{ x : \EE(f|\Sigma) < 0 \}$, then if $|F| \neq 0$,
%
\[ 0 > \int \EE(f|\Sigma) \mathbf{I}_F = \int f \mathbf{I}_F \geq 0. \]
%
Thus $|F| = 0$, and so $\EE(f|\Sigma) \geq 0$ almost everywhere.

Like all other orthogonal projection operators, conditional expectation is a contraction in the $L^2$ norm, i.e. $\| \mathbf{E}(f|\Sigma) \|_{L^2(X)} \leq \| f \|_{L^2(X)}$. We now use interpolation to show that conditional expectation is strong $(p,p)$, for all $1 \leq p \leq \infty$. It suffices to prove the operator is strong $(1,1)$ and strong $(\infty,\infty)$. So suppose $f \in L^2(X,\Sigma_0) \cap L^\infty(X,\Sigma_0)$. If $|E| < \infty$, then $\mathbf{I}_E \in L^2(X)$, so
%
\[ |\EE(f|\Sigma)| \mathbf{I}_E = |\EE(\mathbf{I}_E f | \Sigma)| \leq \EE(\mathbf{I}_E |f| | \Sigma) \leq \| f \|_\infty \mathbf{E}(\mathbf{I}_E|\Sigma) = \| f \|_\infty \mathbf{I}_E. \]
%
Since $\Sigma$ is a sigma finite sigma algebra, we can take $E \to \infty$ to conclude $\| \EE(f|\Sigma) \|_\infty \leq \| f \|_\infty$. The case $(1,1)$ can be obtained by duality, since conditional expectation is self adjoint, or directly, since if $f \in L^1(X,\Sigma_0) \cap L^2(X,\Sigma_0)$, then for any set $E \in \Sigma$ with $|E| < \infty$,
%
\[ \int |\EE(f|\Sigma)| \mathbf{I}_E \leq \int \EE(|f||\Sigma) \mathbf{I}_E = \int_E |f| \mathbf{I}_E \leq \| f \|_1. \]
%
Since $\Sigma$ is $\sigma$ finite, we can take $E \to \infty$ to conclude $\| \EE(f|\Sigma) \|_1 \leq \| f \|_1$. Thus the Riesz interpolation theorem implies that for each $1 \leq p \leq \infty$, $\| \EE(f|\Sigma) \|_p \leq \| f \|_p$.

Since $L^2(X,\Sigma_0)$ is dense in $L^p(X,\Sigma_0)$ for all $1 \leq p < \infty$, there is a unique extension of the conditional expectation operator from $L^p(X,\Sigma_0)$ to $L^p(X,\Sigma_0)$. For $p = \infty$, there are infinitely many extensions of the conditional expectation operator from $L^\infty(X,\Sigma_0)$ to $L^\infty(X,\Sigma_0)$. However, there is a \emph{unique} extension such that for each $f \in L^2(\Sigma_0)$ and $g \in L^\infty(\Sigma)$, $\EE(fg|\Sigma) = g \EE(f|\Sigma)$. This is because for any $E \in \Sigma$ with $|E| < \infty$, $\EE(f \mathbf{I}_E | \Sigma) = \mathbf{I}_E \EE(f|\Sigma)$ is uniquely defined since $f \mathbf{I}_E \in L^2(\Sigma_0)$, and taking $E \to \infty$ by $\sigma$ finiteness.

A simple consequence of the uniform boundedness of these operators on the various $L^p$ spaces is that if $\Sigma_1, \Sigma_2, \dots$ are a family of $\sigma$ algebras, and $\Sigma_\infty$ is the smallest $\sigma$ algebra containing all sets in $\bigcup_{i = 1}^\infty \Sigma_i$, then for each $1 \leq p < \infty$, and for each $f \in L^p(\Sigma_0)$, $\lim_{i \to \infty} \EE(f|\Sigma_i) = \EE(f|\Sigma_\infty)$. This is because the operators $\{ \EE(\cdot|\Sigma_i) \}$ are uniformly bounded. The limit equation holds for any simple function $f$ composed of sets in $\bigcup_{i = 1}^\infty \Sigma_i$, and a $\sigma$ algebra argument can then be used to show this family of simple functions is dense in $L^p(\Sigma_0)$.
\end{example}

It was an important observation of Elias-Stein that complex interpolation can be used not only with a single operator $T$, but with an `analytic family' of operators $\{ T_s \}$, one for each $s$, such that for each pair of simple functions $f$ and $g$, the function
%
\[ \int (T_s f)(y) g(y) \]
%
is analytic in $s$. Thus bounds on $T_{0+it}$ and $T_{1 + it}$ imply intermediary bounds on all other operators, provided that we still have at most doubly exponential growth. The next theorem gives an example application.

\begin{theorem}[Stein-Weiss Interpolation Theorem]
  Let $T$ be a linear operator, and let $w_0, w_1: X \to [0,\infty)$ and $v_0, v_1 : Y \to [0,\infty)$ be weights which are integrable on every finite-measure set. Suppose that
  %
  \[ \| Tf \|_{L^{q_0}(X,v_0)} \leq A_0 \| f \|_{L^{p_0}(X,w_0)}\quad\text{and}\quad \| Tf \|_{L^{q_1}(X,v_1)} \leq A_1 \| f \|_{L^{p_1}(X,w_0)}. \]
  %
  Then for any $\theta \in (0,1)$,
  %
  \[ \| Tf \|_{L^{q_\theta}(X,v_\theta)} \leq A_\theta \| f \|_{L^{p_\theta}(X,w_\theta)}, \]
  %
  where $w_\theta = w_0^{1-\theta} w_\theta$ and $v_\theta = v_0^{1-\theta} v_1^\theta$.
\end{theorem}
\begin{proof}
  Fix a simple function $f$ with $\| f \|_{L^{p_\theta}(X,w_\theta)}$. We begin with some simplifying assumptions. A monotone convergence argument, replacing $w_i(t)$ with
  %
  \[ w_i'(y) = \begin{cases} w_i(y) &: \varepsilon \leq w_i(t) \leq 1/\varepsilon, \\ 0 &: \text{otherwise}, \end{cases} \]
  %
  and then taking $\varepsilon \to 0$, enables us to assume without loss of generality that $w_0$ and $w_1$ are both bounded from below and bounded from above. Truncating the support of $Tf$ enables us to assume that $Y$ has finite measure. Since $f$ has finite support, we may also assume without loss of generality that $X$ has finite support, and by applying the dominated convergence theorem we may replace the weights $v_i$ with
  %
  \[ v_i'(x) = \begin{cases} v_i(x) &: \varepsilon \leq v_i(x) \leq 1/\varepsilon, \\ 0 &: \text{otherwise}, \end{cases} \]
  %
  and then take $\varepsilon \to 0$. Thus we can assume that the $v_i$ are bounded from above and below. Restricting to the support of $X$, we can also assume $X$ has finite measure.

  For each $s$, consider the operator $T_s$ defined by
  %
  \[ T_s f = w_0^{\frac{1-s}{q_0}} w_1^{\frac{s}{q_1}} T \left( f v_0^{- \frac{1-s}{p_0}} v_1^{-\frac{s}{p_1}} \right). \]
  %
  The fact that all functions involved are simple means that the family of operators $\{ T_s \}$ is analytic. Now for all $t \in \RR$
  %
  \[ \| T_{it} f \|_{L^{q_0}(Y)} = \| T f \|_{L^{q_0}(Y,w_0)} \leq A_0 \| f v_0^{-1/p_0} \|_{L^{p_0}(X,v_0)} = A_0 \| f \|_{L^{p_0}(X)}. \]
  %
  For similar reasons, $\| T_{1 + it} f \|_{L^{q_1}(Y)} \leq A_1 \| f \|_{L^{p_0}(X,v_0)}$. Thus the Stein variant of the Riesz-Thorin theorem implies that
  %
  \[ \| T_\theta f \|_{L^{q_\theta}(Y)} \leq A_\theta \| f \|_{L^{p_\theta}(X)}. \]
  %
  But this, of course, is equivalent to the bound we set out to prove.
\end{proof}

\section{Real Interpolation of Operators}

Now we consider the case of real interpolation. One advantage of real interpolation is that it can be applied to sublinear as well as linear operators, and requires weaker endpoint estimates that the complex case. A disadvantage is that, usually, the operator under study cannot vary, and we lose out on obtaining explicit bounds.

A strong advantage to using real interpolation is that the criteria for showing boundedness at the endpoints can be reduced considerably. Let us give names for the boundedness we will want to understand for a particular operator $T$.
%
\begin{itemize}
  \item We say $T$ is \emph{strong type} $(p,q)$ if $\| Tf \|_{L^q(Y)} \lesssim \| f \|_{L^p(X)}$.

  \item We say $T$ is \emph{weak type} $(p,q)$ if $\| Tf \|_{L^{q,\infty}(Y)} \lesssim \| f \|_{L^p(X)}$.

  \item We say $T$ is \emph{restricted strong type} $(p,q)$ if we have a bound
  %
  \[ \| Tf \|_{L^q(Y)} \lesssim HW^{1/p} \]
  %
  for any sub-step functions with height $H$ and width $W$. Equivalently, for any set $E$,
  %
  \[ \| T(\mathbf{I}_E) \|_{L^q(Y)} \lesssim |E|^{1/p}. \]
  %
  The equivalence is proven by breaking any sub-step function $f$ with height $H$ and width $W$ into a dyadic sum $\sum_{k = 1}^\infty H \mathbf{I}_{E_k} 2^{-k}$, where $|E_k| \leq W$.

  \item We say $T$ is \emph{restricted weak type} $(p,q)$ if we have a bound
  %
  \[ \| Tf \|_{L^{q,\infty}(Y)} \lesssim HW^{1/p} \]
  %
  for all sub-step functions with height $H$ and width $W$. Equivalently, for any set $E$,
  %
  \[ \| T(\mathbf{I}_E) \|_{L^{q,\infty}(Y)} \lesssim |E|^{1/p}. \]
\end{itemize}
%
An important tool for us will be to utilize duality to make our interpolation argument `bilinear'. Let us summarize this tool in a lemma. Proving the lemma is a simple application of Theorem \ref{weakdualitytheorem}.

\begin{lemma}
  Let $0 < p < \infty$ and $0 < q < \infty$. Then an operator $T$ is restricted weak-type $(p,q)$ if and only if for any finite measure sets $E \subset X$ and $F \subset Y$, there is $F' \subset Y$ with $|F'| \geq \alpha |F|$ such that
  %
  \[ \int_{F'} |T(\mathbf{I}_E)| \lesssim_\alpha |E|^{1/p} |F|^{1-1/q}. \]
\end{lemma}

Scalar interpoation leads to a simple version of real interpolation, which we employ as a subroutine to obtain a much more powerful real interpolation principle.

\begin{lemma}
  Let $0 < p_0,p_1 < \infty$, $0 < q_0,q_1 < \infty$. If $T$ is restricted weak type $(p_0,q_0)$ and $(p_1,q_1)$, then $T$ is restricted weak type $(p_\theta,q_\theta)$ for all $\theta \in (0,1)$.
\end{lemma}
\begin{proof}
  By assumption, if $E \subset X$ and $F \subset Y$, then there is $F_0, F_1 \subset Y$ with $|F_i| \geq (3/4)|F|$ such that
  %
  \[ \int_{F_i} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_i} |F_i|^{1 - 1/q_i}. \]
  %
  If we let $F_\theta = F_0 \cap F_1$, then $|F_\theta| \geq |F|/2$, and for each $i$,
  %
  \[ \int_{F_\theta} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_i} |F_\theta|^{1 - 1/q_i}. \]
  %
  Scalar interpolation implies
  %
  \[ \int_{F_\theta} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_\theta} |F_\theta|^{1 - 1/q_\theta}, \]
  %
  and thus we have shown
  %
  \[ \| T(\mathbf{I}_E) \|_{q_\theta,\infty} \lesssim |E|^{1/p_\theta}. \]
  %
  This is sufficient to show $T$ is restricted weak type $(p_\theta,q_\theta)$.
\end{proof}

\begin{theorem}[Marcinkiewicz Interpolation Theorem]
  Let $0 < p_0,p_1 < \infty$, $0 < q_0,q_1 < \infty$, and suppose $T$ is restricted weak type $(p_i,q_i)$, with constant $A_i$, for each $i$. Then, for any $\theta \in (0,1)$, if $q_\theta > 1$, then for any $0 < r < \infty$, then
  %
  \[ \| Tf \|_{L^{q_\theta,r}(Y)} \lesssim A_\theta \| f \|_{L^{p_\theta,r}(X)}, \]
  %
  with implicit constants depending on $p_0, p_1, q_0$, and $q_1$.
\end{theorem}
\begin{proof}
  By scaling $T$, and the measures on $X$ and $Y$, we may assume that $\| f \|_{L^{p_\theta,r}(X)} \leq 1$, and that $T$ is restricted type $(p_i,q_i)$ with constant $1$, so that for any step function $f$ with height $H$ and width $W$,
  %
  \[ \| Tf \|_{L^{q_i,\infty}(Y)} \leq \| f \|_{L^{p_i}(X)}. \]
  %
  By duality, using the fact that $q_\theta > 1$, it suffices to show that for any simple function $g$ with $\| g \|_{L^{q_\theta',r'}(Y)} = 1$,
  %
  \[ \int |Tf| |g| \leq 1. \]
  %
  Using the previous lemma, we can `adjust' the values $q_0,q_1$ so that we can assume $q_0,q_1 > 1$. We can perform a horizontal layer decomposition, writing
  %
  \[ f = \sum_{i = -\infty}^\infty f_i, \quad\text{and}\quad g = \sum_{i = -\infty}^\infty g_i, \]
  %
  where $f_i$ and $g_i$ are sub-step functions with width $2^i$ and heights $H_i$ and $H_i'$ respectively, and if we write $A_i = H_i 2^{i/p_\theta}$, and $B_i = H_i' 2^{i/q_\theta}$, then
  %
  \[ \| A \|_{l^r(\ZZ)}, \| B \|_{l^{r'}(\ZZ)} \lesssim 1. \]
  %
  Applying the restricted weak type inequalities, we know for each $i$ and $j$,
  %
  \[ \int |Tf_i| |g_j| \lesssim H_i H_j \min_{k \in \{0,1\}} \left[ 2^{i/p_k + j(1 - 1/q_k)} \right]. \]

  Applying sublinearity (noting that really, the decomposition of $f$ and $g$ is finite, since both functions are simple). Thus
  %
  \begin{align*}
    \int |Tf| |g| &\leq \sum_{i,j} \int |Tf_i| |g_j|\\
    &\lesssim \sum_{i,j} H_i H_j' \min_{k \in \{0,1\}} \left[ 2^{i/p_k + j(1 - 1/q_k)} \right]\\
    &\lesssim \sum_{i,j} A_i B_j \min_{k \in \{ 0, 1 \}} \left[ 2^{i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k)} \right].
  \end{align*}
  %
  If $i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k) = \varepsilon(i + \lambda j)$, where $\varepsilon = (1/p_k - 1/p_\theta)$. We then have
  %
  \[ \sum_{i,j} A_i B_j \min_{k \in \{ 0, 1 \}} \left[ 2^{i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k)} \right] \sim \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \sum_i A_i B_{k - \lfloor i/\lambda \rfloor}. \]
  %
  Applying H\"{o}lder's inequality,
  %
  \begin{align*}
    \sum_i A_i B_{k - \lfloor i/\lambda \rfloor} &\leq \| A \|_{l^r(\ZZ)} \left( \sum_i |B_{k - \lfloor i/\lambda \rfloor}|^{r'} \right)^{1/r'}\\
    &\lesssim \lambda^{1/r'} \| A \|_{l^r(\ZZ)} \| B \|_{l^{r'}(\ZZ)} \lesssim 1.
  \end{align*}
  %
  Thus we conclude that
  %
  \begin{align*}
    \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \sum_i A_i B_{k - \lfloor i/\lambda \rfloor} &\lesssim \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \lesssim_\varepsilon 1. \qedhere
  \end{align*}
\end{proof}

There are many variants of the real interpolation method, but the general technique almost always remains the same: incorporate duality, decompose inputs, often dyadically, bound these decompositions, and then sum up.










\chapter{Basics of Kernel Operators}

We now consider a general family of operators, which can be seen as the infinite dimensional analogue of matrix multiplication. We fix two measure spaces $X$ and $Y$, and consider a function $K: X \times Y \to \CC$, which we call a \emph{kernel}. From this kernel, we obtain an induced operator $T_K$ taking functions on $X$ to functions on $Y$, given, heuristically at least, by the integral formula
%
\[ (T_K f)(y) = \int_X K(x,y) f(x)\; dx. \]
%
Our goal is to relate properties of the kernel $K$ to the regularity of the operator $T_K$ with respect to various norms.

\begin{example}
  Let $X = Y = \RR^d$, equipped with the Lebesgue measure. If we set $K(x,\xi) = e^{2 \pi i \xi \cdot x}$, then using this function as a kernel we can obtain an integral operator
  %
  \[ (T_K f)(\xi) = \int f(x) e^{2 \pi i \xi \cdot x}\; dx. \]
  %
  In the standard theory of Fourier analysis, we find that if $f \in L^1(\RR)$, then for any $\xi$ the integral
  %
  \[ \int f(x) e^{2 \pi i \xi \cdot x} \]
  %
  converges absolutely, and is thus well-defined in the sense of a Lebesgue integral. Moreover, for any $f \in L^1(\RR)$,
  %
  \[ \| T_K f \|_{L^\infty(\RR)} \leq \| f \|_{L^1(\RR)}. \]
  %
  We also know from the classical Hausdorff-Young inequality that if $1 \leq p \leq 2$, then for any $f \in L^1(\RR) \cap L^p(\RR)$,
  %
  \[ \| T_K f \|_{L^{p^*}(\RR)} \leq \| f \|_{L^p(\RR)}. \]
  %
  In particular, this means that there exists a unique extension of $T_K$ to a bounded operator from $L^p(\RR)$ to $L^{p^*}(\RR)$; note, however, that for a general element $f \in L^p(\RR)$, the integral formula
  %
  \[ \int f(x) e^{2 \pi i \xi \cdot x}\; dx \]
  %
  is \emph{not well-defined} in the Lebesgue sense. Thus we can only heuristically view the integral formula as defining the integral operator.
\end{example}

\begin{example}
  Let $X = \{ 1, \dots, N \}$ and $Y = \{ 1, \dots, M \}$, each equipped with the counting measure. Then each kernel $K$ corresponds to an $M \times N$ matrix $A$, with $A_{ij} = K(j,i)$. For any $f: X \to Y$ we can define a vector $v \in \RR^N$ by setting $v_i = f(i)$, and then
  %
  \[ (T_K f)(m) = \sum_{n = 1}^N f(n) K(n,m) = \sum_{n = 1}^N A_{mn} v_n = (Av)_m. \]
  %
  Thus with respect to the standard basis, $T_K$ is just given by matrix multiplication by $A$.
\end{example}

It turns out that if we map \emph{from} $L^1(X)$, or \emph{into} $L^\infty(Y)$, then the conditions on $K$ determining boundedness are trivial to determine for \emph{most} norms. This is one motivation for introduction the intermediate $L^p$ norms, since these norms enable us to extract more features out of the kernel operator $K$. Before we discuss this, we must first reflect on the fact that without even qualitative knowledge of the kernel $K$ besides it's measurability, it is difficult to know how one might interpret the integral formula defining the operator. A natural trick to begin with is to introduce the sublinear analogue of the kernel operator, i.e. the operator $S_K$ defined by setting
%
\[ (S_K f)(y) = \int_X |K(x,y)| |f(x)|; dx \]
%
The flexibility of the theory of non-negative Lebesgue integrals means this operator is well defined for \emph{any} measurable $f$ (though $S_k f(y)$ may be infinite for particular values of $y$). Moreover, if we are to interpret the integral formula for $(T_K f)(y)$ in the Lebesgue sense, it is necessary and sufficient that $(S_K f)(y) < \infty$.

\begin{theorem}
  Fix $q \geq 1$. Then
  %
  \[ \| S_k f \|_{L^q(Y)} \leq \| K \|_{L^q(Y)L^\infty(X)} \| f \|_{L^1(X)}. \]
  %
  Thus $T_k f(y)$ are well defined by a Lebesgue integral for almost every $y \in Y$, and
  %
  \[ \| T_k f \|_{L^q(Y)} \leq \| K \|_{L^q(Y) L^\infty(X)} \| f \|_{L^1(X)}. \]
\end{theorem}
\begin{proof}
  The proof is just a simple consequence of Minkowski's inequality, i.e.
  %
  \begin{align*}
    \| S_K f \|_{L^q(Y)} &= \| K f \|_{L^1(X) L^q(Y)}\\
    &\leq \| Kf \|_{L^q(Y) L^1(X)}\\
    &= \int \left( \int |K(x,y)|^q\; dy \right)^{1/q} |f(x)|\; dx\\
    &\leq \| K \|_{L^q(Y)L^\infty(X)} \| f \|_{L^1(X)}.
  \end{align*}
\end{proof}

\begin{remark}
  In a great many situations, this constant is tight. For isntance, suppose
  %
  \[ K = \sum_{i = 1}^N \sum_{j = 1}^M a_{ij} \mathbf{I}_{E_i \times F_j} \]
  %
  where $E_1,\dots,E_N$ and $F_1,\dots,F_N$ are disjoint finite measure sets. Then there exists $i \in \{ 1, \dots, N \}$ such that for each $x \in E_i$,
  %
  \[ \left( \int |K(x,y)|^q\; dy \right)^{1/q} = \left( \sum_{j = 1}^M |a_{ij}|^q |F_j| \right)^{1/q} = \| K \|_{L^q(Y) L^\infty(X)}. \]
  %
  If $f = \mathbf{I}_{E_i}$, then $\| f \|_{L^1(X)} = |E_i|$, and $T_K f = \sum_{j = 1}^M a_{ij} \mathbf{I}_{F_j}$, so
  %
  \[ \| T_K f \|_{L^q(Y)} = \left( \sum_{j = 1}^M |a_{ij}|^q |F_j| \right)^{1/q} = \| K \|_{L^q(Y)L^\infty(X)} \| f \|_{L^1(X)}. \]
  %
  Thus we conclude that for a certain `dense' family of $K$, the inequality above is tight, which gives a strong heuristic that the inequality above is tight for a great many operators $K$, which trivializes the analysis of $L^1(X) \to L^q(Y)$ estimates.
\end{remark}

A dual statement trivializes the analysis of bounds from $L^p(X)$ to $L^\infty(Y)$.

\begin{theorem}
  Suppose $1 \leq p \leq \infty$. Then
  %
  \[ \| S_K f \|_{L^\infty(Y)} \leq \| K \|_{L^{p^*}(X) L^\infty(Y)} \| f \|_{L^p(X)}. \]
  %
  Thus if $\| K \|_{L^{p^*}(X) L^\infty(Y)} < \infty$, then $T_K f(y)$ is well defined for almost every $y \in Y$, and
  %
  \[ \| T_K f \|_{L^\infty(Y)} \leq \| K \|_{L^{p^*}(X) L^\infty(Y)} \| f \|_{L^p(X)}. \]
\end{theorem}
\begin{proof}
  One option to proving this bound is to take the adjoint of the kernel operator $T_K$ and rely on previous estimates, but we can work more directly. Applying H\"{o}lder's inequality, we conclude that
  %
  \[ \| S_K f \|_{L^\infty(Y)} = \| K f \|_{L^1(X) L^\infty(Y)} \leq \| K \|_{L^{p^*}(X) L^\infty(Y)} \| f \|_{L^p(X)}. \qedhere \]
\end{proof}

Though trivial, the two kernel bounds can often be applied together with an interpolation argument to give more complicated bounds.

\begin{theorem}[Schur's Test]
  Suppose that $\| K \|_{L^1(X) L^\infty(Y)} \leq A$ and $\| K \|_{L^1(Y) L^\infty(X)} \leq B$. Then for every $1 \leq p \leq \infty$ and $f \in L^p(X)$, $(T_K f)(y)$ is well defined by an absolutely convergent integral, and
  %
  \[ \| T_K f \|_{L^p(Y)} \leq A^{1 - 1/p} B^{1/p} \| f \|_{L^p(X)}. \]
\end{theorem}
\begin{proof}
  The previous two results imply that $S_K$ is bounded from $L^1(X)$ to $L^1(Y)$ and from $L^\infty(X)$ to $L^\infty(Y)$. Real interpolation (since $S_K$ is sublinear) shows that $S_K$ is bounded from $L^p(X)$ to $L^p(Y)$ for all $1 \leq p \leq \infty$. Thus the operator $T_K$ is well defined by Lebesgue integrals for $f \in L^p(X)$. Applying the Riesz-Thorin interpolation theorem to $T_K$, which satisfies the bounds $\| T_K f \|_{L^1(Y)} \leq A \| f \|_{L^1(X)}$ and $\| T_K f \|_{L^\infty(Y)} \leq B \| f \|_{L^\infty(X)}$, we obtain the required result.
\end{proof}

For $1 < p < \infty$, we do not expect Schur's test to be sharp in general. But a good heuristic is that it is sharp provided that
%
\begin{itemize}
  \item For all $y \in Y$,
  %
  \[ \int |K(x,y)|\; dx \approx A \]
  %
  and for all $x \in X$,
  %
  \[ \int |K(x,y)|\; dy \approx B. \]

  \item There is little oscillation in the kernel $K$.
\end{itemize}
%
Assuming $X$ and $Y$ have finite measure, from the first property we conclude that
%
\[ A |Y| \approx B |X|. \]
%
Thus if we set $f = \mathbf{I}_X$, then $Tf(y) \approx A$ for all $y \in Y$, hence
%
\[ \| Tf \|_{L^p(Y)} \approx A |Y|^{1/p} \approx A^{1 - 1/p} B^{1/p} |X|^{1/p}. \]
%
Thus we have tightness. If the second property remains true, but the first property fails, Schur's lemma still may remain sharp if we consider a weighted inequality, or alternatively, if we decompose the operator into components on which the marginal is approximately constant.

In some senses, if we are allowed to work with arbitrary weights, and if $K \geq 0$, Schur's test is always sharp. Suppose that
%
\[ \| T_K f \|_{L^p(Y)} \leq A \| f \|_{L^p(X)} \]
%
for all $f \in L^p(X)$, and this inequality is sharp for some particular function $f_0$. We may assume without loss of generality that $\| f_0 \|_{L^p(X)} = 1$ and, since $K$ is non-negative, that $f \geq 0$. Thus
%
\[ \int_Y (T_K f_0(y))^p\; dy = A^p. \]
%
An application of Lagrangian multipliers and basic calculus of variations then shows that there exists a scalar $\lambda$ such that
%
\[ T_K^*((T_K f)^{p-1})(x) = \lambda f(x)^{p-1}. \]
%
But this means that
%
\begin{align*}
  \lambda &= \int \lambda f(x)^p\; dx\\
  &= \int f(x)T_K^*((T_K f)^{p-1})(x)\; dx\\
  &= \int (T_K f)^p(x) = A^p.
\end{align*}
%
Thus if we set $w(x) = f(x)$ and $v(y) = (T_K f(y))^{p-1}$, then
%
\[ \int_X K(x,y) w(x)\; dx = v(y)^{1/(p-1)} \]
%
and
%
\[ \int_Y K(x,y) v(y)\; dy = A^p w(x)^{p-1}. \]
%
Using these estimates, a weighted variant of Schur's lemma gives the bound $\| T_K f \|_{L^p(X)} \leq A \| f \|_{L^p(X)}$, which shows that the two weighted identities above contain as much information as the original bound.

TODO: Fill in rest of Tao's notes.











\section{Localization In Space}

Localization is a fundamental technique in anlaysis, since it enables us to isolate certain parts of a function or operator. If we understand these localized parts, one can then often recover results about the original result using a partition of unity.











\chapter{Maximal Averages}

This chapter is about exploring the behaviour of basic averaging operators. A classical example, given a function $f \in L^1_{\text{loc}}(\RR)$, are the averaging operators
%
\[ A_\delta f(x) = \frac{1}{2\delta} \int_{x-\delta}^{x+\delta} f(y)\; dy. \]
%
If $f \in C(\RR)$, then for each $x \in \RR$, $\lim_{\delta \to 0} A_\delta f(x) = f(x)$. This fact is fundamentally connected to differentiation under the integral sign; if we define the function
%
\[ F(x) = \int_0^x f(y)\; dy \]
%
then for each $x \in \RR$,
%
\[ F'(x) = \lim_{h \to 0} \frac{F(x+h) - F(x)}{h} = \lim_{h \to 0} \frac{1}{h} \int_x^{x+h} f(y)\; dy = f(x). \]
%
Our main goal will be study whether pointwise convergence of the averages $A_\delta f$ hold for a more general family of functions or equivalently, studying whether a kind of fundamental theorem of calculus holds for a more general family of measurable functions, which are not necessarily continuous.


The classical family of averaging operators are defined for $\delta > 0$, $f \in L^1_{\text{loc}}(\RR^d)$, and $x \in \RR^d$ by setting
%
\[ A_\delta f(x) = \frac{1}{|B(x,\delta)|} \int_{B(x,\delta)} f(y)\; dy, \]
%
where $B(x,\delta)$ is the ball of radius $\delta$ centred at $x$. A simple application of Schur's lemma shows that $\| A_\delta f \|_{L^p(\RR^d)} \leq \| f \|_{L^p(\RR^d)}$ for all $1 \leq p \leq \infty$, uniformly in $p$. This uniform bound in $\delta$ is strong enough, together with the density of compactly supported continuous functions is enough to conclude that for any $f \in L^p(\RR^d)$, for $1 \leq p < \infty$, $A_\delta f$ converges to $f$ in $L^p$ norm. This implies that for any $f \in L^p(\RR^d)$, there exists a sequence $\delta_i$ converging to zero such that $A_{\delta_i} f$ converges to $f$ pointwise almost everywhere. In this chapter, we would like to show $A_\delta f$ converges to $f$ pointwise almost everywhere \emph{without taking a subsequence of values $\delta_i$}.

Hardy and Littlewood introduced a powerful technique to study such pointwise convergence problems, known as the \emph{method of maximal functions}. For each $f \in L^1_{\text{loc}}(X)$, we define
%
\[ Mf(x) = \sup_{\delta > 0} A_\delta |f|(x) = \sup_{\delta > 0} \frac{1}{|B(x,\delta)|} \int_{B(x,\delta)} |f(y)|\; dy. \]
%
The next theorem indicates why obtaining bounds on a maximal operator gives pointwise convergence results.

\begin{theorem}
  Let $V$ be a quasinorm space, let $0 < q < \infty$, and consider a family of bounded operators $T_t: V \to L^{q,\infty}(X)$. Then we can define the pointwise maximal operator
  %
  \[ T_* f(x) = \sup_t |T_t f(x)|. \]
  %
  Suppose that for every $f \in L^p(X)$,
  %
  \[ \| T_* f \|_{L^{q,\infty}(X)} \lesssim \| f \|_V. \]
  %
  Then for any bounded operator $S: V \to L^{q,\infty}(X)$, the set
  %
  \[ \{ f \in V : \lim_{t \to \infty} T_t f(y) = Sf(y)\; \text{for a.e $y$} \} \]
  %
  is closed in $V$.
\end{theorem}
\begin{proof}
  Fix a sequence $\{ u_n \}$ in $V$ converging to $u \in V$, and suppose for each $n$,
  %
  \[ \lim_{t \to \infty} (T_t u_n)(x) = Su_n(x) \]
  %
  holds for almost every $x \in X$. For each $\lambda > 0$, we find
  %
  \begin{align*}
    |\{ x \in X: &\limsup_{t \to \infty} |T_t u(x) - Su(x)| > \lambda \}|\\
    &\leq |\{ x \in X: \limsup_t |T_t(u - u_n)(x) - S(u - u_n)(x)| > \lambda \}|\\
    &\leq |\{ x \in X : |T_*(u - u_n)(x)| > \lambda/2 \}| + | \{ x: |S(u - u_n)(x)| > \lambda/2 \} |\\
    &\lesssim_{p,q} \frac{\| u - u_n \|_V^q}{\lambda^q} + \frac{\| u - u_n \|_V^p}{\lambda^p}.
  \end{align*}
  %
  as $n \to \infty$, this quantity tends to zero. Thus for all $\lambda > 0$,
  %
  \[ |\{ x: \limsup_{t \to \infty} |T_t u(x) - Su(x)| > \lambda \}| = 0 \]
  %
  Taking $\lambda \to 0$ gives that $\limsup_t |T_t u(x) - Su(x)| = 0$ for almost every $x \in X$. But this means precisely that $T_tu(x) \to Su(x)$ for almost every $x \in X$.
\end{proof}

Taking $t = \delta$, $T_t = A_\delta$, and $S$ the identity map, the theorem above implies that one way to obtain almost everywhere convergence for the averages we consider is via bounding the maximal operator $M$. Thus we consider a bound of the form
%
\[ \left\| \sup_{\delta > 0} A_\delta f \right\|_{L^{q,\infty}(\RR^d)} \lesssim \| f \|_V \]
%
for an appropriate norm $\| \cdot \|_V$ and $0 < q < \infty$. We have already obtained a bound
%
\[ \sup_{\delta > 0} \| A_\delta f \|_{L^{q,\infty}(\RR^d)} \leq \sup_{\delta > 0} \| A_\delta f \|_{L^q(\RR^d)} \leq \| f \|_{L^q(\RR^d)} \]
%
but moving the supremum inside the $L^q$ norm is nontrivial. One way to think about the difference between the two bounds is that the latter uniformly controls the height and width of the functions $A_\delta f$, whereas the former inequality shows that the main contribution to the height and widths of the functions $A_\delta f$ are uniformly supported in similar regions of space.

\section{Covering Methods}

The bound $\| Mf \|_{L^\infty(\RR^d)} \leq \| f \|_{L^\infty(\RR^d)}$ from a direct calculation. Thus there are trivial techniques of bounding the height of the function $Mf$ in terms of the height of the function $f$. The difficult part is obtaining control of the width of $Mf$ in terms of the width of $f$. This can only be obtained up to a certain degree, because unless $f = 0$, $Mf$ is non-vanishing on the entirety of $\RR^d$ so the width of $f$ `explodes'. A slightly more technical calculation shows that we cannot even have a bound of the form $\| Mf \|_{L^1(\RR^d)} \lesssim \| f \|_{L^1(\RR^d)}$. In fact, $\| Mf \|_{L^1(\RR^d)} = \infty$ for any nonzero $f \in L^1(\RR^d)$.

\begin{example}
  Fix $f \in L^1(\RR^d)$. By rescaling, we may assume without loss of generality that $\| f \|_{L^1(\RR^d)} = 2$. Then, for suitably large $R \geq 1$,
  %
  \[ \int_{B_R(0)} |f(x)|\; dx \geq 1. \]
  %
  For each $x \in \mathbf{R}^d$, $B_R(0) \subset B_{|x|+R}(x)$ and so
  %
  \[ Mf(x) \geq \fint_{B_{|x|+R}(x)} |f(y)|\; dy \gtrsim \frac{1}{(|x| + R)^d} \gtrsim \frac{1}{|x|^d} \]
  %
  But this means that
  %
  \[ \int_{\RR^d} |Mf(x)| \gtrsim \int_{\RR^d} \frac{1}{|x|^d} = \infty. \]
  %
  If we are more careful, we can even find examples of $f \in L^1(\RR^d)$ such that $Mf$ is not even locally integrable. If $f(x) = 1/|x| \log|x|^2$, then the fact that for $x \geq 0$
  %
  \begin{align*}
    \frac{1}{2h} \int_{x-h}^{x+h} \frac{dy}{|y| \log |y|^2} &= \frac{1}{2h} \left( \frac{1}{\log(x-h)} - \frac{1}{\log(x+h)} \right)\\
    &= \frac{1}{2x \log x} + O \left( \frac{h}{\log x} \right)
  \end{align*}
  %
  implies that
  %
  \[ Mf(x) \geq \frac{1}{2x \log x}. \]
  %
  Thus $Mf$ isn't integrable about the origin. Note however, that $Mf$ is on the \emph{border} of integrability, which hints at the fact that we have a weak type $(1,1)$ bound.
\end{example}

The last example shows that $|Mf(x)| \gtrsim |x|^{-d}$. Note, however, that $|x|^{-d}$ is only \emph{barely} nonintegrable. We will also show that $Mf$ is barely nonintegrable by obtaining a bound
%
\[ \| Mf \|_{L^{1,\infty}(\RR^d)} \lesssim_d \| f \|_{L^1(\RR^d)}. \]
%
Interpolation thus shows that $\| Mf \|_{L^p(\RR^d)} \lesssim_{d,p} \| f \|_{L^p(\RR^d)}$ for all $1 < p \leq \infty$. The standard real-variable technique of obtaining this bound is geometric, applying a covering argument. To obtain the weak-type bound, we must show that the set
%
\[ E_\lambda = \{ x \in \RR^d : |Mf(x)| > \lambda \} \]
%
is small. If $|Mf(x)| > \lambda$, there is a ball $B$ around $x$ such that
%
\[ \int_B |f(y)|\; dy > \lambda |B|. \]
%
Clearly $B \subset E_\lambda$. If we could find a large family of \emph{disjoint balls} $B_1,\dots,B_N$ such that this inequality held, such that $\sum |B_i| \gtrsim_d |E_\lambda|$, then we would conclude that
%
\[ \| f \|_{L^1(\RR^d)} \geq \sum_{i = 1}^N \int_{B_i} |f(y)|\; dy > \lambda \sum_{i = 1}^N |B_i| \gtrsim_d \lambda |E_\lambda| \]
%
which would show $|E_\lambda| \lesssim_d \| f \|_{L^1(\RR^d)} / \lambda$, which would show $\| Mf \|_{L^{1,\infty}(\RR^d)} \lesssim_d \| f \|_{L^1(\RR^d)}$. This intuition is true, and the process through which we obtain the family of disjoint balls $B_1,\dots,B_N$ is through the \emph{Vitali covering lemma}.

This particular technique has been shown to generalize to a wide variety of situations including the maximal ball average. All that is really required for the basic theory is a basic `covering type argument' that holds in a great many situations. In particular, we can generalize this argument to a \emph{space of homogenous type}. We consider a locally compact topological space $X$ together with a nonzero Radon measure. For each $x \in X$ and $\delta > 0$, we fix an open, precompact set $B(x,\delta)$, which we assume to be monotonically increasing in $\delta$. The fundamental property we require of these sets is that there is $c > 0$ such that for any $x \in X$ and $\delta > 0$, if we set
%
\[ B^*(x,\delta) = \bigcup \{ B(x',\delta): B(x,\delta) \cap B(x',\delta) \neq \emptyset \}, \]
%
then $|B^*(x,\delta)| \leq c |B(x,\delta)|$. In the case of balls in $\RR^d$, $B^*(x,\delta) \subset B^*(x,3\delta)$, and so $|B^*(x,\delta)| \leq 3^d |B(x,\delta)|$, so $c = 3^d$. More generally, if we are working in any metric space $X$, where $B(x,\delta)$ are the balls of radius $\delta$ in this metric space, and our measure satisfies a \emph{doubling condition}
%
\[ |B(x,3\delta)| \lesssim |B(x,\delta)| \]
%
for all $x \in X$ and $\delta > 0$, then our assumption holds. We also assume the following two technical assumptions
%
\begin{itemize}
  \item For any $x \in X$,
  %
  \[ \bigcap_{\delta > 0} \overline{B}(x,\delta) = \{ x \} \quad\text{and}\quad \bigcup_{\delta > 0} B(x,\delta) = X \]

  \item For any open set $U \subset X$ and $\delta > 0$, the function
  %
  \[ x \mapsto |B(x,\delta) \cap U| \]
  %
  is a continuous function of $x$.
\end{itemize}
%
These are fairly easily verifiable in any particular instance. It follows from these technical assumptions that $|B(x,\delta)| > 0$ for each $x \in X$ and $\delta > 0$, and moreover, for each $\delta > 0$, and $f \in L^1_{\text{loc}}(X)$, the averaged function $A_\delta f$ given by setting
%
\[ A_\delta f(x) = \frac{1}{|B(x,\delta)|} \int_{B(x,\delta)} f(y)\; dy, \]
%
is measurable.

\begin{lemma}
  If $f \in L_1^{\text{loc}}(X)$, then $A_\delta f$ is a measurable function.
\end{lemma}
\begin{proof}
  If $f = a_1 \mathbf{I}_{U_1} + \dots + a_N \mathbf{I}_{U_N}$ is a simple function, where $U_1,\dots,U_N$ are open sets, then
  %
  \[ A_\delta f(x) = a_1 \frac{|B(x,\delta) \cap U_1|}{|B(x,\delta)|} + \dots + a_N \frac{|B(x,\delta) \cap U_N|}{|B(x,\delta)|} \]
  %
  is a continuous function by our technical assumptions. Next, if $f \geq 0$ is a step function, then there exists a monotonically decreasing family of simple functions $\{ f_n \}$ such that $f_n \to f$ pointwise, then the monotone convergence theorem implies that $A_\delta f_n \to A_\delta f$ pointwise, so $A_\delta f$ is measurable. Finally, decomposing any measurable function into the difference of non-negative measurable functions and then considering pointwise limits of step functions completes the proof.
\end{proof}

It also follows from our technical assumptions that for any open set $U$ containing $x$, there exists $\delta_0$ such that for $\delta \leq \delta_0$, $\overline{B(x,\delta)} \subset U$. It follows that for any $f \in C(X)$ and $x \in X$,
%
\begin{equation} \label{pointwiseaverageconvergence}
  \lim_{\delta \to 0} A_\delta f(x) = f(x).
\end{equation}
%
If $Mf = \sup_{\delta > 0} A_\delta f$, then we will show
%
\[ \| Mf \|_{L^{1,\infty}(X)} \lesssim_c \| f \|_{L^1(X)}. \]
%
In particular, this shows that for any $f \in L^1(X)$,
%
\[ \lim_{\delta \to 0} A_\delta f(x) = f(x) \]
%
for almost every $x \in X$. Since this result is a \emph{local result}, it is easy to verify that the result also holds for any $f \in L^1_{\text{loc}}(X)$, i.e. it also holds for any $f \in L^p(X)$ for $1 \leq p \leq \infty$.

\begin{lemma}[Vitali Covering Lemma]
    If $B_1, \dots, B_n$ is a finite collection of balls in $X$, then there is a disjoint subcollection $B_{i_1}, \dots, B_{i_M}$ such that
    %
    \[ \left| \bigcup_{i = 1}^N B_i \right| \leq c \sum_{j = 1}^M |B_{i_j}|. \]
\end{lemma}
\begin{proof}
  Consider the following greedy selection procedure. Let $B_{i_1}$ be the ball in our collection of maximal radius. Given that we have selected $B_{i_1},\dots,B_{i_k}$, let $B_{i_{k+1}}$ be the ball of largest radius not intersecting previous balls selected if possible. Continue doing this until we cannot select any further balls. If $B_j$ is any ball not chosen by this procedure, it must intersect a ball with radius at least as big as $B_j$ itself. But this means that
  %
  \[ \bigcup_{i = 1}^N B_i \subset \bigcup_{j = 1}^M B^*_{i_j}. \]
  %
  Thus
  %
  \[ \left| \bigcup_{i = 1}^N B_i \right| \leq \sum_{j = 1}^M |B^*_{i_j}| \leq c \sum_{j = 1}^M |B_{i_j}|. \qedhere \]
\end{proof}

We have already indicated our proof strategy for proving a weak type bound for the maximal operator, but let us now do things more rigorously.

\begin{theorem}
  For any $f \in L^1(X)$,
  %
  \[ \| Mf \|_{L^{1,\infty}(X)} \leq c \| f \|_{L^1(X)}. \]
\end{theorem}
\begin{proof}
  Set
  %
  \[ E_\lambda = \{ x \in \mathbf{R}^d: Mf(x) > \lambda \}. \]
  %
  Fix a compact subset $K$ of $E_\lambda$ of finite measure. Then $K$ is covered by finitely many balls $B_1,\dots,B_N$ such that on each ball $B_i$,
  %
  \[ \int_{B_i} |f(y)|\; dy > \lambda |B_i|. \]
  %
  Using the Vitali lemma, extract a disjoint subfamily $B_{i_1},\dots, B_{i_M}$ with
  %
  \[ \left| \sum_{j = 1}^M B_{i_j} \right| \leq c \sum_{j = 1}^M |B_{i_j}|. \]
  %
  Then
  %
  \[ \| f \|_{L^1(X)} > \lambda \sum_{j = 1}^M |B_{j_i}| \geq \frac{\lambda}{c} \left| \bigcup_{j = 1}^M B_{j_i} \right| \geq \frac{\lambda |K|}{c}. \]
  %
  Rearranging gives
  %
  \[ |K| \leq \frac{c \| f \|_{L^1(X)}}{\lambda}. \]
  %
  Since $K$ was arbitrary, inner regularity gives
  %
  \[ |E_\lambda| \leq \frac{c \| f \|_{L^1(X)}}{\lambda}. \]
  %
  Since $\lambda$ was arbitrary, the proof is complete.
\end{proof}

\begin{remark}
  The same covering-type argument also gives the boundedness of the \emph{uncentered} Hardy-Littlewood maximal function
  %
  \[ M'f(x) = \sup_{x \in B} \frac{1}{|B|} \int_B |f(y)|\; dy \]
  %
  where $B$ ranges over all balls $\{ B(x',\delta) : x' \in X, \delta > 0 \}$. Since the supremum is over more balls, we have $Mf(x) \leq M'f(x)$ for each $x \in X$. If we assume a stronger condition than we did previously, that if $B(x',\delta) \cap B(x,\delta) \neq \emptyset$, then $B(x',\delta) \subset B(x,c\delta)$ (so that $B^*(x,\delta) \subset B(x,c\delta)$), and that $|B(x,c\delta)| \leq c' |B(x,\delta)|$, then we also find $M' f(x) \leq c' Mf(x)$. Thus in these situations, $M$ and $M'$ are roughly equivalent operators. We shall find these assumptions are also useful for generalizing the Calderon-Zygmund type decompositions that come up in the real-variable analysis of singular integrals.
\end{remark}

\begin{remark}
  We can exploit the ordering of the real line to show that for any family of intervals $\{ I_\alpha \}$ covering a compact set $K$, there is a subcover $I_1,\dots, I_N$ such that any point in $\RR$ is contained in at most two of the intervals. A modification of the argument above shows this gives the slightly better bound $\| Mf \|_{L^{1,\infty}(\RR)} \leq 2 \| f \|_{L^1(\RR)}$, rather than the bound $\| Mf \|_{L^{1,\infty}(\RR)} \leq 3 \| f \|_{L^1(\RR)}$.
\end{remark}





\section{Dyadic Methods}

There are many different techniques for showing the boundedness of the maximal operator. Let us consider some \emph{dyadic methods} for proving the inequality. Recall that the set of dyadic cubes is
%
\[ \{ Q_{n,k} : n \in \ZZ, k \in 2^n \ZZ^d \} \]
%
where $Q_{n,k}$ is the cube $[k_1, k_1 + 2^n] \times \dots \times [k_d, k_d + 2^n]$. We note that dyadic cubes nest within one another much more easily than balls do (cubes are either nested or disjoint). In particular, if $Q_1,\dots,Q_N$ is any collection of dyadic cubes, there exists an almost disjoint subcollection $Q_{i_1}, \dots, Q_{i_k}$ with $Q_{i_1} \cup \dots \cup Q_{i_k} = Q_1 \cup \dots \cup Q_N$. In particular, this operates as a Vitali-type covering lemma with a constant independant of $d$, so if we define the \emph{dyadic} Hardy-Littlewood maximal operator
%
\[ M_\Delta f(x) = \sup_{x \in Q} \frac{1}{|Q|} \int_Q |f(y)|\; dy \]
%
then we easily obtain the bound $\| M_\Delta f \|_{L^{1,\infty}(\RR^d)} \leq \| f \|_{L^1(\RR^d)}$, with no implicit constant depending on $d$. The bound $\| M_\Delta f \|_{L^\infty(\RR^d)} \leq \| f \|_{L^\infty(\RR^d)}$ is easy, so interpolation gives $\| M_\Delta f \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)}$ for all $1 < p \leq \infty$, with a constant now \emph{independant of dimension}.

Two families of sets $\{ B(x,\delta) : x \in \RR^d, \delta > 0 \}$ and $\{ B'(x,\delta) : x \in \RR^d, \delta > 0 \}$ are \emph{equivalent} if there exists $c_1$, $c_2$ such that
%
\[ B'(x, c_1 \delta) \subset B(x,\delta) \subset B(x,c_2 \delta). \]
%
It follows that the resultant maximal averages from the two sets pointwise differ from one another by a universal constant. This allows us to obtain bounds for maximal averages over cubes centred at a point, and ellipses with bounded eccentricity, etc. If for $2^k \leq \delta \leq 2^{k+1}$, we set $B(x,\delta)$ to be a dyadic cube with sidelength $1/2^k$, then the family $\{ B(x,\delta) \}$ is \emph{not} equivalent to the usual family of cubes, but below we show that bounds on the two maximal operators are still equivalent.

If $Q$ is a dyadic cube, then it is contained in a ball $B$ with $|Q| \lesssim_d B$. It follows that for any function $f$ and $x \in \RR^d$,
%
\[ M_\Delta f(x) \lesssim_d Mf(x). \]
%
Thus bounds on $M$ automatically give bounds on $M_\Delta$. The opposite pointwise inequality is unfortunately, \emph{not true}. For instance, if $f$ is the indicator function on $[0,1]$. Then $M_\Delta f$ is supported on $[0,1]$, but $Mf$ is positive on the entirety of $\RR$. To reduce the study of $M$ to the study of $M_\Delta$, we must instead rely on the \emph{$1/3$ translation trick} of Michael Christ.

\begin{lemma}
  Let $I \subset [0,1]$ be an interval. Then there exists an interval $J$, which is either a dyadic interval, or a dyadic interval shifted by $1/3$, such that $I \subset J$ and $|J| \lesssim |I|$.
\end{lemma}
\begin{proof}
  Let $I = [a,b]$. Perform a binary expansion of $a$ and $b$, writing
  %
  \[ a = 0.a_1a_2 \dots \quad\text{and}\quad b = b_1 b_2 \dots. \]
  %
  Let $n$ be the first value where $a_n \neq b_n$. Then $a_n = 0$ and $b_n = 1$. Then $[a,b]$ is contained in the dyadic interval
  %
  \[ Q_1 = \left[ 0.a_1 \dots a_{n-1}, 0.a_1\dots a_{n-1} + 1/2^{n-1} \right] \]
  %
  which has length $1/2^{n-1}$. Find $0 \leq i < \infty$ such that
  %
  \[ a = 0.a_1 \dots a_{n-1} 0 1^i 0 \dots \]
  %
  and $0 \leq j < \infty$ such that
  %
  \[ b = 0.a_1 \dots a_{n-1} 1 0^j 1. \]
  %
  If no such $j$ exists, then $b = 0.a_1 \dots a_{n-1} 1$, and so $[a,b]$ is contained in the rational interval
  %
  \[ Q_2 = \left[ 0.a_1 \dots a_{n-1} 0 1^i, 0.a_1 \dots a_{n-1} 0 1^i + 1/2^{n+i} \right] \]
  %
  and $b - a \geq 1/2^{n+i+1}$, so $|Q_2| \leq 2(b - a)$. Now if $i \leq 5$ or $j \leq 5$, then $b - a \geq 1/2^{n+5}$, so $|Q_1| \leq 2^5(b-a)$. On the other hand, if $i \geq 5$ and $j \geq 5$, we find $b - a \geq 1/2^{n+\min(i,j)}$. Then we can find a dyadic interval $Q_3$ and $2 \leq r \leq 5$ such that
  %
  \[ 1/3 + Q_3 = \left[ 0.a_1 \dots a_{n-1} 0 1^{\min(i,j)-r} 1 0 1 0 \dots, 0.a_1 \dots a_{n-1} 0 1^{i-r} 1 0 1 0 \dots + 1/2^{n+\min(i,j)-r}  \right] \]
  %
  and so $1/3 + Q_3$ contains $[a,b]$ and $|Q_3| = 1/2^{n+\min(i,j)-r} \leq 2^5 (b - a)$.
\end{proof}

It follows that for each $x \in \RR^d$, and any function $f$,
%
\[ Mf(x) \lesssim_d (M_\Delta f)(x) + (M_\Delta \text{Trans}_{1/3} f)(x). \]
%
Since the $L^p$ norms are translation invariant, this implies that the dyadic maximal operator and the maximal operator satisfy equivalent bounds, with operator norms differing by a constant depending on $n$. Since we independently obtained bounds on $M_\Delta$, this section provides an alternate proof to the boundedness of $M$.

There is an alternate way to view the operator $M_\Delta$. For each integer $n$, we let $\mathcal{B}(n)$ denote the family of all sidelength $1/2^n$ dyadic cubes. Thus $\mathcal{B}(n)$ gives a decomposition of $\RR^d$ into an almost disjoint union of cubes. If we define the conditional expecation operators
%
\[ E_n f(x) = \sum_{Q \in \mathcal{B}(n)} \left( \frac{1}{|Q|} \fint_Q f \right) \cdot \mathbf{I}_Q \]
%
then $M_\Delta f = \sup_{n \in \ZZ} E_n f$. In particular, it is easy to see from the bounds on $M_\Delta$ that for any $f \in L^1_{\text{loc}}(\RR^d)$, $\lim_{n \to \infty} E_n f(x) = f(x)$ holds for almost every $x \in \RR^d$. It is simple to conclude from this result a very useful technique, known as the \emph{Calder\'{o}n-Zygmund decomposition}.

\begin{theorem}
  Given $f \in L^1(\RR^d)$ and $\lambda > 0$, we can write $f = g + b$, where $\| g \|_{L^\infty(\RR^d)} \lesssim_d \lambda$, and there is an almost disjoint family of dyadic cubes $\{ Q_i \}$ such that $g$ is supported on $\bigcup_i Q_i$,
  %
  \[ \sum_i |Q_i| \leq \frac{\| f \|_{L^1(\RR^d)}}{\lambda}, \]
  %
  and for each $i$,
  %
  \[ \int_{Q_i} f(y)\; dy = 0. \]
  %
  We also have $\| g \|_{L^1(\RR^d)}, \| b \|_{L^1(\RR^d)} \lesssim_d \| f \|_{L^1(\RR^d)}$.
\end{theorem}
\begin{proof}
  Write $E = \{ x: M_\Delta f(x) > \lambda \}$. By the dyadic Hardy-Littlewood maximal inequality,
  %
  \[ |E| \leq \frac{\| f \|_{L^1(\RR^d)}}{\lambda}. \]
  %
  Because $f$ is integrable, $E \neq \mathbf{R}^d$. Thus we can write $E$ as the almost disjoint union of dyadic cubes $\{ Q_i \}$, such that for each $i$,
  %
  \[ \int_{Q_i} |f(x)|\; dx > \lambda |Q_i|, \]
  %
  and also, if $R_i$ is the parent cube of $Q_i$,
  %
  \[ \int_{R_i} |f(x)|\; dx \leq \lambda |R_i|. \]
  %
  This can be done by a greedy strategy, taking the union of dyadic cubes of largest sidelength contained in $E$. This means
  %
  \[ \int_{Q_i} |f(x)|\; dx \leq \int_{R_i} |f(x)|\; dx \leq \lambda |R_i| \leq 2^d \lambda |Q_i|. \]
  %
  Define
  %
  \[ g(x) = \begin{cases} f(x) &: x \not \in E, \\ \frac{1}{|Q_i|} \int_{Q_i} f(x)\; dx &: x \in Q_i\ \text{for some $i$}. \end{cases} \]
  %
  For almost every $x \in E^c$, $|f(x)| \leq \lambda$, since $E_n f(x) \leq \lambda$ for each $n$, and $E_n f(x) \to f(x)$ as $n \to \infty$ for almost every $x$. Conversely, if $x \in Q_i$ for some $i$, then
  %
  \[ \left| \frac{1}{|Q_i|} \int_{Q_i} f(x)\; dx \right| \leq \frac{1}{|Q_i|} \int_{Q_i} |f(x)|\; dx \leq 2^d \lambda. \]
  %
  Thus $\| g \|_{L^\infty(\RR^d)} \lesssim_d \lambda$. If we define $b = f - g$, then $b$ is supported on $\bigcup Q_i = E$, and for each $i$,
  %
  \[ \int_{Q_i} b(x)\; dx = \int_{Q_i} \left( f(x) - \frac{1}{|Q_i|} \int_{Q_i} f(y)\; dy \right)\; dx = 0. \qedhere \]
\end{proof}

The Calderon-Zygmund theorem will be very useful to us in the sequel, especially when we analyze the theory of singular integrals.

\section{Lebesgue Density Theorem}

If $E$ is a measurable subset of $\mathbf{R}^d$, and $x \in \mathbf{R}^d$, we say $x$ is a point of \emph{Lebesgue density} of $E$, or has \emph{full metric density} if
%
\[ \lim_{\delta \to 0} \frac{|B(x,\delta) \cap E|}{|B(x,\delta)|} = 1 \]
%
This means that for any $\varepsilon > 0$, the inequality $|B(x,\delta) \cap E| \geq (1 - \varepsilon) |B(x,\delta)|$ holds for suitably small $\delta$, so $E$ asymptotically contains as large a fraction of the local points around $x$ as is possible. Since $\chi_E \in L^1_{\text{loc}}(\mathbf{R}^d)$, we can apply the Lebesgue differentiation theorem to immediately obtain an interesting result.

\begin{theorem}[Lebesgue Density Theorem]
    If $E$ is a measurable subset, then almost every point in $E$ is a point of Lebesgue density, and almost every point not in $E$ is not a point of Lebesgue density.
\end{theorem}

The fact that a point is a point of Lebesgue density implies the existence of large sets of rigid patterns in $E$. A simple corollary is that any set of positive Lebesgue measure contains arbitrarily long arithmetic progressions.

\begin{theorem}
  Let $E \subset \RR^d$ be a set of nonzero Lebesgue measure. Then for any non-zero $a_1,\dots,a_N \in \RR$ there exists $x \in E$ and $c \in \RR$ such that
  %
  \[ a_1 x + c,\dots, a_N x + c \in E. \]
\end{theorem}
\begin{proof}
  Without loss of generality, by translation we may assume $0$ is a point of Lebesgue density of $E$. We then claim that we can set $c = 0$. It is simple to see that if $t_0$ is a point of Lebesgue density for a set $E$ and a set $F$, then it is also a point of Lebesgue density for $E \cap F$. In particular $0$ is a point of Lebesgue density for $E \cap a_1^{-1} E \cap \dots \cap a_N^{-1} E$, which means the set is nonempty. If $y \in E \cap a^{-1} E \cap \dots \cap a_N^{-1} E$, then $y,a_1y, \dots, a_N y \in E$.
\end{proof}

If $f$ is locally integrable, the \emph{Lebesgue set} of $f$ consists of all points $x \in \mathbf{R}^d$ such that $f(x)$ is finite and
%
\[ \lim_{\delta \to 0} \frac{1}{|B_\delta|} \int_{B(x,\delta)} |f(y) - f(x)|\ dy = 0. \]
%
If $f$ is continuous at $x$, it is obvious that $x$ is in the Lebesgue set of $f$, and if $x$ is in the Lebesgue set of $f$, then $A_\delta f(x) \to f(x)$ as $\delta \to 0$.

\begin{theorem}
    If $f \in L^1_{\text{loc}}(\mathbf{R}^d)$, almost every point is in the Lebesgue set of $f$.
\end{theorem}
\begin{proof}
    For each rational number $p$, the function $|f - p|$ is measurable, so that there is a set $E_p$ of measure zero such that for $x \in E_p^c$,
    %
    \[ \lim_{\delta \to 0} \fint_{B(x,\delta)} |f(y) - p|\ dy \to |f(x) - p|. \]
    %
    Taking unions, we conclude that $E = \bigcup E_p$ is a set of measure zero. Suppose $x \in E^c$, and $f(x)$ is finite. For any $\varepsilon > 0$, there is a rational $p$ such that $|f(x) - p| < \varepsilon$, and we know the equation above holds, so
    %
    \begin{align*}
        \lim_{\delta \to 0} \fint_{B(x,\delta)} |f(y) - f(x)|\ dy \leq \limsup_{\delta \to 0} \fint_{B(x,\delta)} \left( |f(y) - p| + |p - f(x)| \right)\ dy \leq 2\varepsilon.
    \end{align*}
    %
    We can then let $\varepsilon \to 0$. Since $f(x)$ is finite for almost all $x$, this completes the proof.
\end{proof}

It is interesting to note that for any $f \in L^1_{\text{loc}}(\RR^d)$, there is $g \in L^1_{\text{loc}}(\RR^d)$ such that $f = g$ almost everywhere, and the Lebesgue set of $g$ is maximal. One choice is to define
%
\[ g(x) = \limsup_{\delta \to 0} \fint_{B(x,\delta)} f(y)\; dy. \]
%
This gives us a way to identify a single pointwise defined function from an equivalence class of locally integrable functions defined distributionally. However, this isn't often done, because it doesn't really help in the analysis of integrable functions. Often the Lebesgue set of $f$ is defined to be the Lebesgue set of $g$, when once to think of the Lebesgue set as a distributional invariant of $f$.

\section{Ergodic Averages}

One consequence of the more general setting to homogenous spaces is that if we define, for $f : \ZZ \to \CC$,
%
\[ Mf(n) = \sup_{N > 0} \sum_{m = 1}^N |f(n + m)| \]
%
then $\| Mf \|_{L^{1,\infty}(\ZZ)} \leq 2 \| f \|_{L^1(\ZZ)}$ and $\| Mf \|_{L^p(\ZZ)} \lesssim_p \| f \|_{L^p(\ZZ)}$ for $1 < p \leq \infty$. A consequence of this inequality is a pointwise convergence result that emerges from ergodic theory. We recall that a \emph{measure preserving system} is a probability space $X$ together with a measure preserving transformation $T: X \to X$.

\begin{theorem}
  Let $X$ and $T$ form a measure preserving transformation. Then for all $f \in L^1(X)$ and almost every $x \in X$, the limit
  %
  \[ \lim_{N \to \infty} \frac{1}{N} \sum_{n = 1}^N T^n f(x) \]
  %
  exists.
\end{theorem}
\begin{proof}
  Fix $N_0 > 0$ and $f \in L^1(X)$, and define a measurable function $F$ on $X \times [2N_0]$ by defining
  %
  \[ F(x,n) = T^n f(x). \]
  %
  Let
  %
  \[ MF(x,n) = \sup_{1 \leq N \leq N_0} \frac{1}{N} \sum_{m = 1}^N T^{n+m} f(x). \]
  %
  Then the integer-valued maximal inequality implies that
  %
  \[ \| MF \|_{l^{1,\infty}[N_0]} \lesssim \| F \|_{l^1[2N_0]} \]
  %
  and integrating in $X$, that
  %
  \[ \| MF \|_{l^{1,\infty}[N_0] L^1(X)} \lesssim \| F \|_{l^1[2N_0] L^1(X)} = \| F \|_{L^1(X \times [2N_0])} = 2N_0 \| f \|_{L^1(X)}. \]
  %
  TODO FINISH THIS.
\end{proof}

\section{Approximations to the Identity}

We now switch to the study of how we can approximate functions by convolutions of concentrated functions around the origin. In this section we define the various classes of such functions which give convergence results, to various degrees of strength. We say a family of integrable functions $\{ K_\alpha : \alpha > 0 \}$ in $\RR^d$ is a \emph{good kernel} if it is bounded in the $L^1$ norm, for every $\alpha > 0$,
%
\[ \int K_\alpha(x)\ dx = 1 \]
%
and if for every $\delta > 0$,
%
\[ \lim_{\alpha \to 0} \int_{|x| \geq \delta} |K_\alpha(x)|\ dx \to 0. \]
%
It requires only basic analysis to verify good kernel convergence.

\begin{theorem}
    If $\{ K_\alpha \}$ is a good kernel, then for any absolutely integrable function $f$, $\lim_{\alpha \to 0} f * K_\alpha = f$ in $L^1(\RR^d)$, and for any continuity point $x$ of $f$, $\lim_{\alpha \to 0} (f * K_\alpha)(x) = f(x)$.
\end{theorem}
\begin{proof}
    Note that
    %
    \begin{align*}
        \| (f * K_\alpha) - f \|_1 &= \int |(f * K_\alpha)(x) - f(x)|\ dx\\
        &= \int \left| \int K_\alpha(y) [f(x - y) - f(x)]\ dy \right|\ dx\\
        &\leq \int |K_\alpha(y)| \| T_y f - f \|_1\ dy
    \end{align*}
    %
    where $(T_y f)(x) = f(x - y)$. We know that $\| T_y f - f \|_1 \to 0$ as $y \to 0$. Thus, for each $\varepsilon$, we can pick $\delta$ such that if $|y| < \delta$, $\| T_y f - f \|_1 \leq \varepsilon$, and if we pick $\alpha$ large enough that $\int_{|y| \geq \delta} |K_\alpha(y)|\ dy \leq \varepsilon$, and then
    %
    \[ \| (f * K_\alpha) - f \|_1 \leq \varepsilon \int_{|y| < \delta} |K_\alpha(y)|\ dy + 2 \| f \|_1 \int_{|y| \geq \delta} |K_\alpha(y)|\ dy \leq \varepsilon[\| K_\alpha \|_1 + 2 \| f \|_1] \]
    %
    Since $\| K_\alpha \|_1$ is universally bounded over $\alpha$, we can let $\varepsilon \to 0$ to obtain convergence. If $x$ is a fixed point of continuity, and for a given $\varepsilon > 0$, we pick $\delta > 0$ with $|f(y) - f(x)| \leq \varepsilon$ for $|y - x| < \delta$, then
    %
    \begin{align*}
        |(f * K_\alpha)(x) - f(x)| &= \left| \int_{-\infty}^\infty f(y) K_\alpha(x - y)\ dy - f(x) \right|\\
        &= \left| \int_{-\infty}^\infty [f(y) - f(x)] K_\alpha(x-y)\ dy \right|\\
        &= \left| \int_{-\delta}^\delta [f(y) - f(x)] K_\alpha(x-y)\ dy \right|\\
        &\ \ \ \ \ + \left| \int_{|y| \geq \delta} [f(y) - f(x)] K_\alpha(x - y)\ dy \right|\\
        &\leq \varepsilon \| K_\alpha \|_1 + [\| f \|_1 + f(x)] \int_{|y| \geq \delta} |K_\alpha(y)|\ dy
    \end{align*}
    %
    If $\| K_\alpha \|_1 \leq M$ for all $\alpha$, and we choose $\alpha$ large enough that $\int_{|y| \geq \delta} |K_\alpha(y)| \leq \varepsilon$, then we conclude the value about is bounded by $\varepsilon [M + \| f \|_1 + f(x)]$, and we can then let $\varepsilon \to 0$.
\end{proof}

To obtain almost sure pointwise convergence of $f * K_\alpha$ to $f$, we must place stronger conditions on our family. We say a family $K_\delta \in L^1(\mathbf{R}^d)$, is an \emph{approximation to the identity} if $\int K_\delta = 1$, and
%
\[ |K_\delta(x)| \lesssim \frac{\delta}{|x|^{d+1}}\ \ \ \ |K_\delta(x)| \lesssim \frac{1}{\delta^d} \]
%
where the constant bound is independent of $x$ and $\delta$. These assumptions are stronger than being a good kernel, because if $K_\delta$ is an approximation to the identity, then
%
\[ \int_{|x| \geq \varepsilon} |K_\delta(x)| \leq \int_\varepsilon^\infty \int_{S^{d-1}} \frac{C \delta}{r}\ d\sigma dr = C \delta |S^{n-1}| \int_\varepsilon^\infty \frac{dr}{r} \leq \frac{C \delta |S^{n-1}|}{\varepsilon} \]
%
which converges to zero as $\delta \to 0$. Combined with
%
\[ \int_{|x| < \varepsilon} |K_\delta(x)| \leq C \int_0^\varepsilon \int_{S^{d-1}} \frac{r^{d-1}}{\delta^d} d\sigma dr = \frac{C \varepsilon^d |S^{n-1}|}{d \delta^d} \]
%
This calculation also implies
%
\begin{align*}
    \| K_\delta \|_1 &\leq C |S^{n-1}| \left[ \frac{\delta}{\varepsilon} + \frac{\varepsilon^d}{\delta^d} \right]
\end{align*}
%
Setting $\varepsilon = \delta$ optimizes this value, and gives a bound
%
\[ \| K_\delta \|_1 \leq 2C |S^{n-1}| \]
%
So an approximation to the identity is a stronger version of a good kernel.

\begin{example}
    If $\varphi$ is a bounded function in $\mathbf{R}^d$ supported on the closed ball of radius one with $\int \varphi(x)\ dx = 1$, then $K_\delta(x) = \delta^{-d} \varphi(\delta^{-1}x)$ is an approximation to the identity, because by a change of variables, we calculate
    %
    \[ \int_{\mathbf{R}^d} \frac{\varphi(\delta^{-1}x)}{\delta^d} = \int_{\mathbf{R}^d} \varphi(x) = 1 \]
    %
    Because $\varphi$ is bounded, we find
    %
    \[ |K_\delta(x)| \leq \frac{\| \varphi \|_\infty}{\delta^d} \]
    %
    Now $K_\delta$ is supported on a disk of radius $\delta$, this bound also shows
    %
    \[ |K_\delta(x)| \leq \frac{\delta \| \varphi \|_\infty}{|x|^{d+1}} \]
    %
    and so $K_\delta$ is an approximation to the identity. If $\varphi$ is an arbitrary integrable function, then $K_\delta$ will only be a good kernel.
\end{example}

\begin{example}
    The Poisson kernel in the upper half plane is given by
    %
    \[ P_y(x) = \frac{1}{\pi} \frac{y}{x^2 + y^2} \]
    %
    where $x \in \mathbf{R}$, and $y > 0$. It is easy to see that
    %
    \[ P_y(x) = y^{-1} P_1(xy^{-1}) \]
    %
    And
    %
    \[ \int \frac{1}{1 + x^2} = \arctan(\infty) - \arctan(-\infty) = \pi \]
    %
    We easily obtain the bounds
    %
    \[ |P_y(x)| \leq \frac{\| P_1 \|_\infty}{y}\ \ \ \ \ |P_y(x)| \leq \frac{y}{\pi |x|^2} \]
    %
    so the Poisson kernel is an approximation to the identity.
\end{example}

\begin{example}
    The heat kernel in $\mathbf{R}^d$ is defined by
    %
    \[ H_t(x) = \frac{e^{-|x|^2/4t}}{(4 \pi t)^{d/2}} \]
    %
    where $\delta = t^{1/2} > 0$. Then $H_t(x) = \delta^{-d} H_1(x\delta^{-1})$, and
    %
    \[ \int e^{-|x|^2/4} = \frac{1}{2^d} \int e^{-|x|^2} = \frac{|S^{n-1}|}{2^d} \int_0^\infty r^{d-1} e^{-r^2} dr \]
    %
%    By induction, we can prove that if $d$ is odd, then the antiderivative of $r^de^{-r^2}$ is equal to $P_d(r)e^{-r^2}$, where the coefficients of $P_d$ are nonzero only when the coefficient index is even. This follows because the chain rule gives
    %
%    \[ \int re^{-r^2} = -e^{-r^2}/2 \]
    %
%    and an integration by parts gives
    %
%    \[ \int r^{d+2}e^{-r^2} = r^2P_d(r)e^{-r^2} - 2 \int rP_d(r)e^{-r^2} \]
    %
%    Thus
    %
%    \[ \int r^3e^{-r^2} = (-r^2/2)e^{-r^2} + \int re^{-r^2} = (-1/2)(r^2 + 1) e^{-r^2} \]
%    \[ \int r^5e^{-r^2} = -(1/2) r^2(r^2 + 1)e^{-r^2} + \int r(r^2 + 1) e^{-r^2} = (-1/2)[r^4 + 2r^2 + 2] \]
%    \[ \int r^7e^{-r^2} = -(1/2) r^2[r^4 + 2r^2 + 2]e^{-r^2} + \int (r^5 + 2r^3 + 2r) e^{-r^2} = (-1/2) [r^6 + 3r^4 + 6r^2 + ] e^{-r^2} \]
\end{example}

\begin{example}
    The Poisson kernel for the disk is
    %
    \[ \frac{P_r(x)}{2 \pi} = \begin{cases} \frac{1}{2\pi} \frac{1 - r^2}{1 - 2r \cos x + r^2} &: |x| \leq \pi \\ 0 &: |x| > \pi \end{cases} \]
    %
    where $0 < r < 1$, and $\delta = 1-r$.
\end{example}

\begin{example}
    The F\'{e}jer kernel is
    %
    \[ \frac{F_N(x)}{2 \pi} = \begin{cases} \frac{1}{2 \pi N} \frac{\sin^2(Nx/2)}{\sin^2(x/2)} \end{cases} \]
    %
    where $\delta = 1/N$.
\end{example}

As $\delta \to 0$, we may think of the $K_\delta$ as `tending to the unit mass' Dirac delta function $\delta$ at the origin. $\delta$ may be given a precise meaning, either in the theory of Lebesgue-Stieltjes measures or as a `generalized function', but we don't need it to discuss the actual convergence results of the functions $K_\delta$.

\begin{theorem}
    If $\{ K_\delta \}$ is an approximation to the identity, and $f$ is integrable on $L^1(\mathbf{R}^d)$, then $(f * K_\delta)(x) \to f(x)$ for every $x$ in the Lebesgue set of $f$, and $f * K_\delta$ converges to $f$ in the $L^1$ norm.
\end{theorem}
\begin{proof}
    We rely on the fact that if $x$ is in the Lebesgue set, then the function
    %
    \[ A(r) = \frac{1}{r^d} \int_{|y| \leq r} |f(x-y) - f(x)|\ dy \]
    %
    is a bounded continuous function of $r > 0$, converging to $0$ as $r \to 0$. This means that if $\Delta(y) = |f(x-y) - f(x)| |K_\delta(y)|$, then
    %
    \[ \int \Delta(y)\ dy = \int_{|y| \leq \delta} \Delta(y) + \sum_{k = 0}^\infty \int_{2^k \delta \leq |y| \leq 2^{k+1} \delta} \Delta(y) \]
    %
    The first term is easily upper bounded by $CA(\delta)$, and the $k$'th term of the sum by $C'2^{-k}A(2^{k+1}\delta) \leq C''2^{-k}$ for constants $C',C''$ that do not depend on $\delta$. Letting $\delta \to 0$ gives us the convergence result.
\end{proof}

\section{The Strong Maximal Function}

TODO

\section{The Tangential Poisson Maximal Function}

TODO

\chapter{Aside: Differentiability of Measurable Functions}

A simple consequence of our results is a kind of fundamental theorem of calculus. If $f \in L^1(\RR)$, then we can define $F \in C(\RR)$ by setting
%
\[ F(t) = \int_{-\infty}^t f(s)\; ds. \]
%
It follows from the maximal functions bounds we've established that $F$ is differentiable almost everywhere, and $F'(t) = f(t)$ for almost every $t$. Thus the fundamental theorem of calculus holds in this setting, i.e.
%
\[ F(t) = \int_{-\infty}^t F'(s)\; ds. \]
%
Let us now consider \emph{what} conditions we can assume on a measurable function $f$ such that $f$ is differentiable almost everywhere, such that $f' \in L^1(\RR)$, and such that
%
\[ f(t) = \int_{-\infty}^t f'(s)\; ds \]
%
holds for almost every $t \in \RR$. Clearly this is equivalent to finding which functions are expressed as the indefinite integral of an integrable function.

We shall find that if $f$ has {\it bounded variation}, then most of these problems are answered. If $f$ is a complex valued function on $[a,b]$, and $P$ is a partition, we can consider it's variation on a partition $P = a \leq t_0 < \dots < t_n \leq b$ to be
%
\[ V(f,P) = \sum_{k = 1}^n |f(t_k) - f(t_{k-1})| \]
%
we say $f$ has \emph{bounded variation} if there is a constant $M$ such that for any partition $P$, $V(f,P) \leq M$. This implies that, since the net $P \mapsto V(f,P)$ is increasing, the net converges to a value $V(f) = V(f,a,b)$, the \emph{total variation} of $f$ on $[a,b]$.

The problem of the variation of a function is very connected to the problem of the {\it rectifiability of curves}. If $x: [a,b] \to \mathbf{R}^d$ parameterizes a continuous curve in the plane, then, for a given partition $P = a \leq t_0 \leq \dots \leq t_n$, we can consider an approximate length
%
\[ L_P(x) = \sum_{k = 1}^n |x(t_i) - x(t_{i-1})| \]
%
If $x$ has a reasonable notion of length, then the straight lines between $x(t_{i-1})$ and $x(t_i)$ should be shorter than the length of $x$ between $t_{i-1}$ and $t_i$. It therefore makes sense to define the \emph{length} of $x$ as
%
\[ L(x) = \sup L_P(x) \]
%
The triangle inequality implies that the map $P \mapsto L_P(x)$ is an increasing net, so $L$ is also the limit of the meshes as they become finer and finer. If $L(x) < \infty$, we say $x$ is a \emph{rectifiable curve}. One problem is to determine what analytic conditions one must place on $x$ in order to guarantee regularity, and what further conditions guarantee that, if $x_i$ is differentiable almost everywhere,
%
\[ L(x) = \int_a^b \sqrt{x_1'(t)^2 + \dots + x_n'(t)^2}\ dt \]
%
Considering rectifiable curves leads directly to the notion of a function with bounded variation.

\begin{theorem}
    A curve $x$ is rectifiable iff each $x_i$ has bounded variation.
\end{theorem}
\begin{proof}
    We can find a universal constants $A,B > 0$ such that for any $x,y \in \mathbf{R}^d$,
    %
    \[ A \sum |x_i - y_i| \leq |x-y| \leq B \sum |x_i - y_i| \]
    %
    This means that if $P$ is a partition of $[a,b]$, then
    %
    \[ A \sum_{ij} |x_j(t_i) - x_j(t_{i-1})| \leq \sum |x(t_i) - x(t_{i-1})| \leq B \sum_{ij} |x_j(t_i) - x_j(t_{i-1})| \]
    %
    So $A \sum V(x_i,P) \leq L_P(x) \leq B \sum V(x_i,P)$ gives the required result.
\end{proof}

\begin{example}
    If $f$ is a real-valued, monotonic, increasing function on $[a,b]$, then $f$ has bounded variation, and one can verify that $V(f) = f(b) - f(a)$.
\end{example}

\begin{example}
    If $f$ is differentiable at every point, and $f'$ is bounded, then $f$ has bounded variation. The mean value theorem implies that if $|f'| \leq M$, then for all $x,y \in [a,b]$,
    %
    \[ |f(x) - f(y)| \leq M |x-y| \]
    %
    This implies that $V(f,P) \leq M(b-a)$ for all partitions $P$.
\end{example}

\begin{example}
    Consider the functions $f$ defined on $[0,1]$ with
    %
    \[ f(x) = \begin{cases} x^a \sin(x^{-b}) &: 0 < x \leq 1 \\ 0 &: x = 0 \end{cases} \]
    %
    Then $f$ has bounded variation on $[0,1]$ if and only if $a > b$. The function oscillates from increasing to decreasing on numbers of the form $x = (n \pi)^{-1/b}$, so the total variation is described as
    %
    \begin{align*}
      V(f) &= 1 + \sum_{n = 1}^\infty (n \pi)^{-a/b} + ((n+1) \pi)^{-a/b}
    \end{align*}
    %
    This sum is finite precisely when $a/b > 1$. Thus functions of bounded variation cannot oscillate too widely, too often.
\end{example}

The next result is a decomposition theorem for bounded variation functions into bounded increasing and decreasing functions. We define the \emph{positive variation} of a real valued function $f$ on $[a,b]$ to be
%
\[ P(f,a,b) = \sup_P \sum_{f(t_i) \geq f(t_{i-1})} f(t_i) - f(t_{i-1}) \]
%
The \emph{negative variation} is
%
\[ N(f,a,b) = \sup_P \sum_{f(t_i) \leq f(t_{i-1})} -[f(t_i) - f(t_{i-1})] \]
%
Note that for each partition $P$, the sums of the two values above add up to the variation with respect to the partition.

\begin{lemma}
    If $f$ is real-valued and has bounded variation on $[a,b]$, then for all $a \leq x \leq b$,
    %
    \[ f(x) - f(a) = P(f,a,x) - N(f,a,x) \]
    %
    \[ V(f) = P(f,a,b) + N(f,a,b) \]
\end{lemma}
\begin{proof}
    Given $\varepsilon$, there exists a partition $a = t_0 < \dots < t_n = x$ such that
    %
    \[ \left| P(f,a,x) - \sum_{f(t_i) \geq f(t_{i-1})} f(t_i) - f(t_{i-1}) \right| < \varepsilon \]
    \[ \left| N(f,a,x) + \sum_{f(t_i) \leq f(t_{i-1})} f(t_i) - f(t_{i-1}) \right| < \varepsilon \]
    %
    It follows that
    %
    \[ |f(x) - f(a) - [P(f,a,x) - N(f,a,x)]| < 2 \varepsilon \]
    %
    and we can then take $\varepsilon \to 0$. The second identity follows the same way.
\end{proof}

A real function $f$ on $[a,b]$ has bounded variation if and only if $f$ is the difference of two increasing bounded functions, because if $f$ has bounded variation, then
%
\[ f(x) = [f(a) + P(f,a,x)] - N(f,a,x) \]
%
is the difference of two bounded increasing functions. On the other hand, the difference of two bounded increasing functions is clearly of bounded variation. A complex function has bounded variation if and only if it is the linear combination of four increasing functions in each direction.

\begin{theorem}
    If $f$ is a continuous function of bounded variation, then
    %
    \[ x \mapsto V(f,a,x) \ \ \ \ \ x \mapsto V(x,b) \]
    %
    are continuous functions.
\end{theorem}
\begin{proof}
    $V(f,a,x)$ is an increasing functin of $x$, so for continuity on the left it suffices to prove that for each $x$ and $\varepsilon$, there is $x_1 < x$ such that $V(f,a,x_1) \geq V(f,a,x) - \varepsilon$. If we consider a partition
    %
    \[ P = \{ a = t_0 <  \dots < t_n = x \} \]
    %
    where $|V(f,P) - V(f,a,x)| \leq \varepsilon$, then by continuity of $f$ at $x$, there is $t_{n-1} < x_1 < x$ with $|f(x) - f(x_1)| < \varepsilon$, and then if we modify $P$ to obtain $Q$ by swapping $t_n$ with $x_1$, we find
    %
    \begin{align*}
        V(f,a,x_1) \geq V(f,Q) &= V(f,P) - |f(x) - f(t_{n-1})| + |f(x_1) - f(t_{n-1})|\\
        &\geq V(f,P) - \varepsilon \geq V(f,a,x) - \varepsilon
    \end{align*}
    %
    A similar argument gives continuity on the right, and the continuity as the left bound of the interval changes.
\end{proof}

To obtain the differentiation theorem for functions of bounded variation, we require a lemma of F. Riesz.

\begin{lemma}[Rising Sun lemma]
    If $f$ is real-valued and continuous on $\mathbf{R}$, and $E$ is the set of points $x$ where there exists $h > 0$ such that $f(x+h) > f(x)$, then, provided $E$ is non-empty, it must be open, and can be written as a union of disjoint intervals $(a_n,b_n)$, where $f(b_n) = f(a_n)$. If $f$ is continuous on $[a,b]$, then $E$ is still an open subset of $[a,b]$, and can be written as the disjoint union of countably many intervals, with $f(b_n) = f(a_n)$ except if $a_n = a$, where we can only conclude $f(a_n) \leq f(b_n)$.
\end{lemma}
\begin{proof}
  The openness is clear, and the fact that $E$ can be broken into disjoint intervals follows because of the characterization of open sets in $\mathbf{R}$. If
  %
  \[ E = \bigcup (a_n,b_n) \]
  %
  Then $f(a_n + h) \leq f(a_n)$ and $f(b_n + h) \leq f(b_i)$, implying in particular that $f(b_n) \leq f(a_n)$, If $f(b_n) < f(a_n)$, then choose $f(b_n) < c < f(a_n)$. The intermediate value theorem implies there is $x$ with $f(x) = c$, and we may choose the largest $x \in [a_n,b_n]$ for which this is true. Then since $x \in (a_n,b_n)$, there is $y \in (x,b_i)$ with $f(x) < f(y)$, and by the intermediate value theorem, since $f(b_n) < f(x) < f(y)$, there must be $x' \in (y,b_n)$ with $f(x') = c$, contradicting that $x$ was chosen maximally. The proof for closed intervals operates on the same principles.
\end{proof}

\begin{theorem}
    If $f$ is increasing and continuous on $[a,b]$, then $f$ is differentiable almost everywhere. That is,
    %
    \[ f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h} \]
    %
    exists for almost every $x \in [a,b]$, $f'$ is measurable, and
    %
    \[ \int_a^b f'(x) \leq f(b) - f(a) \]
    %
    In particular, if $f$ is bounded on $\mathbf{R}$, then $f'$ is integrable on $\mathbf{R}$.
\end{theorem}
\begin{proof}the theorem in the
    It suffices to assume that $f$ is increasing, and we shall start by proving case assuming $f$ is continuous. We define
    %
    \[ \Delta_h f (x) = \frac{f(x+h) - f(x)}{h} \]
    %
    and the four {\it Dini derivatives}
    %
    \[ D_+ f(x) = \liminf_{h \downarrow 0} \Delta_h f(x)\ \ \ \ \ D^+ f(x) = \limsup_{h \downarrow 0} \Delta_h f(x) \]
    \[ D_- f(x) = \liminf_{h \uparrow 0} \Delta_h f(x)\ \ \ \ \ D^- f(x) = \limsup_{h \uparrow 0} \Delta_h f(x) \]
    %
    Clearly, $D_+ f \leq D^+ f$ and $D_- f \leq D^- f$, It suffices to show $D^+ f(x) < \infty$ for almost every $x$, and $D^+ f(x) \leq D_- f(x)$ for almost every $x$, because if we consider the function $g(x) = -g(-x)$, then we obtain $D^- f(x) \leq D_+ f(x)$ for almost every $x$, so
    %
    \[ D^+ f (x) \leq D_- f(x) \leq D^- f(x) \leq D_+ f(x) \leq D^+ f(x) < \infty \]
    %
    for almost every $x$, implying all values are equal, and that the derivative exists at $x$.

    For a fixed $\gamma > 0$, consider $E_\gamma = \{ x: D^+ f (x) > \gamma \}$. Since each $\Delta_h f$ is continuous, the supremum of the $\Delta_h f$ over any index set is lower semicontinuous, and since
    %
    \[ D^+ f(x) = \lim_{h \to 0} \sup_{0 \leq s \leq h} \Delta_h f (x + s) \]
    %
    can be expressed as the countable limit of these lower semicontinuous functions, $D^+ f$ is measurable, hence $E_\gamma$ is measurable. Now consider the shifted function $g(x) = f(x) - \gamma x$. If $\bigcup (a_i,b_i)$ is the set obtainable from $g$ from the rising sun lemma, then $E_\gamma \subset \bigcup (a_i, b_i)$, for if $D^+ f(x) > \gamma$, then there is $h > 0$ arbitrarily small with $\Delta_h f(x) > \gamma$, hence $f(x + h) - f(x) > \gamma h$, hence $g(x+h) > g(x)$. We know that $g(a_k) \leq g(b_k)$, so $f(b_k) - f(a_k) \geq \gamma(b_k - a_k)$, so
    %
    \[ |E_\gamma| \leq \sum (b_k - a_k) \leq \frac{1}{\gamma} \sum f(b_k) - f(a_k) \leq \frac{f(b) - f(a)}{\gamma} \]
    %
    Thus $|E_\gamma| \to 0$ as $\gamma \downarrow 0$, implying $D^+ f(x) = \infty$ only on a set of measure zero.

    Now for two real numbers $r < R$, we will now show
    %
    \[ E = \{ a \leq x \leq b : D^+ f(x) > R\ \ \ D_-f(x) < r \} \]
    %
    is a set of measure zero. Letting $r$ and $R$ range over all rational numbers establishes that $D^+ f(x) \leq D_-f(x)$ almost surely. We assume $|E| > 0$ and derive a contradiction. By regularity, we may consider an open subset $U$ in $[a,b]$ containing $E$ such that $|U| < |E| (R/r)$. We can write $U$ as the union of disjoint intervals $I_n$. For a fixed $I_N$, apply the rising sun lemma to the function $rx - f(-x)$ on the interval $-I_N$, yielding a union of intervals $(a_n,b_n)$. If we now apply the rising sun lemma to the function $f(x) - Rx$ on $(a_n, b_n)$, we get intervals $(a_{nm}, b_{nm})$, whose union we denote $U_N$. Then
    %
    \[ R(b_{nm} - a_{nm}) \leq f(b_{nm}) - f(a_{nm})\ \ \ \ \ f(b_n) - f(a_n) \leq r(b_n - a_n) \]
    %
    then, because $f$ is increasing,
    %
    \begin{align*}
      |U_N| &= \sum_{nm} (b_{nm} - a_{nm}) \leq \frac{1}{R} \sum_{nm} (f(b_{nm}) - f(a_{nm}))\\
      &\leq \frac{1}{R} \sum f(b_n) - f(a_n) \leq \frac{r}{R} \sum_n (b_n - a_n) \leq \frac{r}{R} |I_N|
    \end{align*}
    %
    Now $E \cap I_N$ is contained in $U_N$, because if $x \in E \cap I_N$, then $D^+ f(x) > R$ and $D_- f(x) < r$, so we can sum in $N$ to conclude that
    %
    \[ |E| \leq \sum \frac{r}{R} |I_N| = \frac{r}{R} |U_N| < |E| \]
    %
    a contradiction proving the claim.
\end{proof}

\begin{corollary}
  If $f$ is increasing and continuous, then $f'$ is measurable, non-negative, and
  %
  \[ \int_a^b f'(x)\; dx \leq f(b) - f(a) \]
\end{corollary}
\begin{proof}
  The fact the $f'$ is measurable and non-negative results from the fact that the functions $g_n(x) = \Delta_{1/n} f(x)$ are non-negative and continuous, and $g_n \to f'$ almost surely. We know
  %
  \begin{align*}
    \int_a^b f'(x) &\leq \liminf_{n \to \infty} \int_a^b g_n(x) = \liminf_{n \to \infty} n \int_a^b [f(x + 1/n) - f(x)]\\
    &= \liminf_{n \to \infty} n \left[ \int_b^{b+1/n} f(x) - \int_a^{a + 1/n} f(x) \right] = f(b) - f(a)
  \end{align*}
  %
  where the last equality follows because $f$ is continuous.
\end{proof}

Even for increasing continuous functions, the inequality in the theorem above need not be an equality, as the next example shows, so we need something stronger to obtain our differentiation theorem.

\begin{example}
  The Cantor-Lebesgue function is a continuous increasing function $f$ from $[0,1]$ to itself, with $f(0) = 0$, and $f(1) = 1$, but with $f'(x) = 0$ almost everywhere. This means
  %
  \[ \int_0^1 f'(x) = 0 < 1 = f(1) - f(0) \]
  %
  so we cannot obtain equality in general. To construct $f$, consider the Cantor set $C = \bigcap C_k$, where $C_k$ is the disjoint union of $2^k$ closed intervals. Set $f_0 = 0$, and $f_1(0) = 0$, $f_1(x) = 1/2$ on $[1/3,2/3]$, $f_1(1) = 1$, and $f$ linear between $[0,1/3]$ and $[2/3,1]$. Similarily, set $f_2(0) = 0$, $f_2(x) = 1/4$ on $[1/9, 2/9]$, $f_2(x) = 1/2$ on $[1/3,2/3]$, $f_2(x) = 3/4$ on $[7/9,8/9]$, and $f_2(1) = 1$. The functions $f_i$ are increasing and cauchy in the uniform norm, so they converge to a continuous function $f$ called the \emph{Cantor function}. $f$ is constant on each interval in the complement of the cantor set, so $f'(x) = 0$ almost everywhere.
\end{example}

To obtain equality in the integral formula, we require additional conditions on our increasing functions, provided by absolute continuity.

\section{Absolute Continuity}

A function $f: [a,b] \to \mathbf{R}$ is \emph{absolutely continuous} if for every $\varepsilon > 0$, there is $\delta > 0$ such that whenever $(a_1, b_1), \dots, (a_n,b_n)$ are disjoint intervals with $\sum (b_i - a_i) < \delta$, $\sum |f(b_i) - f(a_i)| < \varepsilon$. Thus the function should be `essentially constant' over every set of zero measure. It is easy to see from this that absolutely continuous functions must be uniformly continuous, and have bounded variation. Thus $f$ has a decomposition into the difference of two continuous increasing functions, and one can see quite easily that these functions are also absolutely continuous. Most promising to us, if $f$ is a function defined by $f(x) = \int_a^x g(t)\ dt$, where $g \in L^1[a,b]$, then $f$ is absolutely continuous. This shows that absolute continuity is necessary in order to hope for the integral formula
%
\[ \int_a^b f'(x)\ dx = f(b) - f(a) \]
%
The Cantor function is {\it not} absolutely continuous, since it is constant except on the Cantor set, and we can cover the Cantor set by intervals with total length $(2/3)^n$ for each $n$. Thus it is impossible for the Cantor function to satisfy the fundamental theorem of calculus.

\begin{theorem}
  If $g \in L^1(\mathbf{R})$, and
  %
  \[ f(x) = \int_a^x g(t)\; dt \]
  %
  then $f$ is absolutely continuous.
\end{theorem}
\begin{proof}
  Fix $\varepsilon > 0$. We claim that there is $\delta$ such that if $|E| < \delta$, then $\int_E |g| < \varepsilon$. Otherwise there are sets $E_n$ with $|E_{n+1}| \leq |E_n|/3$ and with $\int_{E_n} |g| \geq \varepsilon$. Thus if we define the sets $E_m' = E_m - \bigcup_{n > m} E_n$ then the $E_m'$ and we have $|E_m| \sim |E_m|'$. Since $g$ is integrable, we must have $\sum \int_{E_n'} |g| < \infty$, so we conclude that as $N \to \infty$,
  %
  \[ \sum_{n \geq N} \int_{E_n'} |g| \to 0 \]
  %
  Yet for any $N$,
  %
  \[ \sum_{n \geq N} \int_{E_n'} |g| = \int_{E_N} |g| \geq \varepsilon \]
  %
  which is an impossibility. Thus such a $\delta$ exists for every $\varepsilon$, and so if we have disjoint intervals $(a_n,b_n)$ with $\sum (b_n - a_n) < \delta$, then
  %
  \[ \sum |f(b_n) - f(a_n)| = \sum \left| \int_{a_n}^{b_n} g(t) \right| \leq \sum \int_{a_n}^{b_n} |g| = \int_{\bigcup (a_n,b_n)} |g| < \varepsilon \]
  %
  which shows the function is absolutely continuous.
\end{proof}

To prove the differentiation theorem, we require a covering estimate not unlike that used to prove the Lebesgue differentiation theorem. We say a collection of balls is a \emph{Vitali covering} of a set $E$ if for every $x \in E$ and every $\eta > 0$, there is a ball $B$ in the cover containing $x$ with radius smaller than $\eta$. Thus every point is covered by an arbitrary small ball.

\begin{lemma}
    If $E$ is a set of finite measure, and $\{ B_\alpha \}$ is a Vitali covering of $E$, then there eixsts a disjoint family of cubes $\{ B_\beta \}$ in the covering such that
    %
    \[ \left| E - \bigcup_\beta B_\beta \right| = 0. \]
\end{lemma}
\begin{proof}
  Fix $\delta > 0$. We claim we can find a disjoint family of cubes $B_1, \dots, B_N$ in the Vitali cover such that
  %
  \[ \left| E - \bigcup_{i = 1}^N B_i \right| \leq \delta. \]
  %
  By inner regularity, pick a compact set $K \subset E$ with $|K| \geq |E| - \delta/2$. Then $K$ is covered by finitely many balls of radius less than $\eta$ in the covering $\{ B_\alpha \}$, and the elementary Vitali covering lemma gives a disjoint subcollection of balls $B_1, \dots, B_{n_0}$ with
  %
  \[ |K| \leq \left| \bigcup B_\alpha \right| \leq 3^d \sum |B_k| \]
  %
  so $\sum |B_k| \geq 3^{-d} |K|$. If $\sum |B_k| \geq |K| - \delta/2$, we're done. Otherwise, define $E_1 = K - \bigcup \overline{B_k}$. Then
  %
  \[ |E_1| \geq |K| - \sum |\overline{B_k}| = |K| - \sum |B_k| > \delta/2 \]
  %
  If we pick a compact set $K_1 \subset E_1$ with $|K_1| \geq \delta/2$, then if we remove all sets in the Vitali covering which intersect $B_1, \dots, B_{n_0}$, then we still obtain a Vitali covering for $K_1$, and we can repeat the argument above to find a disjoint collection of open sets $B_1^1, \dots, B_{n_1}^1$ with $\sum |B_k^1| \geq 3^{-d} |K_1|$. Then $\sum |B_k| + \sum |B^1_k| \geq 2 (3^{-d} \delta)$. If $\sum |B_k| + \sum |B^1_k| < |K| - \delta/2$, we repeat the same process, finding a disjoint family for $K_2 \subset E_2$, where $\smash{E_2 = K_1 - \bigcup \overline{B^1_k}}$. If this process repeats itself $k$ times, then we obtain a family of open sets with total measure greater than or equal to $k (3^{-d} \delta)$. But then if we eventually have $k \geq (|E| - \delta) 3^d/ \delta$, then we obtain the required bound.

  We now construct our final cover inductively. Given $E$, we can find finitely many balls $B_{11},\dots,B_{1 n_1}$ such that
  %
  \[ \left| E - \bigcup_{i = 1}^{n_1} B_i \right| \leq 1/2. \]
  %
  Set $E_1 = E - \bigcup_{i = 1}^{n_1} B_i$. If we remove all balls from the Vitali cover that intersect the balls $B_1,\dots,B_{n_1}$, we still have a Vitali cover of $E_1$. Inductively, we can then find a disjoint family of balls $B_{k1},\dots,B_{kn_k}$ which are disjoint from all previously selected balls such that
  %
  \[ \left| E - \bigcup_{k = 1}^{k_0} \bigcup_{i = 1}^{n_k} B_{ki} \right| \leq 1/2^{k_0}. \]
  %
  Taking $k_0 \to \infty$ gives an infinite family of disjoint balls which cover $E$ up to a set of zero Lebesgue measure.
\end{proof}

\begin{theorem}
    If $f: [a,b] \to \mathbf{R}$ is absolutely continuous, then $f'$ exists almost everywhere, and if $f'(x) = 0$ almost surely, then $f$ is constant.
\end{theorem}
\begin{proof}
    It suffices to prove that $f(a) = f(b)$, since we can then apply the theorem on any subinterval. Let $E = \{ x \in (a,b): f'(x) = 0 \}$. Then $|E| = b - a$. Fix $\varepsilon > 0$. Since for each $x \in E$, we have
    %
    \[ \lim_{h \to 0} \frac{f(x+h) - f(x)}{h} = 0 \]
    %
    This implies that the family of intervals $(x,y)$ such that the inequality $|f(y) - f(x)| \leq \varepsilon (y-x)$ holds forms a Vitali covering of $E$, and we may therefore select a family of disjoint intervals $I_i = (x_i,y_i)$ with
    %
    \[ \sum |I_i| \geq |E| - \delta = (b - a) - \delta \]
    %
    But $|f(y_i) - f(x_i)| \leq \varepsilon (y_i - x_i)$, so we conclude
    %
    \[ \sum |f(y_i) - f(x_i)| \leq \varepsilon (b - a) \]
    %
    The complement of $I_i$ is a union of intervals $J_i = (x_i',y_i')$ of total length $\leq \delta$. Applying the absolute continuity of $f$, we conclude
    %
    \[ \sum |f(y_i') - f(x_i')| \leq \varepsilon \]
    %
    so applying the triangle inequality,
    %
    \[ |f(b) - f(a)| \leq \sum |f(y_i') - f(x_i')| + \sum |f(y_i) - f(x_i)| \leq \varepsilon(b - a + 1) \]
    %
    We can then let $\varepsilon \to 0$ to obtain equality.
\end{proof}

\begin{theorem}
    Suppose $f$ is absolutely continuous on $[a,b]$. Then $f'$ exists almost every and is integrable, and
    %
    \[ f(b) - f(a) = \int_a^b f'(y)\ dy \]
    %
    so the fundamental theorem of calculus holds everywhere. Conversely, if $f \in L^1[a,b]$, then there is an absolutely continuous function $g$ with $g' = f$ almost everywhere.
\end{theorem}
\begin{proof}
    Since $f$ is absolutely continuous, we can write $f$ as the difference of two continuous increasing functions on $[a,b]$, and this easily implies $f$ is differentiable almost everywhere and is integrable on $[a,b]$. If $g(x) = \int_a^x f'(x)$, then $g$ is absolutely continuous, hence $g - f$ is also absolutely continuous. But we know that $(g - f)' = g' - f' = 0$ almost everywhere, so the last theorem implies that $g$ differs from $f$ by a constant. Since $g(a) = 0$, $g(x) = f(x) - f(a)$. The converse was proved exactly in our understanding of differentiating integrals.
\end{proof}

We now dwell slightly longer on the properties of absolutely continuous functions, which enables us to generalize other properties of integrals found in the calculus. We begin by noting that it is easy to verify that if $f$ and $g$ are absolutely continuous functions, then $fg$ is also absolutely continuous. We know $f'$, $g'$, and $(fg)'$ exist almost everywhere. But when all three exist simultaneously, the product rule gives $(fg)' = f'g + fg'$. The absolute continuity implies that
%
\[ \int_a^b f'g + fg' = \int_a^b (fg)' = f(b)g(b) - f(a)g(a) \]
%
Thus one can integrate a pair of absolutely continuous functions by parts. Next, we shall show that monotone absolutely continuous functions are precisely those we can use to change variables. One important thing to note is that even if $f$ is a continuous function, and $g$ is measurable, $g \circ f$ need not be measurable. The easy reason to see this is that the inverse image of every open set in $g$ is measurable, so in order to guarantee $g \circ f$ is measurable we need the inverse image of every measurable set under $f$ be measurable.

\begin{example}
  Consider the function $f(x) = \int_0^x \chi_E(x)\; dx$, where $E$ is a thick Cantor set. Then $f$ is absolutely continuous, strictly increasing on $[0,1]$, and maps $E$ to a set of measure zero. This is because $E = \lim E_n$, where $E_n$ is a family of intervals with $|E_n| \downarrow |E|$. Then $f(E_n)$ has total length $|E_n - E|$, so as $n \to \infty$, we see $\lim f(E_n) = f(E)$ has measure zero.  This means that $f(X)$ is measurable for any subset $X$ of $E$, and in particular, if $X$ is non-measurable, then $f^{-1}(f(X))$ cannot be measurable, even though $f(X)$ is measurable. Note that $f$ is strictly increasing even though it's derivatives vanish on a set of positive measure.
\end{example}

The next lemmas will show that even though $g \circ f$ may not be Lebesgue measurable when $f$ is absolutely continuous and $g$ is Lebesgue measurable, this does not really bother us too much when changing variables.

\begin{lemma}
  If $f$ is absolutely continuous, then it maps sets of measure zero to sets of measure zero.
\end{lemma}
\begin{proof}
  Let $E$ be a set of measure zero. Then for each $\delta > 0$, $E$ is coverable by a family of open intervals with total length $\delta$. But if $\delta$ is taken small enough, this means that $f(E)$ is coverable by a family of open intervals with total length bounded by $\varepsilon$, for any $\varepsilon$.
\end{proof}

This property of absolutely continuous functions is independant of the properties of the Euclidean domain as it's domain, and is used in the generalization of absolute continuity to more general domains, or even to measures. If $f$ is absolutely continuous, then the image of every interval is an interval, and since $f(\bigcup K_n) = \bigcup f(K_n)$, this implies that the image of a $F_\sigma$ set is measurable. But since every measurable set of $\mathbf{R}$ differs from a $F_\sigma$ set by a set of measure zero, the image of every Lebesgue measurable set is Lebesgue measurable. The reverse is almost true.

\begin{lemma}
  If $f$ is absolutely continuous, and $E$ measurable, then the set
  %
  \[ f^{-1}(E) \cap \{ x : f'(x) > 0 \} \]
  %
  is measurable.
\end{lemma}
\begin{proof}
  If $E$ is an open set, then
  %
  \[ |E| = \int_{f^{-1}(E)} f'(x)\; dx \]
  %
  It suffices to prove this when $E$ is an interval, and then this is just the theorem of differentiation for absolutely continuous functions. But then applying the dominated convergence theorem shows that this equation remains true if $E$ is an $G_\delta$ set. Furthermore, this means the theorem is true if $E$ is a closed set, and so by applying the monotone convergence theorem, the theorem is true if $E$ is an $F_\sigma$ set. But if $E$ is an arbitrary measurable set, then for every $\varepsilon$ there are $F_\sigma$ and $G_\delta$ sets $K \subset E \subset U$ with $|U - K| = 0$. But
  %
  \[ \alpha|f^{-1}(U - K) \cap \{ f' \geq \alpha \}| \leq \int_{f^{-1}(U-K)} f'(x)\; dx = |U - K| = 0 \]
  %
  Thus $f^{-1}(U-K) \cap \{ f' \geq \alpha \}$ is a set of measure zero, and so in particular by completeness, every set contained in this set is measurable, in particular $f^{-1}(U - E) \cap \{ f' \geq \alpha \}$ is measurable. But now this means
  %
  \[ \{ f' \geq \alpha \} - f^{-1}(U-E) \cap \{ f' \geq \alpha \} = f^{-1}(E) \cap \{ f' \geq \alpha \} \]
  %
  is measurable. Taking $\alpha \downarrow 0$ completes the proof.
\end{proof}

Because of this, even though $g \circ f$ is not necessarily measurable, $(g \circ f) f'$ is always measurable if $f$ is absolutely continuous. Thus the expression $\int (g \circ f) f'$ makes sense, and thus we can always interpret the change of variables formula.

\begin{theorem}
  If $f$ is absolutely continuous, and $g$ is integrable, then
  %
  \[ \int g(f(x)) f'(x)\; dx = \int g(y)\; dy \]
\end{theorem}
\begin{proof}
  Using the notation in the last proof, if $E$ is measurable, then
  %
  \[ |K| = \int_{f^{-1}(K)} f'(x)\; dx \leq \int_{f^{-1}(E)} f'(x)\; dx \leq \int_{f^{-1}(U)} f'(x)\; dx = |U| \]
  %
  and $|U| = |K| = |E|$, so that for any measurable set $E$,
  %
  \[ |E| = \int_{f^{-1}(E)} f'(x)\; dx \]
  %
  This imples the theorem we need to prove is true whenever $g$ is the characteristic function of any measurable set. But then by linearity, it is true for any simple function. By monotone convergence, it is then true for any non-negative function, and then by partitioning $g$ into the sum of simple functions, we obtain the theorem in general.
\end{proof}





\section{Differentiability of Jump Functions}

We now consider the differentiability of not necessarily continuous monotonic functions. Set $f$ to be an increasing function on $[a,b]$, which we may assume to be bounded.  Then the left and right limits of $f$ exist at every point, which we will denote by $f(x-)$ and $f(x+)$. Of course, we have $f(x-) \leq f(x) \leq f(x+)$. If there is a discontinuity, this means we are forced to have a `jump discontinuity' where $f$ skips an interval. This implies that $f$ can only have countably many such discontinuities, because a family of disjoint intervals on $\mathbf{R}$ is at most countable. Now define the jump function $\Delta f(x) = f(x^+) - f(x-)$, with $\theta(x) \in [0,1]$ defined such that $f(x_n) = f(x_n-) + \theta(x) \Delta f(x)$. If we define the functions
%
\[ j_y(x) = \begin{cases} 0 & : x < y \\ \theta(y) & : x = y \\ 1 & x > y \end{cases} \]
%
then we can define the \emph{jump function} associated with $f$ by
%
\[ J(x) = \sum_x \Delta f(x) j_n(x) \]
%
Since $f$ is bounded on $[a,b]$, we make the final observation that
%
\[ \sum_{x \in [a,b]} \Delta f(x) \leq f(b) - f(a) < \infty \]
%
so the series defining $J$ converges absolutely and uniformly.

\begin{lemma}
    If $f$ is increasing and bounded on $[a,b]$, then $J$ is discontinuous precisely at the values $x$ with $\Delta f(x) \neq 0$ with $\Delta J(x) = \Delta f(x)$. The function $f - J$ is continuous and increasing.
\end{lemma}
\begin{proof}
    If $x$ is a continuity point of $f$, then $j_y$ is continuous at $x$, and hence, because $\sum_y \Delta f(y) j_y(x) \to J(x)$ uniformly, so we conclude that $J$ is continuous at $x$. On the other hand, for each $y$, $j_y(y-) = 0$ and $j_y(y+) = 1$, and if we label the points of discontinuity of $f$ by $x_1, x_2, \dots$, then
    %
    \[ J(x) = \sum_{i = 1}^k \Delta f(x_i) j_{x_i} + \sum_{i = k+1}^\infty \Delta f(x_i) j_{x_i} \]
    %
    The right hand partial sums are continuous at $x_k$, whereas the left hand sum has a jump discontinuity of the same order as $f$ at $x_k$, we conclude $J$ also has this discontinuity. But this means that
    %
    \[ (f - J)(x_k+) - (f - J)(x_k-) = 0 \]
    %
    so $f - J$ is continuous at every point. $f - J$ is increasing because of the inequality
    %
    \[ J(y) - J(x) \leq \sum_{x < x_n \leq y} \alpha_n \leq f(y) - f(x) \]
    %
    which follows because $J$ is just the sum of jump discontinuities, and the right hand side because $f$ can decrease and increase outside of the jump discontinuities.
\end{proof}

Since $f - J$ is continuous and increasing, it is differentiable almost everywhere. It therefore remains to analyze the differentiability of the jump function $J$.

\begin{theorem}
    $J'$ exists and vanishes almost everywhere.
\end{theorem}
\begin{proof}
    Fix $\varepsilon > 0$, and consider
    %
    \[ E = \left\{ x \in [a,b]: \limsup_{h \to 0} \frac{J(x + h) - J(x)}{h} > \varepsilon \right\} \]
    %
    Then $E$ is measurable, because we can take the $\limsup$ over rational numbers because $J$ is increasing. We want to show it has measure zero. Suppose $\delta = |E|$. Consider $\eta > 0$ to be chosen later, and find $n$ such that $\sum_{k = n}^\infty \alpha_k < \eta$. Write
    %
    \[ J_0(x) = \sum_{n > N} \alpha_n j_n \]
    %
    Then $J_0(b) - J_0(a) < \eta$. Now $E$ differs from the set
    %
    \[ E' = \left\{ x \in [a,b]: \limsup_{h \to 0} \frac{J_0(x + h) - J_0(x)}{h} > \varepsilon \right\} \]
    %
    by finitely many points. Using inner regularity, find a compact set $K \subset E'$ with $|K| \geq \delta/2$. For each $x \in K$, we can find intervals $(\alpha_x, \beta_x)$ upon which $J_0(\beta_x) - J_0(\alpha_x) \geq \varepsilon |\beta_x - \alpha_x|$. But applying the elementary Vitali covering lemma, we can find a disjoint family of such intervals with $\sum (\beta_{x_i} - \alpha_{x_i}) \geq |K|/3 \geq \delta/6$. But now we find
    %
    \[ J_0(b) - J_0(a) \geq \sum J_0(\beta_{x_i}) - J_0(\alpha_{x_i}) \geq \varepsilon \delta/6 \]
    %
    This means $\delta \leq 6 \eta/\varepsilon$, and by letting $\eta \to 0$, we can conclude $\delta = 0$.
\end{proof}

This concludes our argument that {\it every} function of bounded variation has a derivative almost everywhere, because every such function can be uniquely written (up to a shift in the range of the functions) as the sum of a continuous function and a jump function. If $f$ is a function with bounded variation, then the function
%
\[ F(x) = \int_0^x f'(x) \]
%
is absolutely continuous, and $f - F$ is a continuous function with derivative zero almost everywhere. The fact that this decomposition is unique up to a shift as well (which can easily be seen in the case of an increasing function, from which the general case follows) leads us to refer to this as the \emph{Lebesgue decomposition} of a function of bounded variation on the real line.

\section{Rectifiable Curves}

We now consider the validity of the length formula
%
\[ L = \int_a^b (x'(t)^2 + y'(t)^2)^{1/2}\ dt \]
%
where $L$ is the length of the curve parameterized by $(x,y)$ on $[a,b]$. We cannot always expect this formula to hold, because if $x$ and $y$ are both the Cantor devil staircase function, then the formula above gives a length of zero, whereas we know the curve traces a line between $0$ and $1$, hence has length at least $\sqrt{2}$.

\begin{theorem}
    If a curve is parameterized by absolutely continuous functions $x$ and $y$ on $[a,b]$, then the curve is rectifiable, and has length
    %
    \[ \int_a^b (x'(t) + y'(t))^{1/2}\ dt \]
\end{theorem}
\begin{proof}
  This proof can be reworded as saying if $f$ is complex-valued and absolutely continuous, then it's total variation can be expressed as
  %
  \[ V(f,a,b) = \int_a^b |f'(t)|\; dt \]
  %
  If $P = \{ a \leq t_1 < \dots < t_n \leq b \}$ is a partition, then
  %
  \[ \sum |f(t_{n+1}) - f(t_n)| = \sum \left| \int_{t_n}^{t_{n+1}} f'(t)\; dt \right| \leq \sum \int_{t_n}^{t_{n+1}} |f'(t)|\; dt \leq \int_a^b |f'(t)|\; dt \]
  %
  so $V(f,a,b) \leq \int_a^b |f'(t)|\; dt$. To prove the converse inequality, fix $\varepsilon > 0$, and find a step function $g$ with $f' = g + h$, with $\| h \|_1 \leq \varepsilon$. If $G(x) = \int_a^x g(t)\; dt$ and $H(x) = \int_a^x h(t)\; dt$, then $F = G + H$, and $V(f,a,b) \geq V(G,a,b) - V(H,a,b) \geq V(G,a,b) - \varepsilon$, and if we partition $[a,b]$ into $a = t_0 < \dots < t_N$, where $G$ is constant on each $(t_n, t_{n+1})$, then
  %
  \begin{align*}
    V(G,a,b) &\geq \sum |G(t_n) - G(t_{n-1})| = \sum \left| \int_{t_{n-1}}^{t_n} g(t)\; dt \right|\\
    &= \sum \int_{t_{n-1}}^{t_n} |g(t)|\; dt = \int_a^b |g(t)|\; dt \geq \| f' \|_1 - \varepsilon
  \end{align*}
  %
  Letting $\varepsilon \to 0$ now gives the result.
\end{proof}

It is interesting to note that any rectifiable curve has a special {\it parameterization by arclength}, i.e. a parameterization $(x(t), y(t))$ such that if $L$ is the length function associated to the parameterization, then $L(A,B) = B - A$. This is obtainable by inverting the length function.

\begin{theorem}
  If $z = (x,y)$ is a parameterization of a rectifiable curve by arclength, then $x$ and $y$ are absolutely continuous, and $|z'| = 1$ almost everywhere.
\end{theorem}
\begin{proof}
  For any $s < t$,
  %
  \[ t - s = L(s,t) = V(f,s,t) \geq |z(t) - z(u)| \]
  %
  so it follows immediately that $|z|$ is an absolutely continuous function, and $|z'| \leq 1$ almost surely. But now we know that
  %
  \[ \int_a^b |z'(t)| = b - a \]
  %
  and this equality can now only hold if $|z'(t)| = 1$ almost surely.
\end{proof}

\section{Bounded Variation in Higher Dimensions}

Since the higher dimensional Euclidean domains do not have an ordering, it is impossible to define their length by partitioning their domain, and the meaning of a jump discontinuity is no longer clear. However, there are properties equivalent to having bounded variation which are more extendable to higher dimensions.

\begin{theorem}
  The following properties of $f: \mathbf{R} \to \mathbf{R}$ are equivalent, for some fixed finite constant $A$.
  %
  \begin{itemize}
    \item $f$ can be modified on a set of measure zero so that it has bounded variation not exceeding $A$.
    \item $\int |f(x+h) - f(x)| \leq A|h|$ for all $h \in \mathbf{R}$.
    \item For any $C^1$ function $\varphi$ with compact support, $\left| \int f(x) \varphi'(x) \right| \leq A \| \varphi \|_\infty$.
  \end{itemize}
\end{theorem}
\begin{proof}
  If $V(f) = A$, where $A < \infty$, then we can write $f = f^+ - f^-$, where $f^+$ and $f^-$ are both increasing functions, and with $V(f) = V(f^+) + V(f^-)$. It then follows that $|f(x+h) - f(x)| \leq (f^+(x+h) - f^+(x)) + |f^-(x+h) - f^-(x)|$, so it suffices to prove the second property by assuming $f$ is increasing. But then by the monotone convergence theorem, assuming $h > 0$ without loss of generality,
  %
  \[ \int |f(x+h) - f(x)| = \lim_{y \to \infty} \int_{-y}^y f(x+h) - f(x) = \lim_{y \to \infty} \int_y^{y+h} f(x) - \int_{-y-h}^{-y} f(x) \]
  %
  The first term of the limit converges to $hV(f)$, and the second to zero, completing the first part of the theorem. Now assuming the second point, we prove the third point. Then using the second point, we find
  %
  \begin{align*}
    \left|\int f(x) \varphi'(x) \right| &= \left| \lim_{h \to 0} \int f(x) \frac{\varphi(x+h) - \varphi(x)}{h} \right|\\
    &= \left| \lim_{h \to 0} \int \frac{f(x-h) - f(x)}{h} \varphi(x) \right| \leq A \| \varphi \|_\infty
  \end{align*}
  %
  Finally, we consider the third point being true. The set of all partitions with rational points is countable. Suppose that for each rational $P = \{ t_0 < \dots < t_N \}$ there is a set $E_P$ of measure zero for each rational partition $P$ such that
  %
  \[ \sum_{n = 1}^N \sup_{\substack{x \in [t_{n-1},t_n]\\x \not \in E_P}} f(x) - \inf_{\substack{x \in [t_{n-1},t_n]\\x \not \in E_P}} f(x) \leq A \]
  %
  Then the union of $E_P$ over all rational $P$ has measure zero. We can modify $f$ on $E_P$ by setting $f(x) = \liminf_{y \to 0} f(x+y)$, and then $V(f,P) \leq A$ for all rational partitions $P$. If $Q$ is now any partition, we can find a rational partition $P$ with $V(f,P) \geq V(f,Q) - \varepsilon$, and so $V(f,P) \leq A - \varepsilon$. Taking $\varepsilon \to 0$ completes the argument. Thus if $f$ cannot be modified to have finite variation $A$, there exists a rational partition $P$ such that for any set $E$ of measure zero,
  %
  \[ \sum_{n = 1}^N \sup_{\substack{x \in [t_{n-1},t_n]\\x \not \in E}} f(x) - \inf_{\substack{x \in [t_{n-1},t_n]\\x \not \in E}} f(x) > A \]
  %
  Thus for any $\varepsilon$, there exists $E_n^+, E_n^- \subset [t_{n-1},t_n]$ of positive measure such that
  %
  \[ \sum_{n = 1}^N \inf_{x \in E_n^+} f(x) - \sup_{x \in E_n^-} f(x) > A \]
  %
  If we consider the polygonal function $\phi$ which
\end{proof}

\section{Minkowski Content}

Given a set $K \in \mathbf{R}^n$, we let $K^\delta$ denote the open set consisting of points $x$ with $d(x,K) < \delta$. The $m$ dimensional \emph{Minkowski content} of $K$ is defined to be
%
\[ \lim_{\delta \to 0} \frac{1}{\alpha(n-m)} \frac{|K^\delta|}{\delta^m} \]
%
where $\alpha(d)$ is the volume of the unit ball in $d$ dimensions. When this limit exists, we denote it by $M^m(K)$. In this section, we mainly discuss the one dimensional Minkowski content in two dimensions, i.e. the values of
%
\[ \lim_{\delta \to 0} \frac{|K^\delta|}{2 \delta^m} \]
%
and it's relation the length of curves. Since we now only care about the one dimensional Minkowski content, we let $M(K)$ denote the one dimension Minkowski content.

\begin{lemma}
  If $\Gamma = \{ z(t): a \leq t \leq b \}$ is a curve, and $\Delta$ is the distance between the endpoints of the curve, then $|\Gamma^\delta| \geq 2 \delta \Delta$.
\end{lemma}
\begin{proof}
  By rotating, we may assume that both endpoints of the curve lie on the $x$ axis, so $z(a) = (A,0)$, $z(b) = (B,0)$ with $A < B$, so $\Delta = B - A$. If $\Delta = 0$, the theorem is obvious. Otherwise, for each point $x \in [A,B]$ there is $t(x)$ such that if $z_1(t(x)) = x$, and so $\Gamma^\delta$ contains $x \times [z_2(t(x)) - \delta, z_2(t(x)) + \delta]$, which has length $2 \delta$. Thus by Fubini's theorem,
  %
  \[ |\Gamma^\delta| = \int_{-\infty}^\infty \int_{-\infty}^\infty \chi_{\Gamma^\delta}(x,y)\; dx \;dy \geq \int_A^B 2 \delta = 2 \delta \Delta \]
  %
  so the theorem is proved.
\end{proof}

\begin{theorem}
  If $\Gamma = \{ z(t): a \leq t \leq b \}$ is a quasi-simple curve (simple except at finitely many points), then the Minkowski content of $\Gamma$ exists if and only if $\Gamma$ is rectifiable, and in this case $M^1(\Gamma)$ is the length of the curve $L$.
\end{theorem}
\begin{proof}
  To prove the theorem, we consider the upper and lower Minkowski contents
  %
  \[ M^*(\Gamma) = \limsup_{\delta\to 0} \frac{|\Gamma|^\delta}{\alpha(n-1) \delta}\ \ \ \ M_*(\Gamma) = \liminf_{\delta \to 0} \frac{|\Gamma|^\delta}{\alpha(n-1) \delta} \]
  %
  First, we prove that $M^*(\Gamma) \leq L$. Consider a partition $P$ of $[a,b]$, and let $L_P$ be the length of the polygonal approximation to the curve. By refining the partition, we may assume that $\Gamma$ is simple, with the repeated points at the boundaries of the intervals. For each interval $I_n$ in the partition, we select a closed subinterval $J_n = [t_n,u_n]$ such that $\Gamma$ is simple on $\bigcup J_n$, and
  %
  \[ \sum |z(u_n) - z(t_n)| \geq L_P - \varepsilon \]
  %
  Since the intervals $J_n$ are disjoint, for suitably small $\delta$ the sets $J_n^\delta$ are disjoint. Applying the previous lemma, we conclude that
  %
  \[ |\Gamma^\delta| \geq \sum |J_n^\delta| \geq 2 \delta \sum |z(u_n) - z(t_n)| = 2 \delta (L_p - \varepsilon) \]
  %
  First, by letting $\varepsilon \to 0$ and then $\delta \to 0$, we conclude that $M_*(\Gamma) \geq \lim_P L_P$. In particular, this shows that if $\Gamma$ has Minkowski content one, then the curve is rectifiable. Conversely, we consider the functions
  %
  \[ F_n(s) = \sup_{0 < |h| < 1/n} \left| \frac{z(s+h) - z(s)}{h} - z'(s) \right| \]
  %
  Because $z$ is continuous, this supremum can be considered over a countable, dense subset, and so each $F_n$ is measurable. Since $F_n(s) \to 0$ for almost every $s$, we can apply Egorov's theorem to show that this limit is uniform except on a singular set $E$ with $|E| < \varepsilon$, so that for some large $N$, for $s \not \in E$ and $|h| < 1/N$, $|z(s+h) - z(s) - hz'(s)| < \varepsilon h$. We now split the interval $[a,b]$ into consecutive intervals $I_1, \dots, I_{M+1}$, with each interval but $I_{M+1}$ having length $1/N$. We let $\Gamma_n$ denote the section of the curve travelled along the interval $I_n$. Thus $|\Gamma^\delta| \leq \sum |\Gamma_n^\delta|$. If an interval $I_n$ contains an element of $E^c$, we say $I_n$ is a `good' interval. Then we can pick an element $x_n \in I_n$ for which for any $x \in I_n$,
  %
  \[ |z(x) - z(x_n) - (x - x_n) z'(x_n)| < \varepsilon |x - x_n| < \varepsilon / N \]
  %
  Thus $\Gamma_n$ is covered by a $\varepsilon / N$ thickening of a length $1/N$ line $J_n$ in $\mathbf{R}^2$ through $z(x_n)$ with slope $z'(x_n)$. Thus if $\varepsilon \leq 1$, we conclude
  %
  \begin{align*}
    |\Gamma_n^\delta| &\leq J_n^{\varepsilon/N + \delta} \leq (1/N + 2\varepsilon/N + 2 \delta)(2\varepsilon/N + 2\delta)\\
    \leq 2 \delta/N + O(\delta \varepsilon / N + \delta^2 + \varepsilon/N^2)
  \end{align*}
  %
  Since $M \leq NL$, if we take the sum of $|\Gamma_n^\delta|$ over all `good' intervals we obtain an upper bound of
  %
  \[ NL \left( 2 \delta/N + O(\delta \varepsilon / N + \delta^2 + \varepsilon/N^2) \right) = 2 \delta L + O(\delta \varepsilon + \delta^2 N + \varepsilon/N) \]
  %
  On the other hand, if $I_n$ is contained within $E$, or if $n = M+1$, we say $I_n$ is a bad interval. Since $E$ has total measure bounded by $\varepsilon$, there can be at most $\varepsilon N + 1$ bad intervals. On these intervals we use the crude estimate $|z(t) - z(u)| \leq |t-u|$ (true because $z$ is an arclength parameterization) to show $\Gamma_n$ is contained in a rectangle with sidelengths $1/N$, so we obtain that $|\Gamma_n^\delta| \leq (1/N + 2\delta)^2 = O(1/N^2 + \delta^2)$. Thus the sum of $|\Gamma_n^\delta|$ over the `bad intervals' is bounded by
  %
  \[ O(\varepsilon/N + 1/N^2 + \varepsilon N \delta^2 + \delta^2) \]
  %
  In particular, the sum of the two bounds gives
  %
  \[ |\Gamma^\delta| \leq 2 \delta L + O(\delta \varepsilon + \delta^2 N + \varepsilon/N + 1/N^2) \]
  %
  Or
  %
  \[ \frac{|\Gamma^\delta|}{2 \delta} \leq L + O(\varepsilon + \delta N + \varepsilon/N + 1/N^2) \]
  %
  If we choose $N \geq 1/\delta$, we get that
  %
  \[ \frac{|\Gamma^\delta|}{2 \delta} \leq L + O(\varepsilon + \delta N + \delta \varepsilon) = L + O(\varepsilon + \delta N) \]
  %
  Letting $\delta \downarrow 0$, we conclude that $M^*(\Gamma) \leq L + O(\varepsilon)$, and we can then let $\varepsilon \downarrow 0$ to conclude $M^*(\Gamma) \leq L$. This completes the proof that if $\Gamma$ is rectifiable, then $\Gamma$ has one dimensional Minkowski content, and $M(\Gamma) = L$.
\end{proof}

If $\Gamma$ is rectifiable, it is parameterizable by a Lipschitz map (the arclength parameterization). If we instead consider a curve parameterizable by a map $z$ which is Lipschitz of order $\alpha$, which may no longer be absolutely continuous, but still has a decay very similar to the Minkowski dimension decay.

\begin{theorem}
  If $z$ is a planar curve which is Lipschitz of order $\alpha > 1/2$, then it's trace $\Gamma$ satisfies $|\Gamma^\delta| = O(\delta^{2-1/\alpha})$.
\end{theorem}
\begin{proof}
  Since $|z(t) - z(s)| \leq |t - s|^\alpha$, we can cover $z$ by $O(N)$ radius $1/N^\alpha$ balls, so $|\Gamma| \lesssim N^{1-2\alpha}$, and so $|\Gamma^\delta| \lesssim N (1/N^\alpha + \delta)^2$. Setting $N = \delta^{-1/\alpha} + O(1)$ gives $|\Gamma^\delta| \lesssim \delta^{2-\alpha - 1/\alpha}$.
\end{proof}

\section{The Isoperimetric Inequality}

We now use our Minkowski content techniques to prove the isoperimetric inequality, which asks us to find the region in the plane with largest area whose boundary has a bounded length $L$. We suppose $\Omega$ is a bounded region of the plane, whose boundary $\partial \Omega$ is a rectifiable curve with length $L$. In particular, we shall find the region with the largest area whose boundary has a fixed length are balls. A key inequality used in the proof is the Brun Minkowski inequality, which lowers bounds the measure of $A+B$ in terms of $A$ and $B$. If we hope for an estimate $|A+B|^\alpha \gtrsim |A|^\alpha + |B|^\alpha$, then taking $B = \alpha A$, where $A$ is convex and, for which $A + \alpha A = (1 + \alpha)A$, we find $(1 + \alpha)^{d\alpha} \gtrsim (1 + \alpha^{d\alpha})$. Thus $\alpha \geq 1/d$.

\begin{lemma}
  If $A$, $B$, and $A+B$ are measurable, $|A + B|^{1/d} \geq |A|^{1/d} + |B|^{1/d}$.
\end{lemma}
\begin{proof}
  Suppose first that $A$ and $B$ are rectangles with side lengths $x_n$ and $y_n$. Then the Minkowski inequality becomes
  %
  \[ \left( \prod (x_n + y_n) \right)^{1/d} \geq \left( \prod x_n \right)^{1/d} + \left( \prod y_n \right)^{1/d} \]
  %
  Replacing $x_n$ with $\lambda_n x_n$ and $y_n$ with $\lambda_n y_n$, we find that we may assume $x_n + y_n = 1$, and so we must prove that for any $x_n \leq 1$,
  %
  \[ \left( \prod x_n \right)^{1/d} + \left( \prod (1 - x_n) \right)^{1/d} \leq 1 \]
  %
  But this inequality is an immediate consequence of the arithmetic geometric mean inequality. Thus the case is proved. Next, we suppose $A$ and $B$ are unions of disjoint closed rectangles, and we prove the inequality by induction on the number of rectangles. Without loss of generality, by symmetry in $A$ and $B$, we may assume that $A$ has at least two rectangles $R_1$ and $R_2$. Since the inequality is translation invariant separately in $A$ and $B$, and $R_1$ and $R_2$ is disjoint, hence separated by a coordinate axis, we may assume there exists an index $j$ such that every element $x$ of $R_1$ has $x_1 < 0$ and every element $x$ of $R_2$ has $x_1 > 0$. Let $A^+ = A \cap \{ x_j \leq 0 \}$ and $A^- = A \cap \{ x_j \geq 0\}$. Next, we translate $B$ such that if $B^{\pm}$ are defined similarily, then
  %
  \[ \frac{|B^{\pm}|}{|B|} = \frac{|A^{\pm}|}{|A|} \]
  %
  Note that $A+B$ contains the union of $A^+ + B^+$ and $A^- + B^-$, and this union is disjoint. Thus by induction,
  %
  \begin{align*}
    |A+B| &\geq |A^+ + B^+| + |A^- + B^-|\\
    &\geq (|A^+|^{1/d} + |B^+|^{1/d})^d + (|A^-|^{1/d} + |B^-|^{1/d})^d\\
    &= |A^+| \left( 1 + \left( \frac{|B|^+}{|A|^+} \right)^{1/d} \right)^d + |A^-| \left( 1 + \left( \frac{|B|^-}{|A|^-} \right) \right)^d\\
    &= (|A|^{1/d} + |B|^{1/d})^d
  \end{align*}
  %
  Thus the proof is completed for unions of rectangles. The proof then passes to open sets by approximating open sets by closed rectangles contained within. Then we can pass to where $A$ and $B$ are compact sets, since then $A+B$ is compact, and so if we consider the open thickenings $A^\varepsilon$, $B^\varepsilon$, and $(A+B)^\varepsilon$, then
  %
  \[ |A| = \lim |A^\varepsilon|\ \ \ |B| = \lim |B^\varepsilon|\ \ \ |A + B| = \lim |(A + B)^\varepsilon| \]
  %
  and $(A+B)^\varepsilon \subset A^\varepsilon + B^\varepsilon \subset (A + B)^{2\varepsilon}$. Finally, we can use inner regularity to obtain the theorem in full.
\end{proof}

\begin{theorem}
  For any region $\Omega$, $4 \pi |\Omega| \leq L^2$.
\end{theorem}
\begin{proof}
  For $\delta > 0$, consider
  %
  \[ \Omega_+(\delta) = \{ x: d(x,\Omega) < \delta \}\ \ \ \ \Omega_-(\delta) = \{ x : d(x,\Omega^c) \geq \delta \} \]
  %
  Then we have a disjoint union $\Omega_+(\delta) = \Omega_-(\delta) + \Gamma^\delta$, where $\Gamma$ is the boundary curve of $\Omega$. Furthermore, $\Omega_+(\delta)$ contains $\Omega + B_\delta$, and $\Omega$ contains $\Omega_-(\delta) + B_\delta$. Applying the Brun Minkowski inequality, we conclude
  %
  \[ |\Omega_+(\delta)| \geq (|\Omega|^{1/2} + \pi^{1/2} \delta)^2 \geq |\Omega| + 2 \pi^{1/2} \delta |\Omega|^{1/2} \]
  \[ |\Omega| \geq (|\Omega_-(\delta)|^{1/2} + \pi^{1/2} \delta)^2 \geq |\Omega_-(\delta)| + 2 \pi^{1/2} \delta |\Omega_-(\delta)|^{1/2} \]
  %
  But
  %
  \[ |\Gamma^\delta| = |\Omega_+(\delta)| - |\Omega_-(\delta)| \geq 2 \pi^{1/2} \delta \left( |\Omega|^{1/2} + |\Omega_-(\delta)|^{1/2} \right) \]
  %
  Dividing by $2\delta$ and letting $\delta \to 0$, we conclude $L \geq 2 \pi^{1/2} |\Omega|^{1/2}$. This is precisely the inequality we need.
\end{proof}

Using some Fourier analysis, we can prove that the only smooth curves which make this inequality tight are circles. Indeed, if a closed $C^1$ curve $\Gamma = \{ z(t): a \leq t \leq b \}$ is given, then Green's theorem implies the area of its interior is given by
%
\[ \frac{1}{2} \left| \int_\Gamma x\; dy - y\; dx \right| = \frac{1}{2} \left| \int_a^b x(t) y'(t) - y(t) x'(t) \right| \]
%
We then take a Fourier series in $x$ and $y$.

\begin{theorem}
  The only curves $\Gamma$ with rectifiable boundary such that $A = \pi (L/2)^2$ are circles.
\end{theorem}
\begin{proof}
By normalizing, we may assume $z$ is an arcline parameterization, and $\Gamma$ has length $2\pi$, so $z:[0,2\pi] \to \mathbf{R}^2$, and $z$ is absolutely continuous. If $x(t) \sim \sum a_n e^{nit}$ and $y(t) \sim \sum b_n e^{int}$, then $x'(t) \sim \sum i n a_n e^{n i t}$ and $y(t) \sim \sum i n b_n e^{nit}$. Parseval's equality implies
%
\[ \int_0^{2\pi} x(t) y'(t) - y(t) x'(t) = 2 \pi i \sum n (b_n \overline{a_n} - a_n \overline{b_n}) \]
%
Thus the area of the curve is precisely
%
\[ \pi \left| \sum n (b_n \overline{a_n} - a_n \overline{b_n}) \right| \leq \pi \sum 2n|b_na_n| \leq \pi \sum |n|(|a_n|^2 + |b_n|^2) \]
%
On the other hand, the length constraint implies that, since $|z'(t)| = 1$,
%
\[ 1 = \frac{1}{2\pi} \int_0^{2\pi} x'(t)^2 + y'(t)^2 = \sum |n|^2(|a_n|^2 + |b_n|^2) \]
%
If $A = \pi$, then
%
\[ \sum |n| (|a_n|^2 + |b_n|^2) \geq 1 = \sum |n|^2 (|a_n|^2 + |b_n|^2) \]
%
This means we cannot have $|n| < |n|^2$ whenever $a_n$ or $b_n$ is nonzero. Thus the Fourier support of $x$ and $y$ is precisely $\{ -1, 0, 1 \}$. Since $x$ is real valued, $a_1 = \overline{a_{-1}} = a$, $b_1 = \overline{b_{-1}}$. We thus have $2(|a_1|^2 + |b_1|^2) = 1$, and since we must have $a$ a scalar multiple of $b$ so the Cauchy Schwarz inequality application becomes an equality, we must have $|a_1| = |b_1| = 1/2$. If $a_1 = e^{i\alpha}/2$ and $b_1 = e^{i\beta}/2$, the fact that $1 = 2|a_1\overline{b_1} - \overline{a_1}b_1|$ implies $|\sin(\alpha - \beta)| = 1$, hence $\alpha - \beta = k \pi /2$, where $k$ is an odd integer. Thus $x(s) = \cos(\alpha + s)$, and $y(s) = \cos(\beta + s)$, which parameterizes a circle.
\end{proof}




\chapter{Singular Integral Operators}

Let us now consider some kernel operators
%
\[ Tf(y) = \int K(x,y) f(x)\; dx \]
%
where $K(x,y)$ is singular for $x = y$. The prototypical example is the Hilbert transform on $\RR$, i.e.
%
\[ Hf(y) = \int \frac{f(x-y)}{y}\; dy. \]
%
One cannot even interpret the right hand side in the Lebesgue sense because the function $1/y$ is not Lebesgue integrable. We can proceed  




\chapter{Fourier Multiplier Operators}

Our aim in this chapter is to study the boundedness of \emph{Fourier multiplier operators}. Given a function $m: \RR^d \to \CC$, known as a \emph{symbol}, we want to associate a multiplier operator $m(D)$ which when applied to a function $f: \RR^d \to CC$ should be formally given by the equation
%
\[ (m(D)f)(x) = \int_{\RR^d} m(\xi) \widehat{f}(\xi) e^{2 \pi i \xi \cdot x}\; d\xi. \]
%
In maximum generality, if $m$ is a tempered distribution on $\RR^d$ we can consider the continuous operator $m(D): \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$. But often times $m$ will be much more regular, which we would hope can be exploited to give stronger continuity statements. Taking the Fourier transform shows that if $\widehat{K} = m$, then $m(D) f = K * f$. Thus Fourier multiplier operators are the same as convolution operators by tempered distributions. In any case, the map $m \mapsto m(D)$ gives an injective \emph{algebra homomorphism} from the family of all tempered distributions to the family of continuous operators on $\mathcal{S}(\RR^d)$ (another injective homomorphism is obtained by considering the multiplier operators $m \mapsto m(X)$, where $m(X)$ is the multiplier operator $m(X) f = m \cdot f$). The main goal, of course, is to determine what properties of the symbol or it's Fourier transform imply boundedness properties of the operator $T$.

\begin{remark}
  In engineering these operators are known as \emph{filters}, and occur in a variety of contexts. Due to the presence of error the regularity of these operators are of utmost importance. The function $m$ is known as the \emph{system-transfer function}, \emph{optical-transfer function}, or \emph{frequency response}, depending on the context, and the function $K$ is known as the \emph{point-spread function}.
\end{remark}

\begin{example}
  Over $\RR$, consider a rough cutoff $\mathbf{I}_{[-1,1]}$. Then we calculate explicitly that
  %
  \[ K(x) = \int_{-1}^1 e^{2 \pi i \xi \cdot x} = \frac{\sin(2 \pi x)}{\pi x}. \]
  %
  A natural way to `localize in frequency'
\end{example}

\begin{example}
  Over $\RR$, we consider the Fourier multiplier
  %
  \[ m(\xi) = - i \text{sgn}(\xi). \]
  %
  Then $m(D)$ is the Hilbert transform.
\end{example}

\begin{example}
  In $\RR^d$, we consider the Fourier multiplier
  %
  \[ m_R(\xi) = \mathbf{I}(|\xi| \leq R). \]
  %
  The operator $m_R(D)$ is known as the \emph{ball multiplier operator}. More generally, given any compact set $S$ we can consider the Fourier multiplier $\mathbf{I}_S(D)$. In the engineering literature these multipliers are called \emph{ideal low pass filters}.
\end{example}

\begin{example}
  In this chapter, it is natural to renormalize the differentiation operators $D^\alpha: \mathcal{S}(\RR^d) \to \mathcal{S}(\RR^d)$ so that for $f \in \mathcal{S}(\RR^d)$,
  %
  \[ \widehat{D^\alpha f} = \xi^\alpha \widehat{f}. \]
  %
  In particular, this implies that if $m(\xi) = \xi_i^\alpha$, then $m(D) = D^\alpha$. More generally, if $m(\xi) = \sum_{|\alpha| \leq k} c_\alpha \xi^\alpha$, then
  %
  \[ m(D) = \sum_{|\alpha| \leq k} c_\alpha D^\alpha. \]
  %
  Thus the family of Fourier multiplier operators contains all constant coefficient differential operators.
\end{example}

Fourier multiplier operators have been essential to us in the classical theory. In particular, we have used Fourier multiplier operators to prove a great many results; the convolution operator by the Poisson kernel is a Fourier multiplier given by the symbol $e^{-|x|}$, and the heat kernel is a Fourier multiplier with symbol $e^{- \pi |x|^2}$. This is no coincidence. It is a general heuristic that any well-behaved translation invariant operator is given by convolution with an appropriate function.

For instance, we have already seen in the chapter on distributions that any translation invariant continuous linear operator $T: C_c^\infty(\RR^d) \to C^\infty(\RR^d)$ is given by convolution with a distribution. If the distribution is tempered, we can take the Fourier transform to conclude that the operator is a Fourier multiplier operator. In fact, if $1 \leq p,q \leq \infty$ and $T$ satisfies a bound of the form
%
\[ \| Tf \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
for any $f \in \mathcal{S}(\RR^d)$, then $T$ is a Fourier multiplier operator. To prove this, we rely on a Sobolev-type regularity result.

\begin{lemma}
  Suppose $1 \leq p,q \leq \infty$. If $f \in L^p(\RR^d)$ has a strong derivative $D^\alpha f$ in $L^p(\RR^d)$ for all $|\alpha| \leq d+1$, then $f \in C(\RR^d)$, and
    %
    \[ |f(0)| \lesssim_{d,p} \sum_{|\alpha| \leq d + 1} \| D^\alpha f \|_{L^p(\RR^d)}. \]
\end{lemma}
\begin{proof}
    Let us first suppose $p = 1$. Then
    %
    \begin{align*}
      |\widehat{f}(x)| &\lesssim \frac{\sum_{|\alpha| \leq d+1} |x^\alpha \widehat{f}(x)|}{(1 + |x|)^{d+1}}\\
      &\lesssim \frac{\sum_{|\alpha| \leq d+1} \| D^\alpha f \|_{L^1(\RR^d)}}{(1 + |x|)^{d+1}}
    \end{align*}
    %
    Since $1/(1 + |x|)^{d+1} \in L^1(\RR^d)$, we conclude that $\widehat{f} \in L^1(\RR^d)$, and
    %
    \[ \| \widehat{f} \|_{L^1(\RR^d)} \lesssim \sum_{|\alpha| \leq d+1} \| D^\alpha f \|_{L^1(\RR^d)}. \]
    %
    It follows by the Fourier inversion formula that $f \in C(\RR^d)$, and moreover,
    %
    \[ \| f \|_{L^\infty(\RR^d)} \leq \sum_{|\alpha| \leq d+1} \| D^\alpha f \|_{L^1(\RR^d)}, \]
    %
    which completes the proof for $p = 1$.

    For $p > 1$, any compactly supported bump function $\phi$, and any multi-index $\alpha$ with $|\alpha| \leq d+1$,
    %
    \[ \| D^\alpha(\phi f) \|_{L^1(\RR^d)} \leq \sum_{\beta \leq \alpha} \| D^\beta \phi \cdot D^{\alpha - \beta} f \|_{L^1(\RR^d)} \lesssim_\phi \sum_{\beta \leq d+1} \| D^\beta f \|_{L^p(\RR^d)}. \]
    %
    It follows from the previous case that $\phi f \in C(\RR)$, and
    %
    \[ \phi(0) f(0) \lesssim_\phi \sum_{\beta \leq d+1} \| D^\beta f \|_{L^p(\RR^d)}. \]
    %
    Since $\phi$ was arbitrary, we conclude $f \in C(\RR)$, and that
    %
    \[ f(0) \lesssim \sum_{\beta \leq d+1} \| D^\beta f \|_{L^p(\RR^d)}. \qedhere \]
\end{proof}

\begin{theorem}
  Suppose $1 \leq p,q \leq \infty$, and $T: \mathcal{S}(\RR^d) \to L^q(\RR^d)$ is a linear map commuting with translations and satisfies
  %
  \[ \| Tf \|_{L^q(\RR^d)} \leq \| f \|_{L^p(\RR^d)} \]
  %
  for all $f \in \mathcal{S}(\RR^d)$. Then $T$ is a Fourier multiplier operator.
\end{theorem}
\begin{proof}
  For any $f \in \mathcal{S}(\RR^d)$, $Tf \in W^{q,n}(\RR^d)$ for any $n > 0$. To see this, we note that for any $h > 0$ and $k \in \{ 1, \dots, d \}$, and
  %
  \[ (\Delta_h f)(x) = \frac{f(x + he_k) - f(x)}{h}. \]
  %
  Then $\Delta_h(T f) = T(\Delta_h f)$ because $T$ is translation invariant. Since $f$ is a Schwartz function, $\Delta_h f$ converges to $D^k f$ in $L^p(\RR^d)$. Thus by continuity of $f$, $Tf$ has a strong derivative $T(D^k f)$ in $L^q(\RR^d)$. Induction shows $Tf$ has strong derivatives of all orders. The last lemma shows that $Tf \in C(\RR^d)$, and
  %
  \begin{align*}
    |Tf(0)| &\lesssim \sum_{|\alpha| \leq n+1} \| D^\alpha(Tf) \|_{L^q(\RR^d)}\\
    &= \sum_{|\alpha| \leq n+1} \| T(D^\alpha f) \|_{L^q(\RR^d)}\\
    &\lesssim \sum_{|\alpha| \leq n+1} \| D^\alpha f \|_{L^q(\RR^d)}.
  \end{align*}
  %
  The map $f \mapsto Tf(0)$ is thus continuous on $\mathcal{S}(\RR^d)$, and therefore defines a tempered distribution $\Lambda$. Translation invariance shows that $Tf = \Lambda * f$, and setting $m = \widehat{\Lambda}$ completes the proof.
\end{proof}

\begin{remark}
    It therefore follows that if $T: \mathcal{S}(\RR^d) \to L^q(\RR^d)$ is a linear operator commuting a translation satisfying a bound
    %
    \[ \| Tf \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)}, \]
    %
    then $Tf \in C^\infty(\RR^d)$ and is slowly increasing, as is all of it's derivatives.
\end{remark}







\section{Frequency Localization}

One use of Fourier multipliers is to localize the support of the Fourier tranform of a function to a portion of space. Given a compactly supported function $m$ supported on some set $S$, and any function $f$, $\widehat{m(D) f} = m \widehat{f}$ is supported on $S$, so Fourier multipliers give us a simple way to localize. Frequency localization has the additional feature that $m(D) f$ is smooth (actually analytic).  One can choose a rough frequency localization, like a ball or rectangle multiplier, or a multiplier corresponding to a smooth cutoff. One major use of frequency localization is that if $\widehat{f}$ is localized near a frequency $\xi$, then it makes sense that $\partial_\alpha f$ is approximately equal to $2 \pi i \xi_0^\alpha$. Thus frequency localization is often useful when studying problems involving derivatives. Another use results from the uncertainty principle, where we find that a function $f$ with $\widehat{f}$ supported on a cube centred at the origin with sidelengths $R_1, \dots, R_d$, then $f$ is locally constant on `dual rectangles' with sidelengths $1/R_1, \dots, 1/R_d$. More generally, if $\widehat{f}$ is supported on such a cube centred at $\xi_0$, then $f$ acts roughly like constant multiples of $e^{2 \pi i \xi \cdot x}$ on dual rectangles.

In one dimension, a rough cutoff can be explicitly computed. If we consider the Fourier multiplier $\mathbf{I}_{[-R,R]}$, then this multiplier corresponds to the kernel
%
\[ K(x) = \int_{-R}^R e^{2 \pi i \xi x} = \frac{\sin(2 \pi R x)}{\pi x}, \]
%
i.e. a sync function. If $f$ is supported on an interval $I$, then it follows from a simple estimate that
%
\[ |(K * f)(x)| \lesssim \frac{\| f \|_{L^1(\RR)}}{d(x,I)}. \]
%
Thus the frequency localization is no longer supported on $I$, but decays inversely away, which is often not enough to obtain useful estimates. Similarily, in $\RR^d$, if we let $K = K_1 \otimes \dots \times K_d$ be the kernel associated with the rectangle multiplier, then we have a similar estimate.

We can do better if we use a smooth cutoff function, i.e. we choose a smooth non-negative function $m$ compactly supported on $I$ which equals one on the inner third of $I$, and satisfies $\| \partial_\alpha m \|_{L^\infty(\RR^d)} \lesssim_\alpha |I|^{-|\alpha|}$ for all multi-indices $\alpha$, and then consider the Fourier multiplier $m(D)$. Then $m(D)$ corresponds to the kernel
%
\[ K(x) = \int e^{2 \pi i \xi \cdot x} m(\xi)\; d\xi. \]
%
Integrating by parts gives that for all $n > 0$, $|K(x)| \lesssim_n |I|^{1-n} |x|^{-n}$, which decreasing away from the origin much faster than for a rough cutoff. This implies that we have the decay estimates
%
\[ |(K * f)(x)| \lesssim_n \frac{|I|^{1-n} \| f \|_{L^1(\RR^d)}}{d(x,J)^n}. \]
%
for $f$ supported on an interval $J$. This is often much more negligible than the estimates above.









\section{$L^p$ Regularity}

We now wish to know what conditions on $m$ guarantee bounds of the form
%
\[ \| m(D) f \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)}. \]
%
for all $f \in \mathcal{S}(\RR^d)$. Littlewood's principle tells us that the only interesting case occur with `the larger exponent on the left'.

\begin{theorem}
  Fix $1 \leq q < p \leq \infty$, and suppose $m \in \mathcal{S}(\RR^d)'$ with
  %
  \[ \| m(D) f \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
  for all $f \in \mathcal{S}(\RR^d)$. Then $m = 0$.F
\end{theorem}
\begin{proof}
  Suppose $m \neq 0$. Then there is $f_0 \in \mathcal{S}(\RR^d)$ with $m(D) f \neq 0$. Thus $m(D) f_0$ lies in $C^\infty(\RR^d) \cap L^q(\RR^d)$. Fix a large integer $N$ and pick $x_1,\dots,x_N \in \RR^d$ separated far enough apart that
  %
  \[ \| \sum_{n = 1}^N \text{Trans}_{x_n} f_0 \|_{L^p(\RR^d)} \gtrsim N^{1/p} \| f_0 \|_{L^p(\RR^d)} \]
  %
  and
  %
  \[ \| \sum_{n = 1}^N \text{Trans}_{x_n} m(D) f_0 \|_{L^q(\RR^d)} \sim N^{1/q} \| m(D) f_0 \|_{L^q(\RR^d)} \lesssim N^{1/q} \| f_0 \|_{L^p(\RR^d)}. \]
  %
  Translation invariance of convolution shows $N^{1/q} \lesssim N^{1/p}$, which is impossible for suitably large $N$. Thus $m = 0$.
\end{proof}

In general, a characterization of the tempered distributions which give bounded convolution operators is unknown except in a few very particular situations. For each $1 \leq p \leq q \leq \infty$, we let $\| m \|_{M^{p,q}(\RR^d)}$ denote the operator norm of the multiplier operator $m(D)$ from $L^p(\RR^d)$ to $L^q(\RR^d)$, i.e. the smallest quantity such that
%
\[ \| m(D) f \|_{L^q(\RR^d)} \leq \| m \|_{M^{p,q}(\RR^d)} \| f \|_{L^p(\RR^d)} \]
%
for all $f \in \mathcal{S}(\RR^d)$. We let $M^{p,q}(\RR^d)$ be the set of tempered distributions for which the bound is finite. For simplicity, we also let $M^p(\RR^d)$ denote $M^{p,p}(\RR^d)$. By symmetries of the Fourier transform, it is easy to check that translations, modulations, and dilations all preserve the $M^{p,q}$. Thus we have a complete set of affine symmetries, as well as a modulation symmetry.

\begin{example}
  A Fourier multiplier operator $T$ corresponding to a tempered distribution $m$ has a bound
  %
  \[ \| m(D)f \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)} \]
  %
  if and only if $m \in L^\infty(\RR^d)$, and then $\| m \|_{M^{2,2}(\RR^d)} = \| m \|_{L^\infty(\RR^d)}$. To see this, let
  %
  \[ \Phi(x) = e^{- \pi |x|^2} \]
  %
  be the Gaussian distribution. Then
  %
  \[ \widehat{m(D) \Phi} = \Phi \cdot m. \]
  %
  Since $\Phi \in L^2(\RR^d)$, $m(D) \Phi \in L^2(\RR^d)$, and so $\Phi \cdot m \in L^2(\RR^d)$. But then we conclude that
  %
  \[ m = \frac{\widehat{m(D) \Phi}}{\Phi}. \]
  %
  Thus $m \in L^1_{\text{loc}}(\RR^d)$. But then the result is obvious.
\end{example}

For any tempered distribution $m$ and $f,g \in \mathcal{S}(\RR^d)$,
%
\begin{align*}
  \langle m(D) f, g \rangle &= \langle m \widehat{f}, \widehat{g} \rangle
  &= \langle \widehat{f}, m^* \widehat{g} \rangle
  &= \langle f, m^*(D) g \rangle.
\end{align*}
%
Thus we have an adjoint relation $m(D)^* = m^*(D)$, which gives a natural duality theory for Fourier multiplier operators.

\begin{theorem}
  For any $1 \leq p,q \leq \infty$ and any tempered distribution $m$,
  %
  \[ \| m \|_{M^{p,q}(\RR^d)} = \| m \|_{M^{q^*,p^*}(\RR^d)}. \]
\end{theorem}
\begin{proof}
  Using the adjoint relation, if
  %
  \[ \| m(D) f \|_{L^q(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
  then
  %
  \[ \| m^*(D) f \|_{L^{p^*}(\RR^d)} \lesssim \| f \|_{L^{q^*}(\RR^d)} \]
  %
  But it is easy to calculate that if we set $[\text{Ref} u](x) = u(-x)$, then for any $x \in \RR^d$,
  %
  \[ [m^*(D) f](x) = [m(D)(\text{Ref}f^*)(-x)]^* \]
  %
  and so $\| m^*(D) f \|_{L^{p^*}(\RR^d)} = \| m(D) f \|_{L^{p^*}(\RR^d)}$.
\end{proof}

In particular, if $1 \leq p \leq \infty$ and $m \in M^p(\RR^d)$, then also $m \in M^{p^*,p^*}(\RR^d)$ and so Riesz-interpolation implies $m \in M^{2,2}(\RR^d)$. Thus if we are studying $L^p$ to $L^p$ boundedness for any $1 \leq p \leq \infty$, we may restrict our attention to bounded Fourier multipliers.

\begin{example}
  The only remaining space which is completely understood is the space $M^{1,1}(\RR^d) = M^{\infty,\infty}(\RR^d)$; in this case, a tempered distribution is included if and only if the distribution is the Fourier transform of a finite Borel measure, and moreover, if $\mu \in M(\RR^d)$ is a finite Borel measure, then $\| \widehat{\mu} \|_{M^{1,1}(\RR^d)} = \| \mu \|_{TV(\RR^d)}$. If $\{ \Phi_\delta : \delta > 0 \}$ is the Gauss kernel, set
  %
  \[ m_\delta(x) = e^{- \delta |x|^2} m(\xi) \]
  %
  Then by assumption of $L^1$ boundedness, and the fact that the Fourier transform of $e^{-\delta |x|^2}$ is a constant multiple of $\Phi_\delta$, we conclude that for all $\delta > 0$,
  %
  \[ \| \widecheck{m_\delta} \|_{L^1(\RR^d)} \lesssim 1. \]
  %
  Thus $\{ \widecheck{m_\delta} \}$ are uniformly bounded in $L^1(\RR^d)$, so by Banach Alaoglu theorem, combined with the fact that $L^1(\RR^d)$ embeds in $M(\RR^d)$, which is the dual of $C_0(\RR^d)$, we conclude there is a subsequence $\{ \delta_k \}$ converging to zero such that $\widecheck{m_{\delta_k}}$ converges weakly to some finite Borel measure $\mu$. But this implies that $m_{\delta_k}$ converges weakly to $\widehat{\mu}$, which implies $m = \widehat{\mu}$.
\end{example}

For $1 < p < 2$ and $2 < p < \infty$, characterizing $M^p(\RR^d)$ is a much more subtle task, if not impossible. For instance, it remains an open question to determine for which values of $p$ and $\delta$ for which the multiplier
%
\[ m^\delta(\xi) = \max((1 - |\xi|^2)^\delta,0) \]
%
lies in $M^p(\RR^d)$, a problem known as the \emph{Bochner-Riesz conjecture}.

The difficulty here is that $m^\delta$ is singular on the boundary of the unit sphere, which is a large, curved set. However, mathematicians have developed criteria which implies boundedness of various operators. The most fundamental occurs if the multiplier $m$ has no singularities. For instance, if $m \in \mathcal{S}(\RR^d)$, then $\widecheck{m} \in L^1(\RR^d)$, so $m \in M^{1,1}(\RR^d)$, and thus in $M^p(\RR^d)$ for all $1 \leq p \leq \infty$. Similarily, if $m$ is a bump function adapted to $L(\Omega)$ for a fixed boundary domain $\Omega$, then $\| m \|_{M^p(\RR^d)} \lesssim_{d,\Omega} 1$ for all $1 \leq p \leq \infty$.

If the multiplier $m$ is only singular on a smaller set, we can also do better. For instance, if the Hilbert transform satisfies the bounds
%
\[ \| Hf \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)} \]
%
for all $f \in \mathcal{S}(\RR^d)$ and $1 < p < \infty$. It therefore follows that for $1 < p < \infty$ and any (possibly unbounded interval) $I$,
%
\[ \| \mathbf{I}_{I} \|_{M^p(\RR^d)}, \| \mathbf{I}_{I} \|_{M^p(\RR^d)} \lesssim_p 1. \]
%
Now suppose $m \in L^\infty(\RR^d)$ has \emph{bounded variation}, which means the quantity
%
\[ V(m) = \sup_{\xi_1 < \dots < \xi_N} \sum_{i = 1}^{N-1} |m(\xi_{i+1}) - m(\xi_i)|. \]
%
is finite. Then $m$ has countably many discontinuities, and the variation prevents too much nonsmoothness.

\begin{theorem}
  Suppose $m \in L^\infty(\RR)$ has finite variation. Then for each $1 < p < \infty$,
  %
  \[ \| m \|_{M^p(\RR)} \lesssim_p \| m \|_{L^\infty(\RR)} + V(m) \]
\end{theorem}
\begin{proof}
  For each $n$, pick $\xi_1,\dots,\xi_{N_n}$ such that
  %
  \[ \sum_{i = 1}^{N-1} |m(\xi_{i+1}) - m(\xi_i)| \geq V(m) - 1/n. \]
  %
  If we define
  %
  \[ m_n = m(\xi_1) \mathbf{I}_{(-\infty,\xi_1)} + \sum_{i = 1}^{N-1} m(\xi_i) \mathbf{I}_{(\xi_i,\xi_{i+1})} + m(\xi_N) \mathbf{I}_{(\xi_N,\infty)} \]
  %
  then $m - m_n$ is a finite signed Borel measure with $\| m - m_n \|_{M(\RR)} \leq 1/n$. Thus
  %
  \[ \| m \|_{M^p(\RR)} \leq \limsup_{n \to \infty} \| m_n \|_{M^p(\RR)}. \]
  %
  Now we can rewrite
  %
  \[ m_n(\xi) = m(\xi_1) \mathbf{I}_{(-\infty,\xi_1)} + \sum_{i = 1}^{N-1} [m(\xi_i) - m(\xi_{i+1})] \mathbf{I}_{(\xi_1,\xi_i)}(\xi) + m(\xi_N) \mathbf{I}_{(\xi_N,\infty)}. \]
  %
  Thus we find that for $1 < p < \infty$,
  %
  \[ \| m_n \|_{M^p(\RR)} \lesssim_p |m(\xi_1)| + \sum_{i = 1}^{N-1} |m(\xi_i) - m(\xi_{i+1})| + |m(\xi_N)| \leq \| m \|_{L^\infty(\RR)} + V(m). \]
  %
  But this means that $\| m \|_{M^p(\RR)} \lesssim_p \| m \|_{L^\infty(\RR)} + V(m)$.
\end{proof}

The theory of Fourier multipliers gets more complicated as we increase the dimension of the ambient space we are working in. De Leeuw's theorem shows slices of continuous $d+1$ dimensional multipliers are bounded by the original mutiplier.

\begin{theorem}
  Let $m \in C(\RR^{d+1})$. For each $\xi_0 \in \RR$ define $m_0 \in C(\RR^d)$ by setting
  %
  \[ m_0(\xi) = m(\xi,\xi_0). \]
  %
  Then for any $1 \leq p \leq \infty$, $\| m_0 \|_{M^p(\RR^d)} \leq \| m \|_{M^p(\RR^{d+1})}$.
\end{theorem}
\begin{proof}
  Without loss of generality, assume $\xi_0 = 0$. For $\lambda > 0$ set
  %
  \[ L(\xi_1,\dots,\xi_d) = (\xi_1,\dots,\xi_{d-1},\xi_d/\lambda). \]
  %
  Then
  %
  \[ \| m \circ L_\lambda \|_{M^p(\RR^d)} = \| m \|_{M^p(\RR^d)}. \]
  %
  Take $\lambda \to \infty$. Since $m$ is continuous, $m \circ L_\lambda$ converges to $m \circ L_\infty$ pointwise as $\lambda \to \infty$, where $L_\infty(\xi_1,\dots,\xi_d) = (\xi_1,\dots,\xi_{d-1},0)$. On the other hand,
  %
  \[ \| m \circ L_\infty \|_{M^p(\RR^d)} = \| m_0 \|_{M^p(\RR^d)}. \]
  %
  Thus it suffices to show that
  %
  \[ \| m \circ L_\infty \|_{M^p(\RR^d)} \leq \limsup_{\lambda \to \infty} \| m \circ L_\lambda \|_{M^p(\RR^d)}. \]
  %
  But to do this it suffices to use a weak convergence argument; for any $f,g \in \mathcal{S}(\RR^{d+1})$, we just note that dominated convergence shows that
  %
  \[ \lim_{\lambda \to \infty} |\langle (m \circ L_\lambda)(D) f, g \rangle| = \langle (m \circ L_\infty)(D) f, g \rangle. \qedhere \]
\end{proof}

The theorem of H\"{o}rmander-Mikhlin gives another instance of this phenomenon, giving $L^p$ bounds to Fourier multipliers which decay smoothly and rapidly away from the origin.

\begin{theorem}
  Let $m \in L^\infty(\RR^d)$ and suppose there exists an integer $n > d/2$ such that for any $\beta \in C_c^\infty(\RR^d - \{ 0 \})$ and any multi-index $\alpha$ with $|\alpha| \leq n$,
  %
  \[ \| D^\alpha( (\text{Dil}_{1/\lambda} \beta) \cdot m ) \|_{L^2(\RR^d)} \lesssim_\beta \lambda^{d/2-|\alpha|} \]
  %
  Then for any $1 < p < \infty$ and $f \in \mathcal{S}(\RR^d)$,
  %
  \[ \| m(D) f \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)}. \]
\end{theorem}

\begin{remark}
  The assumptions of the theorem hold for $m \in C^\infty(\RR^d - \{ 0 \})$ any multi-index $\alpha$ and any $\xi \neq 0$, $|D^\alpha m(\xi)| \lesssim_\alpha |\xi|^{-\alpha}$. It then follows that
  %
  \[ D^\alpha((\text{Dil}_{1/\lambda} \beta) \cdot m) = \sum_{\gamma \leq \alpha} \lambda^{-|\gamma|} \cdot (\text{Dil}_{1/\lambda} (D^\gamma \beta)) \cdot D^{\alpha - \gamma} m \]
  %
  Now rescaling shows
  %
  \begin{align*}
    \| \lambda^{-|\gamma|} (\text{Dil}_{1/\lambda} (D^\gamma \beta)) \cdot (D^{\alpha - \gamma} m) \|_{L^2(\RR^d)} \lesssim_{\beta,n} \lambda^{d/2-|\alpha|},
  \end{align*}
  %
  and summing up implies $m(D)$ is a H\"{o}rmander-Mikhlin operator. In particular, this is true if $m \in C^\infty(\RR^d - \{ 0 \})$ is homogenous of degree zero.
\end{remark}

\begin{proof}
  s
\end{proof}











\chapter{Sobolev Spaces}

Let $\Omega$ be an open subset of $\RR^d$. A natural problem when studying smooth functions $\phi \in C_c^\infty(\Omega)$ is to obtain estimates on the partial derivatives of $\phi$. For instance, one can consider the norms
%
\[ \| \phi \|_{C^n(\Omega)} = \max_{|\alpha| \leq n} \| D^\alpha f \|_{L^\infty(\Omega)}. \]
%
The space $C_c^\infty(\Omega)$ is not complete with respect to this norm, but it's completion is the space $C^n_b(\Omega)$ of $n$ times bounded continuously differentiable functions on $\Omega$, which still consists of regular functions. Unfortunately, such estimates are only encountered in the most trivial situations. As in the non-smooth case, one can often get much better estimates using the $L^p$ norms of the derivatives, i.e. considering the norms
%
\[ \| \phi \|_{W^{n,p}(\Omega)} = \left( \sum_{|\alpha| \leq p} \| D^\alpha \phi \|_{L^p(\Omega)}^p \right)^{1/p}. \]
%
As might be expected, $C_c^\infty(\Omega)$ is not complete with respect to the $W^{n,p}(\Omega)$ norm. However, it's completion cannot be identified with a family of $n$ times differentiable functions. Instead, to obtain a satisfactory picture of the compoetion under this norm, a Banach space we will denote by $W^{n,p}(\Omega)$, we must take a distribution approach.

For each multi-index $\alpha$, if $f$ and $f_\alpha$ are locally integrable functions on $\Omega$, we say $f_\alpha$ is a weak derivative for $f$ if for any $\phi \in C_c^\infty(\Omega)$,
%
\[ \int_\Omega f_\alpha(x) \phi(x)\; dx = (-1)^{|\alpha|} \int_\Omega f(x) \phi_\alpha(x)\; dx. \]
%
In other words, this is the same as the derivative of $f$ viewed as a distribution on $\Omega$. We define $W^{n,p}$ to be the space of all functions $f \in L^p(\Omega)$ such that for each $|\alpha| \leq n$, a weak derivative $f_\alpha$ exists and is an element of $L^p(\Omega)$. We then define
%
\[ \| f \|_{W^{n,p}(\Omega)} = \left( \sum_{|\alpha| \leq n} \| f_\alpha \|_{L^p(\Omega)} \right)^{1/p}. \]
%
Where this sum is treated as a maximum in the case $p = \infty$. Later on we will be able to show this space is a complete Banach space.

\begin{example}
  Let $B$ be the open unit ball in $\RR^d$, and let $u(x) = |x|^{-s}$, where $s < n-1$. For which $p$ is $u \in W^{1,p}(B)$? We calculate by an integration by parts that if $\phi \in C_c^\infty(B)$, we fix $\varepsilon > 0$ and write
  %
  \[ \int_B \phi_i(x) u(x)\; dx = \int_{|x| \leq \varepsilon} \phi_i(x) u(x) + \int_{\varepsilon < |x| \leq 1} \phi_i(x) u(x). \]
  %
  The integral on the $\varepsilon$ ball is neglible since $s < n$. Since $u$ is smooth away from the origin, it's distributional derivative agrees with it's standard derivative, which is
  %
  \[ u_i(x) = \frac{- \alpha x_i}{|x|^{s + 2}}. \]
  %
  Thus $|u_i| \lesssim 1/|x|^{s + 1}$. An integration by parts gives
  % in the $i$'th direction, and we calculate $\nabla u(x) = -\alpha x |x|^{-\alpha-2}$. Thus an integration by parts gives
  %
  \[ \int_{\varepsilon < |x| \leq 1} \phi_i(x) u(x) = \int_{|x| = \varepsilon} \phi(x) u(x) \nu_i\ dS + \int_{\varepsilon < |x| \leq 1} \frac{s \phi(x) x_i}{|x|^{s + 2}}\; dx, \]
  %
  where $\nu_i$ is the normal vector to the sphere pointing inward. Since $s < n-1$, the surface integral tends to zero as $\varepsilon \to 0$. Thus the weak derivative of $u$ is equal to the standard derivative. Consequently, $u \in W^{1,p}(B)$ if $s < n/p - 1$.
\end{example}

\begin{example}
  If $\{ r_k \}$ is a countable, dense subset of $B$, then we can define
  %
  \[ u(x) = \sum_{k = 1}^\infty \frac{|x - r_k|^{-s}}{2^k} \]
  %
  Then $u \in W^{1,p}(B)$ if $0 < \alpha < n/p - 1$, yet $u$ has a dense family of singularities, and thus does not behave like any differentiable function we would think of.
\end{example}

\begin{theorem}
  For each $k \in \mathbf{N}$ and $1 \leq p \leq \infty$, $W^{k,p}(\Omega)$ is a Banach space.
\end{theorem}
\begin{proof}
  It is easy to verify that $\| \cdot \|_{W^{k,p}}$ is a norm on $W^{k,p}(\Omega)$. Let $\{ u_n \}$ be a Cauchy sequence in $W^{k,p}(\Omega)$. In particular, this means that $\{ D^\alpha u_n \}$ is a Cauchy sequence in $L^p(\Omega)$ for each multi-index $\alpha$ with $|\alpha| \leq k$. In particular, these are functions $v_\alpha$ such that $D^\alpha u_n$ converges to $v_\alpha$ in the $L^p$ norm for each $\alpha$. Thus it suffices to prove that if $v = \lim u_n$, then $D^\alpha v = v_\alpha$ for each $\alpha$. But this follows because the H\"{o}lder inequality implies that for each fixed $\phi \in C_c^\infty(\Omega)$,
  %
  \begin{align*}
    (-1)^{|\alpha|} \int \phi_\alpha(x) v(x)\; dx &= \lim_{n \to \infty} (-1)^{|\alpha|} \phi_\alpha u_n(x)\; dx\\
    &= \lim_{n \to \infty} \int \phi(x) (D^\alpha u_n)(x)\; dx\\
    &= \int \phi(x) v_\alpha(x)\; dx.
  \end{align*}
  %
  Thus $W^{k,p}(\Omega)$ is complete.
\end{proof}

\section{Smoothing}

It is often useful to be able to approximate elements of $W^{k,p}(\Omega)$ by elements of $C^\infty(\Omega)$. This is mostly possible. If $u \in W^{k,p}(\Omega)$, and $\{ \eta_\varepsilon \}$ is a family of smooth mollifiers, then, viewing $u$ as a function on $\RR^n$ supported on $\Omega$, we can consider the convolution $u^\varepsilon = u * \eta_\varepsilon$, i.e. the function defined by setting
%
\[ u^\varepsilon(x) = \int_\Omega u(x - y) \eta_\varepsilon(y)\; dy. \]
%
This is just normal convolution, where we identify the function $u$ with the function $u \mathbf{I}_\Omega$ on $\RR^d$. Then $u^\varepsilon$ is a smooth function on $\RR^d$ supported on a $\varepsilon$ thickening of $\Omega$. However, $u^\varepsilon$ does not necessarily converge to $u$ in $W^{k,p}(\Omega)$ as $\varepsilon \to 0$, since the behaviour of the convolution can cause issues at the boundary of $\Omega$, where the distributional derivative $D^\alpha(u \mathbf{I}_\Omega)$ does not behave like a locally integrable function. This is the only problem, however.

\begin{theorem}
  If $U \Subset \Omega$, then $\lim_{\varepsilon \to 0} \| u^\varepsilon - u \|_{L^p(U)} = 0$.
\end{theorem}
\begin{proof}
  For each $\varepsilon > 0$, let $U^\varepsilon = \{ x \in \Omega: d(x,\partial \Omega) > \varepsilon \}$. If $x \in \Omega^\varepsilon$, then
  %
  \[ ((D^\alpha u) * \eta_\varepsilon)(x) = (u_\alpha \mathbf{I}_\Omega * \eta_\varepsilon)(x), \]
  %
  since the convolution only depends on the behaviour of $D^\alpha u$ on a $\varepsilon$ ball around $x$, which is contained in the interior of $\Omega$. We can apply standard results about mollifiers to conclude that $u_\alpha \mathbf{I}_\Omega * \eta_\varepsilon$ converges to $u_\alpha \mathbf{I}_\Omega$ in $L^p(\RR^d)$ as $\varepsilon \to 0$. Since $U \Subset \Omega$, we have $U \subset U^\varepsilon$ for small enough $\varepsilon$, and so $(D^\alpha u) * \eta_\varepsilon$ converges to $u_\alpha$ in $L^p(U)$ as $\varepsilon \to 0$. Since this is true for each $\alpha$ with $|\alpha| \leq k$, we obtain the result.
\end{proof}

If we are a little more careful, then we can fully approximate elements of $W^{k,p}(\Omega)$ by smooth functions on $U$.

\begin{theorem}
  $C^\infty_c(\Omega) \cap W^{k,p}(\Omega)$ is dense in $W^{k,p}(\Omega)$.
\end{theorem}
\begin{proof}
  Consider a family of open sets $\{ V_n \}$ such that $V_n \Subset \Omega$ for each $n$, and $U = \bigcup V_n$. Then we can consider a smooth partition of unity $\{ \xi_n \}$ subordinate to the cover $\{ V_n \}$. For each $u \in W^{k,p}(\Omega)$, we can write $u = \sum_n u \xi_n$. In particular, this means that for each $\varepsilon > 0$, there is $N$ such that $\| \sum_{n = N+1}^\infty u \xi_n \|_{W^{k,p}(\Omega)} \leq \varepsilon$. For each $n \in \{ 1, \dots, N \}$, we can find $\delta_n$ small enough that the $\delta_n$ thickening of $V_n$ is compactly contained in $\Omega$. If $\varepsilon_n$ is small enough, we find $(u \xi_n)^{\varepsilon_n}$ is supported on the $\delta_n$ thickening of $V_n$, and $\| (u \xi_n)^{\varepsilon_n} - u \xi_n \|_{W^{k,p}(V_n)} \leq \varepsilon / N$. But we then find
  %
  \begin{align*}
    \| u - \sum_{n = 1}^N (u \xi_n)^{\varepsilon_n} \|_{W^{k,p}(\Omega)} \leq \varepsilon + \sum_{n = 1}^N \| u \xi_n - (u \xi_n)^{\varepsilon_n} \|_{W^{k,p}(\Omega)} \leq 2\varepsilon.
  \end{align*}
  %
  Thus $C_c^\infty(\Omega)$ is dense in $W^{k,p}(\Omega)$.
\end{proof}

Approximation by elements of $C^\infty(\overline{\Omega})$ requires some more care, and additional assumptions on the behaviour of $\partial \Omega$.













\chapter{Time Frequency Analysis}

In harmonic analysis, it is often useful to study a function $f: \RR^d \to \CC$ via it's Fourier transform $\widehat{f}: \RR^d \to \CC$. The goal of time-frequency analysis is to think of such a function as being a function living simultaneously in both spaces, i.e. a function on the domain $\RR^d \times \RR^d$, which can be either written in temporal coordinates, or frequential coordinates, and in certain special cases, a combination of the two. We call this space the \emph{phase plane}, combining both time and frequency information together. There are several difficulties with rigorously incorporating this approach, for instance, resulting from the uncertainty principle, but the utility makes this . Given a function $f$, we define a \emph{phase portrait} for $f$ to be a subset of $\RR^d \times \RR^d$ where the majority of the `mass' of $f$ and $\widehat{f}$ are concentrated (for an arbitrary locally compact abelian group $G$, phase space is $G^* \times G$). Let us consider a simple example.

\begin{example}
  Consider the Gaussian $f(t) = e^{- \pi t^2}$. Then $70\%$ of the mass of $f$ is concentrated on $[-1,1]$, and the mass decays exponentially away from this interval. Thus the function $f$ is concentrated in $[-1,1]$. We have $\widehat{f_\delta}(\omega) = e^{- \pi \omega^2}$, which similarily, is concentrated in $[-1,1]$. A natural choice of the phase portrait of $f$ is therefore $[-1,1] \times [-1,1]$.
\end{example}

\begin{example}
  The Fourier transform of the Dirac delta function $\delta$ at a point $x$ is the plane wave $\xi \mapsto e^{- 2 \pi i \xi \cdot x}$. Thus a natural phase portrait for the Dirac delta function is $\{ x \} \times \RR^d$. Similarily, the phase portrait of a pure plane wave $x \mapsto e^{2 \pi i \xi \cdot x}$ is $\RR^d \times \{ \xi \}$, since the Fourier transform is the Dirac delta function at $\xi$.
\end{example}

The symmetries of the Fourier transform have natural effects on the phase portrait of a function $f$, which has phase portrait $S$.

\begin{itemize}
  \item The phase portrait of $\text{Trans}_x f$ is obtained by translating $S$ horizontally by $x$ units, since on the Fourier side the translation acts as a modulation, and does not move mass. Similarily, the phase portrait of the modulation $\text{Mod}_\xi f$ is obtained by translating $S$ vertically by $\xi$ units, since modulation does not affect the position of mass on the spatial side of things.

  \item Scaling in physical space has a `dual' effect in phase space. More precisely, $\text{Dil}_\delta f$ has phase portrait
  %
  \[ \{ (x,\xi) \in \RR^d \times \RR^d: (x/\lambda, \lambda \xi) \in S \} \]
  %
  More generally, given a linear transformation $T$, the phase portrait of $f \circ T^{-1}$ is equal to
  %
  \[ \{ (x,\xi) \in \RR^d \times \RR^d: (T(x), T^{-t}(\xi)) \in S \}. \]
  %
  The rescaling above is a special case. In particular, if $T \in O(d)$, then $f \circ T^{-1}$ has phase portrait
  %
  \[ \{ (x,\xi) \in \RR^d \times \RR^d: (T(x), T(\xi)) \in S \}. \]

  \item The phase portrait of $\widehat{f}$ is equal to
  %
  \[ \{ (x,\xi) \in \RR^d \times \RR^d: (\xi,-x) \in S \}, \]
  %
  i.e. a clockwise rotation by ninety degrees.
\end{itemize}

Notice that all the transformations above preserve area, which is where symplectic geometry enters the picture.

We note that the phase portrait of a rescaled, translated, and modulated Gaussian has phase portrait consisting of an axis-oriented rectangle with sidelengths $\delta x$ and $\delta \xi$, where $\delta x \cdot \delta \xi \sim 1$. Such a rectangle in phase space is called a \emph{Heisenberg tile}, and functions whose phase portraits consist of Heisenberg tiles are called \emph{wave packets}. In light of the uncertainty principle, these functions are the best alternatives to a function which is compactly supported in a sidelength one interval, and whose Fourier transform is also supported in a sidelength one interval.

\section{Localization in Time and Space}

Physical space localization is easy, we just multiply by a function, either a rough cutoff, or a smooth cutoff. Frequency localization is only slightly harder, where we can apply a basic Fourier multiplier. To localize in both time and frequency, one approach is to first smoothly localize in space, then time, or vice versa. This works out fine, as long as we do not localize too finely in both time and space, i.e. breaking the uncertainty principle. Here is a characteristic result in this setting

\begin{lemma}
  Fix two cubes $I$ and $J$, and two smooth functions $\psi_I$ and $\psi_J$ adapted to $I$ and $J$, and consider the localization operator $\pi_{I \times J} = \psi_I(D) \circ \psi_J(X)$. Then $\pi_{I \times J} f$ has Fourier support in $I$, and is localized in $J$ in the sense that for $|x| \geq $
  %
  \[ (\pi_{I \times J} f)(x) \lesssim_n |I|^{1-n} |J|^{1/2} \| f \|_{L^2(\RR^d)} d(x,J)^{-n} \]
\end{lemma}
\begin{proof}
  If we let $K_I$ be the inverse Fourier transform of $\psi_I$, then for all $n > 0$,
  %
  \[ |K_I(x)| \lesssim_n |I|^{1-n} |x|^{-n}. \]
  %
  The proof then follows from Cauchy-Schwartz applied to the representation $\pi_{I \times J} f = K_I * (\psi_J \cdot f)$.
  %
  \[ (\int |K_I(x-y)|^2 |\psi_J(y)|^2)^{1/2} \| f \|_{L^2(\RR^d)} \]
  % d(x,J)^{-n}
\end{proof}














\chapter{Riemann Theory of Trigonometric Series}

Using the techniques of measure theory, we can actually prove that the Fourier series is essentially the unique way of representing a function on any part of its domain as a trigonometric series.

\begin{lemma}
  For any sequence $u_n$ and set $E$ of finite measure,
  %
  \[ \lim_{n \to \infty} \int_E \cos^2(nx + u_n)\; dx = |E|/2 \]
\end{lemma}
\begin{proof}
  We have
  %
  \[ \cos^2(nx + u_n) = \frac{1 + \cos(2nx + 2u_n)}{2} = \frac{1}{2} + \frac{\cos(2nx) \cos(2u_n) - \sin(2nx) \sin(2u_n)}{2} \]
  %
  Since $\cos(2u_n)$ and $\sin(2u_n)$ are bounded, we have $\int \chi_E(x) \cos(2nx)$ and $\int \chi_E(x) \sin(2nx) \to 0$ as $n \to \infty$, and the same is true for the latter component of the sum since $\cos(2u_n)$ and $\sin(2u_n)$ are bounded, we conclude that
  %
  \[ \int_E \cos^2(nx + u_n) = \int \chi_E(x) \cos^2(nx + u_n) = |E|/2 \]
  %
  completing the proof.
\end{proof}

\begin{theorem}[Cantor-Lebesgue Theorem]
  If, for some pair of sequences $a_0, a_1, \dots$ and $b_0, b_1, \dots$ are chosen such that
  %
  \[ \sum_{n = 0}^\infty a_n \cos(2 \pi nx) + b_n \sin(2 \pi nx) \]
  %
  converges on a set of positive measure in $[0,1]$, then $a_n, b_n \to 0$.
\end{theorem}
\begin{proof}
  Let $E$ be the set of points upon which the trigonometric series converges. We write $a_n \cos(2 \pi n x) + b_n \sin(2 \pi n x) = r_n \cos(nx + c_n)$. The result of the theorem is then precisely that $r_n \to 0$. If this is not true, then we must have $\cos(nx + c_n) \to 0$ for every $x \in E$. In particular, the dominated convergence theorem implies that
  %
  \[ \lim_{n \to \infty} \int_E \cos(nx + c_n)^2\; dx = 0 \]
  %
  Yet we know this tends to $|E|/2$ as $n \to \infty$, which is a contradiction.
\end{proof}

TODO: EXPAND ON THIS FACT.






\section{Convergence in $L^p$ and the Hilbert Transform}

We now move onto a more 20th century viewpoint on Fourier series, namely, those to do with operator theory. Under this viewpoint, the properties of convergence are captured under the boundedness of certain operators on function spaces, allowing us to use the modern theory of functional analysis to it's full extent on our problems. However, unlike in most of basic functional analysis, where we assume all operators we encounter are bounded to begin with, in harmonic analysis we more often than not are given an operator defined only on a subset of spaces, and must prove the continuity of such an operator to show it is well defined on all of space. We will illustrate this concept through the theory of the circular Hilbert transform, and its relation to the norm convergence of Fourier series.

A \emph{Fourier multiplier} is a linear transform $T$ associated with a given sequence of scalars $\lambda_n$, for $n \in \ZZ$. It is defined for any trigonometric polynomial $f = \sum_{|n| \leq N} c_n e_n$ as $Tf = \sum_{|n| \leq N} \lambda_n c_n e_n$. The trigonometric polynomials are dense in $L^p(\mathbf{T})$, for each $p < \infty$. An important problem is determining whether $T$ is therefore figuring out whether the operator can be extended to a {\it continuous operator} on the entirety of $L^p$. Because the trigonometric polynomials are dense in $L^p$, in the light of the Hahn Banach theorem it suffices to prove an inequality of the form $\| Tf \| \lesssim \| f \|$. Here are some examples of Fourier operators we have already seen.

\begin{example}
    The truncation operator $S_N$ is the transform associated with the scalars $\lambda_n = [|n| \leq N]$. The truncation is continuous, since for any integrable function $f$, the Fourier coefficients are uniformly bounded by $\| f \|_1$, so $\| S_N f \|_1 \leq N \| f \|_1$. Similarily, the F\'{e}jer truncation $\sigma_N$ associated to the multipliers $\lambda_N = [|n| \leq N](1 - |n|/N)$ is continuous on all integrable functions. These operators are easy to extend precisely because the nonzero multipliers have finite support.
\end{example}

\begin{example}
    In the case of the Abel sum, $A_r$, associated with $\lambda_n = r^{|n|}$, $A_r$ extends in a continuous way to all integrable functions, since
    %
    \[ |A_r f| = \left| \sum r^{|n|} \widehat{f}(n) e_n(t) \right| \leq \| f \|_1 \sum r^{|n|} = \| f \|_1 \left( 1 + \frac{2}{1 - r} \right) \]
    %
    Thus the map is bounded.
\end{example}

To understand whether the truncations $S_N f$ of $f$ converge to $f$ in the $L^p$ norms, rather than pointwise, we turn to the analysis of an operator which is the core of the divergence issue, known as the \emph{Hilbert transform}. It is a Fourier multiplier operator $H$ associated with the coeficients
%
\[ \lambda_n = \frac{\text{sgn}(n)}{i} = \begin{cases} +1/i & n > 0 \\ 0 & n = 0 \\ -1/i & n < 0 \end{cases} \]
%
Because
%
\[ [|n| \leq N] = \frac{\text{sgn}(n + N) - \text{sgn}(n-N)}{2} + \frac{[n = N] + [n = -N]}{2} \]
%
we conclude
%
\[ S_n f = \frac{i \left( e_{-n} H(e_n f) - e_n H(e_{-n} f) \right)}{2} + \frac{\widehat{f}(n) e_n + \widehat{f}(-n) e_{-n}}{2} \]
%
Since the operators $f \mapsto \widehat{f}(n) e_n$ are bounded in all the $L^p$ spaces since they are continuous in $L^1(\mathbf{T})$, we conclude that the operators $S_n$ are uniformly bounded as endomorphisms on $L^p(\mathbf{T})$ provided that $H$ is bounded as an operator from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$. Since $S_n f$ converges to $f$ in $L^p$ whenever $f$ is a trigonometric polynomial, this would establish that $S_n f$ converges to $f$ in the $L^p$ norm for any function $f$ in $L^p(\mathbf{T})$. Later on, as a special case of the Hilbert transform on the real line, we will be able to prove that $H$ is a bounded operator on $L^p(\mathbf{T})$ for all $1 < p < \infty$, and as a result, we find that $S_N f \to f$ in $L^p$ for all such $p$. Unfortunately, $H$ is not bounded from $L^1(\mathbf{T})$ to itself, and correspondingly, $S_N f$ does not necessarily converge to $f$ in the $L^1$ norm for all integrable $f$.

For now, we explore some more ideas in how we can analyze the Hilbert transform via convolution, the dual of Fourier multipliers. The fact that $\smash{\widehat{f * g} = \widehat{f} \widehat{g}}$ implies that if their is an integrable function $g$ whose Fourier coefficients corresponds to the multipliers of an operator $T$, then $f * g = Tf$ for any trigonometric polynomial $f$, and by the continuity of convolution, this is the unique extension of the Fourier multiplier operator. In the theory of distributions, one generalizes the family of objects one can take the Fourier series from integrable functions to a more general family of objects, such that every sequence of Fourier coefficients is the Fourier series of some {\it distribution}. One can take the convolution of any such distribution $\Lambda$ with a $C^\infty$ function $f$, and so one finds that $\Lambda * f = Tf$ for any trigonometric polynomial $f$. There is a theorem saying that {\it all} continuous translation invariant operators from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$ are given by convolution with a Fourier multiplier operator. In practice, we just compute the convolution kernel which defines the Fourier multiplier, but it is certainly a satisfying reason to justify the study of Fourier multipliers. For instance, a natural question is to ask which Fourier multipliers result in bounded operations in space.

\begin{theorem}
    A Fourier multiplier is bounded from $L^2(\mathbf{T})$ to itself if and only if the coefficients are bounded.
\end{theorem}
\begin{proof}
    If a Fourier multiplier is given by $\lambda_n$, then for some trigonometric polynomial $f$,
    %
    \[ \| Tf \|_2^2 = \sum \left|\widehat{Tf}(n) \right|^2 = \sum |\lambda_n|^2 \left| \widehat{f}(n) \right|^2 \]
    %
    If the $\lambda_n$ are bounded, then we can obtain from this formula the bound
    %
    \[ \| Tf \|_2^2 \leq \max |\lambda_n| \| f \|_2^2 \]
    %
    Conversely, if $Tf$ is bounded, then
    %
    \[ |\lambda_n^2| = \| T(e_n) \|_2^2 \leq \| T \|^2 \]
    %
    so the $\lambda_n$ are bounded.
\end{proof}

\begin{corollary}
    The Hilbert transform is a bounded endomorphism on $L^2(\mathbf{T})$. Note that we already know that $S_N f \to f$ in the $L^2$ norm.
\end{corollary}

The terms of the Hilbert transform cannot be considered the Fourier coefficients of any integrable function. Indeed, they don't vanish as $n \to \infty$. Nonetheless, we can use Abel summation to treat the Hilbert transform as convolution with an appropriate operator. For $0 < r < 1$, consider, for $z = e^{it}$,
%
\[ K_r(z) = \sum_{n \in \ZZ} \frac{\text{sgn}(n)}{i} r^{|n|} z^n = K * P_r \]
%
Since we know the Hilbert transform is continuous in $L^2(\mathbf{T})$, we can conclude that, in particular, for any $C^\infty$ function $f$,
%
\[ H f = \lim_{r \to 1} K * (P_r * f) = \lim_{r \to 1} (K * P_r) * f = \lim_{r \to 1} K_r * f \]
%
So it suffices to determine the limit of the $K_r$. We find that
%
\begin{align*}
    \sum_{n = 1}^\infty \frac{(rz)^n - (r \overline{z})^n}{i} &= \frac{r}{i} \left( \frac{1}{\overline{z} - r} - \frac{1}{z - r} \right) = \frac{r}{i} \frac{z - \overline{z}}{|z|^2 - 2r \text{Re}(z) + r^2}\\
    &= \frac{2r \sin(t)}{1 - 2r \cos(t) + r^2} = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r \sin^2(t/2)}\\
    &= \cot(t/2) + O \left( \frac{(1 - r)^2}{t^3} \right)
\end{align*}
%
Thus $K_r(t)$ tends to $\cot(t/2)$ locally uniformly away from the origin. But
%
\[ K_r(t) = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r\sin^2(t/2)} = O \left( \frac{t}{(1 - r)^2} \right) \]
%
If $f$ is any $C^\infty$ function on $\mathbf{T}$, then
%
\[ \left| \int_{|t| \geq \varepsilon} [K_r(t) - \cot(t/2)] f(t) \right| \lesssim (1 - r)^2 \| f \|_\infty \int_{|t| \geq \varepsilon} \frac{dt}{|t|^3} \lesssim \frac{(1 - r)^2 \| f \|_\infty}{\varepsilon^2} \]
%
\begin{align*}
    \left| \int_{|t| < \varepsilon} K_r(t) f(t)\; dt \right| &\leq \int_0^\varepsilon |K_r(t)||f(t) - f(-t)|\\
    &\lesssim \int_0^\varepsilon |tK_r(t)||f'(0)| \lesssim \frac{|f'(0)|}{(1 - r)^2} \int_0^\varepsilon t^2 \lesssim \| f' \|_\infty \frac{\varepsilon^3}{(1 - r)^2}
\end{align*}
%
\[ \left| \int_{|t| < \varepsilon} \cot(t/2) f(t)\; dt \right| \lesssim \int_0^\varepsilon \frac{|f(t) - f(-t)|}{t} \lesssim \varepsilon f'(0) \]
%
Thus
%
\[ \left| \int K_r(t) f(t)\; dt - \int \cot(t/2) f(t)\; dt \right| \lesssim \frac{(1 - r)^2}{\varepsilon^2} \| f \|_\infty + \left( \frac{\varepsilon^3}{(1 - r)^2} + \varepsilon \right) \| f' \|_\infty \]
%
Choosing $\varepsilon = (1 - r)^\alpha$ for some $2/3 < \alpha < 1$ shows that for sufficiently smooth $f$,
%
\[ (Hf)(x) = \lim_{r \to 1} \int \cot(t/2) f(x - t)\; dt \]


\section{A Divergent Fourier Series}

Analysis was built to analyze continuous functions, so we would hope the method of fourier expansion would work for all continuous functions. Unfortunately, this is not so. The behaviour of the Dirichlet kernel away from the origin already tells us that the convergence of Fourier series is subtle. We shall take advantage of this to construct a continuous function with divergent fourier series at a point.

To start with, we shall consider the series
%
\[ f(t) \sim \sum_{n \neq 0} \frac{e_n(t)}{n} \]
%
where $f$ is an odd function equaling $i(\pi - t)$ for $t \in (0,\pi]$. Such a function is nice to use, because its Fourier representation is simple, yet very close to diverging. Indeed, if we break the series into the pair
%
\[ \sum_{n = 1}^\infty  \frac{e_n(t)}{n}\ \ \ \ \ \ \ \ \ \ \sum_{n = -\infty}^{-1} \frac{e_n(t)}{n} \]
%
Then these series no longer are the Fourier representations of a Riemann integrable function. For instance, if $g(t) \sim \sum_{n = 1}^\infty \frac{e_n(t)}{n}$, then the Abel means

$A_r(f)(t) = $

\section{Conjugate Fourier Series}

When $f$ is a real-valued integrable function, then $\overline{\widehat{f}(-n)} = \widehat{f}(n)$. Thus we formally calculate that
%
\[ \sum_{n = -\infty}^\infty \widehat{f}(n) e_n(t) = \text{Re} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) \]
%
This series defines an analytic function in the interior of the unit circle since the coefficients are bounded. Thus the sum is a harmonic function in the interior of the unit circle. The imaginary part of this sum is
%
\[ \text{Im} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) = \Re \left( -i \sum_{n = -\infty}^\infty \text{sgn}(n) \widehat{f}(n) e_n(t) \right) \]
%
The right hand side is known as the conjugate series to the Fourier series $\widehat{f}(n)$. It is closely related to the study of a function $\tilde{f}$ known as the {\it conjugate function}.







\chapter{Oscillatory Integrals}

The goal of the theory of oscillatory integrals is to obtain estimates of integrals with highly oscillatory integrands, where standard techniques such as taking in absollute values, or various spatial decomposition strategies, fail completely to give tight estimates. A typical oscillatory integral is of the form
%
\[ I(\lambda) = \int e^{\lambda i \phi(x)} \psi(x)\; dx, \]
%
where $\phi$ and $\psi$ are scalar valued functions, known as the \emph{phase} and \emph{amplitude} functions. The value $\lambda$ is a parameter measuring the degree of oscillation. As $\lambda$ increases, oscillation increases, which implies more cancellation should occur on average, hence we should expect $I(\lambda)$ to decay as $\lambda \to \infty$. One of the main problems in the study of oscillatory integrals is to measure the asymptotic decay more precisely.

\begin{example}
    The most basic example of an oscillatory integral is the Fourier transform, where for each function $f \in L^1(\RR)$, and each $\xi \in \RR$, we consider the quantity
    %
    \[ \widehat{f}(\xi) = \int_{-\infty}^\infty e^{- 2 \pi i \xi \cdot x} f(x)\; dx. \]
    %
    Thus $f$ plays the role of the amplitude, the phase function is $\phi(x) = x$, and $\xi$ takes the role of $\lambda$. The basic theory of the Fourier transform hints that oscillatory integrals decay as $\lambda \to \infty$ by exploiting the smoothness of $f$.
\end{example}

There are two main tools to estimate oscillatory integrals. The first, the method of steepest descent, uses complex analysis to shift the integral to a domain where less oscillation occurs, so that standard estimation strategies can be exmployed. However, this method seems to have limited applicability to oscillatory integrals over multivariable domains. The second method, known as the method of stationary phase, states that if $\phi$ is smooth, and $\nabla \phi$ has an isolated family of zeroes, then the oscillatory integral asymptotics can be localized to regions around the values $x_0$ with $\nabla \phi(x_0) = 0$, and each zero $x_0$ contributes $\psi(x_0) e^{i  \lambda \phi(x_0)}$, times the volume of the region around $x_0$ where $\phi$ deviates by $\approx 1/\lambda$, to the asymptotic value of $I(\lambda)$ as $\lambda \to \infty$.

\section{One Dimensional Theory}

Let us begin with a simple example of an oscillatory integral, i.e.
%
\[ I(\lambda) = \int_J e^{i \lambda \phi(x)}\; dx, \]
%
where $J$ is a closed interval, and $\phi: J \to \RR$ is Borel measurable. Taking in absolute values shows that $|I(\lambda)| \leq |J|$ for all $\lambda$. If $\phi$ is constant, then $I(\lambda) = |J| e^{i \lambda \phi}$, so in this case the estimate is sharp. But if $\phi$ varies, we expect $I(\lambda)$ to decay as $\lambda \to \infty$. For instance, the Esse\'{e}n concentration inequality shows that if we are to expect \emph{average} decay in the integral $I$ over a range of $\lambda$, then $\phi$ must not be concentrated around any point.

\begin{theorem}[Esse\'{e}n Concentration Inequality]
  Let $\phi: J \to \RR$ be Borel measurable, and for each $\lambda \in \RR$, set
  %
  \[ I(\lambda) = \int_J e^{i \lambda \phi(x)}\; dx. \]
  %
  Then for any $\varepsilon > 0$,
  %
  \[ \sup_{a \in \RR} |\{ x \in [0,1]: |\phi(x) - a| \leq \varepsilon \}| \lesssim \varepsilon \int_0^{1/\varepsilon} |I(\lambda)|\; d\lambda, \]
  %
  where the implicit constant is independant of $\phi$.
\end{theorem}
\begin{proof}
  By rescaling, we may assume that $J = [0,1]$. Moreover, for any choice of $a$, we may replace $\phi$ with $\phi - a$, reducing the analysis to the case where $a = 0$. Similarily, replacing $\phi$ with $\phi/\varepsilon$ reduces us to the situation where $\varepsilon = 1$. Thus we must show
  %
  \[ |\{ x \in [0,1]: |\phi(x)| \leq 1 \}| \lesssim \int_0^1 |I(\lambda)|\; d\lambda, \]
  %
  where the implicit constant is independant of the function $\phi$. If $\psi$ is an integrable function supported on $[0,1]$, then Fubini's theorem implies
  %
  \begin{align*}
    \int_0^1 \psi(\lambda) I(\lambda)\; d\lambda &= \int_0^1 \int_0^1 \psi(\lambda) e^{\lambda i \phi(x)}\; d\lambda\; dx\\
    &= \int_0^1 \widehat{\psi}(- \phi(x) / 2 \pi)\; dx.
  \end{align*}
  %
  In particular, this means that
  %
  \[ \left| \int_0^1 \widehat{\psi}(- \phi(x) / 2\pi)\; dx \right| \leq \| \psi \|_{L^\infty[0,1]} \int_0^1 |I(\lambda)|\; d\lambda. \]
  %
  If we choose a bounded function $\psi$ such that $\widehat{\psi}$ is non-negative, and bounded below on $[-2\pi,2\pi]$, then
  %
  \[ \left| \int_0^1 \widehat{\psi}(- \phi(x) / 2 \pi)\; dx \right| \gtrsim |\{ x \in [0,1]: |\phi(x)| \leq 1 \}|, \]
  %
  and so the claim follows easily.
\end{proof}

Thus if large cancellation happens in $I(\lambda)$ for the average $\lambda$, this automatically implies that $\phi$ cannot be concentrated around any particular point.  Conversely, we want to show that if $\phi$ varies significantly, then $I$ exhibits cancellation as $\lambda \to \infty$. The condition that $\phi'$ is bounded below is not sufficient to guarantee cancellation independant of the function $\phi$, as the next example shows, if the integrand oscillates at a wavelength $1/\lambda$.

\begin{example}
  Fix $\lambda_0 \in \ZZ$, and let $\phi(x) = 2 \pi x + f(\lambda_0 x) / \lambda_0$, where $f$ is smooth and 1-periodic, $\| f' \|_{L^\infty(\RR)} \leq \pi$, and
  %
  \[ \int_0^1 e^{2 \pi i x + i f(x)}\; dx \neq 0. \]
  %
  Then for each $x \in \RR$, $\pi \leq |\phi'(x)| \leq 3\pi$, and in particular, is bounded independently of $\lambda_0$. Since $\phi(x + 1/\lambda_0) = \phi(x) + 2 \pi / \lambda_0$, we find $e^{i \lambda_0 \phi(x)}$ is $1/\lambda_0$ periodic. In particular, this means
  %
  \[ I(\lambda_0) = \int_0^1 e^{\lambda_0 i \phi(x)} = \int_0^1 e^{2 \pi i x + i f(x)}\; dx. \]
  %
  which is comparable to 1, independantly of $\lambda_0$.
\end{example}

Controlling $\phi''$ in addition to $\phi'$, however, is sufficient.

\begin{theorem}
  Let $\phi: J \to \RR$ be smooth, and suppose there exists constants $A,B > 0$ with $|\phi'(x)| \geq A$ and $|\phi''(x)| \leq B$ for all $x \in J$. Then for all $\lambda > 0$, we find
  %
  \[ |I(\lambda)| \lesssim \frac{1}{\lambda} \left( \frac{1}{A} + \frac{B}{A^2} |J| \right). \]
\end{theorem}
\begin{proof}
  A dimensional analysis shows that the inequality is invariant under rescalings in $x$ and $\lambda$, so we may assume that $J = [0,1]$, and $\lambda = 1$. An integration by parts shows that
  %
  \begin{align*}
    \int_0^1 e^{i \phi(x)}\; dx &= \int_0^1 \frac{1}{i \phi'(x)} \frac{d}{dx} \left( e^{i \phi(x)} \right)\; dx\\
    &= \left( \frac{e^{i \phi(1)}}{i \phi'(1)} - \frac{e^{i \phi(0)}}{i \phi'(0)} \right) - \int_0^1 \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) e^{i \phi(x)}.
  \end{align*}
  %
  Now
  %
  \[ \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) = - \frac{\phi''(x)}{\phi'(x)^2}, \]
  %
  so taking in absolute values completes the proof.
\end{proof}

One can keep applying absolute values to obtain further bounds in terms of higher order derivatives of $\phi$. For instance, another integration by parts shows that if there is $A,B,C > 0$ such that for $x \in J$, if $\phi'(x) \geq A$, $\phi''(x) \leq B$, and $\phi'''(x) \leq C$, then
%
\[ |I(\lambda)| \lesssim \frac{1}{\lambda} \left( \frac{1}{A} \right) + \frac{1}{\lambda^2} \left( \frac{B}{A^3} + \frac{C}{A^3} |J| + \frac{B^2}{A^4} |J| \right). \]
%
One can keep taking in absolute values, but the $1/\lambda$ decay will still remain. This is to be expected, for instance, if $\phi(x) = x$ and $J = [0,1]$ then
%
\[ \limsup_{\lambda \to \infty} |I(\lambda) \cdot \lambda| = \limsup_{\lambda \to \infty} |\widehat{\mathbf{I}}_J(\lambda) \lambda| = 2, \]
%
so we cannot obtain any better decay than $1/\lambda$ here.

Another option is to not require control on the second derivative of the phase, but instead to assume that $\phi'$ is monotone, which prevents the kind of oscillation present in our counterexample.

\begin{lemma}[Van der Corput]
  Let $\phi: \RR \to \RR$ be a smooth phase such that $|\phi'(x)| \geq A$ for all $x \in J$, and $\phi'$ is monotone. Then for all $\lambda > 0$ we have
  %
  \[ |I(\lambda)| \lesssim \frac{1}{A \lambda}, \]
  %
  where the implicit constant is independent of $J$.
\end{lemma}
\begin{proof}
  The same integration by parts as before shows that if $J = [a,b]$,
  %
  \begin{align*}
    \int_J e^{\lambda i \phi(x)}\; dx &= \left( \frac{e^{i \phi(b)}}{\lambda i \phi'(b)} - \frac{e^{i \phi(a)}}{i \phi'(a)} \right) + \frac{1}{i\lambda} \int_J \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) e^{i \phi(x)}\; dx.
  \end{align*}
  %
  The two endpoints are $O(1/A \lambda)$. For the second sum, we perform a simple trick. Since $\phi'$ is monotone, so too is $1/\phi'$, so in particular, it's derivative has a constant sign. Thus by the fundamental theorem of calculus,
  %
  \begin{align*}
    \left| \int_J \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) e^{i \phi(x)}\; dx \right| &\leq \int_J \left| \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right)  \right|\; dx\\
    &= \left| \int_J \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) \right|\; dx\\
    &= \frac{1}{\phi'(b)} - \frac{1}{\phi'(a)}.
  \end{align*}
  %
  Combining these inequalities completes the proof.
\end{proof}

Since the Van der Corput bound does not depend on $|J|$, it can be easily iterated to give a theorem about higher derivatives of a function $\phi$.

\begin{lemma}
  Let $\phi: \RR \to \RR$ be smooth, and suppose there is some $k \geq 2$ such that $|\phi^{(k)}(x)| \geq A$ for all $x \in J$. Then for all $\lambda > 0$, we find
  %
  \[ |I(\lambda)| \lesssim_k \frac{1}{(A \lambda)^{1/k}}, \]
  %
  where the implicit constant is independant of $J$.
\end{lemma}
\begin{proof}
  We perform an induction on $k$, the case $k = 1$ already proven. By scale invariance, we may assume $\lambda = 1$. Now $\phi^{(k-1)}$ is monotone, so for each $\alpha > 0$, outside an interval of length at most $O(\alpha/A)$, $|\phi^{(k-1)}(x)| \geq \alpha$. Thus applying the trivial bound in the excess region, and the case $k - 1$ on the other intervals, we conclude
  %
  \[ |I(\lambda)| \lesssim_k \frac{\alpha}{A} + \alpha^{-1/(k-1)} \]
  %
  Optimizing over $\alpha$, we find $|I(\lambda)| \lesssim_k A^{-1/k}$.
\end{proof}

\begin{remark}
  The Berry-Esseen theorem says that the decay of $\lambda^{-1/k}$ is tight. We cannot have $I(\lambda) \lesssim \lambda^{-\alpha}$ for any $\alpha > 1/k$.
\end{remark}

Let us now consider a one dimensional oscillatory integral with a varying amplitude $\psi$, i.e.
%
\[ I(\lambda) = \int_{-\infty}^\infty e^{i \lambda \phi(x)} \psi(x)\; dx. \]
%
The Van der Corput lemma also applies here.

\begin{lemma}
  Fix $k \geq 1$. Suppose $\psi$ is supported on $[a,b]$, and suppose $|\phi^{(k)}(x)| \geq A$ for all $x \in [a,b]$, with $\phi'$ monotone if $k = 1$. Then
  %
  \[ |I(\lambda)| \lesssim_k \frac{\| \psi \|_{L^\infty(\RR)} + \| \psi' \|_{L^1(\RR)}}{(A \lambda)^{1/k}}. \]
\end{lemma}
\begin{proof}
  Fix $c_0 \in [a,b]$, and define
  %
  \[ I_0(x) = \int_{c_0}^x e^{i \lambda \phi(t)}\; dt. \]
  %
  The standard Van-der Corput lemma implies that for all $x$,
  %
  \[ |I_0(x)| \lesssim_k \frac{1}{(A \lambda)^{1/k}}. \]
  %
  An integration by parts gives that for any $a < b$,
  %
  \begin{align*}
    \int_a^b \psi(x) e^{i \lambda \phi(x)}\; dx &= \int_a^b \psi(x) I_0'(x)\; dx\\
    &= [\psi(b) I_0(b) - \psi(a) I_0(a)] - \int_a^b \psi'(x) I_0(x)\; dx.
  \end{align*}
  %
  Now
  %
  \[ |\psi(b) I_0(b) - \psi(a) I_0(a)| \lesssim \frac{\| \psi \|_{L^\infty(\RR)}}{(A \lambda)^{1/k}} \]
  %
  and
  %
  \[ \left| \int_a^b \psi'(x) I_0(x)\; dx \right| \lesssim_k \frac{\| \psi' \|_{L^1(\RR)}}{(A \lambda)^{1/k}}. \]
  %
  Putting these two estimates together completes the proof.
\end{proof}

If $\psi$ is smooth and compactly supported, integration by parts is very successful because there are no boundary terms.

\begin{theorem}
    If $\phi$ and $\psi$ are smooth, with $\psi$ compactly supported, and $\phi'(x) \neq 0$ for all $x$ in the support of $\psi$, then for all $N > 0$,
    %
    \[ I(\lambda) \lesssim_N 1/\lambda^N, \]
    %
    where the implicit constants depend on the functions $\phi$ and $\psi$.
\end{theorem}
\begin{proof}
  A single integration by parts gives
  %
  \begin{align*} I(\lambda) &= \frac{1}{\lambda} \int \frac{\psi(x)}{i \phi'(x)} \frac{d}{dx} \left( e^{\lambda i \phi(x)} \right)\\
  &= - \frac{1}{i \lambda} \int \frac{d}{dx} \left( \frac{\psi(x)}{\phi'(x)} \right) e^{i \phi(x)}\\
  &= \frac{1}{i \lambda} \int \frac{\phi'(x) \psi'(x) - \psi(x) \phi''(x)}{\phi'(x)^2}.
  \end{align*}
  %
  Further integration by parts give, for each $N$, that
  %
  \[ I(\lambda) = \lambda^{-N} \int \frac{P(x)}{\phi'(x)^{2N}} e^{i \phi(x)}, \]
  %
  where $P(x)$ is a polynomial function in the derivatives of $\phi$ and $\psi$ up to order $N+1$, in particular, with the same support as $\psi$. Thus we can take in absolute values and integrate to conclude $|I(\lambda)| \lesssim_{\psi,N} \lambda^{-N}$.
\end{proof}

\begin{remark}
  We note that the implicit constants in the theorem for a particular $N$ can be upper bounded uniformly, given uniform upper bounds on the measure of the support of $\psi$, upper bounds on the derivatives of $\phi$ and $\psi$ of order up to $N+1$, and lower bounds on $\phi'$ over the support of $\psi$. In particular, the bound is uniform if $\phi$ is fixed, lower bounded on some compact set $E \subset \RR^d$, and $\phi$ lies in some set $X$ of functions compactly supported on $E$, which is bounded in the Frech\'{e}t space $C^\infty(\RR^d)$.
\end{remark}

Let us now move onto a `stationary phase', i.e. a phase $\phi$ whose derivative vanishes at a point. The simplest example of such a phase is the integral
%
\[ I(\lambda) = \int_{-\infty}^\infty e^{i \lambda x^2} \psi(x)\; dx. \]
%
Our heuristics tell us $I(\lambda)$ decays on the order of $\lambda^{-1/2}$, which agrees with the asymptotics we now find.

\begin{theorem}
  Let $\psi \in \mathcal{S}(\RR)$. Then for each $N \geq 0$,
  %
  \[ \int_{-\infty}^\infty \psi(x) e^{\lambda i x^2}\; dx = e^{i \pi / 4} \cdot \pi^{1/2} \cdot \sum_{n = 0}^N \frac{i^n \psi^{(2n)}(0)}{4^n \lambda^{n + 1/2}} + O_{N,\psi}(1/\lambda^{N + 3/2}). \]
\end{theorem}
\begin{comment}
\begin{proof}
  Rescaling, it suffices to prove the theorem when $\psi(x) = 1$ whenever $|x| < 1$. Let $\alpha(x)$ be a smooth function with $\alpha(x) = 1$ for $|x| \geq 1/2$, and with $\alpha(x) = 0$ for $|x| < 1/4$. Then for each $k \geq 1$, define
  %
  \[ \beta_k(x) = \alpha(2^k x) - \alpha(2^{k-1} x). \]
  %
  Then $\beta_k$ is supported on $1/2^{k+2} \leq |x| \leq 1/2^k$, and moreover, for each $x \in \RR$,
  %
  \[ \alpha(x) + \sum_{k = 1}^\infty \beta_k(x) = 1. \]
  %
  It is simple to see that
  %
  \begin{align*}
    \int_{-\infty}^\infty \psi(x) e^{\lambda i x^2}\; dx &= \int_{-\infty}^\infty \alpha(x) \psi(x) e^{\lambda i x^2}\; dx\\
    &\ \ \ \ + \sum_{k = 1}^\infty \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx.
  \end{align*}
  %
  Now $\alpha \psi$ is a compactly supported amplitude supported away from the origin, so for each $N$,
  %
  \[ \left| \int_{-\infty}^\infty \alpha(x) \psi(x) e^{\lambda i x^2}\; dx \right| \lesssim_{\alpha,\psi,N} \lambda^{-N}. \]
  %
  The same argument works for $\beta_1$, and so by rescaling, for each $k$ and $M$,
  %
  \begin{align*}
    \left| \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx \right| &\lesssim_{\alpha,\psi,M} 2^{(2M-1)k} \lambda^{-M}.
  \end{align*}
  %
  In particular, we may sum the inequality for small $k$, and with $M$ an appropriate multiple of $N$, to conclude
  %
  \[ \sum_{k = 1}^{\lg(\lambda^{1/2-\varepsilon})} \left| \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx \right| \lesssim_{\alpha,\psi,N,\varepsilon} \lambda^{-N}. \]
  %
  If we set
  %
  \[ \gamma(x) = \sum_{k = \lg(\lambda^{1/2-\varepsilon})}^\infty \beta_k(x), \]
  %
  then $\gamma(x) = 0$ for $|x| \geq 1/\lambda^{3/4}$, and $\gamma(x) = 1$ for $|x| \leq 1/4\lambda^{3/4}$. Rescaling, we have
  %
  \[ \int_{-\infty}^\infty \gamma(x) e^{\lambda i x^2} = \lambda^{-3/4} \int_{-\infty}^\infty \gamma(x \cdot \lambda^{3/4}) e^{ix^2 / \lambda^{1/2}}. \]
\end{proof}


IDEA: Sum up dyadically on intervals $|x| \sim 2^k \lambda^{-1/2}$, for $k = 1$ to $k = \lfloor \log( \lambda^{1/2} \varepsilon) - 2 \rfloor$, then hopefully the oscillatory integral with phase $x^2$ and amplitude $\psi(x) \sum_{k = \lfloor \lg(\lambda^{1/2} \varepsilon) - 2 \rfloor}^\infty \beta_k(x/\lambda^{1/2})$ decays arbitrarily fast in $\lambda$?


Then for each $n$, define $\beta_n(x) = \alpha(x/2^n) - \alpha(x/2^{n-1})$. Thus we have $\alpha(x) + \sum_{k = 1}^\infty \beta_k(x) = 1$ for all $x \in \RR$. Moreover, $\beta_k$ is supported on $[-2^n, -$

\end{comment}
\begin{proof}
  Applying the multiplication formula for the Fourier transform, noting that the distributional Fourier transform of $e^{i \lambda x^2}$ is
  %
  \[ e^{i \pi / 4} (\pi/\lambda)^{1/2} e^{-i \pi^2 \xi^2 / \lambda}, \]
  %
  we conclude that
  %
  \[ I(\lambda) = e^{i \pi / 4} (\pi/\lambda)^{1/2} \int_{-\infty}^\infty e^{-i \pi^2 \xi^2 / \lambda} \widehat{\psi}(\xi)\; d\xi. \]
  %
  Now for any $N$, we can write
  %
  \[ e^{-i \pi^2 \xi^2 / \lambda} = \sum_{n = 0}^N \frac{1}{n!} \left( \frac{-i \pi^2 \xi^2}{\lambda} \right)^n + O_N \left( (\xi^2 / \lambda)^{N+1} \right). \]
  %
  Thus substituting in the Taylor series, and then applying the Fourier inversion formula, we find
  %
  \begin{align*}
    I(\lambda) &= e^{i \pi / 4} (\pi/\lambda)^{1/2} \sum_{n = 0}^N \frac{1}{n!} \int_{-\infty}^\infty \left( \frac{-i \pi^2 \xi^2}{\lambda} \right)^n \widehat{\psi}(\xi)\; d\xi + O_{\psi,N} \left( 1/\lambda^{N+3/2}  \right)\\
    &= e^{i \pi / 4} (\pi/\lambda)^{1/2} \sum_{n = 0}^N \frac{i^n}{4^n n!} \frac{1}{\lambda^n} \int_{-\infty}^\infty (2\pi i \xi)^{2n} \widehat{\psi}(\xi)\; d\xi + O_{\psi,N} \left( 1 / \lambda^{N+3/2} \right)\\
    &= e^{i \pi / 4} (\pi/\lambda)^{1/2} \sum_{n = 0}^N \frac{i^n \psi^{(2n)}(0)}{4^n n!} \frac{1}{\lambda^n} + O_{\psi,N} \left( 1 / \lambda^{N+3/2} \right). \qedhere
  \end{align*}
\end{proof}

\begin{remark}
  The implicit constant can be made independent of $\psi$ given uniform upper bounds on
  %
  \[ \int_{-\infty}^\infty |\widehat{\psi}(\xi)| |\xi|^{2(N+1)}\; d\xi. \]
  %
  In particular, this can be obtained by uniform upper bounds on the support of $\psi$, upper bounds on the magnitude of $\psi$, and upper bounds on the magnitude of the $(2N+4)$th derivative of $\psi$.
\end{remark}

It requires only a simple change of variables to extend this theorem to arbitrary quadratic phases. We say a critical point of a function is \emph{non-degenerate} if the second derivative at that point is nonzero.

\begin{theorem}
  Let $\phi$ be a smooth phase with finitely many non-degenerate critical points, and let $\psi$ be a smooth compactly supported amplitude function. Then there exists a sequence of constants $\{ a_n \}$, depending on the derivatives of $\phi$ and $\psi$ at the critical points, such that for each $N \geq 0$,
  %
  \[ I(\lambda) = \lambda^{-1/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_{\phi,\psi,N} ( 1/\lambda^{N+3/2} ). \]
  %
  In particular, if $\phi$ has a single critical point at some $x_0$, then
  %
  \[ a_0 = \sqrt{ \frac{2\pi}{-i \phi''(x_0)} } \cdot e^{\lambda i \phi(x_0)} \psi(x_0). \]
\end{theorem}
\begin{proof}
  By a partition of unity argument, it suffices to prove this theorem assuming that $\phi$ has only a single stationary point, which by translation we may assume to be at the origin, with $\phi(0) = 0$, and that $\phi(x)$ and $\phi'(x)$ are nonzero for all nonzero $x$ in the support of $\psi$. Moreover, rescaling enables us to assume $\phi''(0) = 2$. We can define a function
  %
  \[ y(x) = \text{sgn}(x) \cdot \phi(x)^{1/2}. \]
  %
  Then $y$ is a smooth function in the support of $\phi$. By the change of variables formula, there exists a smooth, compactly supported function $\psi_0(y)$ such that
  %
  \[ I(\lambda) = \int \psi(x) e^{\lambda i \phi(x)}\; dx = \int \psi_0(y) e^{\lambda i y^2}\; dy. \]
  %
  Thus we can apply the previous theorem to conclude that there exists a sequence of constants $\{ a_n \}$ such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-1/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_{\phi,\psi,N}(1/\lambda^{N+3/2}). \]
  %
  The existence in this theorem is a \emph{constructive} existence statement. The proof gives an effective algorithm to produce the constants $a_n$ for any particular phase $\phi$. In particular,
  %
  \[ a_0 = e^{i\pi/4} \pi^{1/2} \psi_0(0) = e^{i\pi/4} \pi^{1/2} \left( \frac{\psi(0)}{y'(0)} \right). \]
  %
  Since
  %
  \begin{align*}
    y'(0) &= \lim_{x \to 0} y'(x) = \lim_{x \to 0} \frac{\phi'(x)}{2 \text{sgn}(x) \phi(x)^{1/2}}\\
    &= \frac{1}{2} \lim_{x \to 0} \frac{\phi'(x)}{x} \left( \frac{x^2}{\phi(x)} \right)^{1/2} = \frac{\phi''(0)}{2 \phi''(0)^{1/2}} = \phi''(0)^{1/2}/2 = 2^{1/2}.
  \end{align*}
  %
  Thus $a_0 = 2^{1/2} e^{i\pi/4} \pi^{1/2} \psi(0)$.
\end{proof}

\begin{remark}
  If we incorporate $\lambda$ into the phase, considering the oscillatory integral
  %
  \[ \int e^{i \phi(x)} \psi(x)\; dx, \]
  %
  then if $\phi$ has a nondegenerate stationary point at $x_0$, the last theorem says that
  %
  \[ \int e^{i \phi(x)} \psi(x)\; dx \approx \left( \frac{2\pi}{-i \phi''(x_0)} \right)^{1/2} e^{i \phi(x_0)} \psi(x_0), \]
  %
  where this approximation gets better and better for larger and larger $\lambda$. Note this agrees with the heuristic given at the beginning of this chapter.
\end{remark}

If the phase $\phi$ has a critical point of order greater than two, than the asymptotics of the oscillatory integral get worse. In particular, if $\phi$ has a zero of order $k$, then around this region $\phi$ differs by $1/\lambda$ on an interval of length $1/\lambda^{1/k}$, so we might expect $I(\lambda)$ to be proportional to $\lambda^{1/k}$. This is precisely what happens, but our proof will not rely on the Fourier transform since the computation of the Fourier transform of $e^{\lambda ix^k}$ is quite difficult to calculate when $k > 2$. The next proof also works for the case $k = 2$, but the proof is different.

\begin{lemma}
  For any non-negative integers $l$ and $k$, there is a positive constant $A_{kl} > 0$ such that for any $\lambda \in \RR$ and $\varepsilon > 0$,
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-\varepsilon x^k} x^l\; dx = A_{kl} (\varepsilon - i \lambda)^{-(l+1)/k}, \]
  %
  where the $k$th root is the principal root for non-negative complex numbers.
\end{lemma}
\begin{proof}
  If $z = (\varepsilon - i \lambda)^{1/k} x$, and if $\alpha_N$ is the ray between the origin and the point $N (\varepsilon - i \lambda)^{1/k}$, then
  %
  \[ \int_0^N e^{\lambda i x^k} e^{- \varepsilon x^k} x^l\; dx = (\varepsilon - i \lambda)^{-(l+1)/k} \int_{\alpha_N} e^{-z^k} z^l\; dz. \]
  %
  Let $\theta \in (-\pi/2,0]$ be the argument of $(\varepsilon - i \lambda)^{1/k}$, and set $\beta_N$ to be the arc between $N ( \varepsilon - i \lambda)^{1/k}$ and $N (\varepsilon^2 + \lambda^2)^{1/2}$. Then $\beta_N$ has length $O(N)$, with implicit constant depending on $\lambda$ and $\varepsilon$. Moreover, any point $z$ on $\beta_N$ has modulus $N (\varepsilon^2 + \lambda^2)^{1/2}$ and argument less than or equal to $\theta / k$. But this implies that $\text{Re}(z^k) \geq N^k (\varepsilon^2 + \lambda^2)^{k/2} \cos(\theta)$, and so there exists a constant $c$ depending on $\varepsilon$ and $\lambda$ such that $|e^{-z^k}| \leq e^{c N^k}$. But this means that $|z^l e^{-z^k}| \leq N^l e^{-cN^k}$. Thus taking in absolute values gives that
  %
  \[ \lim_{N \to \infty} \int_{\beta_N} e^{-z^k} z^l\; dz = 0. \]
  %
  In particular, applying Cauchy's theorem, we conclude that
  %
  \[ \lim_{N \to \infty} \int_{\gamma_N} e^{-z^k} z^l\; dz = \int_0^\infty e^{-x^k} x^l\; dx. \]
  %
  If we denote the latter integral by $A_{kl} > 0$, then we have shown that
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-\varepsilon x^k} x^l\; dx = A_{kl} \cdot (\varepsilon - i \lambda)^{-(l+1)/k}, \]
  %
  as was required to be shown.
\end{proof}

\begin{remark}
  In particular, this implies that for each $\varepsilon$, there exists constants $A_{kln}$ such that
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-x^k} x^l\; dx = \lambda^{-(l+1)/k} \sum_{n = 0}^\infty A_{kln} \lambda^{-n}. \]
  %
  This is obtained by taking the Laurent series of
  %
  \[ (1 - i\lambda)^{-(l+1)/k} = \lambda^{-(l+1)/k} (\lambda^{-1} - i)^{-(l+1)/k}, \]
  %
  which converges absolutely for $\lambda > 1$. In particular, for each $N$ and for each $\lambda$, we conclude
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-x^k} x^l\; dx = \lambda^{-(l+1)/k} \sum_{n = 0}^N A_{kln} \lambda^{-n} + O_N \left(1/\lambda^{n + 1 + 1/k} \right). \]
\end{remark}

\begin{lemma}
  If $\eta$ is compactly supported and smooth, then
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx \right| \lesssim_{l,k,\eta} \lambda^{-(l + 1)/k}. \]
\end{lemma}
\begin{proof}
  Let $\alpha$ be a bump function supported on $[-2,2]$ with $\alpha(x) = 1$ for $|x| \leq 1$. For each $\varepsilon > 0$, write
  %
  \begin{align*}
    \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx &= \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) \alpha(x/\varepsilon)\; dx\\
    &\ \ \ \ + \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx,
  \end{align*}
  %
  where we will bound each term and optimize for a small $\varepsilon$. We trivially have
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) \alpha(x/\varepsilon)\; dx \right| \lesssim_\eta \varepsilon^{l+1}, \]
  %
  We apply an integration by parts to the second integral, noting that $e^{\lambda i x^k}$ is a fixed point of the differential operator
  %
  \[ Df = \frac{1}{\lambda i k x^{k-1}} \frac{df}{dx}. \]
  %
  If we consider the differential operator
  %
  \[ D^*g = \frac{d}{dx} \left( \frac{-f}{\lambda i k x^{k-1}} \right) = \left( \frac{i}{\lambda k} \right) \left( \frac{f'(x)}{x^{k-1}} - \frac{(k-1) f(x)}{x^k} \right), \]
  %
  then for any smooth $f$ and compactly supported $g$,
  %
  \[ \int_{-\infty}^\infty (Df)(x) g(x) = \int_{-\infty}^\infty f(x) (D^* g)(x). \]
  %
  In particular,
  %
  \begin{align*}
    \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx &= \int_{-\infty}^\infty D^N(e^{\lambda i x^k})\; x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx\\
    &= \int_{-\infty}^\infty e^{\lambda i x^k}\; (D^*)^N \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \}\; dx.
  \end{align*}
  %
  Write $g_N(x) = (D^*)^N \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \}$. Since $x^l \eta(x) (1 - \alpha(x/\varepsilon))$ vanishes for $|x| \leq \varepsilon$, so too does $g_N(x)$. For $N \geq l/(k-1)$, and $|x| \geq \varepsilon$, we have
  %
  \[ |g_N(x)| \lesssim_{N,\eta} \lambda^{-N} \varepsilon^{-N} |x|^{l - N(k-1)}, \]
  %
  where the implicit constant depends on upper bounds for the derivatives of $\eta$ of order to $N$. We can thus take in absolute values after integrating by parts to conclude that if $N > (l+1)/(k-1)$, then
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx \right| \lesssim_{N,\eta} \lambda^{-N} \varepsilon^{l + 1 - Nk} \]
  %
  Thus we can put the two bounds together to conclude that
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx \right| \lesssim_{N,\eta} \varepsilon^{l+1} + \lambda^{-N} \varepsilon^{l+1-Nk}. \]
  %
  Picking $\varepsilon = \lambda^{-1/k}$ gives
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx \right| \lesssim_{N,\psi} \lambda^{-(l+1)/k}. \qedhere \]
  %
  But $N$ was chosen depending only on $k$ and $l$, so the implicit constants depend on the correct variables.
%  \[ D^* \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \} = c x^{l-k} \eta(x) (1 - \alpha(x/\varepsilon)) + x^{l+1-k} \eta'(x) (1 - \alpha(x/\varepsilon) - \varepsilon^{-1} x^{l+1-k} \eta(x) \alpha'(x/\varepsilon) \]
%  \[ (D^*)^2 \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \} = x^{l-2k} (1 - \alpha(x/\varepsilon))
  %  (d/dx) \{ x^{l+1-2k} \eta(x) (1 - \alpha(x/\varepsilon)) + x^{l+2-2k} \eta'(x) (1 - \alpha(x/\varepsilon) - \varepsilon^{-1} x^{l+2-2k} \eta(x) \alpha'(x/\varepsilon) \} \]
\end{proof}

\begin{remark}
  The implicit constants can be bounded uniformly given uniform upper bounds on the magnitude of the derivatives of $\eta$ of order up to
  %
  \[ \lceil (l+1)/(k-1) \rceil, \]
  %
  and upper bounds on the measure of the support of $\eta$.
\end{remark}

We can now prove the asymptotics for the model case $\phi(x) = x^k$.

\begin{theorem}
  Suppose $\psi$ is a smooth compactly supported amplitude, and $\phi$ is a smooth phase with $\phi'(x) \neq 0$ on the support of $\psi$ except at some point $x_0$, where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, and $\phi^{(k)}(x_0) \neq 0$. Then there is a sequence $\{ a_n \}$ such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-n/k} + O_{\psi,k,N} \left( 1/\lambda^{(N+2)/k} \right). \]
\end{theorem}
\begin{proof}
  Let us begin with the model case $\phi(x) = x^k$. Let $\tilde{\psi}$ be a bump function with $\tilde{\psi}(x) = 1$ for all $x$ with $\psi(x) > 0$. Then
  %
  \[ I(\lambda) = \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} [e^{x^k} \psi(x)] \tilde{\psi}(x)\; dx. \]
  %
  For each $N$, perform a Taylor expansion, writing
  %
  \[ e^{x^k} \psi(x) = \sum_{n = 0}^N a_n x^n + x^{N+1} R_N(x). \]
  %
  Thus if $P_N(x) = \sum_{n = 0}^N a_n x^n$,
  %
  \begin{align*}
    \int_{-\infty}^\infty &e^{\lambda i x^k} e^{-x^k} [e^{x^k} \psi(x)] \tilde{\psi}(x)\; dx\\
    & = \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} P_N(x)\; dx\\
    & + \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} P_N(x) (\tilde{\psi}(x) - 1)\; dx\\
    & + \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} x^{N+1} R_N(x) \tilde{\psi}(x)\; dx.
  \end{align*}
  %
  The first integral can be expanded in the required power series. The second integral, since it is supported away from the origin, is $O_M(\lambda^{-M})$ for any $M > 0$. And in the last lemma we showed the third integral is $O(\lambda^{-(N+2)/k})$, so combining these three terms gives the required result. The general case follows from a change of variables.
\end{proof}

\begin{remark}
  As we saw in the case $k = 2$, if $k$ is even and $n$ is odd then
  %
  \[ \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} x^n = 0. \]
  %
  Thus we can actually improve the asymptotics to the existence of a sequence $\{ a_n \}$ such that
  %
  \[ I(\lambda) = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-2n/k} + O_{\phi,\psi,N} \left( 1 / \lambda^{(2N + 3)/k} \right). \]
\end{remark}

\begin{comment}

Changing variables then proves the result for general $k$'th order phases.

\begin{lemma}
  Let $\psi$ is a compactly supported and smooth amplitude, and $\phi'(x) \neq 0$ on the support of $\psi$, except at some point $x_0$ where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, with $\phi^{(k)}(x_0) \neq 0$, then there exists constants $\{ a_n \}$ depending on the derivatives of $\phi$ and $\psi$ at $x_0$, such that for each $N$,
  %
  \[ \int_{-\infty}^\infty e^{\lambda i \phi(x)} \psi(x)\; dx = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-n/k} + O_{\phi,\psi,N} \left( 1/\lambda^{(N+2)/k} \right). \]
\end{lemma}

\begin{lemma}
  Let $\psi$ is a compactly supported and smooth amplitude, and $\phi'(x) \neq 0$ on the support of $\psi$, except at some point $x_0$ where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, with $\phi^{(k)}(x_0) \neq 0$, then there exists constants $\{ a_n \}$ depending on the derivatives of $\phi$ and $\psi$ at $x_0$, such that for each $N$,
  %
  \[ \int_{-\infty}^\infty e^{\lambda i \phi(x)} \psi(x)\; dx = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-n/k} + O_{\phi,\psi,N} \left( 1/\lambda^{(N+2)/k} \right). \]
\end{lemma}
\begin{proof}
  Without loss of generality, we may rescale our integral so that $\phi^{(k)}(x_0) = k!$. Then we can write $\phi(x) = x^k + x^{k+1} R(x)$, where $R(x)$ is a smooth function. A Taylor series approach tells us that
  %
  \[ e^{\lambda i \phi(x)} = e^{\lambda i x^k} \left[ \sum_{n = 0}^M \frac{(\lambda i x^{k+1} R(x))^n}{n!} + Q(x) \right], \]
  %
  where
  %
  \[ Q(x) = \frac{(i\lambda)^{M+1}}{(M+1)!} x^{(k+1)(M+1)} R(x)^{M+1} \int_0^1 e^{\lambda i x^{k+1} R(x) s} (1 - s)^M\; ds \]
  %
  For each $n$, we let
  %
  \[ I_n(\lambda) = \frac{(\lambda i)^n}{n!} \int e^{\lambda i x^k} R(x)^n x^{n(k+1)} \psi(x)\; dx, \]
  %
  and let
  %
  \[ J(\lambda) = \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} R(x)^{M+1} e^{\lambda i x^{k+1} R(x) s} (1 - s)^M \psi(x)\; ds\; dx. \]
  %
  Then
  %
  \[ I(\lambda) = I_1(\lambda) + \dots + I_M(\lambda) + \frac{(i\lambda)^{M+1}}{(M+1)!} J(\lambda), \]
  %
  and so it suffices to obtain asymptotics on each term separately. From the previous argument, we know there are are constants $\{ a_{nm} \}$ such that for each $M$,
  %
  \[ I_n(\lambda) = \lambda^{-1/k} \sum_{m = 1}^M a_{nm} \lambda^{n-m/k} + O_{\psi,R,k,n} \left( 1/ \lambda^{(M+2)/k} \right). \]
  %
  Moreover, we can write
  %
  \[ I_n(\lambda) = \int e^{\lambda i x^k} x^{n(k+1)} \psi_n(x)\; dx, \]
  %
  where $\psi_n(x) = R(x)^n \psi(x)$ is smooth. But then we know
  %
  \[ |I_n(\lambda)| \lesssim_{n,k,\psi,R} 1/\lambda^{n + (n+1)/k}. \]
  %
  In particular, this means that $a_{nm} = 0$ for $m \leq (2k+1)n$. Thus we conclude $I_n(\lambda)$ can be expanded in positive powers of $\lambda^{1/k}$, up to an error $O(1/\lambda^{(M+2)/k})$. If we split the integrand for $J(\lambda)$ using a bump function into values $x$ with $|x| \leq \varepsilon$ and values $|x| \geq \varepsilon$, bound the former by bringing in absolute values, bound the latter using integration by parts, and then optimizing over $\varepsilon$ yields

  To complete the argument, we show that for sufficiently large $M$, we can treat $J$ as an error term. If we define
  %
  \[ \psi_M(x,s) = \psi(x) (1 - s)^M R(x)^{M+1}, \]
  %
  then
  %
  \[ J(\lambda) = \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s)\; dx\; ds. \]
  %
  We introduce a bump function $\alpha$ such that $\alpha(x) = 1$ for $|x| \leq 1$, and vanishes outside for $|x| \geq 2$. For $\varepsilon > 0$, we write
  %
  \begin{align*}
    J(\lambda) &= \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s) \alpha(x/\varepsilon)\; dx\\
    &\ \ \ + \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s) (1 - \alpha(x/\varepsilon))\; dx.
  \end{align*}
  %
  The first integral is $O_{\psi,R,M}(\varepsilon^{(k+1)(M+1)+1})$. For the second, we employ an integration by parts in $x$. The value $e^{\lambda i x^k}$ is a fixed point of the differential operator $Df = f' / \lambda i x^{k-1}$, whose adjoint is
  %
  \[ D^* g = \frac{d}{dx} \left( \frac{g}{\lambda i x^{k-1}} \right). \]
  %
  For each $L$, there exists constants $c_n$ such that
  %
  \[ (D^*)^L g = \frac{1}{\lambda^L} \sum_{n = 0}^L \frac{c_n g^{(n)}}{x^{Lk - n}}. \]
  %
  If we write
  %
  \[ g_n(\lambda,x,s) = \frac{1}{x^{Lk-n}} \frac{d^n}{dx^n} \left\{ x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi(x,s) (1 - \alpha(x/\varepsilon)) \right\}, \]
  %
  then our oscillatory integral is bounded by an implicit constant depending on $L$ and $k$, and
  %
  \[ \sum_{n = 0}^L \frac{1}{\lambda^L} \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} g_n(x)\; dx. \]
  %
  Now $g_n$ has compact support depending on $\psi$, and vanishes for $|x| \leq \varepsilon$. For $|x| \geq \varepsilon$, we find that
  % \lambda \lesssim_{k,\phi} 1/\varepsilon
  \[ |g_n(\lambda,x,s)| \lesssim_{L,M,k,\alpha,\psi,n} \sum_{m = 0}^n \lambda^m \varepsilon^{m-n} x^{n-Lk+(k+1)(M+1) + km}. \]
  %
  Thus we conclude that for sufficiently large $L$
  %
  \[ |J(\lambda)| \lesssim_{\psi,R,M,L,k,\alpha} \varepsilon^{(k+1)(M+1) + 1} \left( 1 + \varepsilon^{- Lk} \sum_{m = 0}^L \lambda^{m-L} \varepsilon^{(k+1)m} \right). \]
  %
  TODO.
\end{proof}

\end{comment}

Let us now consider some examples of the method of stationary phase in one dimension.

\begin{example}
  The Bessel function of order $m$, denoted $J_m(r)$, is defined to be the oscillatory integral
  %
  \[ J_m(r) = \frac{1}{2\pi} \int_0^{2\pi} e^{i r \sin(\theta)} e^{-i m \theta} d\theta. \]
  %
  We want to use the method of stationary phase to determine the decay of $J_m(r)$ as $r \to \infty$. The amplitude is $\psi(\theta) = (1/2\pi) e^{-im \theta}$, and the phase is $\phi(\theta) = \sin(\theta)$. We note that the phase $\phi(\theta) = \sin(\theta)$ is stationary when $\theta = \pi/2$ and $\theta = 3\pi/2$, and that these stationary points are nondegenerate. Thus we might expect $|J_m(r)| = O_m(r^{-1/2})$. More precisely, we write $1 = \psi_1 + \psi_2 + \psi_3$, where $\psi_1$ is supported in a small neighbourhood of $\pi/2$, $\psi_2$ in a neighbourhood of $3\pi/2$, and $\psi_3$ is supported away from $\pi/2$ and $3\pi/2$. This oscillatory integral is defined over an integral, but the integrand is periodic, so an integration by parts verifies that since $\psi_3$ is supported away from stationary points, for any $N > 0$,
  %
  \[ \frac{1}{2\pi} \int_0^{2\pi} e^{i r \sin(\theta)} e^{-i m \theta} \psi_3(\theta)\; d\theta = O_N(r^{-N}). \]
  %
  Next, we verify using our formula for the stationary phase that
  %
  \begin{align*}
    \frac{1}{2\pi} \int & e^{i r \sin(\theta)} e^{-i m \theta} \psi_1(\theta)\; d\theta\\
    &= \left( \frac{2\pi}{-i \phi''(\pi/2)} \right)^{1/2} \cdot (1/2\pi) e^{i r \sin(\pi/2)} e^{-i m (\pi/2)} \cdot r^{-1/2} + O_m(r^{-3/2})\\
    &= (2\pi)^{-1/2} e^{i(r - m\pi/2 - \pi/4)} r^{-1/2} + O_m(r^{-3/2}).
  \end{align*}
  %
  Similarily,
  %
  \begin{align*}
    \frac{1}{2\pi} \int & e^{i r \sin(\theta)} e^{-i m \theta} \psi_2(\theta)\; d\theta\\
    &= \left( \frac{2\pi}{-i \phi''(3\pi/2)} \right)^{1/2} \cdot (1/2\pi) e^{i r \sin(3\pi/2)} e^{-i m (3\pi/2)} \cdot r^{-1/2} + O_m(r^{-3/2})\\
    &= (2\pi)^{-1/2} e^{-i(r - m\pi/2 - \pi/4)} r^{-1/2} + O_m(r^{-3/2}).
  \end{align*}
  %
  Summing up the three estimates, we conclude
  %
  \[ J_m(r) = (2/\pi r)^{1/2} \cos(r - m\pi/2 - \pi/4) + O_m(r^{-3/2}). \]
\end{example}

\begin{example}
  Consider the Airy function
  %
  \[ \text{Ai}(x) = \int_{-\infty}^\infty e^{i(x \xi + \xi^3/3)}\; d\xi, \]
  %
  which arises as a solution to the differential equation $y'' = xy$. Again, this integral is not defined absolutely. Nonetheless, for a large $N$, an integration by parts shows that for any finite interval $I$ containing only points $x$ with $|x| \geq N$,
  %
  \[ \int_I e^{i(x \xi + \xi^3/3)}\; d\xi = O(1/N), \]
  %
  where the implicit constant is independant of $I$. Thus we can interpret the integral as
  %
  \[ \lim_{n \to \infty} \int_{a_n}^{b_n} e^{i(x \xi + \xi^3/3)}\; d\xi, \]
  %
  where $\{ a_n \}$ and $\{ b_n \}$ are any sequences with $a_n \to -\infty$, $b_n \to \infty$.

  Now consider the phase $\phi(\xi) = x \xi + \xi^3/3$. Then $\phi'(\xi) = x + \xi^2$. When $x$ is negative, there are two stationary points. Thus we can rescale the integral, writing $\nu = x^{-1/2} \xi$, so that
  %
  \[ \text{Ai}(-x) = x^{1/2} \int_{-\infty}^\infty e^{i x^{3/2}(\nu^3/3 - \nu)}\; d\nu. \]
  %
  If we write $\phi_0(\nu) = \nu^3/3 - \nu$, then $\phi_0$ has two stationary points, at $\nu = \pm 1$. These stationary points are non-degenerate, so if we write $1 = \psi_1 + \psi_2 + \psi_3 + \psi_4$, where $\psi_1$ equal to one in a neighbourhood of $1$, $\psi_2$ equal to one in a neighbourhood of $-1$, and $\psi_3$ is supported in the region between $-1$ and $1$, and $\psi_4$ vanishes in all such regions, then we decompose $\text{Ai}(-x)$ as $I_1 + I_2 + I_3 + I_4$. Now the principle of stationary phase tells us that
  %
  \[ I_1 = \pi^{1/2} x^{-1/4} e^{i \pi/4} e^{-2i x^{3/2}/3} + O(x^{-1}) \]
  %
  and
  %
  \[ I_2 = \pi^{1/2} x^{-1/4} e^{-i\pi/4} e^{2i x^{3/2}/3} + O(x^{-1}). \]
  %
  Moreover, $I_3 = O_N(x^{-N})$ for all $N \geq 0$. It remains to show $I_4 = O(x^{-1})$. Indeed, an integration by parts shows that
  %
  \begin{align*}
    I_4 &= x^{1/2} \int_{-\infty}^\infty e^{i x^{3/2} \phi_0(\nu)} \psi_4(\nu)\; d\nu\\
    &= \frac{i}{x} \int_{-\infty}^\infty e^{i x^{3/2} \phi_0(\nu)} \frac{d}{d\nu} \left( \frac{\psi_4(\nu)}{\nu^2 - 1} \right)\; d\nu.
  \end{align*}
  %
  Taking in absolute values shows $|I_4| \lesssim 1/x$. Thus as $x \to \infty$,
  %
  \[ \text{Ai}(-x) = 2 \pi^{1/2} x^{-1/4} \cos((2/3) x^{3/2} - \pi/4) + O(1/x), \]
  %
  which gives the first order asymptotics of the integral.

  On the other hand, let us consider large positive $x$. Then the phase $\phi$ has no critical points, and we therefore expect very fast decay. To achieve this decay, we employ a contour shift, replacing the oscillatory integral with a different oscillatory integral which \emph{has} a stationary point, so we can obtain asymptotics here. If we write $\phi(z) = xz + z^3/3$, then $\phi'(z) = 0$ when $z = \pm i x^{1/2}$. A simple contour shift argument to the line $\RR + i x^{1/2}$ gives
  %
  \begin{align*}
    \text{Ai}(x) &= \int_{-\infty}^\infty e^{i \phi(\xi + ix^{1/2})}\; d\xi\\
    &= e^{-(2/3)x^{3/2}} \int_{-\infty}^\infty e^{-\xi^2 x^{1/2}} e^{i \xi^3/3}\; d\xi.
  \end{align*}
  %
  We have
  %
  \[ \int_{-\infty}^\infty e^{-\xi^2 x^{1/2}} e^{i \xi^3/3}\; d\xi \approx x^{-1/4} \int_{-\infty}^\infty e^{-\xi^2} e^{i x^{-3/4} \xi^3/3}\; d\xi. \]
  %
  Now a Taylor series shows
  %
  \[ e^{i x^{-3/4} \xi^3/3} = 1 + O(x^{-3/4} \xi^3/3), \]
  %
  so, plugging in, we conclude
  %
  \[ \text{Ai}(x) = \pi^{1/2} x^{-1/4} e^{-(2/3) x^{3/2}} + O(x^{-3/4} e^{-(2/3) x^{3/2}}). \]
  %
  Thus Airy's function decreases exponentially as $x \to \infty$.
\end{example}

\begin{example}
  Let us consider the integral quantities
  %
  \[ \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx \]
  %
  where to avoid technicalities we assume $0 \leq \gamma < 2$. These integral quantities are not defined absolutely, so we actually interpret this integral as
  %
  \[ \lim_{\varepsilon \to 0} \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx \]
  %
  If we write $\phi(x) = x \xi + 1/x$, then
  %
  \[ \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx = \int_0^1 e^{i\phi(x)} x^{-\gamma}\; dx. \]
  %
  For $0 < \varepsilon_1 < \varepsilon_2 < \varepsilon$, since $\phi'(x) = \xi - 1/x^2$, an easy integration by parts shows that for $\varepsilon \leq \xi^{-1/2}/2$,
  %
  \begin{equation} \label{riemannsingularityibp}
  \begin{aligned}
    \int_{\varepsilon_1}^{\varepsilon_2} e^{i\phi(x)} x^{-\gamma}\; dx &= \frac{1}{i \xi} \int_{\varepsilon_1}^{\varepsilon_2} \frac{d}{dx} \left( e^{i \phi(x)} \right) \frac{x^{2-\gamma}}{x^2 - 1/\xi}\; dx\\
    &= \frac{-1}{i \xi} \int_{\varepsilon_1}^{\varepsilon_2} e^{i \phi(x)} \frac{d}{dx} \left( \frac{x^{2-\gamma}}{x^2 - 1/\xi} \right) + O(\varepsilon^{2-\gamma})\\
    &= O(\varepsilon^{2-\gamma}),
  \end{aligned}
  \end{equation}
  %
  where the constant is independent of $\xi$. This implies the limit we study certainly exist. We wish to prove an asymptotic formula for this integral as $\xi \to \infty$. If we write $\phi(x) = x \xi + 1/x$, then
  %
  \[ \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx = \int_0^1 e^{i \phi(x)} x^{-\gamma}. \]
  %
  Since $\phi$ has a nondegenerate stationary point when $x = \xi^{-1/2}$, our heuristics might suggest that if the phase and amplitude were smooth at the origin, then as $\gamma \to \infty$,
  %
  \begin{align*}
    \int_0^1 e^{i\phi(x)} x^{-\gamma} &\approx \left( \frac{2\pi}{-i \phi''(\xi^{-1/2})} \right)^{1/2} e^{i\phi(\xi^{-1/2})} \xi^{\gamma/2}\\
    &= \pi^{1/2} e^{i(2 \xi^{1/2} + \pi/4)} \xi^{\gamma/2 - 3/4}.
  \end{align*}
  %
  We shall show that these heuristics continue to hold, up to an error of $O(\xi^{\gamma/2 - 1})$.

  In an attempt to isolate the critical point, we split the interval $[0,1]$ into three parts, $[0,0.5 \xi^{-1/2}]$, $[0.5 \xi^{-1/2},1.5 \xi^{-1/2}]$, and $[1.5 \xi^{-1/2},1]$, obtaining three integrals $I_1$, $I_2$, and $I_3$. The calculation \eqref{riemannsingularityibp} shows that $|I_1| \lesssim \xi^{\gamma/2 - 1}$, and thus is neglible to our asymptotic formula. To obtain a bound on $I_3$, we use the Van der Corput lemma, noting that $\phi'(x) = \xi - 1/x^2$ is monotone, and $|\phi'(x)| \gtrsim \xi$ for $x \geq 1.5 \xi^{-1/2}$. Thus we find $|I_1| \lesssim \xi^{-1}$, and thus is also neglible to our formula. Thus we are left with the trick part of calculating $I_2$ accurately. It will easiest to do this by renormalizing the integral, i.e. writing $y = \xi^{1/2} x$, and calculating
  %
  \[ I_2 = \int_{0.5 \xi^{-1/2}}^{1.5 \xi^{-1/2}} e^{i \phi(x)} x^{-\gamma}\; dx = \xi^{\gamma/2 - 1/2} \int_{0.5}^{1.5} e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma}\; dy. \]
  %
  We consider a smooth amplitude function $\psi(x)$ supported on the interior of $[0.5,1.5]$. Then since $y + 1/y$ is stationary at $y = 1$, but non-degenerate, we can write
  %
  \[ \int e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma} \psi(y)\; dy = \xi^{-1/4} \pi^{1/2} e^{i(2\xi^{1/2} + 1/4)} + O(\xi^{-1/2}), \]
  %
  from which we obtain our main term. On the other hand, we can apply the Van der Corput lemma to show that
  %
  \[ \int_{0.5}^{1.5} e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma} (1 - \psi(y))\; dy = \int e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma} \psi(y)\; dy = O(\xi^{-1/2}). \]
  %
  Combining all these estimates gives the theorem.

  On the other hand, consider the integral
  %
  \[ I(\xi) = \int_0^1 e^{-i \xi x} e^{i/x} x^{-\gamma}\; dx = \int_0^1 e^{i \phi(x)} x^{-\gamma}, \]
  %
  where $\phi(x) = 1/x - \xi x$ is the phase. Then the phase has no critical points so we can assume that we can large decay for large $\xi$. We decompose the integral onto the intervals $[0,\xi^{-1/2}]$ and $[\xi^{-1/2},1]$, inducing the two quantities $I_1$ and $I_2$. Now applying the Van der Corput lemma to $I_2$ with $|\phi'(x)| = |1/x^2 + \xi| \geq \xi$ for $x \geq 0$, gives $|I_2| \lesssim \xi^{\gamma/2 - 1}$. On the other hand, renormalizing with $y = \xi^{1/2} x$, we have
  %
  \[ I_1 = \xi^{\gamma/2 - 1/2} \int_0^1 e^{i \xi^{1/2} (1/y - y)} y^{-\gamma}\; dy. \]
  %
  For each $n$, we note that for the phase $\phi_0(x) = 1/y - y$, for $1/2^{n+1} \leq y \leq 1/2^n$, we have $|\phi_0'(x)| \gtrsim 4^n$. Thus we can apply the Van der Corput lemma to conclude
  %
  \[ \left| \int_{1/2^{n+1}}^{1/2^n} e^{i \phi_0(x)} y^{-\gamma}\; dy \right| \lesssim \frac{2^{\gamma n}}{4^n \xi^{1/2}}. \]
  %
  Summing up over all $n \geq 0$, we conclude $|I_1| \lesssim \xi^{\gamma/2 - 1}$. Thus $|I(\xi)| \lesssim \xi^{\gamma/2 - 1}$.

  One way to interpret this asymptotic formula is through a \emph{Riemann singularity}, i.e. a tempered distribution $\Lambda$ supported on the half-life $x \geq 0$, that agrees with the oscillatory function $e^{i/x} x^{-\gamma}$ for small $x$, but is compactly supported and smooth away from the origin. We consider the case $0 \leq \gamma < 2$ for simplicity. Thus for Schwartz $f \in \mathcal{S}(\RR)$, we have
  %
  \[ \Lambda(f) = \lim_{\varepsilon \to 0^+} \int_\varepsilon^\infty f(x) e^{i/x} x^{-\gamma} \psi(x)\; dx, \]
  %
  where $\psi$ is smooth and compactly supported, and equals one in a neighbourhood of the origin. An easy integration by parts shows that for a fixed Schwartz $f$, and for $0 < \varepsilon_1 < \varepsilon_2 < \varepsilon$,
  %
  \[ \left| \int_{\varepsilon_1}^{\varepsilon_2} f(x) e^{i/x} x^{-\gamma}\; dx \right| = O\left(\varepsilon^{2-\gamma} \right), \]
  %
  where the implicit constants depend on upper bounds for $f$ and $f'$ in a neighbourhood of the origin. Thus we find $\Lambda(f)$ is well defined, and moreover, $\Lambda$ is a distribution of order one. Since $\Lambda$ is compactly supported, the Paley-Weiner theorem implies that $\widehat{\Lambda}$ is a distribution represented by a locally integrable function, and
  %
  \[ \widehat{\Lambda}(\xi) = \int_0^\infty e^{i/x} x^{-\gamma} \psi(x) e^{-2 \pi \xi i x}\; dx. \]
  %
  Our asymptotics under some small modifications tell us that if $\xi$ is large, then
  %
  \[ \widehat{\Lambda}(-\xi) = 2^{\gamma/2 - 3/4} \pi^{\gamma/2-1/2} e^{i(2^{3/2} \pi^{1/2} \xi^{1/2} + \pi/4)} \xi^{\gamma/2 - 3/4} + O(\xi^{\gamma/2 - 1}). \]
  %
  On the other hand,
  %
  \[ \widehat{\Lambda}(\xi) = O(\xi^{\gamma/2 - 1}), \]
  %
  so the Fourier transform of $\Lambda$ decays much faster to the right than to the left.
\end{example}

\section{Stationary Phase in Multiple Variables}

When we move from a single variable oscillatory integral to a multivariable oscillatory integrals. Thus we consider the oscillatory integral
%
\[ I(\lambda) = \int_{\RR^d} \psi(x) e^{\lambda i \phi(x)}\; dx. \]
%
for large $\lambda$. The method of stationary phase becomes significantly more complicated in this setting because the stationary points of the phase function are no longer necessarily isolated. In certain basic situations, however, we can obtain simple results.

\begin{theorem}
  Let $\phi$ and $\psi$ be smooth functions on $\RR^d$, with $\psi$ compactly supported. If $\nabla \phi$ is nowhere vanishing on the support of $\psi$, then for each $N$, $|I(\lambda)| \lesssim_N \lambda^{-N}$ for all $N$.
\end{theorem}

\begin{proof}
    Set $a = (\nabla \phi)/|\nabla \phi|^2$. Note that $\nabla e^{\lambda i \phi(x)} = (i\lambda) e^{\lambda i \phi(x)} \nabla \phi(x)$ is an eigenfunction of the differential operator $D$ defined such that
    %
    \[ Df(x) = \frac{a \cdot \nabla f}{i \lambda}. \]
    %
    The adjoint operator of $D$ is the operator $D^*$ defined by setting
    %
    \[ D^*f(x) = \frac{\nabla \cdot (af)}{-i\lambda}, \]
    %
    i.e. for any smooth $f$ and $g$, with one of these functions compactly supported,
    %
    \[ \int Df(x) g(x)\; dx = \int f(x) (D^*g)(x)\; dx. \]
    %
    Thus
    %
    \[ I(\lambda) = \int D^N(e^{i \lambda \phi(x)}) \psi(x)\; dx = \int e^{i \lambda \phi(x)} ((D^*)^N\psi)(x)\; dx. \]
    %
    Taking absolute values in the last integral gives that
    %
    \[ |I(\lambda)| \leq \int |(D^*)^N \psi(x)|\; dx \lesssim_{\phi,\psi,N} \frac{1}{\lambda^N}. \qedhere \]
\end{proof}

\begin{remark}
  The implicit constants for a fixed $N$ can be uniformly bounded given a uniform lower bound on $|\nabla \phi|$, and upper bounds on the derivatives of $\phi$ up to order $N+1$, on $\psi$ up to order $N$, and on the measure of the support of $\psi$.
\end{remark}

A tensorization argument establishes the result for a quadratic phase.

\begin{theorem}
  Let $A$ be an invertible $d \times d$ matrix, fix $x_0 \in \RR^d$, and consider the phase $\phi(x) = A(x - x_0) \cdot (x - x_0)$. Then for any compactly supported smooth amplitude $\psi$, there exists constants $\{ a_n \}$ depending only on the derivatives of $\psi$ at the origin, such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-d/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_N(1/\lambda^{N+d/2 +1}). \]
  %
  Moreover,
  %
  \[ a_0 = \frac{(2\pi)^{d/2} \psi(x_0)}{(-i \mu_1)^{1/2} \dots (-i \mu_d)}, \]
  %
  where $\mu_1, \dots, \mu_d$ are the eigenvalues of $A$.
\end{theorem}
\begin{proof}
  Suppose first that $\psi$ is a tensor product of $d$ compactly supported functions in $\RR$. The constant $a_0$ is invariant under affine changes of coordinates. Thus we may assume that $A$ is a diagonal matrix. But then the oscillatory integral splits into the product of single variable integrals, to which we can apply our one-dimensional asymptotics. Since the asymptotics here depend only on the support of $\psi$, and upper bounds on the magnitude of $\psi$ on derivatives up to order $2N + 4$. A density argument then shows the argument generalizes to any smooth $\psi$, with implicit constants depending on upper bounds on the measure of the support of $\psi$, and upper bounds on the derivative of $\psi$ of order up to $2N + (d + 4)$.
\end{proof}

Morse's theorem says that if $x_0$ is a non-degenerate critical point of a smooth function $\phi$, then there exists a coordinate system around $x_0$ and $a_1, \dots, a_d \in \{ \pm 1 \}$ such that, in this coordinate system,
%
\[ \phi(x_0 + t) = a_1 t_1^2 + \dots + a_d t_d^2. \]
%
In one dimension, the same is true if $x_0$ has a higher order critical point, but this does not generalize to higher dimensions, which reflects the lack of as nice a theory in this case. But in the case of functions with finitely many non-degenerate critical points, we can obtain nice asymptotics. Applying Morse's theorem gives the following theorem.

\begin{theorem}
  Let $\phi$ and $\psi$ be smooth functions, with $\psi$ compactly supported. Suppose $\phi$ has only finitely many critical points on the support of $\psi$, each of which being nondegenerate. Then there exists constants $\{ a_n \}$ depending only on finitely many derivatives of $\Phi$ and $\psi$ at the points $x_1, \dots, x_n$, such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-d/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_N(1/\lambda^{N+d/2 +1}). \]
  %
  Moreover, if the critical points of $\psi$ are $x_1, \dots, x_m$, then
  %
  \[ a_0 = \sum_{k = 1}^m \frac{(2\pi)^{d/2} \psi(x_k)}{\prod_{l = 1}^m (-i \mu_l(x_k))^{1/2}}, \]
  %
  where $\mu_1(x_k), \dots, \mu_d(x_k)$ are the eigenvalues of the Hessian of $\phi$ at $x_k$.
\end{theorem}

\section{Surface Carried Measures}

Let us consider oscillatory integrals on a `curved' version of Euclidean space. One most basic example is the Fourier transform of the surface measure of the sphere, i.e.
%
\[ \widehat{\sigma}(\xi) = \int_{S^{d-1}} e^{-2 \pi i \xi x} d\sigma(x). \]
%
Studying the decay of this surface measure is of much interest to many problems in analysis. One can reduce the study of this Fourier transform to the study of Bessel functions, to which we have already developed an asymptotic theory.

\begin{theorem}
  If $\sigma$ is the surface measure on the sphere $S^{d-1}$, then
  %
  \[ \widehat{\sigma}(\xi) = \frac{2\pi \cdot J_{d/2 - 1}(2 \pi |\xi|)}{|\xi|^{d/2 - 1}}. \]
  %
  In particular,
  %
  \[ \widehat{\sigma}(\xi) = \frac{2 \cos(2\pi |\xi| - (d/2 - 1)(\pi/2) - \pi/4)}{|\xi|^{(d-1)/2}} + O_d(1/|\xi|^{(d+1)/2}). \]
\end{theorem}
\begin{proof}
  Since $\sigma$ is rotationally symmetric, so too is $\widehat{\sigma}$. In particular, we can apply Fubini's theorem to conclude that if $V_{d-2}$ is the surface area of the unit sphere in $\RR^{d-2}$, then
  %
  \begin{align*}
    \widehat{\sigma}(\xi) &= \int_{S^{d-1}} e^{-2 \pi |\xi| x_1} d\sigma(x)\\
    &= V_{d-2} \int_{-1}^1 e^{-2 \pi |\xi| t} (1 - t^2)^{d/2-1} dt.
  \end{align*}
  %
  Setting $r = 2 \pi |\xi|$ completes the argument.
\end{proof}

Since the multivariate stationary phase approach is essentially `coordinate independant', we can also generalize the approach to manifolds. If $M$ is a $d$ dimensional Riemmannian manifold, and $\phi$ and $\psi$ are complex-valued functions on the manifold, we can consider the oscillatory integral
%
\[ I(\lambda) = \int_M e^{\lambda i \phi(x)} \psi(x) d\sigma(x), \]
%
where $\sigma$ is the surface measure induced by the metric on $M$. If $\phi$ and $\psi$ are compactly supported, then this integral is well defined in the Lebesgue sense.

\begin{theorem}
  Suppose that $\psi$ is a compactly supported smooth amplitude on a Riemannian manifold $M$, $\phi$ is a smooth phase, and $\nabla \phi$ vanishes on at most finitely many points $x_1, \dots, x_m$ on the support of $\psi$, upon each of which the Hessian $H\phi$ is non-degenerate at each point. Then there exists constants $\{ a_n \}$ such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-d/2} \sum_{n = 0}^N a_n \lambda^{-n} + O(1/\lambda^{N + d/2 + 1}). \]
  %
  Moreover,
  %
  \[ a_0 = \sum_{k = 1}^m \frac{(2\pi)^{d/2} \psi(x_k)}{\prod_{l = 1}^m (-i \mu_l(x_k))^{1/2}}, \]
  %
  where $\mu_1, \dots, \mu_d$ are the eigenvalues of the Hessian $H\phi$.
\end{theorem}

The theorem is proved by a simple partition of unity approach which reduces to the Euclidean case. It has the following important corollary.

\begin{theorem}
  If a surface $\Sigma$ is a smooth submanifold of $\RR^{d+1}$, and has non-vanishing Gauss curvature, and if $\psi$ is a smooth, compactly supported function on $\Sigma$, then
    %
    \[ |\widehat{\psi \sigma}(\xi)| \lesssim_{\psi,\sigma} \frac{1}{|\xi|^{d/2}}, \]
    %
    where $\sigma$ is the surface measure of $\Sigma$.
\end{theorem}
\begin{proof}
  For each $\xi \in S^d$,
  %
  \[ I_\xi(\lambda) = \int_M e^{\lambda i \phi_\xi(x)} \psi(x)\; d\sigma, \]
  %
  where $\phi_\xi(x) = -2 \pi i \xi \cdot x$. The derivatives of $\phi_\xi$ of order $\leq N$ on $M$ are $O_N(1)$, independently of $\xi$. Similarily, $H_M \phi_\xi$ is uniformly non-degenerate, in the sense that the operator norm of $(H_M \phi_\xi)^{-1}(x)$ is $O(1)$, independently of $\xi$. Working with $\Sigma$ as a local graph, and then applying the curvature condition on $\Sigma$ implies that for each $\xi \in S^d$, $\phi_\xi$ has $O(1)$ stationary points on the support of $\psi$. There also exists a constant $r$ such that if $x$ does not lie in any ball of radius $r$ around a stationary point, then $|\nabla_M \phi_\xi| \gtrsim 1$. Moreover, the Hessian $H_M \phi_\xi$ is uniformly non-degenerate in the radius $r$ balls around the critical point, independently of $\xi$. Thus we can apply the last result to conclude
  %
  \[ I_\xi(\lambda) \lesssim \lambda^{-d/2}, \]
  %
  where the implicit constant is independent of $\xi$, because all the required derivatives are uniformly bounded.
\begin{comment}

  Working locally, since the support of $\mu$ is precompact, we may consider a finite partition of unity $\{ \psi_\alpha \}$ with respect to an open family of sets $\{ U_\alpha \}$ covering $U$, such that for each $\alpha$, there exists a transformation $T$ composed of a rotation, translation, and dilation such that if $B$ is the open unit ball, then there is a smooth function $u: B \to \RR$ with $\nabla u(0) = 0$, such that
  %
  \[ T(U_\alpha) = \left\{ (x,u(x)): x \in B \right\}. \]
  %
  The fact that $\Sigma$ has non-vanishing Gauss curvature implies that the Hessian of $u$ is non-zero at each point, so in particular we may assume that $\nabla u$ does not equal to zero anywhere else on $B$. The asymptotics of the Fourier transform of $\mu \psi_\alpha$ is the same as the Fourier transform of the measure $T_*(\mu \psi_\alpha)$, so we may assume without loss of generality that $U_\alpha$ takes the form $T(U_\alpha)$. Then
  %
  \[ d\sigma = (1 + |\nabla u|^2)^{1/2}\; dx^1 \dots dx^d, \]
  %
  which can be incorporated into $\psi_\alpha$. Thus it suffices to show that for each $\xi = (\xi_0, \xi_1) \in \RR^d$,
  %
  \[ \left| \int_B e^{-2 \pi i(\xi_0 \cdot x + \xi_1 u(x))} \psi(x)\; dx \right| \lesssim_{\psi,u} \frac{1}{(|\xi_0|^2 + \xi_1^2)^{d/4}}. \]
  %
  Let us fix $\xi \in S^d$, and consider the oscillatory integral
  %
  \[ I_\xi(\lambda) = \int_B e^{\lambda i \phi_\xi(x)} \psi(x)\; dx, \]
  %
  where
  %
  \[ \phi_\xi(x) = -2\pi \left( \xi_0 \cdot x + \xi_1 u(x) \right). \]
  %
  Note that
  %
  \[ \nabla \phi_\xi(x) = -2\pi(\xi_0 + \xi_1 \nabla u(x)) \]
  %
  The inverse function theorem combined with our curvature condition tells us that if we choose our neighbourhoods $U_\alpha$ small enough, the map $x \mapsto \nabla u(x)$ is a smooth diffeomorphisms on $B$. In particular, for each $\xi$, there is at most one $x \in B$ such that $\phi_\xi$ is stationary at $x$. Even without the curvature condition, we can conclude that for each $x$, there is at most one $\xi \in S^d$, up to a negation, such that $\phi_\xi$ is stationary at $x$.

  Because of the curvature condition, one can verify that for each $\xi \in \RR^d$, there are $O(1)$ stationary points for the phase $\phi_\xi$. Moreover, if

  In particular, we conclude that for each $\xi$, there are $O(1)$ stationary points for the phase $\phi(\cdot | \xi)$ on the support of $\psi$.

  The curvature condition implies that, if we have chosen are neighbourhoods small enough, for each $\xi$ there is at most one $x \in B$ such $\phi(\cdot|\xi)$ is stationary at $x$.

  Then $\nabla_x \phi(x|\xi) = -2\pi( \xi_0 + \xi_1 \nabla u(x) )$. In particular, $\phi(\cdot|(0,1))$ has a stationary point at $0$. If we consider $D_x[\nabla_x \phi(x|\xi)] = -2\pi  \xi_1 H_x u(x)$, which is nonsingular by assumption in a neighbourhood of $(0,1)$. Thus there exists a relatively open set $V_\alpha \subset S^d$


  Applying the implicit function theorem, having chosen our sets $\psi_\alpha$ small enough, there exists a relatively open set $V_\alpha \subset S^d$ containing $(0,1)$ such that for each $\xi = (\xi_0,\xi_1) \in V_\alpha$, there is a unique $x(\xi) \in B$ such that $\nabla_x \phi(x(\xi)|\xi) = 0$

  such that for each $\xi \in \RR^d$ and $\alpha$, there is at most one point $x \in U_\alpha$ such that $\xi$ is orthogonal to $T_x(M)$. Moreover, we can find a relatively open subset $V_\alpha$ of $S^{d-1}$ such that for each $\xi \in V_\alpha$, there exists a unique $x \in U_\alpha$ such that $\xi$ is orthogonal to $T_x(M)$.

  we can write
  %
  \[ \widehat{\mu}(\xi) = \sum_\alpha \int e^{-2 \pi i \xi \cdot x} \psi_\alpha(x)\; d\mu. \]
  %


  $\Sigma$ is the smooth graph of a function $f: B \to \RR$, where $B$ is the closed unit ball in $\RR^d$, i.e.
  %
  \[ \Sigma = \{ (x,t) : x \in B, t = f(x) \}. \]
  %
  Then $d\sigma = (1 + |\nabla f|^2)^{1/2} dx^1 \dots dx^d$, and the fact that $\Sigma$ has non-vanishing Gauss curvature implies that the Hessian of $f$ is non-degenerate. It thus suffices to obtain a bound of the form
  %
  \[ \int e^{i (\xi \cdot x) + \eta f(x)} \psi(x)\; dx \lesssim_{\psi} \frac{1}{\sqrt{|\xi|^2 + \eta^2}}. \]
  %
  where $\psi$ is a compactly supported, smooth function on $B$. Fix $(\xi_0, \eta_0)$ such that $\xi_0^2 + \eta_0^2 = 1$, and consider the oscillatory integral
  %
  \[ I(\lambda) = \int_B e^{\lambda i (\xi_0 \cdot x) + \eta_0 f(x)} \psi(x)\; dx \]
  %
  This is an oscillatory integral with phase $\phi(x;\xi_0,\eta_0) = (\xi_0 \cdot x) + \eta_0 f(x)$.

  We are considering the oscillatory integral
  %
  \[ \int e^{-2 \pi i \xi x} d\Sigma(x). \]
  %
  If $\phi(x) = x \cdot \xi$. The nondegeneracy of the Hessian of $\phi$ on the support of $\mu$ corresponds precisely to the nonvanishing of the curvatures of $\Sigma$ on $\mu$. Then we may find a family of
\end{comment}
\end{proof}

If $\Omega$ is a bounded open subset of $\RR^{d+1}$ whose boundary is a smooth manifold with non-zero Gaussian curvature at each point, then it's Fourier transform has decay one order better than the Fourier transform of it's boundary.

\begin{corollary}
  If $\Omega$ is a bounded open subset of $\RR^d$ whose boundary is a smooth manifold $\Sigma$ with non-zero Gaussian curvature at each point. If $I_\Omega$ is the indicator function on $\Omega$, then
  %
  \[ |\widehat{I_\Omega}(\xi)| \lesssim_\Omega |\xi|^{-d/2}. \]
\end{corollary}
\begin{proof}
  We have
  %
  \[ \widehat{I_\Omega}(\xi) = \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx \]
  % u div(V) dV = u (V . n) dS - Grad(u) . V dV
  % As long as V is smooth and div(V) is fine
  % If u = e^{-2 \pi i \xi . x}, Grad(u) = (-2\pi i \xi) e^{-2 \pi i \xi . x}
  % If V(x) = x_1
  %
  Then we can apply Stoke's theorem for each $1 \leq k \leq d+1$ to conclude
  %
  \[ \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx = \frac{(-1)^k}{2 \pi i \xi_k} \int_\Sigma e^{-2 \pi i \xi \cdot x} (dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n). \]
  %
  For each $k$, there is a smooth function $\psi_k$ such that
  %
  \[ dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n = \psi_k d\sigma. \]
  %
  Thus applying the last case, we find
  %
  \[ \left| \frac{(-1)^k}{2 \pi i \xi_k} \int_\Sigma e^{-2 \pi i \xi \cdot x} (dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n) \right| \lesssim \xi_k^{-1} |\xi|^{-(d-1)/2}. \]
  %
  At each point $\xi$, if we choose $\xi_k$ with the largest value, then $|\xi_k| \sim |\xi|$, so
  %
  \[ \left| \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx \right| \lesssim |\xi|^{-(d+1)/2}. \qedhere \]
\end{proof}

The fact that curved surfaces have Fourier decay has many consequences in harmonic analysis.

\begin{example}
  If $M$ is a hypersurface in $\RR^d$, and $\psi$ is a smooth, compactly supported function on $M$, and $f$ is a smooth, compactly supported function on $\RR^d$, we can define a function $Af$ on $\RR^d$ by defining
  %
  \[ (Af)(y) = \int_M f(y - x) \psi(x)\; d\sigma(x). \]
  %
  We note that $Af$ is really the convolution of $f$ with $\psi \sigma$. Thus
  %
  \[ \widehat{Af}(\xi) = \widehat{f}(\xi) \widehat{\psi d\sigma}(\xi). \]
  %
  For each multi-index $\alpha$, the derivative $(Af)_\alpha$ is equal to
  %
  \[ \int_M f_\alpha(y-x) \psi(x)\; d\sigma(x) = f_\alpha * (\psi \sigma). \]
  %
  In particular, we have
  %
  \[ \widehat{(Af)_\alpha} = (2 \pi i \xi)^\alpha \widehat{f}(\xi) \widehat{\psi \sigma}(\xi). \]
  %
  Since we have shown
  %
  \[ |\widehat{\psi \sigma}(\xi)| \lesssim |\xi|^{-(d-1)/2}, \]
  %
  we conclude that if $|\alpha| \leq k$, where $k = (d-1)/2$,
  %
  \[ \| (Af)_\alpha \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)}. \]
  %
  In particular, this implies that $A$ extends to a unique bounded operator from $L^2(\RR^d)$ to $L^2_k(\RR^d)$, i.e. to a map such that for each $f \in L^2(\RR^d)$, $Af$ is a square integrable function which has square integrable weak derivatives of all orders less than or equal to $k$, and moreover, $\| (Af)_\alpha \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)}$ for all $|\alpha| \leq k$. Thus the operator $A$ is `smoothening', in a certain sense.

  The operator $A$ is obviously bounded from $L^1(\RR^d)$ to $L^1(\RR^d)$ and $L^\infty(\RR^d)$ to $L^\infty(\RR^d)$, purely from the fact that $\psi \sigma$ is a finite measure. Using curvature and some analytic interpolation, we will now also show that $A$ is bounded from $L^p(\RR^d)$ to $L^q(\RR^d)$, where $p = (d+1)/d$, and $q = d+1$. Interpolation thus yields a number of intermediate estimates. The trick here is to obtain an $(L^1,L^\infty)$ bound for an `improved' version of $A$, and an $(L^2,L^2)$ bound for a `worsened' version of $A$. Interpolating between these two results gives a bound for precisely $A$. It suffices to prove this bound `locally' on $M$, since we can then sum up these bounds, so we may assume that $M$ is given as the graph of some function, i.e. there exists $u$ such that
  %
  \[ M = \{ (x,u(x)):  \} \]


  For each $s$, we write $A_sf = K_s * f$, where
  %
  \[ K_s(x) = \gamma_s |x_d - \phi(x')|_+^{s-1} \psi_0(x). \]
  %
  Here $\gamma_s = s \dots (s + N) e^{s^2}$, where $N$ is some large parameter to be fixed in a moment. The $e^{s^2}$ parameter is to mitigate the growth of $\gamma_s$ as $|\text{Im}(s)| \to \infty$, which allows us to interpolate. The quantity $|u|_+^{s-1}$ is equal to $u^{s-1}$ where $u > 0$, and is equal to 0 when $u \leq 0$. And $\psi_0(x) = \psi(x) (1 + |\nabla_{x'} \phi(x')|^2)^{1/2}$.
\end{example}





\chapter{Restriction Theorems}

If a function $f$ lies in $L^p(\RR^d)$, there does not exist a numerically meaningful way to restrict $f$ to a set of measure zero, since $f$ is only defined up to measure zero. More precisely, for any $0 < p < \infty$, $0 < q \leq \infty$, and any Radon measure $\sigma$ supported on a set $S$ with Lebesgue measure zero, there does not exist a bound $\| f \|_{L^q(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)}$ for all $f \in C(\RR^d) \cap L^p(\RR^d)$. We can consider a very similar problem for the Lebesgue measure; given $f \in L^1(\RR^d)$, $\widehat{f} \in C(\RR^d)$, and so $\widehat{f}|_S$ is a well defined function on $S$. If there exists a bound of the form
%
\begin{equation} \label{restrictionestimate}
  \| \widehat{f} \|_{L^q(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)}
\end{equation}
%
for all $f \in L^1(\RR^d) \cap L^p(\RR^d)$, then (assuming $p < \infty$, which will always be the case in nontrivial situations) there exists a unique bounded operator $R: L^p(\RR^d) \to L^q(S,\mu)$ such that $Rf = \widehat{f}|_S$ for $f \in L^1(\RR^d) \cap L^p(\RR^d)$; thus we have a meaningful way of restricting the Fourier transforms of functions in $L^p(\RR^d)$ to $S$. In light of the failure to restrict elements of $L^p(\RR^d)$ to $L^q(S,\mu)$ without taking the Fourier transform, this indicates that the Fourier transform of $L^p(\RR^d)$ is a fairly special element of $L^q(\RR^d)$. We refer to an estimate of the form above as a \emph{restriction estimate}.

The approximate translation invariance of restriction bounds implies (from Littlewood's principle) that $q \geq p$ for any restriction estimate. For $p = 1$, a restriction bound from $L^1(\RR^d)$ to $L^\infty(S,\mu)$ is trivial in light of the bound $\| \widehat{f} \|_{L^\infty(\RR^d)} \leq \| f \|_{L^1(\RR^d)}$. On the other hand, for $p = 2$ and $0 < q \leq \infty$, \emph{no such bound is possible} unless $\mu$ is absolutely continuous with respect to the Lebesgue measure. This follows from a simple application of Parseval's theorem. Interpolation shows we also should not expect any bounds when $p > 2$, and indeed such restriction estimates even fail when $\mu$ is absolutely continuous, for the Hausdorff-Young inequality fails in this setting. Thus the interesting bounds occur when $1 < p < 2$. For a particular pair $(S,\mu)$ and exponent $q$, the goal is to push the value of $p$ as close to $2$ as possible. Often, we study a smooth surface $S$, and consider a measure $\mu$ which is absolutely continuous with respect to the surface measure on $S$. We shall find that in this setting there is a rich theory relating the existence of restriction maps to the curvature of the surface $S$.

%\begin{theorem}
%  Fix $0 < p < \infty$ and $0 < q \leq \infty$. If $S$ has measure zero, and $\sigma$ is a non-zero measure supported on $S$, then there does not exist a bounded operator $P: L^p(\RR^d) \to L^q(S,\sigma)$ such that for each function $f \in C_c(\RR^d) \cap L^p(\RR^d)$, $P(f)$ is the usual restriction of $f$ to $S$.
%\end{theorem}
%\begin{proof}
%  For each $\varepsilon > 0$, we can find an open set $U$ containing $S$ with $|U| < \varepsilon$. If we find an Urysohn function $f \in C_c(\RR^d)$ supported on $U$ with $\| f \|_{L^\infty(\RR^d)} \leq 1$, and with $f(x) = 1$ for all $x \in S$, then
  %
%  \[ \| f \|_{L^p(\RR^d)} \leq |U|^{1/p} \| f \|_{L^\infty(\RR^d)} < \varepsilon^{1/p}, \]
  %
%  yet for $q < \infty$, $\| Pf \|_{L^q(S,\sigma)} = \| 1 \|_{L^q(S,\sigma)} = \sigma(S)^{1/q} \gtrsim 1$, and for $q = \infty$, $\| Pf \|_{L^q(S,\sigma)} = 1$. Taking $\varepsilon \to 0$ shows that there cannot exist a bound
  %
%  \[ \| Pf \|_{L^q(S,\sigma)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
%  for all $f \in C_c(\RR^d)$.
%\end{proof}

%\begin{remark}
%  If $S$ has finite, positive measure, and $\sigma$ is the Lebesgue measure restricted to $S$, then a restriction is meaningful, and for each $f \in C_c(\RR^d)$,
  %
%  \[ \| Pf \|_{L^q(S)} \leq |S|^{1/q} \cdot \| f \|_{L^\infty(\RR^d)} \]
  %
%  and
  %
%  \[ \| Pf \|_{L^q(S)} \leq \| f \|_{L^q(\RR^d)}, \]
  %
%  so we can interpolate to conclude that for all $p \geq q$,
  %
%  \[ \| Pf \|_{L^q(S)} \leq |S|^{1/q - 1/p}  \| f \|_{L^p(S)}. \]
  %
%  Thus we can restrict functions to sets of positive measure meaningfully.
%\end{remark}

%For instance, if $f \in L^1(\RR^d)$, then we know $\widehat{f}$ is a \emph{continuous} function on $\RR^d$ vanishing at infinity, with $\| \widehat{f} \|_{L^\infty(\RR^d)}$. It follows that we \emph{do} have a bound
%
%\[ \| \widehat{f} \|_{L^\infty(S,\mu)} \leq \| f \|_{L^1(S)}, \]
%
%where $\widehat{f}$ is integrable on $S$ because it is continuous and bounded. Thus there does exist a bounded operator $R: L^1(\RR^d) \to L^\infty(S,\mu)$ such that $Rf$ is the restriction of the Fourier transform of $f$ to $S$. More generally, it is possible to define a bounded operator $R: L^p(\RR^d) \to L^q(S,\mu)$ such that $Rf = \widehat{f}|_S$ whenever $f \in L^1(\RR^d) \cap L^p(\RR^d)$ by the Hahn-Banach theorem if we have a bound $\| \widehat{f} \|_{L^q(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)}$ for any $f \in L^1(\RR^d) \cap L^p(\RR^d)$ (we have to restrict to $L^1(\RR^d)$ so that the Fourier transform is continuous, and can thus be easily restricted to singular sets). The existence of such an operator gives an indication that the structure of Fourier transforms of elements of $L^p(\RR^d)$ are distinguished from an arbitrary element of $L^{p^*}(\RR^d)$. These results are trivial for integrable functions, and \emph{always} fail for square integrable functions (unless $\mu$ is a.c. with respect to the Lebesgue measure). By interpolation, these results also fail on $L^p(\RR^d)$ for $p > 2$ (such bounds even do not even hold when $\mu$ is a.c. with respect to the Lebesgue measure because the Hausdorff-Young inequality fails). Thus the goal for a particular pair $(S,\mu)$ and exponent $q$ is to push the value of $p$ as close to $2$ as possible. Often, we study a smooth surface $S$, and consider a measure $\mu$ which is absolutely continuous with respect to the surface measure on $S$. We shall find that in this setting there is a rich theory relating the existence of restriction maps to the curvature of the surface $S$.

%It should be expected that restriction estimates always hold from $L^1(\RR^d)$ to $L^\infty(S,\mu)$. On the other hand, we do not have \emph{any} restriction estimates from $L^2(\RR^d)$ to $L^q(S,\mu)$ for any $1 \leq q \leq \infty$, unless $\mu$ is absolutely continuous with respect to the Lebesgue measure. The reason for this is Parsevel's theorem, which says that the Fourier transform of a square integrable function behaves like an arbitrary square integrable function; there is no way to meaningfully restrict a morphism from $L^2(\RR^d)$ to $L^q(S,\mu)$, and therefore no such bound holds. The next theorem argues this more rigorously.

%\begin{theorem}
%  For any $0 < q < \infty$, one cannot obtain a bound of the form
  %
%  \[ \| \widehat{f} \|_{L^q(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
%  unless $\mu$ is absolutely continuous with respect to the Lebesgue measure.
%\end{theorem}
%\begin{proof}
%  Suppose some such bound held, and $E$ is a compact subset of $\RR^d$ with $|E| = 0$. Then for any $\varepsilon > 0$, we can find $f_\varepsilon \in L^2(\RR^d)$ such that $\widehat{f_\varepsilon}$ is a non-negative function supported on $E_\varepsilon$, equal to one on $E_{\varepsilon/2}$, and satisfying $\| \widehat{f_\varepsilon} \|_{L^\infty(\RR^d)} = 1$. It follows that
  %
%  \[ \| f_\varepsilon \|_{L^2(\RR^d)} = \| \widehat{f_\varepsilon} \|_{L^2(\RR^d)} \leq |E_\varepsilon|. \]
  %
%  On the other hand,
  %
%  \[ \| \widehat{f_\varepsilon} \|_{L^q(S,\mu)} \geq \mu(E_{\varepsilon/2})^{1/q}. \]
  %
%  It follows from outer regularity that
  %
%  \[ \mu(E) \leq \lim_{\varepsilon \to 0} \mu(E_{\varepsilon/2}) \lesssim \lim_{\varepsilon \to 0} |E_\varepsilon|^q = |E|^q = 0. \]
  %
%  Thus $\mu$ is absolutely continuous with respect to the Lebesgue measure.
%\end{proof}

%\begin{remark}
%  Interpolation shows that we cannot have any restriction estimate from $L^p(\RR^d)$ to $L^q(S,\mu)$ for $p \geq 2$ unless $\mu$ is absolutely continuous with respect to the Lebesgue measure.
%\end{remark}

%\begin{remark}
%  The most classical, though slightly trivial, example of a restriction inequality is the Hausdorff-Young inequality, which shows that for $1 \leq p \leq 2$,
  %
%  \[ \| \widehat{f} \|_{L^{p'}(\RR^d)} \leq \| f \|_{L^p(\RR^d)}. \]
  %
%  This is the largest range of exponents for which a bound of this forms, and can be viewed as a restriction inequality when $S = \RR^d$, and where $\mu$ is the Lebesgue measure.
%\end{remark}

There is a dual problem associated with the pair $(S,\mu)$. For $g \in L^1(S,\mu)$, we consider the \emph{extension operator}
%
\[ E_S g(x) = \int_S g(\xi) e^{2 \pi i \xi \cdot x}\; d\mu(\xi). \]
%
In other words, $E_S g$ is the inverse Fourier transform of the finite Borel measure $g \cdot \mu$. It is simple to see using Fubini's theorem that if $f \in L^1(\RR^d)$ and $g \in L^1(S,\mu)$, then
%
\[ \int_S R_S f(\xi) \overline{g(\xi)}\; d\mu(\xi) = \int_{\RR^d} f(x) \overline{(E_S g)(x)}\; dx. \]
%
For $1 \leq p < \infty$, and $1 < q \leq \infty$, $\mathcal{S}(\RR^d)$ is dense in $L^p(\RR^d)$ and $C_c^\infty(\RR^d)$ is dense in $L^{q'}(S,\mu)$. Moreover, for this range of parameters, $R_S f$ lies in $L^q(\RR^d)$ for all $f \in \mathcal{S}(\RR^d)$, and $E_S g$ lies in $L^{p'}(\RR^d)$ for all $g \in C_c^\infty(\RR^d)$. We therefore conclude by duality that for $1 \leq p < \infty$ and $1 < q \leq \infty$, a bound of the form
%
\[ \| R_S f \|_{L^q(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
holding for all $f \in \mathcal{S}(\RR^d)$ is equivalent to a bound
%
\[ \| E_S g \|_{L^{p'}(\RR^d)} \lesssim \| g \|_{L^{q'}(S,\mu)}, \]
%
for all $g \in C_c^\infty(\RR^d)$. Since bounds only hold for $1 \leq p < 2$ then this duality result essentially covers all cases of interest.

If $\mu$ is a singular measure, using the fact that $E_S g = g \cdot \mu$, for any nonzero $g$ we see that we cannot have $E_S g \in L^{p'}(\RR^d)$ for any $2 \leq p \leq \infty$, because then Hausdorff-Young and the Fourier inversion theorem would imply that $g \cdot \mu \in L^p(\RR^d)$, which is not the case for any such value of $p$. Thus, just like restriction estimates, extension estimates in nontrivial situations only hold when $1 \leq p < 2$.

It is simple to prove that restriction bounds for product sets reduce to bounds on their projections. Thus the interesting sets $S$ we consider will never be product sets.

\begin{theorem}
  Consider two pairs $(S_1,\mu_1)$ and $(S_2,\mu_2)$ in $\RR^n$ and $\RR^m$, and let $S = S_1 \times S_2$, $\mu = \mu_1 \times \mu_2$. Then for $0 < p \leq q \leq \infty$, a restriction bound of the form
  %
  \[ \| \widehat{f} \|_{L^q(S,\mu)} \lesssim \| f \|_{L^p(\RR^{n+m})} \]
  %
  for all $f \in \mathcal{S}(\RR^{n+m})$ is equivalent to a pair of bounds of the form
  %
  \[ \| \widehat{f_1} \|_{L^q(S_1,\mu_1)} \lesssim \| f_1 \|_{L^p(\RR^n)} \quad\text{and}\quad \| \widehat{f_2} \|_{L^q(S_2,\mu_2)} \lesssim \| f_2 \|_{L^p(\RR^m)}. \]
  %
  for all $f_1 \in \mathcal{S}(\RR^n)$ and $f_2 \in \mathcal{S}(\RR^m)$.
\end{theorem}
\begin{proof}
  We calculate that for any pair $f_1,f_2$,
  %
  \[ \| \widehat{f_1 \otimes f_2} \|_{L^q(S,\mu)} = \| \widehat{f_1} \|_{L^q(S_1,\mu_1)} \| \widehat{f_2} \|_{L^q(S_2,\mu_2)}. \]
  %
  and
  %
  \[ \| f_1 \otimes f_2 \|_{L^p(\RR^{n+m})} = \| f_1 \|_{L^p(\RR^n)} \| f_2 \|_{L^p(\RR^m)}. \]
  %
  If a restriction estimate held on $(S,\mu)$, it would then follow that
  %
  \[ \| \widehat{f_1} \|_{L^q(S_1,\mu_1)} \lesssim \frac{\| f_2 \|_{L^p(\RR^d)}}{\| \widehat{f_2} \|_{L^q(S_2,\mu_2)}} \| f_1 \|_{L^p(\RR^n)}. \]
  %
  Choosing any nontrivial choice of $f_2$ gives a restriction estimate on $(S_1,\mu_1)$. By symmetry, we also get a restriction estimate on $(S_2,\mu_2)$.

  Conversely, suppose we have a restriction estimate on $(S_1,\mu_1)$ and $(S_2,\mu_2)$, and $f \in L^1(\RR^{n+m}) \cap L^p(\RR^{n+m})$. Without loss of generality, we may assume by Littlewood's principle that $q \geq p$. If we temporarily let $\mathcal{F}_1$ and $\mathcal{F}_2$ denote the Fourier transform in the first and second variables respectively, then by applying Minkowski's inequality and Fubini's theorem we find that
  %
  \begin{align*}
    \| \widehat{f} \|_{L^q(S,\mu)} &= \left( \int_{\RR^m} \int_{\RR^n} |\mathcal{F}_1(\mathcal{F}_2 f)(\xi_1,\xi_2)|^q\; d\mu_1(\xi_1) d\mu_2(\xi_2) \right)^{1/q}\\
    &\lesssim \left( \int_{\RR^m} \left( \int_{\RR^n} |(\mathcal{F}_2 f)(x_1,\xi_2)|^p dx_1 \right)^{q/p}\; d\mu_2(\xi_2) \right)^{1/q}\\
    &\leq \left( \int_{\RR^n} \left( \int_{\RR^m} |(\mathcal{F}_2 f)(x_1,\xi_2)|^q\; d\mu_2(\xi_2) \right)^{p/q}\; dx_1 \right)^{1/p}\\
    &\lesssim \left( \int_{\RR^n} \int_{\RR^m} |f(x_1,x_2)|^p dx_2 dx_1 \right)^{1/p} = \| f \|_{L^p(\RR^d)}. \qedhere
  \end{align*}
\end{proof}

The most classical example of a restriction conjecture is when $\mu = \sigma$ is the surface measure on $S^{d-1} \subset \RR^d$, or when $\mu = \psi \sigma$ for some $\psi \in C_c^\infty(S)$. If $S$ is the graph of some smooth function $\phi: U \to \RR$, where $U$ is an open subset of $\RR^{d-1}$, then \eqref{restrictionestimate} is equivalent to an estimate of the form
%
\[ \left( \int_U \psi(\eta) |\widehat{f}(\eta,\phi(\eta))|^q\; d\eta \right)^{1/q} \lesssim \left( \int_{\RR^d} |f(x)|^p\; dx \right)^{1/p}, \]
%
for some $\psi \in C_c^\infty(U)$. Dual to this are the extension estimates, which are equivalent to bounds of the form
%
\begin{align*}
  &\left( \int_{\RR^{d-1} \times \RR} \left| \int_U \psi(\eta) f(\eta) e^{2 \pi i (x \cdot \eta + y \phi(\eta))}\; d\eta \right|^{p'}\; dx\; dy \right)^{1/p'}\\
  &\quad\quad\quad\quad\lesssim \left( \int_U \psi(\eta) |f(\eta)|^{q'}\; d\eta \right)^{1/q'}.
\end{align*}
%
These types of estimates often appear in the theory of dispersive partial differential equations, which makes them useful outside of harmonic analysis.  For instance, we can use restriction estimates to understand the free Schr\"{o}dinger equation $u_t = 2 \pi i \Delta_x u$. In particular, if $u: \RR^{d-1} \times \RR \to \RR$ solves this equation, and $u(x,0) = f(x)$ for all $x \in \RR^{d-1}$, then
% L = Delta / 2 pi i
\[ u(x,t) = (e^{2 \pi i \Delta t} f)(x) = \int_{\RR^{d-1}} \widehat{f}(\xi) e^{2 \pi i (\xi \cdot x - 4\pi^2 |\xi|^2 t)}\; d\xi. \]
%
The map $f \mapsto u$ is thus essentially the extension operator associated to the \emph{elliptic paraboloid} $S = \{ (\xi,|\xi|^2) : \xi \in \RR^d \}$, together with the measure $\mu$ induced by the projection of $S$ onto $\RR^{d-1}$.

\begin{example}
  Consider extension estimates to a hyperplane, i.e. to the graph of the map $\phi: \RR^{d-1} \to \RR$ with $\phi(x) = 0$ for all $x \in \RR^{d-1}$. We are thus attempting to obtain a bound of the form
  %
  \[ \left( \int_{\RR^{d-1} \times \RR} \left| \widehat{f}(x) \right|^{p'}\; dx\; dy \right)^{1/p'} \lesssim \left( \int_{\RR^{d-1}} |f(\eta)|^{q'}\; d\eta \right)^{1/q'}. \]
  %
  The left hand side doesn't depend on $y$, and thus is infinite unless $f = 0$. Thus no extension estimates can hold unless $p' = \infty$ and $q' = 1$, i.e. for the trivial estimates. The general heuristic here is that `flatness' is preventing us from getting better estimates. For curved surfaces, one expects to get a much wider range of exponents.
\end{example}

The general heuristic suggests that restriction estimates for surfaces with non-vanishing curvature behave the best. The classical `toy' examples of such results are the restriction estimates for the paraboloid and the sphere, where we have additional symmetries to use not present in all surfaces. The conjectured estimates for such surfaces still remain open problems today. The conjectured exponents come from two examples which are seen to be `worst case examples'.

The standard theory of stationary phase shows that if $\psi \in C_c^\infty(\RR^{d-1})$ is supported in a small enough neighborhood of the origin, then there exists a continuous, non-vanishing function $a: S^{d-1} \to \CC$ such that for $r > 0$ and $x \in S^{d-1}$,
%
\[ E_S \psi(rx) = a(x) r^{-(d-1)/2} + O(r^{-(d+1)/2}). \]
%
Thus $E_S \psi \in L^{p'}(\RR^d)$ if and only if $2d/(d-1) < p'$, i.e. $p < 2d/(d+1)$. Since $\psi \in L^{q'}(S,\mu)$ for any $q'$, the restriction theorem is thus only interesting when $p < 2d/(d+1)$.

The second example is due to Knapp, and called the `Knapp example' in the literature, which is really just studying the extension operator applied to a wave packet. To construct the Knapp example, by translating and rotating (which by symmetry does not change any estimates in the Fourier transform) we may assume our surface contains the origin, and near the origin is the graph of a map $\phi: U \to \RR$, where $U \subset \RR^{d-1}$ contains the origin, $\phi(0) = 0$, and $\nabla \phi(0) = 0$. Furthermore, rescaling $\mu$ if necessary, we may assume that $\mu(B_r(0)) \geq r^{d-1}$ for all $r \leq 1$. Now if we fix $r \leq 1$, and consider a bump function $\psi \in C_c^\infty(\RR^d)$ supported on a ball of radius $r$ with $|\psi(x)| = 1$ for all $|x| \leq r/2$ and with $\| \psi \|_{L^\infty(S)} \leq 1$, then $\| \psi \|_{L^{q'}(S,\mu)} \sim r^{(d-1)(1 - 1/q)}$. On the other hand, $\psi \cdot \mu$ is actually supported on a `cap'
%
\[ \theta_r = \{ (\xi,\xi_d): |\xi| \leq r, |\xi_d| \leq C r^2 \} \]
%
for some constant $C$ depending on $\phi$, independant of $r$. Now $E_S \psi$ is equal to $\widehat{\psi \cdot \mu} = \widehat{\psi} * \widehat{\mu}$ once reflected about the origin. Since $\psi \in C_c^\infty(\RR^d)$, $\widehat{\psi}$ is Schwartz, and since $\mu$ has finite measure, $\widehat{\mu}$ is a continuous, bounded function, which implies that $E_S(\psi)$ is Schwartz. Since $\widehat{E_S(\psi)}$ is supported in $\theta_r$, the uncertainty principle heuristically implies that $E_S(\psi)$ is locally constant on translations of the `tube'
%
\[ \theta_r^* = \{ (x,x_d): |x| \leq 1/r, |x_d| \leq C/r^2 \}. \]
%
Since
%
\[ E_S(\psi)(0) = \int \psi(x) d\mu(x) \gtrsim r^{d-1} \]
%
it follows from (TODO: record Prop 5.5 of Wolff's notes in these notes) that
%
\[ \int |E_S(\psi)(x,x_d)| (1 + rx + r^2 x_d)^{-N}\; dx\; dx_d \gtrsim_N |\theta_r^*| r^{d-1} \gtrsim r^{-2} \]
%
H\"{o}lder's inequality implies that if $N$ is chosen larger than $d$, then
%
\begin{align*}
  \int |E_S(\psi)(x,x_d)| (1 + rx + r^2 x_d)^{-N}\; dx\; dx_d \lesssim r^{-(d+1)(1/p)} \| E_S \phi \|_{L^{p'}(\RR^d)},
\end{align*}
%
and so we conclude that $\| E_S \phi \|_{L^{p'}(\RR^d)} \geq r^{(d+1)(1/p) - 2}$. Letting $r \to 0$ shows that an extension estimate for $S$ from $L^{q'}(S,\mu)$ to $L^{p'}(\RR^d)$ cannot hold if $(d+1)(1/p) - 2 < (d-1)(1 - 1/q)$. Thus an extension estimate can only hold for $(d-1)/q' < (d+1)/p'$. 

\begin{remark}
  TODO: If $S$ is a surface passing through the origin whose derivatives vanish to order $k$, consider a variant of the Knapp example which shows how restriction fails in this domain.
\end{remark}

The general belief in the field is that these examples are essentially the only barriers to restriction. Thus for any such pair $1 \leq p,q < \infty$ such that $p < 2d/(d+1)$ and $(d+1)(1/p) - 2 \geq (d-1)(1-1/q)$, we have restriction (and thus extension) bounds from $L^{q'}(S,\mu)$ to $L^{p'}(\RR^d)$, and thus a restriction bound from $L^p(\RR^d)$ to $L^q(S,\mu)$. This is the \emph{restriction conjecture}, which, to a large extent, still remains an open problem.



\section{Stein-Tomas Theorem}

The classical result for restriction estimates on surfaces with non-vanishing curvature is the \emph{Stein-Tomas theorem}. If $S$ is a hypersurface in $\RR^d$ with nonvanishing curvature, and $\mu = \psi \sigma$ for some $\psi \in C_c^\infty(\RR^d)$, where $\sigma$ is the surface measure on $S$, then for $p \leq 2(d+1)/(d+3)$,
%
\[ \| \widehat{f} \|_{L^2(S)} \lesssim \| f \|_{L^p(\RR^d)}. \]
%
This result is tight, as shown by the Knapp example. There are many proofs of the Stein-Tomas theorem. The simplest uses the theory of stationary phase, but has the disadvantage that it does not include the endpoint case where $p = 2(d+1)/(d+3)$.

\begin{theorem}
  If $p < 2(d+1)/(d+3)$, then for $f \in L^1(\RR^d)$,
  %
  \[ \| R_S f \|_{L^2(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)}. \]
\end{theorem}
\begin{proof}
  We apply a $TT^*$ argument, which can be used to study the boundedness of any operator whose codomain is a Hilbert space. For $f \in L^1(\RR^d)$,
  %
  \[ (E_S R_S f)(x) = \int_S \widehat{f}(\xi) e^{2\pi i \xi \cdot x} d\mu(\xi) = f * \widehat{\nu}. \]
  %
  where $\nu$ is the reflection of $\mu$ about the origin. The $TT^*$ method implies that the restriction estimate we wish to prove holds if and only if we have a bound of the form
  %
  \[ \| E_S R_S f \|_{L^{p'}(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)}. \]
  %
  The operator $E_S R_S$ is just a convolution operator by $\widehat{\nu}$, which makes it much simpler to understand. In particular, the fact that $S$ has nonvanishing curvature means that
  %
  \[ |\widehat{\nu}(\xi)| \lesssim \langle \xi \rangle^{-(d-1)/2}. \]
  %
  This implies that $\widehat{\nu} \in L^r(\RR^d)$ for $r > 2d/(d-1)$, which implies via Young's inequality that
  %
  \[ \| E_S R_S f \|_{L^{p'}(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
  for $p < 4d/(d - 1)$. To improve this bound to hold for $p < 2(d+1)/(d-1)$, we will also exploit the fact that $\nu(B_r(\xi)) \lesssim r^{d-1}$ uniformly over $\xi \in \RR^d$ and $r > 0$.

  Consider a dyadic phase-space decomposition of $\nu$. In other words, fix a bump function $\phi_0 \in C_c^\infty(\RR^d)$ with $\phi_0(x) = 1$ for $|x| \leq 1$, and supported on $|x| \leq 2$. Define $\phi_n(x) = \phi_0(x/2^n) - \phi(x/2^{n-1})$. Then $\phi_n$ is supported on the annulus $2^{n-1} \leq |x| \leq 2^{n+1}$ and $\sum_{n \geq 0} \phi_n = 1$. Define $K_n = \phi_n \widehat{\nu}$ for $n \geq 0$. Then $\| K_n \|_{L^\infty(\RR^d)} \leq 2^{-n(d-1)/2}$, so Young's inequality implies that
  %
  \[ \| f * K_n \|_{L^\infty(\RR^d)} \lesssim 2^{-n(d-1)/2} \| f \|_{L^1(\RR^d)} \]
  %
  On the other hand, $\widehat{K_n} = \widehat{\phi_n} * \mu$, where for all $N > 0$,
  %
  \[ |\widehat{\phi_n}(\xi)| \lesssim_N \frac{2^{dn}}{(1 + 2^n |\xi|)^N} \]
  %
  is a function which rapidly decays for $|\xi| \geq 1/2^n$. Thus a dyadic decomposition with $N > d - 1$ yields
  %
  \begin{align*}
    |\widehat{K_n}(\xi)| &= \left| \int \widehat{\phi_n}(\eta) d\mu(\xi - \eta) \right|\\
    &\lesssim_N 2^{dn} \mu(B_{1/2^n}(\xi)) + \sum_{k = 1}^\infty (2^{dn} / 2^{Nk}) \mu(B_{2^k/2^n})\\
    &\lesssim 2^n + \sum_{k = 1}^\infty 2^{k(d-1)-Nk} 2^n\\
    &\lesssim 2^n.
  \end{align*}
  %
  But this means we have a bound $\| f * K_n \|_{L^2(\RR^d)} \lesssim 2^n \| f \|_{L^2(\RR^d)}$. Interpolating between these two bounds gives that for $p \leq 2$,
  %
  \begin{align*}
    \| f * K_n \|_{L^{p'}(\RR^d)} &\lesssim 2^{-(2/p - 1)n(d-1)/2} 2^{2n(1-1/p)} \| f \|_{L^p(\RR^d)}\\
    &= 2^{n((d+3)/2 - (1/p)(d+1))} \| f \|_{L^p(\RR^d)},
  \end{align*}
  %
  The operator norm bound here decays exponentially for
  %
  \[ p < 2(d+1)/(d+3), \]
  %
  in which case we can sum over $n$ and use the triangle inequality to obtain the bound we desire.
\end{proof}

\begin{remark}
  The only structure we used about $S$ and $\mu$ here is that $\mu$ has a uniform, Frostman type bound, and that $\widehat{\mu}$ has a geometric decay as frequencies become large. For such a pair one has a bound
  %
  \[ \| R_S f \|_{L^2(S,\mu)} \lesssim \| f \|_{L^p(\RR^d)} \]
  %
  provided that $1 \leq p \leq 2(d + \beta - \alpha)/(2d + \beta - 2\alpha)$, where $0 < \alpha < n$, $\beta > 0$, where $|\widehat{\mu}(\xi)| \lesssim \langle \xi \rangle^{-\beta}$ and $|\mu(B_r(x)) \lesssim r^\alpha$.
\end{remark}

The proof at the endpoint $p = 2(d+1)/(d+3)$ is quite different, requiring some analytic interpolation bounds. TODO. In the special case of the sphere, relying on an alternate property of the sphere.

\begin{lemma}
  Let $\sigma$ be the surface measure of the sphere $S = S^{n-1}$. Then $\sigma * \sigma$ is absolutely continuous with respect to the Lebesgue measure, supported on $|\xi| \leq 2$, and on this set,
  %
  \[ (\sigma * \sigma)(\xi) \lesssim \begin{cases} 1/|\xi| &: 0 < |\xi| \leq 1, \\ (2 - |\xi|)^{(n-3)/2} &: 1 \leq |\xi| \leq 2. \end{cases} \]
\end{lemma}
\begin{proof}
  For each $\varepsilon > 0$, let $\sigma_\varepsilon = (1/\varepsilon) \mathbf{I}_{S_\varepsilon}$. Then $\sigma_\varepsilon$ converges weakly to $\sigma$ as $\varepsilon \to 0$, which implies that $(\sigma_\varepsilon * \sigma_\varepsilon)$ converges to $\sigma * \sigma$ weakly. Now $\sigma_\varepsilon * \sigma_\varepsilon$ is radial. Thus it suffices to bound $(\sigma_\varepsilon * \sigma_\varepsilon)(\xi)$ for $\xi = (r,0)$, where $0 < r \leq 2$. Now
  %
  \[ (\sigma_\varepsilon * \sigma_\varepsilon)(\xi) = |S_\varepsilon \cap (\xi + S_\varepsilon)|. \]
  %
  If $(\alpha,\beta) \in S_\varepsilon \cap (\xi + S_\varepsilon)$, where $\alpha \in \RR$, $\beta \in \RR^{n-1}$, then
  %
  \[ 1 - 2\varepsilon \leq \alpha^2 + \beta^2 \leq 1 + 3\varepsilon\quad\text{and}\quad 1 - 2\varepsilon \leq (\alpha - r)^2 + \beta^2 \leq 1 + 3\varepsilon. \]
  %
  Together, these inequalities imply that $\alpha = r/2 + O(\varepsilon/r)$ and thus $\beta^2 = 1 - r^2/4 + O(\varepsilon + \varepsilon^2/r)$, so $\beta = \sqrt{1 - r^2/4} + O()$. TODO Thus $\alpha$ ranges over an interval of length $O(\varepsilon/r)$, and for each $\alpha$, $\beta$ can vary over a region of $n-1$ dimensional volume $O(\varepsilon)$, so we conclude that
\end{proof}

\section{Restriction on the Paraboloid}

The main way we can extend local estimates to global estimates is to apply some kind of symmetry property, normally scaling. Let us use this technique to show that we can extend the result of the Tomas-Stein theorem to give the same bounds for restriction to the non-compact elliptic paraboloid
%
\[ S = \{ (\xi,\omega) \in \RR^{d-1} \times \RR: |\xi|^2 = \omega \}. \]
%
We work with extension estimates, setting, for a function $f: \RR^{d-1} \to \CC$,
%
\[ Ef(x,t) = \int_{\RR^{d-1}} e^{2 \pi i (|\xi|^2 t + \xi \cdot x)} f(\xi)\; d\xi. \]
%
Our goal is to show bounds of the form $\| Ef \|_{L^p(\RR^d)} \lesssim \| f \|_{L^2(\RR^{d-1})}$. This is possible, provided that$p = 2(d+1)/(d+3)$.

\begin{theorem}
  If $p = 2(d+1)/(d+3)$, then for any $f \in \mathcal{S}(\RR^{d-1})$,
  %
  \[ \| Ef \|_{L^{p'}(\RR^d)} \lesssim \| f \|_{L^2(\RR^{d-1})}. \]
\end{theorem}
\begin{proof}
  The Tomas-Stein theorem gives the required bound for any $f \in C_c^\infty(\RR^d)$, where the implicit constant depends on the support of $f$. For such $f$, define
  %
  \[ Ef(x,t) = \int_{\RR^{d-1}} e^{2 \pi i (|\xi|^2 t + \xi \cdot x)} f(\xi)\; d\xi. \]
  %
  We note that $E(\text{Dil}_{\xi,a} f) = a^{d-1} \cdot \text{Dil}_{a^{-2},t} \text{Dil}_{a^{-1},x}(Ef)$, in light of the `parabolic symmetry' of the extension operator. Given a function $f \in C_c^\infty(\RR^d)$ supported on a ball of radius $R$ at the origin, $\text{Dil}_{\xi,1/R} f$ is supported on a ball of radius 1 at the origin, and so Tomas-Stein says that
  %
  \[ \| E(\text{Dil}_{\xi,1/R} f) \|_{L^{p'}(\RR^d)} \lesssim \| \text{Dil}_{\xi,1/R} f \|_{L^2(\RR^{d-1})} = R^{-(d-1)/2} \cdot \| f \|_{L^2(\RR^{d-1})}, \]
  %
  where the implicit constant is independent of $f$. But we also know that
  %
  \begin{align*}
    \| E(\text{Dil}_{\xi,1/R} f) \|_{L^{p'}(\RR^d)} &= R^{1-d} \| \text{Dil}_{R^2,t} \text{Dil}_{R,x}(Ef) \|_{L^{p'}(\RR^d)}\\
    &= R^{1-d} R^{2/p'} R^{(d-1)/p'} \| Ef \|_{L^{p'}(\RR^d)},
  \end{align*}
  %
  and so we conclude that
  %
  \[ \| Ef \|_{L^{p'}(\RR^d)} \lesssim R^{(d-1)/2-(d+1)/p'} \| f \|_{L^2(\RR^{d-1})} = \| f \|_{L^2(\RR^{d-1})}. \]
  %
  In other words, we have found a bound independant of the support of $f$. A simple approximation argument extends the bound to general $f \in \mathcal{S}(\RR^d)$.
\end{proof}

\begin{remark}
  The same scaling symmetries show that we can only have an extension bound
  %
  \[ \| Ef \|_{L^{p'}(\RR^d)} \lesssim \| f \|_{L^{q'}(\RR^{d-1})} \]
  %
  if $(d+1)/p' = (d-1)/q$. For $q = 2$, this shows the above result is tight.
\end{remark}

It is a general heuristic that the extension theory for the paraboloid is essentially the same as the extension theory for a cap of a curve point. In particular, if we have a bound of the form
%
\[ \| Ef \|_{L^{p'}(\RR^d)} \lesssim \| f \|_{L^{q'}(S,\mu)}, \]
%
where $(d+1)/p' = (d-1)/q$, and where $\mu$ is a smooth measure supported on a small cap around the neighbourhood of a point with non-vanishing curvature. One can then approximate the paraboloid by a rescaling of the cap, and thus obtain a bound of the form
%
\[ \| Ef \|_{L^{p'}(\RR^d)} \lesssim \| f \|_{L^{q'}(\RR^{d-1})} \]
%
for any $f \in \mathcal{S}(\RR^{d-1})$, where $E$ is the extension function on the paraboloid TODO: Prove This. Thus, despite one theory being local and the other being global, the theories of these two extension operators are roughly equivalent. Every result obtained in one setting can essentially be translated to the other setting.

\begin{comment}
for all $f \in C_c^\infty(\RR^d)$. For large $R > 0$, let $T_R(x,x_d) = (Rx,R^2x_d + R^4)$, and let $S_R = T_R(S^{d-1})$. Then
%
\[ S_R = \left\{ (x,x_d): |x_d - R^4|^2 = R^4 \left(1 - |x|^2/R^2 \right) \right\}. \]
%
For $f \in L^{q'}(S_R)$, $T_R^*f \in L^{q'}(S^{d-1})$, and
%
\[ \| T_R^* f \|_{L^{q'}(S^{d-1})} = R^{-d/q'} \| f \|_{L^{q'}(S_R)}. \]
%
If we let $E_R f = \widehat{f \cdot \sigma_R}$ be the extension operator associated with $S_R$, where $\sigma_R$ is the surface measure in $S_R$, and let $Ef = \widehat{f \cdot \sigma}$ be the extension operator associated with $S^{d-1}$, where $\sigma$ is the surface area on the unit sphere. Then $(T_R)_* \sigma = R^{-d} \sigma_R$, and so for any given $f \in C_c^\infty(\RR^d)$, we calculate simply that
%
\[ E(T_R^* f)(x,x_d) = R^{-d} e^{2 \pi i x_d} E_R f(x/R,x_d/R^2). \]
%
Thus
%
\[ \| E(T_R^* f) \|_{L^{p'}(\RR^d)} = R^{(d+1)/p'-d} \| E_R f \|_{L^{p'}(\RR^d)} \]
%
Thus we conclude that
%
\[ \| E_R f \|_{L^{p'}(\RR^d)} \lesssim R^{d-(d+1)/p'} \|T_R^* f \|_{L^{q'}(S^{d-1})} = R^{d(1-1/q')-(d+1)/p'} \| f \|_{L^{q'}(S_R)}. \]
%
TODO: Show that restriction for the sphere implies restriction for the paraboloid, and vice versa.
\end{comment}

\section{Restriction to the Cone}

TODO: Conjectured Estimates

TODO: Lorentz Invariant

TODO: Application to the wave equation.

\section{TODO: Hardy Littlewood Majorant Conjecture}




\chapter{Almost Orthogonality}

It is a standard result of Hilbert space theory that if $\{ e_n \}$ are a family of pairwise orthogonal vectors in a Hilbert space $H$, then Parseval's inequality
%
\[ \| \sum_n a_n e_n \|_H = \left( \sum |a_n|^2 \right)^{1/2} \]
%
holds. In many cases in analysis, we do not have \emph{perfect} orthogonality, but we know that $\langle e_n, e_m \rangle$ is small for most pairs $n$ and $m$. For general non-orthogonal vectors we do have the identity
%
\[ \| \sum_n a_n e_n \|_H^2 = \sum a_n \overline{a_m} \langle e_n, e_m \rangle. \]
%
Here is a simple result which exploits this identity.

\begin{lemma}
  Suppose $\{ e_n : n \in \ZZ^d \}$ is a family of vectors such that there is $\delta > 0$ with
  %
  \[ \langle e_n, e_m \rangle \leq \frac{C}{\langle n - m \rangle^{d + \delta}}. \]
  %
  Then
  %
  \[ \| \sum_n a_n e_n \| \lesssim_\delta C^{1/2} \left( \sum |a_n|^2 \right)^{1/2} \]
\end{lemma}
\begin{proof}
  Applying Cauchy-Schwartz and Young's convolution inequality, we conclude that
  %
  \begin{align*}
    \| \sum_n a_n e_n \|_H^2 &\leq C \sum_n |a_n| \sum_m \frac{|a_m|}{\langle n - m \rangle^{d + \delta}}\\
    &\leq C \left( \sum_n |a_n|^2 \right)^{1/2} \left( \sum_n \left( \sum_m \frac{|a_m|}{\langle n - m \rangle^{d + \delta}} \right)^2 \right)^{1/2}\\
    &\lesssim_\delta C \left( \sum_n |a_n|^2 \right).
  \end{align*}
  %
  We then just take square roots on both sides of the formula.
\end{proof}

Let us consider some examples of almost orthogonal systems.

\begin{example}
  Consider $f \in L^2(\RR^d)$ with compact support, and set $e_n = \text{Trans}_n f$. The $\langle e_n, e_m \rangle \neq 0$ only if $|n - m| \lesssim 1$, and then we have the trivial bound $\langle e_n, e_m \rangle \leq \| f \|_{L^2(\RR^d)}^2$. Thus we conclude that
  %
  \[ \| \sum a_n e_n \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)} \left( \sum |a_n|^2 \right)^{1/2}. \]
  %
  In this situation, another way to prove this inequality is to break up the sum into arithmetic subsequences which have a high enough gap so that the sums \emph{are} over functions with disjoint support, in which case we have true orthogonality. Summing up the subsums then gives the result.
\end{example}

\begin{example}
  Given $\phi \in C_c^\infty(\RR^d)$, and consider $e_n = \text{Mod}_n f$. Then
  %
  \[ \langle e_n, e_m \rangle = \int |\phi(x)|^2 e^{2 \pi i (n - m) \cdot x}\; dx. \]
  %
  We can then apply the theorem of nonstationary phase, which gives
  %
  \[ |\langle e_n, e_m \rangle \lesssim_k \frac{1}{\langle n - m \rangle^k} \]
  %
  for any $k$. Thus this is an almost orthogonal system.
\end{example}

For almost orthogonal systems, we do \emph{not} have a lower bound
%
\[ \| \sum a_n e_n \|_{L^2(\RR^d)} \gtrsim \left( \sum |a_n|^2 \right)^{1/2}. \]
%
Indeed, the decay does not preclude us from choosing the same two vectors for different indices, which give complete cancellation for appropriately chosen constants.

\begin{example}
  Consider a family of vectors $\{ e_n \}$ in $L^2(\RR^d)$ such that for each $n$, the support of $e_n$ intersects the support of $O(1)$ other vectors $e_m$. Do we have almost orthogonality here?
\end{example}



The most well used almost orthogonality result is the Cotler-Stein lemma, which enables us to bound sums of operators which are almost orthogonal (the bounded operators from a Hilbert space to itself form a Hilbert space).

\begin{theorem}[Cotler Stein]
  Let $H_1$ and $H_2$ be Hilbert spaces, and consider a family of bounded operators $\{ T_\alpha : H_1 \to H_2 \}$. Let $a_{\alpha \beta} = \| T_\alpha T_\beta^* \|$ and let $b_{\alpha \beta} = \| T_\alpha^* T_\beta \|$. Then if
  %
  \[ A = \sup_\alpha \sum_\beta \sqrt{a_{\alpha \beta}} \quad\text{and}\quad B = \sup_\alpha \sum_\beta \sqrt{b_{\alpha \beta}} \]
  %
  are both finite, then $\sum T_\alpha$ converges unconditionally in the strong operator topology, and
  %
  \[ \left\| \sum T_\alpha \right\| \leq \sqrt{AB}. \]
\end{theorem}

One can often extend almost orthogonality to obtain bounds in other $L^p$ spaces via applying interpolation. Here is such a version I encountered in Heo, Nazarov, and Seeger's paper \emph{Radial Fourier Multipliers in High Dimensions}.

\begin{theorem}
  Consider a family of functions $\{ f_n : n \in \ZZ^d \}$ in $L^2(\RR^d)$, together with a family of sidelength one cubes $\{ Q_n \}$ in $\RR^d$ such that $\text{supp}(f_n) \subset Q_n$. Suppose
  %
  \[ |\langle f_n, f_m \rangle| \leq \frac{1}{\langle n - m \rangle^\beta}. \]
  %
  for some $\beta \in (0,d)$. Then for $p < 2d/(2d - \beta)$,
  %
  \[ \left\| \sum a_n f_n \right\|_{L^p(\RR^d)} \lesssim_{d,\beta,p} \left( \sum |a_n|^p \right)^{1/p} \]
\end{theorem}

\begin{remark}
  If $\beta > d$, then Young's convolution inequality implies that
  %
  \begin{align*}
    \left\| \sum a_n f_n \right\|_{L^2(\RR^d)} &= \left( \sum_{n,m} a_n \overline{a_m} \langle f_n,f_m \rangle \right)^{1/2}\\
    &\leq \left( \sum_{n,m} \frac{a_n \overline{a_m}}{\langle n - m \rangle^\beta} \right)^{1/2}\\
    &\leq \left( \sum_n |a_n|^2 \right)^{1/4} \left( \sum_n \left| \sum_m \frac{\overline{a_m}}{\langle n - m \rangle^\beta} \right|^2 \right)^{1/2}\\
    &\leq \left( \sum_n |a_n|^2 \right)^{1/2} \left( \sum_n \frac{1}{\langle n \rangle^\beta} \right)\\
    &\lesssim_{\beta,d} \left( \sum_n |a_n|^2 \right)^{1/2}
  \end{align*}
  %
  Thus one can view $\beta < d$ as a case where we have some, but not enough orthogonality to prove an $L^2$ orthogonality bound.
\end{remark}

\begin{proof}
  We view this result as proving the boundedness of the operator
  %
  \[ a \mapsto \sum_n a_n f_n \]
  %
  from $l^p(\ZZ^d)$ to $L^p(\RR^d)$. We shall prove that for $1 \leq p \leq 2d/(2d - \beta)$, a \emph{restricted strong type inequality holds}, from which the general bound holds by interpolation. It suffices to show that for any finite set of indices $I \subset \ZZ^d$,
  %
  \[ \| \sum_{n \in I} f_n \|_{L^p(\RR^d)} \lesssim \#(I)^{1/p}. \]
  %
  Partition $\RR^d$ into an almost disjoint family of sidelength one cubes $\{ R_\alpha \}$, define $I_\alpha = \{ n \in I : Q_n \cap R_\alpha \neq \emptyset \}$, and set $F_\alpha = \sum_{n \in I_\alpha} f_n$. Now for each $x \in \RR^d$, there are at most $3^d$ indices $\alpha$ such that $F_\alpha(x) \neq 0$. Thus
  %
  \[ \| \sum_{n \in I} f_n \|_{L^p(\RR^d)} = \| \sum_\alpha F_\alpha \|_{L^p(\RR^d)} \leq 3^d \left( \sum_\alpha \| F_\alpha \|_{L^p(\RR^d)}^p \right)^{1/p}. \]
  %
  Applying the almost-orthogonality of the functions $\{ f_n \}$,
  %
  \begin{align*}
    \| F_\alpha \|_{L^2(\RR^d)}^2 &\leq \sum_{n,m \in I_\alpha} \frac{1}{\langle n - m \rangle^\beta}\\
    &\leq \sum_{n \in I_\alpha} \sum_{|m| \lesssim \#(I_\alpha)^{1/d}} \frac{1}{\langle n - m \rangle^\beta}\\
    &\lesssim \#(I_\alpha) \cdot \#(I_\alpha)^{1-\beta/d}
  \end{align*}
  %
  Thus $\| F_\alpha \|_{L^2(\RR^d)} \lesssim \#(I_\alpha)^{1 - \beta/2d}$. Combined with the fact that $F_\alpha$ is supported on a sidelength $O(1)$ cube, we conclude that for $0 < p \leq 2$, $\| F_\alpha \|_{L^p(\RR^d)} \lesssim_p \| F_\alpha \|_{L^2(\RR^d)}$. But putting this together means that
  %
  \[ \left( \sum_\alpha \| F_\alpha \|_{L^p(\RR^d)}^p \right)^{1/p} = \left( \sum_\alpha \#(I_\alpha)^{p(1 - \beta/2d)} \right)^{1/p} \]
  %
  Provided that $p(1 - \beta/2d) \leq 1$, i.e. $p \leq 2d/(2d - \beta)$, we have
  %
  \[ \sum_\alpha \#(I_\alpha)^{p(1 - \beta/2d)} \leq \sum \#(I_\alpha) = \#(I) \]
  %
  and so we conclude that
  %
  \[ \left( \sum_\alpha \| F_\alpha \|_{L^p(\RR^d)}^p \right)^{1/p} \lesssim \#(I)^{1/p}, \]
  %
  which completes the proof of the restricted strong type bound.
\end{proof}







\chapter{Weighted Estimates}

\section{Hardy-Littlewood Maximal Function}

Let us consider a basic weighted estimate for the Hardy-Littlewood maximal function.

\begin{theorem}
  Suppose $w > 0$ is a measurable function. Then for any $f \in L^1_{\text{loc}}(\RR^d)$, we have the weak type bound
  %
  \[ \int_{\RR^d} \mathbf{I} \left( |Mf(x)| > \lambda \right) w(x)\; dx \lesssim_d \frac{1}{\lambda} \int_{\RR^d} |f(x)| Mw(x)\; dx, \]
  %
  and for all $1 \leq p \leq \infty$, we have the strong type bound
  %
  \[ \left( \int_{\RR^d} |Mf(x)|^p w(x)\; dx \right)^{1/p} \lesssim_{d,p} \left( \int_{\RR^d} |f(x)|^p Mw(x)\; dx \right)^{1/p}. \]
\end{theorem}
\begin{proof}
  The result automatically follows for $p = \infty$, so by the Stein-Weiss interpolation theorem it suffices to obtain the weak-type bound. We work similarily to the standard Vitali-type approach. Renormalizing, to complete the proof it suffices to show that for any compact set $K$ such that $|Mf(x)| > 1$ for all $x \in K$,
  %
  \[ \int_K w(x)\; dx \lesssim_d \int_{\RR^d} |f(x)| Mw(x)\; dx. \]
  %
  Find a disjoint family of balls $B_1,\dots,B_N$ such that $3B_1,\dots,3B_N$ covers $K$, and $\int_{B_i} |f(x)|\; dx \gtrsim_d 1$ for each $i$. Then
  %
  \[ \int_K w(x)\; dx \leq \sum_{i = 1}^N \int_{3B_i} w(x)\; dx \]
  %
  and so it suffices to show that
  %
  \[ \int_{3B_i} w(x)\; dx \lesssim_d \int_{B_i} |f(x)| Mw(x)\; dx. \]
  %
  But for $x \in B_i$, we have
  %
  \[ Mw(x) \gtrsim_d \frac{1}{|B_i|} \int_{3B_i} w(y)\; dy \]
  %
  from which the claim follows.
\end{proof}

A simple corollary is a vector-valued generalization of the Hardy-Littlewood inequality.

\begin{theorem}
  If $1 < p,q < \infty$  and $\{ f_n \}$ are any sequence of functions in $L^1_{\text{loc}}(\RR^d)$, then
  %
  \[ \left\| \left( \sum_n |Mf_n|^p \right)^{1/p} \right\|_{L^q(\RR^d)} \lesssim_{d,p,q} \left\| \left( \sum_n |f_n|^p \right)^{1/p} \right\|_{L^q(\RR^d)} \]
  %
  and
  %
  \[ \left| \left\{ x : \left( \sum_n |Mf_n(x)|^p \right)^{1/p} \geq \lambda \right\} \right| \lesssim_{d,p} \frac{1}{\lambda} \cdot \left\| \left( \sum_n |f_n(x)|^p \right)^{1/p} \right\|_{L^1(\RR^d)}. \]
\end{theorem}
\begin{proof}
  For $p = q$, the theorem follows from the standard Hardy-Littlewood maximal inequality. For $p < q$ we apply the equivalence between vector-valued bounds and weight bounds. To prove the remaining case, it suffices to prove the weak-type estimate for $p > 1$. By linearization, we may find radii $r_n(y)$ such that
  %
  \[ |Mf_n(y)| \leq \frac{1}{|B(y,r_n(y))} \int_{\RR^d} \psi_n(x,y) f_n(y)\; dy, \]
  %
  where $\psi_n(x,y)$ is a smooth bump function which equals one for $x \in B(y,r_n(y))$ and vanishes for $x \not \in 2B(y,r_n(y))$. Thus it suffices to obtain a weak-type bound for the vector-valued operator
  %
  \[ T(\{ f_n \})(y) = \left\{ \int_{\RR^d} \frac{1}{|B(y,r_n(y))|} \psi_n(x,y) f_n(x)\; dx \right\}. \]
  % 
  This is a vector-valued kernel operator with kernel $K(x,y)$ the diagonal matrix with entry. TODO: SEE TAO.
\end{proof}





\chapter{Bellman Function Methods}

It is interesting to ask whether we can obtain bounds of the form
%
\[ \| M f \|_{L^p(\RR^d)} \lesssim_{d,p} \| f \|_{L^p(\RR^d)} \]
%
without employing any interpolation techniques. This is possible, though nontrivial. We begin with a Bellman function approach, which works best in the dyadic scheme, i.e. proving bounds on $M_\Delta$.

The idea here is to perform an \emph{induction on scales}, i.e. to induct on the complexity of the function $f$. For a fixed $f \in L^p(\RR^d)$, our goal is to obtain bounds of the form
%
\[ \left( \int |M_\Delta f(x)|^p\; dx \right)^{1/p} \lesssim \left( \int |f(x)|^p \right)^{1/p} \]
%
where the implicit constant is independent of $p$.

We begin by applying some monotone convergence arguments to simplify our analysis. For each $x \in \RR^d$, $|M_\Delta f(x)| = \lim_{m \to -\infty} |M_{\geq m} f(x)|$, where $M_{\geq m}$ is the operator giving a maximal average over all dyadic cubes containing a point with sidelength exceeding $2^m$, and the limit is monotone increasing. It follows that for any $f \in L^p(\RR^d)$,
%
\[ \| M_\Delta f \|_{L^p(\RR^d)} = \lim_{m \to -\infty} \| M_{\geq m} f \|_{L^p(\RR^d)}. \]
%
Thus if we can obtain a bound
%
\[ \| M_{\geq m} f \|_{L^p(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
with a bound independant of $m$, we would obtain the required bound on $M_\Delta$. But if we could obtain a bound
%
\[ \| M_{\geq 0} f \|_{L^p(\RR^d)} \lesssim \| f \|_{L^p(\RR^d)} \]
%
for all $f \in L^p(\RR^d)$, then a rescaling argument, using the fact that
%
\[ M_{\geq m} f = \text{Dil}_{1/2^d} M_{\geq 0} \text{Dil}_{2^d} f \]
%
shows that we in fact have
%
\begin{align*}
  \| M_{\geq m} f \|_{L^p(\RR^d)} &= 2^{d/p} \| M_{\geq 0} \text{Dil}_{2^d} f \|_{L^p(\RR^d)}\\
  &\lesssim 2^{d/p} \| \text{Dil}_{2^d} f \|_{L^p(\RR^d)} = \| f \|_{L^p(\RR^d)}.
\end{align*}
%
Thus we need only concentrate on the operator $M_{\geq 0}$. Finally, we note we can \emph{localize} our estimates. Given a function $f$ supported on a dyadic cube $Q$ with sidelength $2^n$, and given $x \not \in Q$, then there exists a smallest value $m_x > n$ such that $x$ is contained in a dyadic cube with sidelength $2^{m_x}$ which also contains $Q$. It then follows that
%
\[ (M_{\geq 0} f)(x) = \frac{\int_Q |f(y)|\; dy}{2^{dm_x}} = \frac{\| f \|_{L^1(Q)}}{2^{dm_x}} \]
%
For each $m > n$, if we set $E_m = \{ x \in \RR^d: m_x = m \}$, then $E_m$ is contained in a dyadic cube of sidelength $2^m$, so $|E_m| \leq 2^{dm}$. Thus we have
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(Q^c)} &= \left( \sum_{m = n+1}^\infty \| M_{\geq 0} f \|_{L^p(E_m)}^p \right)^{1/p}\\
  &\leq \left( \sum_{m = n+1}^\infty \left( \| f \|_{L^1(Q)}^p / 2^{dpm} \right) 2^{dm} \right)^{1/p}\\
  &\lesssim_{d,p} \| f \|_{L^1(Q)} 2^{dn(1/p - 1)} = \| f \|_{L^1(Q)} |Q|^{1/p-1} \leq \| f \|_{L^p(Q)}.
\end{align*}
%
Thus, if we obtained the bound $\| M_{\geq 0} f \|_{L^p(Q)} \lesssim \| f \|_{L^p(Q)}$, then we would find
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(\RR^d)} &\leq \| M_{\geq 0} f \|_{L^p(Q)} + \| M_{\geq 0} f \|_{L^p(Q^c)} \lesssim \| f \|_{L^p(Q)}.
\end{align*}
%
Thus if $f$ is supported on a dyadic cube $Q$, it suffices to estimate $M_{\geq 0} f$ on the support of $f$. But by a final monotone convergence argument, it suffices to bound such functions, since given any $n$ we can write $[-2^n,2^n]$ as the almost disjoint union of $2^d$ sidelength $2^d$ dyadic cubes $Q_{n,1},\dots,Q_{n,2^d}$. For any $f \in L^p(\RR^d)$, we consider a pointwise limit $f = \lim_{n \to \infty} f_{n,1} + \dots + f_{n,2^d}$, where $f_{n,i}$ is equal to $f$ restricted to $Q_{n,i}$, and the limit is monotone. We also have
%
\[ M_{\geq 0} f = \lim_{n \to \infty} M_{\geq 0} f_{n,1} + \dots + M_{\geq 0} f_{n,2^d}. \]
%
where the limit is pointwise and monotone, so
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(\RR^d)} &= \lim_{n \to \infty} \| M_{\geq 0} f_{n,1} + \dots + M_{\geq 0} f_{n,2^d} \|_{L^p(\RR^d)}\\
  &\lesssim \lim_{n \to \infty} \| f_{n,1} \|_{L^p(\RR^d)} + \dots + \| f_{n,2^d} \|_{L^p(\RR^d)} \lesssim 2^d \| f \|_{L^p(\RR^d)}.
\end{align*}
%
Thus, after a technical reduction argument, we now show that we only have to establish a bound
%
\[ \| M_{\geq 0} f \|_{L^p(Q)} \lesssim \| f \|_{L^p(Q)}, \]
%
where $f \in L^p(Q)$, $Q$ is a dyadic cube with sidelength $\geq 1$, and the implicit constant is independant of $Q$.

To carry out the inequality, we perform an \emph{induction on scales}. For each $n \geq 0$, we let $C(n)$ denote the optimal constant such that for any function $f \in L^p(\RR^d)$ supported on a dyadic cube $Q$ of sidelength $2^n$,
%
\[ \| M_{\geq 0} f \|_{L^p(Q)} \leq C(n) \cdot \| f \|_{L^p(Q)}. \]
%
If $n = 0$, the problem is trivial, since if $Q$ is dyadic with sidelength $1$ and $x \in Q$, then
%
\[ M_{\geq 0} f = \fint_Q |f(y)|\; dy \]
%
so $\| M_{\geq 0} f \|_{L^p(Q)} = \| f \|_{L^1(Q)}$, and $C(0) = 1$. Our goal is to show that $\sup_{n \geq 0} C(n) < \infty$. Given $f$ supported on a cube $Q$ with sidelength $2^n$, the cube has $2^d$ children $Q_1,\dots,Q_{2^d}$ with sidelength $2^{n-1}$. If we decompose $f = f_1 + \dots + f_{2^d}$ onto these cubes, then by induction we know that
%
\[ \| M_{\geq 0} f_i \|_{L^p(Q_i)} \leq C(n-1) \| f_i \|_{L^p(Q_i)}. \]
%
Now for $x \in Q_i$,
%
\[ (M_{\geq 0} f)(x) = \max \left(M_{\geq 0} f_i(x), \fint_Q |f(y)|\; dy \right). \]
%
Thus if $A = \fint_Q |f(y)|\; dy$, then
%
\begin{align*}
  \| M_{\geq 0} f \|_{L^p(Q)} &= \left( \| M_{\geq 0} f \|_{L^p(Q_1)}^p + \dots + \| M_{\geq 0} f \|_{L^p(Q_{2^d})}^p \right)^{1/p}\\
  &= \left( \| \max(M_{\geq 0} f_1, A) \|_{L^p(Q_1)}^p + \dots + \| \max(M_{\geq 0} f_{2^d}, A) \|_{L^p(Q_{2^d})}^p \right)^{1/p}
\end{align*}
%
The bound $\max(M_{\geq 0} f_i, A) \leq M_{\geq 0} f_i + A$ gives
%
\[ \| M_{\geq 0} f \|_{L^p(Q)} \leq C(n-1) \| f \|_{L^p(Q)} + 2^{d/p} |Q|^{1/p} A = (C(n-1) + 2^{d/p}) \| f \|_{L^p(Q)}. \]
%
This gives $C(n) \leq C(n-1) + 2^{d/p}$, which is not enough to obtain a uniform bound. The idea here is to include more information in our induction hypothesis which gives control on $\max(M_{\geq 0} f_i, A)$. Since $Q$ contains points not in $Q_i$, we need to treat $A$ as an arbitrary quantity in our hypothesis.

To do this, we introduce \emph{cost functions}. For each $A,B,D > 0$ and any integer $n \geq 0$, we let $V_n(A,B,D)$ be the optimal constant such that
%
\[ \| \max(M_{\geq 0} f, A)^p \|_{L^p(Q)} \leq V_n(A,B,D) \]
%
For any function $f$ supported on a dyadic cube $Q$ with sidelength $2^n$, with
%
\[ \| f \|_{L^1(Q)} = B\quad\text{and}\quad \| f \|_{L^p(Q)} = D. \]
%
Our goal will be to show $V_n(A,B,D) \lesssim_p 2^{-dn/p} A + D$ which completes the proof. The role of $B$ is subtle, but will soon become apparan. Of course, we have $\| f \|_{L^1(Q)} \leq 2^{dn(1-1/p)} \| f \|_{L^p(Q)}$, so we have $V_n(A,B,D) = -\infty$ unless $B \leq 2^{dn(1 - 1/p)} D$.

The recursive inequality gives an inequality for the values $V_n(A,B,D)$. TODO: COMPLETE THIS PROOF.

\chapter{$TT^*$ Arguments}

The method of $TT^*$ arguments enables us to obtain bounds on an operator $T$ by exploiting cancellation between an operator and it's adjoint. However, this approach only works when establishing $L^2$ estimates (or at least where one side of an inequality has a norm induced by an inner product). By monotocity, it suffices to consider maximal operators of the form $\max(A_{r_1} f, \dots, A_{r_N} f)$ (provided the implicit constants are independant of $N$),  and by linearization, it suffices to show that for any measurable function $r: \RR^d \to \{ r_1, \dots, r_N \}$,
%
\[ \left( \int |A_{r(x)} f(x)|^p\; dx \right)^{1/p} \lesssim \| f \|_{L^p(\RR^d)} \]
%
where the implicit constant is independant of the function $r$. Thus we consider the linearized operator $M_r: L^2(\RR^d) \to L^2(\RR^d)$ obtained by setting
%
\[ M_r f(y) = (A_{r(y)} f)(y). \]
%
We see easily that $M_r$ is a kernel operator with kernel
%
\[ K(x,y) = \frac{1}{|B_{r(y)}(y)|} \mathbf{I}(|x - y| \leq r(y)). \]
%
Thus
%
\[ M_r^* g(x) = \int_{\RR^d} \frac{\mathbf{I}(|x - y| \leq r(y))}{|B_{r(y)}(y)|} g(y)\; dy, \]
%
and so one can verify that
%
\begin{align*}
  |(M_r M_r^* f)(y)| &= \left| \int_{\RR^d} \int_{\RR^d} \frac{\mathbf{I}(|z - x| \leq r(z)) \mathbf{I}(|y - x| \leq r(y))}{|B(z,r(z))| |B(y,r(y))|} f(z)\; dz\; dx \right|\\
  &= \left| \int_{\RR^d} \int_{\RR^d} \frac{\mathbf{I}(|z - x| \leq r(z)) \mathbf{I}(|y - x| \leq r(y))}{|B(z,r(z))| |B(y,r(y))|} f(z)\; dx\; dz \right|.
\end{align*}
%
For a fixed $z$, the integrand in $x$ vanishes unless $|z - y| \leq r(y) + r(z)$, and in this case we find
%
\[ \left| \int_{\RR^d} \frac{\mathbf{I}(|z - x| \leq r(z)) \mathbf{I}(|y - x| \leq r(y))}{|B(z,r(z))| |B(y,r(y))|} \right| \lesssim_d \frac{1}{\max(r(y)^d, r(z)^d)}. \]
%
Thus we can write
%
\begin{align*}
  |(M_r M_r^* f)(y)| &\lesssim_d \int_{\RR^d} \left( \int_{\substack{|z - y| \leq r(y) + r(z)\\r(y) \leq r(z)}} \frac{|f(z)|}{r(z)^d} + \int_{\substack{|z - y| \leq r(y) + r(z)\\r(y) \geq r(z)}} \frac{|f(z)|}{r(y)^d}\; dx \right)\\
  &\lesssim_d M_{2r}|f|(y) + M_{2r}^* |f|(y).
\end{align*}
%
But we verify by rescaling that $\| M_{2r} \| = \| M_{2r}^* \| = \| M_r \|$, so
%
\[ \| M_r \|^2 = \| M_r M_r^* \| \lesssim_d \| M_r \|. \]
%
But this means that $\| M_r \| \lesssim_d 1$, which gives the bound that we required. Thus we find that the Hardy-Littlewood maximal function is bounded from $L^2(\RR^d)$ to $L^2(\RR^d)$.






\chapter{Maximal Averages Over Curves}

\section{Averages over a Parabola}

Given any measurable function $f: \RR^2 \to \CC$ we can consider the maximal average
%
\[ (Mf)(x,y) = \sup_{\varepsilon > 0} \frac{1}{2\varepsilon} \int_{-\varepsilon}^\varepsilon|f(x+t,y+t)|\; dt. \]
%
Thus $Mf$ gives a maximal average over parabolas. Our goal is to show $\| Mf \|_{L^p(\RR^d)} \lesssim_p \| f \|_{L^p(\RR^d)}$ for $1 < p < \infty$.

It will be convenient to look at the operator
%
\[ \tilde{M} f(x,y) = \sup_{\varepsilon > 0} \frac{1}{2\varepsilon} \int_{\varepsilon/2}^{\varepsilon} |f(x+t,y+t^2)|\; dt. \]
%
A dyadic decomposition shows that $L^p$ bounds for $\tilde{M}$ imply $L^p$ bounds for $M$.

For each $k \in \ZZ$, let $\tilde{M_k} f(x,y) = 2^{-k} \int_{2^k}^{2^{k+1}} f(x+t,y+t^2)\; dt$. Rescaling shows that
%
\[ \| \tilde{M}_k \|_{L^p(\RR^2) \to L^p(\RR^2)} = \| \tilde{M}_0 \|_{L^p(\RR^2) \to L^p(\RR^2)} \]
%
so it suffices to focus on $\tilde{M}_0$. The operator is translation invariant and therefore has a Fourier multiplier
%
\[ \tilde{m}(\xi,\eta) = \int_1^2 e^{2 \pi i (\xi t + \eta t^2)}\; dt. \]
%
Note that $\tilde{m}$ is defined by an oscillatory integral with phase $\phi(t) = \xi t + \eta t^2$. We note that $\phi'(t) = \xi + 2 \eta t$, so Van der Corput's lemma implies that for $|\xi| \geq 10|\eta|$,
%
\[ |\tilde{m}(\xi,\eta)| \lesssim \frac{1}{|\xi|}. \]
%
Similarily, $\phi''(t) = 2 \eta$, so we find
%
\[ |\tilde{m}(\xi,\eta)| \lesssim \frac{1}{|\eta|^{1/2}}. \]
%
If $f \in L^2(\RR^2)$ and $\widehat{f}$ is supported on the region
%
\[ E_0 = \{ (\xi,\eta) : |\eta| \geq 1\ \text{or}\ |\xi| \leq 1\ \text{and} |\eta| \geq 10 \} \]
%
then $\| \tilde{m} \|_{L^\infty(E_0)} \lesssim 1$ and so
%
\[ \| \tilde{M}_0 f \|_{L^2(\RR^2)} = \| \tilde{m} \widehat{f} \|_{L^2(\RR^2)} \lesssim \| \widehat{f} \|_{L^2(\RR^2)} = \| f \|_{L^2(\RR^2)}. \]
%
On the other hand, we can decompose $\RR^2 - E_0$ into

suppose $\widehat{f}$ is supported on the region
%
\[ E_1 = \{ (\xi,\eta) : |\xi| \leq 1\ \text{and}\ |\eta| \leq 10 \}. \]
%
Then the uncertainty principle implies that $f$ is roughly constant on scales $|\Delta x| \leq 1$ and $|\Delta y| \leq 1/10$, which should imply good bounds for the maximal average. More precisely, $\widehat{f}$ is supported on the ellipsoid
%
\[ \left\{ (\xi,\eta) \in \RR^2 : \xi^2/2 + \eta^2/20 \leq 1 \right\}. \]
%
Thus the uncertainty principle implies that $f$ is roughly constant on scales $|\Delta x|^2 \leq 1/2$ and $|\Delta y|^2 \leq 1/20$,
%
\[ s \]
%
\[ \phi(x) = \frac{1}{( 1 + 2 x^2 + 20 y^2 )^N} \]
