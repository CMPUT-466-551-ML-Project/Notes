\documentclass{article}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{amssymb}
\usepackage{mathabx}
\usepackage{accents}
\usepackage[margin=0.7in]{geometry}
\usepackage[english]{babel}
\usepackage{blindtext}

\theoremstyle{plain}
\newtheorem{lemma}{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem*{example}{Example}
\newtheorem*{fact}{Fact}
\newtheorem*{corollary}{Corollary}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem*{remark}{Remark}

\def\changemargin#1#2{\list{}{\rightmargin#2\leftmargin#1}\item[]}
\let\endchangemargin=\endlist 

\DeclareMathOperator{\codim}{codim}

\title{Fractals Avoiding Fractal Sets}

\author{Jacob Denson\\ \and Malabika Pramanik\\ \and Josh Zahl}

\begin{document}

\maketitle

\begin{multicols}{2}

\begin{abstract}
	\blindtext[1]
\end{abstract}

% Ergodic Theoretic Connections: Furstenberg Katznelson and Weiss. Ziegler sets of positive density.

Consider a geometric point configuration, such as three points forming an isoceles triangle in the plane, or four points lying in a plane in $\mathbf{R}^3$. A natural problem is to determine the minimum size a collection of points must be before we can guarantee a subselection lies in a specified configuration. It is often the case that we can obtain arbitrarily large finite sets not containing these configurations. On the other hand, if the configuration is affine invariant, every positive measure set contains these configurations. Thus we need finer analytical measures of size for infinite sets, which is provided by the Hausdorff dimension. The general class of problems for finding high Hausdorff dimension sets avoiding configuration as a {\it configuration avoidance problems}. They can be seen as a continuous analogue to Ramsey theory, and seeing how the continuous setting differs from the discrete counterpart is what makes these problems interesting.

In this paper, we give techniques to {\it construct} sets with high Hausdorff dimension avoiding a very general class of geometric configurations. There are already generic pattern avoidance methods in the literature. We compare our method to them in section 6. But these rely on the non-singular nature of the configurations. The novel feature of our method is we can avoid configurations which have an {\it arbitrary} fractal quality to them. Meanwhile, the Hausdorff dimension of the set we construct still holds up in comparison to previous methods.

The key idea to our method is the introduction of a new geometric framework for pattern avoidance problems, described in section 1. A simple combinatorial argument, described in section 2, exploited repeatedly in section 3 via a queueing process leads directly to a pattern avoiding set. We believe this new geometric framework should help find further methods in the field, which we currently developing for publication in a later paper.

%We show this by proving another pattern avoidance result in section 5, assuming extra geometric information on the patterns.

\section{A Fractal Avoidance Framework}

One way to think about generic pattern avoidance methods is to specify the pattern as the zero set of a function. For example,
%
\begin{itemize}
	\item A set $X \subset \mathbf{R}$ contains no three term arithmetic progressions if and only if for any distinct $x,y,z \in X$,
	%
	\[ f(x,y,z) = x + z - 2y \neq 0  \]
	%
	This function vanishes if and only if there exists $b$ and $t$ such that $x = b$, $y = b+t$, and $z = b+2t$.

	\item A set $X \subset \mathbf{R}^d$ contains the vertices of no isosceles triangles if and only if for any three distinct $x,y,z \in X$,
	%
	\[ f(x,y,z) = d(x,y) - d(y,z) \neq 0 \]
	%
	The problem of avoiding this function is similar to the last example, since isosceles triangles are planar variants of three term arithmetic progressions.

	\item A set $X \subset \mathbf{R}^d$ does not contain a family of angles $\{ \alpha \}$ if and only if for any distinct $x,y,z \in X$, and $\alpha$,
	%
	\[ f(x,y,z) = \frac{(x - z) \cdot (y - z)}{|x - z||y - z|} \neq \cos(\alpha) \]
	%
	where the cosine formula for the dot product is used.

	\item A set $X \subset \mathbf{R}^d$ does not contain $d+1$ points in a lower dimensional hyperplane if and only if for any distinct $x_0, \dots, x_d \in X$,
	%
	\[ f(x_0, \dots, x_d) = \det(x_1 - x_0, \dots, x_d - x_0) \neq 0 \]
	%
	since $\det(x_1 - x_0, \dots, x_d - x_0) = 0$ only when the vectors $x_1 - x_0, \dots, x_d - x_0$ do not form a basis, and thus span a plane of dimension smaller than $d$.
\end{itemize}
%
These problems are summarized by a general framework.

\begin{changemargin}{0.5em}{0em}
{\bf The Configuration Avoidance Problem:} Given a function $f: (\mathbf{R}^d)^n \to \mathbf{R}$ as input, find $X \subset \mathbf{R}^d$ such that for any {\it distinct} $x_1, \dots, x_n \in X$, $f(x_1, \dots, x_n) \neq 0$, with as high a Hausdorff dimension as possible.
\end{changemargin}

The functional framework is common in the literature. For instance, it is the viewpoint behind the methods of \cite{MalabikaRob} and \cite{Mathe}, who give results assuming various regularity conditions on the function $f$. It is the viewpoint of this paper that the function $f$ contains extraneous information which is irrelevant to the problem. The only important information we need to extract from the function $f$ is the geometric structure of it's zero set. If we denote the zero set of $f$ by $Z$, the configuration avoidance problem becomes equivalent to another framework. It is the viewpoint of this paper that this framework is easier to work with, and leads to new general avoidance methods.

\begin{changemargin}{0.5em}{0em}
	{\bf The Fractal Avoidance Problem:} Given $Z \subset (\mathbf{R}^d)^n$, find a high dimensional set $X \subset \mathbf{R}^d$ such that if $x_1, \dots, x_n \in X$ are {\it distinct}, $(x_1, \dots, x_n) \not \in Z$.
\end{changemargin}

Because we are the first to introduce the fractal avoidance problem, a natural goal is to solve the generic problem with minimal assumptions on $Z$. Thus we let $Z$ take the form of an arbitrary fractal, and the only assumptions we place on $Z$ are it's fractal dimension.

\begin{theorem}
	If $Z$ has Minkowski dimension $\alpha \geq d$, then there is $X$ solving the fractal avoidance problem for $Z$ with
	%
	\[ \dim_{\mathbf{H}}(X) = \frac{dn - \alpha}{n - 1} = \frac{\codim_{\mathbf{H}}(Z)}{n - 1} \]
\end{theorem}

\begin{remark}
	If $Z$ has dimension $\alpha < d$, the set obtained from $\mathbf{R}^d$ by removing the projections of $Z$ onto each coordinate has full Hausdorff dimension and trivially solves the fractal avoidance problem. Thus we need not consider these parameters in our theorem.
\end{remark}

Due to the lack of any {\it rigid} geometric information about the set $Z$, we are led to avoid $Z$ by discretization. At the discrete scale, we can efficiently avoid $Z$ by randomly choosing $X$, which we detail in the next section. Exploiting this technique repeatedly at all scales gives a complete avoiding set.

\section{Avoidance at a Single Scale}

We now develop a discrete technique used to construct solutions to the fractal avoidance problem. We assume $Z$ has been discretized into cubes, all of the same fixed length. We then aim to construct a discretized version of $X$ avoiding these cubes.

For a length $L$, we let $\mathcal{B}(L,d)$ denote the partition of $\mathbf{R}^d$ into the family of all half open cubes with corners on the lattice $(\mathbf{Z}/L)^d$. If the dimension $d$ is clear, or unnecessary to the argument, we abbreviate $\mathcal{B}(L,d)$ as $\mathcal{B}(L)$. Families of cubes are denoted using calligraphic font, and the non-calligraphic version of the same character denotes the union of the family. For instance, we might have $\mathcal{I} \subset \mathcal{B}(L)$, and then $I$ is the union of all cubes in $\mathcal{I}$.

\begin{lemma}
	Consider three dyadic scales $L \gg R \gg S$, as well as two collections $\mathcal{I} \subset \mathcal{B}(L,d)$ and $\mathcal{K} \subset \mathcal{B}(S,dn)$. Then there exists $\mathcal{J} \subset \mathcal{B}(S,d)$ with $J \subset I$, such that for any distinct $J_1, \dots, J_n \in \mathcal{J}$, $J_1 \times \dots \times J_n \not \in \mathcal{K}$. Furthermore, for all but at most $|K|R^{-dn}$ of the elements of $\mathcal{B}(R,d)$ intersecting $I$, $J \cap \mathcal{B}(R,d)$ is nonempty.
\end{lemma}
\begin{proof}
	Form a random set $U$ by selecting uniformly randomly, from each $\mathcal{B}(R)$ subcube of $I$, a single subcube in $\mathcal{B}(S)$. The probability that any $\mathcal{B}(R)$ subcube is selected is $(S/R)^d$. Since any two $\mathcal{B}(S)$ subcubes of $U$ lie in distinct elements of $\mathcal{B}(R)$, the only chance that a $\mathcal{B}(S)$ subcube $I$ of $K$ with distinct sides intersects $U^n$ is if $I_1, \dots, I_n$ all lie in separate cubes in $\mathcal{B}(R)$. Then the chance that each occurs is independant of one another, and so
	%
	\begin{align*}
		\mathbf{P}(I \subset U^n) &= \mathbf{P}(I_1 \subset U) \dots \mathbf{P}(I_n \subset U) = (S/R)^{dn}
	\end{align*}
	%
	If $E$ denotes the number of $\mathcal{B}(S)$ subcubes $I$ of $K$ contained in $U^n$,
	%
	\[ \mathbf{E}(E) = \sum_{\substack{I \subset K}} \mathbf{P}(I \subset U^n) = [|K| S^{-dn}] [(S/R)^{dn}] = |K| R^{-dn} \]
	%
	If, for each $\mathcal{B}(S)$ subcube $I$ of $U^n$, we remove $I_1$ from $U$, we obtain a set $J$ with $J_1 \times \dots \times J_n$ disjoint from $K$ for any distinct $\mathcal{B}(R)$ subcubes $J_i$ of $J$. The cube $J$ contains an cube from all but $E$ sidelength $R$ cubes. In particular, we can select some nonrandom choice of $U$ such that $E \leq |K| R^{-dn}$, which gives the required $J$.
\end{proof}

If we obtain $\mathcal{K}$ by discretizing the fractal $Z$, then the size is obviously related to the dimension of $Z$. Quantifying this precisely leads directly to the quantity which will become the Hausdorff dimension of $X$.

\begin{corollary}
	Consider the notation introduced in the last theorem. Fix $0 < \beta < 1$, and suppose $R$ is the closest dyadic number to $S^\beta$. Furthermore, suppose that $|\mathcal{K}| \leq S^{-\gamma}$, and
	%
	\[ 0 < \beta \leq \frac{dn - \gamma - \log_S |I| - \log_S(O(A))}{d(n-1)} \] 
	%
	Then the set $J$ obtained in the last lemma contains a portion of all but a fraction $A$ of all $\mathcal{B}(R)$ subcubes of $I$.
\end{corollary}
\begin{proof}
	The inequality here is equivalent to
	%
	\begin{align*}
		dn - \gamma - \beta(n-1)d &\geq \log_S |I| + \log_S(O(A))
	\end{align*}
	%
	Since $R$ is within a factor of two from $S^\beta$, we compute
	%
	\begin{align*}
		&\frac{\# (\text{$\mathcal{B}(R)$ subcubes not selected from})}{\# (\text{all $\mathcal{B}(R)$ subcubes})} = \frac{|K| R^{-dn}}{|I|R^{-d}}\\
		&\ \ \ \ \ \leq |I|^{-1} S^{dn - \gamma} R^{-(n-1)d} \leq |I|^{-1} S^{dn - \gamma} (S/2)^{-d(n-1)}\\
		&\ \ \ \ \ \leq 2^{\beta d}|I|^{-1} S^{\log_S|I| + \log_S(O(A))} = 2^{\beta d} O(A) \leq A.
	\end{align*}
	%
	At the end, we chose the constant in the $O(A)$ term to be on the order of $2^{-\beta d}$.
\end{proof}

\section{Construction of Avoiding Set}

To construct a set $X$ solving the fractal avoidance problem, we fix a decreasing series of dyadic scales $L_1, L_2, \dots$, which enable us to discretize the problem. We will specify the exact values of these scales later. Since $Z$ has Minkowski dimension $\alpha$, for each $N$ we can find $\mathcal{Z}_N \subset \mathcal{B}(L_N)$ such that $Z \subset Z_N$ for each $N$, and $|\mathcal{Z}_N| \leq 1/L_N^{\alpha + \varepsilon_N}$, where $\varepsilon_N \to 0$ as $N \to \infty$. Given this setup, we construct a nested family of discretized sets $X_1 \supseteq X_2 \supseteq \dots$, with $X = \lim X_N$. One condition that guarantees that $X$ solves the fractal avoidance problem is that $X_N^n$ is disjoint from {\it non diagonal} cubes in $Z_N$. By a non-diagonal cube, we mean a cube $I \subset \mathcal{B}(L_N,dn)$ such that the projections $I_i \in \mathcal{B}(L_N,d)$ onto the $d$ dimensional coordinate axis of $(\mathbf{R}^d)^n$ are distinct.

\begin{lemma}
	If for each $N$, $X_N^n$ avoids non-diagonal cubes in $Z_N$, $X$ solves the fractal avoidance problem for $Z$.
\end{lemma}
\begin{proof}
	Let $z \in Z$ be given with $z_1, \dots, z_n$ are distinct. Set
	%
	\[ \Delta = \{ w \in (\mathbf{R}^d)^n : \text{there exists}\ i,j\ \text{such that}\ w_i = w_j \} \]
	%
	Then $d(\Delta,z) > 0$. In particular, this means that for suitably large $N$, the cube $I$ in $\mathcal{B}(L_N)$ containing $z$ is disjoint from $\Delta$. But this means that $I$ is non diagonal. Thus $z \not \in X_N^d$, and so in particular, is not an element of $X^n$.
\end{proof}

As an initial set, for lack of an interesting choice, we let $X_0 = [0,1]^d$. Given $X_{N-1}$, we define $X_N$ recursively. To do this, we apply the discrete corollary of the last section. The parameters we use are $I = X_{N-1}$, $K = Z_N$, $L = L_{N-1}$, $S = L_N$, and $R$ the closest dyadic number to $L_N^{\beta_N}$, which from now on we denote by $R_N$. The exponent $\beta_N$ is defined as
%
\[ \frac{dn - \alpha - \varepsilon_N - \log_{L_N} |X_{N-1}| - \log_{L_N}(O(1/2^{2N+2}))}{(n-1)d} \]
%
For suitably small choices of $L_N$ relative to $|X_{N-1}|$ and $1/2^{2N+2}$, $0 < \beta_N < 1$. Thus the discrete corollary we described in the last section constructs a set $J$ avoiding nondiagonal cubes in $\mathcal{Z}_N$, and containing a sidelength $L_N$ portion from all but a fraction $1/2^{2N+2}$ of the $\mathcal{B}(R_N)$ cubes in $X_N$. Naturally, we set $X_N = J$. The resulting $X = \lim X_N$ is therefore a solution to the fractal avoidance problem. In the next section, we show that for a sufficiently fast decaying set of lengths $L_N$, $X$ has the Hausdorff dimension we need. This completes the description of our method.

\section{Dimension Bounds}

Now we show that the set $X$ obtained is $\beta d$ dimensional, where $\beta = (dn - \alpha)/d(n-1)$. To offset implicit obstructions to this dimension, we must choose the lengths $L_N$ to decay suitably rapidly. The constraints on $L_N$ will emerge naturally from our arguments, but for the impatient, one such choice is to set $L_N$ to be the closest dyadic number to $2^{-N^2} \left( L_1 \dots L_{N-1} \right)^{Nd(1-\beta)}$. The construction we considered looks like a $d\beta_N$ dimensional set at the discrete scales $L_N$. Another very useful fact is that the construction looks {\it full} dimensional between the scales $L_{N-1}$ and $R_N$ because of the relative uniformity by which we have taken intervals. This enables us to let the scales $L_N$ to decrease arbitrarily rapidly, without penalizing us for initially looking at the Hausdorff dimension at discrete scales.

An initial requirement to get the $\beta d$ dimensional result is to show that $\beta_N \to \beta$ as $N \to \infty$. Otherwise, we do not even get a $\beta d$ dimensional result at the discrete scales. To obtain this, we just require the $L_N$ decrease rapidly in proportion to the exponential $2^{-2N}$ and $|X_{N - 1}|$. We know $\varepsilon_N = o(1)$ provided $L_N \to 0$, which is easy to obtain. If $L_N \lesssim_C 2^{-CN}$ for all large $C > 0$, then $\log_{L_N}(O(1/2^{2N+2})) = o(1)$. Given the bound $L_N \lesssim_C |X_{N-1}|^C$, we conclude $\log_{L_N} |X_{N-1}| = o(1)$. These two constraints thus imply that $\beta_N \to \beta$ as $N \to \infty$. Thus $X$ behaves like a $\beta d$ dimensional set at discrete scales. We first quantify this behaviour by working with a measure supported on $X$, then interpolate to obtain the behaviour at all scales.

Using Frostman's lemma, to prove $X$ has dimension $\beta d$, it suffices to find a non-zero measure $\mu$ supported on $X$ such that for all $\varepsilon > 0$, for all lengths $L$, and for all sidelength $L$ cube $I$, $\mu(I) \lesssim_\varepsilon L^{\beta d - \varepsilon}$. To construct $\mu$, we rely on a variant of the mass distribution principle, i.e. as the weak limit of measures $\mu_N$ supported on the discrete sets $X_N$. Initially, we put the uniform probability measure $\mu_0$ on $X_0 = [0,1]^d$. We then define $\mu_N$, supported on $X_N$, by modifying the distribution of $\mu_{N-1}$. First, we throw away the mass of the $\mathcal{B}(L_{N-1})$ cubes $I$ in $X_{N-1}$ for which $X_N$ fails to contain a $\mathcal{B}(L_N)$ cube in more than half of the $\mathcal{B}(R_N)$ subcubes of $I$. For the remaining cubes $I$, we uniformly distribute the mass $\mu_{N-1}(I)$ over the cubes in $X_N$ contained in $I$. Throwing away mass is necessary to avoid the mass of $\mu_N$ clumping in undesirable places. It is easy to see from the cumulative distribution functions of the $\mu_N$ that $\mu_N$ converges weakly to a limit $\mu$. The measure $\mu$ has the property that for any $I \in \mathcal{B}(L_N)$, $\mu(I) \leq \mu_N(I)$, which is useful from passing from discrete results about our construction to properties of the final measure. The measure $\mu$ is the measure for which we will ultimately obtain a Frostman type inequality.

\begin{lemma}
	If $N \geq 1$, and $I \in \mathcal{B}(L_N)$,
	%
	\[ \mu(I) \leq \mu_N(I) \leq 2^N \left[ \frac{R_N R_{N-1} \dots R_1}{L_{N-1} \dots L_1} \right]^d \]
\end{lemma}
\begin{proof}
	Consider $I \in \mathcal{B}(L_N)$, $J \in \mathcal{B}(L_{N-1})$. If $\mu_N(I) > 0$, this means that $J$ contains a $\mathcal{B}(L_N)$ cube in at least half of the $\mathcal{B}(R_N)$ cubes it contains. Thus the mass of $J$ distributes itself evenly over at least $2^{-1} (L_{N-1}/R_N)^d$ cubes, which gives that $\mu_N(I) \leq 2(R_N/L_{N-1})^d \mu_{N-1}(J)$. But then expanding this recursive inequality, we obtain exactly the result we need.
\end{proof}

\begin{corollary}
	The measure $\mu$ is positive.
\end{corollary}
\begin{proof}
	To prove this result, it suffices to show that the total mass of $\mu_N$ is bounded below, independantly of $N$. At each stage $N$, $X_N$ consists of at most
	%
	\[ \left[ \frac{L_{N-1} \dots L_1}{R_N \dots R_1} \right]^d \]
	%
	$\mathcal{B}(L_N)$ cubes. Since only a fraction $1/2^{2N+2}$ of the $\mathcal{B}(R_N)$ cubes do not contain an interval in $X_{N+1}$, it is only for at most a fraction $1/2^{2N+1}$ of the $\mathcal{B}(L_N)$ cubes that $X_{N+1}$ fails to contain a $\mathcal{B}(L_{N+1})$ cube from more than half of the $\mathcal{B}(R_{N+1})$ cubes. Using the last lemma, this means that in the passage from $\mu_N$ to $\mu_{N+1}$, we discard a mass of at most $1/2^{N+1}$. Thus
	%
	\[ \mu_N(\mathbf{R}^d) \geq 1 - \sum_{k = 0}^N \frac{1}{2^{k+1}} \geq 1/2 \]
	%
	Thus $\mu(\mathbf{R}^d) \geq 1/2$, and in particular, $\mu \neq 0$.
\end{proof}

%It is intuitive that the mass on $\mu$ will distribute more thinly at each stage the fatter the cubes we keep on each iteration of the discrete scale argument. Quantifying this leads directly to our result. We will prove that for each length $L$ interval $I$, $\mu(I) \lesssim_N L^{\beta_N}$. Thus Frostman's lemma guarantees that $\dim_{\mathbf{H}}(X) \geq \beta_N$, and taking $\beta_N \to \beta$ will complete the proof.

We fix an increasing sequence $\lambda_N$ with $\lambda_N < \beta_N$, and $\lambda_N \to \beta$ as $N \to \infty$. This gives us slightly more room to bound mass when obtaining the Frostman's lemma result. We set $\lambda_N - \beta_N = 1/N$ to obtain the choice of $L_N$ given as an example.

\begin{corollary}
	If $L_N \ll 1$, $\mu(I) \leq L_N^{d \lambda_N}$ for $I \in \mathcal{B}(L_N)$.
\end{corollary}
\begin{proof}
	We can rewrite the inequality in the last problem as
	%
	\[ \mu(I) \leq \left[ 2^N \left( \frac{R_{N-1} \dots R_1}{L_{N-1} \dots L_1} \right)^d R_N^d L_N^{- d \lambda_N} \right] L_N^{d\lambda_N} \]
	%
	Now $R_N^d L_N^{-d\lambda_N} \leq (2L_N^{\beta_N})^d L_N^{-d\lambda_N} \leq 2^d L_N^{d(\beta_N - \lambda_N)}$, which tends to zero as $L_N \to \infty$, while the remaining parameters are fixed. Thus if $L_N$ is sufficiently small, we can bound the constant in the square brackets by $1$, which is sufficient to obtain the inequality.
\end{proof}

This is the cleanest expression of the $d \beta$ dimensional behaviour at discrete scales. To get a general inequality of this form, we use the fact that our construction distributes uniformly across all intervals.

\begin{theorem}
	Assume the last corollary holds. If $L \leq L_N$ is dyadic and $I \in \mathcal{B}(L)$, then $\mu(I) \leq 2 L^{\lambda_N}$.
\end{theorem}
\begin{proof}
	We break our analysis into three cases, depending on the size of $L$ in proportion to $L_N$ and $R_N$:
	%
	\begin{itemize}
		\item If $R_{N+1} \leq L \leq L_N$, we can cover $I$ by $(L/R_{N+1})^d$ cubes in $\mathcal{B}(R_{N+1})$. For each of these cubes, we know the mass is bounded by at most $2(R_{N+1}/L_{N+1})^d$ times the mass of a $\mathcal{B}(L_N)$ cube. Thus
		%
		\begin{align*}
			\mu(I) &\leq [(L/R_{N+1})^d] [2(R_{N+1}/L_N)^d] [L_N^{\lambda_N}]\\
			&\leq 2 L^d L_N^{d - \lambda_N} \leq 2 L^{\lambda_N}
		\end{align*}

		\item If $L_{N+1} \leq L \leq R_{N+1}$, we can cover $I$ by a single cube in $\mathcal{B}(R_{N+1})$. Each cube in $\mathcal{B}(R_{N+1},d)$ contains at most one cube in $\mathcal{B}(L_{N+1},d)$ which is also contained in $X_{N+1}$, so $\mu(I) \leq L_{N+1}^{d\lambda_{N+1}} \leq L^{d \lambda_N}$.

		\item If $L \leq L_{N+1}$, there certainly exists $M$ such that $L_{M+1} \leq L \leq L_M$, and one of the previous cases yields that $\mu(I) \leq 2 L^{\lambda_M} \leq 2 L^{\lambda_N}$.
	\end{itemize}
	%
	This addresses all cases considered in the theorem.
\end{proof}

To use Frostman's lemma, we need the result $\mu(I) \lesssim L^{\lambda_N}$ for an {\it arbitrary} interval, not just one with $L \leq L_N$. But this is no trouble; it is only the behavior of the measure on arbitrarily small scales that matters. This is because if $L \geq L_N$, then $\mu(I)/L^{\lambda_N} \leq 1/L_N^{\lambda_N} \lesssim_N 1$, so $\mu(I) \lesssim_N L^{\lambda_N}$ holds automatically for all sufficiently large intervals. Thus the general bound is complete, and we have proven that there is a choice of parameters which constructs a set $X$ with Hausdorff dimension no less than $(dn - \alpha)/(n-1)$. It is also easy to see $X$ has {\it precisely} this dimension.

\begin{theorem}
	$\dim_{\mathbf{H}}(X) \leq (dn - \alpha)/(n-1)$.
\end{theorem}
\begin{proof}
	$X_N$ is covered by at most
	%
	\[ \left[ \frac{L_{N-1} \dots L_1}{R_N \dots R_1} \right]^d \]
	%
	sidelength $L_N$ cubes. It follows that if $\gamma > \beta$, then
	%
	\[ H^{d\gamma}_{L_N}(X) \leq \left[ \frac{L_{N-1} \dots L_1}{R_N \dots R_1} L_N^\gamma \right]^d \lesssim \left[ \frac{L_{N-1} \dots L_1}{R_{N-1} \dots R_1} L_N^{\gamma - \beta} \right]^d \]
	%
	Thus if $L_N$ is suitably small depending on previous constants, which we know to be true from the last corollary, we conclude that as $N \to \infty$, $H^\gamma(X)$ is finite. Since $\gamma$ was arbitrary, taking it to $\beta$ allows us to conclude that $\dim_{\mathbf{H}}(X) \leq d \beta$.
\end{proof}

%\section{Low Rank Projection Method}

%We now introduce a method which enables us to find a higher dimensional subset $X$, under some `low rank' assumptions about the set $Z$. The theorem below should be compared to Theorem 3. We will substitute the theorem below in the construction of our solutions to the fractal avoidance problem to improve the Hausdorff dimension.

%\begin{theorem}
%	Let $\mathcal{I}_1, \dots, \mathcal{I}_n$ be disjoint collections of cubes in $\mathcal{B}(1/N,d)$, with $|\mathcal{I}_i| \gtrsim N^d$. If there is a linear transformation $T: \mathbf{R}^{nd} \to \mathbf{R}^{nk}$ with rational coefficients such that the Minkowski dimension of $T(Z)$ is bounded above by $\alpha$, and $\beta$ is a rational parameter such that $\beta > d(k-1)/(dk - \alpha - k)$, then for arbitrarily large $N$ such that $N^\beta$ is an integer, there exists collections of cubes $\mathcal{J}_1, \dots, \mathcal{J}_n \in \mathcal{B}(1/N^\beta,d)$ with each cube in $\mathcal{J}_1 \times \dots \times \mathcal{J}_n \subset \mathcal{B}(1/N^\beta,nd)$ disjoint from $Y$, and as $N \to \infty$, each $\mathcal{J}_i$ contains cubes in all but a fraction $o(1)$ of cubes in $\mathcal{I}_i$.
%\end{theorem}
%\begin{proof}
%	Since for any integer $M$, $M \cdot T(Z)$ has the same Minkowski dimension as $T(Z)$, we may without loss of generality assume by multiplying by a large enough $M$ that $T$ has integer coefficients. Write $T(x) = S(x_1) + U(x_2)$, where $x_1$ is a subset of $kd$ coordinates of $x$, $x_2$ are the remaining $(n-k)d$ coordinates, and $S$ is invertible. Let $\mathcal{J}_{k+1}, \dots, \mathcal{J}_n \subset \mathcal{B}(1/N^\beta,d)$ be the set of cubes contained in a cube in $\mathcal{I}_{k+1}, \dots, \mathcal{I}_n$ and also containing a point in the lattice $(\mathbf{Z}/N)^{d(n-k)}$. We then consider the set $\mathcal{K}$ of cubes in $\mathcal{B}(1/N^\beta,kd)$ intersecting the image of some cube in $U(\mathcal{J}_{k+1}, \dots, \mathcal{J}_n)$. Because $U$ is integral, if $x \in (\mathbf{Z}/N)^{d(n-k)}$, then $U(x) \in (\mathbf{Z}/N)^{dk}$. Since all points in cubes in $\mathcal{J}_{k+1}, \dots, \mathcal{J}_n$ are contained in a $1/N^\beta$ thickening of the lattice $(\mathbf{Z}/N)^{d(n-k)}$, their image under $U$ is contained in a $\lesssim 1/N^\beta$ thickening of the lattice $(\mathbf{Z}/N)^{dk}$. Since the image of the cubes $U(\mathcal{J}_{k+1}, \dots, \mathcal{J}_n)$ is a bounded set, this implies $|\mathcal{K}| \lesssim N^{dk}$. If we let
	%
%	\begin{align*}
%		\mathcal{Z} = &\{ I \in \mathcal{B}(1/N^\beta,dk):\\
%		&\ \ \ \text{there is}\ J \in \mathcal{K}\ \text{s.t.}\ (S(I) + J) \cap T(Z) \neq \emptyset \}
%	\end{align*}
	%
%	and we form a graph $G$ on the side length $1/N^\beta$ cubes in $\mathcal{J}_1, \dots, \mathcal{J}_k$ where there is an edge between $I_1, \dots, I_k$ if their Cartesian product lies in $\mathcal{Z}$, then an independent set $\mathcal{J}_1, \dots, \mathcal{J}_k$ gives a candidate solution $\mathcal{J}_1, \dots, \mathcal{J}_n$ for the entire theorem. Since $T(Z)$ intersects $O(N^{\alpha \beta})$ cubes in $\mathcal{B}(1/N^\beta,dk)$, $|\mathcal{K}| \lesssim N^{dk}$, and $S$ is invertible, $\mathcal{Z}$ contains $O(N^{dk + \alpha \beta})$ cubes. Then $G$ has $\Omega(N^{d \beta})$ vertices, $O(N^{dk + \alpha \beta})$ edges, and if we consider the coloring as in the previous problem, an $\Omega(N^{d(\beta - 1)})$ uniform coloring. Thus when applying the discrete corollary, we have $a = d \beta$, $b = dk + \alpha \beta$, and $c = d(\beta - 1)$. The inequality
	%
%	\[ \beta > d \cdot \frac{2k - 1}{dk - \alpha} \]
	%
%	is equivalent to the equality $b < a + c(k-1)$, which allows us to use the corollary to obtain the required result.
%\end{proof}

%Following our proof constructing $X$, as well as proving it's Hausdorff dimension, but using the lemma above instead of the standard lemma, and replacing the $\beta$ in this proof with the $\beta$ in the lemma above, we obtain $X$ solving the fractal avoidance problem for $Z$ with
%
%\[ \dim_{\mathbf{H}}(X) = \frac{dk - \alpha}{2k - 1} \]
%
%The fact that the dimension is independent of $n$ has some interesting consequences. In particular, it can be used to solve problems involving infinitely many variables.

%\begin{theorem}
%	Let $Z$ be a zero set, and let $f: \mathbf{R}^{nd} \to \mathbf{R}^{kd}$ be a polynomial map with degree at most $m$ such that $f(Z)$ is $\alpha$ dimensional. Then can we improve our result?
%\end{theorem}

\section{Applications}

%\begin{example}
%	Consider $Z = \{ (x,y): \mathbf{R}^{m+1}: y = f(Sx) \}$, where $S: \mathbf{R}^m \to \mathbf{R}^l$. If we consider the map $T(x,y) = (Sx,y)$, then $T(Z) = \{ (a,b) \in \mathbf{R}^{l+1}: b = f(a) \}$. This is a hypersurface of dimension $l$. Applying the result above with $k = l+1$, $d = 1$, and $\alpha = l$, we find a set $X$ with Hausdorff dimension $1/(2l + 1)$. This isn't exactly what we want, so maybe the proof can be fine tuned.
%\end{example}

\section{Comparison with Other Generic Avoidance Schemes}

In the past few years in the discrete setting it has been noticed that rephrasing particular questions in terms of abstract problems on hypergraphs allows one to extend various results into sparse analogues \cite{BaloghMorrisSamotij}. In this paper we consider a continuous analogue, where sparsity is represented in terms of the dimension of the set $Z$ we are trying to avoid.

\section{Concluding Remarks}



Another goal of our current research programme is to show an example of a fractal avoidance problem where extra geometric conditions on $Z$ leads to constructions with a higher Hausdorff dimension. This means that our framework isn't designed for a single method, but naturally incorporates further methods in the field. We consider a condition where $Z$ is efficiently coverable by parallel hyperplanes of a fixed dimension.

\begin{theorem}
	If there is $k \geq 2$ and a linear $T: \mathbf{R}^{dn} \to \mathbf{R}^{kd}$ such that $T(Z)$ is $\alpha$ dimensional, with $\alpha \leq (d-1)k$, then there exists $X$ with
	%
	\[ \dim_{\mathbf{H}}(X) = \frac{dk - \alpha}{2k-1} \]
	%
	solving the fractal avoidance problem for $Z$.
\end{theorem}

\begin{thebibliography}{9}

\bibitem{KeletiDimOneSet}
Tam\'{a}s Keleti
\textit{A 1-Dimensional Subset of the Reals that Intersects Each of its Translates in at Most a Single Point}

\bibitem{MalabikaRob}
Robert Fraser, Malabika Pramanik
\textit{Large Sets Avoiding Patterns}

\bibitem{Mathe}
A. Ma\'{t}h\'{e}
\textit{Sets of Large Dimension Not Containing Polynomial Configurations}

\bibitem{BaloghMorrisSamotij}
J\'{o}zsef Balogh, Robert Morris, Wojceich Samotij
\textit{Independent Sets in Hypergraphs}

\bibitem{David}
Guy David
\textit{Bounded singular integrals on a Cantor set}

\bibitem{Vasilis}
Vasilis Chousionis
\textit{Singular Integrals On Sierpinski Gaskets}

\bibitem{Bennett}
Michael Bennett, Alex Iosevich, Krystal Taylor
\textit{Finite Chains Inside Thin Subsets of $\mathbf{R}^d$}

\end{thebibliography}

\end{multicols}

\end{document}

Once we have discretized the problem, the Euclidean structure of the setting becomes irrelevant. As such, we rephrase our single scale avoidance method as a combinatorial problem on graphs. Here we prove a form of Tur\'{a}n's theorem, which quantifies the idea that graphs with few edges contain large independant sets. In the next section, we apply this theorem to find large discretized sets avoiding a discretization of the fractal we are required to avoid. Exploiting this repeatedly at an infinite series of discretizations then gives a set completely avoiding the required fractal.

Recalling notation, we consider a fixed set of $V$ elements, whose points we call {\it vertices}. A set of $n$ {\it distinct} vertices will be called an {\it $n$ vertex hyperedge}. The structure consisting of a set of vertices, and a family of $n$ vertex hyperedges on those vertices, will be called an {\it $n$ uniform hypergraph}. We let $E$ denote the number of edges in such a graph. A subset of vertices which does not contain any hyperedge as a subset is known as an {\it independent set}. We will consider partitions of the vertex set, and we say a partition is {\it $K$ spread} if there are at least $K$ vertices in each equivalence class.

\begin{lemma}
	Every $n$ uniform hypergraph with a $K$ spread partition contains an independent set with elements selected from all but at most $E/K^n$ equivalence classes.
\end{lemma}
\begin{proof}
	Let $X$ be a random vertex set chosen by selecting a representative vertex from every equivalence class uniformly at random. Then every vertex occurs in $X$ with probability at most $1/K$. If an edge $e = \{ v_1, \dots, v_n \}$ satisfies $\mathbf{P}(v_1, \dots, v_n \in X) > 0$, then the $v_1, \dots, v_n$ are distinct, and lie in separate equivalence classes of the partition. This implies that $v_1, \dots, v_n$ each occur in $X$ with independant likelihood, so a bound on the probability that all vertices in $e$ lie in $X$ is
	%
	\begin{align*}
		\mathbf{P}(v_1, \dots, v_n \in X) = \mathbf{P}(v_1 \in V) \dots \mathbf{P}(v_n \in X) \leq 1/K^n
	\end{align*}
	%
	If $E_0$ denotes the number of edges $e = \{ v_1, \dots, v_n \}$ with $v_1, \dots, v_n \in X$, then
	%
	\begin{align*}
		\mathbf{E}(E_0) = \sum_{e \in E} \mathbf{P}(e \in E_0) \leq \sum_{e \in E} 1/K^n = E/K^n
	\end{align*}
	%
	This means we may choose a particular, {\it nonrandom} $X$ for which $E_0 \leq E/K^n$. If we form a vertex set $W \subset V$ by removing, for each $e \in E_0$, a vertex in $X$ adjacent to $e$, then $W$ is an independent set containing representatives from all but $E_0 \leq E/K^n$ equivalence classes of the partition.
\end{proof}

%\begin{corollary}
%	If $|V| \gtrsim N^a$, $|E| \lesssim N^b$, and $K \gtrsim N^c$, where $b < a + c(n-1)$, then as $N \to \infty$ we can find an independent set containing all but a fraction $o(1)$ of the colors.
%\end{corollary}
%\begin{proof}
%	A simple calculation on the quantities of the previous lemma yields
	%
%	\begin{align*}
%		\frac{\# ( \text{colors removed} )}{\# ( \text{all colors} )} = \frac{|E|/K^n}{|V|/K} = \frac{|E|}{|V|K^{n-1}} \lesssim \frac{N^b}{N^{a + c(n-1)}}
%	\end{align*}
	%
%	This is $o(1)$ if $b < a + c(n-1)$.
%\end{proof}

%To apply the theorem to fractals, we will take cubes in the Euclidean plane as our vertices, and connect an edge between cubes if their cartesian product intersects a portion of $Y$. For technical reasons, we require that the cubes are essentially uniformly chosen across the candidate set of choices, and this is the reason for the introduction of partitions of vertices in the graph theory result above.

An important feature of our bound on the independant set selected is the ratio between the number of equivalence classes we choose versus the total number of equivalence classes. Since each class contains $K$ elements, there are $V/K$ equivalence classes. We calculate
%
\[ \frac{\# (\text{classes not chosen})}{\# (\text{total classes})} \leq \frac{E/K^n}{V/K} \leq \frac{E/V}{K^{n-1}} \]
%
To make this ratio small, we upper bound $E$, and lower bound $V$ and $K$.

%In our case, $E$ will be dependant on the Hausdorff dimension of $Y$, $V$ will depend on the sidelength

%In our case, we get few edges if our set $Y$ has low Hausdorff dimension, and we have lots of vertices if we choose a proportionally small sidelengths for our cubes.

%We now apply these constructions to a problem clearly related to the fractal avoidance problem. It will form our key method to construct fractal avoidance solutions. Given a real number $L$, we subdivide $\mathbf{R}^d$ into a lattice of side length $L$ cubes with corners on $L \cdot \mathbf{Z}^d$, the collection of such cubes we will denote by $\mathcal{B}(L,d)$. This grid is used to granularize configuration avoidance.

%\begin{theorem}
%	Suppose $\mathcal{I}_1, \dots, \mathcal{I}_n$ are disjoint collections of cubes in $\mathcal{B}(L,d)$, with $|\mathcal{I}_i| \gtrsim (1/L)^d$. If $\alpha$ strictly bounds the lower Minkowski dimension of $Z$ from above, and a rational parameter
	%
%	\[ \beta > \max \left(1, d \cdot \frac{n-1}{nd-\alpha} \right) \]
	%
%	is fixed, then there exists collections of cubes $\mathcal{J}_1, \dots, \mathcal{J}_n \in \mathcal{B}(L^\beta,d)$ with each cube in $\mathcal{J}_1 \times \dots \times \mathcal{J}_n$ disjoint from $Z$, and each $\mathcal{J}_i$ containing cubes in all but a fraction $o(1)$ of cubes in $\mathcal{I}_i$ as $L \to 0$.
%\end{theorem}
%\begin{proof}
%	We reduce this problem to the independent set problem we just proved a result about. We define the discretization of $Z$ to be
	%
%	\[ \mathcal{Z} = \{ I \in \mathcal{B}(L^\beta,nd) : I \cap Z \neq \emptyset \} \]
	%
%	For each $i$, we set
	%
%	\[ \mathcal{I}_i' = \{ I \in \mathcal{B}(L^\beta,d) : \text{there is}\ J \in \mathcal{I}_i\ \text{s.t.}\ I \subset J \} \]
	%
%	We obtain an $n$ uniform hypergraph $G$ by taking the cubes in $\mathcal{I}_1', \dots, \mathcal{I}_n'$ as vertices, with a hyperedge between $I_1 \in \mathcal{I}'_1, \dots, I_n \in \mathcal{I}'_n$ if $I_1 \times \dots \times I_n \in \mathcal{Z}$. We then take a coloring on $G$ by declaring two cubes in $\mathcal{I}_i'$ to be the same color if they are contained in a common cube in $\mathcal{I}_i$. In particular, this gives us a true coloring because every color occurs solely in $\mathcal{I}_i$ for some index $i$, and every edge in the hypergraph contains exactly one vertex from each index. An independent set in this graph can be written as $\mathcal{J}_1, \dots, \mathcal{J}_n$, where the $\mathcal{J}_i$ are collections of cubes which are sub-cubes of cubes in $\mathcal{I}_i$ and no cube in $\mathcal{J}_1 \times \dots \times \mathcal{J}_n \subset \mathcal{B}(1/N^\beta,nd)$ intersects $Z$. Thus to prove the theorem it suffices to find a large independent set in this graph.

%	We employ the corollary we just proved to do this, by bounding the number of vertices and edges in $G$. Since a cube in $\mathcal{B}(L,d)$ contains $\Omega(1/L^{d(\beta-1)})$ cubes in $\mathcal{B}(L^\beta,d)$, we conclude that $|\mathcal{I}'_i| \gtrsim (1/L)^{d(\beta - 1)} |\mathcal{I}_i| \gtrsim (1/L)^{d \beta}$. But then the number of vertices of $G$ is $\sum |\mathcal{I}'_i| \gtrsim (1/L)^{d \beta}$. The Minkowski dimension bound on $Z$ implies that the number of edges in $G$ is bounded above by $|\mathcal{Z}| \lesssim (1/L)^{\alpha \beta}$,Finally, the coloring is $N^{d(\beta - 1)}$ uniform. Thus in the terminology of the previous corollary, $a = d \beta$, $b = \alpha \beta$, and $c = d(\beta - 1)$. The inequality $\beta > d(n-1)/(nd - \alpha)$, is equivalent to the inequality $b < a + c(n-1)$, and so the corollary applies to give the required result.
%\end{proof}

%The value $d \cdot (n-1)/(n-\alpha)$ in the theorem is directly related to the dimension $(n-\alpha)/(n-1)$ we get in our main result. If, for a specific $Z$, we can prove a variant of this lemma with $d \cdot (n-1)/(n-\alpha)$ replaced with $d/\lambda$, then going through the rest of our proof will immediately yield $X$ with Hausdorff dimension $\lambda$. In particular, to prove our second result it will suffice to prove the theorem above given that $Z$ has a low rank assumption and $d \cdot (n-1)/(n-\alpha)$ is replaced with $d \cdot(2k-1)/(dk - k - \alpha)$.

% TODO: Include Tightness Calculation?