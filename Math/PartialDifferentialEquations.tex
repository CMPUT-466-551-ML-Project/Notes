\input{../style.tex}

\title{Partial Differential Equations}
\author{Jacob Denson}

\begin{document}

\pagenumbering{gobble}

\maketitle

\tableofcontents

\pagenumbering{arabic}

\part{Classical PDEs}

\chapter{Introduction}

Physicists were the first to consider partial differential equations. Physical problems provided the insight for many of the basic techniques to solving partial differential equations, and it removes something from the subject to forget the physical motivations for partial differential equations. In this chapter, we derive the four main partial differential equations which began the study of partial differential equations. These equations all involve the most important partial differential operator, the {\bf Laplacian} operator
%
\[ \Delta = \sum \frac{\partial^2}{\partial x_i^2} = \nabla \cdot \nabla \]
%
Recall that we can interpret the value $\Delta f(x)$, up to a scale factor depending on dimension, as the second order term of the average difference $f(y) - f(x)$ in an infinitisimal neighbourhood of $x$.

\section{The Transport Equation}

Suppose we wish to model mass travelling in the direction of a single vector $a \in \mathbf{R}^d$. If $u(x,t)$ is a mass distribution, and $\Omega$ is some region, then the change in volume in $\Omega$ over time is the amount of volume entering $\Omega$, and the amount leaving $\Omega$. This can just be measured by the directional derivative of $u$ in the direction of $a$. Thus
%
\[ \int_\Omega \frac{\partial u}{\partial t}\ dx = \frac{\partial}{\partial t} \int_\Omega u(x,t) dx = - \int_{\partial \Omega} (ua \cdot \nu)\ d\sigma(x) \]
%
Now applying the divergence theorem, we find
%
\[ \int_{\partial \Omega} (ua \cdot \nu)\ d\sigma(x) = \int_\Omega \nabla \cdot ua\  dx = \int_\Omega \nabla u \cdot a\ dx \]
%
Since $\Omega$ was an arbitrary subset of $\mathbf{R}^d$ with smooth boundary, we conclude that $u$ satisfies the partial differential equation
%
\[ \frac{\partial u}{\partial t} + \nabla u \cdot a = 0 \]
%
This is the {\bf transport equation}. If, in addition, there is a source function $f: \mathbf{R}^d \to \mathbf{R}$, which constantly either produces or removes mass from a location, then we find the integral equation is
%
\[ \int_\Omega \frac{\partial u}{\partial t}\ dx = \int_\Omega f - \nabla u \cdot a\ dx \]
%
and we obtain the non homogenous heat equation
%
\[ \frac{\partial u}{\partial t} + \nabla u \cdot a = f \]
%
which is only slightly harder to solve.

\section{The Heat Equation}

Consider a region $\Omega$ in space, where we fix a temperature on the boundary, and then allow temperature to fluctuate on the interior on its own volition. Let $u(t,x)$ represent a density for the temperature at $x \in \Omega$ at time $t$. Given a subregion $D \subset \Omega$, the value
%
\[ \frac{d}{dt} \int_D u(t,x)\ dx = \int_D \frac{\partial u}{\partial t}(t,x)\ dx \]
%
represents the rate of energy entering $D$. Newton's law of cooling says that the rate of energy leaving $D$ is proportional to the difference in temperatures between the boundary of the body and its immediate surroundings. To a first order, this is approximated by
%
\[ \int_{\partial D} (\nabla u \cdot \nu)(x)\ dx \]
%
where $\nu(x)$ is the outward pointing unit vector varying about the boundary of $D$. The divergence theorem implies that
%
\[ \int_{\partial D} (\nabla u \cdot \nu)(x)\ dx = \int_D (\nabla \cdot \nabla u)(x)\ dx = \int_D \Delta u(x)\ dx \]
%
By conservation of energy, we therefore find that
%
\[ \int_D \frac{\partial u}{\partial t}(t,x)\ dx = k \int_D (\Delta u)(x)\ dx \]
%
where $k > 0$ is some constant of proportionality. Since this holds for any domain $D$ with smooth boundary, we conclude that heat must satisfy the partial differential equation
%
\[ \frac{\partial u}{\partial t} = k \Delta u \]
%
throughout the entire domain $\Omega$. This is the {\bf heat equation}. We note that the equation can also be applied to understand the diffusion of anything over time in some region, provided the rate of diffusion is linearly related to the change of concentration.

\section{Wave Equation}

Consider a one dimensional string in two dimensions, or a two dimensional membrane in three dimensions, which is fixed on in boundary, but allowed to vibrate up or down on its interior. Let $\Omega$ denote the region upon which the object lies before it begins vibrating. Let $u(t,x)$ denote the displacement of a point $x \in \Omega$ at time $t$ from the plane. The average displacement over a region $D$ is therefore equal to
%
\[ \fint_D u(t,x)\ dx \]
%
For a single point mass, Hooke's law tells us that a point under tension will experience a force proportional to its distance from equilibrium. Here, our membrane has no equilibrium position, but if we fix $x$, and consider a small neighbourhood around $x$, the force at $x$ should be proportional to the difference between $u(t,x)$ and the average of $u(t,y)$ on a small neighbourhood $D$ around $x$. Using the fact that this difference is proportional to $|D|^2 (\Delta u)(x)$ for nice enough small neighbourhoods $D$, we can absorb constants and we find that the average force in a small region $D$ is equal to
%
\[ \fint_D k |D|^2 \Delta u(x) = k |D| \int_D k \Delta u(x) \]
%
Applying Newton's law, assuming that $u(t,x)$ has constant density $\rho$, we conclude that the average force in $D$ is also equal to
%
\[ \rho |D| \int_D \frac{\partial^2 u}{\partial t^2}(t,x) \ dx \]
%
And therefore
%
\[ \rho |D| \int_D \frac{\partial^2 u}{\partial t^2}(t,x) = k |D| \int_D (\Delta u)(t,x) \]
%
Dividing by $|D|$, and then taking the equation over all subregions $D$ of $\Omega$, we conclude that
%
\[ \rho \frac{\partial^2 u}{\partial t^2} = k \Delta u \]
%
This is the {\bf wave equation}.

\section{Laplace and Poisson's equations}

A special case to solutions of both the heat equation and the wave equation is Laplace's equation $\Delta u = 0$, which finds functions whose average difference is essentially equal to zero. Twice continously differentiable solutions to Laplace's equation are known as {\bf harmonic}. In terms of the heat equation, $u$ gives {\it steady state} temperature distributions which stay constant throughout time. In terms of the wave equation, $u$ also gives steady state wave distributions, because we assume the membrane upon which $u$ is defined is fixed at the boundary, so that if
%
\[ \frac{\partial^2 u}{\partial t^2} = 0 \]
%
then $u$ is in fact constant. More generally, we can try and solve the partial differential equation
%
\[ - \Delta u = f \]
%
where $f$ is some given function. This generalization of Laplace's equation is known as {\bf Poisson's equation}, and arises in many contexts, like in Electrostatics, where solving the Poisson equation amounts to finding a charge potential $u$ for a given charge distribution $f$.

\section{The Field of Partial Differential Equations}

In general, a partial differential equation is an equation involving a function and some of its partial derivatives. The utopian goal of the theory of partial differential equations is to {\it solve} a given partial differential equation, which means to find all functions which solve the equation, possibly assuming some additional restriction on the class of solutions, such as how the solution behaves at the boundary of the functions definition. In the best scenario, we can find explicit formulae for all of the solutions to the partial differential equations, but even in the case of ordinary differential equations, we know that this is not possible, so we instead deduce qualitative properties of the solutions.

For ordinary differential equations, there is a conclusive {\it existence and uniqueness} theory guaranteeing that a given differential equations is solvable, and uniquely solvable given some initial conditions. For a general partial differential equation, we have no such theory. Instead, we must argue for ourself whether a partial differential equation given to us is {\it well posed}, in the sense that it has a solution, the solution is unique given certain conditions, and whether the solution depends continuously based on the initial conditions. In some cases, we may have to enlarge the variety of functions we consider to solve the equation. As an example, the PDE
%
\[ \frac{\partial u}{\partial t} + \frac{\partial (f \circ u)}{\partial x} = 0 \]
%
governs the motion of shock waves in physics. In real life, the behavior of these waves is highly discontinuous, and as such we should not expect a solution to this equation to even be differentiable. It is true that this equation has no differentiable solutions, but if we enlarge the class of functions which can solve this equation to the class of {\it generalized} or {\it weak solutions}, then we do have a uniqueness theory. To summarize, the theory of partial differential equations focuses on three phenomena:
%
\begin{itemize}
    \item (Existence) Does a solution to a partial differential equation exist, and if so, is it possible to express the solution in a formula.

    \item (Uniqueness) Given initial conditions, is the solution to a given partial differential equation unique?

    \item (Regularity) Are the solutions to a given differential equation differentiable, and to what extent?
\end{itemize}
%
In these notes we discuss our ability to answer these types of questions.

\chapter{Solving Classical Partial Differential Equations}

\section{The Transport Equation}

The easiest PDE to analyze is the {\bf transport equation}
%
\[ \frac{\partial u}{\partial t} + a \cdot \nabla u = 0 \]
%
It is essentially an exercise in basic multivariate calculus to show the uniqueness and existence theory of this PDE. Intuitively, $u$ should just propogate in the direction of the vector $a$. If $u$ is any differentiable solution to this equation, and we define $z(s) = u(t+s, x + as)$, then we find that $z$ satisfies the differential equation $z'(s) = u_t(t+s,x + as) + a \cdot \nabla u(t+s, x - as) = 0$, so $z$ is constant, and we conclude $u$ is constant on each line parallel to the hyperplane through the origin generated by $(1,a)$. Conversely, any differentiable function constant on these hyperplanes is a solution. If we specify a set of values on any hyperplane not parallel to $v$, there is a unique differentiable solution $u$ extending these values to the entire plane. If the values are not smooth, then $u$ will not be smooth, but we shall find that we can still view $u$ as a {\it weak} solution to the equation, as we will find later. Thus even the most basic partial differentiable equations have non-differentiable solutions.

Now how do we solve the non-homogenous equation
%
\[ \frac{\partial u}{\partial t} + a \cdot \nabla u = f \]
%
By linearity of the physical situation, it makes sense that the initial mass of the equation should propogate independently of the source mass produced. Thus, given any particular solution $u$, and a fixed $x$, we consider the function $z(s) = u(t+s, x + as)$. Then
%
\[ z'(s) = \frac{\partial u}{\partial t} + a \cdot \nabla u = f(t + s, x - as) \]
%
It therefore follows that
%
\[ u(t + s, x - as) = u(t,x) + \int_0^s f(t+y,x-ay)\ dy \]
%
If we are given initial values $u(0,x) = g(x)$, then we have unique solution solving the nonhomogenous equation given by
%
\[ u(t,x) = g(x-ta) + \int_0^t f(x + (s-t)a,s)\ ds \]
%
So the initial values $g$ propogate throughout the equation at a velocity $a$, as well as build up occuring based on the function $f$. In this case, the regularity of $u$ depends on the smoothness of $g$ and $f$.

\section{The Laplacian and Fundamental Solutions}

Provided a partial differential equation is linear, then a linear combination of solutions to the partial differential equation is also a solution to the partial differential equation. A good strategy to finding {\it all} solutions to PDEs of this form is to find a set of explicit solutions to the PDE, and then to find arbitrary solutions by taking arbitrary linear combinations of explicit solutions. We begin by analyzing Laplace's equation $\Delta u = 0$. It will help to note that the operator is invariant under rotations.

\begin{theorem}
    $(\Delta u) \circ T = \Delta (u \circ T)$ for any rotation $T$.
\end{theorem}
\begin{proof}
    $\Delta u(x)$ is the trace of the Hessian operator
    %
    \[ (Hu)(x) = \left( \frac{\partial^2 u}{\partial x_ix_j} \right) = D(\nabla u)(x) \]
    %
    Now the chain rule implies $D(u \circ T)(x) = (Du)(Tx) \cdot T$, so
    %
    \begin{align*}
        \nabla (u \circ T)(x) &= [D(u \circ T)(x)]^T = [(Du)(Tx) \cdot T]^T\\
        &= T^T \cdot (Du)(Tx)^T = T^T \cdot (\nabla u)(Tx) = (T^{-1} \circ \nabla u \circ T)(x)
    \end{align*}
    %
    The equation $\nabla (u \circ T) = T^{-1} \circ \nabla u \circ T$ essentially says that the gradient respects a coordinate change obtained by a rotation matrix (Remark: This is the reason why we can define the gradient unambiguously on a Riemannian manifold). Now
    %
    \begin{align*}
        H(u \circ T)(x) &= D(\nabla (u \circ T))(x) = D(T^{-1} \circ \nabla u \circ T)(x)\\
        &= T^{-1} \cdot D(\nabla u)(Tx) \cdot T = T^{-1} \cdot (Hu)(Tx) \cdot T
    \end{align*}
    %
    The trace is an invariant of similar matrices, so therefore the trace of $H(u \circ T)(x)$ is the same as the trace of $Hu(Tx)$, so $\Delta (u \circ T)(x) = (\Delta u)(Tx)$.
\end{proof}

Since $\Delta u = 0$ has rotational symmetry, it makes sense to find solutions which are rotationally symmetric. These will form our explicit solutions we can put into superposition to construct other solutions. So suppose we have a rotationally symmetric function $u(x) = f(r)$. Note that in this case we may write
%
\[ \Delta u(x) = f''(r) + \frac{d - 1}{2r} f'(r) \]
%
In this case,
%
\[ \frac{f''(r)}{f'(r)} = \frac{1 - d}{r} \]
%
So integrating both sides in terms of $r$, we conclude that
%
\[ \log(f'(r)/f'(1)) = (1 - d) \log(r) \]
\[ f'(r) = \frac{f'(1)}{r^{d-1}} \]
%
For $d = 2$, we conclude $f(r) = f'(1) \log(r) + f(1)$. Otherwise, we conclude that
%
\[ f(r) = \frac{f'(1)}{2 - d} \frac{1}{r^{d-2}} + \left[ f(1) - \frac{f'(1)}{2 - d} \right] \]
%
These solutions motivate us to define the {\bf fundamental solution of the Laplacian}, which, depending on the dimension, is defined by
%
\[ \Phi(x) = \frac{-1}{2 \pi} \log |x|\ \ \ \ \ \ \ \ \Phi(x) = \frac{1}{d(d-2) |B^d_1|} \frac{1}{|x|^{d-2}} \]
%
in dimension $2$, and dimension $\neq 2$, respectively.
%
The only problem with the fundamental solution is that it {\it doesn't solve Laplace's equation in $\mathbf{R}^n$}, only in $\mathbf{R}^d - \{ 0 \}$. Indeed, $\Phi(x) \to \infty$ as $|x| \to 0$. We often write $\Delta \Phi = \delta$, where $\delta$ is the Dirac delta function at the origin, which we can interpret rigorously when we introduce the theory of weak solutions to PDEs, because of the following theorem which can be seen as an `integration by parts' formulation of the Laplacian operator, since for any reasonable functions we should find
%
\[ \int \Delta \Phi(x) f(x)\ dx = - \int \nabla \Phi \cdot \nabla f dx \]
%
In the higher dimensions neither $\Delta \Phi$ nor $\nabla \Phi$ is in $L^p$ for any $p \geq 1$, so neither of these integrals can be interpreted in the Lebesgue sense. However, they are locally integrable in $\mathbf{R}^d - \{ 0 \}$, and so the next result makes sense.

\begin{theorem}
    For any function $f \in C_c^\infty(\mathbf{R}^d)$,
    %
    \[ \lim_{\varepsilon \to 0} \int_{|x| > \varepsilon} \Delta \Phi(x) f(x)\ dx = - \lim_{\varepsilon \to 0} \int_{|x| > \varepsilon} \nabla \Phi \cdot \nabla f\ dx = f(0) \]
\end{theorem}
\begin{proof}
    We find that the fundamental solutions satisfy
    %
    \[ \nabla \Phi(x) = \frac{-x}{d|B^d_1|} \frac{1}{|x|^{d-1}}\ \ \ \ \ \nabla \Phi(x) = \frac{-x}{2 \pi |x|} \]
    %
    For $d \geq 3$,
    %
    \begin{align*}
        \int_{|x| > \varepsilon} \nabla \Phi \cdot \nabla f &= \int_{S^{d-1}} \int_\varepsilon^\infty r^{d-1} (\nabla \Phi \cdot \nabla f)(rx) dr d\sigma(x)\\
        &= \frac{-1}{d |B_1^d| } \int_{S^{d-1}} \int_\varepsilon^\infty (x \cdot \nabla f(rx))\\
        &= \frac{-1}{d |B_1^d|} \int_{S^{d-1}} \int_\varepsilon^\infty f_r(rx) dr d\sigma(x)
    \end{align*}
    %
    Using the fundamental theorem of calculus, $\int_\varepsilon^\infty f_r(rx) = -f(\varepsilon x)$, and so
    %
    \[ \int_{|x| > \varepsilon} \nabla \Phi \cdot \nabla f = \frac{1}{d |B_1^d|} \int_{S^{d-1}} f(\varepsilon x) d\sigma(x) \]
    %
    Since $f$ is continuous, as $\varepsilon \to 0$, this value tends to $f(0)$. For $d = 2$, the same kind of techniques apply.
\end{proof}

%\section{Appendix: The Laplacian}

%Using Taylor's theorem, we write
%
%\begin{align*}
%    f(x + y) &= f(x) + \langle (\nabla f)(x), y \rangle + \frac{1}{2} \sum_{i \leq j} y_iy_j f_{x_ix_j}(x) + \sum_{i \leq j \leq k} h_{ijk}(y) y_iy_jy_k
%\end{align*}
%
%where $h_{ijk}(y) \to 0$ as $y \to 0$. Note that since $y_i$ and $y_iy_j$ are odd functions of $i$ for $i \neq j$, the average value over a region symmetric in the $i$'th axis is equal to zero, and in particular for a ball of radius $r$, we find
%
%\[ \int_{B_r} y_i = \int_{B_r} y_iy_j = 0 \]
%
%If we let $\alpha(n)$ denote the volume of an $n$ dimensional unit ball, which can be calculated recursively by the formula
%
%\[ \alpha(n) = \alpha(n-1) \int_{-\pi/2}^{\pi/2} \cos^n(u)\ du \]
%
%with $\alpha(1) = 2$. We then find that
%
%\begin{align*}
%    \frac{1}{v(B^n_r)} \int_{B^n_r} [f(x+y) - f(x)] dy &= \sum \frac{f_{x_i}^2(x)}{2 v(B^n_r)} \int_{B^n_r} y_i^2 + \sum_{i \leq j \leq k} \frac{1}{v(B^n_r)} \int_{B^n_r} h_{ijk}(y) y_iy_jy_k\\
%    &= \sum \frac{f_{x_i^2}(x)}{v(B_r^n)} \int_0^r v\left(B^{n-1}_{\sqrt{1-y^2}}\right) y^2 dy + o(r^3)\\
%    &= (\Delta f)(x) \frac{\alpha(n-1)}{\alpha(n)} r^{-n} \int_0^r y^2(1-y^2)^{\frac{n-1}{2}} dy + o(r^3)\\
%    &= (\Delta f)(x) \frac{\alpha(n-1)}{\alpha(n)} r^2 \int_0^{\pi/2} [\cos^n(t) - \cos^{n+2}(t)] dt + o(r^3)\\
%    &= (\Delta f)(x) \frac{\alpha(n-1)}{\alpha(n)} r^2 (W_n/n) + o(r^3)
%\end{align*}
%
%So, up to a scalar factor depending on the dimension of the Laplacian, $(\Delta f)(x)$ measures the average difference in a small neighbourhood about the point.

\begin{thebibliography}{9}

\bibitem{evans}
Lawrence C. Evans
\textit{Partial Differential Equations}

\end{thebibliography}

\end{document}