\begin{enumerate}%[label=\Alph*]
	\item A {\it dyadic length} is a number $l$ of the form $2^{-k}$ for some non-negative integer $k$.

	\item Given a length $l > 0$, we let $\B^d_l$ denote the set of all half open cubes in $\RR^d$ with sidelength $l$ and corners on the lattice $(l \cdot \ZZ)^d$, i.e.
	%
	\[ \B^d_l = \{ [a_1, a_1 + l] \times \cdots \times [a_d, a_d+l] : a_k \in l \cdot \ZZ \}. \]
	%
	If $E \subset \RR^d$, we let $\B^d_l(E)$ denote the set of cubes in $\B^d_l$ intersecting $E$, i.e.
	%
	\[ \B^d_l(E) = \{ I \in \B^d_l: I \cap E = \emptyset \}. \]

	\item\label{defnMinkowskiDim} The {\it lower} and {\it upper Minkowski dimension} of a compact set $Z \subset \RR^d$ are defined as
	%
	%	\begin{equation} \label{minkdimdef}
	\[		\lowminkdim(Z) = \liminf_{l \to 0} \frac{\log(\# \B^d_l(Z))}{\log(1/l)}\quad \text{and}\quad \upminkdim(Z) = \limsup_{l \to 0} \frac{\log(\# \B^d_l(Z))}{\log(1/l)}. \]
	%	\end{equation}
	%If $\lowminkdim(Z) = \upminkdim(Z)$, then we define $\minkdim(Z)$ equal to the common value.

	\item If $0 \leq \alpha$ and $\delta > 0$, we define the dyadic Hausdorff content of a set $E\subset\RR^d$ as 
		%
	\[ H^\alpha_\delta(E) = \inf \left\{ \sum_{k = 1}^m l_k^\alpha : E \subset \bigcup_{k = 1}^m I_k\ \text{and}\ I_k \in \B^d_{l_k}, l_k \leq \delta\ \text{for all $k$} \right\}. \]
	%
	The $\alpha$-dimensional dyadic Hausdorff measure $H^\alpha$ on $\RR^d$ is $H^\alpha(E) = \lim_{\delta \to 0} H_\delta^\alpha(E)$, and the {\it Hausdorff dimension} of a set $E$ is $\hausdim(E) = \inf \{ \alpha \geq 0 : H^\alpha(E) = 0 \}$.

	\item \label{stronglyNonDiagonalDef}Given $I \in \B^{dn}_l$, we can decompose $I$ as $I_1 \times \cdots \times I_n$ for unique cubes $I_1, \dots, I_n \in \B_l^d$. We say $I$ is {\it strongly non-diagonal} if the cubes $I_1, \dots, I_n$ are distinct. Strongly non-diagonal cubes will play an important role in Section \ref{discretesection}, when we solve a discrete version of Theorem \ref{mainTheorem}.

	\item\label{strongCoverDefn} Adopting the terminology of \cite{KatzTao}, we say a collection of sets $\{ U_k \}$ is a {\it strong cover} of a set $E$ if $E \subset \limsup U_k$, which means every element of $E$ is contained in infinitely many of the sets $U_k$. This idea will be useful in Section \ref{discretizationsection}.  

	\item\label{frostmanItem} A {\it Frostman measure} of dimension $\alpha$ is a non-zero compactly supported probability measure $\mu$ on $\RR^d$ such that for every cube $I$ of sidelength $l$, $\mu(I) \lesssim l^\alpha$. Note that a measure $\mu$ satisfies this inequality for every cube $I$ if and only if it satisfies the inequality for cubes whose sidelengths are dyadic lengths. {\it Frostman's lemma} says that
	%
	\begin{equation}  \hausdim(E) = \sup \left\{ \alpha: 
	\begin{aligned}
	&\text{there is a Frostman measure of dimension}\\
	&\text{dimension $\alpha$ supported on $E$} 
	\end{aligned} 
	\right\}.  \label{Hdim-defn} \end{equation} 
\end{enumerate}









\section{Avoidance at Discrete Scales}\label{discretesection}

In this section we describe a method for avoiding $Z$ at a single scale. We apply this technique in Section \ref{discretizationsection} at many scales to construct a set $X$ avoiding $Z$ at all scales. This single scale avoidance technique is the building block of our construction, and the efficiency with which we can avoid $Z$ at a single scale has direct consequences on the Hausdorff dimension of the set $X$ obtained in Theorem \ref{mainTheorem}.

At a single scale, we solve a discretized version of the problem, where all sets are unions of cubes at two dyadic lengths $l \geq s$ (later, we will choose $l=l_n$ and $s=l_{n+1}$). Given a set $E \subseteq [0,1)^d$ that is a union of cubes in $\B_l^d$, our goal is to construct a set $F\subset E$ that is a union of cubes in $\B_s^d$ such that $F^n$ is disjoint from the strongly non-diagonal cubes of $\B_{s}^{dn}(Z)$.

In order to ensure the final set $X$ obtained in Theorem \ref{mainTheorem} has large Hausdorff dimension regardless of the rapid decay of scales used in the construction of $X$, it is crucial that $F$ is uniformly distributed at intermediate scales between $l$ and $s$. This is the `non-concentration' property discussed below. The next lemma constructs a set $F$ with these properties. 

\begin{lemma} \label{discretelemma}
	Fix two distinct dyadic lengths $l$ and $s$, $l > s$. Let $E \subseteq [0, 1)^d$ be a nonempty union of cubes in $\B^d_l$, and let $G\subset\RR^{dn}$ be a nonempty union of cubes in $\B_s^{dn}$ such that 
	\begin{equation}\label{ZsLarge}
	(l/s)^d \leq \# \B^{dn}_s(G)  \leq \frac{1}{2}(l/s)^{dn}.
	\end{equation} 
	Then there exists a dyadic length $r \in [s,l]$ of size
	\begin{equation} \label{rBound}
	 	r \sim \big(l^{-d}s^{dn} \# \B^{dn}_s(G)\big)^{\frac{1}{d(n-1)}},
	 \end{equation}
	 and a set $F \subset E$ that is a nonempty union of cubes in $\B^d_s(E)$ satisfying the following three properties:
	%
	\begin{enumerate}
		\item\label{avoidanceItem} \emph{Avoidance}: For any choice of distinct cubes $J_1, \dots, J_n \in \B^d_s(F)$, $J_1 \times \dots \times J_n \not \in \B_s^{dn}(G)$.
		\item\label{nonConcentrationItem} \emph{Non-Concentration}: For every $I' \in \B_r^d(E)$, there is at most one $J \in \B_s^d(F)$ with $J \subset I'$.
		\item\label{largeSizeItem} \emph{Large Size}: For every $I \in \B^d_l(E)$, $\# \B^d_s(F \cap I) \geq \# \B^d_r(I) / 2 = (l/r)^d / 2$.
	\end{enumerate}
	\end{lemma}
	%
	{\em{Remark: }} Item \ref{avoidanceItem} says that $F$ avoids strongly non-diagonal cubes in $\B^{dn}_s(G)$. Items \ref{nonConcentrationItem} and \ref{largeSizeItem} together imply that for every $I \in \B^d_l(E)$, at least half the cubes $I'\in \B_r^d(I)$ contribute a single sub-cube of sidelength $s$ to $F$; the rest contribute none.  
	%contains a single cube of sizelength $s$ inside of $I$. 

\begin{proof}
Let $r$ be the smallest dyadic length satisfying 
\begin{equation} \label{What-is-r}
r\geq R := \big(2 l^{-d}s^{dn}\# \B^{dn}_s(G)\big)^{\frac{1}{d(n-1)}}.
%r\geq\max\Big(s,\ \big(l^{-d}s^{dn}\# \B^{dn}_s(G)\big)^{\frac{1}{d(n-1)}}\Big).
\end{equation} 
%By the first inequality in \eqref{ZsLarge}, 
This choice of $r$ satisfies \eqref{rBound}. 
%Define $A_l = (2^{1/d}/l)^{1/(n-1)}.$ By the second inequality in \eqref{ZsLarge}, we have
	%
%	\[ A_l (s^{dn}\#\B^{dn}_s(G))^{1/d(n-1)} \leq A_l l^{n/(n-1)} / 2^{1/d(n-1)} = l. \]
	%Since $l$ is a dyadic length, we conclude that $r\leq l$ and thus 
	The inequalities in \eqref{ZsLarge} ensure that $r \in [s,l]$; more precisely, the left inequality in \eqref{ZsLarge} implies $R$ is bounded from below by $s$, proving $r \geq s$. On the other hand, the right inequality in \eqref{ZsLarge} shows that $R$ bounded from above by $l$. The minimality of $r$ then proves that $r \leq l$.  

	For each $I' \in \B_r^d(E)$, let $J_{I'}$ be an element of $\B^d_s(I)$ chosen uniformly at random; these choices are independent as $I'$ ranges over the elements of $\B_r^d(E)$. Define
	%
	\[ 	U = \bigcup \left\{ J_{I'} :  I' \in \B_r^d(E) \right\}, \]
	%
	and
	%
	\[ \mathcal{K}(U) = \{ K \in \B^{dn}_s(G) : K \in U^n, \text{$K$ strongly non-diagonal} \}. \]
	%
	Note that the sets $U$ and $\mathcal{K}(U)$ are random sets, in the sense that they are depend on the random variables $\{J_I\}$. 
	Define
	%
	\begin{equation} \label{defnOfF}
		F_U = U - \{ \pi(K): K \in \mathcal{K}(U) \},
	\end{equation}
	%
	where $\pi: \RR^{dn} \to \RR^d$ is the projection map $(x_1, \cdots, x_n) \in \mathbb R^{dn} \mapsto x_1 \in \mathbb R^d$. Thus $\pi$ sends the cube $K_1 \times \dots \times K_n\in \B^{dn}_s$ to the cube $K_1\in \B^{d}_s$. Given any strongly non-diagonal cube $J_1 \times \cdots \times J_n \in \B_s^{dn}(G)$, either $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(U^n)$, or $J_1 \times \cdots \times J_n \in \B_s^{dn}(U^n)$. If the former occurs then $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(F_U^n)$ since $F_U \subset U$, while if the latter occurs then $K \in \mathcal{K}(U)$, so $J_1 \not \in \B_s^d(F_U)$. In either case, $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(F_U^n)$, so $F_U$ satisfies Property \ref{avoidanceItem}. By construction, $U$ contains at most one subcube $J \in \B^{dn}_s$ for each $I \in \B^{dn}_l(E)$. Since $F_U \subset U$, $F_U$ satisfies Property \ref{nonConcentrationItem}. Thus the set $F_U$ satisfies Properties \ref{avoidanceItem} and \ref{nonConcentrationItem} regardless of which values are assumed by the random variables $\{J_I\}$. Next we will show that with non-zero probability, the set $F_U$ satisfies Property \ref{largeSizeItem}. 

	For each cube $J \in \B_s^d(E)$, there is a unique `parent' cube $I' \in \B_r^d(E)$ such that $J \subset I'$. Since $I'$ contains $(r/s)^d$ elements of $\B^d_s(E)$, and $J_{I'}$ is chosen uniformly at random from $\B^d_s(I)$,
	%
%	\begin{equation} \label{singleCubeProb}
	\[ \Prob(J \subset U) = \Prob(J_{I'} = J) = (s/r)^d. \]
%	\end{equation}
	%
	%Here the probability measure $\Prob(\cdot)$ is taken with respect to the randomly chosen set $U$ defined in \eqref{Udefinition}.
	The cubes $J_I$ are chosen independently, so if $J_1, \dots, J_k$ are distinct cubes in $\B^d_s(E)$, then %the last calculation combined with Property \ref{nonConcentrationItem} shows that
	%
	\begin{equation}\label{jointprob}
	\Prob(J_1, \dots, J_k \in U) = \begin{cases} (s/r)^{dk} & \text{if $J_1, \dots, J_k$ have distinct parents,} \\ 0 & \text{otherwise}. \end{cases} 
	\end{equation}
	%
	Let $K = J_1 \times \dots \times J_n \in \B^{dn}_s(G)$. If the cubes $J_1, J_2, \cdots J_n$ are distinct, we deduce from \eqref{jointprob} that
	%
	\begin{equation}\label{probaKSubsetUn}
		\Prob(K \subset U^n) = \Prob(J_1, \dots, J_n \in U) = (s/r)^{dn}.
	\end{equation}
	%
	By \eqref{probaKSubsetUn} and linearity of expectation, we have 
	%
	\begin{align*}
		\Expect(\# \mathcal{K}(U)) &= \sum_{K \in \B^{dn}_s(G)} \Prob(K \subset U^n) \\
		& \leq \# \B_s^{dn}(G) \cdot (s/r)^{dn} \\
	%	&= \left[ s^{dn}\#\B^{dn}_s(G) r^{-d(n-1)} \right] r^{-d} \\
	%	& \leq \left[ s^{dn}\#\B^{dn}_s(G) (A_l (s^{dn}\#\B^{dn}_s(G))^{1/d(n-1)})^{-d(n-1)} \right] r^{-d} \\
		&\leq \left[ l^d/2 \right] r^{-d},
		%& = (l/r)^d /2.
	\end{align*}
	where the last inequality is just a restatement of \eqref{What-is-r}. 
	%
	%
	In particular, there exists at least one (non-random) set $U_0$ such that
	%
	\begin{equation}\label{KU0Small}
		\# \mathcal{K}(U_0) \leq \Expect(\# \mathcal{K}(U)) \leq \frac{1}{2}(l/r)^d.
	\end{equation}
	%
	 In other words, $F_{U_0}\subset U_0$ is obtained by removing at most $\frac{1}{2}(l/r)^d$ cubes in $\B^d_s$ from $U_0$. For each $I \in \B_l^d(E)$, we know that 
\[ \# \B_{s}^d(I \cap U_0) = (l/r)^d. \] 	
Combining this with the previous observation, we arrive at the estimate 
\begin{align*}  \# \B_{s}^d(I \cap F_{U_0}) &= \# \B_{s}^d(I \cap F_{U_0}) - \# \B_{s}^d \bigl[ I \cap \pi(\mathcal K(U_0)) \bigr] \\  
&\geq \# \B_{s}^d(I \cap F_{U_0}) - \# \B_{s}^d (\pi(\mathcal K(U_0))) \\ 
& \geq  \# \B_{s}^d(I \cap F_{U_0}) - \# \B_{s}^d (\mathcal K(U_0)) \geq \frac{1}{2} (l/r)^d.  
\end{align*}  
	%Since $U_0$ contains $(l/r)^d$ cubes in $\B^d_s(I)$ for each $I \in \B^d_l(E)$, we conclude that $F_{U_0}$ contains at least $\frac{1}{2}(l/r)^d$ cubes in $\B^d_s(I)$ for each $I \in \B^d_l(E)$, so 
	In other words, $F_{U_0}$ satisfies Property \ref{largeSizeItem}. Setting $F = F_{U_0}$ completes the proof.
\end{proof}

{\em{Remarks: }} 
\begin{enumerate}[1.]
\item	While Lemma \ref{discretelemma} uses probabilistic arguments, the conclusion of the lemma is not a probabilistic statement. In particular, one can find a suitable $F$ constructively by checking every possible choice of $U$ (there are finitely many) to find one particular choice $U_0$ which satisfies \eqref{KU0Small}, and then defining $F$ by \eqref{defnOfF}. Thus the set we obtain in Theorem \ref{mainTheorem} exists by purely constructive means.

\item At this point, it is possible to understand the numerology behind the Hausdorff dimension bound $\dim_H(X) \geq (nd-\alpha)/(n-1)$ from Theorem \ref{mainTheorem}. We will pause to do so here before returning to the proof of Theorem \ref{mainTheorem}. For simplicity, suppose that $Z\subset\RR^{dn}$ satisfies 
\begin{equation}\label{specialCase}
\#\B_{s}^{dn}(Z)\leq Cs^{-\alpha}\quad  \textrm{for every}\ s\in(0,1],
\end{equation}
where $C>0$ is a fixed constant. Let $l=1$, let $E=[0,1)^d$, let $s>0$ be a small parameter. If $s$ is chosen sufficiently small compared to $d,n,\alpha,$ and $C$, then \eqref{ZsLarge} is satisfied, and we can apply Lemma \ref{discretelemma} to find a dyadic scale $r\sim s^{\frac{dn-\alpha}{d(n-1)}}$ and a set $F$ that avoids the strongly non-diagonal cubes of $B_{s}^{dn}(Z)$. The set $F$ is a union of approximately $r^{-d}\sim s^{-\frac{dn-\alpha}{n-1}}$ cubes of sidelength $s$. Informally, the set $F$ resembles a set with Minkowski dimension $\alpha$ when viewed at scale $s$. 

The set $X$ constructed in Theorem \ref{mainTheorem} will be obtained by applying Lemma \ref{discretelemma} iteratively at many scales. At each of these scales, $X$ will resemble a set of Minkowski dimension $\frac{dn-\alpha}{n-1}$. A careful analysis of the construction (performed in Section \ref{dimensionsection}) shows that $X$ actually has Hausdorff dimension at least $\frac{dn-\alpha}{n-1}$.




\item	Lemma \ref{discretelemma} is the core method in our avoidance technique. The remaining argument is fairly modular. If, for a special case of $Z$, one can improve the result of Lemma \ref{discretelemma} so that $r$ is chosen on the order of $s^{\beta/d}$, then the remaining parts of our paper can be applied near verbatim to yield a set $X$ with Hausdorff dimension $\beta$, as in Theorem \ref{mainTheorem}. 

\end{enumerate} 









\section{Fractal Discretization}\label{discretizationsection}
In this section we will construct the set $X$ from Theorem \ref{mainTheorem} by applying Lemma \ref{discretelemma} at many scales. The goal is to find a nested decreasing family of discretized sets $\{ X_k \}$ and to set $X = \bigcap X_k$. One condition guaranteeing that $X$ avoids $Z$ is that $X_k^n$ is disjoint from {\it strongly non-diagonal} cubes in $Z_k$.

\begin{lemma} \label{stronglydiagonal}
	Let $Z \subset \RR^{dn}$, let $\{Z_k\}$ be a sequence of sets that strongly cover $Z$, and let $\{ l_k \}$ be a sequence of lengths converging to zero. For each index $k$, let $X_k$ be a union of cubes in $\B^d_{l_k}$. Suppose that for each $k$, $X_k^n$ avoids strongly non-diagonal cubes in $\B^{dn}_{l_k}(Z_k)$. Then for any distinct $x_1, \dots, x_n \in \bigcap X_k$, we have $(x_1, \dots, x_n) \not \in Z$.
\end{lemma}
\begin{proof}
	Let $z \in Z$ be a point with distinct coordinates $z_1, \dots, z_n$. Define
	%
	\[ \Delta = \{ (w_1, \dots, w_n) \in \RR^{dn}: \text{there exists $i \neq j$ such that $w_i = w_j$} \}. \]
	%
	Then $d(\Delta,z) > 0$, where $d$ is the Hausdorff distance between $\Delta$ and $z$. Since $\{ Z_k \}$ strongly covers $Z$, there is a subsequence $\{ k_m \}$ such that $z \in Z_{k_m}$ for every index $m$. Since $l_k\searrow 0$ and thus $l_{k_m}\searrow 0$, if $m$ is sufficiently large then $\sqrt{dn}l_{k_m}<\Delta$ (note that $\sqrt{dn}l_{k_m}$ is the diameter of a cube in $\B_{l_{k_m}}^{dn}$). For such a choice of $m$, we have that if $I\in \B_{l_{k_m}}^{dn}(Z_{k_m})$ is the (unique) cube in $\B_{l_{k_m}}^{dn}$ containing $z$, then $I\cap\Delta=\emptyset$. But this means $I$ is strongly non-diagonal. Since $X_{k_m}$ avoids the strongly non-diagonal cubes of $Z_{k_m}$, we conclude that $z \not \in X_{k_m}^n$. In particular, $z\not\in \bigcap_{k=1}^\infty X_k$.
\end{proof}

We are now ready to construct the set $X$ in Theorem \ref{mainTheorem}. Recall that $Z \subset \RR^{dn}$ is a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Thus we can write \[ Z =  \bigcup_{i=1}^{\infty} Y_i  \quad \text{ with }  \lowminkdim(Y_i) \leq \alpha  \text{ for each $i$}. \]  Recall that in the statement of Theorem \ref{mainTheorem}, we assumed that $\alpha\geq d$. However, it might be the case that some of the sets $Y_i$ have lower Minkowski dimension smaller than $d$. We will deal with this minor annoyance as follows. Let $H\subset[0,1)^{dn}$ be a set satisfying $\#\B_{l}^{dn}(H)\geq l^{-d}$ for each $l\in (0,1]$ (for example, $H$ could be the intersection of $[0,1)^{dn}$ with a finite union of $d$-dimensional hyperplanes). Let $\{i_k\}$ be a sequence of integers that repeats each integer infinitely often and define $Z_k = Y_{i_k}\cup H.$ The sequence of sets $\{Z_k\}$ is a strong cover of $Z$; each set $Z_k$ has lower Minkowski dimension at most $\alpha$ and satisfies the bound 
\begin{equation}\label{lowerBoundZk}
\#\B_{l}^{dn}(Z_k)\geq l^{-d}\quad\textrm{for all}\ l\in (0,1].
\end{equation}

Our next task is to specify the length scales $\{l_k\}$. We define these scales inductively, predicated on a sequence of small constants $\epsilon_k \searrow 0$ that is fixed at the outset. We will choose the sequence $\epsilon_k \searrow 0$ so that $dn-\alpha-2\epsilon_k>0$ for each $k$. Define $l_0=1$. Suppose that the length scales $l_0,\ldots,l_{k-1}$ have been chosen. Define
%\begin{equation}\label{defnVarEpsk}
%\varepsilon_k = \min \left(\frac{dn - \alpha}{4k},\ \frac{n-1}{2k} \right).
%\end{equation}
%Note that
%$$dn - \alpha - 2\varepsilon_k > 0.$$
Since $\lowminkdim(Z_k) \leq \alpha$, Definition \ref{defnMinkowskiDim} implies that there exist arbitrarily small lengths $l$ which satisfy 
%$\# \B_l^{dn}(Z_k) \leq l^{-\alpha - (\varepsilon_k/2)}$. This implies that there exist arbitrarily small dyadic lengths $l$ satisfying
\begin{equation}\label{coveringOfBdnlZk}
\# \B^{dn}_l(Z_k) \leq l^{-\alpha - \frac{\varepsilon_k}{2}}.
\end{equation}
In addition, we can choose $l = l_k$ small enough to satisfy 
%In particular, there exist arbitrarily small lengths $l$ that satisfy \eqref{coveringOfBdnlZk} and the requirements
\begin{align}
l^{dn-\alpha-\varepsilon_k} & \leq \frac{1}{2}l_{k-1}^{dn}, \text{ and } \label{coverBoundRequirement}\\
l^{\epsilon_k} & \leq l_{k-1}^{2d}\label{quadDecayRequirement}.
\end{align}
%Let $l_k>0$ be a dyadic length that satisfies \eqref{coveringOfBdnlZk}, \eqref{coverBoundRequirement}, and \eqref{quadDecayRequirement}.

\subsection{Construction of $X$} 
\begin{lemma} 
%Next, we will inductively construct 
Given a sequence of dyadic length scales $l_k$ obeying \eqref{coveringOfBdnlZk}, \eqref{coverBoundRequirement} and \eqref{quadDecayRequirement} as above, there exists a sequence of sets $\{X_k\}$ and a sequence of dyadic intermediate scales $r_k$ obeying the following properties. Each set $X_k$ is a union of cubes in $\B_{l_k}^d(X_{k-1})$ that avoids the strongly non-diagonal cubes of $\mathcal B_{l_k}^{dn}(Z_k)$. Furthermore, for each index $k\geq 1$ we have
\begin{align}
& l_k\leq r_k\leq l_{k-1},\\
& r_k \lesssim l_{k}^{\frac{dn-\alpha -\epsilon_k}{d(n-1)}},\label{rkSizeBound}\\
& \# \B^d_{l_k}(X_k \cap I) \geq \frac{1}{2}(l_{k-1}/r_k)^d  \text{ for each}\ I\in \B_{l_{k-1}}^d(X_{k-1}), \label{manyIkInIkm1}\\
&\# \B^d_{l_k}(X_k \cap I') \leq 1 \text{ for each}\ I' \in \B_{r_{k}}^d(X_{k-1}).\label{XkWellDistributed}
\end{align}
\end{lemma} 
\begin{proof} 
We will proceed to construct $X_k$ by induction, using Lemma \ref{discretelemma} as building block. Set $X_0=[0,1)^d$.  
%and define $r_0=1$; $X_0$ and $r_0$ certainly satisfy the properties listed above. 
Next, suppose that the sets $X_0,\ldots,X_{k-1}$ have been defined. Our goal is to apply Lemma \ref{discretelemma} to $E=X_{k-1}$ and $G=Z_k$ with $l=l_{k-1}$ and $s=l_k$. 
This will be possible once we verify the hypothesis \eqref{ZsLarge}, which in this case takes the form 
\begin{equation}  \left(l_{k-1}/l_k \right)^{d} \leq \#\B_{l_k}^{dn}(Z_k) \leq \frac{1}{2} \left(l_{k-1}/l_k \right)^{dn}. \label{need-to-check} \end{equation} 
The right hand side follows from inequalities \eqref{coveringOfBdnlZk} and \eqref{coverBoundRequirement}. 
%imply that 
%$$
%\#\B_{l_k}^{dn}(Z_k)\leq\frac{1}{2}(l_{k-1}/l_k)^{dn}.
%$$
On the other hand, \eqref{lowerBoundZk} and that fact that $l_k, l_{k-1}\leq 1$ implies that
$$
(l_{k-1}/l_k)^d\leq l_{k}^{-d}\leq \#\B_{l_k}^{dn}(Z_k), 
$$
establishing the left inequality in \eqref{need-to-check}. Applying Lemma \ref{discretelemma} as described above now produces a dyadic length 
\begin{equation}\label{definOfr}
r\sim \big(l_{k-1}^{-d}l_k^{dn} \# \B^{dn}_{l_k}(Z_k)\big)^{\frac{1}{d(n-1)}} 
\end{equation}
and a set $F\subset X_{k-1}$ that is a union of cubes in $\B_{l_k}^{d}$. The set $F$ satisfies Properties \ref{avoidanceItem}, \ref{nonConcentrationItem}, and \ref{largeSizeItem} from the statement of Lemma \ref{discretelemma}. Define $r_k=r$ and $X_k=F$. The estimate  \eqref{rkSizeBound} on $r_k$ follows from \eqref{definOfr} using the known bounds \eqref{coveringOfBdnlZk} and \eqref{quadDecayRequirement}:  
\[ r_k \lesssim \bigl( l_{k-1}^{-d}  l_k^{dn -\alpha - \frac{\epsilon_k}{2}} \bigr)^{\frac{1}{d(n-1)}} =  \bigl( l_{k-1}^{-d} l_k^{\frac{\epsilon_k}{2}} l_k^{dn -\alpha - \epsilon_k} \bigr)^{\frac{1}{d(n-1)}} = \bigl( l_{k-1}^{-2d} l_k^{\epsilon_k}\bigr)^{\frac{1}{2d(n-1)}} l_{k}^{\frac{dn-\alpha -\epsilon_k}{d(n-1)}} \lesssim l_{k}^{\frac{dn-\alpha -\epsilon_k}{d(n-1)}}. \] 
The requirements \eqref{manyIkInIkm1} and \eqref{XkWellDistributed} follow from Properties \ref{largeSizeItem} and \ref{nonConcentrationItem} of Lemma \ref{discretelemma} respectively.
\end{proof} 

Now that we have defined the sets $\{X_k\}$, we set $X:=\bigcap X_k$. Since $X_k$ avoids strongly non-diagonal cubes in $Z_{k}$, Lemma \ref{stronglydiagonal} implies that if $x_1, \dots, x_n \in X$ are distinct, then $(x_1, \dots, x_n) \not \in Z$. To finish the proof of Theorem \ref{mainTheorem}, we must show that $\dim_{\mathbf H}(X)\geq \frac{dn - \alpha}{n - 1}$. This will be done in the next section. 







\section{Dimension Bounds}\label{dimensionsection}
To complete the proof of Theorem \ref{mainTheorem}, we must show that $\dim_{\mathbf{H}}(X) \geq  \frac{dn - \alpha}{n - 1}$.  %, where
%
% \[ \beta = \frac{dn - \alpha}{n - 1}. \]
In view of \eqref{Hdim-defn}, we will do this by constructing a Frostman measure of appropriate dimension supported on $X$. 
%
% We begin with a rough outline of our proof strategy. Recall that from the previous section, we have a decreasing sequence of lengths $\{ l_k \}$. The most convenient way to examine the dimension of $X$ at various scales is to use Frostman's lemma (see Definition \ref{frostmanItem}). We construct a probability measure $\mu$ supported on $X$ such that for all $\varepsilon > 0$, for all dyadic lengths $l$, and for all $I \in \B^d_l$, $\mu(I) \lesssim_\varepsilon l^{\beta - \varepsilon}$. We begin by showing that for each $k\geq 1$,
% \begin{equation}\label{muIScalek}
% \mu(I) \lesssim l_k^{\beta - O(1/k)}\quad\textrm{for all}\ I \in \B^d_{l_k}.
% \end{equation}
% Heuristically, this inequality stays that $X$ looks like a set with dimension $\beta - O(1/k)$ at the scale $l_k$. Our next task will be understand the behavior of $\mu$ (and thus $X$) at scales between $l_{k-1}$ and $l_k$. This task is complicated by the fact that $l_{k}$ might be much smaller than $l_{k-1}$ (indeed, we have no effective control on how quickly the length scales $\{l_k\}$ converge to 0). Thankfully, however, the sets $X_k$ defined in the previous section are unions of cubes of sidelength $I_{l_k}$ that are somewhat uniformly distributed at scales larger than $l_k$ (this Property \ref{nonConcentrationItem} in Lemma \ref{discretelemma}); this fact will allow us to establish an analogue of \eqref{muIScalek} at intermediate scales between $l_k$ and $l_{k+1}$. 
%

We start by defining a premeasure on $\bigcup_{i = 1}^\infty \B^d_{l_i}[0,1)^d$. Set $\mu([0,1)^d) = 1$. Suppose now that $\mu(I)$ has been defined for all cubes in $\bigcup_{i = 1}^{k-1} \B^d_{l_i}[0,1)^d$, and let $J \in \B^d_{l_k}$. Let $I \in \B^d_{l_{k-1}}$ be the `parent cube' of $J$ (i.e. $I$ is the unique cube in $\B^d_{l_{k-1}}$ with $J \subset I$). Define
\begin{equation} \label{muRecurse} 
\mu(J) = \left\{ \begin{array}{ll}
{\mu(I)}/{\# \B^d_{l_k}(X_k \cap I)}& \textrm{if }  J \subset X_k,\\
0& \textrm{otherwise}.
\end{array}
\right. 
\end{equation}
Observe that for each index $k\geq 1$ and each $I \in \B_{l_{k-1}}^d$, 
\begin{equation}\label{muBreakDown}
\sum_{J\in \B_{l_k}^d(I) }\mu(J)=\sum_{J \in \B_{l_k}^d(X_k\cap I) }\mu(J) = \mu(I).
\end{equation}
In particular, for each index $k$ we have
$$
\sum_{I\in\B_{l_k}}\mu(I)=1.
$$
By a standard argument involving the Caratheodory extension theorem \cite[Proposition 1.7]{Falconer}, the premeasure $\mu$ extends to a measure on the Borel subsets of $[0,1)^d$. Note that for each $k\geq 1$, $\operatorname{supp}(\mu)\subset X_k$. Thus $\mu$ is supported on $\bigcap X_k = X$. To complete the proof of Theorem \ref{mainTheorem} we will show that $\mu$ is a Frostman measure of dimension $\frac{dn - \alpha}{n - 1}-\epsilon$ for every $\epsilon>0$. 



\begin{lemma}\label{massSomeScales}
	For each $k\geq 1$ and each $J \in \B^d_{l_k}(X)$, 
	$$
	\mu(J) \lesssim l_k^{\frac{dn-\alpha}{n-1}- \eta_k}, \quad \text{ where } \quad \eta_k = \frac{n+1}{2(n-1)} \epsilon_k \searrow 0 \text{ as } k \rightarrow \infty.
	$$
\end{lemma}
\begin{proof}
	Let $J \in \B^d_{l_k}$ and let $I \in B^d_{l_{k-1}}$ be the parent of cube of $I$. Since $\mu$ is a probability measure, we have $\mu(I^\prime)\leq 1$. Combining \eqref{muRecurse}, \eqref{manyIkInIkm1}, \eqref{rkSizeBound}, and \eqref{quadDecayRequirement} we obtain
	$$
	\mu(J)\leq \frac{2r_k^d}{l_{k-1}^d}\mu(I)\leq \frac{2r_k^d}{l_{k-1}^d}\lesssim \frac{l_{k}^{\frac{dn-\alpha - \epsilon_k}{n-1}}}{l_{k-1}^d}=l_k^{\frac{dn-\alpha}{n-1}-\eta_k}\big(l_k^{\frac{\epsilon_k}{2}}/l_{k-1}^d\big)\leq l_k^{\frac{dn-\alpha}{n-1}-\eta_k}.\qedhere
	$$
\end{proof}

\begin{corollary}\label{muAtScaleRk}
For each $k\geq 1$ and each $I' \in \B^d_{r_k} (X_{k-1})$, 
	\begin{equation} 
	\mu(I') \lesssim (r_k/l_{k-1})^d l_{k-1}^{\frac{dn-\alpha}{n-1}-\eta_{k-1}}. \label{mu-Rk}
	\end{equation} 
\end{corollary}
\begin{proof}
%Lemma \ref{massSomeScales} allows us to control $\mu$ at the scales $\{l_k\}$. 
Let us fix a cube $I' \in \B^d_{r_k}(X_{k-1})$, and let $I$ denote its unique parent cube in $\B_{l_{k-1}}^d (X_{k-1})$. According to \eqref{XkWellDistributed}, $I'$ contains at most one cube in $\B_{l_k}^d(I)$; let us denote this cube by $J(I')$ if it exists. Then the mass distribution rule given by \eqref{muRecurse} dictates that 
\begin{align*}
\mu(I') = \mu(X_k \cap I') = \begin{cases} \mu(J(I')) = {\mu(I)}/{\# \B_{l_k}^d(X_k \cap I)}  &\text{ if } \# \B_{l_k}^d(X_k \cap I) = 1, \\ 0 &\text{ otherwise.} \end{cases} 
\end{align*} 
Using the estimate \eqref{manyIkInIkm1} and applying Lemma \ref{massSomeScales} to $I \in \mathcal B_{l_{k-1}}^d(X)$, we arrive at the claimed bound \eqref{mu-Rk}. 
\end{proof}
Lemma \ref{massSomeScales} and Corollary \ref{muAtScaleRk} allow us to control the behavior of $\mu$ at all scales. %To understand the behavior of $\mu$ at other scales, we will obtain a Frostman measure bound at {\it all} scales, we need to apply a covering argument. This is where the uniform mass assignment technique comes into play. Because $\mu$ behaves like a full dimensional set between the scales $l_k$ and $r_{k+1}$, we won't be penalized for making the gap between $l_k$ and $r_{k+1}$ arbitrarily large. This is essential to our argument, because $l_k$ decays faster than $2^{-k^m}$ for any $m > 0$.

\begin{lemma} \label{frostmanBound}
For every $\alpha \in [d, dn)$, and for each $\epsilon>0$, there is a constant $C_\epsilon$ so that for all dyadic lengths $l\in (0,1]$ and all $I \in \B_l^d$, we have
	\begin{equation} 
	\mu(I) \leq C_{\epsilon} l^{\frac{dn - \alpha}{n - 1} - \epsilon}. \label{mu-ball-condition} 
	\end{equation} 
\end{lemma}
\begin{proof} Fix $\epsilon > 0$. Since $\eta_k \searrow 0$ as $k\to\infty$, there is a constant $C_{\epsilon}$ so that $l_k^{-\eta_k}\leq C_{\epsilon}l_k^{-\epsilon}$ for each $k\geq 1$ (for example, we could choose $C_{\epsilon}=l_{k_0}^{-\eta_{k_0}}$, where $k_0$ is the largest integer for which $\eta_{k_0}<\epsilon$). Next, let $k$ be the (unique) index so that $l_{k+1}\leq l\leq l_{k}$. We will split the proof of \eqref{mu-ball-condition} into two cases, depending on the position of  $l$ within $[l_{k+1}, l_k]$. 
	%We now consider several cases. 
	%\begin{itemize}
	%\item If $k<k_0$, then $l\geq l_{k_0}$ and thus 
	%$$
	%\mu(I)\leq 1 = \big(l^{\frac{dn - \alpha}{n - 1} - \epsilon}\big)^{-1}\big(l^{\frac{dn - \alpha}{n - 1} - \epsilon}\big)\leq C_{\epsilon}\big(l^{\frac{dn - \alpha}{n - 1} - \epsilon}\big).
	%$$

	{\em{Case 1: }} If $r_{k+1} \leq l \leq l_k$, 
	we can cover $I$ by $(l/r_{k+1})^d$ cubes in $\B^d_{r_{k+1}}$. By Corollary \ref{muAtScaleRk},
	\begin{equation}
	\begin{split}
	\mu(I) & \lesssim (l/r_{k+1})^d (r_{k+1}/l_k)^d l_k^{\frac{dn-\alpha}{n-1}-\eta_k} \\
	& =(l/l_k)^d l_k^{\frac{dn-\alpha}{n-1}-\eta_{k}}\\
	& \leq l^{\frac{dn-\alpha}{n-1}} (l/l_k)^{\frac{\alpha - d}{n-1}} l_k^{-\eta_k}\\
	& \leq l^{\frac{dn-\alpha}{n-1} - \eta_k}  \\
	& \leq C_{\epsilon}l^{\frac{dn-\alpha}{n-1}-\epsilon}.
	\end{split}
	\end{equation}
The penultimate inequality is a consequence of our assumption $\alpha \geq d$. 

	{\em{Case 2: }} If $l_{k+1} \leq l \leq r_{k+1},$ we can cover $I$ by a single cube in $\B^d_{r_{k+1}}$. By \eqref{XkWellDistributed}, each cube in $\B^d_{r_{k+1}}$ contains at most one cube $I_0 \in \B^d_{l_{k+1}}(X_{k+1})$, so by Lemma \ref{massSomeScales},  
		%
		$$ 
		\mu(I) \leq \mu(I_0) \lesssim l_{k+1}^{\frac{dn - \alpha}{n - 1} - \eta_{k+1}} 
		% \lesssim l_{k+1}^{\frac{dn - \alpha}{n - 1}}r_{k+1}^{-\eta_{k+1}\frac{d(n-1)}{dn-\alpha-\epsilon_{k+1}}}
		% \leq C_{\epsilon}l_{k+1}^{\frac{dn - \alpha}{n - 1}}r_{k+1}^{-\epsilon}
		\leq C_{\epsilon}l_{k+1}^{\frac{dn - \alpha}{n - 1} - \epsilon}
		\leq C_{\epsilon}l^{\frac{dn - \alpha}{n - 1} - \epsilon} \leq C_{\epsilon}l^{\frac{dn - \alpha}{n - 1} - \epsilon }.\qedhere
		$$
	%\end{itemize}

\end{proof}

Applying Frostman's lemma to Lemma \ref{frostmanBound} gives $\hausdim(X) \geq \frac{dn - \alpha}{n - 1} - \epsilon$ for every $\epsilon>0$, which concludes the proof of Theorem \ref{mainTheorem}.









\section{Applications}\label{applications}

As discussed in the introduction, Theorem \ref{mainTheorem} generalizes Theorems 1.1 and 1.2 from \cite{MalabikaRob}. In this section, we present two applications of Theorem \ref{mainTheorem} in settings where previous methods do not yield any results.

\subsection{Sum-sets avoiding specified sets}

\begin{theorem} \label{sumset-application} 
	Let $Y \subset \RR^d$ be a countable union of sets of Minkowski dimension at most $\beta < d$. Then there exists a set $X \subset \RR^d$ with Hausdorff dimension at least $d - \alpha$ such that $X + X$ is disjoint from $Y$.
\end{theorem}
\begin{proof}
	Define $Z = Z_1 \cup Z_2$, where
	%
	\[ Z_1 = \{ (x,y) : x + y \in Y \} \quad \text{and} \quad Z_2 = \{ (x,y): y \in Y/2 \}. \]
	%
	Since $Y$ is a countable union of sets of Minkowski dimension at most $\beta$, $Z$ is a countable union of sets with lower Minkowski dimension at most $d + \beta$. Applying Theorem \ref{mainTheorem} with $n = 2$ and $\alpha = d + \beta$ produces a set $X \subset \RR^d$ with Hausdorff dimension $2d  - (d + \beta) = d - \beta$ avoiding $Z$. We claim that $X+ X$ is disjoint from $Y$. To see this, first suppose $x, y \in X$, $x \ne y$. Since $X$ avoids $Z_1$, we conclude that $x + y \not \in Y$. Suppose now that $x = y \in X$. Since $X$ avoids $Z_2$, we deduce that $X \cap (Y/2) = \emptyset$, and thus for any $x \in X$, $x + x = 2x \not \in Y$. This completes the proof. 
\end{proof}


\subsection{Subsets of Lipschitz curves avoiding isosceles triangles}

In \cite{MalabikaRob}, Fraser and the second author prove that if $\gamma\subset\RR^n$ is a simple $C^2$ curve with non-vanishing curvature, then there exists a set $S\subset\gamma$ of Hausdorff dimension $1/2$ that does not contain the vertices of an isosceles triangle. Using Theorem \ref{mainTheorem}, we generalize this result to Lipschitz curves. 

\begin{theorem}\label{C1IsoscelesThm}
Let $g\colon [0,1]\to \RR^{n-1}$ be Lipschitz. Then there is a set $X\subset [0,1]$ of Hausdorff dimension $1/2$ so that the set $\{(t,g(t))\colon t\in X\}$ not contain the vertices of an isosceles triangle.
\end{theorem}

\begin{proof}
Choose $M>0$ so that for all $s,t\in [0,1]$, we have $\Vert g(s)-g(t)\Vert \leq M|s-t|,$ where $\Vert \cdot \Vert$ denotes the Euclidean norm in $\RR^{n-1}$. Let $f\colon[0,1]\to\ \RR^{n-1}$ be given by $f(t) = g(\frac{x}{10M})-g(0)$. Then $f$ is $1/10$-Lipschitz and the graph of $f$ is contained in $[0,1]^n$. Define
\begin{align*}
Z=\{(x_1,x_2,x_3)\in [0,1]^3\colon (x_1,f(x_1)),&\ (x_2,f(x_2)),\ (x_3,f(x_3))\ \textrm{form}\\
&\textrm{the vertices of an isosceles triangle}\}.
\end{align*}

We will show that $Z$ has lower Minkowski dimension at most 2. Fix $0<\delta<1$. It suffices to show that
\begin{equation}\label{deltaCoveringZ}
\# \mathcal{B}_{\delta}^{3}(Z)\lesssim\delta^{-2}\log(1/\delta).
\end{equation}

We have
\begin{align*}
|\mathcal{B}_{\delta}^{3}(Z)| &= \sum_{I_1 \in \mathcal{B}_{\delta}^1([0,1])} \#\{ I_2,I_3\in \mathcal{B}_{\delta}^1([0,1])\colon I_1\times I_2\times I_3\in \mathcal{B}_{\delta}^{3}(Z) \}\\
&= \sum_{I_1 \in \mathcal{B}_{\delta}^1([0,1])} \sum_{k=0}^{\log(1/\delta)} \sum_{\substack{I_2 \in \mathcal{B}_{\delta}^1([0,1]) \\ \operatorname{dist}(I_1,I_2)\sim \delta 2^k }} \#\{ I_3\in \mathcal{B}_{\delta}^1([0,1])\colon  I_1\times I_2\times I_3\in \mathcal{B}_{\delta}^{3}(Z) \}.
\end{align*}
In the above expression we abuse notation slightly and say that $\operatorname{dist}(I_1,I_2)\sim \delta$ if $I_1=I_2$; this will not affect our estimates.

Note that for each $I_1 \in \mathcal{B}_{\delta}^1([0,1])$, there are roughly $(\delta 2^k)/\delta=2^k$ intervals $I_2\in  \mathcal{B}_{\delta}^1([0,1])$ with $\operatorname{dist}(I_1,I_2)\sim \delta 2^k$. Thus to establish \eqref{deltaCoveringZ}, it suffices to prove that for each $I_1 \in \mathcal{B}_{\delta}^1([0,1])$ and each $I_2\in  \mathcal{B}_{\delta}^1([0,1])$ with $\operatorname{dist}(I_1,I_2)\sim \delta 2^k$, we have
\begin{equation}\label{numberOfI3}
\#\{ I_3\in \mathcal{B}_{\delta}^1([0,1])\colon  I_1\times I_2\times I_3\in \mathcal{B}_{\delta}^{3}(Z) \}\lesssim 2^{-k}/\delta.
\end{equation}

For each distinct $p,q\in [0,1]^n$, define 
$$
H_{p,q}=\big\{z\in \RR^n\colon \big(z-\frac{p+q}{2}\big)\cdot (p-q)=0  \big\}.
$$
This is the hyperplane passing through the midpoint of $p$ and $q$ that is perpendicular to the line passing through $p$ and $q$. We will call $H_{p,q}$ the perpendicular bisector of $p$ and $q$.

Fix a choice of intervals $I_1$ and $I_2$ with $\operatorname{dist}(I_1,I_2)\sim \delta 2^k$. Let $\tilde I_1$ and $\tilde I_2$ denote the twofold dilates of $I_1$ and $I_2$, respectively. Note that if $I_3\in\mathcal{B}_\delta^1([0,1])$ with $I_1\times I_2\times I_3\in \mathcal{B}_{\delta}^{3}(Z)$, then there are points $x_j\in \tilde I_j,\ i=1,2,3$ so that 
$$
(x_3,f(x_3))\in H_{(x_1,f(x_1)), (x_2,f(x_2))}.
$$

Consider the set
$$
S_{I_1,I_2}=[0,1]^n \cap \bigcup_{\substack{x_1\in \tilde I_1\\ x_2\in \tilde I_2}}H_{(x_1,f(x_1)), (x_2,f(x_2))}.
$$
For each $x_1\in \tilde I_1$ and $x_2\in \tilde I_2$, the line passing through $(x_1,f(x_1))$ and $(x_2,f(x_2))$ makes an angle $\leq 1/10$ with the $e_1$ direction. Thus the hyperplane $H_{(x_1,f(x_1)), (x_2,f(x_2))}$ makes an angle $\leq 1/10$ with the hyperplane spanned by the $e_2,\ldots,e_n$ directions. Since $\tilde I_1$ and $\tilde I_2$ are intervals of length $\leq 3\delta$ that are $\sim \delta 2^k$ separated, $S_{I_1,I_2}$ is contained in the $\sim 2^{-k}$ neighborhood of a hyperplane that makes an angle $\leq 1/10$ with the $e_2,\ldots,e_n$ directions.  

Suppose that $x_3,x_3^\prime\in [0,1]$ satisfy
\begin{equation}\label{x3x3pContainedR}
(x_3,f(x_3))\in S_{I_1,I_2}\quad\textrm{and}\quad(x_3^\prime,f(x_3^\prime))\in S_{I_1,I_2}.
\end{equation}

Since $f$ is $1/10$-Lipschitz, we must have 
$$
|f(x_3)-f(x_3^\prime)|\leq \frac{1}{10}|x_3-x_3^\prime|.
$$
On the other hand, by \eqref{x3x3pContainedR} and the fact that $S_{I_1,I_2}$ is contained in the $\sim 2^{-k}$ neighborhood of a hyperplane that makes an angle $\leq 1/10$ with the $e_2,\ldots,e_n$ directions, we have
$$
|f(x_3)-f(x_3^\prime)|\geq 10|x_3-x_3^\prime|-O(2^{-k}).
$$ 


we conclude that $|x_3-x_3^\prime|\lesssim 2^{-k}$. This establishes \eqref{numberOfI3}. We conclude that \eqref{deltaCoveringZ} holds, so $Z$ has lower Minkowski dimension at most 2. 

By Theorem \ref{mainTheorem}, there is a set $X_1\subset[0,1]$ of Hausdorff dimension $1/2$ so that for each distinct $x_1,x_2,x_3\in X,$ we have $(x_1,x_2,x_3)\not\in Z$. This is precisely the statement that for each $x_1,x_2,x_3\in X$, the points $(x_1,f(x_1)),\ (x_2,f(x_2))$, and $(x_3,f(x_3))$ do not form the vertices of an isosceles triangle. To complete the proof, let $X = X/(10M)$.
\end{proof}

\bibliographystyle{amsplain}
\bibliography{FractalsAvoidingFractalSetsPaper}

\end{document}