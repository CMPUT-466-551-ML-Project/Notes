\documentclass[12pt,reqno]{article}

%\documentclass[dvipsnames,letterpaper,12pt]{article}

\usepackage[margin = 1in]{geometry}
\usepackage{amsmath,amssymb,graphicx,mathabx,accents}
\usepackage{enumerate,mdwlist}

%\setlist[enumerate]{label*={\normalfont(\Alph*)},ref=(\Alph*)}

\numberwithin{equation}{section}

\usepackage{amsthm}

\usepackage{hyperref}

\usepackage{verbatim}

\usepackage{nag}

\DeclareMathOperator{\minkdim}{\dim_{\mathbf{M}}}
\DeclareMathOperator{\hausdim}{\dim_{\mathbf{H}}}
\DeclareMathOperator{\lowminkdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\upminkdim}{\overline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\fordim}{\dim_{\mathbf{F}}}

\DeclareMathOperator{\lhdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\lmbdim}{\underline{\dim}_{\mathbf{MB}}}

\DeclareMathOperator{\RR}{\mathbf{R}}
\DeclareMathOperator{\ZZ}{\mathbf{Z}}
\DeclareMathOperator{\QQ}{\mathbf{Q}}
\DeclareMathOperator{\TT}{\mathbf{T}}
\DeclareMathOperator{\CC}{\mathbf{C}}

\DeclareMathOperator{\B}{\mathcal{B}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{prop}[theorem]{Proposition}
\newtheorem{remark}{Remark}
\newtheorem*{concludingremarks}{Concluding Remarks}

\DeclareMathOperator{\EE}{\mathbf{E}}
\DeclareMathOperator{\PP}{\mathbf{P}}

\DeclareMathOperator{\DQ}{\mathcal{Q}}
\DeclareMathOperator{\DR}{\mathcal{R}}

\newcommand{\psitwo}[1]{\| {#1} \|_{\psi_2(L)}}
\newcommand{\TV}[2]{\| {#1} \|_{\text{TV}({#2})}}








\title{Salem Sets Avoiding Rough Configurations}
\author{Jacob Denson}

\begin{document}

\maketitle

\section{Introduction}

Geometric measure theory explores the relationship between the geometry of subsets of Euclidean spaces, and regularity properties of the family of Borel measures supported on those subsets. From the perspective of harmonic analysis, it is interesting to explore what structural information can be gathered from the Fourier analytic properties of measures supported on a particular subset of Euclidean space. In this paper, we focus on the relationship between the Fourier analytic properties of a set and the existence of patterns on the set. In particular, given a `rough pattern', in the sense of \cite{OurPaper}, we construct a family of sets which generically avoids this pattern, and which supports measures with fast Fourier decay.

A useful statistic associated with any Borel set $E \subset \RR^d$ is it's \emph{Fourier dimension}; given a finite Borel measure $\mu$ on $\RR^d$, it's Fourier dimension, $\fordim(\mu)$, is the supremum of all $s \in [0,d]$ such that
%
\begin{equation} \label{fordim}
    \sup \left\{ |\widehat{\mu}(\xi)| |\xi|^{s/2} : \xi \in \RR^d \right\} < \infty.
\end{equation}
%
The Fourier dimension of a Borel set $E \subset \RR^d$, denoted $\fordim(E)$, is then the supremum of $\fordim(\mu)$, over all Borel probability measures $\mu$ supported on $E$. A particularly tractable family of sets in this scheme are \emph{Salem sets}, those sets whose Fourier dimension agrees with their Hausdorff dimension. Most classical fractal sets are not Salem, often having Fourier dimension zero. Nonetheless, the sets we construct in this paper are Salem.

\begin{theorem} \label{maintheorem}
    Let $0 \leq \alpha < dn$, and let $Z \subset \RR^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Then there exists a compact Salem set $X \subset [0,1]^d$ with dimension
    %
    \[ \beta = \min \left( \frac{nd - \alpha}{n-1/2}, d \right) \]
    %
    such that for any distinct points $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

\begin{remark}
    Theorem \ref{maintheorem} is an attempt to strengthen the main result of \cite{OurPaper} to give a Fourier dimension bound, albeit under a weaker dimension bound. Unlike in \cite{OurPaper}, the case of Theorem \ref{maintheorem} when $0 \leq \alpha < d$ is still interesting, since the trivial construction $[0,\pi]^d - \pi(Z)$ is not necessarily a Salem set, where $\pi(x_1, \dots, x_n) = x_1$ is projection onto the first coordinate. For instance, in Example 8 of \cite{Ekstrom2014} it is shown that there exists a compact set $E \subset [0,1]$ such that $\minkdim(E) < 1$ and $\fordim([0,1] - E) < 1$. Setting $Z = E \times \{ 0 \} \cup \{ 0 \} \times E$ shows that neither subtracting projections onto the first nor the second coordinate gives the required Fourier dimension bounds.
\end{remark}

\begin{comment}
A well-known result in this pattern avoidance setting is that sets with large Fourier dimension satisfy many algebraic relations. More precisely, if integer coefficients $m_1, \dots, m_n \in \ZZ$ are fixed, and we consider a compact set $X \subset \RR$ with $\fordim(X) > 2/n$, then the sum set $m_1 X + \dots + m_n X$ contains an open interval. It follows by a slight modification of these coefficients that if $X \subset \RR$ and $\fordim(X) > 2/n$, then there exists $m_1, \dots, m_n \in \ZZ$, distinct points $x_1, \dots, x_n \in X$, and an additional integer $a \in \ZZ$, such that
%
\begin{equation} \label{intequation}
    m_1 x_1 + \dots + m_n x_n = a.
\end{equation}
%
It is an interesting to determine how tight this result is. In \cite{Korner2}, T.W. K\"{o}rner constructs a Salem set $X$ with Fourier dimension $1/(n-1)$ such that for non-zero $m \in \ZZ^n$, and $a \in \ZZ$, $X$ does not contain distinct points $x_1, \dots, x_n$ solving \eqref{intequation}. If, for each nonzero $m \in \ZZ^n$ and $a \in \ZZ$, we consider the set
%
\[ Z_{m,a} = \left\{ (x_1, \dots, x_n) \in [0,1]^n : m_1x_1 + \dots + m_n x_n = a \right\}, \]
%
then $Z_{m,a}$ is a subset of an $n-1$ dimensional hyperplane, and thus can be easily seen to have Minkowski dimension $n-1$. It follows that we can apply Theorem \ref{maintheorem} to $Z = \bigcup \{ Z_{m,a} : m \neq 0, a \in \ZZ \}$ to obtain a Salem set $X \subset [0,1]$ with dimension
%
\[ \frac{n - (n-1)}{n - 1} = \frac{1}{n-1}, \]
%
such that $(x_1, \dots, x_n) \not \in Z$ for each distinct $x_1, \dots, x_n \in X$. This means precisely that $X$ avoids solutions to $\eqref{intequation}$ for all nonzero $m \in \ZZ^n$ and $a \in \ZZ$. Thus we see Theorem \ref{maintheorem} generalizes K\"{o}rner's result, and thus shows the result depends little on the arithmetic properties of the pattern K\"{o}rner avoids, but rather, depends only on the `thickness' of the family of tuples $(x_1, \dots, x_n)$ satisfying the pattern. Since we expect Theorem \ref{maintheorem} to be tight for general sets, an improvement to K\"{o}rner's construction must rely more heavily on the algebraic properties of the pattern involved.
\end{comment}

Because we are working with \emph{compact} sets avoiding patterns, working in the domain $\RR^d$ is not significantly different from working in a periodic domain $\TT^d = \RR^d / \ZZ^d$, and working in this space has several advantages over the Euclidean case. For a finite measure $\mu$ on $\TT^d$, we can define it's Fourier dimension $\fordim(\mu)$ as the supremum of all $0 \leq s \leq d$ such that
%
\begin{equation} \label{fordimtorus}
    \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{s/2} < \infty.
\end{equation}
%
We can then define the Fourier dimension $\fordim(E)$ of any Borel set $E \subset \TT^d$ as the supremum of $\fordim(\mu)$, over all Borel measures $\mu$ supported on $E$. Since $\TT^d$ has a natural metric space structure, we can define the Hausdorff dimension of sets on $\TT^d$. It is a simple consequence of the Poisson summation formula that if $\mu$ is a compactly supported measure on $\RR^d$, then \eqref{fordim} is equivalent to the more discrete condition
%
\begin{equation} \label{discretefordim}
    \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{s/2} < \infty.
\end{equation}
%
A proof is given in Lemma 39 of \cite{myThesis}. In particular, if $\mu^*$ is the \emph{periodization} of $\mu$, i.e. the measure on $\TT^d$ such that for any $f \in C(\TT^d)$,
%
\begin{equation}
    \int_{\TT^d} f(x)\; d\mu^*(x) = \int_{\RR^d} f(x)\; d\mu(x),
\end{equation}
%
then \eqref{discretefordim}, together with the Poisson summation formula, implies $\fordim(\mu^*) = \fordim(\mu)$. Since $\mu$ is compactly supported, it is also simple to see that $\hausdim(\mu^*) = \hausdim(\mu)$. Thus Theorem \ref{maintheorem} is clearly equivalent to Theorem \ref{periodictheorem}, which is it's periodic variant.

\begin{theorem} \label{periodictheorem}
    Let $0 \leq \alpha < dn$, and let $Z \subset \TT^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Then there exists a compact Salem set $X \subset \TT^d$ with dimension
    %
    \[ \beta = \min \left( \frac{dn - \alpha}{n-1/2}, d \right) \]
    %
    such that for any distinct points $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

We construct the set in Theorem \ref{periodictheorem} by relying on Baire-category arguments. Thus we consider a complete metric space $\mathcal{X}_\beta$, whose elements consist of pairs $(E,\mu)$, where $E$ is a subset of $\TT^d$, and $\mu$ is a probability measure supported on $E$. We then show that for \emph{quasi-all} elements $(E,\mu) \in \mathcal{X}_\beta$, $E$ is a Salem set of dimension $\beta$, and for distinct $x_1,\dots,x_n \in E$, $(x_1,\dots,x_n) \not \in Z$, in the sense that the set of pairs $(E,\mu)$ which do not satisfy these properties is a set of first category in $\mathcal{X}_\beta$. It thus follows that the consequences of Theorem \ref{periodictheorem} holds in a `generic' sense for elements of $\mathcal{X}_\beta$.

Once we have setup the appropriate metric space $\mathcal{X}_\beta$, our approach is quite similar to the construction in \cite{OurPaper}, relying on a random selection procedure, which is now exploited to give high probability bounds on the Fourier transform of the measures we study. The use of the Baire category approach in this paper, rather than an algorithmic, `nested set' approach as used in \cite{OurPaper}, is mostly of an aesthetic nature, avoiding the complex queuing method and dyadic decomposition strategy required in the nested set approach; our approach can, with some care, be converted into a queuing procedure like in \cite{OurPaper}. But the Baire category argument makes our proof much simpler to read, and has the advantage that it indicates that Salem sets of a specified dimension `generically' avoid a given rough pattern.% Moreover, the proof of the Baire category theorem is in some senses, `hidden' in the queuing method, so the two methods are, aside from small technical differences, equivalent to one another.

\section{Notation} \label{notationSection}

\begin{itemize}
%    \item For a positive integer $N$, we let $[N] = \{ 1, \dots, N \}$.

    \item Given a metric space $\Omega$ (here either $\RR^d$ or $\TT^d$), $x \in \Omega$, and $\varepsilon > 0$, we shall let $B_\varepsilon(x)$ denote the open ball of radius $\varepsilon$ around $x$. For a given set $E \subset \Omega$ and $\varepsilon > 0$, we let
    %
    \[ E_\varepsilon = \bigcup_{x \in E} B_\varepsilon(x), \]
    %
    denote the \emph{$\varepsilon$-thickening} of the set $E$. A subset of $\Omega$ is of \emph{first category} in $\Omega$ if it is the countable union of closed sets with nonempty interior. We say a property holds \emph{quasi-always}, or a property is \emph{generic} in $\Omega$ if the set of points in $\Omega$ failing to satisfy that property form a set of first category.

    \item We let $\TT^d = \RR^d/\ZZ^d$. Given $x \in \TT$, we let
    %
    \[ |x| = \min \{ |x + n| : n \in \ZZ \}, \]
    %
    and for $x \in \TT^d$, we let
    %
    \[ |x| = \sqrt{|x_1|^2 + \dots + |x_d|^2}. \]
    %
    The canonical metric on $\TT^d$ is then given by $d(x,y) = |x - y|$, for $x,y \in \TT^d$. For a cube $Q$ in $\TT^d$, we let $2Q$ be the cube in $\TT^d$ with the same centre and twice the sidelength.

    \item Suppose $\mathbf{E} = \TT^d$ or $\mathbf{E} = \RR^d$. For $\alpha \in [0,d]$ and $\delta > 0$, we define the Hausdorff content of a Borel set $E \subset \mathbf{E}$ as
    %
    \[ H^\alpha_\delta(E) = \inf \left\{ \sum_{i = 1}^\infty \varepsilon_i^\alpha : E \subset \bigcup_{i = 1}^\infty B_{\varepsilon_i}(x_i)\ \text{and $\varepsilon_i \leq \delta$ for all $i \in \mathbf{N}$} \right\}. \]
    %
    The $\alpha$ dimensional Hausdorff measure of $E$ is equal to
    %
    \[ H^\alpha(E) = \lim_{\delta \to 0} H^\alpha_\delta(E). \]
    %
    The Hausdorff dimension $\hausdim(E)$ of a Borel set $E$ is then the infinum over all $s \in [0,d]$ such that $H^s(E) = \infty$, or alternatively, the supremum over all $s \in [0,d]$ such that $H^s(E) = 0$.
    %Frostman's lemma says that if we define the Hausdorff dimension $\hausdim(\mu)$ of a finite Borel measure $\mu$ as the supremum of all $s \in [0,d]$ such that
    %
    %\begin{equation} \label{hausdim}
    %    \sup \left\{ \mu(B_\varepsilon(x)) \cdot \varepsilon^{-\alpha} : x \in \RR^d, \varepsilon > 0 \right\} < \infty,
    %\end{equation}
    %
    %then $\hausdim(E)$ is the supremum of $\hausdim(\mu)$, over all Borel probability measures $\mu$ supported on $E$, analogous to the definition of the Fourier dimension of a set $E$ given in the introduction.

    \item Suppose $\mathbf{E} = \RR^d$ or $\mathbf{E} = \TT^d$, and for a measurable set $E$, we let $|E|$ denote it's Lebesgue measure. We define the lower Minkowski dimension of a compact Borel set $E \subset \mathbf{E}$ as
    %
    \[ \lowminkdim(E) = \liminf_{\varepsilon \to 0} \log_\varepsilon|E_\varepsilon|. \]

    \item In this paper we will need to employ concentration bounds several times. In particular, we use \emph{McDiarmid's inequality}, trivially modified from the standard theorem to work with complex-valued functions. Let $\{ X_1, \dots, X_N \}$ be an independant family of random variables, and consider a measurable function $f: \RR^N \to \CC$. Suppose that for each $i \in \{ 1, \dots, N \}$, there exists a constant $A_i > 0$ such that for $x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_N \in \RR$, and for each $x_i, x_i' \in \RR$,
    %
    \[ |f(x_1, \dots, x_i, \dots, x_N) - f(x_1, \dots, x_i', \dots, x_N)| \leq A_i. \]
    %
    Then McDiarmid's inequality guarantees that for all $t \geq 0$,
    %
    \[ \PP \left( |f(X_1, \dots, X_N) - \EE(f(X_1, \dots, X_N))| \geq t \right) \leq 4 \exp \left( \frac{-2t^2}{A_1^2 + \dots + A_N^2} \right). \]
    %
    The complex-valued extension we have just stated is proved easily from the real-valued case by taking a union bound to the inequality for the real and imaginary values of $f$.

    A special case of McDiarmid's inequality is \emph{Hoeffding's Inequality}. The version of Hoeffding's inequality we use states that if $\{ X_1, \dots, X_N \}$ is an independent family of mean-zero random variables, such that for each $i$, there exists a constant $A_i \geq 0$ such that $|X_i| \leq A_i$ almost surely, then for each $t \geq 0$,
    %
    \[ \PP \left( |X_1 + \dots + X_N| \geq t \right) \leq 4 \exp \left(\frac{-t^2}{2(A_1^2 + \dots + A_N^2)} \right). \]
    %
    Proofs of McDiarmid's inequality are given in many probability textbooks, for instance, in Theorem 3.11 of \cite{VanHandel}.
    \begin{comment}

    \item Our random construction involves a probabilistic concentration of measure argument. Define a convex function $\psi_2: [0,\infty) \to [0,\infty)$ by setting
    %
    \[ \psi_2(t) = e^{t^2} - 1, \]
    %
    The function $\psi_2$ induces an Orlicz norm on the family of scalar valued random variables over a probability space by setting, for each random variable $X$,
    %
    \[ \psitwo{X} = \inf \left\{ A \in (0,\infty) : \EE(\psi_2(|X|/A)) \leq 1 \right\}. \]
    %
    The family of random variables with $\psitwo{X} < \infty$ are known as \emph{subgaussian random variables}. Here are the important properties of subgaussian random variables which we use in this paper:
    %
    \begin{itemize}
        \item If $\psitwo{X} \leq A$, then for each $t \geq 0$,
        %
        \[ \PP \left( |X| \geq t \right) \leq 10 \exp \left( -t^2/10A^2 \right). \]
        %
        Thus Subgaussian random variables have Gaussian tails.

        \item If $|X| \leq A$ almost surely, then $\psitwo{X} \leq 10 A$. Thus bounded random variables are subgaussian.

    %\item (Centering) For any random variable $X$,
    %
    %\[ \psitwo{X - \EE(X)} \lesssim \psitwo{X}. \]

    %\item (Union Bound) If $X_1, \dots, X_N$ are random variables, then
    %
    %\[ \psitwo{X_1 + \dots + X_N} \leq \psitwo{X_1} + \dots + \psitwo{X_N}. \]

        \item If $X_1, \dots, X_N$ are \emph{independent}, then
        %
        \[ \psitwo{X_1 + \dots + X_N} \leq 10 \left( \psitwo{X_1}^2 + \dots + \psitwo{X_N}^2 \right)^{1/2}. \]
        %
        This is an equivalent way to state \emph{Hoeffding's Inequality}, and we refer to an application of this inequality as an application of Hoeffding's inequality.
    \end{itemize}
    %
    Roughly speaking, if $X$ is a random variable with $\psitwo{X} \leq A$, we can think of $X$ as being sharply concentrated in the region $[-A,A]$. The Orlicz norm thus provides a convenient way to quantify concentration phenomena.
    %
    \begin{remark}
        The constants involved in these statements are suboptimal, but will suffice for our purposes. Proofs can be found in Chapter 2 of \cite{Vershynin}.
    \end{remark}

    \end{comment}

%    \item Let $X$ and $Y$ be metric spaces. For a given $f: X \to Y$, we let
    %
%    \[ \| f \|_{\text{Lip}(X)} = \sup \left\{ \frac{d(f(x_1),f(x_2))}{d(x_1,x_2)} : x_1,x_2 \in X \right\} \]
    %
%    denote the optimal Lipschitz constant for $f$.

    \item Throughout this paper, we will need to consider a standard mollifier. So we fix a smooth, non-negative function $\phi \in C^\infty(\TT^d)$ such that $\phi(x) = 0$ for $|x| \geq 2/5$ and
%
\[ \int_{\TT^d} \phi(x)\; dx = 1. \]
%
\begin{comment}
\begin{theorem} \label{equationASFGCISIX}
    There exists a smooth probability density $\phi \in C^\infty(\TT^d)$ such that $\phi(x) = 0$ for $|x| \geq 2/5$, and such that for each $x \in \TT^d$
    %
    \[ \sum_{k \in \{ 0, 1 \}^d} \phi(x + k/2) = 2^d. \]
\end{theorem}
\begin{proof}
    Let $\psi$ be a non-negative smooth function on $\TT$ such that $\psi(x) = \psi(- x)$ for all $x \in \TT$, $\psi(x) = 1$ for $|x| \leq 1/10$, $\psi(x) = 0$ for $|x| \geq 2/10$, and $0 \leq \psi(x) \leq 1$ for all $x \in \TT$. Then define $\eta$ to be the non-negative, $C^\infty$ function
    %
    \[ \eta(x) = \frac{1}{2} - \frac{\psi(x) + \psi(x + 1/2)}{2}. \]
    %
    If we define
    %
    \[ \phi_0(x) = 2(\psi(x) + \eta(x)), \]
    %
    then $\phi_0(x) + \phi_0(x + 1/2) = 2$ for all $x \in \TT$. Moreover, if $|x| \geq 2/5$, then $\psi(x) = 0$, and since this implies $|x + 1/2| \leq 1/10$, we find $\eta(x) = 0$. Thus $\phi_0(x) = 0$ for $|x| \geq 2/5$. But the condition $\phi_0(x) + \phi_0(x + 1/2) = 2$ implies that $\phi_0$ is a probability density function. Thus it suffices to define
    %
    \[ \phi(x_1, \dots, x_d) = \phi_0(x_1) \dots \phi_0(x_d). \qedhere \]
\end{proof}
\end{comment}
%
For each $r \in (0,1)$, we can then define $\phi_r \in C^\infty(\TT^d)$ by writing
%
\[ \phi_r(x) = \begin{cases} r^{-d} \phi(x/r) &: |x| < r, \\ 0 &: \text{otherwise}. \end{cases} \]
%
The following standard properties hold for this choice of mollifier $\{ \phi_r \}$:
%
\begin{enumerate}
    \item[(1)] For each $r \in (0,1)$, $\phi_r$ is a smooth probability density, and $\phi_r(x) = 0$ for $|x| \geq r$.

    \item[(2)] For any $r \in (0,1)$,
    %
    \begin{equation} \label{equationDIOJAOIJVIV23242}
        \| \widehat{\phi_r} \|_{L^\infty(\ZZ^d)} \leq 1.
    \end{equation}

%    \item For any positive integer $N$, if $\varepsilon = 1/N$ and $x \in \TT^d$,
    %
%    \begin{equation} \label{equation5550002352124124512}
%        \sum_{k \in [2N]^d} \phi_{1/N}(x + k/2N) = (2N)^d.
%    \end{equation}

    \item[(3)] For each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{approximationtoidentitypointwiseconvergence}
        \lim_{r \to 0} \widehat{\phi_r}(\xi) = 1.
    \end{equation}

    \item[(4)] For each $T > 0$, and for all $r > 0$ and non-zero $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{molificationdecaybound}
        |\widehat{\phi_r}(\xi)| \lesssim_T r^{-T} |\xi|^{-T}.
    \end{equation}
\end{enumerate}
\end{itemize}

\section{A Metric Space Controlling Fourier Dimension}

In order to work with a Baire category type argument, we must construct an appropriate metric space appropriate for our task. Though in later sections we will specify $\beta$ as in Theorem \ref{maintheorem}, in this section we let $\beta$ be an arbitrary element of $(0,d]$. We proceed as in \cite{Korner2}, forming our metric space as a combination of two simpler metric spaces. However, we employ a novel Frech\'{e}t space construction instead of the Banach space used in \cite{Korner2}, which enables us to use softer estimates in our arguments:
%
\begin{itemize}
    \item We let $\mathcal{E}$ denote the family of all compact subsets of $\TT^d$. If, for two compact sets $E,F \in \mathcal{E}$, we consider their Hausdorff distance
    %
    \[ d_H(E,F) = \inf \{ \varepsilon > 0 : E \subset F_\varepsilon\ \text{and}\ F \subset E_\varepsilon \}, \]
    %
    then $(\mathcal{E},d_H)$ forms a complete metric space. %We note that if a sequence $\{ E_k \}$ converges to a set $E$ in the Hausdorff distance, then $E$ is the collection of all values $\lim_{k \to \infty} x_k$, where $\{ x_k \}$ is a convergent sequence with $x_k \in E_k$ for each $k$.

    \item We let $M(\beta/2)$ consist of the class of all finite Borel measures $\mu$ on $\TT^d$ such that for each $\varepsilon \in (0,\beta/2]$, the quantity
    %
    \[ \| \mu \|_{M(\beta/2 - \varepsilon)} = \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{\beta/2 - \varepsilon} \]
    %
    is finite. Then $\| \cdot \|_{M(\beta/2 - \varepsilon)}$ is a seminorm on $M(\beta/2)$, and the collection of all such seminorms for $\varepsilon \in (0,\beta/2]$ gives $M(\beta/2)$ the structure of a Frech\'{e}t space. Under this topology, a sequence of probability measures $\{ \mu_k \}$ converges to a probability measure $\mu$ in $M(\beta/2)$ if and only if for any $\varepsilon > 0$, $\lim_{k \to \infty} \| \mu_k - \mu \|_{M(\beta/2 - \varepsilon)} = 0$.
\end{itemize}

\begin{comment}
\begin{theorem}
    $M(\beta)$ is a Frech\'{e}t space.
\end{theorem}
\begin{proof}
    Let $\{ \mu_k \}$ be a Cauchy sequence in $M(\beta)$. By the Banach-Alaoglu theorem, we can find a finite Borel measure $\mu$ such that some subsequence $\{ \mu_{k_i} \}$ of the sequence $\{ \mu_k \}$ converges weakly to $\mu$. Then for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationAAGDDTYY8}
        \lim_{i \to \infty} \widehat{\mu_{k_i}}(\xi) = \widehat{\mu}(\xi).
    \end{equation}
    %
    Since $\{ \mu_k \}$ is Cauchy, for each $\varepsilon > 0$ there exists a constant $M_\varepsilon > 0$ such that for each $k$,
    %
    \begin{equation} \label{equationGFDSCCSI9}
        \| \mu_k \|_{M(\beta,\varepsilon)} \leq M_\varepsilon.
    \end{equation}
    %
    But combining \eqref{equationAAGDDTYY8} with \eqref{equationGFDSCCSI9} shows that for each $\varepsilon > 0$,
    %
    \begin{equation} \label{equationFGSCIS991}
        \| \mu \|_{M(\beta,\varepsilon)} \leq M_\varepsilon < \infty.
    \end{equation}
    %
    In particular, $\mu \in M(\beta)$. Now fix $r > 0$ and $\varepsilon > 0$. Because $\{ \mu_k \}$ is Cauchy, there exists $k_0$ such that for $k_1,k_2 \geq k_0$,
    %
    \begin{equation} \label{equationGGSIC8823}
        \| \mu_{k_1} - \mu_{k_2} \|_{M(\beta,r)} \leq \varepsilon.
    \end{equation}
    %
    But then combining \eqref{equationAAGDDTYY8} and\eqref{equationGGSIC8823} shows that for $k \geq k_0$,
    %
    \begin{equation} \label{equationGGSCSXXX}
        \| \mu - \mu_k \|_{M(\beta,r)} \leq \varepsilon.
    \end{equation}
    %
    Since $r$ and $\varepsilon$ were arbitrary, \eqref{equationGGSCSXXX} shows that $\mu_k$ converges to $\mu$ in the topology determined by the seminorms of $M(\beta)$. If we consider a decreasing family $\{ \varepsilon_k \}$ such that $\varepsilon_k \to 0$, then $M(\beta)$ is clearly topologized by the subfamily of seminorms $\{ \| \cdot \|_{M(\beta,\varepsilon_k)} \}$, so $M(\beta)$ is metrizable. Thus we conclude that $M(\beta)$ is a Frech\"{e}t space.
\end{proof}
\end{comment}

We now let $\mathcal{X}_\beta$ be the collection of all pairs $(E,\mu) \in \mathcal{E} \times M(\beta/2)$, where $\mu$ is a probability measure such that $\text{supp}(\mu) \subset E$. Then $\mathcal{X}_\beta$ is a closed subset of $\mathcal{E} \times M(\beta/2)$ under the product metric, and thus a complete metrizable space. We remark that for any $\varepsilon > 0$ and $(E,\mu) \in \mathcal{X}_\beta$,
%
\begin{equation} \label{equationGFSCSC4}
    \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = 0,
\end{equation}
%
which follows because $\| \mu \|_{M(\beta/2 - \varepsilon/2)}$ is finite. Thus $\fordim(\mu) \geq \beta$ for each $(E,\mu) \in \mathcal{X}_\beta$.
\begin{comment}
\begin{theorem}
    $\mathcal{X}$ is a closed subset of $\mathcal{E} \times M(\beta)$.
\end{theorem}
\begin{proof}
    Suppose $\{ (E_k,\mu_k) \}$ is a sequence of elements of $\mathcal{X}$ converging to some tuple $(E,\mu) \in \mathcal{E} \times M(\beta)$. Fix $\varepsilon > 0$. Since $E_k \to E$ in the Hausdorff dimension, there exists $k_0$ such that for $k \geq k_0$, $E_k \subset E(\varepsilon)$. Since $\mu_k \to \mu$ weakly, this implies that $\mu$ is a probability measure, and that $\text{supp}(\mu) \subset E(\varepsilon)$. Taking $\varepsilon \to 0$ shows that $\text{supp}(\mu) \subset E$. Again for a fixed $\varepsilon > 0$, applying the triangle inequality and the reverse triangle inequality combined with \eqref{equationGFSCSC4} applied to $\mu_k$, we conclude
    %
    \[ \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi) - \widehat{\mu_k}(\xi)| \leq \| \mu - \mu_k \|_{M(\beta,\varepsilon)}. \]
    %
    Taking $k \to \infty$ shows that
    %
    \[ \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = 0, \]
    %
    which completes the proof.
\end{proof}
\end{comment}

The next lemma allows us to work with smooth measures for the remainder of the paper.

\begin{lemma} \label{smoothdensitylemma}
    The set of all $(E,\mu)$ with $\mu \in C^\infty(\TT^d)$ is dense in $\mathcal{X}_\beta$.
\end{lemma}
\begin{proof}
    Consider $(E,\mu) \in \mathcal{X}_\beta$. For each $r \in (0,1)$, consider the convolved measure $\mu_r = \mu * \phi_r$. Then $\mu_r \in C^\infty(\TT^d)$. If we set $E_r = E \cup \text{supp}(\mu_r)$, then we claim
    %
    \begin{equation} \label{equationFFSPCOS}
        \lim_{r \to 0}\; (E_r, \mu_r) = (E,\mu).
    \end{equation}
    %
    Since $\text{supp}(\mu_r) \subset E_r$, we conclude that
    %
    \begin{equation} \label{equationFFSICSI}
        d_H(E,E_r) \leq r.
    \end{equation}
    %
    Thus $E_r \to E$ as $r \to 0$ under the Hausdorff distance. Now fix $\varepsilon_1 \in (0,\beta/2]$ and $\varepsilon > 0$. For each $\xi \in \ZZ^d$, $|\widehat{\mu_r}(\xi)| = |\widehat{\phi_r}(\xi)| |\widehat{\mu}(\xi)|$, so
    %
    \begin{equation} \label{equationFFSCI}
        |\xi|^{\beta/2 - \varepsilon_1} |\mu_r(\xi) - \mu(\xi)| = |\xi|^{\beta/2 - \varepsilon_1} |\widehat{\phi_r}(\xi) - 1| |\widehat{\mu}(\xi)|.
    \end{equation}
    %
    Since $(E,\mu) \in \mathcal{X}_\beta$, we can apply \eqref{equationGFSCSC4} to conclude that there exists $R$ such that for $|\xi| \geq R$,
    %
    \begin{equation} \label{equationDIICSIC}
        |\xi|^{\beta/2 - \varepsilon_1} |\widehat{\mu}(\xi)| \leq \varepsilon.
    \end{equation}
    %
    Combining \eqref{equationFFSCI}, \eqref{equationDIICSIC}, and \eqref{equationDIOJAOIJVIV23242}, we conclude that for $|\xi| \geq R$,
    %
    \begin{equation} \label{equationDSCISIIXX}
        |\xi|^{\beta/2 - \varepsilon_1} |\mu_r(\xi) - \mu(\xi)| \leq 2 \varepsilon.
    \end{equation}
    %
    By \eqref{approximationtoidentitypointwiseconvergence}, we conclude that there exists $r_0 > 0$ such that for $r \leq r_0$ and $|\xi| \leq R$,
    %
    \begin{equation} \label{equationDISCIIS}
        |\xi|^{\beta/2 - \varepsilon} |\widehat{\phi_r}(\xi) - 1| \leq \varepsilon.
    \end{equation}
    %
    The $(L^1,L^\infty)$ bound for the Fourier transform implies that
    %
    \begin{equation} \label{equationFSCISIXX}
        |\widehat{\mu}(\xi)| \leq \mu(\TT^d) = 1
    \end{equation}
    %
    But from \eqref{equationDISCIIS} and \eqref{equationFSCISIXX} applied to \eqref{equationFFSCI}, we find that for $r \leq r_0$ and $|\xi| \leq R$,
    %
    \begin{equation} \label{equatioNFISISCISI}
        |\xi|^{\beta/2 - \varepsilon_1} |\mu_r(\xi) - \mu(\xi)| \leq \varepsilon.
    \end{equation}
    %
    Putting together \eqref{equationDSCISIIXX} and \eqref{equatioNFISISCISI}, we find that for $r \leq r_0$,
    %
    \begin{equation} \label{equationDAIWOIC}
        \| \mu_r - \mu \|_{M(\beta/2 - \varepsilon_1)} \leq 2\varepsilon.
    \end{equation}
    %
    Since $\varepsilon$ and $\varepsilon_1$ were arbitrary, we conclude from \eqref{equationDAIWOIC} and \eqref{equationFFSICSI} that $(E_r,\mu_r) \to (E,\mu)$, completing the proof.
\end{proof}

\begin{remark} \label{remarkDOIWJDIOWJ2}
    Let
    %
    \[ \tilde{\mathcal{X}_\beta} = \{ (E,\mu) \in \mathcal{X}_\beta : \text{supp}(\mu) = E \}. \]
    %
    Suppose $(E_0,\mu_0) \in \tilde{\mathcal{X}_\beta}$. Then, in the proof above, one may let $E_r$ be equal to $\text{supp}(\mu_r)$, since it follows from this that $d_H(E_0,E_r) \leq r$. This means that the set of pairs $(E,\mu) \in \tilde{\mathcal{X}_\beta}$ with $\mu \in C^\infty(\TT^d)$ are dense in $\tilde{\mathcal{X}_\beta}$.
\end{remark}

The reader might be wondering why we don't work with the smaller space $\tilde{\mathcal{X}_\beta} \subset \mathcal{X}_\beta$. The reason is that $\tilde{\mathcal{X}_\beta}$ is not a closed subset of $\mathcal{E} \times M(\beta/2)$, and so is not a complete metrizable space under the product topology. However, as a consolation, quasi-all elements of $\mathcal{X}_\beta$ belong to $\tilde{\mathcal{X}_\beta}$, so that one can think of $\mathcal{X}_\beta$ and $\tilde{\mathcal{X}_\beta}$ as being equal `generically'.

\begin{lemma} \label{lemmaOIJAWDIOJW23232}
    For quasi-all $(E,\mu) \in \mathcal{X}_\beta$, $\text{supp}(\mu) = E$.
\end{lemma}
\begin{proof}
    For each closed cube $I \subset \TT^d$, let
    %
    \[ A(I) = \{ (E,\mu) \in \TT^d: (E \cap I) = \emptyset\ \text{or}\ \mu(I) > 0 \}. \]
    %
    Then $A(I)$ is an open set. If $\{ I_k \}$ is a sequence enumerating all cubes with rational corners in $\TT^d$, then
    %
    \[ \bigcap_{k = 1}^\infty A(I_k) \]
    %
    is the collection of $(E,\mu) \in \mathcal{X}_\beta$ with $\text{supp}(\mu) = E$. Thus it suffices to show that $A(I)$ is dense in $\mathcal{X}_\beta$ for each closed cube $I$.

    Consider $(E_0,\mu_0) \in \mathcal{X}_\beta - A(I)$, $\varepsilon_1 \in (0,\beta/2]$, and $\varepsilon > 0$. Our goal is to find $(E,\mu) \in A(I)$ with $d_H(E,E_0) \leq \varepsilon$ and $\| \mu_0 - \mu \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$. Without loss of generality by Lemma \ref{smoothdensitylemma} we may assume that $\mu_0 \in C^\infty(\TT^d)$. Because $(E_0,\mu_0) \in \mathcal{X}_\beta - A(I)$, we know $E \cap I \neq \emptyset$ and $\mu(I) = 0$. Find a smooth probability measure $\nu$ supported on $E_\varepsilon \cap I$ and, for $t \in (0,1)$, define $\mu_t = (1 - t) \mu_0 + t \nu$. Then $\text{supp}(\mu_t) \subset E_\varepsilon$, so if we let $E = \text{supp}(\nu) \cup \text{supp}(\mu)$, then $d_H(E,E_0) \leq \varepsilon$. Clearly $(E,\mu_t) \in A(I)$ for $t > 0$. And
    %
    \[ \| \mu_t - \mu_0 \|_{M(\beta/2 - \varepsilon)} \leq t \left( \| \mu_0 \|_{M(\beta/2 - \varepsilon)} + \| \nu \|_{M(\beta/2 - \varepsilon)} \right), \]
    %
    so if we choose $t \leq \varepsilon (\| \mu \|_{M(\beta/2 - \varepsilon)} + \| \nu \|_{M(\beta/2 - \varepsilon)})^{-1}$ shows $\| \mu_t - \mu \|_{M(\beta/2 - \varepsilon)} \leq \varepsilon$. Since $\varepsilon$ was arbitrary, we conclude $A(I)$ is dense in $\mathcal{X}_\beta$.
\end{proof}

Combining Lemma \ref{lemmaOIJAWDIOJW23232} with Remark \ref{remarkDOIWJDIOWJ2} gives the following simple corollary.

\begin{corollary} \label{corollaryOIDJOWIJD2212}
    The family of $(E,\mu)$ with $\text{supp}(\mu) = E$ and $\mu \in C^\infty(\TT^d)$ is dense in $\mathcal{X}_\beta$.
\end{corollary}

Our main way of constructing approximations to $(E_0,\mu_0) \in \mathcal{X}_\beta$ is to multiply $\mu_0$ by a smooth function $f$. For instance, we might choose $f$ in such a way as to remove certain points from the support of $\mu_0$ which contribute to the formation of a pattern we are trying to avoid. As long as the Fourier transform of $f$ decays appropriately quickly, we find $f \mu_0 \approx \mu_0$.

\begin{lemma} \label{LemmaTTSICICS}
    Consider a smooth finite measure $\mu_0$ on $\TT^d$, as well as a smooth probability density function $f \in C^\infty(\TT^d)$. If we define $\mu = f \mu_0$, then
    %
    \[ \| \mu - \mu_0 \|_{M(\beta/2)} \lesssim_{d,\mu_0} \| f \|_{M(\beta/2)}. \]
\end{lemma}
\begin{proof}
    Since $\widehat{\mu} = \widehat{f} * \widehat{\mu_0}$, and $\widehat{f}(0) = 1$, for each $\xi \in \ZZ^d$ we have
    %
    \begin{equation} \label{equationPPYTUECUUCS}
    \begin{split}
        |\xi|^{\beta/2} |\widehat{\mu}(\xi) - \widehat{\mu_0}(\xi)| &= |\xi|^{\beta/2} \left| \sum_{\eta \neq \xi} \widehat{f}(\xi - \eta) \widehat{\mu_0}(\eta) \right|.
    \end{split}
    \end{equation}
    %
    If $|\eta| \leq |\xi|/2$, then $|\xi|/2 \leq |\xi - \eta| \leq 2 |\xi|$, so
    %
    \begin{equation} \label{equationPPDOSO}
        |\xi|^{\beta/2} |\widehat{f}(\xi - \eta)| \leq \| f \|_{M(\beta/2)} |\xi|^{\beta/2} |\xi-\eta|^{-\beta} \leq 2^{\beta/2} \| f \|_{M(\beta/2)} \lesssim_d \| f \|_{M(\beta/2)}.
    \end{equation}
    %
    Since $\mu_0$ is smooth, for any $T \geq 0$ and $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationGGIDISCXJIX}
        |\xi|^T |\widehat{\mu_0}(\xi)| \lesssim_{T,\mu_0} 1.
    \end{equation}
    %
    Thus we can combine the bounds \eqref{equationPPDOSO} and \eqref{equationGGIDISCXJIX}, with $T = d+1$, to conclude that
    %
    \begin{equation} \label{equationGGPSOVVCSI}
    \begin{split}
        |\xi|^{\beta/2} \left| \sum_{0 \leq |\eta| \leq |\xi|/2} \widehat{f}(\eta) \widehat{\mu_0}(\xi - \eta) \right| &\lesssim_{\mu_0,d} \left( 1 + \sum_{0 < |\eta| \leq |\xi|/2} \frac{1}{|\eta|^{d+1}} \right) \| f \|_{M(\beta)} \lesssim_d \| f \|_{M(\beta)}.
    \end{split}
    \end{equation}
    %
    On the other hand, for all $\eta \neq \xi$,
    %
    \begin{equation} \label{equationGGDPSOX}
    \begin{split}
        |\widehat{f}(\xi - \eta)| \leq  \| f \|_{M(\beta/2)} |\xi - \eta|^{-\beta} \leq \| f \|_{M(\beta/2)}.
    \end{split}
    \end{equation}
    %
    Thus applying \eqref{equationGGIDISCXJIX} and \eqref{equationGGDPSOX}, with $T = 3d/2$, we conclude that
    %
    \begin{equation} \label{equationGGHOODPPS}
    \begin{split}
        |\xi|^{\beta/2} \left| \sum_{\substack{|\eta| > |\xi|/2\\ \eta \neq \xi}} \widehat{f}(\xi - \eta) \widehat{\mu_0}(\eta) \right| &\lesssim_{d,\mu_0} |\xi|^{\beta/2} \sum_{|\eta| > |\xi|/2} \frac{\| f \|_{M(\beta/2)}}{|\eta|^{3d/2}} \lesssim_d \| f \|_{M(\beta/2)}.
    \end{split}
    \end{equation}
    %
    Combining \eqref{equationPPYTUECUUCS}, \eqref{equationGGPSOVVCSI} and \eqref{equationGGHOODPPS} completes the proof.
\end{proof}

\begin{remark} \label{remarkFOIJIOSJCIOSJ}
    In particular, we note that this lemma implies that $\mu(\TT^d) \geq 1 - O_{d,\mu_0}(\| f \|_{M(0)})$.
\end{remark}

The bound in \eqref{LemmaTTSICICS}, if $\| f \|_{M(\beta/2)}$ is taken appropriately small, also implies that the Hausdorff distance between the supports of $\mu$ and $\mu_0$ is not too large.

\begin{lemma} \label{LemmaTAOIAWOIDJ12301}
    Fix a probability measure $\mu_0 \in C^\infty(\TT^d)$. For any $\varepsilon > 0$, there exists $\delta > 0$ depending on $\mu_0$ and $\varepsilon$, such that if $\mu \in C^\infty(\TT^d)$ is any other probability measure and $\| \mu_0 - \mu \|_{M(\beta/2)} \leq \delta$, then $d_H(\text{supp}(\mu),\text{supp}(\mu_0)) \leq \varepsilon$.
\end{lemma}
\begin{proof}
    Consider any cover of $\text{supp}(\mu_0)$ by a family of radius $\varepsilon$ balls $\{ B_1,\dots,B_N \}$, and for each $i \in \{ 1, \dots, N \}$, consider a smooth function $f_i \in C_c^\infty(B_i)$ such that there is $s > 0$ with
    %
    \begin{equation} \label{equationCIJCIJCIJ}
        \int f_i(x) d\mu_0(x) \geq s.
    \end{equation}
    %
    for each $i \in \{ 1, \dots, N \}$. Fix $A > 0$ with
    %
    \begin{equation} \label{equationvVVIJIJX}
        \sum_{\xi \neq 0} |\widehat{f_i}(\xi)| \leq A
    \end{equation}
    %
    for all $i \in \{ 1, \dots, N \}$ as well. Set $\delta = s/2A$. If $\| \mu_0 - \mu \|_{M(\beta/2)} \leq \delta$, we apply Plancherel's inequality together with \eqref{equationCIJCIJCIJ} and \eqref{equationvVVIJIJX} to conclude that
    %
    \begin{equation} \label{equationIVIJVIVJIVJ}
    \begin{split}
        \left| \int f_i(x) d\mu(x)\; dx - \int f_i(x) d\mu_0(x) \right| &= \left| \sum_{\xi \in \ZZ^d} \widehat{f_i}(\xi) \left( \widehat{\mu}(\xi) - \widehat{\mu_0}(\xi) \right) \right|\\
        &\leq A \| \mu_0 - \mu \|_{M(\beta/2)} \leq s/2.
    \end{split}
    \end{equation}
    %
    Thus we conclude from \eqref{equationCIJCIJCIJ} and \eqref{equationIVIJVIVJIVJ} that
    %
    \begin{equation} \label{equationVIOJVIOSJCICJXXXXX}
        \int f_i(x) d\mu(x)\; dx \geq \int f_i(x) d\mu_0(x) - s/2 \geq s/2 > 0.
    \end{equation}
    %
    Since equation \eqref{equationVIOJVIOSJCICJXXXXX} hodls for each $i \in \{ 1,\dots, N \}$, the support of $\mu$ intersects every balls in $\{ B_1, \dots, B_N \}$. Combined with the assumption that $\text{supp}(\mu) \subset \text{supp}(\mu_0)$, this implies that $d_H(\mu_0,\mu) \leq \varepsilon$.
\end{proof}

Given $K$ points $x_1,\dots,x_K \in \TT^d$, consider the smooth function
%
\[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_r(x - x_i). \]
%
The support of $f$ consists of $K$ radius $r$ balls. Provided $K \approx r^{-\beta}$, the support of $f$ behaves like an $r$-thickening of a $\beta$ dimensional set. The next lemma shows that if there is enough square root cancellation in the exponential sum
%
\[ \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i x_i \cdot \xi}, \]
%
then $f$ has the appropriate Fourier decay of a discretized $\beta$ dimensional set.

\begin{comment}

\begin{lemma} \label{Lemma65493}
    Fix $C > 0$, $r,\varepsilon_1 > 0$, and $\beta \in (0,d/2]$. Consider $K$ points $x_1, \dots, x_K \in \TT^d$ such that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq 1/r^{1+\varepsilon_1}$,
    %
    \begin{equation} \label{equationOIJDOIJIO}
        \left| \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i x_i \cdot \xi} \right| \leq C |\xi|^{-\beta}.
    \end{equation}
    %
    Then if we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{r}(x - x_i), \]
    %
    then $\| f \|_{M(\beta-\varepsilon_1)} \lesssim_{d,\varepsilon_1} C$.
\end{lemma}
\begin{proof}
    Set
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then \eqref{equationOIJDOIJIO} is equivalent to the property that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq 1/r^{1 + \varepsilon_1}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C |\xi|^{-\beta}.
    \end{equation}
    %
    Noting that $f = D * \phi_{r}$, we conclude that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_{r}}|.
    \end{equation}
    %
    For $0 < |\xi| \leq 1/r^{1 + \varepsilon_1}$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationDIOJAOIJVIV23242} to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
        |\widehat{f}(\xi)| \leq C |\xi|^{-\beta} \leq C |\xi|^{\varepsilon_1 - \beta}.
    \end{equation}
    %
    For $|\xi| \geq 1/r^{1 + \varepsilon_1}$, we note that \eqref{molificationdecaybound} implies $\widehat{\phi_{r}}(\xi) \lesssim_T r^{-T} |\xi|^{-T}$, and so if $T \geq \beta$,
    %
    \begin{equation} \label{equationDIICCCJSXVVM21}
        |\widehat{f}(\xi)| \lesssim_T [r^{-T} |\xi|^{\beta-T}] |\xi|^{-\beta} \leq [r^{-T} r^{-(1+\varepsilon_1)(\beta-T)}] |\xi|^{-\beta} \leq r^{-(1+\varepsilon_1) \beta + \varepsilon_1 T} |\xi|^{-\beta}.
    \end{equation}
    %
    Setting $T = (1 + 1/\varepsilon_1) \cdot \beta$ gives $|\widehat{f}(\xi)| \lesssim_{\varepsilon_1,d} |\xi|^{-\beta}$.
\end{proof}

\end{comment}

\begin{lemma} \label{Lemma65493}
    Fix $C > 0$, $r > 0$ and $\varepsilon_1 > 0$. Consider an integer $K \geq (1/C) \cdot r^{-\beta}$, and let $x_1,\dots,x_K \in \TT^d$ be such that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq (1/r)^{1 + \varepsilon_1}$,
    %
    \begin{equation} \label{equationOIJDOIJIO}
        \left| \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i x_i \cdot \xi} \right| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Then for each $\varepsilon > 0$ and $\varepsilon_2 \in (0,\beta/2)$, there exists $r_0 > 0$ depending only on $C$, $\beta$, $\varepsilon$, $\varepsilon_1$, and $\varepsilon_2$, such that if $r \leq r_0$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_r(x - x_i) \]
    %
    then $\| f \|_{M(\beta/2 - \varepsilon_2)} \leq \varepsilon$.
\end{lemma}
\begin{proof}
    Set
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then \eqref{equationOIJDOIJIO} is equivalent to the property that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq (1/r)^{1+\varepsilon_1}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Noting that $f = D * \phi_r$, we conclude that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_r}|.
    \end{equation}
    %
    If $r_1 = (10C)^{-1/\beta}$ and $r \leq r_1$, then the function $x \mapsto x^{-1/2} \log(x)^{1/2}$ is decreasing for $x \geq (1/C) r^{-1/\beta}$. Thus for $0 < |\xi| \leq 1/r$ and $r \leq r_1$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationDIOJAOIJVIV23242} together with the bound $K \geq (1/C) r^{-\beta}$ to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
    \begin{split}
        |\widehat{f}(\xi)| &\leq \left[ C K^{-1/2} \log(K)^{1/2} |\xi|^{\beta/2 - \varepsilon_2} \right] |\xi|^{\varepsilon_2-\beta/2}\\
        &\leq \left[ C^{1 + \beta/2} r^{\beta/2} \log((1/C)r^{-\beta})^{1/2} (1/r)^{\beta/2 - \varepsilon_2} \right] |\xi|^{\varepsilon_2 - \beta/2}\\
        &\leq \left[ C^{1 + \beta/2} r^{\varepsilon_2} \log((1/C)r^{-\beta})^{1/2} \right] |\xi|^{\varepsilon_2 - \beta/2}.
    \end{split}
    \end{equation}
    %
    As $r \to 0$, $C^{1 + \beta/2} r^{\varepsilon_2} \log((1/C)r^{-\beta})^{1/2} \to 0$, so we conclude from \eqref{equationGGIOHISI99234} that there exists $r_2 \leq r_1$ depending on $C$, $\beta$, $\varepsilon_2$, and $\varepsilon$, such that for $r \leq r_2$ and $0 < |\xi| \leq (1/r)$,
    %
    \begin{equation} \label{equation663sdDDDCC}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_2-\beta/2}.
    \end{equation}
    %
    If $(1/r) \leq |\xi| \leq (1/r)^{1+\varepsilon_1}$, \eqref{molificationdecaybound} implies $|\widehat{\phi_{r}}(\xi)| \lesssim_\beta r^{-\beta/2} |\xi|^{-\beta/2}$, which together with \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS}, and the bound $K \geq (1/C) r^{-\beta}$, show that for $r \leq r_1$,
    %
    \begin{equation} \label{equationGGOOSC66341}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_\beta \left( C K^{-1/2} \log(K)^{1/2} r^{-\beta/2} |\xi|^{-\varepsilon_2} \right) |\xi|^{\varepsilon_2-\beta/2}\\
        &\leq \left( C^{1 + \beta/2} \log((1/C) r^{-\beta})^{1/2} r^{\varepsilon_2(1 + \varepsilon_1)} \right) |\xi|^{\varepsilon_2 - \beta/2}.
    \end{split}
    \end{equation}
    %
    Again, we find that as $r \to 0$, $C^{1 + \beta/2} \log((1/C) r^{-\beta})^{1/2} r^{\varepsilon_2} \to 0$, so we conclude from \eqref{equationGGOOSC66341} that there exists $r_3$ depending on $C$, $\beta$, $\varepsilon$, $\varepsilon_1$ and $\varepsilon_2$, such that if $r \leq r_3$,
    %
    \begin{equation} \label{equationUUUDDDCII777}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_2-\beta/2}.
    \end{equation}
    %
    If $|\xi| \geq (1/r)^{1 + \varepsilon_1}$, we apply \eqref{molificationdecaybound} for $T \geq \beta/2$ together with the bound $K \geq (1/C) r^{-\beta}$ to conclude
    %
    \begin{equation} \label{equationGGUSCCCYVSSXX998723}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_T [r^{-T} |\xi|^{\beta/2 - T}] |\xi|^{-\beta/2}\\
        &\leq \left[ r^{-T} (1/r)^{(\beta/2 - T)(1 + \varepsilon_1)} \right] |\xi|^{-\beta/2}\\
        &= \left[ r^{\varepsilon_1 T - (\beta/2)(1 + \varepsilon_1)} \right] |\xi|^{-\beta/2}.
    \end{split}
    \end{equation}
    %
    If we choose $T > (\beta/2)(1 + 1/\varepsilon_1)$, then as $r \to 0$, $r^{\varepsilon_1 T - (\beta/2)(1 + \varepsilon_1)} \to 0$. Thus we conclude from \eqref{equationGGUSCCCYVSSXX998723} that there exists a large integer $r_4$ depending on $C$, $\beta$, $\varepsilon$, $\varepsilon_1$, and $\varepsilon_2$ such that for $r \leq r_4$ and $|\xi| \geq (1/r)^{1+\varepsilon_1}$,
    %
    \begin{equation} \label{equationBBCDSGDCC77}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{-\beta/2} \leq \varepsilon |\xi|^{\varepsilon_2-\beta/2}.
    \end{equation}
    %
    All that remains is to combine \eqref{equation663sdDDDCC}, \eqref{equationUUUDDDCII777}, and \eqref{equationBBCDSGDCC77}, defining $r_0 = \min(r_1,r_2,r_3,r_4)$.
\end{proof}

\begin{comment}

\begin{proof}
    Set
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then \eqref{equationOIJDOIJIO} is equivalent to the property that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C |\xi|^{-\beta/2}.
    \end{equation}
    %
    Noting that $f = D * \phi_{\varepsilon_0}$, we conclude that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_{\varepsilon_0}}|.
    \end{equation}
    %
    For $0 < |\xi| \leq 1/\varepsilon_0^{1 + \varepsilon_2}$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationDIOJAOIJVIV23242} to conclude
    %
    \begin{equation} \label{equationWOIDJAOIDJOISCJOICJCCCCCC}
        |\widehat{f}(\xi)| \leq C |\xi|^{-\beta/2} \leq C |\xi|^{\varepsilon_1 - \beta/2}.
    \end{equation}
    %
    For $|\xi| \geq 1/\varepsilon_0^{1 + \varepsilon_2}$, we note that \eqref{molificationdecaybound} implies $\widehat{\phi_{\varepsilon_0}}(\xi) \lesssim_T \varepsilon_0^{-T} |\xi|^{-T}$, and so if $T \geq \beta/2$,
    %
    \begin{align} \label{equationDIOJIOCJCCCXXXSDDQW}
        |\widehat{f}(\xi)| &\lesssim_T [\varepsilon_0^{-T} |\xi|^{T-\beta/2}] |\xi|^{-\beta/2}\\
        &\leq [\varepsilon_0^{-T} \varepsilon_0^{-(1 + \varepsilon_2)(T - \beta/2)}] |\xi|^{-\beta/2}\\
        &= \varepsilon_0^{(1 + \varepsilon_2)(\beta/2) - T(2 + \varepsilon_2)}
    \end{align}
\end{proof}

\begin{lemma} \label{Lemma65493}
    Fix $C > 0$, $\varepsilon_1, \varepsilon_2 > 0$, and $\varepsilon > 0$. Consider $K$ points $x_1, \dots, x_K \in \TT^d$ such that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationOIJDOIJIO}
        \left| \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i x_i \cdot \xi} \right| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Then there exists a large integer $K_0$ depending on $C$,$\beta$,$\varepsilon_1$,$\varepsilon_2$, and $\varepsilon$, such that if $K \geq K_0$, $r \geq C^{-1} K^{-1/\beta}$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{r}(x - x_i), \]
    %
    then $\| f \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$.
\end{lemma}
\begin{proof}
    Set
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then \eqref{equationOIJDOIJIO} is equivalent to the property that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Noting that $f = D * \phi_{r}$, we conclude that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_{r}}|.
    \end{equation}
    %
    For $0 < |\xi| \leq K^{1/\beta}$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationDIOJAOIJVIV23242} to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
        |\widehat{f}(\xi)| \leq \left[ C K^{-\varepsilon_1/\beta} \log(K)^{1/2} \right] |\xi|^{\varepsilon_1 - \beta/2}.
    \end{equation}
    %
    As $K \to \infty$, $K^{-\varepsilon_1/\beta} \log(K)^{1/2} \to 0$, so we conclude from \eqref{equationGGIOHISI99234} there exists a large integer $K_1(C,\beta,\varepsilon_1,\varepsilon)$ such that for $K \geq K_1(C,\beta,\varepsilon_1,\varepsilon)$,
    %
    \begin{equation} \label{equation663sdDDDCC}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_1-\beta/2}.
    \end{equation}
    %
    If $K^{1/\beta} \leq |\xi| \leq K^{1/\beta + \varepsilon_2}$, we note that \eqref{molificationdecaybound} implies $\widehat{\phi_{r}}(\xi) \lesssim_d r^{-\beta/2} |\xi|^{-\beta/2}$, which together with \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS}, and the bound $r \geq C^{-1} K^{-1/\beta}$, imply
    %
    \begin{equation} \label{equationGGOOSC66341}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_d \left( C K^{-1/2} r^{-\beta/2} K^{-\varepsilon_1/\beta} \log(K)^{1/2} \right) |\xi|^{\varepsilon_1-\beta/2}\\
        &\leq \left( C^{1 + \beta/2} K^{-\varepsilon_1/\beta} \log(K)^{1/2} \right) |\xi|^{\varepsilon_1 - \beta/2}.
    \end{split}
    \end{equation}
    %
    Again, we find that as $K \to \infty$, $K^{-\varepsilon_1/\beta} \log(K)^{1/2} \to 0$, so we conclude from \eqref{equationGGOOSC66341} that there exists $K_2(C,\beta,\varepsilon_1,\varepsilon)$ such that if $K \geq K_2(C,\beta,\varepsilon_1,\varepsilon)$, then
    %
    \begin{equation} \label{equationUUUDDDCII777}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_1-\beta/2}.
    \end{equation}
    %
    If $|\xi| \geq K^{1/\beta + \varepsilon_2}$, we apply \eqref{molificationdecaybound} for $T \geq \beta/2$ together with the bound $r \geq C^{-1} K^{-1/\beta}$ to conclude
    %
    \begin{equation} \label{equationGGUSCCCYVSSXX998723}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_T r^{-T} |\xi|^{-T}\\
        &\leq \left[ C^T K^{T/\beta} |\xi|^{\beta/2 - T} \right] |\xi|^{-\beta/2}\\
        &\leq \left[ C^T K^{1/2 + (\beta/2 - T) \varepsilon_2} \right] |\xi|^{-\beta/2}.
    \end{split}
    \end{equation}
    %
    If we choose $T > \beta/2 + 1/2 \varepsilon_2$, then as $K \to \infty$, $K^{1/2 + (\beta/2 - T) \varepsilon_1} \to 0$. Thus we conclude from \eqref{equationGGUSCCCYVSSXX998723} that there exists a large integer $K_3(C,\beta,\varepsilon_2,\varepsilon)$ such that for $K \geq K_3(C,\beta,\varepsilon_2,\varepsilon)$ and $|\xi| \geq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationBBCDSGDCC77}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{-\beta/2}.
    \end{equation}
    %
    All that remains is to combine \eqref{equation663sdDDDCC}, \eqref{equationUUUDDDCII777}, and \eqref{equationBBCDSGDCC77}, defining $K_0 = \max(K_1,K_2,K_3)$.
\end{proof}

\end{comment}

\begin{corollary} \label{lemmaIOJDD23124}
    Consider a smooth finite measure $\mu_0$ on $\TT^d$. Fix $C > 0$, $r > 0$ and $\varepsilon_1 > 0$. Consider an integer $K \geq (1/C) r^{-\beta}$, and let $x_1,\dots,x_K \in \TT^d$ be such that if
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq (1/r)^{1+\varepsilon_1}$,
    %
    \begin{equation} \label{equationBBBBODDUH}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    It is then true that for each $\varepsilon_2 \in (0,\beta/2]$, there exists $r_0$ depending on $C$, $\beta$, $d$, $\beta$, $\varepsilon$, $\varepsilon_1$, and $\varepsilon_2$, such that if $r \leq r_0$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{r}(x - x_i), \]
    %
    and a smooth probability measure
    %
    \[ \mu = \frac{f \mu_0}{(f \mu_0)(\TT^d)}, \]
    %
    then $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_2)} \leq \varepsilon$.
\end{corollary}
\begin{proof}
    It suffices to use Lemmas \ref{LemmaTTSICICS} and \ref{Lemma65493} to show that there exists $r_0$ such that for $r \leq r_0$,
    %
    \begin{equation} \label{equationDIOJAWDOIJAWIOJ212412}
        \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon_2)} \leq \varepsilon/2,
    \end{equation}
    %
    and
    %
    \begin{equation} \label{equationOIJOIJWOIDJWOIDJ3424526342412}
        \| f \mu_0 - \mu_0 \|_{M(0)} \leq \min \left( \frac{1}{2}, \frac{\varepsilon}{4 \| \mu_0 \|_{M(\beta/2 - \varepsilon_2)}} \right).
    \end{equation}
    %
    Equation \eqref{equationOIJOIJWOIDJWOIDJ3424526342412} implies that
    %
    \begin{equation} \label{equationIOAWJDOIJWDIOWJDIOW2414521}
        1 - \min \left( \frac{1}{2}, \frac{\varepsilon}{4 \| \mu_0 \|_{M(\beta/2 - \varepsilon_2)}} \right) \leq (f\mu_0)(\TT^d) \leq 1.
    \end{equation}
    %
    But now \eqref{equationDIOJAWDOIJAWIOJ212412} and \eqref{equationIOAWJDOIJWDIOWJDIOW2414521} show that
    %
    \begin{align*}
        \| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_2)} &\leq \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon)} + \| \mu - f \mu_0 \|_{M(\beta/2 - \varepsilon)}\\
        &\leq (\varepsilon/2) + \left( 1 - \frac{1}{(f \mu_0)(\TT^d)} \right) \| \mu_0 \|_{M(\beta/2 - \varepsilon)}\\
        &\leq (\varepsilon/2) + (\varepsilon/2) \leq \varepsilon. \qedhere
    \end{align*}
\end{proof}

\begin{comment}
\begin{lemma} \label{lemmaIOJDD23124}
    Consider a smooth finite measure $\mu_0$ on $\TT^d$. Fix $C > 0$, $r, \varepsilon_1, \varepsilon_2 > 0$, and $\varepsilon > 0$. Consider $K$ points $x_1, \dots, x_K \in \TT^d$ such that if
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationBBBBODDUH}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Then there exists a large integer $K_0(C,d,\beta,\mu_0,\varepsilon_1,\varepsilon_2,\varepsilon)$, such that if $K \geq K_0$ and $r \geq C^{-1} K^{-1/\beta}$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{r}(x - x_i), \]
    %
    and a smooth probability measure
    %
    \[ \mu = \frac{f \mu_0}{(f \mu_0)(\TT^d)}, \]
    %
    then $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$.
\end{lemma}
\begin{proof}
    It suffices to combine Lemmas \ref{LemmaTTSICICS} and \ref{Lemma65493} to show that there exists $K_0(C,d,\beta,\mu_0,\varepsilon_1,\varepsilon_2,\varepsilon)$ such that
    %
    \begin{equation} \label{equationDIOJAWDOIJAWIOJ212412}
        \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon/10,
    \end{equation}
    %
    and
    %
    \begin{equation} \label{equationOIJOIJWOIDJWOIDJ3424526342412}
        \| f \mu_0 - \mu_0 \|_{M(0)} \leq \min \left( \frac{1}{2}, \frac{\varepsilon}{4 \| \mu_0 \|_{M(\beta/2 - \varepsilon)}} \right).
    \end{equation}
    %
    As mentioned in Remark \ref{remarkFOIJIOSJCIOSJ}, \eqref{equationOIJOIJWOIDJWOIDJ3424526342412} implies that
    %
    \begin{equation} \label{equationIOAWJDOIJWDIOWJDIOW2414521}
        1 - \min \left( 1/2, (\varepsilon/4) \| \mu \|_{M(\beta/2-\varepsilon)} \right) \leq (f\mu_0)(\TT^d) \leq 1.
    \end{equation}
    %
    But now \eqref{equationDIOJAWDOIJAWIOJ212412} and \eqref{equationIOAWJDOIJWDIOWJDIOW2414521} show that
    %
    \begin{align*}
        \| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} &\leq \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon)} + \| \mu - f \mu_0 \|_{M(\beta/2 - \varepsilon)}\\
        &\leq (\varepsilon/2) + \left( 1 - \frac{1}{(f \mu_0)(\TT^d)} \right) \| \mu_0 \|_{M(\beta/2 - \varepsilon)} \leq \varepsilon. \qedhere
    \end{align*}
\end{proof}
\end{comment}

A common method to obtain square root cancellation in a sum is to use concentration properties of collections of independant random variables. Since square root cancellation occurs often in random phenomena, it is reasonable to use random constructions to construct Salem sets.

\begin{lemma} \label{LemmaGISCICS1}
    Fix a large integer $K$. Let $X_1, \dots, X_K$ be independant random variables on $\TT^d$, such that for each nonzero $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equatioNVVVVSXXJVU1132}
        \sum_{k = 1}^K \EE \left( e^{2 \pi i \xi \cdot X_k} \right) = 0.
    \end{equation}
    %
    In particular, \eqref{equatioNVVVVSXXJVU1132} holds if the family $\{ X_i \}$ are uniformly distributed on $\TT^d$. Set
    %
    \[ D(x) = \frac{1}{K} \sum_{k = 1}^K \delta(x - x_k) \]
    %
    and
    %
    \[ B = \{ \xi \in \ZZ^d: |\xi| \leq K^{1/\beta + 1} \}. \]
    %
    Then there exists a constant $C$ depending on $\beta$ and $d$, such that
    %
    \[ \PP \left( \| \widehat{D} \|_{L^\infty(B)} \geq C K^{-1/2} \log(K)^{1/2} \right) \leq 1/10. \]
\end{lemma}
\begin{proof}
    For each $\xi \in \ZZ^d$ and $k \in \{ 1, \dots, K \}$, consider the random variable $Y(\xi,k) = K^{-1} e^{2 \pi i (\xi \cdot X_k)}$. Then for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationPPDOCS999223}
        \sum_{k = 1}^K Y(\xi,k) = \widehat{D}(\xi).
    \end{equation}
    %
    We also note that for each $\xi \in \ZZ^d$ and $k \in \{ 1, \dots, K \}$,
    %
    \begin{equation} \label{equationGFDSCSXAOOO99}
        |Y(\xi,k)| = K^{-1},
    \end{equation}
    %
    Moreover,
    %
    \begin{equation} \label{equationDOIJWIJCCCCC5555322}
    \begin{split}
        \sum_{i = 1}^k \EE(Y(\xi,k)) = 0.
    \end{split}
    \end{equation}
    %
    Since the family of random variables $\{ Y(\xi,1), \dots, Y(\xi,K) \}$ is independent for a fixed non-zero $\xi$, we can apply Hoeffding's inequality together with \eqref{equationPPDOCS999223} and \eqref{equationGFDSCSXAOOO99} to conclude that for all $t \geq 0$,
    %
    \begin{equation} \label{equationDDISCCOXOSPP998323}
        \PP \left( |\widehat{D}(\xi)| \geq t \right) \leq 2 e^{-Kt^2/2}.
    \end{equation}
    %
    A union bound obtained by applying \eqref{equationDDISCCOXOSPP998323} over all $|\xi| \leq K^{1/\beta+1}$ shows that if
    %
    \[ B = \{ \xi \in \ZZ^d : |\xi| \leq K^{1/\beta + 1} \}, \]
    %
    then there exists a constant $C \geq 1$ depending on $d$ and $\beta$ such that
    %
    \begin{equation} \label{equationPPDOCS2424}
        \PP \left( \| \widehat{D} \|_{L^\infty(B)} \geq t \right) \leq \exp \left( C \log(K) - \frac{5K t^2}{C} \right).
    \end{equation}
    %
    But then, setting $t = CK^{-1/2} \log(K)^{1/2}$ in \eqref{equationPPDOCS2424} completes the proof.
\end{proof}

It is a general heuristic that quasi-all sets are as `thin as possible' with respect to the Hausdorff metric. In particular, we should expect the Hausdorff dimension and Fourier dimension of a generic element of $\mathcal{X}_\beta$ to be as low as possible. For each $(E,\mu) \in \mathcal{X}_\beta$, the condition that $\mu \in M(\beta/2)$ implies that $\fordim(\mu) \geq \beta$, so $\fordim(E) \geq \beta$. Thus it is natural to expect that for quasi-all $(E,\mu) \in M(\beta/2)$, the set $E$ has both Hausdorff dimension and Fourier dimension equal to $\beta$.

\begin{lemma}
    For quasi-all $(E,\mu) \in \mathcal{X}_\beta$, $E$ is a Salem set of dimension $\beta$.
\end{lemma}
\begin{proof}
    We shall assume $\beta < d$ in the proof, since when $\beta = d$, $E$ is a Salem set for any $E(,\mu) \in \mathcal{X}_\beta$, and thus the result is trivial. Since the Hausdorff dimension of a measure is an upper bound for the Fourier dimension, it suffices to show that for quasi-all $(E,\mu) \in \mathcal{X}_\beta$, $E$ has Hausdorff dimension at most $\beta$. For each $\alpha > \beta$ and $\delta, s > 0$, and let $A(\alpha,\delta,s) = \{ (E,\mu) \in \mathcal{X}: H^\alpha_\delta(E) < s \}$. Then $A(\alpha,\delta,s)$ is an open subset of $\mathcal{X}_\beta$, and
    %
    \[ \bigcap_{n = 1}^\infty \bigcap_{m = 1}^\infty \bigcap_{k = 1}^\infty A(\beta + 1/n, 1/m, 1/k) \]
    %
    is precisely the family of $(E,\mu) \in \mathcal{X}_\beta$ such that $E$ has Hausdorff dimension at $\beta$.
%
    %Certainly any $E$ in this family must have $H^\alpha(E) = 0$ for all $\alpha > \beta$, so $\hausdim(E) \leq \beta$. But the condition that $\mu \in M(A)$ implies $\fordim(\mu) \geq \beta$. Thus
    %
    %\[ \beta \leq \fordim(\mu) \leq \fordim(E) \leq \hausdim(E) \leq \beta, \]
    %
    %hence all these quantities are equal to $\beta$.
    Thus it suffices to show that $A(\alpha,\delta,s)$ is dense in $\mathcal{X}_\beta$ for $\alpha \in (\beta,d)$ and $\delta, s > 0$. Fix $(E_0,\mu_0) \in \mathcal{X}_\beta$, $\alpha \in (\beta,d)$, $\delta > 0$, $s > 0$, and $\varepsilon_1 > 0$. We aim to show that for each $\varepsilon > 0$, there exists $(E,\mu) \in A(\alpha,\delta,s)$ such that $d_H(E,E_0) \leq \varepsilon$ and $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$. Without loss of generality, in light of Lemma \ref{smoothdensitylemma}, we may assume that $\mu_0 \in C^\infty(\TT^d)$.

    Fix a small value $r$, and then find an integer $K$ such that $r^{-\beta} \leq K \leq r^{-\beta} + 1$. Lemma \ref{LemmaGISCICS1} shows that there exists a constant $C$ depending on $\beta$ and $d$, as well as $K$ points $x_1, \dots, x_K \in \TT^d$ such that if
    %
    \[ D(x) = \frac{1}{K} \sum_{k = 1}^K \delta(x - x_k), \]
    %
    then for each $|\xi| \leq (1/r)^{1 + 1/\beta} \leq K^{1/\beta + 1}$,
    %
    \begin{equation} \label{equationDDVVIXXSX23}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Applying Corollary \ref{lemmaIOJDD23124} with \eqref{equationDDVVIXXSX23}, we conclude that there exists $r_1$ depending on $d$, $\beta$, $\mu_0$, $\varepsilon$, and $\varepsilon_1$ such that if $r \leq r_1$, if
    %
    \[ \mu_1(x) = \frac{1}{K} \left( \sum_{k = 1}^K \phi_{r}(x - x_k) \right) \mu_0(x), \]
    %
    and if
    %
    \[ \mu = \mu_1 / \mu_1(\TT^d), \]
    %
    then
    %
    \begin{equation} \label{equationYYUDUSC4434}
        \| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon.
    \end{equation}
    %
    Note that $\mu$ is supported on $K$ balls of radius $r$. Thus for $r \leq \delta$,
    %
    \begin{equation} \label{equationGGSCPXX22}
        H^\alpha_\delta(\text{supp}(\mu)) \leq K r^\alpha \leq (r^{-\beta} + 1) r^\alpha = r^{\alpha - \beta} + r^\alpha.
    \end{equation}
    %
    Since $\alpha > \beta$, \eqref{equationGGSCPXX22} implies that there is $r_2$ depending on $\alpha$, $\beta$, and $s$ such that for $r \leq r_2$,
    %
    \begin{equation} \label{equationGGSXSOF9923}
        H^\alpha_\delta(\text{supp}(\mu)) \leq s.
    \end{equation}
    %
    Now let
    %
    \[ E = \text{supp}(\mu) \cup \{ y_1, \dots, y_N \}, \]
    %
    where $\{ y_1, \dots, y_N \} \subset E_0$ is a $\varepsilon$-net of $E_0$. Set $r_0 = \min(r_1,r_2, \delta)$ and suppose $r \leq r_0$. Equation \eqref{equationGGSXSOF9923} implies that $H^\alpha_\delta(E) \leq s$, so $(E,\mu) \in A(\alpha,\delta,s)$. And since $\text{supp}(\mu) \subset E$,
    %
    \begin{equation} \label{equationGGISIICV222}
        d_H(E,E_0) \leq \varepsilon.
    \end{equation}
    %
    Recalling \eqref{equationYYUDUSC4434}, we see that we have proved what was required.
\end{proof}

All that now remains is to show that quasi-all elements of $\mathcal{X}_\beta$ avoid the given set $Z$; just as with the proof above, the advantage of the Baire category approach is that we can reduce our calculations to discussing only a couple scales at once, which allows us to focus solely on the discrete, quantitative question at the heart of the problem.

\section{Random Avoiding Sets}

In the last section, our results held for an arbitrary $\beta \in (0,d]$. But in this section, we assume
%
\[ \beta = \frac{dn - \alpha}{n - 1/2}, \]
%
which will enable us to generically avoid the pattern $Z$ described in Theorem \ref{periodictheorem}. The argument here is very similar to the construction in \cite{OurPaper} albeit in the Baire category setting, though we must modify parameters slightly to ensure a Fourier dimension bound rather than a Hausdorff dimension bound.

\begin{lemma} \label{LemmaVIVIJCIJSIJ}
    Suppose $Z \subset \TT^{dn}$ is a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Then for quasi-all $(E,\mu) \in \mathcal{X}_\beta$, for any distinct points $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$.
\end{lemma}
\begin{proof}
    The set $Z \subset \RR^{dn}$ is the countable union of sets with lower Minkowski dimension at most $\alpha$. For a closed set $W \subset \TT^{dn}$ with lower Minkowski dimension at most $\alpha$, and $s > 0$, consider the set
    %
    \[ B(W,s) = \left\{ (E,\mu) \in \mathcal{X}_\beta: \begin{array}{c}
            \text{for all $x_1, \dots, x_n \in E$ such that}\\
            \text{$|x_i - x_j| \geq s$ for $i \neq j$, $(x_1, \dots, x_n) \not \in W$}
        \end{array} \right\}. \]
    %
    If $(E_0,\mu_0) \in B(W,s)$, then because $E_0$ is compact, so too is the set
    %
    \[ F = \{ (x_1,\dots,x_n) \in E_0^n : |x_i - x_j| \geq s\ \text{for $i \neq j$} \} \]
    %
    Since $W$ is also closed, hence compact, there exists $\varepsilon > 0$ such that if $(x_1,\dots,x_n) \in F$, then $d((x_1,\dots,x_n),W) > \varepsilon$. It follows that if $d_H(E_0,E) \leq \varepsilon$, then for any measure $\mu$ supported on $E$, $(E,\mu) \in B(W,s)$. Thus $B(W,s)$ is an open subset of $\mathcal{X}_\beta$. If $Z$ is a countable union of closed sets $\{ Z_k \}$ with lower Minkowski at most $\alpha$, then clearly the set
    %
    \[ \bigcup_{k = 1}^\infty \bigcup_{n = 1}^\infty B(Z_k,1/n) \]
    %
    consists of the family of sets $(E,\mu)$ such that for distinct $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$. Thus it suffices to show that $B(W,s)$ is dense in $\mathcal{X}_\beta$ for any $s > 0$, and any closed set $W$ with lower Minkowski dimension at most $\alpha$.

    Let us begin by fixing a set $W \subset \TT^{dn}$ and a pair $(E_0,\mu_0) \in \mathcal{X}_\beta$. We will show that for any $\varepsilon_1 \in (0,\beta/100]$ and $\varepsilon > 0$, we can find $(E,\mu) \in B(W,s)$ with $d_H(E,E_0) \leq \varepsilon$ and $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$. We may assume by Corollary \ref{corollaryOIDJOWIJD2212} that $\text{supp}(\mu_0) = E$ and $\mu_0 \in C^\infty(\TT^d)$. Since $W$ has lower Minkowski dimension at most $\alpha$, we can find arbitrarily small $r \in (0,1)$ such that
    %
    \begin{equation} \label{equationGGSCSAS}
        |W_r| \leq r^{dn - \alpha - \varepsilon_1/4}.
    \end{equation}
    %
    Assume also that $r$ is small enough that we can find an integer $K \geq 10$ with
    %
    \begin{equation} \label{equationICCISAXAX122412}
        r^{\varepsilon_1/2 - \beta} \leq K \leq r^{\varepsilon_1/2 - \beta} + 1.
    \end{equation}
    %
    Let $X_1, \dots, X_K$ be independent and uniformly distributed on $\TT^d$. For each distinct set of indices $k_1, \dots, k_n \in \{ 1, \dots, K \}$, the random vector $X_k = (X_{k_1}, \dots, X_{k_n})$ is uniformly distributed on $\TT^{nd}$, and so \eqref{equationGGSCSAS} and \eqref{equationICCISAXAX122412} imply that
    % \psi_1 = \varepsilon \beta
    % \varepsilon \leq n - 1/2
    % \psi_2 \leq \beta/2
    % \psi_2 = 2 \varepsilon \beta
    \begin{equation} \label{equationGGASDCJWIJSFGGGG}
    \begin{split}
        \PP(d(X_k,W) \leq r) \leq |W_{r}| &\leq r^{dn - \alpha - \varepsilon_1/4}\\
        &\lesssim_{d,n,\beta} K^{\frac{-(dn - \alpha - \varepsilon_1/4)}{\beta - \varepsilon_1/2}}\\
        &= K^{- \left( n - 1/2 - \varepsilon_1 / 4 \beta \right) \left( 1 + \frac{\varepsilon_1}{2\beta - \varepsilon_1} \right)}\\
        &= K^{1/2 - n + \varepsilon_1 / 4\beta - \frac{\varepsilon_1}{2\beta - \varepsilon_1}\left( n - 1/2 - 6\varepsilon_1/\beta \right)}\\
        &\leq K^{1/2 - n + \varepsilon_1/4\beta - \frac{\varepsilon_1}{2\beta - \varepsilon_1}} \leq K^{1/2 - n}.
    \end{split}
    \end{equation}
    %
    If $M_0$ denotes the number of indices $i$ such that $d(X_i,W) \leq r$, then by linearity of expectation we conclude from \eqref{equationGGASDCJWIJSFGGGG} that there is a constant $C$ depending only on $d$, $n$, and $\beta$ such that
    %
    \begin{equation} \label{equationDDASGVV}
        \EE(M_0) \leq (C/10) K^{1/2}.
    \end{equation}
    %
    Applying Markov's inequality to \eqref{equationDDASGVV}, we conclude that
    %
    \begin{equation} \label{equationFGGGSC}
        \PP(M_0 \geq C K^{1/2}) \leq 1/10.
    \end{equation}
    %
    %For each cube $I$ with sides parallel to the axis of $\TT^d$, and with sidelength $K^{-1/4d}$, we find
    %
%    \begin{equation} \label{equationDIOJOIDJSOIJ2222312414}
%    \begin{split}
%        \PP \left( \text{there is $i \in \{ 1, \dots, K \}$ such that $X_i \in I$} \right) &= 1 - (1 - K^{-1/4})^K \geq 1 - K^{-3/4}.
%    \end{split}
%    \end{equation}
    %
%    Now $\TT^d$ is covered by a family of at most $K^{1/4}$ such cubes $I$. If $F = \{ X_1, \dots, X_K \}$, then a union bound applying \eqref{equationDIOJOIDJSOIJ2222312414} repeatedly shows
    %
%    \begin{equation} \label{equationOIJIOWJDIOWJ23122142}
%        \PP \left( d_H(F,\TT^d) \leq d^{1/2} K^{-1/4d} \right) \geq 1 - K^{-1/2}.
%    \end{equation}
    %
%    In particular, we conclude from \eqref{equationOIJIOWJDIOWJ23122142} that there is $K_0$ depending only on $d$ and $\varepsilon$ such that if $K \geq K_0$, then
    %
%    \begin{equation} \label{equationOIWJOIAWJDOIWJ}
%         \PP \left( d_H(F,\TT^d) \leq d^{1/2} K^{-1/4d} \right) \leq 1/10.
%    \end{equation}
    %
    Taking a union bound to \eqref{equationFGGGSC} %\eqref{equationOIWJOIAWJDOIWJ}
    and the result of Lemma \ref{LemmaGISCICS1}, we conclude that there exists $K$ points $x_1, \dots, x_K \in \TT^d$ and a constant $C$ depending only on $d$, $n$, and $\beta$ such that the following two statements hold:
    %
    \begin{itemize}
        \item[(1)] Let $S$ be the set of indices $k_1 \in \{ 1, \dots, K \}$ with the property that we can find distinct indices $k_2, \dots, k_n \in \{ 1, \dots, K \}$ such that if $X = (X_{k_1}, \dots, X_{k_n})$, then $d(X, W) \leq r$. Then
        %
        \begin{equation} \label{equationGGSC99124}
            \#(S) \leq C K^{1/2}.
        \end{equation}

        \item[(2)] If we define
        %
        \[ D_0(x) = \frac{1}{K} \sum_{k = 1}^K \delta(x - x_k) \]
        %
        then for $|\xi| \leq K^{1/\beta + 1}$,
        %
        \begin{equation} \label{equationGGGISCI11242}
            |\widehat{D_0}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
        \end{equation}
    \end{itemize}
    %
    Thus \eqref{equationGGSC99124} and \eqref{equationGGGISCI11242} imply that if
    %
    \[ D_1(x) = \sum_{k \not \in S} \delta(x - x_k), \]
    %
    then for each $|\xi| \leq K^{1/\beta_0 + 1}$,
    %
    \begin{equation} \label{equationGGSCSIAXAXXXSFGG}
        |\widehat{D_1}(\xi)| \leq 2C K^{-1/2} \log(K).
    \end{equation}
    %
    Since $K \geq r^{\varepsilon_1/2 - \beta}$, we can apply Corollary \ref{lemmaIOJDD23124} for any $\delta > 0$ in conjunction with \eqref{equationGGSCSIAXAXXXSFGG} to find $r_0(q)$ depending only on $d$, $q$, $n$, $\beta$, $\mu_0$, $\varepsilon$, $\delta$, and $\varepsilon_1$ such that if $r \leq \min(r_0(q),s)$ and we define
    %
    \[ \mu'(x) = \left( \sum_{k \not \in S} \phi_{(1/2n^{1/2}) r}(x - X_k) \right) \mu_0(x), \]
    %
    and then set $\mu = \mu' / \mu'(\TT^d)$, then
    %
    \begin{equation} \label{equationvVVV323285853S}
        \| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \min(\delta,\varepsilon).
    \end{equation}
    %
    Choosing $\delta$ in accordance with Lemma \ref{LemmaTAOIAWOIDJ12301}, \eqref{equationvVVV323285853S} also implies that
    %
    \[ d_H(\text{supp}(\mu), \text{supp}(\mu_0)) \leq \varepsilon. \]
    %
    Thus all that remains to prove the density statement is to show that if $E = \text{supp}(\mu)$, then $(E,\mu) \in B(W,s)$.

    Consider $n$ points $y_1, \dots, y_n \in \text{supp}(\mu)$, with $|y_i - y_j| \geq r$ for any two indices $i \neq j$. We can therefore find distinct indices $k_1, \dots, k_n \in \{ 1, \dots, K \}$ such that for each $i \in \{ 1, \dots, n \}$,
    %
    \begin{equation} \label{equationFFISICSIC223}
        |x_{k_i} - y_i| \leq (n^{-1/2}/2) \cdot r.
    \end{equation}
    %
    If we set $x = (x_{k_1}, \dots, x_{k_n})$ and $y = (y_1, \dots, y_n)$, then \eqref{equationFFISICSIC223} implies
    %
    \begin{equation} \label{equationFISICISCI232222452}
        |x - y| \leq (r/2).
    \end{equation}
    %
    Since $i_1 \not \in S$, $d(x,W) \geq r$, which combined with \eqref{equationFISICISCI232222452} implies
    %
    \begin{equation} \label{equationSICSICI}
        d(y,W) \geq d(x,W) - |x - y| \geq r/2.
    \end{equation}
    %
    Thus in particular we conclude $y \not \in W$, which shows $(E,\mu) \in B(W,s)$.
\end{proof}

Before we move onto the next proof, let us discuss where the loss in Theorem \ref{maintheorem} occurs in our proof, as compared to the Hausdorff dimension bound of \cite{OurPaper}. In the proof of Lemma \ref{LemmaVIVIJCIJSIJ}, in order to obtain the bound \eqref{equationGGSCSIAXAXXXSFGG}, we were forced to choose the parameter $r$ such that $\#(S) \leq K^{1/2}$, so that we can use the trivial bound
%
\begin{equation}
    \left| \sum_{k \in S} e^{2 \pi i (\xi \cdot x_k)} \right| \leq \#(S) \leq K^{1/2}.
\end{equation}
%
On the other hand, if we were able to justify that with high probability, we could obtain a square root cancellation bound
%
\begin{equation}
    \left| \sum_{k \in S} e^{2 \pi i (\xi \cdot x_k)} \right| \lesssim \#(S)^{1/2},
\end{equation}
%
then we would only need to choose the parameter $r$ such that $\#(S) \lesssim K$, which leads to a set with larger Fourier dimension, matching with the relevant Hausdorff dimension bound obtained in \cite{OurPaper}. We are able to carry out this square root cancellation calculation completely when the set $W$ we are avoiding has greater regularity, i.e. it is a Lipschitz manifold.

\section{The More Difficult Case}

Let us now consider the more difficult case. We consider a manifold $W \subset \TT^{dn}$ of dimension $dn - d$ with the appropriate regularity condition, and set
%
\[ \beta = \frac{d}{n-1}. \]
%
Given any family of disjoint, sidelength $s$ cubes $R_1,\dots,R_n \subset \TT^d$ such that $d(R_i,R_j) \geq 10s$, we let
%
\[ H(W;R_1,\dots,R_n) = \left\{ (E,\mu) \in \mathcal{X}_\beta: (R_1 \times \dots \times R_n) \cap E^n \cap W = \emptyset \right\}. \]
%
Then $H(W;R_1,\dots,R_n)$ is an open subset of $\mathcal{X}_\beta$. For the purpose of a Baire category argument, our result will follow by showing $H(W;R_1,\dots,R_n)$ is dense in $\mathcal{X}_\beta$ for each family of cubes $\{ R_1,\dots, R_n \}$. Without loss of generality, possibly permuting coordinates if necessary we may assume that $1/s$ is an integer, and that for the family of cubes $\{ R_1,\dots, R_n \}$, if $Q_1 = 2R_1,\dots, Q_n = 2R_n$, then there exists a Lipschitz function $f: Q_2 \times \dots \times Q_n \to \RR^d$ such that
%
\[ W \cap (Q_1 \times \dots \times Q_n) = \{ (x_1,\dots,x_d) \in Q_1 \times \dots \times Q_n : x_1 = f(x_2,\dots,x_d) \}. \]
%
Fix a constant $L \geq 0$ such that for any $x,x' \in Q_2 \times \dots \times Q_n$,
%
\begin{equation}
    |f(x - x')| \leq L |x - x'|.
\end{equation}
%
As with the previous proof, we fix $(E_0,\mu_0) \in \mathcal{X}_\beta$ with $\text{supp}(\mu_0) = E_0$ and $\mu_0 \in C^\infty(\TT^d)$, and show that for any $\varepsilon_1 \in (0,\beta/100]$ and $\varepsilon > 0$, there is $(E,\mu) \in H(W;Q_1,\dots,Q_n)$ with $\| \mu - \mu_0 \|_{M(\beta/2-\varepsilon_1)} \leq \varepsilon$.

Consider a family of independant random variables $\{ X_i(k) : 1 \leq i \leq n, 1 \leq k \leq K \}$, where each $X_i(k)$ is uniformly distributed on $Q_i$. Set $K_1 = K(s^{-d} - n)$ (an integer since $s$ is a power of two), and consider an additional family of independant random variables $\{ X_0(k) : 1 \leq k \leq K_1 \}$, where each $X_0(k)$ is uniformly distributed on $\TT^d - Q_1 - \dots - Q_n$. Let $r = K^{-1/\beta} = 1/K^{\frac{n-1}{d}}$, and then set $S$ be the set of indices $k_1 \in \{ 1, \dots, K \}$ such that there are indices $k_2,\dots,k_n \in \{ 1,\dots,K \}$ with the property that
%
\begin{equation} \label{equationDDIVJIVCJIJSDDKODKI23125}
    |X_1(k_1) - f(X_2(k_2),\dots,X_n(k_n))| \leq r/(L+1).
\end{equation}
%
A simple argument following from \eqref{equationDDIVJIVCJIJSDDKODKI23125}, which we prove in Lemma BLAH, shows that if $k_1 \not \in S$, then for any $k_2,\dots,k_n \in \{ 1, \dots, K \}$, if $X = (X_1(k_1),\dots,X_n(k_n))$, then $d(X,W) \geq r$. If we define
%
\[ \mu_k'(x) = \left( \sum_{k = 1}^{K_1} \phi_{(1/2n^{1/2}) r}(x - X_0(k)) \right) \]




Then for any nonzero $\xi \in \ZZ^d$,
%
\begin{equation} \label{equationFIJCIJVIJVIVJIV1231312}
    \EE \left( \sum_{k = 1}^{K_1} e^{2 \pi i \xi \cdot X_0(k)} + \sum_{i = 1}^n \sum_{k = 1}^K e^{2 \pi i \xi \cdot X_i(k)} \right) = 0.
\end{equation}
%
Let $r = K^{-1/\beta} = 1/K^{\frac{n-1}{d}}$, and then set $S$ be the set of indices $k_1 \in \{ 1, \dots, K \}$ such that there are indices $k_2,\dots,k_n \in \{ 1,\dots,K \}$ with the property that
%
\[ |X_1(k_1) - f(X_2(k_2),\dots,X_n(k_n))| \leq r. \]
%
Now for each $\xi \in \ZZ^d$, let
%
\[ Y_\xi = \sum_{k \in S} e^{2 \pi i \xi \cdot X_k}. \]
%
If we write $\Omega \subset Q_1$ to be the set of values $x \in Q_1$ such that there are $k_2,\dots,k_n \in \{ 1,\dots,K \}$ such that
%
\[ |x - f(X_2(k_2),\dots,X_n(k_n))| \leq r, \]
%
then
%
\[ Y_\xi = \sum_{k = 1}^K Z_k \]
%
where
%
\[ Z(k) = \begin{cases} e^{2 \pi i \xi \cdot X_1(k)} &: X_1(k) \in \Omega, \\ 0 &: X_1(k) \not \in \Omega \end{cases}. \]
%
If $\Sigma$ is the $\sigma$ algebra generated by the random variables $\{ X_i(k) : i \geq 2, k \in \{ 1, \dots, K \} \}$, then the random variables $\{ Z(k) \}$ are \emph{conditionally independant} (and identically distributed) given $\Sigma$. Since we have $|Z(k)| \leq 1$ almost surely, Hoeffding's inequality thus implies that for all $t \geq 0$,
%
\[ \PP \left( \left| Y_\xi - \EE(Y_\xi|\Sigma) \right| \geq t \right) \leq 4 \exp \left( \frac{-t^2}{2K} \right). \]
%
It is simple to see that
%
\[ \EE(Y_\xi | \Sigma) = \frac{K}{|Q_1|} \int_\Omega e^{2 \pi i \xi \cdot x}\; dx=  \frac{K}{s^d} \int_\Omega e^{2 \pi i \xi \cdot x}\; dx. \]
%
Since
%
\[ \Omega = \bigcup \left\{ B(f(X_2(k_2),\dots,X_n(k_n)),r) \right\}. \]
%
we see that varying each random variable $X_i(k)$ adjusts at most $K^{n-2}$ of these balls, and thus varying $X_i(k)$ independantly of the other random variables changes $\EE(Y_\xi|\Sigma)$ by at most
%
\[ \frac{2^d r^d K^{n-1}}{s} \leq \frac{2^d}{s}. \]
% K^{-(n-1)} = r^d
% 
Thus McDiarmid's inequality shows that for any $t \geq 0$,
%
\[ \PP \left( |\EE(Y_\xi|\Sigma) - \EE(Y_\xi)| \geq t \right) \leq 4 \exp \left( \frac{s}{n 2^d} \cdot \frac{-2t^2}{K} \right). \]
%
Combining BLAH and BLAH, we conclude that
%
\[ \PP \left( | Y_\xi - \EE(Y_\xi) | \geq t  \right) \leq 8 \exp \left( \min \left( \frac{s}{n2^{d+1}}, 1/8 \right) \cdot \frac{-t^2}{K} \right) \]
%
Now for each $x \in Q_1$, we find that
%
\begin{align*}
    \PP(x \in \Omega) &= \PP(\text{There is $k_2,\dots,k_n$ s.t. $|f(X_2(k_2),\dots,X_n(k_n)) - x| \leq r$}).
\end{align*}

Now
%
\[ \EE(Y_\xi) = \EE(\EE(Y_\xi | \Sigma)) = \frac{K}{s^d} = \frac{K}{s^d} \int_{Q_1} \mathbf{P}(x \in \Omega) e^{2 \pi i \xi \cdot x}\; dx. \]


%
\[ u(x) = \frac{|f^{-1}(B(x,r))|}{s^{d(n-1)}}, \]
%
then
%
\[ \EE(Y_\xi) = \EE(\EE(Y_\xi | \Sigma)) = \int_{Q_1} u(x) e^{2 \pi i \xi \cdot x}. \]
%
Using Fubini's theorem, we find that
%
\begin{align*}
    \int_{Q_1} u(x)\; dx &= \frac{1}{s^{d(n-1)}} \int_{Q_1} \int_{f^{-1}(B(x,r))}\; dy\; dx\\
    &= \frac{1}{s^{d(n-1)}} \int_{Q_2 \times \dots \times Q_d} \int_{B(f(y),r))}\; dx\; dy\\
    &= 
    \sim r^d \sim K^{1-n} \lesssim K^{-1}.
\end{align*}

%$r = K^{-1/\beta} = K^{-(n-1)/d}$
%so
%$ r^d = K^{1-n}$


By permuting coordinate and localizing correctly, we may assume that $W = \{ (x_1,\dots,x_n): x_1 = f(x_2,\dots,x_n) \}$. We have $r \approx K^{-1/\beta}$, and so $\Omega$ is a random `splodge' of $K^{n-1}$ randomly chosen radius $1/K^{(n-1)/d}$ balls, which has total area $O(1)$, so we should expect some overlap, but not too much. It might be useful to assume that $\partial_2 f$ is also bounded from below, since we can probably also treat the case $\partial_2 f$ small separately.
% r = K^{-(n-1)/d}
% What is the estimated overlap with N random variables in {1, ..., N}

 Given that $X^i_k = x^i_k$, the random variable $Y_\xi$ is then the sum of $K$ random variables, which each 

Suppose $X^i_k = x^i_k$

If we let $\Sigma$ be the $\sigma$ algebra generated , then McDiarmid's inequality tells us that
%
\[ \PP \left( |Y_\xi - \EE(Y_\xi | \Sigma)| \geq t \right) \]
%

Now if $\#(S) \leq K$, then if we individually alter each input, we can adjust $Y_\xi$ by at most $2K$. Thus McDiarmid's inequality gives that
%
\[ \PP \left( |Y_\xi - \EE(Y_\xi|BLAH)| \geq t | BLAH \right) \leq 4 \exp \left(- \frac{t^2}{2K^{d-1}} \right). \]
%
Thus $Y_\xi$ deviates from $\EE(Y_\xi|BLAH)$ at a rate of $K^{1/2}$ with low probability, and a union bound over all $\xi$ gives a deviation of $K^{1/2} \log(K)^{1/2}$ with low probability. If we can show that $|\EE(Y_\xi|BLAH)| \leq K^{1/2}$ with high probability, we're be done!.

As a next step, let's calculate $\EE(Y_\xi)$. Each $X_1, \dots, X_K$ independantly has a probability of being in $S$, and the distribution of $e^{2 \pi i \xi \cdot X_k}$ given that $k \in S$ has a particular distribution. Thus $\EE(Y_\xi|BLAH) = K \PP(k \in S|BLAH) \EE(e^{2 \pi i \xi \cdot X_k}|BLAH, k \in S)$.

If
%
\[ W_\varepsilon = \{ (x,y) \in \TT^2: d(x,K^{-1/2} \ZZ) \leq \varepsilon \}, \]
%
then $|W_\varepsilon| \leq K^{1/2} \varepsilon$

Let us think about this in a manner discretized as a scale $\varepsilon$. If $\PP(k \in S| BLAH) \geq K^{-1/2} = \varepsilon^{\beta/2}$, then there are at least $\varepsilon^{\beta/2-1}$ different $\varepsilon$-separated values that $X_k$ can take. Thus $e^{2 \pi i X_k}$ can take. Now $e^{2 \pi i \xi \cdot X}$ points in a particular direction on $|\xi| \varepsilon^{-1}$






If $k_1 \not \in S$, then for any indices $k_2,\dots,k_n \in \{ 1, \dots, K \}$, if $X = (X^1_{k_1},\dots,X^n_{k_n})$, then $d(X,W) \geq r/(L+1)$. To see this, it certainly follows by definition that
%
\[ |X_1(k_1) - f(X_2(k_2),\dots,X_n(k_n))| \geq r. \]
%
If $Y = (Y_1,\dots,Y_n) \in W \cap (Q_1 \times \dots \times Q_n)$, then
%
\begin{align*}
    r &\leq |X_1(k_1) - f(X_2(k_2),\dots,X_n(k_n))|\\
    &\leq |X_1(k_1) - Y_1| + |Y_1 - f(X_2(k_2),\dots,X_n(k_n)|\\
    &= |X_1(k_1) - Y_1| + |f(Y_2,\dots,Y_n) - f(X_2(k_2),\dots,X_n(k_n)|\\
    &\leq |X_1(k_1) - Y_1| + L|(Y_2,\dots,Y_n) - (X_2(k_2),\dots,X_n(k_n))\\
    &\leq (L+1) |X - Y|,
\end{align*}
%
so $|X-Y| \geq r/(L+1)$.

\begin{comment}
Suppose we can show that for any $\xi \neq 0$,
%
\[ |\widehat{Y_1}(\xi) + \dots + \widehat{Y_N}(\xi)| \lesssim C \left( \| \widehat{Y_1} \|_{L^\infty(\RR^d)}^2 + \dots + \| \widehat{Y_N} \|_{L^\infty(\ZZ^d)}^2 \right)^{1/2}. \]
%
In the example we consider, this would then imply
%
\[ |Y_1(\xi) + \dots + Y_N(\xi)| \lesssim N^{1/2}. \]
%
Thus in the last theorem we can take $N = K$,
%
\[ N \leq K^{1 - (2d/\beta)(1 - 1/p)} \]
%
If we can set $p \geq 1$,
\end{comment}

\begin{comment}

\section{Techniques for Avoiding Hyperplanes}

Let $y = f(x)$ be a curve in $\TT^2$ defining a curve $S$, where $f$ is an analytic function (except perhaps at finitely many points?). Given $\varepsilon > 0$, we want to determine the differentiability of the map
%
\[ A(x) = H^1(S_\varepsilon \cap \{ x \times \TT \}). \]
%
We wish to show $A$ is a smooth function. The tangent to $S$ at a point $(x,f(x))$ is given by $(1,f'(x))$, and so the unit normal vector is
%
\[ N(x) = \frac{(f'(x),-1)}{\sqrt{1 + f'(x)^2}}. \]
%
Suppose that $x_0 \in \TT$ is fixed, and let $x \in \TT$ and $|\delta| \leq \varepsilon$ be given such that
%
\[ (x_0,y_0) = (x,f(x)) + \delta N(x) = \left( x + \frac{\delta f'(x)}{\sqrt{1+ f'(x)^2}}, f(x) - \frac{\delta}{\sqrt{1 + f'(x)^2}} \right) \]
%
Thus
%
\[ x_0 = x + \frac{\delta f'(x)}{\sqrt{1 + f'(x)^2}} \]
%
and
%
\[ y_0 = f(x) - \frac{\delta}{\sqrt{1 + f'(x)^2}}. \]
%
Now the first equation tells us that
%
\[ \delta = - (x - x_0) \frac{\sqrt{1 + f'(x)^2}}{f'(x)}. \]
%
Thus if we define
%
\[ g(x,x_0) = \begin{cases} f(x) + \frac{x - x_0}{f'(x)} &: f'(x) \neq 0 \\ BLAH &: BLAH, \end{cases} \]
%
then $y_0 = g(x,x_0)$. Thus we ask ourselves what is the value of
%
\[ A(x_0) = \max \left\{ f(x) + \frac{x - x_0}{f'(x)} : |x - x_0| \leq \frac{\varepsilon |f'(x)|}{\sqrt{1 + f'(x)^2}} \right\}. \]
%
Now $g(x,x_0)$ is a smooth function except where $f'(x) = 0$. In particular, if $f'(x_0) \neq 0$, then the constraint region defining $A(x_0)$ is a finite union of closed intervals. And $f'(x_0) = 0$ only at finitely many points, and if we make $\varepsilon$ small enough we can make $A(x_0) = f(x_0) + \varepsilon$ at these points.

so this causes us no problems since we only care about whether $A$ is differentiable except at finitely many points. To analyze $A(x_0)$ when $f'(x_0) = 0$, we note that a solution that gives the maximum either satisfies
%
\[ f'(x)(f'(x)^2 + 1) + (x - x_0) f''(x) = 0 \]
%
or
%
\[ x - x_0 = \frac{\varepsilon f'(x)}{\sqrt{1 + f'(x)^2}} \]
%
or
%
\[ x - x_0 = \frac{-\varepsilon f'(x)}{\sqrt{1 + f'(x)^2}}. \]
%
If $\varepsilon$ is small enough, then the implicit function theorem implies that the second and third equations have finitely many solutions for each $x_0$, which are locally smoothly parameterized. Since $f'(x_0) \neq 0$, the first equation does not even have any solutions if $\varepsilon \lesssim 1$. Thus we conclude that if $\varepsilon$ is small enough, there exists a function $x(x_0)$ which is smooth, except at finitely many points, such that
%
\[ g(x_0) = f(x) + \frac{x - x_0}{f'(x)}. \]
%
Thus at any $x_0$ where $x$ is smooth, we conclude
%
\[ g'(x_0) = f'(x) \cdot x' + \frac{x' - 1}{f'(x)} - \frac{x - x_0}{f'(x)^2} f''(x) x'. \]

\end{comment}

\begin{thebibliography}{9}

\bibitem{Korner1}
    T.W. K\"{o}rner,
    \textit{Measures on Independent Sets, A Quantitative Version of Rudin's Theorem}.

\bibitem{Korner2}
    T.W. K\"{o}rner,
    \textit{Fourier transforms of measures and algebraic relations on their supports}.

\bibitem{OurPaper}
    Jacob Denson, Malabika Pramanik, Joshua Zahl,
    \textit{Large sets avoiding rough patterns}.

\bibitem{myThesis}
    Jacob Denson,
    \textit{Cartesian products avoiding patterns}.

%\bibitem{Vershynin}
%    Roman Vershynin,
%    \textit{High dimensional probability},
%    Cambridge Series in Statistical and Probabilistic Mathematics,
%    2018.

\bibitem{VanHandel}
    Ramon van Handel
    \textit{Probability in High Dimensions},
    2016.

\bibitem{Ekstrom2014}
    Fredrik Ekstr\"{o}m, Tomas Persson J\"{o}rg Schmeling,
    \textit{On the Fourier dimension and a modification},
    2015.

\end{thebibliography}

\end{document}
