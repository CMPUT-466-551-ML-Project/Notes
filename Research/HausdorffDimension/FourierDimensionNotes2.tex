\documentclass[12pt,reqno]{article}

%\documentclass[dvipsnames,letterpaper,12pt]{article}

\usepackage[margin = 1in]{geometry}
\usepackage{amsmath,amssymb,graphicx,mathabx,accents}
\usepackage{enumerate,mdwlist}

%\setlist[enumerate]{label*={\normalfont(\Alph*)},ref=(\Alph*)}

\numberwithin{equation}{section}

\usepackage{amsthm}

\usepackage{hyperref}

\usepackage{verbatim}

\usepackage{nag}

\DeclareMathOperator{\minkdim}{\dim_{\mathbf{M}}}
\DeclareMathOperator{\hausdim}{\dim_{\mathbf{H}}}
\DeclareMathOperator{\lowminkdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\upminkdim}{\overline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\fordim}{\dim_{\mathbf{F}}}

\DeclareMathOperator{\lhdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\lmbdim}{\underline{\dim}_{\mathbf{MB}}}

\DeclareMathOperator{\RR}{\mathbf{R}}
\DeclareMathOperator{\ZZ}{\mathbf{Z}}
\DeclareMathOperator{\QQ}{\mathbf{Q}}
\DeclareMathOperator{\TT}{\mathbf{T}}
\DeclareMathOperator{\CC}{\mathbf{C}}

\DeclareMathOperator{\B}{\mathcal{B}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{prop}[theorem]{Proposition}
\newtheorem{remark}{Remark}
\newtheorem*{concludingremarks}{Concluding Remarks}

\DeclareMathOperator{\EE}{\mathbf{E}}
\DeclareMathOperator{\PP}{\mathbf{P}}

\DeclareMathOperator{\DQ}{\mathcal{Q}}
\DeclareMathOperator{\DR}{\mathcal{R}}

\newcommand{\psitwo}[1]{\| {#1} \|_{\psi_2(L)}}
\newcommand{\TV}[2]{\| {#1} \|_{\text{TV}({#2})}}








\title{Salem Sets Avoiding Rough Configurations}
\author{Jacob Denson}

\begin{document}

\maketitle

\section{Introduction}

Geometric measure theory explores the relationship between the geometry of subsets of Euclidean spaces, and regularity properties of the family of Borel measures supported on those subsets. From the perspective of harmonic analysis, it is interesting to explore what structural information can be gathered from the Fourier analytic properties of measures supported on a particular subset of Euclidean space. In this paper, we focus on the relationship between the Fourier analytic properties of a set and the existence of patterns on the set. In particular, given a `rough pattern', in the sense of \cite{OurPaper}, we construct a family of sets which generically avoids this pattern, and which supports measures with fast Fourier decay.

A useful statistic associated with any Borel set $E \subset \RR^d$ is it's \emph{Fourier dimension}; given a finite Borel measure $\mu$ on $\RR^d$, it's Fourier dimension, $\fordim(\mu)$, is the supremum of all $s \in [0,d]$ such that
%
\begin{equation} \label{fordim}
    \sup \left\{ |\widehat{\mu}(\xi)| |\xi|^{s/2} : \xi \in \RR^d \right\} < \infty.
\end{equation}
%
The Fourier dimension of a Borel set $E \subset \RR^d$, denoted $\fordim(E)$, is then the supremum of $\fordim(\mu)$, over all Borel probability measures $\mu$ supported on $E$. A particularly tractable family of sets in this scheme are \emph{Salem sets}, those sets whose Fourier dimension agrees with their Hausdorff dimension. Most classical fractal sets are not Salem, often having Fourier dimension zero. Nonetheless, the sets we construct in this paper are Salem.

\begin{theorem} \label{maintheorem}
    Let $0 \leq \alpha < dn$, and let $Z \subset \RR^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Then there exists a compact Salem set $X \subset [0,1]^d$ with dimension
    %
    \[ \beta = \min \left( \frac{nd - \alpha}{n-1/2}, d \right) \]
    %
    such that for any distinct points $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

\begin{remark}
    Theorem \ref{maintheorem} is an attempt to strengthen the main result of \cite{OurPaper} to give a Fourier dimension bound, albeit under a weaker dimension bound. Unlike in \cite{OurPaper}, the case of Theorem \ref{maintheorem} when $0 \leq \alpha < d$ is still interesting, since the trivial construction $[0,\pi]^d - \pi(Z)$ is not necessarily a Salem set, where $\pi(x_1, \dots, x_n) = x_1$ is projection onto the first coordinate. For instance, in Example 8 of \cite{Ekstrom2014} it is shown that there exists a compact set $E \subset [0,1]$ such that $\minkdim(E) < 1$ and $\fordim([0,1] - E) < 1$. Setting $Z = E \times \{ 0 \} \cup \{ 0 \} \times E$ shows that neither subtracting projections onto the first nor the second coordinate gives the required Fourier dimension bounds.
\end{remark}

\begin{comment}
A well-known result in this pattern avoidance setting is that sets with large Fourier dimension satisfy many algebraic relations. More precisely, if integer coefficients $m_1, \dots, m_n \in \ZZ$ are fixed, and we consider a compact set $X \subset \RR$ with $\fordim(X) > 2/n$, then the sum set $m_1 X + \dots + m_n X$ contains an open interval. It follows by a slight modification of these coefficients that if $X \subset \RR$ and $\fordim(X) > 2/n$, then there exists $m_1, \dots, m_n \in \ZZ$, distinct points $x_1, \dots, x_n \in X$, and an additional integer $a \in \ZZ$, such that
%
\begin{equation} \label{intequation}
    m_1 x_1 + \dots + m_n x_n = a.
\end{equation}
%
It is an interesting to determine how tight this result is. In \cite{Korner2}, T.W. K\"{o}rner constructs a Salem set $X$ with Fourier dimension $1/(n-1)$ such that for non-zero $m \in \ZZ^n$, and $a \in \ZZ$, $X$ does not contain distinct points $x_1, \dots, x_n$ solving \eqref{intequation}. If, for each nonzero $m \in \ZZ^n$ and $a \in \ZZ$, we consider the set
%
\[ Z_{m,a} = \left\{ (x_1, \dots, x_n) \in [0,1]^n : m_1x_1 + \dots + m_n x_n = a \right\}, \]
%
then $Z_{m,a}$ is a subset of an $n-1$ dimensional hyperplane, and thus can be easily seen to have Minkowski dimension $n-1$. It follows that we can apply Theorem \ref{maintheorem} to $Z = \bigcup \{ Z_{m,a} : m \neq 0, a \in \ZZ \}$ to obtain a Salem set $X \subset [0,1]$ with dimension
%
\[ \frac{n - (n-1)}{n - 1} = \frac{1}{n-1}, \]
%
such that $(x_1, \dots, x_n) \not \in Z$ for each distinct $x_1, \dots, x_n \in X$. This means precisely that $X$ avoids solutions to $\eqref{intequation}$ for all nonzero $m \in \ZZ^n$ and $a \in \ZZ$. Thus we see Theorem \ref{maintheorem} generalizes K\"{o}rner's result, and thus shows the result depends little on the arithmetic properties of the pattern K\"{o}rner avoids, but rather, depends only on the `thickness' of the family of tuples $(x_1, \dots, x_n)$ satisfying the pattern. Since we expect Theorem \ref{maintheorem} to be tight for general sets, an improvement to K\"{o}rner's construction must rely more heavily on the algebraic properties of the pattern involved.
\end{comment}

Because we are working with \emph{compact} sets avoiding patterns, working in the domain $\RR^d$ is not significantly different from working in a periodic domain $\TT^d = \RR^d / \ZZ^d$, and working in this space has several advantages over the Euclidean case. For a finite measure $\mu$ on $\TT^d$, we can define it's Fourier dimension $\fordim(\mu)$ as the supremum of all $0 \leq s \leq d$ such that
%
\begin{equation} \label{fordimtorus}
    \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{s/2} < \infty.
\end{equation}
%
We can then define the Fourier dimension of any Borel set $E \subset \TT^d$ as the supremum of $\fordim(\mu)$, over all Borel measures $\mu$ supported on $E$. Since $\TT^d$ has a natural metric space structure, we can define the Hausdorff dimension of sets on $\TT^d$. It is a simple consequence of the Poisson summation formula that if $\mu$ is a compactly supported measure on $\RR^d$, then \eqref{fordim} is equivalent to the more discrete condition
%
\begin{equation} \label{discretefordim}
    \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{s/2} < \infty.
\end{equation}
%
A proof is given in Lemma 39 of \cite{myThesis}. In particular, if $\mu^*$ is the \emph{periodization} of $\mu$, i.e. the measure on $\TT^d$ such that for any $f \in C(\TT^d)$,
%
\begin{equation}
    \int_{\TT^d} f(x)\; d\mu^*(x) = \int_{\RR^d} f(x)\; d\mu(x),
\end{equation}
%
then \eqref{discretefordim}, together with the Poisson summation formula, implies $\fordim(\mu^*) = \fordim(\mu)$. Since $\mu$ is compactly supported, it is also simple to see that $\hausdim(\mu^*) = \hausdim(\mu)$. Thus Theorem \ref{maintheorem} is clearly equivalent to it's periodic variant, introduced below as Theorem \ref{periodictheorem}.

\begin{theorem} \label{periodictheorem}
    Let $0 \leq \alpha < dn$, and let $Z \subset \TT^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Then there exists a compact Salem set $X \subset \TT^d$ with dimension
    %
    \[ \beta = \min \left( \frac{dn - \alpha}{n-1/2}, d \right) \]
    %
    such that for any distinct points $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

To construct our set, we rely on a Baire-category argument. Thus we consider a complete metric space $\mathcal{X}_\beta$, whose elements consist of pairs $(E,\mu)$, where $E$ is a subset of $\TT^d$, and $\mu$ is a probability measure supported on $E$. We then show that for \emph{quasi-all} elements $(E,\mu) \in \mathcal{X}_\beta$, $E$ is a Salem set of dimension $\beta$, and is pattern avoiding, in the sense that the set of pairs $(E,\mu)$ which do not satisfy these properties is a set of first category in $\mathcal{X}_\beta$. It follows that Theorem \ref{periodictheorem} holds in a `generic' sense for elements of $\mathcal{X}_\beta$.

Once we have setup the appropriate metric space $\mathcal{X}_\beta$, our approach is quite similar to the construction in \cite{OurPaper}, relying on a random selection procedure, which is now exploited to give high probability bounds on the Fourier transform of the measures we study. The use of the Baire category approach in this paper, rather than an algorithmic, `nested set' approach as used in \cite{OurPaper}, is mostly of an aesthetic nature, avoiding the complex queuing method and dyadic decomposition strategy required in the nested set approach; our approach can, with some care, be converted into a queuing procedure like in \cite{OurPaper}. But the Baire category argument makes our proof much simpler to read, and has the advantage that it indicates that Salem sets of a specified dimension `generically' avoid a given rough pattern.% Moreover, the proof of the Baire category theorem is in some senses, `hidden' in the queuing method, so the two methods are, aside from small technical differences, equivalent to one another.

\section{Notation} \label{notationSection}

\begin{itemize}
%    \item For a positive integer $N$, we let $[N] = \{ 1, \dots, N \}$.

    \item Given a metric space $\Omega$ (here either $\RR^d$ or $\TT^d$), $x \in \Omega$, and $\varepsilon > 0$, we shall let $B_\varepsilon(x)$ denote the open ball of radius $\varepsilon$ around $x$. For a given set $E \subset \Omega$ and $\varepsilon > 0$, we let
    %
    \[ E_\varepsilon = \bigcup_{x \in E} B_\varepsilon(x), \]
    %
    denote the \emph{$\varepsilon$-thickening} of the set $E$. A subset of $\Omega$ is of \emph{first category} in $\Omega$ if it is the countable union of closed sets with nonempty interior. We say a property holds \emph{quasi-always}, or a property is \emph{generic} in $\Omega$ if the set of points in $\Omega$ failing to satisfy that property form a set of first category.

    \item We let $\TT^d = \RR^d/\ZZ^d$. Given $x \in \TT$, we let
    %
    \[ |x| = \min \{ |x + n| : n \in \ZZ \}, \]
    %
    and for $x \in \TT^d$, we let
    %
    \[ |x| = \sqrt{|x_1|^2 + \dots + |x_d|^2}. \]
    %
    The canonical metric on $\TT^d$ is then given by $d(x,y) = |x - y|$, for $x,y \in \TT^d$.

    \item Suppose $\mathbf{E} = \TT^d$ or $\mathbf{E} = \RR^d$. For $\alpha \in [0,d]$ and $\delta > 0$, we define the Hausdorff content of a Borel set $E \subset \mathbf{E}$ as
    %
    \[ H^\alpha_\delta(E) = \inf \left\{ \sum_{i = 1}^\infty \varepsilon_i^\alpha : E \subset \bigcup_{i = 1}^\infty B_{\varepsilon_i}(x_i)\ \text{and $\varepsilon_i \leq \delta$ for all $i \in \mathbf{N}$} \right\}. \]
    %
    The $\alpha$ dimensional Hausdorff measure of $E$ is equal to
    %
    \[ H^\alpha(E) = \lim_{\delta \to 0} H^\alpha_\delta(E). \]
    %
    The Hausdorff dimension $\hausdim(E)$ of a Borel set $E$ is then the infinum over all $s \in [0,d]$ such that $H^s(E) = \infty$, or alternatively, the supremum over all $s \in [0,d]$ such that $H^s(E) = 0$.
    %Frostman's lemma says that if we define the Hausdorff dimension $\hausdim(\mu)$ of a finite Borel measure $\mu$ as the supremum of all $s \in [0,d]$ such that
    %
    %\begin{equation} \label{hausdim}
    %    \sup \left\{ \mu(B_\varepsilon(x)) \cdot \varepsilon^{-\alpha} : x \in \RR^d, \varepsilon > 0 \right\} < \infty,
    %\end{equation}
    %
    %then $\hausdim(E)$ is the supremum of $\hausdim(\mu)$, over all Borel probability measures $\mu$ supported on $E$, analogous to the definition of the Fourier dimension of a set $E$ given in the introduction.

    \item Suppose $\mathbf{E} = \RR^d$ or $\mathbf{E} = \TT^d$, and for a measurable set $E$, we let $|E|$ denote it's Lebesgue measure. We define the lower Minkowski dimension of a compact Borel set $E \subset \mathbf{E}$ as
    %
    \[ \lowminkdim(E) = \liminf_{\varepsilon \to 0} \log_\varepsilon|E_\varepsilon|. \]

    \item In this paper we will need to employ concentration bounds several times. In particular, we use \emph{McDiarmid's inequality}, trivially modified from the standard theorem to work with complex-valued functions. Let $\{ X_1, \dots, X_N \}$ be an independant family of random variables, and consider a measurable function $f: \RR^N \to \CC$. Suppose that for each $i \in \{ 1, \dots, N \}$, there exists a constant $A_i > 0$ such that for $x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_N \in \RR$, and for each $x_i, x_i' \in \RR$,
    %
    \[ |f(x_1, \dots, x_i, \dots, x_N) - f(x_1, \dots, x_i', \dots, x_N)| \leq A_i. \]
    %
    Then McDiarmid's inequality guarantees that for all $t \geq 0$,
    %
    \[ \PP \left( |f(X_1, \dots, X_N) - \EE(f(X_1, \dots, X_N))| \geq t \right) \leq 4 \exp \left( \frac{-2t^2}{A_1^2 + \dots + A_N^2} \right). \]
    %
    The complex-valued extension we have just stated is proved easily from the real-valued case by taking a union bound to the inequality for the real and imaginary values of $f$.

    A special case of McDiarmid's inequality is \emph{Hoeffding's Inequality}. The version of Hoeffding's inequality we use states that if $\{ X_1, \dots, X_N \}$ is an independent family of mean-zero random variables, such that for each $i$, there exists a constant $A_i \geq 0$ such that $|X_i| \leq A_i$ almost surely, then for each $t \geq 0$,
    %
    \[ \PP \left( |X_1 + \dots + X_N| \geq t \right) \leq 4 \exp \left(\frac{-t^2}{2(A_1^2 + \dots + A_N^2)} \right). \]
    %
    Proofs of McDiarmid's inequality are given in many probability textbooks, for instance, in Theorem 3.11 of \cite{VanHandel}.
    \begin{comment}

    \item Our random construction involves a probabilistic concentration of measure argument. Define a convex function $\psi_2: [0,\infty) \to [0,\infty)$ by setting
    %
    \[ \psi_2(t) = e^{t^2} - 1, \]
    %
    The function $\psi_2$ induces an Orlicz norm on the family of scalar valued random variables over a probability space by setting, for each random variable $X$,
    %
    \[ \psitwo{X} = \inf \left\{ A \in (0,\infty) : \EE(\psi_2(|X|/A)) \leq 1 \right\}. \]
    %
    The family of random variables with $\psitwo{X} < \infty$ are known as \emph{subgaussian random variables}. Here are the important properties of subgaussian random variables which we use in this paper:
    %
    \begin{itemize}
        \item If $\psitwo{X} \leq A$, then for each $t \geq 0$,
        %
        \[ \PP \left( |X| \geq t \right) \leq 10 \exp \left( -t^2/10A^2 \right). \]
        %
        Thus Subgaussian random variables have Gaussian tails.

        \item If $|X| \leq A$ almost surely, then $\psitwo{X} \leq 10 A$. Thus bounded random variables are subgaussian.

    %\item (Centering) For any random variable $X$,
    %
    %\[ \psitwo{X - \EE(X)} \lesssim \psitwo{X}. \]
    
    %\item (Union Bound) If $X_1, \dots, X_N$ are random variables, then
    %
    %\[ \psitwo{X_1 + \dots + X_N} \leq \psitwo{X_1} + \dots + \psitwo{X_N}. \]
    
        \item If $X_1, \dots, X_N$ are \emph{independent}, then
        %
        \[ \psitwo{X_1 + \dots + X_N} \leq 10 \left( \psitwo{X_1}^2 + \dots + \psitwo{X_N}^2 \right)^{1/2}. \]
        %
        This is an equivalent way to state \emph{Hoeffding's Inequality}, and we refer to an application of this inequality as an application of Hoeffding's inequality.
    \end{itemize}
    %
    Roughly speaking, if $X$ is a random variable with $\psitwo{X} \leq A$, we can think of $X$ as being sharply concentrated in the region $[-A,A]$. The Orlicz norm thus provides a convenient way to quantify concentration phenomena.
    %
    \begin{remark}
        The constants involved in these statements are suboptimal, but will suffice for our purposes. Proofs can be found in Chapter 2 of \cite{Vershynin}.
    \end{remark}

    \end{comment}

    \item Throughout this paper, we will need to consider a standard mollifier. So we fix a smooth, non-negative function $\phi \in C^\infty(\TT^d)$ such that $\phi(x) = 0$ for $|x| \geq 2/5$ and
%
\[ \int_{\TT^d} \phi(x)\; dx = 1. \]
%
\begin{comment}
\begin{theorem} \label{equationASFGCISIX}
    There exists a smooth probability density $\phi \in C^\infty(\TT^d)$ such that $\phi(x) = 0$ for $|x| \geq 2/5$, and such that for each $x \in \TT^d$
    %
    \[ \sum_{k \in \{ 0, 1 \}^d} \phi(x + k/2) = 2^d. \]
\end{theorem}
\begin{proof}
    Let $\psi$ be a non-negative smooth function on $\TT$ such that $\psi(x) = \psi(- x)$ for all $x \in \TT$, $\psi(x) = 1$ for $|x| \leq 1/10$, $\psi(x) = 0$ for $|x| \geq 2/10$, and $0 \leq \psi(x) \leq 1$ for all $x \in \TT$. Then define $\eta$ to be the non-negative, $C^\infty$ function
    %
    \[ \eta(x) = \frac{1}{2} - \frac{\psi(x) + \psi(x + 1/2)}{2}. \]
    %
    If we define
    %
    \[ \phi_0(x) = 2(\psi(x) + \eta(x)), \]
    %
    then $\phi_0(x) + \phi_0(x + 1/2) = 2$ for all $x \in \TT$. Moreover, if $|x| \geq 2/5$, then $\psi(x) = 0$, and since this implies $|x + 1/2| \leq 1/10$, we find $\eta(x) = 0$. Thus $\phi_0(x) = 0$ for $|x| \geq 2/5$. But the condition $\phi_0(x) + \phi_0(x + 1/2) = 2$ implies that $\phi_0$ is a probability density function. Thus it suffices to define
    %
    \[ \phi(x_1, \dots, x_d) = \phi_0(x_1) \dots \phi_0(x_d). \qedhere \]
\end{proof}
\end{comment}
%
For each $r \in (0,1)$, we can then define $\phi_r \in C^\infty(\TT^d)$ by writing
%
\[ \phi_r(x) = \begin{cases} r^{-d} \phi(x/r) &: |x| < r, \\ 0 &: \text{otherwise}. \end{cases} \]
%
The following standard properties hold for this choice of mollifier $\{ \phi_r \}$:
%
\begin{enumerate}
    \item[(1)] For each $r \in (0,1)$, $\phi_r$ is a smooth probability density, and $\phi_r(x) = 0$ for $|x| \geq r$.

    \item[(2)] For any $r \in (0,1)$,
    %
    \begin{equation} \label{equationDIOJAOIJVIV23242}
        \| \widehat{\phi_r} \|_{L^\infty(\ZZ^d)} \leq 1.
    \end{equation}

%    \item For any positive integer $N$, if $\varepsilon = 1/N$ and $x \in \TT^d$,
    %
%    \begin{equation} \label{equation5550002352124124512}
%        \sum_{k \in [2N]^d} \phi_{1/N}(x + k/2N) = (2N)^d.
%    \end{equation}

    \item[(3)] For each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{approximationtoidentitypointwiseconvergence}
        \lim_{r \to 0} \widehat{\phi_r}(\xi) = 1.
    \end{equation}
        
    \item[(4)] For each $T > 0$, and for all $r > 0$ and non-zero $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{molificationdecaybound}
        |\widehat{\phi_r}(\xi)| \lesssim_T r^{-T} |\xi|^{-T}.
    \end{equation}
\end{enumerate}
\end{itemize}

\section{A Metric Space Controlling Fourier Dimension}

In order to work with a Baire category type argument, we must construct an appropriate metric space appropriate for our task. Though in later sections we will specify $\beta$ as in Theorem \ref{maintheorem}, in this section we let $\beta$ be an arbitrary element of $(0,d]$. We proceed as in \cite{Korner2}, forming our metric space as a combination of two simpler metric spaces. However, we employ a novel Frech\'{e}t space construction instead of the Banach space used in \cite{Korner2}, which enables us to use softer estimates in our arguments:
%
\begin{itemize}
    \item We let $\mathcal{E}$ denote the family of all compact subsets of $\TT^d$. If, for two compact sets $E,F \in \mathcal{E}$, we consider their Hausdorff distance
    %     
    \[ d_H(E,F) = \inf \{ \varepsilon > 0 : E \subset F_\varepsilon\ \text{and}\ F \subset E_\varepsilon \}, \]
    %
    then $(\mathcal{E},d_H)$ forms a complete metric space. %We note that if a sequence $\{ E_k \}$ converges to a set $E$ in the Hausdorff distance, then $E$ is the collection of all values $\lim_{k \to \infty} x_k$, where $\{ x_k \}$ is a convergent sequence with $x_k \in E_k$ for each $k$.

    \item We let $M(\beta/2)$ consist of the class of all finite Borel measures $\mu$ on $\TT^d$ such that for each $\varepsilon \in (0,\beta/2]$, the quantity
    %
    \[ \| \mu \|_{M(\beta/2 - \varepsilon)} = \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{\beta/2 - \varepsilon} \]
    %
    is finite. Then $\| \cdot \|_{M(\beta/2 - \varepsilon)}$ is a seminorm on $M(\beta/2)$, and the collection of all such seminorms for $\varepsilon \in (0,\beta/2]$ gives $M(\beta/2)$ the structure of a Frech\'{e}t space. Under this topology, a sequence of probability measures $\{ \mu_k \}$ converges to a probability measure $\mu$ in $M(\beta/2)$ if and only if for any $\varepsilon > 0$, $\lim_{k \to \infty} \| \mu_k - \mu \|_{M(\beta/2 - \varepsilon)} = 0$.
\end{itemize}

\begin{comment}
\begin{theorem}
    $M(\beta)$ is a Frech\'{e}t space.
\end{theorem}
\begin{proof}
    Let $\{ \mu_k \}$ be a Cauchy sequence in $M(\beta)$. By the Banach-Alaoglu theorem, we can find a finite Borel measure $\mu$ such that some subsequence $\{ \mu_{k_i} \}$ of the sequence $\{ \mu_k \}$ converges weakly to $\mu$. Then for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationAAGDDTYY8}
        \lim_{i \to \infty} \widehat{\mu_{k_i}}(\xi) = \widehat{\mu}(\xi).
    \end{equation}
    %
    Since $\{ \mu_k \}$ is Cauchy, for each $\varepsilon > 0$ there exists a constant $M_\varepsilon > 0$ such that for each $k$,
    %
    \begin{equation} \label{equationGFDSCCSI9}
        \| \mu_k \|_{M(\beta,\varepsilon)} \leq M_\varepsilon.
    \end{equation}
    %
    But combining \eqref{equationAAGDDTYY8} with \eqref{equationGFDSCCSI9} shows that for each $\varepsilon > 0$,
    %
    \begin{equation} \label{equationFGSCIS991}
        \| \mu \|_{M(\beta,\varepsilon)} \leq M_\varepsilon < \infty.
    \end{equation}
    %
    In particular, $\mu \in M(\beta)$. Now fix $r > 0$ and $\varepsilon > 0$. Because $\{ \mu_k \}$ is Cauchy, there exists $k_0$ such that for $k_1,k_2 \geq k_0$,
    %
    \begin{equation} \label{equationGGSIC8823}
        \| \mu_{k_1} - \mu_{k_2} \|_{M(\beta,r)} \leq \varepsilon.
    \end{equation}
    %
    But then combining \eqref{equationAAGDDTYY8} and\eqref{equationGGSIC8823} shows that for $k \geq k_0$,
    %
    \begin{equation} \label{equationGGSCSXXX}
        \| \mu - \mu_k \|_{M(\beta,r)} \leq \varepsilon.
    \end{equation}
    %
    Since $r$ and $\varepsilon$ were arbitrary, \eqref{equationGGSCSXXX} shows that $\mu_k$ converges to $\mu$ in the topology determined by the seminorms of $M(\beta)$. If we consider a decreasing family $\{ \varepsilon_k \}$ such that $\varepsilon_k \to 0$, then $M(\beta)$ is clearly topologized by the subfamily of seminorms $\{ \| \cdot \|_{M(\beta,\varepsilon_k)} \}$, so $M(\beta)$ is metrizable. Thus we conclude that $M(\beta)$ is a Frech\"{e}t space.
\end{proof}
\end{comment}

We now let $\mathcal{X}_\beta$ be the collection of all pairs $(E,\mu) \in \mathcal{E} \times M(\beta/2)$, where $\mu$ is a probability measure such that $\text{supp}(\mu) \subset E$. Then $\mathcal{X}_\beta$ is a closed subset of $\mathcal{E} \times M(\beta/2)$ under the product metric, and thus a complete metrizable space. We remark that for any $\varepsilon > 0$ and $(E,\mu) \in \mathcal{X}_\beta$,
%
\begin{equation} \label{equationGFSCSC4}
    \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = 0,
\end{equation}
%
which follows because $\| \mu \|_{M(\beta/2 - \varepsilon/2)}$ is finite. Thus $\fordim(\mu) \geq \beta$ for each $(E,\mu) \in \mathcal{X}_\beta$.
\begin{comment}
\begin{theorem}
    $\mathcal{X}$ is a closed subset of $\mathcal{E} \times M(\beta)$.
\end{theorem}
\begin{proof}
    Suppose $\{ (E_k,\mu_k) \}$ is a sequence of elements of $\mathcal{X}$ converging to some tuple $(E,\mu) \in \mathcal{E} \times M(\beta)$. Fix $\varepsilon > 0$. Since $E_k \to E$ in the Hausdorff dimension, there exists $k_0$ such that for $k \geq k_0$, $E_k \subset E(\varepsilon)$. Since $\mu_k \to \mu$ weakly, this implies that $\mu$ is a probability measure, and that $\text{supp}(\mu) \subset E(\varepsilon)$. Taking $\varepsilon \to 0$ shows that $\text{supp}(\mu) \subset E$. Again for a fixed $\varepsilon > 0$, applying the triangle inequality and the reverse triangle inequality combined with \eqref{equationGFSCSC4} applied to $\mu_k$, we conclude
    %
    \[ \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi) - \widehat{\mu_k}(\xi)| \leq \| \mu - \mu_k \|_{M(\beta,\varepsilon)}. \]
    %
    Taking $k \to \infty$ shows that
    %
    \[ \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = 0, \]
    %
    which completes the proof.
\end{proof}
\end{comment}

The next lemma allows us to work with smooth measures for the remainder of this paper.

\begin{lemma} \label{smoothdensitylemma}
    The set of all $(E,\mu)$ with $\mu \in C^\infty(\TT^d)$ is dense in $\mathcal{X}_\beta$.
\end{lemma}
\begin{proof}
    Consider $(E,\mu) \in \mathcal{X}_\beta$. For each $r \in (0,1)$, consider the convolved measure $\mu_r = \mu * \phi_r$. Then $\mu_r \in C^\infty(\TT^d)$. If we set $E_r = E \cup \text{supp}(\mu_r)$, then we claim
    %
    \begin{equation} \label{equationFFSPCOS}
        \lim_{r \to 0}\; (E_r, \mu_r) = (E,\mu).
    \end{equation}
    %
    Since $\text{supp}(\mu_r) \subset E_r$, we conclude that
    %
    \begin{equation} \label{equationFFSICSI}
        d_H(E,E_r) \leq r.
    \end{equation}
    %
    Thus $E_r \to E$ as $r \to 0$ under the Hausdorff distance. Now fix $\varepsilon_1 \in (0,\beta/2]$ and $\varepsilon > 0$. For each $\xi \in \ZZ^d$, $|\widehat{\mu_r}(\xi)| = |\widehat{\phi_r}(\xi)| |\widehat{\mu}(\xi)|$, so
    %
    \begin{equation} \label{equationFFSCI}
        |\xi|^{\beta/2 - \varepsilon_1} |\mu_r(\xi) - \mu(\xi)| = |\xi|^{\beta/2 - \varepsilon_1} |\widehat{\phi_r}(\xi) - 1| |\widehat{\mu}(\xi)|.
    \end{equation}
    %
    Since $(E,\mu) \in \mathcal{X}_\beta$, we can apply \eqref{equationGFSCSC4} to conclude that there exists $R$ such that for $|\xi| \geq R$,
    %
    \begin{equation} \label{equationDIICSIC}
        |\xi|^{\beta/2 - \varepsilon_1} |\widehat{\mu}(\xi)| \leq \varepsilon.
    \end{equation}
    %
    Combining \eqref{equationFFSCI}, \eqref{equationDIICSIC}, and \eqref{equationDIOJAOIJVIV23242}, we conclude that for $|\xi| \geq R$,
    %
    \begin{equation} \label{equationDSCISIIXX}
        |\xi|^{\beta/2 - \varepsilon_1} |\mu_r(\xi) - \mu(\xi)| \leq 2 \varepsilon.
    \end{equation}
    %
    By \eqref{approximationtoidentitypointwiseconvergence}, we conclude that there exists $r_0 > 0$ such that for $r \leq r_0$ and $|\xi| \leq R$,
    %
    \begin{equation} \label{equationDISCIIS}
        |\xi|^{\beta/2 - \varepsilon} |\widehat{\phi_r}(\xi) - 1| \leq \varepsilon.
    \end{equation}
    %
    The $(L^1,L^\infty)$ bound for the Fourier transform implies that
    %
    \begin{equation} \label{equationFSCISIXX}
        |\widehat{\mu}(\xi)| \leq \mu(\TT^d) = 1
    \end{equation}
    %
    But from \eqref{equationDISCIIS} and \eqref{equationFSCISIXX} applied to \eqref{equationFFSCI}, we find that for $r \leq r_0$ and $|\xi| \leq R$,
    %
    \begin{equation} \label{equatioNFISISCISI}
        |\xi|^{\beta/2 - \varepsilon_1} |\mu_r(\xi) - \mu(\xi)| \leq \varepsilon.
    \end{equation}
    %
    Putting together \eqref{equationDSCISIIXX} and \eqref{equatioNFISISCISI}, we find that for $r \leq r_0$,
    %
    \begin{equation} \label{equationDAIWOIC}
        \| \mu_r - \mu \|_{M(\beta/2 - \varepsilon_1)} \leq 2\varepsilon.
    \end{equation}
    %
    Since $\varepsilon$ and $\varepsilon_1$ were arbitrary, we conclude from \eqref{equationDAIWOIC} and \eqref{equationFFSICSI} that $(E_r,\mu_r) \to (E,\mu)$, completing the proof.
\end{proof}

\begin{remark} \label{remarkDOIWJDIOWJ2}
    Let
    %
    \[ \tilde{\mathcal{X}_\beta} = \{ (E,\mu) \in \mathcal{X}_\beta : \text{supp}(\mu) = E \}. \]
    %
    Suppose $(E_0,\mu_0) \in \tilde{\mathcal{X}_\beta}$. Then, in the proof above, one may let $E_r$ be equal to $\text{supp}(\mu_r)$, since it follows from this that $d_H(E_0,E_r) \leq r$. This means that the set of pairs $(E,\mu) \in \tilde{\mathcal{X}_\beta}$ with $\mu \in C^\infty(\TT^d)$ are dense in $\tilde{\mathcal{X}_\beta}$.
\end{remark}

The reader might be wondering why we don't work with the smaller space $\tilde{\mathcal{X}_\beta} \subset \mathcal{X}_\beta$. The reason is that $\tilde{\mathcal{X}_\beta}$ is not a closed subset of $\mathcal{E} \times M(\beta/2)$, and so is not a complete metrizable space under the product topology. However, as a consolation, quasi-all elements of $\mathcal{X}_\beta$ belong to $\tilde{\mathcal{X}_\beta}$, so that one can think of $\mathcal{X}_\beta$ and $\tilde{\mathcal{X}_\beta}$ as being equal `generically'.

\begin{lemma} \label{lemmaOIJAWDIOJW23232}
    For quasi-all $(E,\mu) \in \mathcal{X}_\beta$, $\text{supp}(\mu) = E$.
\end{lemma}
\begin{proof}
    For each closed cube $I \subset \TT^d$, let
    %
    \[ A(I) = \{ (E,\mu) \in \TT^d: (E \cap I) = \emptyset\ \text{or}\ \mu(I) > 0 \}. \]
    %
    Then $A(I)$ is an open set. If $\{ I_k \}$ is a sequence enumerating all cubes with rational corners in $\TT^d$, then
    %
    \[ \bigcap_{k = 1}^\infty A(I_k) \]
    %
    is the collection of $(E,\mu) \in \mathcal{X}_\beta$ with $\text{supp}(\mu) = E$. Thus it suffices to show that $A(I)$ is dense in $\mathcal{X}_\beta$ for each closed cube $I$.

    Consider $(E_0,\mu_0) \in \mathcal{X}_\beta - A(I)$, $\varepsilon_1 \in (0,\beta/2]$, and $\varepsilon > 0$. Our goal is to find $(E,\mu) \in A(I)$ with $d_H(E,E_0) \leq \varepsilon$ and $\| \mu_0 - \mu \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$. Without loss of generality by Lemma \ref{smoothdensitylemma} we may assume that $\mu_0 \in C^\infty(\TT^d)$. Because $(E_0,\mu_0) \in \mathcal{X}_\beta - A(I)$, we know $E \cap I \neq \emptyset$ and $\mu(I) = 0$. Find a smooth probability measure $\nu$ supported on $E_\varepsilon \cap I$ and, for $t \in (0,1)$, define $\mu_t = (1 - t) \mu_0 + t \nu$. Then $\text{supp}(\mu_t) \subset E_\varepsilon$, so if we let $E = \text{supp}(\nu) \cup \text{supp}(\mu)$, then $d_H(E,E_0) \leq \varepsilon$. Clearly $(E,\mu_t) \in A(I)$ for $t > 0$. And
    %
    \[ \| \mu_t - \mu_0 \|_{M(\beta/2 - \varepsilon)} \leq t \left( \| \mu_0 \|_{M(\beta/2 - \varepsilon)} + \| \nu \|_{M(\beta/2 - \varepsilon)} \right), \]
    %
    so if we choose $t \leq \varepsilon (\| \mu \|_{M(\beta/2 - \varepsilon)} + \| \nu \|_{M(\beta/2 - \varepsilon)})^{-1}$ shows $\| \mu_t - \mu \|_{M(\beta/2 - \varepsilon)} \leq \varepsilon$. Since $\varepsilon$ was arbitrary, we conclude $A(I)$ is dense in $\mathcal{X}_\beta$.
\end{proof}

Combining Lemma \ref{lemmaOIJAWDIOJW23232} with Remark \ref{remarkDOIWJDIOWJ2} gives the following simple corollary.

\begin{corollary} \label{corollaryOIDJOWIJD2212}
    The family of $(E,\mu)$ with $\text{supp}(\mu) = E$ and $\mu \in C^\infty(\TT^d)$ is dense in $\mathcal{X}_\beta$.
\end{corollary}

Our main way of constructing approximations to $(E_0,\mu_0) \in \mathcal{X}_\beta$ is to multiply $\mu_0$ by a smooth function $f$. For instance, we might choose $f$ in such a way as to remove certain points from the support of $\mu_0$ which contribute to the formation of a pattern we are trying to avoid. As long as the Fourier transform of $f$ decays appropriately quickly, we find $f \mu_0 \approx \mu_0$.

\begin{lemma} \label{LemmaTTSICICS}
    Consider a smooth finite measure $\mu_0$ on $\TT^d$, as well as a smooth probability density function $f \in C^\infty(\TT^d)$. If we define $\mu = f \mu_0$, then
    %
    \[ \| \mu - \mu_0 \|_{M(\beta/2)} \lesssim_{d,\mu_0} \| f \|_{M(\beta/2)}. \]
\end{lemma}
\begin{proof}
    Since $\widehat{\mu} = \widehat{f} * \widehat{\mu_0}$, and $\widehat{f}(0) = 1$, for each $\xi \in \ZZ^d$ we have
    %
    \begin{equation} \label{equationPPYTUECUUCS}
    \begin{split}
        |\xi|^{\beta/2} |\widehat{\mu}(\xi) - \widehat{\mu_0}(\xi)| &= |\xi|^{\beta/2} \left| \sum_{\eta \neq \xi} \widehat{f}(\xi - \eta) \widehat{\mu_0}(\eta) \right|.
    \end{split}
    \end{equation}
    %
    If $|\eta| \leq |\xi|/2$, then $|\xi|/2 \leq |\xi - \eta| \leq 2 |\xi|$, so
    %
    \begin{equation} \label{equationPPDOSO}
        |\xi|^{\beta/2} |\widehat{f}(\xi - \eta)| \leq \| f \|_{M(\beta/2)} |\xi|^{\beta/2} |\xi-\eta|^{-\beta} \leq 2^{\beta/2} \| f \|_{M(\beta/2)} \lesssim_d \| f \|_{M(\beta/2)}.
    \end{equation}
    %
    Since $\mu_0$ is smooth, for any $T \geq 0$ and $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationGGIDISCXJIX}
        |\xi|^T |\widehat{\mu_0}(\xi)| \lesssim_{T,\mu_0} 1.
    \end{equation}
    %
    Thus we can combine the bounds \eqref{equationPPDOSO} and \eqref{equationGGIDISCXJIX}, with $T = d+1$, to conclude that
    %
    \begin{equation} \label{equationGGPSOVVCSI}
    \begin{split}
        |\xi|^{\beta/2} \left| \sum_{0 \leq |\eta| \leq |\xi|/2} \widehat{f}(\eta) \widehat{\mu_0}(\xi - \eta) \right| &\lesssim_{\mu_0,d} \left( 1 + \sum_{0 < |\eta| \leq |\xi|/2} \frac{1}{|\eta|^{d+1}} \right) \| f \|_{M(\beta)} \lesssim_d \| f \|_{M(\beta)}.
    \end{split}
    \end{equation}
    %
    On the other hand, for all $\eta \neq \xi$,
    %
    \begin{equation} \label{equationGGDPSOX}
    \begin{split}
        |\widehat{f}(\xi - \eta)| \leq  \| f \|_{M(\beta/2)} |\xi - \eta|^{-\beta} \leq \| f \|_{M(\beta/2)}.
    \end{split}
    \end{equation}
    %
    Thus applying \eqref{equationGGIDISCXJIX} and \eqref{equationGGDPSOX}, with $T = 3d/2$, we conclude that
    %
    \begin{equation} \label{equationGGHOODPPS}
    \begin{split}
        |\xi|^{\beta/2} \left| \sum_{\substack{|\eta| > |\xi|/2\\ \eta \neq \xi}} \widehat{f}(\xi - \eta) \widehat{\mu_0}(\eta) \right| &\lesssim_{d,\mu_0} |\xi|^{\beta/2} \sum_{|\eta| > |\xi|/2} \frac{\| f \|_{M(\beta/2)}}{|\eta|^{3d/2}} \lesssim_d \| f \|_{M(\beta/2)}.
    \end{split}
    \end{equation}
    %
    Combining \eqref{equationPPYTUECUUCS}, \eqref{equationGGPSOVVCSI} and \eqref{equationGGHOODPPS} completes the proof.
\end{proof}

\begin{remark} \label{remarkFOIJIOSJCIOSJ}
    In particular, we note that this lemma implies that $\mu(\TT^d) \geq 1 - O_{d,\mu_0}(\| f \|_{M(0)})$.
\end{remark}

Given $K$ points $x_1,\dots,x_K \in \TT^d$, consider the smooth function
%
\[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_r(x - x_i). \]
%
The support of $f$ consists of $K$ radius $r$ balls. Provided $K \approx r^{-\beta}$, the support of $f$ behaves like a discretized $\beta$ dimensional set. The next lemma shows that if there is enough square root cancellation in the exponential sum
%
\[ \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i x_i \cdot \xi}, \]
%
then $f$ has the appropriate Fourier decay of a discretized $\beta$ dimensional set.

\begin{comment}

\begin{lemma} \label{Lemma65493}
    Fix $C > 0$, $r,\varepsilon_1 > 0$, and $\beta \in (0,d/2]$. Consider $K$ points $x_1, \dots, x_K \in \TT^d$ such that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq 1/r^{1+\varepsilon_1}$,
    %
    \begin{equation} \label{equationOIJDOIJIO}
        \left| \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i x_i \cdot \xi} \right| \leq C |\xi|^{-\beta}.
    \end{equation}
    %
    Then if we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{r}(x - x_i), \]
    %
    then $\| f \|_{M(\beta-\varepsilon_1)} \lesssim_{d,\varepsilon_1} C$.
\end{lemma}
\begin{proof}
    Set
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then \eqref{equationOIJDOIJIO} is equivalent to the property that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq 1/r^{1 + \varepsilon_1}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C |\xi|^{-\beta}.
    \end{equation}
    %
    Noting that $f = D * \phi_{r}$, we conclude that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_{r}}|.
    \end{equation}
    %
    For $0 < |\xi| \leq 1/r^{1 + \varepsilon_1}$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationDIOJAOIJVIV23242} to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
        |\widehat{f}(\xi)| \leq C |\xi|^{-\beta} \leq C |\xi|^{\varepsilon_1 - \beta}.
    \end{equation}
    %
    For $|\xi| \geq 1/r^{1 + \varepsilon_1}$, we note that \eqref{molificationdecaybound} implies $\widehat{\phi_{r}}(\xi) \lesssim_T r^{-T} |\xi|^{-T}$, and so if $T \geq \beta$,
    %
    \begin{equation} \label{equationDIICCCJSXVVM21}
        |\widehat{f}(\xi)| \lesssim_T [r^{-T} |\xi|^{\beta-T}] |\xi|^{-\beta} \leq [r^{-T} r^{-(1+\varepsilon_1)(\beta-T)}] |\xi|^{-\beta} \leq r^{-(1+\varepsilon_1) \beta + \varepsilon_1 T} |\xi|^{-\beta}.
    \end{equation}
    %
    Setting $T = (1 + 1/\varepsilon_1) \cdot \beta$ gives $|\widehat{f}(\xi)| \lesssim_{\varepsilon_1,d} |\xi|^{-\beta}$.
\end{proof}

\end{comment}

\begin{lemma} \label{Lemma65493}
    Fix $C > 0$, $r > 0$ and $\varepsilon_1 > 0$. Consider an integer $K \geq (1/C) \cdot r^{-\beta}$, and let $x_1,\dots,x_K \in \TT^d$ be such that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq (1/r)^{1 + \varepsilon_1}$,
    %
    \begin{equation} \label{equationOIJDOIJIO}
        \left| \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i x_i \cdot \xi} \right| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Then for each $\varepsilon > 0$ and $\varepsilon_2 \in (0,\beta/2)$, there exists $r_0 > 0$ depending only on $C$, $\beta$, $\varepsilon$, $\varepsilon_1$, and $\varepsilon_2$, such that if $r \leq r_0$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_r(x - x_i) \]
    %
    then $\| f \|_{M(\beta/2 - \varepsilon_2)} \leq \varepsilon$.
\end{lemma}
\begin{proof}
    Set
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then \eqref{equationOIJDOIJIO} is equivalent to the property that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq (1/r)^{1+\varepsilon_1}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Noting that $f = D * \phi_r$, we conclude that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_r}|.
    \end{equation}
    %
    If $r_1 = (10C)^{-1/\beta}$ and $r \leq r_1$, then the function $x \mapsto x^{-1/2} \log(x)^{1/2}$ is decreasing for $x \geq (1/C) r^{-1/\beta}$. Thus for $0 < |\xi| \leq 1/r$ and $r \leq r_1$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationDIOJAOIJVIV23242} together with the bound $K \geq (1/C) r^{-\beta}$ to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
    \begin{split}
        |\widehat{f}(\xi)| &\leq \left[ C K^{-1/2} \log(K)^{1/2} |\xi|^{\beta/2 - \varepsilon_2} \right] |\xi|^{\varepsilon_2-\beta/2}\\
        &\leq \left[ C^{1 + \beta/2} r^{\beta/2} \log((1/C)r^{-\beta})^{1/2} (1/r)^{\beta/2 - \varepsilon_2} \right] |\xi|^{\varepsilon_2 - \beta/2}\\
        &\leq \left[ C^{1 + \beta/2} r^{\varepsilon_2} \log((1/C)r^{-\beta})^{1/2} \right] |\xi|^{\varepsilon_2 - \beta/2}.
    \end{split}
    \end{equation}
    %
    As $r \to 0$, $C^{1 + \beta/2} r^{\varepsilon_2} \log((1/C)r^{-\beta})^{1/2} \to 0$, so we conclude from \eqref{equationGGIOHISI99234} that there exists $r_2 \leq r_1$ depending on $C$, $\beta$, $\varepsilon_2$, and $\varepsilon$, such that for $r \leq r_2$ and $0 < |\xi| \leq (1/r)$,
    %
    \begin{equation} \label{equation663sdDDDCC}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_2-\beta/2}.
    \end{equation}
    %
    If $(1/r) \leq |\xi| \leq (1/r)^{1+\varepsilon_1}$, \eqref{molificationdecaybound} implies $|\widehat{\phi_{r}}(\xi)| \lesssim_\beta r^{-\beta/2} |\xi|^{-\beta/2}$, which together with \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS}, and the bound $K \geq (1/C) r^{-\beta}$, show that for $r \leq r_1$,
    %
    \begin{equation} \label{equationGGOOSC66341}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_\beta \left( C K^{-1/2} \log(K)^{1/2} r^{-\beta/2} |\xi|^{-\varepsilon_2} \right) |\xi|^{\varepsilon_2-\beta/2}\\
        &\leq \left( C^{1 + \beta/2} \log((1/C) r^{-\beta})^{1/2} r^{\varepsilon_2(1 + \varepsilon_1)} \right) |\xi|^{\varepsilon_2 - \beta/2}.
    \end{split}
    \end{equation}
    %
    Again, we find that as $r \to 0$, $C^{1 + \beta/2} \log((1/C) r^{-\beta})^{1/2} r^{\varepsilon_2} \to 0$, so we conclude from \eqref{equationGGOOSC66341} that there exists $r_3$ depending on $C$, $\beta$, $\varepsilon$, $\varepsilon_1$ and $\varepsilon_2$, such that if $r \leq r_3$,
    %
    \begin{equation} \label{equationUUUDDDCII777}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_2-\beta/2}.
    \end{equation}
    %
    If $|\xi| \geq (1/r)^{1 + \varepsilon_1}$, we apply \eqref{molificationdecaybound} for $T \geq \beta/2$ together with the bound $K \geq (1/C) r^{-\beta}$ to conclude
    %
    \begin{equation} \label{equationGGUSCCCYVSSXX998723}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_T [r^{-T} |\xi|^{\beta/2 - T}] |\xi|^{-\beta/2}\\
        &\leq \left[ r^{-T} (1/r)^{(\beta/2 - T)(1 + \varepsilon_1)} \right] |\xi|^{-\beta/2}\\
        &= \left[ r^{\varepsilon_1 T - (\beta/2)(1 + \varepsilon_1)} \right] |\xi|^{-\beta/2}.
    \end{split}
    \end{equation}
    %
    If we choose $T > (\beta/2)(1 + 1/\varepsilon_1)$, then as $r \to 0$, $r^{\varepsilon_1 T - (\beta/2)(1 + \varepsilon_1)} \to 0$. Thus we conclude from \eqref{equationGGUSCCCYVSSXX998723} that there exists a large integer $r_4$ depending on $C$, $\beta$, $\varepsilon$, $\varepsilon_1$, and $\varepsilon_2$ such that for $r \leq r_4$ and $|\xi| \geq (1/r)^{1+\varepsilon_1}$,
    %
    \begin{equation} \label{equationBBCDSGDCC77}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{-\beta/2} \leq \varepsilon |\xi|^{\varepsilon_2-\beta/2}.
    \end{equation}
    %
    All that remains is to combine \eqref{equation663sdDDDCC}, \eqref{equationUUUDDDCII777}, and \eqref{equationBBCDSGDCC77}, defining $r_0 = \min(r_1,r_2,r_3,r_4)$.
\end{proof}

\begin{comment}

\begin{lemma} \label{Lemma65493}
    Fix $C > 0$, $\varepsilon_1, \varepsilon_2 > 0$, and $\varepsilon > 0$. Consider $K$ points $x_1, \dots, x_K \in \TT^d$ such that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationOIJDOIJIO}
        \left| \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i x_i \cdot \xi} \right| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Then there exists a large integer $K_0$ depending on $C$,$\beta$,$\varepsilon_1$,$\varepsilon_2$, and $\varepsilon$, such that if $K \geq K_0$, $r \geq C^{-1} K^{-1/\beta}$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{r}(x - x_i), \]
    %
    then $\| f \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$.
\end{lemma}
\begin{proof}
    Set
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then \eqref{equationOIJDOIJIO} is equivalent to the property that for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Noting that $f = D * \phi_{r}$, we conclude that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_{r}}|.
    \end{equation}
    %
    For $0 < |\xi| \leq K^{1/\beta}$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationDIOJAOIJVIV23242} to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
        |\widehat{f}(\xi)| \leq \left[ C K^{-\varepsilon_1/\beta} \log(K)^{1/2} \right] |\xi|^{\varepsilon_1 - \beta/2}.
    \end{equation}
    %
    As $K \to \infty$, $K^{-\varepsilon_1/\beta} \log(K)^{1/2} \to 0$, so we conclude from \eqref{equationGGIOHISI99234} there exists a large integer $K_1(C,\beta,\varepsilon_1,\varepsilon)$ such that for $K \geq K_1(C,\beta,\varepsilon_1,\varepsilon)$,
    %
    \begin{equation} \label{equation663sdDDDCC}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_1-\beta/2}.
    \end{equation}
    %
    If $K^{1/\beta} \leq |\xi| \leq K^{1/\beta + \varepsilon_2}$, we note that \eqref{molificationdecaybound} implies $\widehat{\phi_{r}}(\xi) \lesssim_d r^{-\beta/2} |\xi|^{-\beta/2}$, which together with \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS}, and the bound $r \geq C^{-1} K^{-1/\beta}$, imply
    %
    \begin{equation} \label{equationGGOOSC66341}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_d \left( C K^{-1/2} r^{-\beta/2} K^{-\varepsilon_1/\beta} \log(K)^{1/2} \right) |\xi|^{\varepsilon_1-\beta/2}\\
        &\leq \left( C^{1 + \beta/2} K^{-\varepsilon_1/\beta} \log(K)^{1/2} \right) |\xi|^{\varepsilon_1 - \beta/2}.
    \end{split}
    \end{equation}
    %
    Again, we find that as $K \to \infty$, $K^{-\varepsilon_1/\beta} \log(K)^{1/2} \to 0$, so we conclude from \eqref{equationGGOOSC66341} that there exists $K_2(C,\beta,\varepsilon_1,\varepsilon)$ such that if $K \geq K_2(C,\beta,\varepsilon_1,\varepsilon)$, then
    %
    \begin{equation} \label{equationUUUDDDCII777}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_1-\beta/2}.
    \end{equation}
    %
    If $|\xi| \geq K^{1/\beta + \varepsilon_2}$, we apply \eqref{molificationdecaybound} for $T \geq \beta/2$ together with the bound $r \geq C^{-1} K^{-1/\beta}$ to conclude
    %
    \begin{equation} \label{equationGGUSCCCYVSSXX998723}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_T r^{-T} |\xi|^{-T}\\
        &\leq \left[ C^T K^{T/\beta} |\xi|^{\beta/2 - T} \right] |\xi|^{-\beta/2}\\
        &\leq \left[ C^T K^{1/2 + (\beta/2 - T) \varepsilon_2} \right] |\xi|^{-\beta/2}.
    \end{split}
    \end{equation}
    %
    If we choose $T > \beta/2 + 1/2 \varepsilon_2$, then as $K \to \infty$, $K^{1/2 + (\beta/2 - T) \varepsilon_1} \to 0$. Thus we conclude from \eqref{equationGGUSCCCYVSSXX998723} that there exists a large integer $K_3(C,\beta,\varepsilon_2,\varepsilon)$ such that for $K \geq K_3(C,\beta,\varepsilon_2,\varepsilon)$ and $|\xi| \geq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationBBCDSGDCC77}
        |\widehat{f}(\xi)| \leq \varepsilon |\xi|^{-\beta/2}.
    \end{equation}
    %
    All that remains is to combine \eqref{equation663sdDDDCC}, \eqref{equationUUUDDDCII777}, and \eqref{equationBBCDSGDCC77}, defining $K_0 = \max(K_1,K_2,K_3)$.
\end{proof}

\end{comment}

\begin{corollary} \label{lemmaIOJDD23124}
    Consider a smooth finite measure $\mu_0$ on $\TT^d$. Fix $C > 0$, $r > 0$ and $\varepsilon_1 > 0$. Consider an integer $K \geq (1/C) r^{-\beta}$, and let $x_1,\dots,x_K \in \TT^d$ be such that if
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq (1/r)^{1+\varepsilon_1}$,
    %
    \begin{equation} \label{equationBBBBODDUH}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    It is then true that for each $\varepsilon_2 \in (0,\beta/2]$, there exists $r_0$ depending on $C$, $\beta$, $d$, $\beta$, $\varepsilon$, $\varepsilon_1$, and $\varepsilon_2$, such that if $r \leq r_0$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{r}(x - x_i), \]
    %
    and a smooth probability measure
    %
    \[ \mu = \frac{f \mu_0}{(f \mu_0)(\TT^d)}, \]
    %
    then $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_2)} \leq \varepsilon$.
\end{corollary}
\begin{proof}
    It suffices to use Lemmas \ref{LemmaTTSICICS} and \ref{Lemma65493} to show that there exists $r_0$ such that for $r \leq r_0$,
    %
    \begin{equation} \label{equationDIOJAWDOIJAWIOJ212412}
        \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon_2)} \leq \varepsilon/2,
    \end{equation}
    %
    and
    %
    \begin{equation} \label{equationOIJOIJWOIDJWOIDJ3424526342412}
        \| f \mu_0 - \mu_0 \|_{M(0)} \leq \min \left( \frac{1}{2}, \frac{\varepsilon}{4 \| \mu_0 \|_{M(\beta/2 - \varepsilon_2)}} \right).
    \end{equation}
    %
    Equation \eqref{equationOIJOIJWOIDJWOIDJ3424526342412} implies that
    %
    \begin{equation} \label{equationIOAWJDOIJWDIOWJDIOW2414521}
        1 - \min \left( \frac{1}{2}, \frac{\varepsilon}{4 \| \mu_0 \|_{M(\beta/2 - \varepsilon_2)}} \right) \leq (f\mu_0)(\TT^d) \leq 1.
    \end{equation}
    %
    But now \eqref{equationDIOJAWDOIJAWIOJ212412} and \eqref{equationIOAWJDOIJWDIOWJDIOW2414521} show that
    %
    \begin{align*}
        \| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_2)} &\leq \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon)} + \| \mu - f \mu_0 \|_{M(\beta/2 - \varepsilon)}\\
        &\leq (\varepsilon/2) + \left( 1 - \frac{1}{(f \mu_0)(\TT^d)} \right) \| \mu_0 \|_{M(\beta/2 - \varepsilon)}\\
        &\leq (\varepsilon/2) + (\varepsilon/2) \leq \varepsilon. \qedhere
    \end{align*}
\end{proof}

\begin{comment}
\begin{lemma} \label{lemmaIOJDD23124}
    Consider a smooth finite measure $\mu_0$ on $\TT^d$. Fix $C > 0$, $r, \varepsilon_1, \varepsilon_2 > 0$, and $\varepsilon > 0$. Consider $K$ points $x_1, \dots, x_K \in \TT^d$ such that if
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationBBBBODDUH}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Then there exists a large integer $K_0(C,d,\beta,\mu_0,\varepsilon_1,\varepsilon_2,\varepsilon)$, such that if $K \geq K_0$ and $r \geq C^{-1} K^{-1/\beta}$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{r}(x - x_i), \]
    %
    and a smooth probability measure
    %
    \[ \mu = \frac{f \mu_0}{(f \mu_0)(\TT^d)}, \]
    %
    then $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$.
\end{lemma}
\begin{proof}
    It suffices to combine Lemmas \ref{LemmaTTSICICS} and \ref{Lemma65493} to show that there exists $K_0(C,d,\beta,\mu_0,\varepsilon_1,\varepsilon_2,\varepsilon)$ such that
    %
    \begin{equation} \label{equationDIOJAWDOIJAWIOJ212412}
        \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon/10,
    \end{equation}
    %
    and
    %
    \begin{equation} \label{equationOIJOIJWOIDJWOIDJ3424526342412}
        \| f \mu_0 - \mu_0 \|_{M(0)} \leq \min \left( \frac{1}{2}, \frac{\varepsilon}{4 \| \mu_0 \|_{M(\beta/2 - \varepsilon)}} \right).
    \end{equation}
    %
    As mentioned in Remark \ref{remarkFOIJIOSJCIOSJ}, \eqref{equationOIJOIJWOIDJWOIDJ3424526342412} implies that
    %
    \begin{equation} \label{equationIOAWJDOIJWDIOWJDIOW2414521}
        1 - \min \left( 1/2, (\varepsilon/4) \| \mu \|_{M(\beta/2-\varepsilon)} \right) \leq (f\mu_0)(\TT^d) \leq 1.
    \end{equation}
    %
    But now \eqref{equationDIOJAWDOIJAWIOJ212412} and \eqref{equationIOAWJDOIJWDIOWJDIOW2414521} show that
    %
    \begin{align*}
        \| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} &\leq \| f \mu_0 - \mu_0 \|_{M(\beta/2 - \varepsilon)} + \| \mu - f \mu_0 \|_{M(\beta/2 - \varepsilon)}\\
        &\leq (\varepsilon/2) + \left( 1 - \frac{1}{(f \mu_0)(\TT^d)} \right) \| \mu_0 \|_{M(\beta/2 - \varepsilon)} \leq \varepsilon. \qedhere
    \end{align*}
\end{proof}
\end{comment}

A common method to obtain square root cancellation in a sum is to use concentration properties of collections of independant random variables. This makes it very reasonable to use random constructions to find Salem sets.

\begin{lemma} \label{LemmaGISCICS1}
    Fix a large integer $K$, let $X_1, \dots, X_K$ be independant uniformly distributed random variables on $\TT^d$. Set
    %
    \[ D(x) = \frac{1}{K} \sum_{k = 1}^K \delta(x - x_k) \]
    %
    and
    %
    \[ B = \{ \xi \in \ZZ^d: |\xi| \leq K^{1/\beta + 1} \}. \]
    %
    Then there exists a constant $C$ depending on $\beta$ and $d$, such that
    %
    \[ \PP \left( \| \widehat{D} \|_{L^\infty(B)} \geq C K^{-1/2} \log(K)^{1/2} \right) \leq 1/10. \]
\end{lemma}
\begin{proof}
    For each $\xi \in \ZZ^d$ and $k \in \{ 1, \dots, K \}$, consider the random variable $Y(\xi,k) = K^{-1} e^{2 \pi i (\xi \cdot X_k)}$. Then for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationPPDOCS999223}
        \sum_{k = 1}^K Y(\xi,k) = \widehat{D}(\xi).
    \end{equation}
    %
    We also note that for each $\xi \in \ZZ^d$ and $k \in \{ 1, \dots, K \}$,
    %
    \begin{equation} \label{equationGFDSCSXAOOO99}
        |Y(\xi,k)| = K^{-1},
    \end{equation}
    %
    Moreover, for $\xi \neq 0$,
    %
    \begin{equation} \label{equationDOIJWIJCCCCC5555322}
    \begin{split}
        \EE(Y(\xi,k)) = K^{-1} \int_{\TT^d} e^{2 \pi i (\xi \cdot x)}\; dx = 0.
    \end{split}
    \end{equation}
    %
    Since the family of random variables $\{ Y(\xi,1), \dots, Y(\xi,K) \}$ is independent for a fixed non-zero $\xi$, we can apply Hoeffding's inequality together with \eqref{equationPPDOCS999223} and \eqref{equationGFDSCSXAOOO99} to conclude that for all $t \geq 0$,
    %
    \begin{equation} \label{equationDDISCCOXOSPP998323}
        \PP \left( |\widehat{D}(\xi)| \geq t \right) \leq 2 e^{-Kt^2/2}.
    \end{equation}
    %
    A union bound obtained by applying \eqref{equationDDISCCOXOSPP998323} over all $|\xi| \leq K^{1/\beta+1}$ shows that if
    %
    \[ B = \{ \xi \in \ZZ^d : |\xi| \leq K^{1/\beta + 1} \}, \]
    %
    then there exists a constant $C \geq 1$ depending on $d$ and $\beta$ such that
    %
    \begin{equation} \label{equationPPDOCS2424}
        \PP \left( \| \widehat{D} \|_{L^\infty(B)} \geq t \right) \leq \exp \left( C \log(K) - \frac{5K t^2}{C} \right).
    \end{equation}
    %
    But then, setting $t = CK^{-1/2} \log(K)^{1/2}$ in \eqref{equationPPDOCS2424} completes the proof.
\end{proof}

It is a general heuristic that quasi-all sets are as `thin as possible' with respect to the Hausdorff metric. In particular, we should expect the Hausdorff dimension and Fourier dimension of a generic element of $\mathcal{X}_\beta$ to be as low as possible. For each $(E,\mu) \in \mathcal{X}_\beta$, the condition that $\mu \in M(\beta/2)$ implies that $\fordim(\mu) \geq \beta$, so $\fordim(E) \geq \beta$. Thus it is natural to expect that for quasi-all $(E,\mu) \in M(\beta/2)$, the set $E$ has both Hausdorff dimension and Fourier dimension equal to $\beta$.

\begin{lemma}
    For quasi-all $(E,\mu) \in \mathcal{X}_\beta$, $E$ is a Salem set of dimension $\beta$.
\end{lemma}
\begin{proof}
    We shall assume $\beta < d$ in the proof, since when $\beta = d$, $E$ is a Salem set for any $E(,\mu) \in \mathcal{X}_\beta$, and thus the result is trivial. Since the Hausdorff dimension of a measure is an upper bound for the Fourier dimension, it suffices to show that for quasi-all $(E,\mu) \in \mathcal{X}_\beta$, $E$ has Hausdorff dimension at most $\beta$. For each $\alpha > \beta$ and $\delta, s > 0$, and let $A(\alpha,\delta,s) = \{ (E,\mu) \in \mathcal{X}: H^\alpha_\delta(E) < s \}$. Then $A(\alpha,\delta,s)$ is an open subset of $\mathcal{X}_\beta$, and
    %
    \[ \bigcap_{n = 1}^\infty \bigcap_{m = 1}^\infty \bigcap_{k = 1}^\infty A(\beta + 1/n, 1/m, 1/k) \]
    %
    is precisely the family of $(E,\mu) \in \mathcal{X}_\beta$ such that $E$ has Hausdorff dimension at $\beta$.
%
    %Certainly any $E$ in this family must have $H^\alpha(E) = 0$ for all $\alpha > \beta$, so $\hausdim(E) \leq \beta$. But the condition that $\mu \in M(A)$ implies $\fordim(\mu) \geq \beta$. Thus
    %
    %\[ \beta \leq \fordim(\mu) \leq \fordim(E) \leq \hausdim(E) \leq \beta, \]
    %
    %hence all these quantities are equal to $\beta$.
    Thus it suffices to show that $A(\alpha,\delta,s)$ is dense in $\mathcal{X}_\beta$ for $\alpha \in (\beta,d)$ and $\delta, s > 0$. Fix $(E_0,\mu_0) \in \mathcal{X}_\beta$, $\alpha \in (\beta,d)$, $\delta > 0$, $s > 0$, and $\varepsilon_1 > 0$. We aim to show that for each $\varepsilon > 0$, there exists $(E,\mu) \in A(\alpha,\delta,s)$ such that $d_H(E,E_0) \leq \varepsilon$ and $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$. Without loss of generality, in light of Lemma \ref{smoothdensitylemma}, we may assume that $\mu_0 \in C^\infty(\TT^d)$.

    Fix a small value $r$, and then find an integer $K$ such that $r^{-\beta} \leq K \leq r^{-\beta} + 1$. Lemma \ref{LemmaGISCICS1} shows that there exists a constant $C$ depending on $\beta$ and $d$, as well as $K$ points $x_1, \dots, x_K \in \TT^d$ such that if
    %
    \[ D(x) = \frac{1}{K} \sum_{k = 1}^K \delta(x - x_k), \]
    %
    then for each $|\xi| \leq (1/r)^{1 + 1/\beta} \leq K^{1/\beta + 1}$,
    %
    \begin{equation} \label{equationDDVVIXXSX23}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Applying Corollary \ref{lemmaIOJDD23124} with \eqref{equationDDVVIXXSX23}, we conclude that there exists $r_1$ depending on $d$, $\beta$, $\mu_0$, $\varepsilon$, and $\varepsilon_1$ such that if $r \leq r_1$, if
    %
    \[ \mu_1(x) = \frac{1}{K} \left( \sum_{k = 1}^K \phi_{r}(x - x_k) \right) \mu_0(x), \]
    %
    and if
    %
    \[ \mu = \mu_1 / \mu_1(\TT^d), \]
    %
    then
    %
    \begin{equation} \label{equationYYUDUSC4434}
        \| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon.
    \end{equation}
    %
    Note that $\mu$ is supported on $K$ balls of radius $r$. Thus for $r \leq \delta$,
    %
    \begin{equation} \label{equationGGSCPXX22}
        H^\alpha_\delta(\text{supp}(\mu)) \leq K r^\alpha \leq (r^{-\beta} + 1) r^\alpha = r^{\alpha - \beta} + r^\alpha.
    \end{equation}
    %
    Since $\alpha > \beta$, \eqref{equationGGSCPXX22} implies that there is $r_2$ depending on $\alpha$, $\beta$, and $s$ such that for $r \leq r_2$,
    %
    \begin{equation} \label{equationGGSXSOF9923}
        H^\alpha_\delta(\text{supp}(\mu)) \leq s.
    \end{equation}
    %
    Now let
    %
    \[ E = \text{supp}(\mu) \cup \{ y_1, \dots, y_N \}, \]
    %
    where $\{ y_1, \dots, y_N \} \subset E_0$ is a $\varepsilon$-net of $E_0$. Set $r_0 = \min(r_1,r_2, \delta)$ and suppose $r \leq r_0$. Equation \eqref{equationGGSXSOF9923} implies that $H^\alpha_\delta(E) \leq s$, so $(E,\mu) \in A(\alpha,\delta,s)$. And since $\text{supp}(\mu) \subset E$,
    %
    \begin{equation} \label{equationGGISIICV222}
        d_H(E,E_0) \leq \varepsilon.
    \end{equation}
    %
    Recalling \eqref{equationYYUDUSC4434}, we see that we have proved what was required.
\end{proof}

All that now remains is to show that quasi-all elements of $\mathcal{X}_\beta$ avoid the given set $Z$; just as with the proof above, the advantage of the Baire category approach is that we can reduce our calculations to discussing only a couple scales at once, which allows us to focus solely on the discrete, quantitative question at the heart of the problem.

\section{Random Avoiding Sets} 

In the last section, our results held for an arbitrary $\beta \in (0,d]$. But in this section, we assume
%
\[ \beta = \frac{dn - \alpha}{n - 1/2}, \]
%
which will enable us to generically avoid the pattern $Z$.

\begin{lemma}
    For quasi-all $(E,\mu) \in \mathcal{X}_\beta$, for any distinct points $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$.
\end{lemma}
\begin{proof}
    The set $Z \subset \RR^{dn}$ is the countable union of sets with lower Minkowski dimension at most $\alpha$. For a closed set $W \subset \TT^{dn}$ with lower Minkowski dimension at most $\alpha$, and $s > 0$, consider the set
    %
    \[ B(W,s) = \left\{ (E,\mu) \in \mathcal{X}_\beta: \begin{array}{c}
            \text{for all $x_1, \dots, x_n \in E$ such that}\\
            \text{$|x_i - x_j| \geq s$ for $i \neq j$, $(x_1, \dots, x_n) \not \in W$}
        \end{array} \right\}. \]
    %
    If $(E_0,\mu_0) \in B(W,s)$, then because $E_0$ is compact, so too is the set
    %
    \[ F = \{ (x_1,\dots,x_n) \in E_0^n : |x_i - x_j| \geq s\ \text{for $i \neq j$} \} \]
    %
    Since $W$ is also closed, hence compact, there exists $\varepsilon > 0$ such that if $(x_1,\dots,x_n) \in F$, then $d((x_1,\dots,x_n),W) > \varepsilon$. It follows that if $d_H(E_0,E) \leq \varepsilon$, then for any measure $\mu$ supported on $E$, $(E,\mu) \in B(W,s)$. Thus $B(W,s)$ is an open subset of $\mathcal{X}_\beta$. If $Z$ is a countable union of closed sets $\{ Z_k \}$ with lower Minkowski at most $\alpha$, then clearly the set
    %
    \[ \bigcup_{k = 1}^\infty \bigcup_{n = 1}^\infty B(Z_k,1/n) \]
    %
    consists of the family of sets $(E,\mu)$ such that for distinct $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$. Thus it suffices to show that $B(W,s)$ is dense in $\mathcal{X}_\beta$ for any $s > 0$, and any closed set $W$ with lower Minkowski dimension at most $\alpha$.

    Let us begin by fixing a set $W \subset \TT^{dn}$ and a pair $(E_0,\mu_0) \in \mathcal{X}_\beta$. We will show that for any $\varepsilon_1 \in (0,\beta/100]$ and $\varepsilon > 0$, we can find $(E,\mu) \in B(W,s)$ with $d_H(E,E_0) \leq \varepsilon$ and $\| \mu - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon$. We may assume by Corollary \ref{corollaryOIDJOWIJD2212} that $\text{supp}(\mu) = E$ and $\mu \in C^\infty(\TT^d)$. Since $W$ has lower Minkowski dimension at most $\alpha$, we can find arbitrarily small $r \in (0,1)$ such that
    %
    \begin{equation} \label{equationGGSCSAS}
        |W_r| \leq r^{dn - \alpha - \varepsilon_1/4}.
    \end{equation}
    %
    Assume also that $r$ is small enough that we can find an integer $K \geq 10$ with
    %
    \begin{equation} \label{equationICCISAXAX122412}
        r^{\varepsilon_1/2 - \beta} \leq K \leq r^{\varepsilon_1/2 - \beta} + 1.
    \end{equation}
    %
    Let $X_1, \dots, X_K$ be independent and uniformly distributed on $\TT^d$. For each distinct set of indices $k_1, \dots, k_n \in \{ 1, \dots, K \}$, the random vector $X_k = (X_{k_1}, \dots, X_{k_n})$ is uniformly distributed on $\TT^{nd}$, and so \eqref{equationGGSCSAS} and \eqref{equationICCISAXAX122412} imply that
    % \psi_1 = \varepsilon \beta
    % \varepsilon \leq n - 1/2
    % \psi_2 \leq \beta/2
    % \psi_2 = 2 \varepsilon \beta
    \begin{equation} \label{equationGGASDCJWIJSFGGGG}
    \begin{split}
        \PP(d(X_k,W) \leq r) \leq |W_{r}| &\leq r^{dn - \alpha - \varepsilon_1/4}\\
        &\lesssim_{d,n,\beta} K^{\frac{-(dn - \alpha - \varepsilon_1/4)}{\beta - \varepsilon_1/2}}\\
        &= K^{- \left( n - 1/2 - \varepsilon_1 / 4 \beta \right) \left( 1 + \frac{\varepsilon_1}{2\beta - \varepsilon_1} \right)}\\
        &= K^{1/2 - n + \varepsilon_1 / 4\beta - \frac{\varepsilon_1}{2\beta - \varepsilon_1}\left( n - 1/2 - 6\varepsilon_1/\beta \right)}\\
        &\leq K^{1/2 - n + \varepsilon_1/4\beta - \frac{\varepsilon_1}{2\beta - \varepsilon_1}} \leq K^{1/2 - n}.
    \end{split}
    \end{equation}
    %
    If $M_0$ denotes the number of indices $i$ such that $d(X_i,W) \leq r$, then by linearity of expectation we conclude from \eqref{equationGGASDCJWIJSFGGGG} that there is a constant $C$ depending only on $d$, $n$, and $\beta$ such that
    %
    \begin{equation} \label{equationDDASGVV}
        \EE(M_0) \leq (C/10) K^{1/2}.
    \end{equation}
    %
    Applying Markov's inequality to \eqref{equationDDASGVV}, we conclude that
    %
    \begin{equation} \label{equationFGGGSC}
        \PP(M_0 \geq C K^{1/2}) \leq 1/10.
    \end{equation}
    %
    %For each cube $I$ with sides parallel to the axis of $\TT^d$, and with sidelength $K^{-1/4d}$, we find
    %
%    \begin{equation} \label{equationDIOJOIDJSOIJ2222312414}
%    \begin{split}
%        \PP \left( \text{there is $i \in \{ 1, \dots, K \}$ such that $X_i \in I$} \right) &= 1 - (1 - K^{-1/4})^K \geq 1 - K^{-3/4}.
%    \end{split}
%    \end{equation}
    %
%    Now $\TT^d$ is covered by a family of at most $K^{1/4}$ such cubes $I$. If $F = \{ X_1, \dots, X_K \}$, then a union bound applying \eqref{equationDIOJOIDJSOIJ2222312414} repeatedly shows
    %
%    \begin{equation} \label{equationOIJIOWJDIOWJ23122142}
%        \PP \left( d_H(F,\TT^d) \leq d^{1/2} K^{-1/4d} \right) \geq 1 - K^{-1/2}.
%    \end{equation}
    %
%    In particular, we conclude from \eqref{equationOIJIOWJDIOWJ23122142} that there is $K_0$ depending only on $d$ and $\varepsilon$ such that if $K \geq K_0$, then
    %
%    \begin{equation} \label{equationOIWJOIAWJDOIWJ}
%         \PP \left( d_H(F,\TT^d) \leq d^{1/2} K^{-1/4d} \right) \leq 1/10.
%    \end{equation}
    %
    Taking a union bound to \eqref{equationFGGGSC} %\eqref{equationOIWJOIAWJDOIWJ}
    and the result of Lemma \ref{LemmaGISCICS1}, we conclude that there exists $K$ points $x_1, \dots, x_K \in \TT^d$ and a constant $C$ depending only on $d$, $n$, and $\beta$ such that the following two statements hold:
    %
    \begin{itemize}
        \item[(1)] Let $S$ be the set of indices $k_1 \in \{ 1, \dots, K \}$ with the property that we can find distinct indices $k_2, \dots, k_n \in \{ 1, \dots, K \}$ such that if $x = (x_{k_1}, \dots, x_{k_n})$, then $d(x, W) \leq r$. Then
        %
        \begin{equation} \label{equationGGSC99124}
            \#(S) \leq C K^{1/2}.
        \end{equation}

        \item[(2)] If we define
        %
        \[ D_0(x) = \frac{1}{K} \sum_{k = 1}^K \delta(x - x_k) \]
        %
        then for $|\xi| \leq K^{1/\beta + 1}$,
        %
        \begin{equation} \label{equationGGGISCI11242}
            |\widehat{D_0}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
        \end{equation}
    \end{itemize}
    %
    Thus \eqref{equationGGSC99124} and \eqref{equationGGGISCI11242} imply that if
    %
    \[ D_1(x) = \sum_{k \not \in S} \delta(x - x_k), \]
    %
    then for each $|\xi| \leq K^{1/\beta_0 + 1}$,
    %
    \begin{equation} \label{equationGGSCSIAXAXXXSFGG}
        |\widehat{D_1}(\xi)| \leq 2C K^{-1/2} \log(K).
    \end{equation}
    %
    Since $K \geq r^{\varepsilon_1/2 - \beta}$, we can apply Corollary \ref{lemmaIOJDD23124} in conjunction with \eqref{equationGGSCSIAXAXXXSFGG} to find $r_0(k)$ depending only on $d$, $k$, $n$, $\beta$, $\mu_0$, $\varepsilon$, and $\varepsilon_1$ such that if $r \leq \min(r_0(k),s)$ and we define
    %
    \[ \mu_{1,k}(x) = \left( \sum_{k \not \in S} \phi_{(1/2n^{1/2}) r}(x - x_k) \right) \mu_0(x), \]
    %
    and if we then define $\mu_k = \mu_1 / \mu_1(\TT^d)$, then
    %
    \begin{equation} \label{equationvVVV323285853S}
        \| \mu_k - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon/k.
    \end{equation}
    %
    Then the sequence $\{ \mu_k \}$ converges to $\mu_0$ in the norm $M(\beta/2-\varepsilon_1)$. But this means that $\mu_k$ converges to $\mu_0$ in the weak-$*$ topology, i.e. for any $f \in C^\infty(\TT^d)$,
    %
    \[ \lim_{k \to \infty} \int f(x) d\mu_k(x) = \int f(x) d\mu_0(x). \]
    %
    Consider any cover of $\text{supp}(\mu_0)$ by a family of radius $\varepsilon$ balls $\{ B_1, \dots, B_N \}$, and for each $i \in \{ 1, \dots, N \}$ consider a non-negative smooth function $f_i$ supported on $B_i$ with
    %
    \[ \int f_i(x) d\mu_0(x) > 0. \]
    %
    Then weak convergence implies there exists $k_0$ such that for $k \geq k_0$ and $i \in \{ 1, \dots, N \}$,
    %
    \[ \int f_i(x) d\mu_k(x) > 0. \]
    %
    Since $\text{supp}(\mu_k) \subset \text{supp}(\mu)$, this implies that
    %
    \[ d_H(\text{supp}(\mu_{k_0}), \text{supp}(\mu_0)) \leq \varepsilon. \]
    %
    Moreover, 
    %
    \[ \| \mu_{k_0} - \mu_0 \|_{M(\beta/2 - \varepsilon_1)} \leq \varepsilon / k_0 \leq \varepsilon. \]
    %
    Thus all that remains is to show that if $E = \text{supp}(\mu_{k_0})$, then $(E,\mu) \in B(W,s)$.

    Consider $n$ points $y_1, \dots, y_n \in \text{supp}(\mu_{k_0})$, with $|y_i - y_j| \geq r$ for any two indices $i \neq j$. We can therefore find distinct indices $k_1, \dots, k_n \in \{ 1, \dots, K \}$ such that for each $i \in \{ 1, \dots, n \}$,
    %
    \begin{equation} \label{equationFFISICSIC223}
        |x_{k_i} - y_i| \leq (n^{-1/2}/2) \cdot r.
    \end{equation}
    %
    If we set $x = (x_{k_1}, \dots, x_{k_n})$ and $y = (y_1, \dots, y_n)$, then \eqref{equationFFISICSIC223} implies
    %
    \begin{equation} \label{equationFISICISCI232222452}
        |x - y| \leq (r/2).
    \end{equation}
    %
    Since $i_1 \not \in S$, $d(x,W) \geq r$, which combined with \eqref{equationFISICISCI232222452} implies
    %
    \begin{equation} \label{equationSICSICI}
        d(y,W) \geq d(x,W) - |x - y| \geq r/2.
    \end{equation}
    %
    Thus in particular we conclude $y \not \in W$, which shows $(E,\mu) \in B(W,s)$.
\end{proof}

Before we move onto the next proof, let us discuss where the loss in Theorem \ref{maintheorem} occurs in our proof, as compared to \cite{OurPaper}. In the last calculation, in order to obtain the bound \eqref{equationGGSCSIAXAXXXSFGG}, we were forced to choose parameters in such that $\#(S) \leq K^{1/2}$. However, if we were able to justify that square root cancellation occured in the sum
%
\[ \sum_{k \in S} e^{2 \pi i (\xi \cdot x_k)}, \]
%
then we would only be forced to pick $\#(S) \leq K$, which would lead to a dimension bound of the form
%
\[ \frac{dn - \alpha}{n - 1}. \]
%
This would give a Salem set with the same dimension as obtained in the main result of Theorem \cite{OurPaper}.

\section{The More Difficult Case}

Let us now consider the more difficult case. Given $W \subset \TT^{dn}$ with Minkowski dimension at most $\alpha$, and any family of disjoint, sidelength $s$ cubes $Q_1,\dots,Q_n \subset \TT^{dn}$ such that $d(Q_i,Q_j) \geq 10s$, we let
%
\[ H(W;Q_1,\dots,Q_n) = \left\{ (E,\mu) \in \mathcal{X}_\beta: \text{for all $x_1 \in Q_1 \cap E, \dots, x_n \in Q_n \cap E$, $(x_1,\dots, x_n) \not \in W$} \right\}. \]
%
Then $H(W;Q_1,\dots,Q_n)$ is an open subset of $\mathcal{X}_\beta$. Similar to the last case, the proof will follow from showing $H(W;Q_1,\dots,Q_n)$ is dense in $\mathcal{X}_\beta$ for each family of cubes $\{ Q_1,\dots, Q_n \}$. Consider a family of independant random variables
%
\[ \{ X^i_k : i \in \{ 1, \dots, n \}, k \in \{ 1, \dots, K \} \} \]
%
where $X^i_k$ is uniformly distributed on $Q_i$.

Let
%
\[ Y_\xi = \sum_{k \in S} e^{2 \pi i \xi \cdot X_k}, \]
%
Then $Y_\xi$ is a function of the family of random variables $\{ X_i \}$. Now if $\#(S) \leq K$, then if we individually alter each input, we can adjust $Y_\xi$ by at most $2K$. Thus McDiarmid's inequality gives that
%
\[ \PP \left( |Y_\xi - \EE(Y_\xi|BLAH)| \geq t | BLAH \right) \leq 4 \exp \left(- \frac{t^2}{2K^{d-1}} \right). \]
%
Thus $Y_\xi$ deviates from $\EE(Y_\xi|BLAH)$ at a rate of $K^{1/2}$ with low probability, and a union bound over all $\xi$ gives a deviation of $K^{1/2} \log(K)^{1/2}$ with low probability. If we can show that $|\EE(Y_\xi|BLAH)| \leq K^{1/2}$ with high probability, we're be done!.

As a next step, let's calculate $\EE(Y_\xi)$. Each $X_1, \dots, X_K$ independantly has a probability of being in $S$, and the distribution of $e^{2 \pi i \xi \cdot X_k}$ given that $k \in S$ has a particular distribution. Thus $\EE(Y_\xi|BLAH) = K \PP(k \in S|BLAH) \EE(e^{2 \pi i \xi \cdot X_k}|BLAH, k \in S)$.

If
%
\[ W_\varepsilon = \{ (x,y) \in \TT^2: d(x,K^{-1/2} \ZZ) \leq \varepsilon \}, \]
%
then $|W_\varepsilon| \leq K^{1/2} \varepsilon$

Let us think about this in a manner discretized as a scale $\varepsilon$. If $\PP(k \in S| BLAH) \geq K^{-1/2} = \varepsilon^{\beta/2}$, then there are at least $\varepsilon^{\beta/2-1}$ different $\varepsilon$-separated values that $X_k$ can take. Thus $e^{2 \pi i X_k}$ can take. Now $e^{2 \pi i \xi \cdot X}$ points in a particular direction on $|\xi| \varepsilon^{-1}$

\begin{comment}
Suppose we can show that for any $\xi \neq 0$,
%
\[ |\widehat{Y_1}(\xi) + \dots + \widehat{Y_N}(\xi)| \lesssim C \left( \| \widehat{Y_1} \|_{L^\infty(\RR^d)}^2 + \dots + \| \widehat{Y_N} \|_{L^\infty(\ZZ^d)}^2 \right)^{1/2}. \]
%
In the example we consider, this would then imply
%
\[ |Y_1(\xi) + \dots + Y_N(\xi)| \lesssim N^{1/2}. \]
%
Thus in the last theorem we can take $N = K$,
%
\[ N \leq K^{1 - (2d/\beta)(1 - 1/p)} \]
%
If we can set $p \geq 1$, 
\end{comment}

\begin{comment}

\section{Techniques for Avoiding Hyperplanes}

Let $y = f(x)$ be a curve in $\TT^2$ defining a curve $S$, where $f$ is an analytic function (except perhaps at finitely many points?). Given $\varepsilon > 0$, we want to determine the differentiability of the map
%
\[ A(x) = H^1(S_\varepsilon \cap \{ x \times \TT \}). \]
%
We wish to show $A$ is a smooth function. The tangent to $S$ at a point $(x,f(x))$ is given by $(1,f'(x))$, and so the unit normal vector is
%
\[ N(x) = \frac{(f'(x),-1)}{\sqrt{1 + f'(x)^2}}. \]
%
Suppose that $x_0 \in \TT$ is fixed, and let $x \in \TT$ and $|\delta| \leq \varepsilon$ be given such that
%
\[ (x_0,y_0) = (x,f(x)) + \delta N(x) = \left( x + \frac{\delta f'(x)}{\sqrt{1+ f'(x)^2}}, f(x) - \frac{\delta}{\sqrt{1 + f'(x)^2}} \right) \]
%
Thus
%
\[ x_0 = x + \frac{\delta f'(x)}{\sqrt{1 + f'(x)^2}} \]
%
and
%
\[ y_0 = f(x) - \frac{\delta}{\sqrt{1 + f'(x)^2}}. \]
%
Now the first equation tells us that
%
\[ \delta = - (x - x_0) \frac{\sqrt{1 + f'(x)^2}}{f'(x)}. \]
%
Thus if we define
%
\[ g(x,x_0) = \begin{cases} f(x) + \frac{x - x_0}{f'(x)} &: f'(x) \neq 0 \\ BLAH &: BLAH, \end{cases} \]
%
then $y_0 = g(x,x_0)$. Thus we ask ourselves what is the value of
%
\[ A(x_0) = \max \left\{ f(x) + \frac{x - x_0}{f'(x)} : |x - x_0| \leq \frac{\varepsilon |f'(x)|}{\sqrt{1 + f'(x)^2}} \right\}. \]
%
Now $g(x,x_0)$ is a smooth function except where $f'(x) = 0$. In particular, if $f'(x_0) \neq 0$, then the constraint region defining $A(x_0)$ is a finite union of closed intervals. And $f'(x_0) = 0$ only at finitely many points, and if we make $\varepsilon$ small enough we can make $A(x_0) = f(x_0) + \varepsilon$ at these points.

so this causes us no problems since we only care about whether $A$ is differentiable except at finitely many points. To analyze $A(x_0)$ when $f'(x_0) = 0$, we note that a solution that gives the maximum either satisfies
%
\[ f'(x)(f'(x)^2 + 1) + (x - x_0) f''(x) = 0 \]
%
or
%
\[ x - x_0 = \frac{\varepsilon f'(x)}{\sqrt{1 + f'(x)^2}} \]
%
or
%
\[ x - x_0 = \frac{-\varepsilon f'(x)}{\sqrt{1 + f'(x)^2}}. \]
%
If $\varepsilon$ is small enough, then the implicit function theorem implies that the second and third equations have finitely many solutions for each $x_0$, which are locally smoothly parameterized. Since $f'(x_0) \neq 0$, the first equation does not even have any solutions if $\varepsilon \lesssim 1$. Thus we conclude that if $\varepsilon$ is small enough, there exists a function $x(x_0)$ which is smooth, except at finitely many points, such that
%
\[ g(x_0) = f(x) + \frac{x - x_0}{f'(x)}. \] 
%
Thus at any $x_0$ where $x$ is smooth, we conclude
%
\[ g'(x_0) = f'(x) \cdot x' + \frac{x' - 1}{f'(x)} - \frac{x - x_0}{f'(x)^2} f''(x) x'. \]

\end{comment}

\begin{thebibliography}{9}

\bibitem{Korner1}
    T.W. K\"{o}rner,
    \textit{Measures on Independent Sets, A Quantitative Version of Rudin's Theorem}.

\bibitem{Korner2}
    T.W. K\"{o}rner,
    \textit{Fourier transforms of measures and algebraic relations on their supports}.

\bibitem{OurPaper}
    Jacob Denson, Malabika Pramanik, Joshua Zahl,
    \textit{Large sets avoiding rough patterns}.

\bibitem{myThesis}
    Jacob Denson,
    \textit{Cartesian products avoiding patterns}.

%\bibitem{Vershynin}
%    Roman Vershynin,
%    \textit{High dimensional probability},
%    Cambridge Series in Statistical and Probabilistic Mathematics,
%    2018.

\bibitem{VanHandel}
    Ramon van Handel
    \textit{Probability in High Dimensions},
    2016.

\bibitem{Ekstrom2014}
    Fredrik Ekstr\"{o}m, Tomas Persson J\"{o}rg Schmeling,
    \textit{On the Fourier dimension and a modification},
    2015.

\end{thebibliography}

\end{document}