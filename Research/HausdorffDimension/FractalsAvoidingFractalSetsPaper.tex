\documentclass{article}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{amssymb}
\usepackage{mathabx}
\usepackage{accents}
\usepackage[margin=0.7in]{geometry}
\usepackage[english]{babel}
\usepackage{blindtext}

\theoremstyle{plain}
\newtheorem{lemma}{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem*{example}{Example}
\newtheorem*{fact}{Fact}
\newtheorem*{corollary}{Corollary}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem*{remark}{Remark}

\def\changemargin#1#2{\list{}{\rightmargin#2\leftmargin#1}\item[]}
\let\endchangemargin=\endlist 

\DeclareMathOperator{\codim}{codim}

\title{Fractals Avoiding Fractal Sets}

\author{Jacob Denson\\ \and Malabika Pramanik\\ \and Josh Zahl}

\begin{document}

\maketitle

\begin{multicols}{2}

\begin{abstract}
	\blindtext[1]
\end{abstract}

Suppose you have to determine the stability of an operator on function spaces. Thinking geometrically, one can study how the operator acts on indicator functions. The existence of interesting characteristics in sets often gives insight into how the operator behaves on the corresponding indicator function. The problem then reduces to studying fractals with certain characteristics.
%
\begin{itemize}
	\item Classically, the tubular maximal operator
	%
	\[ f_\delta^*(e) = \sup_{a \in \mathbf{R}^n} \frac{1}{|T_e^\delta|} \int_{a + T_e^\delta} |f(y)|\; dy \]
	%
	where $T_e^\delta$ is a $\delta$ thickened line in the direct $e \in S^{n-1}$, satisfies a bound $\| f^*_\delta \|_{L^n(S^{n-1})} \lesssim_\varepsilon \delta^{-\varepsilon} \| f \|_{L^n(\mathbf{R}^n)}$ for all $\varepsilon$ if and only if every set in $\mathbf{R}^n$ containing a unit line segment in every direction has Hausdorff dimension $n$.

	\item For a given Radon measure $\mu$ and kernel $K$, we can consider the singular integral operator
	%
	\[ T(f)(x) = \int K(x,y) f(y)\; d\mu(x) dy \]
	%
	The nonexistence of principal values for the operator depends on the geometric structure of the support of $\mu$. For instance, using the symmetry of the fractals given, in \cite{David} it is show that there is $\mu$ supported on a one-dimensional four corners Cantor set in the plane for which all principal values do not exist, and in \cite{Vasilis} the same is shown for low Hausdorff dimension variants of the planar Sierpinski triangle.

	\item For a compactly supported Borel measure $\mu$ on $\mathbf{R}^n$, the authors of \cite{Bennett} consider the operator
	%
	\[ T(\mu) = \int \prod_{i = 1}^k (\sigma_{t_i} * \rho_\varepsilon)(x_i - x_{i-1})\;  d\mu^{k+1}(x_0, \dots, x_k) \]
	%
	where $\rho$ is a smooth cutoff function and $\sigma_r$ is the Lebesgue measure on the sphere of radius $r$ is $\mathbf{R}^n$. The existence of a uniform estimate $T(\mu) \leq C^k$ independent of $\varepsilon$ and $t_1, \dots, t_k$ implies that if a set $E$ has Hausdorff dimension greater than $(d+1)/2$, then the `$k$ distance set'
	%
	\[ \Big\{ \big(|x_0 - x_1|, |x_1 - x_2|, \dots, |x_{k-1} - x_k|\big) : x_i \in E \Big\} \]
	%
	has positive Lebesgue measure.
\end{itemize}

In this paper, we do not discuss particular operators, but instead describe methods to find large sets avoiding fine-scale patterns. This provides users studying operators to have general tools to construct fractals for their needs. Important examples of fine-scale patterns include affine configurations, such as sets not containing the vertices of isosceles triangles, sets not containing three term arithmetic progressions, sets not generating particular families of angles, and sets not containing points in a common hyperplane. For these examples, the Lebesgue density theorem implies any set of positive measure contains these patterns. Thus we quantify the size of sets by their Hausdorff dimension.

There are two approaches to the pattern avoidance problem. We get upper bounds by proving sets with large Hausdorff dimension contains patterns. Constructing sets avoiding patterns with large Hausdorff dimension give lower bounds. In this paper, we focus on the {\it construction problem} for lower bounding pattern avoidance problems.

There are already generic pattern avoidance methods in the literature. We compare our method to them in detail in section 6. But these rely on the non-singularity of the patterns. The novel feature of our method is we can avoid points with patterns lying on an {\it arbitrary} fractal set, and the Hausdorff dimension of our constructions is still comparable to previous methods.

The {\it key idea} of our method is the introduction of a new geometric framework for pattern avoidance problems, described in section 1. A simple combinatorial argument, described in section 2, exploited repeatedly in section 3 via a queueing process leads directly to a pattern avoiding set. We believe this new geometric framework should help find further methods in the field. We show this by proving another pattern avoidance result in section 5, assuming extra geometric information on the patterns.

\section{A Fractal Avoidance Framework}

The common framework used to think about pattern avoidance problems is to specify the pattern as the zero set of some function.
%
\begin{itemize}
	\item A set $X \subset \mathbf{R}$ contains no three term arithmetic progressions if and only if for any distinct $x,y,z \in X$,
	%
	\[ f(x,y,z) = x + z - 2y \neq 0  \]
	%
	This function vanishes if and only if there exists $b$ and $t$ such that $x = b$, $y = b+t$, and $z = b+2t$.

	\item A set $X \subset \mathbf{R}^d$ contains the vertices of no isosceles triangles if and only if for any three distinct $x,y,z \in X$,
	%
	\[ f(x,y,z) = d(x,y) - d(y,z) \neq 0 \]
	%
	The problem of avoiding this function is similar to the last example, since isosceles triangles can be considered as planar variants of three term arithmetic progressions.

	\item A set $X \subset \mathbf{R}^d$ does not contain a family of angles $\{ \alpha_i \}$ if and only if for any distinct $x,y,z \in X$, and $i$,
	%
	\[ f(x,y,z) = \frac{(x - z) \cdot (y - z)}{|x - z||y - z|} \neq \cos(\alpha_i) \]
	%
	where the cosine formula for the dot product is used.

	\item A set $X \subset \mathbf{R}^d$ does not contain $d+1$ points in a lower dimensional hyperplane if and only if for any distinct $x_0, \dots, x_d \in X$,
	%
	\[ f(x_0, \dots, x_d) = \det(x_1 - x_0, \dots, x_d - x_0) \neq 0 \]
	%
	since $\det(x_1 - x_0, \dots, x_d - x_0) = 0$ only when the vectors $x_1 - x_0, \dots, x_d - x_0$ do not form a basis, and thus span a plane of dimension smaller than $d$.
\end{itemize}
%
This leads naturally to a generic formulation of pattern avoidance problems:

\begin{changemargin}{0.5em}{0em}
{\bf The Configuration Avoidance Problem:} Given a function $f: (\mathbf{R}^d)^n \to \mathbf{R}$ as input, find $X \subset \mathbf{R}^d$ such that for any {\it distinct} $x_1, \dots, x_n \in X$, $f(x_1, \dots, x_n) \neq 0$, with as high a Hausdorff dimension as possible.
\end{changemargin}

This is the viewpoint for the methods of \cite{MalabikaRob} and \cite{Mathe}, who give results assuming various regularity conditions on the function $f$. It is the viewpoint of this paper that the function $f$ contains extraneous information which is irrelevant to the problem. The only important information we need to extract from the function $f$ is the geometric structure of it's zero set. If we denote the zero set of $f$ by $Z$, the configuration avoidance problem becomes equivalent to a more flexible framework:

\begin{changemargin}{0.5em}{0em}
	{\bf The Fractal Avoidance Problem:} Given $Z \subset (\mathbf{R}^d)^n$, find a set $X \subset \mathbf{R}^d$ such that $X^d \cap Z \subset \Delta$, where $\Delta = \{ x \in (\mathbf{R}^d)^n : x_i = x_j\; \text{for some $i$ and $j$} \}$, with as high a Hausdorff dimension as possible.
\end{changemargin}

A natural goal is to solve the generic fractal avoidance problem with minimal assumptions on $Z$. Here we let $Z$ take the form of an arbitrary fractal, and the only assumptions we place on $Z$ are it's fractal dimension.

\begin{theorem}
	If $Z$ has Minkowski dimension $\alpha \geq d$, then there exists $X$ solving the fractal avoidance problem for $Z$ with
	%
	\[ \dim_{\mathbf{H}}(X) = \frac{nd - \alpha}{n - 1} = \frac{\codim_{\mathbf{H}}(Z)}{n - 1} \]
\end{theorem}

\begin{remark}
	If $Z$ has dimension $\alpha < d$, then the set
	%
	\[ X = (\pi_1(Z) \cup \dots \cup \pi_n(Z))^c \]
	%
	where $\pi_i: (\mathbf{R}^d)^n \to \mathbf{R}^d$ is projection on the $i$th coordinate, has full Hausdorff dimension and solves the fractal avoidance problem. Thus for these bounds the problem is trivial.
\end{remark}

% TODO: Describe why Delta is important in the problem description.

A second goal is to show an example where assuming extra geometric conditions on $Z$ leads to constructions with a higher Hausdorff dimension. Thus the framework extends to further methods in pattern avoidance. We consider the condition where $Z$ is efficiently coverable by parallel hyperplanes of a fixed dimension.

\begin{theorem}
	If there is $k \geq 2$ and a linear $T: \mathbf{R}^{nd} \to \mathbf{R}^{kd}$ such that $T(Z)$ is $\alpha$ dimensional, with $\alpha \leq (d-1)k$, then there exists $X$ solving the fractal avoidance problem for $Z$ with
	%
	\[ \dim_{\mathbf{H}}(X) = \frac{dk - \alpha}{k-1} \]
\end{theorem}

Because of the lack of any {\it rigid} geometric information about the set $Z$, such as smoothness, the only techniques we can use to avoid $Z$ are discretizing the problem using covering arguments. This can be neatly summarized as a combinatorial argument on graphs, which we detail in the next section and exploit repeatedly in the proofs of both results.

\section{Avoidance at a Single Scale}

We now develop a discrete technique used to construct solutions to the fractal avoidance problem. It depends very little on the Euclidean structure of the plane. As such, we rephrase the construction as a combinatorial problem on graphs. In the past few years in the discrete setting it has been noticed that rephrasing particular questions in terms of abstract problems on hypergraphs allows one to extend various results into sparse analogues \cite{BaloghMorrisSamotij}. In this paper we consider a continuous analogue, where sparsity is represented in terms of the dimension of the set $Z$ we are trying to avoid. Breaking down the problem into a sequence of discrete scales then reduces to discrete techniques.

%TODO: Maybe move this to the comparison section?

Recalling notation, we consider a fixed {\it vertex set} $V$ and a collection of {\it hyperedges} $E \subset 2^V$ consisting solely of {\it $n$ element subsets} of $V$. The collection of data $G = (V,E)$ is known as a {\it $n$ uniform hypergraph}. A subset of vertices $W \subset V$ that {\it contains no edge}, in the sense that for any $e \in E$, $e \not \subset W$, is known as an {\it independent set}. Finally, a {\it coloring} is a partition of the vertex set into finitely many subclasses, each class called a {\it color}, subject to the restriction that no two vertices in any edge $e \in E$ have the same color. We consider {\it $K$ uniform} colorings, such that there are at least $K$ vertices with each color.

We prove a form of Tur\'{a}n's theorem, which quantifies the statement that graphs with few edges contain large independent sets. The connection with fractals is we will take the vertices of our graph as cubes in $\mathbf{R}^d$, and take a hyperedge between cubes whose Cartesian product intersects $Z$. The smaller the dimension of $Z$, the fewer edges exist in the graph. For technical reasons, we need an extra restriction on the independent sets we construct so it is `uniformly' chosen over the graph. This is the reason for the introduction of colorings.

\begin{lemma}
	Let $G$ be an $n$ uniform hypergraph with a $K$ uniform coloring. Then there is an independent set $W$ containing elements from all but at most $|E|/K^n$ colors.
\end{lemma}
\begin{proof}
	Let $U$ be a random vertex set chosen by selecting a vertex of each color uniformly at random. So every vertex occurs in $U$ with probability at most $1/K$. For any edge $e = \{ v_1, \dots, v_n \}$, the vertices $v_i$ all have different colors. Thus they occur in $U$ independently, and so
	%
	\begin{align*}
		\mathbf{P}(v_1 \in U, \dots, v_n \in U) = \mathbf{P}(v_1 \in U) \dots \mathbf{P}(v_n \in U) \leq 1/K^n
	\end{align*}
	%
	If we let $E'$ denote the edges $e = \{ u_1, \dots, u_n \}$ with $u_1, \dots, u_n \in U$, then
	%
	\[ \mathbf{E}|E'| = \sum_{e \in E} \mathbf{P}(e \in E') \leq \sum_{e \in E} 1/K^n = \frac{|E|}{K^n} \]
	%
	This means we may choose a particular, {\it nonrandom} $U$ for which $|E'| \leq |E|/K^n$. If we form a vertex set $W \subset U$ by removing, for each $e \in E'$, a vertex in $U$ adjacent to the edge, then $W$ is an independent set containing all but $|E'| \leq |E|/K^n$ colors.
\end{proof}

\begin{corollary}
	If $|V| \gtrsim N^a$, $|E| \lesssim N^b$, and $K \gtrsim N^c$, where $b < a + c(n-1)$, then as $N \to \infty$ we can find an independent set containing all but a fraction $o(1)$ of the colors.
\end{corollary}
\begin{proof}
	A simple calculation on the quantities of the previous lemma yields
	%
	\begin{align*}
		\frac{\# ( \text{colors removed} )}{\# ( \text{all colors} )} = \frac{|E|/K^n}{|V|/K} = \frac{|E|}{|V|K^{n-1}} \lesssim \frac{N^b}{N^{a + c(n-1)}}
	\end{align*}
	%
	This is $o(1)$ if $b < a + c(n-1)$.
\end{proof}

We now apply these constructions to a problem clearly related to the fractal avoidance problem. It will form our key method to construct fractal avoidance solutions. Given a real number $L$, we subdivide $\mathbf{R}^d$ into a lattice of side length $L$ cubes with corners on $L \cdot \mathbf{Z}^d$, the collection of such cubes we will denote by $\mathcal{B}(L,d)$. This grid is used to granularize configuration avoidance.

\begin{theorem}
	Suppose $\mathcal{I}_1, \dots, \mathcal{I}_n$ are disjoint collections of cubes in $\mathcal{B}(L,d)$, with $|\mathcal{I}_i| \gtrsim (1/L)^d$. If $\alpha$ strictly bounds the lower Minkowski dimension of $Z$ from above, and a rational parameter
	%
	\[ \beta > \max \left(1, d \cdot \frac{n-1}{nd-\alpha} \right) \]
	%
	is fixed, then there exists collections of cubes $\mathcal{J}_1, \dots, \mathcal{J}_n \in \mathcal{B}(L^\beta,d)$ with each cube in $\mathcal{J}_1 \times \dots \times \mathcal{J}_n$ disjoint from $Z$, and each $\mathcal{J}_i$ containing cubes in all but a fraction $o(1)$ of cubes in $\mathcal{I}_i$ as $L \to 0$.
\end{theorem}
\begin{proof}
	We reduce this problem to the independent set problem we just proved a result about. We define the discretization of $Z$ to be
	%
	\[ \mathcal{Z} = \{ I \in \mathcal{B}(L^\beta,nd) : I \cap Z \neq \emptyset \} \]
	%
	For each $i$, we set
	%
	\[ \mathcal{I}_i' = \{ I \in \mathcal{B}(L^\beta,d) : \text{there is}\ J \in \mathcal{I}_i\ \text{s.t.}\ I \subset J \} \]
	%
	We obtain an $n$ uniform hypergraph $G$ by taking the cubes in $\mathcal{I}_1', \dots, \mathcal{I}_n'$ as vertices, with a hyperedge between $I_1 \in \mathcal{I}'_1, \dots, I_n \in \mathcal{I}'_n$ if $I_1 \times \dots \times I_n \in \mathcal{Z}$. We then take a coloring on $G$ by declaring two cubes in $\mathcal{I}_i'$ to be the same color if they are contained in a common cube in $\mathcal{I}_i$. In particular, this gives us a true coloring because every color occurs solely in $\mathcal{I}_i$ for some index $i$, and every edge in the hypergraph contains exactly one vertex from each index. An independent set in this graph can be written as $\mathcal{J}_1, \dots, \mathcal{J}_n$, where the $\mathcal{J}_i$ are collections of cubes which are sub-cubes of cubes in $\mathcal{I}_i$ and no cube in $\mathcal{J}_1 \times \dots \times \mathcal{J}_n \subset \mathcal{B}(1/N^\beta,nd)$ intersects $Z$. Thus to prove the theorem it suffices to find a large independent set in this graph.

	We employ the corollary we just proved to do this, by bounding the number of vertices and edges in $G$. Since a cube in $\mathcal{B}(L,d)$ contains $\Omega(1/L^{d(\beta-1)})$ cubes in $\mathcal{B}(L^\beta,d)$, we conclude that $|\mathcal{I}'_i| \gtrsim (1/L)^{d(\beta - 1)} |\mathcal{I}_i| \gtrsim (1/L)^{d \beta}$. But then the number of vertices of $G$ is $\sum |\mathcal{I}'_i| \gtrsim (1/L)^{d \beta}$. The Minkowski dimension bound on $Z$ implies that the number of edges in $G$ is bounded above by $|\mathcal{Z}| \lesssim (1/L)^{\alpha \beta}$,Finally, the coloring is $N^{d(\beta - 1)}$ uniform. Thus in the terminology of the previous corollary, $a = d \beta$, $b = \alpha \beta$, and $c = d(\beta - 1)$. The inequality $\beta > d(n-1)/(nd - \alpha)$, is equivalent to the inequality $b < a + c(n-1)$, and so the corollary applies to give the required result.
\end{proof}

The value $d \cdot (n-1)/(n-\alpha)$ in the theorem is directly related to the dimension $(n-\alpha)/(n-1)$ we get in our main result. If, for a specific $Z$, we can prove a variant of this lemma with $d \cdot (n-1)/(n-\alpha)$ replaced with $d/\lambda$, then going through the rest of our proof will immediately yield $X$ with Hausdorff dimension $\lambda$. In particular, to prove our second result it will suffice to prove the theorem above given that $Z$ has a low rank assumption and $d \cdot (n-1)/(n-\alpha)$ is replaced with $d \cdot (k-1)/(dk - k - \alpha)$.

% TODO: Include Tightness Calculation?

\section{A Fractal Avoiding Set}

We get solutions $X$ to fractal avoidance problems by breaking the problem down into a sequence of discrete configuration problems. The central idea was first used in \cite{MalabikaRob}. We construct $X$ as a limit $\lim X_N$, where $X_N$ is a disjoint union of side length $L_N$ cubes. To obtain $X_{N+1}$, we subdivide $X_N$ into cubes of side length $R_N$, then further subdivide these cubes into cubes of smaller side length $L_{N+1}$, and removing a portion of them. The remaining set is $X_{N+1}$.

At each step $N$, we consider a disjoint collection of side length $R_N$ cubes $\mathcal{I}_1(N), \dots, \mathcal{I}_n(N) \subset \mathcal{B}(R_N,d)$, each cube contained in $X_N$. The main result of the previous section allows us to find a collection of side length $R_N^{\beta_N}$ cubes $\mathcal{J}_i(N) \subset \mathcal{I}_i(N)$ with all cubes in $\mathcal{J}_1(N) \times \dots \times \mathcal{J}_n(N)$ disjoint from $Y$, and where $\beta_N$ is an arbitrary decreasing sequence converging to $\beta = d(n-1)/(n-\alpha)$ from above. We then form $X_{N+1}$ from $X_N$ by removing the parts of cubes in $\mathcal{I}_i(N)$ which are not contained in the cubes in $\mathcal{J}_i(N)$. Note that in particular this means that we can set $L_{N+1} = R_N^{\beta_N}$. Once we fix parameters and an initial set $X_0$, we get a sequence $X_0, X_1, \dots$ converging to a set $X$. We set $X_0 = [0,1]^d$ for simplicity. A simple constraint detailed below is the only requirement to ensure that $X$ is a solution to the fractal avoidance problem.

\begin{lemma}
	Suppose that for any choice of distinct $x_1, \dots, x_n \in X$, there exists $N$ such that each $\mathcal{I}_i(N)$ contains a cube containing $x_i$. Then $X^d \cap Y \subset \Delta$.
\end{lemma}
\begin{proof}
	Given any such $x_1, \dots, x_n$, we know that $x_1, \dots, x_n \subset X_{N+1}$, so $x_1 \in \mathcal{J}_1(N), \dots, x_n \in \mathcal{J}_n(N)$. This means that $(x_1, \dots, x_n)$ are contained in a cube in $\mathcal{J}_1(N) \times \mathcal{J}_n(N)$, and by assumption this cube is disjoint from $Y$. Taking contrapositives of this argument shows that if $y \in X^d \cap Y$, then there must be some $i$ and $j$ for which $y_i = y_j$, so $y \in \Delta$.
\end{proof}

% TODO: Include diagram of construction of queueing.

We achieve the constraint in the lemma by dynamically choosing parameters subject to a queueing process which eventually ensures all points in $X$ are separated. The queue will consist of an ordered sequence of tuples $(I_1, \dots, I_n)$, where $I_1 ,\dots, I_n$ are disjoint cubes. At stage $N$ of the construction, we take off the front tuple $(I_1, \dots, I_n)$ from the queue, and set $\mathcal{I}_i(N)$ to be the set of all cubes in $\mathcal{B}(R_N,d)$ which are a subset of both $I_i$ and $X_N$. We then subdivide $X_N$ using these parameters to form the set $X_{N+1}$ as a union of length $L_{N+1} = R_N^\beta$ intervals. After this, for {\it any} ordered choice of distinct intervals $I_1, \dots, I_n \in \mathcal{B}(L_{N+1},d)$, with each interval $I_i$ a subset of $X_{N+1}$, we add the tuple $(I_1, \dots, I_n)$ to the end of the queue.

If the lengths of intervals $L_N$ tend to zero as $N \to \infty$, which will of course be the case, then for any distinct choice of $x_1, \dots, x_n \in X$, there exists $N$ and $L_N$ such that $|x_i - x_j| \geq 2 L_N$ for all $i \neq j$. Thus at stage $N$ of the construction, we push a tuple $(I_1, \dots, I_n)$ to the end of the queue with $x_i \in I_i$, and at a {\it much} {\it much} later stage $M$ of the construction, this tuple pops off the front of the queue, and so $\mathcal{I}_i(M)$ contains a cube containing $x_i$. Thus we conclude that $X$ is a solution to the fractal avoidance problem.

\section{Dimension Bounds}

To complete the proof, it suffices to choose the parameters $R_N$ which lead to the correct Hausdorff dimension bound on $X$. To do this, we also fix a decreasing sequence $\lambda_N$ such that $\lambda_N \beta_N > d$, used later on in our argument. Since $\beta_N$ converges to $\beta$ from above, we can let $\lambda_N$ tend to $\lambda = (dn - \alpha)/(n - 1)$ from below. The fact that the dissection of $X_{N+1}$ for $X_N$ occurs uniformly over the will aid us in annihilating the super-exponentially increasing constants which inherently occur from the exponentially decreasing values of $L_N$ forced upon us.

We rely on the mass distribution principle to construct a probability measure $\mu$ supported on $X$. This enables us to calculate the Hausdorff dimension of $X$ using Frostman's lemma. We begin by putting the uniform probability measure $\mu_0$ on $X_0 = [0,1]^d$. Then, at each stage of the construction, we construct $\mu_{N+1}$ from $\mu_N$ by taking the mass on a certain side length $L_N$ cube in $X_N$, and uniformly distributing it's mass over the side length $L_{N+1}$ cubes in $I \cap X_{N+1}$. Using the weak compactness of the unit ball in $L^1(\mathbf{R}^d)^*$, we get a weak limit $\mu = \lim \mu_n$. The fact that $X_n$ contains the support of $\mu_n$ implies $X$ supports $\mu$.

It is intuitive that the mass on $\mu$ will distribute more thinly at each stage the fatter the cubes we keep on each iteration of the discrete scale argument. Quantifying this leads directly to our result. More precisely, we will prove that for each length $L$ interval $I$, $\mu(I) \lesssim_N L^{\lambda_N}$. Thus Frostman's lemma guarantees that $\dim_{\mathbf{H}}(X) \geq \lambda_N$, and taking $\lambda_N \to \lambda$ will complete the proof.

\begin{lemma}
	For $R_N \gg 0$, if $I \in \mathcal{B}(L_{N+1},d)$ and $J \in \mathcal{B}(L_N,d)$,
	%
	\[ \mu(I) \leq 2 (R_N/L_N)^d \mu(J)\ \ \ \mu(I) \leq 2^N R_0^{d - \beta_0} \dots R_N^{d - \beta_N} R_N^d \]
\end{lemma}
\begin{proof}
	If $I$ is not a cube in $X_{N+1}$, then
	%
	\[ \mu(I) = \mu_{N+1}(I) = 0 \]
	%
	so the inequality is obviously true. Otherwise, we can find a cube $J \in \mathcal{B}(L_N,d)$ in $I \cap X_N$. $J$ contains $(L_N/R_N)^d$ side length $R_N$ cubes. Our main discrete result implies that $X_{N+1}$ contains a side length $L_{N+1}$ cube in all but a fraction $o(1)$ of these cubes,. In particular, if we choose $R_N$ sufficiently large, then we know that we keep a side length $L_N$ portion of at least half of these cubes. Thus
	%
	\begin{align*}
		\mu(I) &= \mu_{N+1}(I) \leq \frac{\mu_N(J)}{(L_N/R_N)^d/2}\\
		&= 2 \mu_N(J) (R_N/L_N)^d = 2 \mu(J) (R_N/L_N)^d
	\end{align*}
	%
	completing the calculation. Applying this calculation iteratively, we conclude
	%
	\begin{align*}
		\mu(I) &\leq 2^N (R_0/L_0)^d (R_1/L_1)^d \dots (R_N/L_N)^d\\
		&= 2^N R_0^{d - \beta_0} \dots R_{N-1}^{d - \beta_{N-1}} R_N^d
	\end{align*}
	%
	completing the calculation.
\end{proof}

\begin{corollary}
	If $R_N \gg 0$, $\mu(I) \leq L_N^{\lambda_N}$ for $I \in \mathcal{B}(L_N,d)$.
\end{corollary}
\begin{proof}
	We write the inequality in the last problem as
	%
	\[ \mu(I) \leq [2^N R_0^{d - \beta_0} \dots R_{N-1}^{d - \beta_{N-1}} R_N^{d - \lambda_N \beta_N}] L_{N+1}^{\lambda_N} \]
	%
	Since $\lambda_N \beta_N > d$, the quantity in the square brackets is $o(1)$ as $R_N \to \infty$. Thus for sufficiently large $R_N$, we conclude that $\mu(I) \leq L_N^{\lambda_N}$.
\end{proof}

This is almost the required inequality, except we have only proven it for intervals at particular scales. To get a general inequality, we use the fact that our construction distributes uniformly across all intervals.

\begin{theorem}
	If $R_N \gg 0$, then we have $\mu(I) \leq 2^{d+1} L^{\lambda_N}$ for all intervals $I$ with side length $L \leq L_N$.
\end{theorem}
\begin{proof}
	We break our analysis into three cases, depending on the size of $L$:
	%
	\begin{itemize}
		\item If $R_N \leq L \leq L_N$, we can cover $I$ by at most $2^d(L/R_N)^d$ cubes in $\mathcal{B}(R_N,d)$. For each such cube, we know that the mass on each side length $R_N$ cube is at most $2(R_N/L_N)^d$ times the mass on an element of $\mathcal{B}(L_N,d)$. Thus
		%
		\begin{align*}
			\mu(I) &\leq [2^d(L/R_N)^d] [2(R_N/L_N)^d] [L_N^{\lambda_N}]\\
			&\leq \frac{2^{d+1} L^d}{L_N^{d - \lambda_N}} \leq 2^{d+1} L^{\lambda_N}
		\end{align*}
		%
		which gives the required result.

		\item If $L_{N+1} \leq L \leq R_N$, we can cover $L$ by at most $2^d$ cubes in $\mathcal{B}(R_N,d)$. Each cube in $\mathcal{B}(R_N,d)$ contains at most one cube in $\mathcal{B}(L_{N+1},d)$ which is also contained in $X_{N+1}$, so the bound in the last corollary gives that $\mu(I) \leq 2^d L_{N+1}^{\lambda_N} \leq 2^d L^{\lambda_N}$.

		\item If $L \leq L_{N+1}$, there certainly exists $M$ such that $L_{M+1} \leq L \leq L_M$, and one of the previous cases yields that $\mu(I) \leq 2^{d+1} L^{\lambda_M} \leq 2^{d+1} L^{\lambda_N}$.
	\end{itemize}
	%
	This covers all possible situations, completing the proof.
\end{proof}

To use Frostman's lemma, we need the result $\mu(I) \lesssim L^{\lambda_N}$ for an {\it arbitrary} interval, not just one with $L \leq L_N$. But this is no trouble; it is only the behavior of the measure on arbitrarily small scales that matters. This is because if $L \geq L_N$, then $\mu(I)/L^{\lambda_N} \leq 1/L_N^{\lambda_N} \lesssim_N 1$, so $\mu(I) \lesssim_N L^{\lambda_N}$ holds automatically for all sufficiently large intervals. Thus all problems with the Hausdorff dimension argument are complete, and we have proven that there is a choice of parameters which constructs a set $X$ with Hausdorff dimension no less than $(nd - \alpha)/(n-1)$. By looking at the way we dissect our intervals at each scale, it is easy to see that $X$ cannot have dimension any higher than this quantity, so it has {\it precisely} this dimension.

\section{Low Rank Projection Method}

We now introduce a method which enables us to find a higher dimensional subset $X$, under some `low rank' assumptions about the set $Z$. The theorem below should be compared to Theorem 3. We will substitute the theorem below in the construction of our solutions to the fractal avoidance problem to improve the Hausdorff dimension.

\begin{theorem}
	Let $\mathcal{I}_1, \dots, \mathcal{I}_n$ be disjoint collections of cubes in $\mathcal{B}(1/N,d)$, with $|\mathcal{I}_i| \gtrsim N^d$. If there is a linear transformation $T: \mathbf{R}^{nd} \to \mathbf{R}^{nk}$ with rational coefficients such that the Minkowski dimension of $T(Z)$ is bounded above by $\alpha$, and $\beta$ is a rational parameter such that $\beta > d(k-1)/(dk - \alpha - k)$, then for arbitrarily large $N$ such that $N^\beta$ is an integer, there exists collections of cubes $\mathcal{J}_1, \dots, \mathcal{J}_n \in \mathcal{B}(1/N^\beta,d)$ with each cube in $\mathcal{J}_1 \times \dots \times \mathcal{J}_n \subset \mathcal{B}(1/N^\beta,nd)$ disjoint from $Y$, and as $N \to \infty$, each $\mathcal{J}_i$ contains cubes in all but a fraction $o(1)$ of cubes in $\mathcal{I}_i$.
\end{theorem}
\begin{proof}
	Write $T(x) = T_1(x_1) + T_2(x_2)$, where $x_1$ is a subset of $kd$ coordinates of $x$, and $x_2$ are the remaining $(n-k)d$ coordinates. Let $\mathcal{J}_{k+1}, \dots, \mathcal{J}_n \subset \mathcal{B}(1/N^\beta,d)$ be the set of cubes contained in a cube in $\mathcal{I}_{k+1}, \dots, \mathcal{I}_n$ and also containing a point in the lattice $(\mathbf{Z}/N)^d$. We then consider the set $\mathcal{K}$ of cubes in $\mathcal{B}(1/N^\beta,kd)$ intersecting the image of some cube in $T_2(\mathcal{J}_{k+1}, \dots, \mathcal{J}_n)$. This is in some sense a $1/N^\beta$ thickening of a lattice with dimension at most $kd$, and so $|\mathcal{K}| \lesssim O(N^{dk})$. If we let
	%
	\[ \mathcal{Z} = \{ I \in \mathcal{B}(1/N^\beta,kd): \text{there is}\ J \in \mathcal{K}\ \text{s.t.}\ I + J \in T(Z) \} \]
	%
	and we form a graph $G$ on the side length $1/N^\beta$ cubes in $\mathcal{J}_1, \dots, \mathcal{J}_k$ where there is an edge between $I_1, \dots, I_k$ if their Cartesian product lies in $\mathcal{Z}$, then an independent set $\mathcal{J}_1, \dots, \mathcal{J}_k$ gives a candidate solution $\mathcal{J}_1, \dots, \mathcal{J}_n$ for the entire theorem. Since $T(Z)$ intersects $O(N^{\alpha \beta})$ cubes in $\mathcal{B}(1/N^\beta,dk)$, and $|\mathcal{K}| \lesssim N^{dk}$, $\mathcal{Z}$ contains $O(N^{dk + \alpha \beta})$ cubes. Then $G$ has $\Omega(N^{d \beta})$ vertices, $O(N^{dk + \alpha \beta})$ edges, and if we consider the coloring as in the previous problem, a $N^{d(\beta - 1)}$ uniform coloring. Thus when applying the discrete corollary, we have $a = d \beta$, $b = dk + \alpha \beta$, and $c = d(\beta - 1)$. The inequality
	%
	\[ \beta > d \cdot \frac{2k - 1}{dk - \alpha} \]
	%
	is equivalent to the equality $b < a + c(k-1)$, which allows us to use the corollary to obtain the required result.
\end{proof}

Following our proof constructing $X$, as well as proving it's Hausdorff dimension, but using the lemma above instead of the standard lemma, and replacing the $\beta$ in this proof with the $\beta$ in the lemma above, we obtain $X$ with Hausdorff dimension
%
\[ \frac{dk - \alpha}{2k - 1} \]
%
The fact that the dimension is independent of $n$ has some interesting consequences. In particular, it can be used to solve problems involving infinitely many variables.

\begin{example}
	Consider $Z = \{ (x,y): \mathbf{R}^{m+1}: y = f(Sx) \}$, where $S: \mathbf{R}^m \to \mathbf{R}^l$. If we consider the map $T(x,y) = (Sx,y)$, then $T(Z) = \{ (a,b) \in \mathbf{R}^{l+1}: b = f(a) \}$. This is a hypersurface of dimension $l$. Applying the result above with $k = l+1$, $d = 1$, and $\alpha = l$, we find a set $X$ with Hausdorff dimension $1/(2l + 1)$. This isn't exactly what we want, so maybe the proof can be fine tuned.
\end{example}

%\begin{theorem}
%	Let $Z$ be a zero set, and let $f: \mathbf{R}^{nd} \to \mathbf{R}^{kd}$ be a polynomial map with degree at most $m$ such that $f(Z)$ is $\alpha$ dimensional. Then can we improve our result?
%\end{theorem}

\section{Comparison with Other Generic Avoidance Schemes}

\section{Concluding Remarks}

\begin{thebibliography}{9}

\bibitem{KeletiDimOneSet}
Tam\'{a}s Keleti
\textit{A 1-Dimensional Subset of the Reals that Intersects Each of its Translates in at Most a Single Point}

\bibitem{MalabikaRob}
Robert Fraser, Malabika Pramanik
\textit{Large Sets Avoiding Patterns}

\bibitem{Mathe}
A. Ma\'{t}h\'{e}
\textit{Sets of Large Dimension Not Containing Polynomial Configurations}

\bibitem{BaloghMorrisSamotij}
J\'{o}zsef Balogh, Robert Morris, Wojceich Samotij
\textit{Independent Sets in Hypergraphs}

\bibitem{David}
Guy David
\textit{Bounded singular integrals on a Cantor set}

\bibitem{Vasilis}
Vasilis Chousionis
\textit{Singular Integrals On Sierpinski Gaskets}

\bibitem{Bennett}
Michael Bennett, Alex Iosevich, Krystal Taylor
\textit{Finite Chains Inside Thin Subsets of $\mathbf{R}^d$}

\end{thebibliography}

\end{multicols}

\end{document}