\input{../style.tex}

\title{Functional Analysis}
\author{Jacob Denson}

\begin{document}

\pagenumbering{gobble}
\maketitle
\tableofcontents
\pagenumbering{arabic}

\chapter{Introduction}

Functional analysis is the interlace of algebra and analysis, in which we study algebraic structures endowed with topological properties. The utility of this approach is established by the rapid growth of applications over the past century, be it in quantum mechanics, statistics, or Computing science. Most of the time, a mathematician is not concerned with a single object, like a function, a random variable, or a measure, but instead considers large classes of these objects. One technique for handling these objects is to add algebraic structure which elaborates on the natural relation between these objects, and functional analysis provides the tools for handling this augmentation. Let's consider some examples of how this approach is used.

\begin{example}
    We rarely analyze a measurable function $f$ in isolation. Instead, we prove theorems about a class of measurable functions defined on the same measurable space. If $f$ and $g$ are measurable, then we may consider their addition $f + g$, their multiplication $fg$, and scaling $\lambda f$ (for $\lambda \in \mathbf{R}$), which are all measurable. Thus the space of measurable functions on a set has some predefined algebraic structure. Similarily, we may consider $C[0,1]$, the space of all continuous, real-valued functions defined on the unit interval in the same way.
\end{example}

The main reason why the subject is called functional analysis is because most of the time we shall be analyzing functions from one space to another, which naturally have an additive and multiplicative structure obtained from the space these functions are defined on.

\begin{definition}
    A {\bf topological vector space} is a vector space over a field (here assumed to be $\mathbf{R}$ or $\mathbf{C}$), endowed with  topology which makes the operations of addition and multiplication continuous.
\end{definition}

Some immediate corollaries of the definition include that

\begin{prop}
    The translation $U + v$ of any open set $U$ by a vector $v$ is open.
\end{prop}
\begin{prop}
    When $v_\alpha \to v$, $w_\alpha \to w$, and $\lambda_\alpha \to \lambda$, $\lambda_\alpha (v_\alpha + w_\alpha) = \lambda ( v + w)$.
\end{prop}
\begin{prop}
    A translated local base at the origin by a vector $v$ is a local base at $v$.
\end{prop}
%
Proposition (1.2) and (1.3) give different characterizations of topological vector spaces. We can define topological vector spaces either in terms of neighbourhood bases at the origin, or in terms of convergent nets obeying the rule denoted in (1.2). A neighbourhood containing the origin will be hereafter known as a {\bf 0-neighbourhood}.
%
\begin{lemma}
    Every 0-neighbourhood $U$ contains a 0-neighbourhood $W$ for which $W + W \subset U$.
\end{lemma}
\begin{proof}
    Since addition is continuous, and $U$ is a 0-neighbourhood, there are neighbourhoods $W$ and $V$ for which $W + V \subset U$. Our problem is solved by picking $W \cap V$ as our neighbourhood.
\end{proof}

\begin{definition}
    A set $B$ is {\bf balanced} if $\lambda B \subset B$ for $|\lambda| < 1$.
\end{definition}

\begin{lemma}
    Every 0-neighbourhood can be shrunk to a balanced neighbourhood.
\end{lemma}
\begin{proof}
    Let $U$ be a neighbourhood of zero. Then there is a scalar neighbourhood $\Lambda$ of zero, and a neighbourhood $V$ of any vector $V$, for which $\Lambda V \subset U$. We may choose $\Lambda$ so it is balanced, and then $\Lambda V$ is balanced.
\end{proof}

\begin{prop}
    If $K$ and $C$ are disjoint subsets of a T1 vector space $V$, where $K$ is compact and $C$ is closed, then 0 has a neighbourhood $V$ such that $K + V$ and $C + V$ are disjoint.
\end{prop}
\begin{proof}
    Fix some point $k \in K$. It suffices to show that there is a neighbourhood $U_k$ for which $k + U_k$ is disjoint from $C + U_k$. If this is true, (1.4) tells us we may pick a subset $W_k$ of $U_k$ for which $W_k + W_k \subset U_k$. Then we may choose a finite subcover $k_1 + W_{k_1}, \dots, k_n + W_{k_n}$ of $K$. If we let $V = \bigcap_{i = 1}^n W_{k_i}$, then we find $K + V$ is disjoint from $C + V$.

    To find this neighbourhood of $k$, we know that we may first pick a neighbourhood $U$ containing $C$, disjoint from $k$. Without loss of generality, by translation, we may assume $U$ is a neighbourhood of 0. Then we may choose $W$ for which $W + W \subset U$ and $-W = W$. It then follows that $k + W$ is disjoint from $W + C$, since if $k + w = w' + c$, $k + w - w' = c$, the left side is contained within $U$.
\end{proof}

\begin{corollary}
    A T1 vector space is Hausdorff.
\end{corollary}

\begin{corollary}
    Every set in a neighbourhood base contains the closure of another neighbourhood.
\end{corollary}
\begin{proof}
    Let 
\end{proof}

\begin{corollary}
    The closure of a set $A$ is the intersection of all $A + V$, where $V$ is a 0-neighbourhood.
\end{corollary}
\begin{proof}

\end{proof}

\begin{prop}
    A locally bounded space is first-countable.
\end{prop}
\begin{proof}
    
\end{proof}

\begin{definition}
Vector spaces should be familiar, but we specify some basic properties which may have been missed in a basic course.
\begin{enumerate}
    \item A set $C$ is {\bf convex} if $tC + (1 - t)C \subset C$ for any $t \in [0,1]$.
    \item A set $B$ is {\bf balanced} if $\lambda B \subset B$ for $| \lambda | \leq 1$.
    \item a set $B$ is {\bf (Von-Neumann) bounded} if, for any neighbourhood $E$ of 0, there is a scalar $\lambda > 0$ such that $B \subset \gamma E$ for every $\gamma > \lambda$.
\end{enumerate}
\end{definition}

\begin{definition}
    There are many additional properties one can ascribe to a topological vector space.
    %
    \begin{enumerate}
        \item A topological vector space is {\bf locally convex} if there is a neighbourhood base of convex sets.
        \item A space is {\bf locally bounded} if there a neighbourhood base of bounded sets.
        \item An {\bf $\mathbf{F}$-space} is a vector space endowed with a complete, invariant metric ($d(v + u, w + u) = d(v,w)$ for any vectors $v,w,u$).
        \item A {\bf Fr\'{e}chet} space is a locally convex $F$-space.
        \item A {\bf normed space} is a vector space endowed with a norm function $\| \cdotp \|: V \to \mathbf{R}+$, such that
        %
        \begin{itemize}
            \item $\| v \| = 0$ if and only if $v = 0$.
            \item $\| v + w \| \leq \| v \| + \| w \|$.
            \item $\| \lambda v \| = | \lambda | \| v \|$.
        \end{itemize}
        %
        We can consider a norm space as an $F$-space by defining a distance function $d(v,w) = \| v - w \|$.
        \item A {\bf Banach space} is a complete normed space.
        \item A space is {\bf normable} if its topology can be induced by a norm.
        \item A space is {\bf Heine-Borel} if every closed-bounded set is compact.
    \end{enumerate}
\end{definition}

\begin{theorem}
    Every locally bounded space is first countable.
\end{theorem}
\begin{proof}
    
\end{proof}

We will be studying a specific subclass of topological vector space.

\begin{definition}
    A norm space is a vector space $V$ endowed with a norm function $\| \cdotp \|: \mathbf{R} \to \mathbf{R}^+$, such that
    %
    \begin{enumerate}
        \item $\| v \| = 0$ if and only if $v = 0$.
        \item $\| \lambda v \| = | \lambda | \| v \|$.
        \item $\| v + w \| \leq \| v \| + \| w \|$.
    \end{enumerate}
    %
    We obtain a distance function on a norm space by defining $d(v,w) = \| v - w \|$.
\end{definition}

\section{Convexity}

A function $f:(a,b) \to \mathbf{R}$ is convex when the line segment between $(a,f(a))$ and $(b,f(b))$ lies above the graph of $f$. The line segment connecting these two points is described by
%
\[ \{ (\lambda a + (1 - \lambda) b, \lambda f(a) + (1 - \lambda) f(b)) : 0 \leq \lambda \leq 1 \} \]
%
and we require that $(\lambda a + (1 - \lambda)b, f(\lambda a + (1 - \lambda)b)$ lies below the corresponding point on the line defined above. This is satisfied exactly when we have a certain inequality:

\begin{definition}
    A function $f:U \to \mathbf{R}$ is {\bf convex} on $(a,b)$ if, for any $a \leq x < y \leq b$, and $0 \leq \lambda \leq 1$, we have
    %
    \begin{equation} \label{convex1} f(\lambda x + (1 - \lambda) y) \leq \lambda f(x) + (1 - \lambda) f(y) \end{equation}
    %
    By rewording the definition, convexity is also satisfied when, for $a \leq x < y < z \leq b$,
    %
    \begin{equation} \label{convex2} \frac{f(y) - f(x)}{y - x} \leq \frac{f(z) - f(y)}{z - y} \end{equation}
    %
    Geometrically, this equation says that the slope of the tangent line from $(x, f(x))$ to $(y, f(y))$ is smaller than the tangent line from $(y, f(y))$ to $(z, f(z))$.
\end{definition}

\begin{lemma}
    A $C^1$ convex function's derivative is non-decreasing on $(a,b)$.
\end{lemma}
\begin{proof}
    Suppose $f$ is a $C^1$ function, and $f'$ is non-decreasing, then consider any $a \leq x < y < z \leq b$. Then $f'(x) \leq f'(y) \leq f'(z)$. Applying the mean value theorem, we conclude there is $t \in (x,y)$, and $u \in (y,z)$, for which
    %
    \begin{equation} \label{convexderivative} f'(t) = \frac{f(y) - f(x)}{y - x}\ \ \ \ \ f'(u) = \frac{f(z) - f(y)}{z - y} \end{equation}
    %
    And since $t < u$, (\ref{convexderivative}) implies $f'(t) \leq f'(u)$, i.e. (\ref{convex2}) is satisfied.

    If $f$ is $C^1$ and convex, then surely $f'$ is non-decreasing. Fix $a \leq x < y \leq b$. In (\ref{convex2})), letting $y$ converge to $x$, we obtain
    %
    \begin{equation} \label{yconvergeleft} f'(x) = \lim_{y \to x^+} \frac{f(y) - f(x)}{y - x} \leq \lim_{y \to x} \frac{f(z) - f(y)}{z - y} = \frac{f(z) - f(x)}{z - x} \end{equation}
    %
    Conversely, letting $y \to z$, we obtain
    %
    \begin{equation} \label{yconvergeright} f'(y) = \lim_{y \to z^-} \frac{f(z) - f(y)}{z - y} \geq \lim_{y \to z} \frac{f(y) - f(x)}{y - x} = \frac{f(z) - f(x)}{z - x} \end{equation}
    %
    And in tandem, (\ref{yconvergeleft}), (\ref{yconvergeright}) and (\ref{convex2}) imply that $f'(x) \leq f'(y)$.
\end{proof}

\begin{example}
    $\exp: \mathbf{R} \to \mathbf{R}$ is convex on $(-\infty, \infty)$, since $\exp'' = \exp > 0$.
\end{example}

\begin{lemma}
    A function is continuous on the open segments where it is convex.
\end{lemma}

The most important inequality in analysis is the triangle inequality, undershadowed by the Schwarz inequality. Almost as important is Jensen's inequality. Despite its importance, the proof is fairly simple and intuitive. Consider the center of mass of an object.  

\begin{theorem}[Jensen's Inequality]
    Let $(\Omega, \mathbf{P})$ be a probability space. If $X \in L^1(\mathbf{P})$, where $a < X< b$, and if $f$ is a real function, convex on $(a,b)$, then
    %
    \begin{equation} \label{jensen} f(\mathbf{E}[X]) \leq \mathbf{E}[f \circ X] \end{equation}
\end{theorem}
\begin{proof}
    Since $a < X < b$, $a < \mathbf{E}[X] < b$. Let
    %
    \[ \beta = \sup_{a < x < \mathbf{E}[X]} \frac{g(\mathbf{E}[X]) - g(x)}{\mathbf{E}[X] - x} \]
    %
    For any $a < x < y$, $g(x) + \beta(\mathbf{E}[X] - x) \geq g(y)$. But also, by the right side of $(\ref{convex2})$, for any $z > y$, $g(z) - \beta(z - \mathbf{E}[X]) \geq g(\mathbf{E}[X])$. For any $\omega \in \Omega$, we may restate these equations as as
    %
    \[ g(f(\omega)) - \beta(f(\omega) - y) \geq g(y) \]
    %
    But then taking expectations, we obtain (\ref{jensen}).
\end{proof}

Jensen's inequality is incredibly useful. To see this, consider some examples.

\begin{example}
    We have seen the exponential function is convex. Hence for any $L_1(\mathbf{P})$, where $\mathbf{P}$ is a probability measure, we have
    %
    \begin{equation} \label{harmonic} exp\left(\int f d\mathbf{P} \right) \leq \int e^f d\mathbf{P} \end{equation}
    %
    Let $\mathbf{P}$ be the uniform measure over a finite set $\{ x_1, x_2, \dots, x_n \}$. Then (\ref{harmonic})) tells us that
    %
    \[ e^{f(x_1)/n}e^{f(x_2)/n} \dots e^{f(x_n)/n} \leq \frac{\sum e^{f(x_i)}}{n} \]
    %
    If we let $x_i$ be real numbers, and $f(x_i) = \log(x_i)$, we conclude
    %
    \[ (x_1x_2 \dots x_n)^{1/n} \leq \frac{\sum x_i}{n} \]
    %
    In other words, the geometric mean is always smaller than the arithmetic mean.
\end{example}

Jensen's inequality implies so many other inequalities in analysis.

\begin{definition}
    Let $1 \leq p \leq \infty$. We say $1 \leq q \leq \infty$ is the {\bf conjugate} of $p$ if $p^{-1} + q^{-1} = 1$, and write $q = p'$.
\end{definition}

\begin{theorem}[H\"{o}lder]
    If $p' = q$, $(\Omega,\mu)$ is a measure space, and $f,g$ are positive measurable functions on $\Omega$, then
    %
    \begin{equation} \label{holder} \| fg \|_1 \leq \| f \|_p \| g \|_q \end{equation}
\end{theorem}
\begin{proof}
    Let $A,B$ be the values on the right hand side of (\ref{holder})). If $A = 0$, then $f = 0$ almost everywhere, so that the theorem is trivial. Symmetry shows that the same is true if $B = 0$, so assume $A, B \neq 0$. Define $F = f/A$, and $G = g/B$. Then
    %
    \[ \left( \int F^p d\mu \right)^{1/p} = A^{-1} \left( \int f^p d\mu \right)^{1/p} = 1\ \ \ \ \ \left( \int G^q d\mu \right)^{1/q} = B^{-1} \left( \int g^q d\mu \right)^{1/q} = 1 \]
    %
    For any $x$, there is a number $s$ such that $e^{s/p} = F(x)$, and $t$ such that $e^{t/q} = G(x)$. By the convexity of the exponential function, $e^{s/p + t/q} \leq e^s p^{-1} + e^t q^{-1}$. Thus $FG \leq p^{-1} F^p + q^{-1} G^q$, and thus by integrating,
    %
    \[ \int FG\ d\mu \leq p^{-1} + q^{-1} = 1 \]
\end{proof}

\begin{corollary}[Minkowski]
    For
    \[ \| f + g \|_p \leq \| f \|_p + \| g \|_p \]
\end{corollary}



\chapter{Hilbert Spaces}

A Hilbert space is a Banach space most similar to Euclidean space. They have an incredibly structure, and occur in wide applications of functional analysis to mathematics, physics, and computing science.

\begin{definition}
    A {\bf Hilbert space} is a complete inner product space -- That is, a vector space equiped with an inner (hermitian) product such that the corresponding metric structure is complete.
\end{definition}

In this chapter, we shall let $H$ denote a general Hilbert space, and $\langle \cdot, \cdot \rangle$ the inner product space with which the space is equipped.

\begin{theorem}[Cauchy-Schwarz inequality]
    $\langle x, y \rangle \leq \| x \| \| y \|$.
\end{theorem}

\end{document}