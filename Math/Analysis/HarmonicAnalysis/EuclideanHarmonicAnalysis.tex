%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = HarmonicAnalysis.tex

\part{Euclidean Harmonic Analysis}

Here, we try and describe the more modern approaches to real-variable harmonic analysis, as developed by the \emph{Calderon-Zygmund school} of analysis as developed in the 1970s. Almost all of the problems we consider are to do with bounding operators on function spaces. Given some function $f$ lying in a space $V$, we have an associated function $Tf$ lying in some space $W$. The main goal of the techniques in this part of the book attempt to understand how quantitative control on certain properties of $f$ imply quantitative control on properties of $Tf$. In particular, given some quantity $A(f)$ associated with each $f \in V$, and a quantity $B(g)$ defined for all $g \in W$. Our goal is to understand whether a general bound $B(Tf) \lesssim A(f)$ is possible for all functions $f \in V$, i.e. whether these exists a universal constant $C > 0$ such that $B(Tf) \leq C \cdot A(f)$ for all $f \in V$.

A core technique we employ here is the method of \emph{decomposition}. We write $f = \sum_k f_k$, where the function $f_k$ have particular properties, perhaps being concentrated in a particular region of space, or having a Fourier transform concentrated in a particular region. These concentration properties often simplify analysis, enabling us to obtain bounds $B(Tf_k) \lesssim A(f_k)$ for each $n$. Provided that the operator $T$, and the quantities $A$ and $B$ are `stable under addition', we can then obtain the bound $B(Tf) \leq A(f)$ by `summing' up the related quantities. The stability of $A$ and $B$ is often obtained by assuming these quantities are \emph{norms} on their respective function spaces, i.e. that there exists norms $\| \cdot \|_V$ and $\| \cdot \|_W$ such that $A(f) = \| f \|_V$ for each $f \in V$ and $B(g) = \| g \|_W$ for each $g \in W$. The stability of $T$ under addition is obtained by assuming linearity, or at least sub-linearity, in the sense that for each $f_1, f_2 \in V$,
%
\[ \| T(f_1 + f_2) \|_W \leq \| T f_1 \|_W + \| Tf_2 \|_W. \]
%
We can then use the triangle inequality to conclude that
%
\[ \| Tf \|_W \leq \sum_k \| Tf_k \|_W \lesssim \sum_k \| f_k \|_V. \]
%
Thus if $\sum_k \| f_k \|_V \lesssim \| f \|_V$, our argument is complete. This will be true, for instance, if there exists $\varepsilon > 0$ such that $\| f_k \|_V \lesssim 2^{- \varepsilon k} \| f \|_V$. This can often be obtained if we employ a \emph{dyadic decomposition technique}. For such decompositions, it is also possible to generalize are technique not only to norms, but also to \emph{quasinorms}, i.e. maps $\| \cdot \|$ which are homogeneous and satisfy a \emph{quasi-triangle inequality} $\| v + w \| \lesssim \| v \| + \| w \|$.

\begin{lemma}
    Suppose $\| \cdot \|_V$ is a quasi-norm on a vector space $V$, and under the topology induced by $\| \cdot \|_V$, we can write $f = \sum_{k = 1}^\infty f_k$, where there is $\varepsilon > 0$ and $C > 0$ such that for each $n$, $\| f_k \| \leq C \cdot 2^{-\varepsilon k}$. Then $\| f \| \lesssim_\varepsilon C$.
\end{lemma}

\begin{remark}
	Thus if $T$ is sublinear and we have $\| Tf_k \|_W \lesssim \| f_k \|_V$ and $\| f_k \|_V \lesssim 2^{- \varepsilon k} \| f \|_V$, we conclude $\| Tf_k \|_W \lesssim 2^{-\varepsilon k} \| f \|_V$, and then by sublinearity and the lemma applied to $\| \cdot \|_W$, we conclude
	%
	\[ \| Tf \|_W \leq \| \sum_k Tf_k \|_W \lesssim_\varepsilon \| f \|_V. \]
	%
	A slight modification of the proof below even gives this claim provided $T$ is \emph{quasi sublinear}, in the sense that for all $f_1, f_2 \in V$, $\| T(f_1 + f_2) \|_W \lesssim \| Tf_1 \|_V + \| Tf_2 \|_V$ for all $f_1, f_2 \in V$. However, such operators occur so rarely in practice that it isn't worth concentrating on them.
\end{remark}

\begin{proof}
	Pick $A > 0$ such that $\| f_1 + f_2 \|_V \leq A \cdot (\| f_1 \|_V + \| f_2 \|_V)$ for all $f_1$ and $f_2$. If $A < 2^{\varepsilon}$, we can write apply the quasitriangle inequality iteratively to conclude
    %
    \begin{align*}
        \| f \| &\leq C \cdot \sum_{k = 1}^\infty A^k \| f_k \|_V \leq C \cdot \left( \sum_{k = 1}^\infty (A 2^{-\varepsilon})^k \right) \leq C \cdot \left( \frac{1}{1 - A 2^{-\varepsilon}} \right) \lesssim_\varepsilon C.
    \end{align*}
    %
    In general, fix $N$, and write $f = f^1 + \dots + f^N$, where $f^m = \sum_{k = 0}^\infty f_{m + Nk}$. Then $\| f_{m + Nk} \|_V \leq C \cdot 2^{- N \varepsilon k}$, and if $N$ is chosen large enough that $A < 2^{N \varepsilon}$, we can apply the previous case to conclude that $\| f^m \|_V \lesssim_\varepsilon C$. Then we can apply the quasi-triangle inequality to conclude that $\| f \| \lesssim_\varepsilon C$.
\end{proof}

We can even apply the method of decomposition in the presence of suitably large polynomial decay.

\begin{lemma}
    Suppose $\| \cdot \|_V$ is a quasinorm on a function space $V$. Then there exists $t$ such that for all $s > t$, if $f = \sum_{k = 1}^\infty f_k$, and if $\| f_k \|_V \leq C \cdot k^{-s}$, for $s > t$, then $\| f \|_V \lesssim_s C$.
\end{lemma}
\begin{proof}
    As in the previous lemma, pick $A > 0$ such that $\| f_1 + f_2 \|_V \leq A (\| f_1 \|_V + \| f_2 \|_V)$ for all $f_1,f_2 \in V$. We perform a decomposition of dyadic type, writing $f = \sum_{m = 0}^\infty f^m$, where
    %
    \[ f^m = \sum_{k = 2^m}^{2^{m+1} - 1} f_k. \]
    %
    By splitting up the sum into a binary tree, we can ensure that
    %
    \[ \| f^m \|_V \lesssim A^{m+1} \sum_{k = 2^m}^{2^{m+1} - 1} \| f_k \|_V \leq C \cdot A^{m+1} \sum_{k = 2^m}^{2^{m+1} - 1} k^{-s} \lesssim C (A 2^{1-s})^m. \]
    %
    If $s > 1 + \lg(A)$, we can thus apply the previous lemma to conclude that $\| f \|_V \lesssim C$.
\end{proof}

In this part of the notes, we define the various classes of quasi-norms we will study, describe the general methods which make up the Calderon-Zygmund theory, and find applications to geometric measure theory, complex analysis, partial differential equations, and analytic number theory.





\chapter{Monotone Rearrangement Invariant Norms}

In this chapter, we discuss common families of \emph{monotone, rearrangement invariant quasinorms} that occur in harmonic analysis. The general framework is as follows. For each function $f$, we associate it's \emph{distribution function} $F: [0,\infty) \to [0,\infty]$ given by $F(t) = |\{ x : |f(x)| > t \}|$. A \emph{rearrangement invariant space} is a subspace $V$ of the collection of measurable complex-valued functions on some measure space $X$, equipped with a quasi-norm $\| \cdot \|$, satisfying the following two properties:
%
\begin{itemize}
    \item \emph{Monotonicity}: If $|f(x)| \leq |g(x)|$ for all $x \in X$, then $\| f \| \leq \| g \|$.

    \item \emph{Rearrangement-Invariance}: If $f$ and $g$ have the same distribution function, then $\| f \| = \| g \|$.
\end{itemize}
%
A monotone rearrangement-invariant norm essentially provides a way of quantifying the height and width of functions on $X$. It has no interest in the `shape' of the objects studied, because of the property of rearrangement invariance. In a particular problem, one picks the norm best emphasizing a particular family of features useful in the problem.

There are two very useful classes of functions useful for testing the behaviour of translation invariant norms:
%
\begin{itemize}
    \item The \emph{indicator functions} $\mathbf{I}_E(x) = \mathbf{I}(x \in E)$, for a measurable set $E$.
    \item The \emph{simple functions} $f = \sum_{i = 1}^n a_i \mathbf{I}_{E_i}$, for disjoint sets $E_i$.
\end{itemize}
%
The class of all simple functions forms a vector space, and for almost all the monotone rearrangement invariant norm we consider in this section, this vector space will form a dense subspace of the class of all functions. This means that when we want to study how an operator transforms the height and width of functions, the behaviour of the operator on simple functions often reflects the behaviour of an arbitrary function.

\section{The $L^p$ norms}

For $p \in (0,\infty)$, we define the $L^p$ norm on measurable function on a measure space $X$ by
%
\[ \| f \|_p = \left( \int |f(x)|^p\; dx \right)^{1/p}. \]
%
For $p = \infty$, we define
%
\[ \| f \|_\infty = \min \left\{ t \geq 0: |f(x)| \leq t\ \text{almost surely} \right\}. \]
%
These are the most fundamental monotone, rearrangement invariant norms. The space of functions $f$ with $\| f \|_p < \infty$ is denoted by $L^p(X)$. The most important spaces to consider here are the space $L^1(X)$, consisting of absolutely square integrable functions, $L^\infty(X)$, consisting of almost-everywhere bounded functions, and $L^2(X)$, consisting of square integrable functions. The main motivation for the introduction of the other $L^p$ spaces is that much of the quantitative theory for $p \in \{ 1, \infty \}$ is rather trivial, in the sense that it is easy to see when certain operators are bounded on these spaces, or unbounded.

As $p$ increases, the $L^p$ norm of a particular function $f$ gives more control over the height of the function $f$, and weaker control on values where $f$ is particular small. At one extreme, $L^\infty(X)$ only has control over the height of a function, and no control over it's width. Conversely, one can think of $L^0(X)$ as being the space of functions with finite support, though no natural norm exists on this space of functions solely classifying width. After all, such a quantity couldn't be homogenous, since the width of $f$ and $\alpha f$ are the same for each $\alpha \neq 0$. Thus the space $L^0(X)$ isn't so interesting to us from a quantitative perspective.

\begin{example}
  If $f(x) = |x|^{-s}$ for $x \in \RR^d$ and $s > 0$, then integration by radial coordinates shows that
  %
  \[ \int_{\varepsilon \leq |x| \leq M} \frac{1}{|x|^{s p}}\; dx \approx \int_\varepsilon^M r^{d-1 - ps}\; dr = \frac{M^{d - p s} - \varepsilon^{d - p s}}{d - p s}. \]
  %
  This quantity remains finite as $\varepsilon \to 0$ if and only if $d > p s$, and finite as we let $M \to \infty$ if and only if $d < p s$. Thus if $p < d/s$, $f$ is \emph{locally} in $L^p$, in the sense that $f \in L^p(B)$ for every bounded $B \in \RR^d$. The class of functions for which this condition holds is denoted $L^p_{\text{loc}}(X)$. Conversely, if $p > d/s$, then for every domain $B$ separated from the origin, $f \in L^p(B)$. For $p = d/s$, the function $f$ fails to be $L^p(\RR^d)$, but only `by a logarithm', in the sense that
  %
  \[ \int_{\varepsilon \leq |x| \leq M} \frac{1}{|x|^{s p}}\; dx \approx \int_\varepsilon^M \frac{dr}{r} = \log(M/\varepsilon). \]
  %
  We will later find `weaker' versions of the $L^p$ norm, and $f$ will have finite version of these norms.
\end{example}

The last example shows that, roughly speaking, control on the $L^p$ norm of a function for large values of $p$ prevents the formation of higher order singularities, and control of the norm for small values of $p$ ensures that functions have large decay at infinity.

\begin{example}
  If $s = A \chi_E$, and we set $H = |A|$ and $W = |E|$, then $\| s \|_p = W^{1/p} H$. As $p \to \infty$, the value of $\| s \|_p$ depends more and more on $H$, and less on $W$, and in fact $\lim_{p \to \infty} \| s \|_p = H$. If $s = \sum A_n \chi_{E_n}$, and $|A_m|$ is the largest constant from all other values $A_n$, then as $p$ becomes large, $|A_m|^p$ overwhelms all other terms. We calculate that as $p \to \infty$,
  %
  \[ \| s \|_p = \left( \sum |E_n| |A_n|^p \right)^{1/p} = |A_m|^p (|E_m| + o(1))^{1/p} = |A_m| (1 + o(1)). \]
  %
  This implies $\| s \|_p \to |A_m|$ as $p \to \infty$. But as $p \to 0$, $\lim_{p \to 0} \| f \|_p$ does not in general exist, even for step functions with finite support. Nonetheless, we can conclude that $\lim_{p \to 0} \| s \|_p^p = \sum |E_n|$, which is the measure of the support of $s$.
\end{example}

As $p \to \infty$, the width of a function is disregarded completely by the $L^p$ norm, motivating the definition of \emph{the $L^\infty$ norm}; Given a measurable $f$, we define $\| f \|_\infty$ to be the smallest number such that $|f| \leq \| f \|_\infty$ almost surely. We then define $L^\infty(X)$ to be the space of measurable functions $f$ for which $\| f \|_\infty < \infty$. We have already shown $\| s \|_p \to \| s \|_\infty$ if $s$ is a simple function, and the density of such functions gives a general result.

\begin{theorem}
    Let $p \in (0,\infty)$. If $f \in L^p(X) \cap L^\infty(X)$, then
    %
    \[ \lim_{t \to \infty} \| f \|_t = \| f \|_\infty. \]
\end{theorem}
\begin{proof}
    Without loss of generality, assume $p \geq 1$. Consider the norm $\| \cdot \|$ on $L^p(X) \cap L^\infty(X)$ given by
    %
    \[ \| f \| = \| f \|_p + \| f \|_\infty. \]
    %
    Then $L^p(X) \cap L^\infty(X)$ is complete with respect to this metric. For each $t \in [p,\infty)$, define $T_t(f) = \| f \|_t$. Then the functions $\{ T_t \}$ are uniformly bounded in the norm $\| \cdot \|$, since if $p = \theta t$, then
    %
    \[ |T_t(f)| = \| f \|_t \leq \| f \|_p^\theta \| f \|_\infty^{1-\theta} \leq \| f \|^\theta \| f \|^{1-\theta} = \| f \|. \]
    %
    For any $\varepsilon > 0$, we can find a step function $s$ with $\| s - f \|_p, \| s - f \|_\infty \leq \varepsilon$. This means that for all $t \in (p,\infty)$,$\| s - f \|_t \leq \varepsilon$. And so
    %
    \begin{align*}
        \Big| T_t(f) - \| f \|_\infty \Big| &\leq |T_t(f) - T_t(s)| + |T_t(s) - \| s \|_\infty| + |\| s \|_\infty - \| f \|_\infty| \leq 2\varepsilon + o(1). 
    \end{align*}
    %
    Taking $\varepsilon \to 0$ gives the result.
\end{proof}

Abusing notation, we define $\| f \|_0^0 = | \text{supp} f | = | \{ x: f(x) \neq 0 \} |$, and let $L^0(X)$ be the space of functions with finite support. We know that for any simple function $s$, $\| s \|_p^p \to \| s \|_0^0$ as $p \to 0$. If $f \in L^0(X) \cap L^p(X)$ for some $p \in (0,\infty)$, then the monotone and dominated convergence theorems implies that
%
\[ \| f \|_0^0 = \int \mathbf{I}(f(x) \neq 0) = \int \left( \lim_{t \to 0} |f(x)|^t \right)\; dx = \lim_{t \to 0} \int |f(x)|^t\; dx = \lim_{t \to 0} \| f \|_t^t. \]
%
Thus the space $L^0(X)$ lies at the opposite end of the spectrum to $L^\infty$.

The fact that $\| f \|_0^0$ is a norm taken to the `power of zero' implies that many nice norm properties of the $L^p$ spaces fail to hold for $L^0(X)$. For instance, homogeneity no longer holds; in fact, for each $\alpha \neq 0$,
%
\[ \| \alpha f \|_0^0 = \| f \|_0^0. \]
%
It does, however, satisfy the triangle inequality $\| f + g \|_0^0 \leq \| f \|_0^0 + \| g \|_0^0$, which follows from a union bound on the supports of the functions.

\begin{example}
  Let $p < q$, and suppose $f \in L^p(X) \cap L^q(X)$. For any $r \in (p,q)$, the $L^r$ norm emphasizes the height of $f$ less than the $L^q$ norm, and emphasizes the width of $f$ less than the $L^p$ norm. In particular, we find that for any $\lambda \geq 0$,
  %
  \begin{align*}
    \| f \|_r^r = \int_{\RR} |f(x)|^r\; dx &= \int_{|f(x)| \leq 1} |f(x)|^r\; dx + \int_{|f(x)| > 1} |f(x)|^r\; dx\\
    &\leq \int_{|f(x)| \leq 1} |f(x)|^p\; dx + \int_{|f(x)| > 1} |f(x)|^q\; dx\\
    &\leq \| f \|_p^p + \| f \|_q^q < \infty.
  \end{align*}
  %
  In particular, this shows $f \in L^r(X)$.
\end{example}

\begin{remark}
    The bound obtained in the last example can be improved by using scaling symmetries. For any $A > 0$,
    %
    \[ \| f \|_r^r = \frac{\| Af \|_r^r}{A^r} \leq \frac{\| Af \|_p^p + \| Af \|_q^q}{A^r} \leq \frac{A^p \| f \|_p^p + A^q \| f \|_q^q}{A^r}. \]
    %
    If $1/r = \theta/p + (1 - \theta)/q$, and we set $A = \| f \|_q^{q/(p-q)} / \| f \|_p^{p/(p-q)}$, then the above inequality implies $\| f \|_r \leq 2 \| f \|_p^\theta \| f \|_q^{1 - \theta}$, which is a homogenous equality. The constant 2 can be removed in the equation using the {\it tensor power trick}. If we consider the function on $X^n$ defined by $f^{\otimes n}(x_1, \dots, x_n) = f(x_1) \dots f(x_n)$, then $\| f^{\otimes n} \|_r = \| f \|_r^n$, and so
    %
    \[ \| f \|_r = \| f^{\otimes n} \|_r^{1/n} \leq \left( 2 \| f^{\otimes n} \|_p^\theta \| f^{\otimes n} \|_q^{1-\theta} \right)^{1/n} = 2^{1/n} \| f \|_p^\theta \| g \|_q^{1-\theta}. \]
    %
    We can then take $n \to \infty$ to conclude that $\| f \|_r \leq \| f \|_p^\theta \| f \|_q^{1-\theta}$.
\end{remark}

The argument in the last remark is an instance of \emph{real interpolation}; In order to conclude some fact about a function which lies `between' two other functions we know how to deal with, we split the function up into two parts lying in the other spaces, deal with them separately, and then put them back together to get some equality. One can then apply various symmetry considerations (homogeneity and the tensor power trick being two examples) to eliminate extraneous constants. We now also show how to prove this inequality using convexity, which illustrates another core technique. In the next theorem, $1/\infty = 0$.

\begin{theorem}[H\"{o}lder]
  If $0 < p,q \leq \infty$ and $1/p + 1/q = 1/r$, $\| f g \|_r \leq \| f \|_p \| g \|_q$.
\end{theorem}
\begin{proof}
  The case where $p$ or $q$ is $\infty$ is left as an exercise to the reader. In the other case, by moving around exponents, we may simplify to the case where $r = 1$. The theorem depends on the log convexity inequality, such that for $A,B \geq 0$ and $0 \leq \theta \leq 1$, $A^\theta B^{1 - \theta} \leq \theta A + (1 - \theta) B$. But since the logarithm is concave, we calculate
  %
  \[ \log(A^\theta B^{1 - \theta}) = \theta \log A + (1 - \theta) \log B \leq \log(\theta A + (1 - \theta) B), \]
  %
  and we can then exponentiate. To prove H\"{o}lder's inequality, by scaling $f$ and $g$, which is fine by homogeneity, we may assume that $\| f \|_p = \| g \|_q = 1$. Then we calculate
  %
  \begin{align*}
    \| f g \|_1 &= \int |f(x)| |g(x)| = \int |f(x)|^{p/p} |g(x)|^{q/q}\\
    &\leq \int \frac{|f(x)|^p}{p} + \frac{|g(x)|^q}{q} = \frac{1}{p} + \frac{1}{q} = 1 = \| f \|_p \| g \|_q.
  \end{align*}
  %
  If $p = \infty$, $q = 1$, then the inequality is trivial, since we have the pointwise inequality $|f(x) g(x)| \leq \| f \|_\infty |g(x)|$ almost everywhere, which we can then integrate.
\end{proof}

\begin{remark}
  Note that $A^\theta B^{1-\theta} \leq \theta A + (1 - \theta) B$ is an \emph{equality} if and only if $A = B$, or $\theta \in \{ 0, 1 \}$. In particular, following through the proof above shows that if $\| f \|_p = \| g \|_q = 1$, we must have $|f(x)|^{1/p} = |g(x)|^{1/q}$ almost everywhere. In general, this means H\"{o}lder's inequality is sharp if and only if $|f(x)|^{1/p}$ is a constant multiple of $|g(x)|^{1/q}$.
\end{remark}

The next inequality is known as the \emph{triangle inequality}.

\begin{corollary} \label{lptriangleinequality}
  Given $f$,$g$, and $p \geq 1$, $\| f + g \|_p \leq \| f \|_p + \| g \|_p$.
\end{corollary}
\begin{proof}
  The inequality when $p = 1$ is obtained by integrating the inequality $|f(x) + g(x)| \leq |f(x)| + |g(x)|$, and the case $p = \infty$ is equally trivial. When $1 < p < \infty$, by scaling we can assume that $\| f \|_p + \| g \|_p = 1$. Then we can apply H\"{o}lder's inequality combined with the $p = 1$ case to conclude
  %
  \begin{align*}
    \int |f(x) + g(x)|^p &\leq \int |f(x)| |f(x) + g(x)|^{p-1} + |g(x)| |f(x) + g(x)|^{p-1}\\
    &\leq \| f \|_p \| (f + g)^{p-1} \|_q + \| g \|_p \| (f + g)^{p-1} \|_q = \| f + g \|_{p}^{p-1}
  \end{align*}
  %
  Thus $\| f + g \|_p^p \leq \| f + g \|_p^{p-1}$, and simplifying gives $\| f + g \|_p \leq 1$.
\end{proof}

\begin{remark}
  Suppose $\| f + g \|_p = \| f \| + \| g \|_p$. Following through the proof given above shows that both applications of H\"{o}lder's inequality must be sharp. And this is true if and only if $|f(x)|^p$ and $|g(x)|^p$ are scalar multiples of $|f(x) + g(x)|^p$ almost everywhere. But this means $|f(x)|$ and $|g(x)|$ are scalar multiples of $|f(x) + g(x)|$. If $|f(x)| = A|f(x) + g(x)|$ and $|g(x)| = B|f(x) + g(x)|$. If $g \neq 0$, this implies there is $C$ such that $|f(x)| = C |g(x)|$ for some $C > 0$. Thus we can write $f(x) = C e^{i \theta(x)} g(x)$, and we must have
  %
  \[ \| f + g \|_p^p = \int |1 + C e^{i \theta(x)}|^p |g(x)|^p = (1 + C)^p \int |g(x)|^p \]
  %
  so $|1 + Ce^{i \theta(x)}| = |1 + C|$ almost everywhere but this can only be true if $e^{i \theta(x)} = 1$ almost everywhere, so $f = C g$. Thus the triangle inequality is only sharp is $f$ and $g$ are positive scalar multiples of one another.
\end{remark}

This discussion leads to a useful heuristic: Unless $f$ and $g$ are `aligned' in a certain way, the triangle inequality is rarely sharp. For instance, if $f$ and $g$ have disjoint support, we calculate that
%
\[ \| f + g \|_p = \left( \| f \|_p^p + \| g \|_p^p \right)^{1/p} \]
%
For $p > 1$, this is always sharper than the triangle inequality.

If $p < 1$, then the proof of Corollary \ref{lptriangleinequality} no longer works, and in fact, is no longer true. In fact, if $f$ and $g$ are non-negative functions, then we actually have the \emph{anti} triangle inequality
%
\[ \| f + g \|_p \geq \| f \|_p + \| g \|_p, \]
%
as proved in the next theorem.

\begin{theorem}
    If $p \geq 1$, then for any functions $f_1, \dots, f_N \geq 0$,
    %
    \begin{equation} \label{triangleInequality} ( \| f_1 \|_p^p + \dots + \| f_N \|_p^p )^{1/p} \leq \| f_1 + \dots + f_N \|_p \leq \| f_1 \|_p + \dots + \| f_N \|_p. \end{equation}
    %
    If $p \leq 1$, then the inequality reverses, i.e. for any positive functions $f_1, \dots, f_N$,
    %
    \begin{equation} \label{antiTriangleInequality} \| f_1 \|_p + \dots + \| f_N \|_p \leq \| f_1 + \dots + f_N \|_p \leq (\| f_1 \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \end{equation}
\end{theorem}
\begin{proof}
    The upper bound in \eqref{triangleInequality} is just obtained by applying the triangle inequality iteratively. To obtain the lower bound, we note that for $A_1, \dots, A_N \geq 0$,
    %
    \[ (A_1 + \dots + A_N)^p \geq A_1^p + \dots + A_N^p, \]
    %
    One can prove this from induction from the inequality $(A_1 + A_2)^p \geq A_1^p + A_2^p$, which holds when $A_2 = 0$, and the derivative of the left hand side is greater than the right hand side for all $A_2 \geq 0$. But then setting $A_k = f_k$ and then integrating gives
    %
    \[ \| f_1 + \dots + f_N \|_p^p \geq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \]
    %
    Now assume $0 < p < 1$. We begin by proving the lower bound in \ref{antiTriangleInequality}. We can assume $N = 2$, and $\| f_1 \|_p + \| f_2 \|_p = 1$, and then it suffices to show $\| f_1 + f_2 \|_p \geq 1$. For any $\theta \in (0,1)$, and $A,B \geq 0$, concavity implies
    %
    \[ (A + B)^p = (\theta (A/\theta) + (1 - \theta) (B/(1-\theta)))^p \geq \theta^{1-p} A^p + (1 - \theta)^{1-p} B^p. \]
    %
    Thus setting $A = f_1(x)$, $B = f_2(x)$, and $\theta = \| f_1 \|_p$, so that $1 - \theta = \| f_2 \|_p$, and then integrating, we find
    %
    \[ \| f_1 + f_2 \|_p^p \geq \theta + (1 - \theta) = 1. \]
    %
    On the other hand, the inequality $(A_1 + \dots + A_N)^p \leq A_1^p + \dots + A_N^p$, which holds for $A_1, \dots, A_N \geq 0$, can be applied with $f_k = A_k$ and integrated to yield
    %
    \[ \| f_1 + \dots + f_N \|_p^p \leq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \qedhere \]
\end{proof}

Thus the triangle inequality is not satisfied for the $L^p$ norms when $p < 1$. This is one of the deficiencies which leads the $L^p$ theories for $0 < p < 1$ to be rather deficient when compared to the case with $p \geq 1$. One way to fix this is to use the theory of Hardy spaces. We note that for $p < 1$, we do have a \emph{quasi} triangle inequality.

\begin{theorem} \label{quasitriangleinequalitylp}
    For $f_1, \dots, f_N \in L^p(X)$, with $0 < p < 1$,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \]
\end{theorem}
\begin{proof}
    By H\"{o}lder's inequality applied to sums,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq (\| f \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \qedhere \]
\end{proof}

This result is sharp, i.e. if we take a disjoint family of sets $\{ E_1, E_2, \dots \}$ with $|E_i| = 1$ for each $i$, and then set $f_i = \mathbf{I}_{E_i}$, then the inequality is sharp for each $N$.

\begin{remark}
    When $p < 1$, the space $L^p(X)$ is \emph{not} normable. To see why, we look at the topological features of $L^p(X)$. Fix $\varepsilon > 0$, and let $C$ be a convex set containing all functions $f$ with $\| f \|_p < \varepsilon$. Thus, in particular, $C$ contains all step functions $H \mathbf{I}_E$ where $H |E|^{1/p} < \varepsilon$. But if we now find a countable sequence of disjoint sets $\{ E_k \}$, each with positive measure, and for each $k$, define $H_k = (\varepsilon/2) |E_k|^{-1/p}$, then for any $N$, the function
    %
    \[ f_N = (H_1/N) \mathbf{I}_{E_1} + \dots + (H_N/N) \mathbf{I}_{E_N} \]
    %
    lies in $C$, and
    %
    \[ \| f_N \|_p = (1/N) (H_1^p |E_1| + \dots + H_N^p |E_N|)^{1/p} = (\varepsilon/2) N^{1/p - 1} \]
    %
    as $N \to \infty$, the $L^p$ norm of $f_N$ becomes unbounded. In particular, this means that we have proven that every bounded convex subset of $L^p(X)$ has empty interior, and a norm space certainly does not have this property.
\end{remark}

As we have mentioned, as $p \to \infty$, the $L^p$ norm excludes functions with large peaks, or large height, and as $p \to 0$, the $L^p$ norm excludes functions with large tails, or large width. They form a continuously changing family of functions as $p$ ranges over the positive numbers. In general, there is no inclusion of $L^p(X)$ in $L^q(X)$ for any $p,q$, except in two circumstances which occur often enough to be mentioned.

\begin{example}
  If $X$ is a finite measure space, and $0 < p \leq q \leq \infty$, $L^p(X) \subset L^q(X)$. H\"{o}lder's inequality implies $\| f \|_p = \| f \chi_X \|_p \leq \| f \|_q |X|^{1/p-1/q}$. Taking $q \to \infty$, we conclude $\| f \|_p \leq | X |^{1/p} \| f \|_\infty$. One can best remember the constants here by the formula
  %
  \[ \left( \fint |f(x)|^p \right)^{1/p} \leq \left( \fint |f(x)|^q \right)^{1/q}. \]
  %
  In particular, when $X$ is a probability space, the $L^p$ norms are increasing.
\end{example}

\begin{example}
  On the other hand, suppose the measure space is {\it granular}, in the sense that there is $\varepsilon > 0$ such that either $|E| = 0$ or $|E| \geq \varepsilon$ for any measurable set $E$. Then $L^q(X) \subset L^p(X)$ for $0 < p \leq q \leq \infty$. First we check the $q = \infty$ case, which follows by the trivial estimate
  %
  \[ \int |f(x)|^p \geq \varepsilon \| f \|_\infty, \]
  %
  so $\| f \|_\infty \leq \| f \|_p \varepsilon^{-1/p}$. But then applying log convexity, if $p \leq q < \infty$, we can write $1/q = \theta/p$ for $0 < \theta \leq 1$, and then log convexity shows
  %
  \[ \| f \|_q = \| f \|_p^\theta \| f \|_\infty^{1-\theta} \leq \varepsilon^{-(1 - \theta)/p} \| f \|_p = \varepsilon^{-1/p - 1/q} \| f \|_p. \]
  %
  If $\varepsilon = 1$, which occurs if $X = \ZZ$, then the $L^p$ norms are decreasing in $p$. This gives the best way to remember the constants involved, since the measure $\mu(E) = |E|/\varepsilon$ is one granular, and so
  %
  \[ \left( \frac{1}{\varepsilon} \int |f(x)|^q\; dx \right)^{1/q} \leq \left( \frac{1}{\varepsilon} \int |f(x)|^p\; dx \right)^{1/p}. \]
\end{example}

%\begin{example}
%  Controlling additional properties of the function offers similar properties as for control on the measure space. If $|f(x)| \leq M$ for almost all $x$, then for $p \leq q$,
  %
%  \[ \| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}. \]
  %
%  Conversely, if $|f(x)| \geq M$ whenever $f(x) \neq 0$, then
  %
%  \[ \| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}. \]
  %
  
%\end{example}

\begin{remark}
  We can often use such results in spaces which are not granular by coarsening the sigma algebra. For instance, the Lebesgue measure is $\varepsilon^d$ granular over the sigma algebra generated by the length $\varepsilon$ cubes whose corner's lie on the lattice $(\ZZ/\varepsilon)^d$, and if a function is measurable with respect to such a $\sigma$ algebra we call the function $\varepsilon$ granular.
\end{remark}

\begin{remark}
  If we let $X = \{ 1, \dots, N \}$, then $X$ is both finite and granular, so all $L^p$ norms are comparable. In particular, if $p \leq q$,
  %
  \[ \| f \|_q \leq \| f \|_p \leq N^{1/p - 1/q} \| f \|_q. \]
  %
  The left hand side of this inequality becomes sharp when $f$ is concentrated at a single point, i.e. $f(n) = \mathbf{I}(n = 1)$. On the other hand, the left hand side becomes sharp when $f$ is constant, i.e. $f(n) = 1$ for all $n$.
\end{remark}

\begin{example}
    We can obtain similar $L^p$ bounds by controlling the functions $f$ involved, rather than the measure space. For instance, if $|f(x)| \leq M$, and $p \leq q$, then then $\| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}$, which follows by log convexity. On the other hand, if $|f(x)| \geq M$ on the support of $f$, then $\| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}$.
\end{example}

\begin{theorem}
  If $p_\theta$ lies between $p_0$ and $p_1$, then
  %
  \[ L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X) \subset L^{p_0}(X) + L^{p_1}(X) \]
\end{theorem}
\begin{proof}
  If $\| f \|_{p_0}, \| f \|_{p_1} < \infty$, then for any $p_\theta$ between $p_0$ and $p_1$,
  %
  \[ \| f \chi_{|f| \leq 1} \|_{p_\theta}^{p_\theta} = \int_{|f| \leq 1} |f|^{p_\theta} \leq \int_{|f| \leq 1} |f|^{p_0} < \infty \]
  \[ \| f \chi_{|f| > 1} \|_{p_\theta}^{p_\theta} = \int_{|f| > 1} |f|^{p_\theta} \leq \int_{|f| > 1} |f|^{p_1} < \infty \]
  %
  Applying the triangle inequality, we conclude that $\| f \|_{p_\theta} < \infty$. In the case where $p_1 = \infty$, then $f \chi_{|f| > 1}$ is bounded, and must have finite support if $p_0 < \infty$, which shows this integral is bounded. Note the inequalities above show that we can split any function with finite $L^{p_\theta}$ norm into the sum of a function with finite $L^{p_0}$ norm and another with finite $L^{p_1}$ norm.
\end{proof}

\begin{remark}
  This theorem is important in the study of interpolation theory, because if we have two linear operators $T_{p_0}$ defined on $L^{p_0}(X)$ and $T_{p_1}$ on $L^{p_1}(X)$, and they agree on $L^{p_0}(X) \cap L^{p_1}(X)$, then there is a unique linear operator $T_{p_\theta}$ on $L^{p_\theta}(X)$ which agrees with these two functions, and we can consider the boundedness of such a function with respect to the $L^{p_\theta}$ norms.
\end{remark}

The last property of the $L^p$ norms we want to focus on is the principle of \emph{duality}. Given any values of $p$ and $q$ with $1/p + 1/q = 1$, H\"{o}lder's inequality implies that if $f \in L^p(X)$ and $g \in L^q(X)$, then $fg \in L^1(X)$. In particular, for each function $g \in L^q(X)$, the map
%
\[ \lambda: f \mapsto \int f(x)g(x)\; dx \]
%
is a linear functional on $L^p(X)$. H\"{o}lder's inequality implies that $\| \lambda \| \leq \| g \|_q$. But this is actually an \emph{equality}. In particular, if $1 < p < \infty$, one can show these are \emph{all} linear functionals. For $p \in \{ 1, \infty \}$, the dual space of $L^p(X)$ is more subtle. But, since in harmonic analysis we concentrate on quantitative bounds, the following theorem often suffices as a replacement.

\begin{theorem}
    If $1 \leq p < \infty$, and $f \in L^p(X)$, then
    %
    \[ \| f \|_p = \sup \left\{ \int f(x)g(x) : \| g \|_q = 1 \right\}. \]
    %
    If the underlying measure space is $\sigma$ finite, then this claim also holds for $p = \infty$.
\end{theorem}
\begin{proof}
    Suppose that $1 \leq p < \infty$. Given $f$, we define
    %
    \[ g(x) = \frac{1}{\| f \|_p^{p-1}} \text{sgn}(f(x)) |f(x)|^{p-1}. \]
    %
    If $\| f \|_p < \infty$, then
    %
    \[ \| g \|_q^q = \frac{1}{\| f \|_p^{pq - q}} \int |f(x)|^{pq-q} = \frac{1}{\| f \|_p^p} \| f \|_p^p = 1, \]
    %
    and
    %
    \[ \int f(x) g(x) = \frac{1}{\| f \|_p^{p-1}} \int |f(x)|^p = \| f \|_p. \]
    %
    On the other hand, suppose $\| f \|_p = \infty$. Then there exists a sequence of step functions $s_1 \leq s_2 \leq \dots \to |f|$. Each $s_k$ lies in $L^p(X)$, but the monotone convergence theorem implies that $\| s_k \|_p \to \infty$. For each $k$, find a function $g_k \geq 0$ with $\| g_k \|_q = 1$, and $\int g_k(x) s_k(x) \geq \| s_k \|_p / 2$. Then
    %
    \[ \int g_k(x) \text{sgn}(f(x)) f(x) = \int g_k(x) |f(x)| \geq \int g_k(x) s_k(x) \geq \| s_k \|_p / 2 \to \infty, \]
    %
    this completes the proof in this case. 

    Now we take the case $p = \infty$. Given any $f$, fix $\varepsilon > 0$. Then we can find a set $E$ with $0 < |E| < \infty$ such that $|f(x)| \geq \| f \|_\infty - \varepsilon$ for $x \in E$. If $g(x) = \text{sgn}(f(x)) \mathbf{I}_E / |E|$, then $\| g \|_1 = 1$, and
    %
    \[ \int f(x) g(x) = \frac{1}{|E|} \int_E |f(x)| \geq \| f \|_\infty - \varepsilon. \]
    %
    Taking $\varepsilon \to 0$ completes the claim.
\end{proof}

\section{Decreasing Rearrangements}

 The properties of a functions distribution are best reflected quite simply in the \emph{distribution function} of the function $f$, i.e. the function $F: [0,\infty) \to [0,\infty)$ given by $F(t) = |\{ x : |f(x)| > t \}|$, and any rearrangement invariant norm on $f$ should be a function of $F$. The function $F$ is right-continuous and decreasing, but has a jump discontinuity whenever $\{ x : |f(x)| = t \}$ is a set of positive measure. We denote distributions of functions $g$ and $h$ by $G$ and $H$.

\begin{lemma}
  Given a function $f$ and $g$, $\alpha \in \mathbf{C}$, and $t,s > 0$, then
  %
  \begin{itemize}
    \item If $|g| \leq |f|$, then $G \leq F$.
    \item If $g = \alpha f$, then $G(t) = F(t/|\alpha|)$.
    \item If $h = f + g$, then $H(t+s) \leq F(t) + G(s)$.
    \item If $h = fg$, then $H(ts) \leq F(t) + G(s)$.
  \end{itemize}
\end{lemma}
\begin{proof}
    The first point follows because $\{ x : |g(x)| > t \} \subset \{ x : |f(x)| > t \}$, and the second because $\{ x : |\alpha f(x)| > t \} = \{ x : |f(x)| > t/|\alpha| \}$. The third point follows because if $|f(x) + g(x)| \geq t + s$, then either $|f(x)| \geq t$ or $|g(x)| \geq s$. Finally, if $|f(x) g(x)| \geq ts$, then $|f(x)| \geq t$ or $|g(x)| \geq s$.
\end{proof}

We can simplify the study of the distribution of $f$ even more by defining the \emph{decreasing rearrangement} of $f$, a decreasing function $f^*: [0,\infty) \to [0,\infty)$ such that $f^*(s)$ is the \emph{smallest} number $t$ such that $F(t) \leq s$. Effectively, $f^*(s)$ is the inverse of $F$:
%
\begin{itemize}
    \item If there is a unique $t$ with $F(t) = s$, then $f^*(s) = t$.
    \item If there are multiple values $t$ with $F(t) = s$, let $f^*(s)$ be the \emph{smallest} such value.
    \item If there are no values $t$ with $F(t) = s$, then we pick the first value $t$ with $F(t) < s$.
\end{itemize}
%
We find
%
\[ \{ s : f^*(s) > t \} = \{ s : s < F(t) \} = [0,F(t)), \]
%
which has measure $F(t)$. This is the most important property of $f^*$; it is a decreasing function on the line which has the same distribution as the function $|f|$. It is also the unique such function which is right continuous. Thus our intuition when analyzing monotone, rearrangement invariant norms is not harmed if we focus on right continuous decreasing functions.

\begin{theorem}
    The function $f^*$ is right continuous.
\end{theorem}
\begin{proof}
    We note that $F(t) > s$ if and only if $t < f^*(s)$. Since $f^*$ is decreasing, for any $s \geq 0$, we automatically have $f^*(s^+) \leq f^*(s)$. If $f^*(s^+) < f^*(s)$, then
    %
    \[ s < F \left( f^*(s^+) \right) \leq F(f^*(s)) \leq s, \]
    %
    which gives a contradiction, so $f^*(s) = f^*(s^+)$.
\end{proof}

\begin{remark}
    We have a jump discontinuity at a point $s$ wherever $F$ is flat, and $f^*$ is flat wherever $F$ has a jump discontinuity.
\end{remark}

In particular, when understanding intuition about monotone rearrangement invariant norms, one is allowed to focus on non-increasing, right continuous functions on $(0,\infty)$. For instance, this means that these norms do not care about the number of singularities that a function has, since all these singularities `pile up' in the decreasing rearrangement.

\section{Weak Norms}

The weak $L^p$ norms are obtained as a slight `refinement' of the $L^p$ norms.

\begin{theorem}
  If $\phi$ is an increasing, differentiable function on the real line with $\phi(0) = 0$, then
  %
  \[ \int_X \phi(|f(x)|) = \int_0^\infty \phi'(t) F(t)\; dt \]
\end{theorem}
\begin{proof}
  An application of Fubini's theorem is all that is needed to show
  %
  \begin{align*}
    \int_X \phi(|f(x)|)\; dx &= \int_X \int_0^{|f(x)|} \phi'(t)\; dt\; dx\\
    &= \int_0^\infty \phi'(t) \int_{|f(x)| > t}\; dx\; du\\
    &= \int_0^\infty \phi'(t) F(t)\; dt. \qedhere
  \end{align*}
\end{proof}

As a special case we find
%
\[ \| f \|_p = \left( p \int_0^\infty F(t) t^p \frac{dt}{t} \right)^{1/p}. \]
%
For this to be true, $F(t)$ must tend to zero `logarithmically faster' than $1/t^p$. Indeed, we find
%
\[ F(t) = |\{ |f|^p > t^p \}| \leq \frac{1}{t^p} \int |f|^p = \frac{\| f \|_p^p}{t^p}, \]
%
a fact known as \emph{Chebyshev's inequality}. But a bound $F(t) \lesssim 1/t^p$ might be true even if $f \not \in L^p(\RR^d)$. This leads to the \emph{weak $L^p$ norm}, denoted by $\| f \|_{p,\infty}$, which is defined to be the smallest value $A$ such that $F(t) \leq (A/t)^p$ for all $t$. We let $L^{p,\infty}(X)$ denote the space of all functions $f$ for which $\| f \|_{p,\infty} < \infty$. By Chebyshev's inequality, $\| f \|_{p,\infty} \leq \| f \|_p$ for any function $f$. The reason that the value $A$ occurs within the brackets is so that the norm is homogenous; if $g = \alpha f$, and $\| f \|_{p,\infty} = A$, then
%
\[ G(t) = F(t/|\alpha|) \leq \left( \frac{A |\alpha|}{t} \right)^p, \]
%
so $\| \alpha f \|_{p,\infty} = |\alpha| \| f \|_p$. The weak norms do not satisfy a triangle inequality, but they do satisfy a quasitriangle inequality. This can be proven quite simply from the property that if $f = f_1 + \dots + f_N$, and $\alpha_1, \dots, \alpha_N \in [0,1]$ satisfy $\alpha_1 + \dots + \alpha_N = 1$, then
%
\[ F(t) = F_1(\alpha_1 t) + \dots + F_N(\alpha_N t). \]
%
Thus if $f = g + h$, then
%
\[ F(t) \leq G(t/2) + H(t/2) \leq \frac{\| g \|_{p,\infty}^p + \| h \|_{p,\infty}^p}{t^p} \lesssim_p \left( \frac{\| g \|_{p,\infty} + \| h \|_{p,\infty}}{t} \right)^p. \]
%
Thus $\| f + g \|_{p,\infty} \lesssim \| f \|_{p,\infty} + \| g \|_{p,\infty}$. We can measure the degree to which the weak $L^p$ norm fails to be a norm by determining how much the triangle inequality fails for the sum of $N$ functions, instead of just one function.

\begin{theorem}[Stein-Weiss Inequality]
  Let $f_1, \dots, f_N$ be functions. If $p > 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty}. \]
  %
  If $p = 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{1,\infty} \lesssim \log N \left[ \| f_1 \|_{1,\infty} + \dots + \| f_N \|_{1,\infty} \right]. \]
  %
  If $0 < p < 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \left( \| f_1 \|_{p,\infty}^p + \dots + \| f_N \|_{p,\infty}^{1/p} \right)^{1/p} \]
\end{theorem}
\begin{proof}
    Begin with the case $p \geq 1$. Without loss of generality, assume $\| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty} = 1$. Fix $t > 0$. For each $k \in [1,N]$, define
    %
    \[ g_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \geq t/2, \\ 0 &: \text{otherwise}, \end{cases} \]
    %
    and
    %
    \[ h_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \leq \| f_k \|_{p,\infty} \cdot (t/2), \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    Also define $j_k = f_k - g_k - h_k$. Then write $f = f_1 + \dots + f_N$, $g = g_1 + \dots + g_N$, $h = h_1 + \dots + h_N$, and $j = j_1 + \dots + j_N$. Note that $\| h \|_\infty \leq t/2$, so
    %
    \[ \{ x : |f(x)| \geq t \} \subset \{ x : |g(x)| \geq t/4 \} \cup \{ x : |j(x)| \geq t/4 \}. \]
    %
    Each $g_k$ is supported on a set of measure at most $\| f_k \|_{p,\infty}^p \cdot (2/t)^p$. We conclude that $g$ is supported on a set of measure at most
    %
    \[ (2/t)^p \sum_{k = 1}^N \| f_k \|_{p,\infty}^p \leq (2/t)^p. \]
    %
    If $p > 1$, then the measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded by
    %
    \begin{align*}
        \frac{4}{t} \int |j(x)|\; dx &\leq \frac{4}{t} \sum_{k = 1}^N \int |j_k(x)|\\
        &= \frac{4}{t} \sum_{k = 1}^N \int_{\| f_k \|_{p,\infty} (t/2)}^{t/2} \frac{\| j_k \|_{p,\infty}^p}{s^p}\; ds\\
        &= \frac{2^{p+1}}{p-1} \frac{1}{t^p} \sum_{k = 1}^N \| j_k \|_{p,\infty}^p \left( \frac{1}{\| f_k \|_{p,\infty}^{p-1}} - 1 \right) \\
        &\leq \frac{2^{p+1}}{p-1} \frac{1}{t^p} \sum_{k = 1}^N \| f_k \|_{p,\infty}^p \left( \frac{1}{\| f_k \|_{p,\infty}^{p-1 }} - 1 \right)\\
        &\leq \frac{2^{p+1}}{p-1} \frac{1}{t^p}.
    \end{align*}
    %
    Thus in total, we conclude the measure of $\{ x: |f(x)| \geq t \}$ is at most
    %
    \[ \frac{2^p}{t^p} + \frac{2^{p+1}}{p - 1} \frac{1}{t^p} \lesssim_p \frac{1}{t^p}. \]
    %
    If $p = 1$, then the measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded
    %
    \begin{align*}
        (4/t) \int |j(x)|\; dx &\leq (4/t) \sum_{k = 1}^N \int |j_k(x)|\\
        &= (4/t) \sum_{k = 1}^N \int_{\| f_k \|_{1,\infty} (t/2)}^{t/2} \frac{\| j_k \|_{1,\infty}}{s}\; ds\\
        &= (4/t) \sum_{k = 1}^N \| f_k \|_{1,\infty} \log(1/\| f_k \|_{1,\infty}).
    \end{align*}
    %
    Now the maximum of $x_1 \log(1/x_1) + \dots + x_N \log(1/x_N)$, subject to the constraint that $x_1 + \dots + x_N = 1$, is maximized by taking $x_k = 1/N$ for all $N$, which gives a maximal bound of $\log(N)$. In particular, we find that
    %
    \[ (2/t) \sum_{k = 1}^N \| f_k \|_{1,\infty} \log(1/\| f_k \|_{1,\infty}) \leq (2 \log N)/t. \]
    %
    Thus in total, we conclude the measure of $\{ x: |f(x)| \geq t \}$ is at most
    %
    \[ 2(1 + \log N)/t \lesssim \log N / t. \]
    %
    If $p < 1$, we may assume without loss of generality that
    %
    \[ \| f_1 \|_{p,\infty}^p + \dots + \| f_N \|_{p,\infty}^p = 1. \]
    %
    Then, we perform the same decomposition as before, with functions $\{ g_k \}$, $\{ h_k \}$, and $\{ j_k \}$, defined the same as before, except that
    %
    \[ h_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \leq \| f_k \|_{p,\infty}^p \cdot (t/2), \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    The function $g_k$ has support at most $\| f_k \|_{p,\infty}^p \cdot (2/t)^p$, and thus $g$ has total support
    %
    \[ \sum \| f_k \|_{p,\infty}^p (2/t)^p = (2/t)^p. \]
    %
    The measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded by
    %
    \begin{align*}
      \frac{4}{t} \int |j(x)|\; dx &\leq \frac{4}{t} \sum_{k = 1}^N \int_{\| f_k \|_{p,\infty}^p (t/2)}^{t/2} \frac{\| f_k \|_{p,\infty}^p}{s^p}\; ds\\
      &\leq \frac{2^{p+1}}{t^p} \frac{1}{1 - p} \sum_{k = 1}^N \| f_k \|_{p,\infty}^{p + p(1-p)}\\
      &= \frac{2^{p+1}}{t^p} \frac{1}{1 - p} \max \| f_k \|_{p,\infty}^{p(1-p)} \lesssim_p \frac{1}{t^p},
    \end{align*}
    %
    Combining the two bounds gives that $\| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p 1$.
\end{proof}

\begin{remark}
  For $p = 1$, compare this \emph{logarithmic} failure to be a norm with the \emph{polynomial} failure to be a norm found in the norms $\| \cdot \|_p$, when $p < 1$, in Theorem \ref{quasitriangleinequalitylp}.
\end{remark}

For $p = 1$, the Stein-Weiss inequality is asymptotically tight in $N$.

\begin{example}
  Let $X = \RR$. For each $k$, let
  %
  \[ f_k(x) = \frac{1}{|x - k|}. \]
  %
  Then $\| f_k \|_{1,\infty} \lesssim 1$ is bounded independantly of $k$. If $|x| \leq N$, there are integers $k_1, \dots, k_N > 0$ such that $|x - k_i| \leq 2i$, so
  %
  \[ f(x) \geq \sum_{i = 1}^N \frac{1}{|x - k_i|} \geq \sum_{i = 1}^N \frac{1}{2i} \gtrsim \log(N). \]
  %
  Thus $\| f \|_{1,\infty} \gtrsim N \log N \gtrsim \log N \sum \| f_k \|_{1,\infty}$.
\end{example}

The weak $L^p$ norms provide another monotone translation invariant norm, and it oftens comes up when finer tuning is needed in certain interpolation arguments, especially when dealing with maximal functions.

\begin{example}
  If $f = H \mathbf{I}_E$, with $|E| = W$, then
  %
  \[ F(t) = W \cdot \mathbf{I}_{[0,H)}. \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \sup_{0 \leq t < H} W t^p \right)^{1/p} = W^{1/p} H^p = \| f \|_p. \]
  %
  If $f = H_1 \mathbf{I}_{E_1} + H_2 \mathbf{I}_{E_2}$, with $|E_1| = W_1$ and $|E_2| = W_2$, with $H_1 \leq H_2$, then
  %
  \[ F(t) = \begin{cases} W_1 + W_2 &: t < H_1, \\ W_2 &: t < H_2, \\ 0 &: \text{otherwise.} \end{cases} \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \max((W_1 + W_2) H_1^p, W_2 H_2^p) \right)^{1/p} = \max((W_1 + W_2)^{1/p} H_1, W_2^{1/p} H_2). \]
\end{example}

\begin{example}
    The function $f(x) = 1/|x|^s$ does not lie in any $L^p(\RR^d)$, but lies in $L^{p,\infty}$ precisely when $p = d/s$, since
    %
    \[ \left| \{ 1/|x|^{ps} > t \} \right| = \left| \left\{ |x| \leq \frac{1}{t^{1/ps}} \right\} \right|\ \propto_d\ \frac{1}{t^{d/ps}}. \]
\end{example}

Before we move on, we consider a form of duality for the weak norm, at least when $p > 1$.

\begin{theorem}
	If $p > 1$, and $X$ is $\sigma$ finite, then
	%
	\[ \| f \|_{p,\infty} \sim_p \sup_{|E| < \infty} \frac{1}{|E|^{1-1/p}} \int_E |f(x)|\; dx \]
\end{theorem}
\begin{proof}
	Suppose $\| f \|_{p,\infty} < \infty$. If we write $f = \sum f_k$, where $f_k = \mathbf{I}_{F_k} f$, and $F_k = \{ x: 2^{k-1} < |f(x)| \leq 2^k \}$, then $|F_k| \leq \| f \|_{p,\infty}^p 2^{-kp}$. Thus
	%
	\[ \left| \int_E |f_k(x)| \right| \leq 2^k \| f \|_{p,\infty}^p 2^{-kp} = \| f \|_{p,\infty}^p 2^{k(1-p)}. \]
	%
	Fix some integer $n$. Then
	%
	\begin{align*}
		\int_E |f(x)|\; dx &\leq \sum_{k = -\infty}^{n-1} \int_E |f_k(x)|\; dx + \sum_{k = n}^\infty \int_E |f_k(x)|\; dx\\
		&\leq |E| 2^{n-1} + \| f \|_{p,\infty}^p \sum_{k = n}^\infty 2^{k(1-p)}\\
		&\lesssim_p |E| 2^n + \| f \|_{p,\infty}^p 2^{-k(1-p)}.
	\end{align*}
	%
	If we let $2^n \sim \| f \|_{p,\infty} |E|^{1/p}$, then we conclude
	%
	\[ \int_E |f(x)|\; dx \lesssim_p |E|^{1 - 1/p} \| f \|_{p,\infty}. \]
	%
	Conversely, write 
	%
	\[ A = \sup_{|E| < \infty} \frac{1}{|E|^{1-1/p}} \int_E |f(x)|\; dx/ \]

	%
	If $G_t = \{ x: |f(x)| \geq t \}$, then
	%
	\[ |G_t| \leq \frac{1}{t} \int_{G_t} |f(x)|\; dx \leq \frac{A |G_t|^{1 - 1/p}}{t}, \]
	%
	so
	%
	\[ |G_t| \leq \frac{A^p}{t}, \]
	%
	which gives $\| f \|_{p,\infty} \leq A$.
\end{proof}

For $p \leq 1$, the spaces $L^{p,\infty}(X)$ are not normable, as seen by the tightness of the Stein-Weiss inequality. Nonetheless, we still have a certain `duality' property, that is often useful in the analysis of operators on these spaces. Most useful is it's application when $p = 1$.

\begin{theorem} \label{weakdualitytheorem}
  Let $0 < p < \infty$, and let $f \in L^{p,\infty}(X)$, and let $\alpha \in (0,1)$. Then the following are equivalent:
  %
  \begin{itemize}
    \item $\| f \|_{p,\infty} \lesssim_{\alpha,p} A$.

    \item For any set $E \subset X$ with finite measure, there is $E' \subset E$ with $|E'| \geq \alpha |E|$ such that
    %
    \[ \int_{E'} |f(x)|\; dx \lesssim_{\alpha,p} A |E'|^{1 - 1/p}. \]
  \end{itemize}
\end{theorem}
\begin{proof}
  By homogeneity, assume $\| f \|_{p,\infty} \leq 1$, so that if $F$ is the distribution of $f$, $F(t) \leq 1/t^p$. If $|E| = (1-\alpha)^{-1} / t_0^p$, and we set
  %
  \[ E' = \{ x: |f(x)| \leq t_0 \}, \]
  %
  then
  %
  \[ |E'| \geq |E| - F(t_0) = \frac{(1 - \alpha)^{-1} - 1}{t_0^p} = \alpha |E|, \]
  %
  and
  %
  \[ \int_{E'} |f(x)| \leq t_0 |E'| \lesssim_\alpha |E'|^{1-1/p}. \]
  %
  Conversely, suppose Property (2) holds. For each $k$, set
  %
  \[ E_k = \{ x: 2^k \leq |f(x)| < 2^{k+1} \}. \] 
  %
  Then there exists $E_k'$ with $|E_k'| \geq \alpha |E_k|$ and
  %
  \[ \int_{E_k'} |f(x)|\; dx \leq |E_k'|^{1 - 1/p} \]
  %
  On the other hand,
  %
  \[ \int_{E_k'} |f(x)|\; dx \geq 2^k |E_k'|. \]
  %
  Rearranging this equation gives $|E_k'| \leq 2^{-pk}$, and so $|E_k| \lesssim_\alpha 2^{-pk}$. But this means
  %
  \[ F(2^N) = \sum_{k = N}^\infty |E_k| \lesssim_{\alpha,p} 2^{-Np}, \]
  %
  and this implies $\| f \|_{p,\infty} \lesssim_{\alpha,p} 1$.
\end{proof}

\section{Lorentz Spaces}

Recall that we can write
%
\[ \| f \|_p = \left( p \int_0^\infty F(t) t^p \frac{dt}{t} \right)^{1/p}. \]
%
Thus $F(t) t^p$ is integrable with respect to the Haar measure on $\RR^+$. But if we change the integrality condition to the condition that $F(t) t^p \in L^q(\RR^+)$ for some $0 < q \leq \infty$, we obtain a different integrability condition, giving rise to a monotone, translation-invariant norm. Thus leads us to the definition of the \emph{Lorentz norms}. For each $0 < p,q < \infty$, we define the Lorentz norm
%
\[ \| f \|_{p,q} = p^{1/q} \| t F^{1/p} \|_{L^q(\RR^+)} \]
%
The \emph{Lorentz space} $L^{p,q}(X)$ as the space of functions $f$ with $\| f \|_{p,q} < \infty$. We can define the norm in terms of $f^*$ as well.

\begin{lemma}
  For any measurable $f: X \to \RR$, $\| f(t) \|_{p,q} = \| s^{1/p} f^*(s) \|_{L^q(\RR^+)}$.
\end{lemma}
\begin{proof}
  First, assume $f^*$ has non-vanishing derivative on $(0,\infty)$, and that $f$ is bounded, with finite support. An integration by parts gives
  %
  \[ \| f \|_{p,q} = p^{1/q} \left( \int_0^\infty t^{q-1} F(t)^{q/p}\; dt \right)^{1/q} = \left( \int_0^\infty t^q F(t)^{q/p - 1} (-F'(t))\; dt \right)^{1/q}. \]
  %
  If we set $s = F(t)$, then $f^*(s) = t$, and $ds = F'(t) dt$, and so
  %
  \[ \left( \int_0^\infty t^q F(t)^{q/p - 1} F'(t)\; dt \right)^{1/q} = \left( \int_0^\infty f^*(s)^q s^{q/p - 1} ds \right)^{1/q} = \| s^{1/p} f^* \|_{L^q(\RR^+)}. \]
  %
  This gives the result in this case. The general result can then be obtained by applying the monotone convergence theorem to an arbitrary $f^*$ with respect to a family of smooth functions.
\end{proof}

The definition of the Lorentz space may seem confusing, but we really only require various special cases in most applications. Aside from the weak $L^p$ norms $\| \cdot \|_{p,\infty}$ and the $L^p$ norms $\| \cdot \|_p = \| \cdot \|_{p,p}$, the $L^{p,1}$ norms and $L^{p,2}$ norms also occur, the first, because of the connection with integrability, and the second because we may apply orthogonality techniques. As $q \to 0$, the norms $\| \cdot \|_{p,q}$ give stronger control over the function $f$.

\begin{theorem}
    For $q < r$, $\| f \|_{p,r} \lesssim_{p,q,r} \| f \|_{p,q}$.
\end{theorem}
\begin{proof}
    First we treat the case $r = \infty$. We have
    %
    \begin{align*}
        s_0^{1/p} f^*(s_0) &= \left( (p/q) \int_0^{s_0} [s^{1/p} f^*(s_0)]^q \frac{ds}{s} \right)^{1/q}\\
        &\leq \left( (p/q) \int_0^{s_0} [s^{1/p} f^*(s)]^q \frac{ds}{s} \right)\\
        &\leq (p/q)^{1/q} \| f \|_{p,q}.
    \end{align*}
    %
    When $r < \infty$, we can interpolate, calculating
    %
    \begin{align*}
      \| f \|_{p,r} &= \left( \int_0^\infty [s^{1/p} f^*(s)]^r \frac{ds}{s} \right)^{1/r}\\
    &\leq \| f \|_{p,\infty}^{1 - q/r} \| f \|_{p,q}^{q/r} \leq (p/q)^{p(1/q - 1/r)} \| f \|_{p,q}. \qedhere
    \end{align*}
\end{proof}

The fact that multiplying a function by a constant dilates the distribution implies that the Lorentz norm is homogeneous. We do not have a triangle inequality for the Lorentz norms, but we have a quasi triangle inequality.

\begin{theorem}
	For each $p,q > 0$, $\| f_1 + f_2 \|_{p,q} \lesssim_{p,q} \| f_1 \|_p + \| f_2 \|_q$.
\end{theorem}
\begin{proof}
    We calculate that if $g = f_1 + f_2$,
    %
    \begin{align*}
    \| g \|_{p,q} &= \left( q \int_0^\infty \left[t G(t)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\leq \left( q \int_0^\infty \left[ t (F_1(t/2) + F_2(t/2))^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\lesssim \left( q \int_0^\infty \left[ t \left( F_1(t) + F_2(t) \right)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\lesssim_p \left( q \int_0^\infty t^q \left( F_1(t)^{q/p} + F_2(t)^{q/p} \right) \frac{dt}{t} \right)^{1/q}\\
    &\lesssim_q  \left( q \int_0^\infty t^q F_1(t)^{q/p} \frac{dt}{t} \right)^{1/q} +  \left( q \int_0^\infty t^q F_2(t)^{q/p} \frac{dt}{t} \right)^{1/q}\\
    &= \| f_1 \|_{p,q} + \| f_2 \|_{p,q}. \qedhere
  \end{align*}
\end{proof}

\section{Dyadic Layer Cake Decompositions}

An important trick to utilizing Lorentz norms is by utilizing a dyadic layer cake decomposition. The dyadic layer cake decompositions enable us to understand a function by breaking it up into parts upon which we can control the height or width of a function. We say $f$ is a \emph{sub step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \leq W$, and $|f(x)| \leq H$. A \emph{quasi step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \sim W$ and on $E$, $|f(x)| \sim H$.

\begin{remark}
  It might seem that sub step functions of height $H$ and width $W$ can take on a great many different behaviours, rather than that of a step function with height $H$ and width $W$. However, from the point of view of monotone, translation invariant norms, this isn't so. This is because using the binary expansion of real numbers, for every sub-step function $f$ of height $H$ and width $W$, we can find sets $\{ E_k \}$ such that
  %
  \[ f(x) = H \sum_{k = 1}^\infty 2^{-k} \mathbf{I}_{E_k}, \]
  %
  where $|E_k| = 1$. Thus bounds on step functions that are stable under addition tend to automatically imply bounds on substep functions.
\end{remark}

We start by discussing the \emph{vertical dyadic layer cake decomposition}. We define, for each $k \in \ZZ$,
%
\[ f_k(x) = f(x) \mathbf{I}(2^{k-1} < |f(x)| \leq 2^k) \]
%
Then we set $f = \sum f_k$. Each $f_k$ is a quasi step function with height $2^k$ and width $F(2^{k-1}) - F(2^k)$. We can also perform a \emph{horizontal layer cake decomposition}. If we define $H_k = f^*(2^k)$, and set
%
\[ f_k(x) = f(x) \mathbf{I}(H_{k-1} < |f(x)| \leq H_k), \]
%
then $f_k$ is a substep function with height $H_k$ and width $2^k$. These decompositions are best visualized with respect to the representation $f^*$ of $f$, in which case the decomposition occurs over particular intervals.

\begin{theorem}
    The following values $A_1, \dots, A_4$ are all comparable up to absolute constant depending only on $p$ and $q$:
    %
    \begin{enumerate}
        \item \label{onebound} $\| f \|_{p,q} \leq A_1$.

        \item \label{twobound} We can write $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a quasi-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[ 2^k W_k^{1/p} \right]^q \right)^{1/q} \leq A_2. \]

        \item \label{threebound} We can write $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a sub-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[2^{k} W_k^{1/p} \right]^q \right)^{1/q} \leq A_3. \]

        \item \label{fourbound} We can write $f(x) = \sum_{k \in \ZZ} f_k$, where $f_k$ is a sub-step function with width $2^k$ and height $H_k$, where $\{ H_k \}$ is a decreasing family of functions, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[H_k 2^{k/p} \right]^q \right)^{1/q} \leq A_4. \]
    \end{enumerate}
\end{theorem}
\begin{proof}
    It is obvious that we can always select $A_3 \leq A_2$. Next, we bound $A_2$ in terms of $A_1$ by performing a vertical layer cake decomposition on $f$. If we write $f = \sum_{k \in \ZZ} f_k$, then $f_k$ is supported on a set with measure $W_k = F(2^{k-1}) - F(2^k) \leq F(2^{k-1})$, and so
    %
    \begin{align*}
        \sum_{k \in \ZZ} [2^k W_k^{1/p}]^q &\leq \sum_{k \in \ZZ} [2^k F(2^{k-1})^{1/p}]^q\\
        &\lesssim_q \sum_{k \in \ZZ} [2^{k-1} F(2^k)^{1/p}]^q\\
        &\lesssim \sum_{k \in \ZZ} \int_{2^{k-1}}^{2^k} [tF(t)^{1/p}]^q\; \frac{dt}{t} \lesssim_q \| f \|_{p,q}^q \leq A_1^q.
    \end{align*}
    %
    Thus $A_2 \lesssim_q A_1$. Next, we bound $A_4$ in terms of $A_1$. Perform a horizontal layer cake decomposition, writing $f = \sum f_k$, where $f_k$ is supported on a set with measure $W_k \leq 2^k$, and $H_{k+1} \leq |f_k(x)| \leq H_k$. Then a telescoping sum shows
    %
    \begin{align*}
        H_k 2^{k/p} &= \left( \sum_{m = 0}^\infty (H_{k+m}^q - H_{k+m+1}^q) 2^{kq /p} \right)^{1/q}\\
        &\lesssim_q \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t 2^{k/p}]^q \frac{dt}{t} \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q}
    \end{align*}
    %
    Thus
    %
    \[ \left( \sum_{k \in \ZZ} [H_k 2^{k/p}]^q \right)^{1/q} \leq \left( \int_0^\infty [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q} \lesssim_q A_1. \]
    %
    Thus $A_4 \lesssim_q A_1$. It remains to bound $A_1$ by $A_4$ and $A_3$. Given $A_3$, we can write $|f(x)| \leq \sum 2^k \mathbf{I}_{E_k}$, where $|E_k| \leq W_k$. We then find
    %
    \[ F(2^k) \leq \sum_{m = 1}^\infty W_{k+m}. \]
    %
    Thus
    %
    \[ \int_{2^{k-1}}^{2^k} [t F(t)^{1/p}]^q \frac{dt}{t} \lesssim \left[ 2^k \left(\sum_{m = 0}^\infty W_k \right)^{1/p} \right]^q. \]
    %
    Thus if $q \leq p$,
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \ZZ} \left[2^k \left( \sum_{m = 0}^\infty W_{k+m} \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{k \in \ZZ} \sum_{m = 0}^\infty \left[ 2^k W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty 2^{-qm} \sum_{k \in \ZZ} \left[ 2^{k+m} W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( A_3^q \sum_{m = 0}^\infty 2^{-mq} \right)^{1/q} \lesssim_q A_3.
    \end{align*}
    %
    If $q \geq p$, we can employ the triangle inequality for $l^{q/p}$ to write
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \ZZ} \left[2^k \left( \sum_{m = 0}^\infty W_{k + m}  \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \left( \sum_{k \in \ZZ} 2^{kq} W_{k+m}^{q/p} \right)^{p/q} \right)^{1/p}\\
        &\leq \left( A_3^p \sum_{m = 0}^\infty 2^{-mq} \right)^{1/p} \lesssim_{p,q} A_3.
    \end{align*}
    %
    The bound of $A_1$ in terms of $A_4$ involves the same `shifting' technique, and is left to the reader.
\end{proof}

\begin{remark}
    Heuristically, the theorem above says that if $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a quasi-step function with width $H_k$ and width $W_k$, and if either $\{ H_k \}$ and $\{ W_k \}$ grow faster than powers of two, then
    %
    \[ \| f \|_{p,q} \sim_{p,q} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}. \]
    %
    Thus the $L^{p,q}$ norm has little interaction between elements of the sum when the sum occurs over dyadically different heights or width. This is one reason why we view the $q$ parameter as a `logarithmic' correction of the $L^p$ norm. In particular, if we can write $f = f_1 + \dots + f_N$, and $q_1 < q_2$, then the last equation, combined with a $l^{q_1}$ to $l^{q_2}$ norm bound, gives
    %
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^{q_1} \right)^{1/q_1} \leq N^{1/q_1 - 1/q_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^{q_2} \right)^{1/q_2} \]
    %
    This implies
    %
    \[ \| f \|_{p,q_2} \lesssim_{p,q_1,q_2} \| f \|_{p,q_1} \lesssim_{p,q_1,q_2} N^{1/q_1 - 1/q_2} \| f \|_{p,q_2}. \]
    %
    In particular, this occurs if there exists a constant $C$ such that $C \leq |f(x)| \leq C \cdot 2^N$ for all $x$. On the other hand, if we vary the $p$ parameter, we find that for $p_1 < p_2$,
    %
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} \leq \max(W_k)^{1/p_1 - 1/p_2} \left( \sum_{k \in \ZZ} \left[H_k W_k^{1/p_2} \right]^q \right)^{1/q}, \]
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} \leq \left( \frac{1}{\min(W_k)} \right)^{1/p_1 - 1/p_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q}. \]
    %
    which gives
    %
    \[ \min(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q} \lesssim_{p_1,p_2,q} \| f \|_{p_1,q} \lesssim_{p_1,p_2,q} \max(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q}. \]
    %
    Both of these inequalities can be tight. Because of the dyadic decomposition of $f$, we find $\max(W_k) \geq 2^N \min(W_k)$, so these two norms can differ by at least $2^{N(1/p_1 - 1/p_2)}$, and at \emph{most} if the $f_k$ occur over consecutive dyadic values, which is \emph{exponential} in $N$. Conversely, if the heights change dyadically, we find that
    % q = q'p_2/p-1
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} &\leq \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^{qp_2/p_1} \right)^{(p_1/p_2)/q}\\
        &\leq \max(H_k)^{1 - p_1/p_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{(p_1/p_2)/q}
    \end{align*}
    %
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} &\lessapprox \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^{qp_1/p_2} \right)^{(p_2/p_1)/q}\\
        &\leq \left( \frac{1}{\min(H_k)} \right)^{p_2/p_1 - 1} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{(p_2/p_1)/q}
    \end{align*}
    %
    where $\lessapprox$ denotes a factor ignoring polynomial powers of $N$ occuring from the estimate. Thus
    %
    \[ \min(H_k)^{p_2 - p_1} \| f \|_{p_1,q}^{p_1} \lessapprox_{p_1,p_2,q} \| f \|_{p_2,q}^{p_2} \lesssim_{p_1,p_2,q} \max(H_k)^{p_2-p_1} \| f \|_{p_1,q}^{p_1} \]
    %
    again, these inequalities can be both tight, and $\max(H_k) \geq 2^N \min(H_k)$, with equality if the quasi step functions from which $f$ is composed occur consecutively dyadically.
\end{remark}

\begin{example}
    Consider the function $f(x) = |x|^{-s}$. For each $k$, let
    %
    \[ E_k = \{ x : 2^{-(k+1)/s} \leq |x| < 2^{-k/s} \} \]
    %
    and define $f_k = f \mathbf{I}_{E_k}$. Then $f_k$ is a quasi-step function with height $2^k$, and width $1/2^{dk/s}$. We conclude that if $p = d/s$, and $q < \infty$,
    %
    \[ \| f \|_{p,q} \sim_{p,q,d} \left( \sum_{k = -\infty}^\infty 2^{qk(1 - d/ps)} \right)^{1/q} = \infty. \]
    %
    Thus the function $f$ lies exclusively in $L^{p,\infty}(\RR^d)$.
\end{example}

A simple consequence of the layer cake decomposition is H\"{o}lder's inequality for Lorentz spaces.

\begin{theorem}
    If $0 < p_1,p_2,p < \infty$ and $0 < q_1,q_2,q < \infty$ with
    %
    \[ 1/p = 1/p_1 + 1/p_2 \quad \text{and} \quad 1/q = 1/q_1 + 1/q_2, \]
    %
    then
    %
    \[ \| f g \|_{p,q} \lesssim_{p_1,p_2,q_1,q_2} \| f \|_{p_1,q_1} \| g \|_{p_2,q_2}. \]
\end{theorem}
\begin{proof}
    Without loss of generality, assume $\| f \|_{p_1,q_1} = \| g \|_{p_2, q_2} = 1$. Perform horizontal layer cake decompositions of $f$ and $g$, writing $|f| \leq \sum_{k \in \ZZ} H_k \mathbf{I}_{E_k}$ and $|g| \leq \sum_{k \in \ZZ} H_k' \mathbf{I}_{F_k}$, where $|E_k|, |F_k| \leq 2^k$. Then
    %
    \[ |fg| \leq \sum_{k,k' \in \ZZ} H_k H_k' \mathbf{I}_{E_k \cap F_{k'}} \]
    %
    For each fixed $k$, $|E_{k + m} \cap F_m| \leq 2^m$, and so
    %
    \begin{align*}
        \left\| \sum_{m \in \ZZ} H_{k + m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q} &\lesssim_{p,q} \left( \sum_{m \in \ZZ} [H_{k+m} H_m' 2^{m/p}]^q \right)^{1/q}\\
        &= \left( \sum_{m \in \ZZ} \left[ (H_{k+m} 2^{m/p_1}) (H_m 2^{m/p_2}) \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m \in \ZZ} [H_{k+m} 2^{m/p_1} ]^{q_1} \right)^{1/q_1} \left( \sum_{m \in \ZZ} [H_m' 2^{m/p_2}]^{q_2} \right)^{1/q_2}\\
        &\lesssim_{p,q,p_1,q_1,p_2,q_2} 2^{-k/p_1}\\
    \end{align*}
    %
    Summing over $k > 0$ gives that
    %
    \[ \left\| \sum_{k \geq 0} \sum_{m \in \ZZ} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\| \lesssim_{p,q,p_1,q_1,p_2,q_2} 1 \]
    %
    By the quasitriangle inequality, it now suffices to obtain a bound
    %
    \[ \left\| \sum_{k < 0} \sum_{m \in \ZZ} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q}. \]
    %
    This is done similarily, but using the bound $|E_{k+m} \cap F_m| \leq 2^{k+m}$ instead of the other bound.
\end{proof}

\begin{corollary}
    If $p > 1$ and $q > 0$, $L^{p,q}(X) \subset L^1_{\text{loc}}(X)$.
\end{corollary}
\begin{proof}
    Let $E$ have finite measure and let $f \in L^{p,q}(X)$. Then the H\"{o}lder's inequality for Lorentz spaces shows
    % 1 = 1/p + 1/p_2 = 1/q + 1/q_2
    %
    \[ \| f \|_{L^1(E)} = \| \mathbf{I}_E f \|_{L^1(X)} \lesssim_{p,q} |E|^{1 - 1/p} \| f \|_{p,q} < \infty. \qedhere \]
\end{proof}

Finally, we consider the duality of the $L^{p,q}$ norms. If $1 < p < \infty$, and $1 < q < \infty$, then $L^{p,q}(X)^* = L^{p',q'}(X)$. When $q = 1$ or $q = \infty$, things are more complex, but the following theorem often suffices. When $p = 1$, things get more tricky, so we leave this case out.

\begin{theorem}
    Let $1 < p < \infty$ and $1 \leq q < \infty$. Then if $f \in L^{p,q}(X)$,
    %
    \[ \| f \|_{p,q} \sim \sup \left\{ \int fg : \| g \|_{p',q'} \leq 1 \right\}. \]
\end{theorem}
\begin{proof}
    Without loss of generality, we may assume $\| f \|_{p,q} = 1$. We may perform a vertical layer cake decomposition, writing $f = \sum_{k \in \ZZ} f_k$, where $2^{k-1} \leq |f_k(x)| \leq 2^k$, is supported on a set with width $W_k$, and
    %
    \[ \left( (2^k W_k^{1/p})^q \right) \sim_{p,q} 1. \]
    %
    Define $a_k = 2^k W_k^{1/p}$, and set $g = \sum_{k \in \ZZ} g_k$, where $g_k(x) = a_k^{q-p} \text{sgn}(f_k(x)) |f_k(x)|^{p-1}$. Then
    %
    \begin{align*}
        \int f(x) g(x) &= \sum_{k \in \ZZ} \int f_k(x) g_k(x) = \sum_{k \in \ZZ} a_k^{q-p} \int |f_k(x)|^p\\
        &\gtrsim_p \sum_{k \in \ZZ} a_k^{q-p} W_k 2^{kp} = \sum_{k \in \ZZ} a_k^q \gtrsim_{p,q} 1.
    \end{align*}
    %
    We therefore need to show that $\| g \|_{p',q'} \lesssim 1$. We note $|g_k(x)| \lesssim a_k^{q-p} 2^{kp}$, and has width $W_k$. The gives a decomposition of $g$, but neither the height nor the widths necessarily in powers of two. Still, we can fix this since the heights increase exponentially; define
    %
    \[ H_k = \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2}. \]
    %
    Then $|g_k(x)| \lesssim_{p,q} H_k$, and $H_{k+1} \geq 2^{p/2} H_k$. In particular, if we pick $m$ such that $2^{mp/2} \geq 1$, then for any $l \leq m$, the sequence $H_{km + l}$, as $k$ ranges over values, increases dyadically, and so by the quasitriangle inequality for the $L^{p',q'}$ norm, and then the triangle inequality in $l^q$, we find
    % W_k = a_k^p/ 2^{kp}
    \begin{align*}
        \| g \|_{p',q'} &\lesssim_{m,p,q} \left( \sum [H_k W_k^{1/p'}]^{q'} \right)^{1/q'}\\
        &\lesssim \left( \sum_{k \in \ZZ} \left[ \left( \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2} \right) (a_k 2^{-k})^{p-1} \right]^{q'} \right)^{1/q'}\\
        &\lesssim_p \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} \sum_{l = 0}^\infty a_{k-l}^{q-p} 2^{-lp/2} \right]^{q'} \right)^{1/q'}\\
        &\lesssim \sum_{l = 0}^\infty 2^{-lp/2} \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'}.
    \end{align*}
    %
    Applying's H\"{o}lder's inequality shows
    %
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'} &\leq  \left( \sum_{k \in \ZZ} a_k^q \right)^{(p-1)/q} \left( \sum_{k \in \ZZ} a_{k-l}^q \right)^{(q-p)/q}\\
        &\lesssim_{p,q} \| f \|_{p,q}^{q-1} \lesssim_{p,q} 1. \qedhere
    \end{align*}
\end{proof}

\begin{remark}
    This technique shows that if $f = \sum f_k$, where $f_k$ is a quasi-step function with measure $W_k$ and height $2^{ck}$, then we can find $m$ such that $cm > 1$, and then consider the $m$ functions $f^1, \dots, f^m$, where $f_i = \sum f_{km + i}$. Then the functions $f_{km + i}$ have heights which are separated by powers of two, and so the quasi-triangle inequality implies
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_m \sum_{i = 1}^m \| f^i \|_{p,q}\\
        &\lesssim_{p,q} \sum_{i = 1}^m \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\lesssim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}
    \end{align*}
    %
    On the other hand,
    %
    \begin{align*}
        \| f \|_{p,q} &\gtrsim \max_{1 \leq i \leq m} \| f^i \|_{p,q}\\
        &\sim \max_{1 \leq i \leq m} \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\gtrsim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}.
    \end{align*}
    %
    Thus the dyadic layer cake decomposition still works in this setting.
\end{remark}

We remark that if $1 < p < \infty$ and $1 \leq q \leq \infty$, then for each $f \in L^{p,q}$, the value
%
\[ \sup \left\{ \int fg : \| g \|_{p',q'} \leq 1 \right\} \]
%
gives a norm on $L^{p,q}(X)$ which is comparable with the $L^{p,q}$ norm. In particular, this implies that for $p > 1$ and $q \geq 1$,
%
\[ \| f_1 + \dots + f_N \|_{p,q} \lesssim_{p,q} \| f_1 \|_{p,q} + \dots + \| f_N \|_{p,q}, \]
%
so that the triangle inequality has constants independent of $N$. We can also use a layer cake decomposition to get a version of the Stein-Weiss inequality for Lorentz norms.

\begin{theorem}
	For each $1 < q < \infty$, there is $\alpha(q) > 0$ such that for any functions $f_1, \dots, f_N$,
	%
	\[ \| f_1 + \dots + f_N \|_{1,q} \lesssim (\log N)^{\alpha(q)} \left( \| f_1 \|_{1,q} + \dots + \| f_N \|_{1,q} \right). \]
\end{theorem}
\begin{proof}
	For values $A$ and $B$ in this argument, we write $A \lessapprox B$ if there exists $\alpha$ such that $A \lesssim (\log N)^\alpha B$. Given $f_1, \dots, f_N$, write $f_i = \sum_{j = -\infty}^\infty f_{ij}$, where $f_{ij}$ has width $W_{ij}$ and height $2^j$. If we assume, without loss of generality, that $\| f_1 \|_{1,q} + \dots + \| f_N \|_{1,q} = 1$, then
	%
	\[ \sum_{i = 1}^N \left( \sum_{j = -\infty}^\infty (2^j W_{ij})^q \right)^{1/q} \lesssim_q 1 \]
	%
	Thus we want to show $\| f_1 + \dots + f_N \|_{1,q} \lessapprox_q 1$. Our first goal is to upper bound the measure of the set
	%
	\[ E = \{ x: 2^{k-1} < |f_1(x) + \dots + f_N(x)| \leq 2^k  \} \]
	%
	The measure of the set $E$ is upper bounded by the measure of the set
	%
	\[ E' = \left\{ x: 2^{k-2} < \left|\sum_{j = k - \lg(N)}^k f_{1j}(x) + \dots + f_{Nj}(x) \right| \leq 2^{k+1} \right\} \]
	%
	Applying the usual Stein-Weiss inequality, we have
	%
	\[ \left\| \sum_{i = 1}^N \sum_{j = k - \lg N}^k f_{ij} \right\|_{1,\infty} \lessapprox \sum_{i = 1}^N \sum_{j = k - \lg N}^k \| f_{ij} \|_{1,\infty} \lesssim \sum_{i = 1}^N \sum_{j = k - \lg N}^k \| f_{ij} \|_{1,\infty} \lesssim_q \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \]
	%
	Thus we conclude
	%
	\[ |E'| \lessapprox_q 2^{-k} \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \]
	%
	This implies that
	%
	\[ \| f_1 + \dots + f_N \|_{1,q} \lessapprox_q \left( \sum_{k = -\infty}^\infty \left( \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \right)^q \right)^{1/q}. \]
	%
	Applying Minkowski's inequality, we conclude
	%
	\begin{align*}
		\left( \sum_{k = -\infty}^\infty \left( \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \right)^q \right)^{1/q} &\lesssim \sum_{i = 1}^N \left( \sum_{k = -\infty}^\infty \left( \sum_{j = k - \lg N}^k W_{ij 2^j} \right)^q \right)^{1/q}\\
		&\lessapprox \sum_{i = 1}^N \left( \sum_{k = -\infty}^\infty \sum_{j = k - \lg N}^k W_{ij}^q 2^{qj} \right)^{1/q}\\
		&\lessapprox \sum_{i = 1}^N \left( \sum_{j = -\infty}^\infty W_{ij}^q 2^{qj} \right)^{1/q} \lesssim 1. \qedhere
	\end{align*}
\end{proof}

\begin{comment}

\section{Normability of the Lorentz Spaces}

Though the Lorentz norms do not satisfy the triangle inequality, the space $L^{p,q}(X)$ is still a `Banach-able' space when $p > 1$, and $q \geq 1$. First off, the standard proof shows the norm gives a complete quasimetric, since a Cauchy sequence in the $L^{p,q}$ norm converges to a function almost everywhere, which is easily verified to have finite $L^{p,q}$ norm. The easiest way to define a norm is to through the decreasing rearrangement.

\begin{lemma}
    For any measurable set $E$,
    %
    \[ \int_E |f(x)|\; dx \leq \int_0^{|E|} f^*(t)\; dt. \]
    %
    and
    %
    \[ \int_{\{ |f(x)| > t \}} |f(x)|\; dx = \int_0^{F(t)} f^*(t)\; dt. \]
\end{lemma}
\begin{proof}
    If $g \leq f$, $g^* \leq f^*$. Thus $(\chi_E f)^* \leq f^*$, so
    %
    \[ \int_E |f(x)|\; dx = \int \chi_E |f(x)| = \int_0^\infty (\chi_E f)^*(t)\; dt = \int_0^{|E|} (\chi_E f)^*(t)\; dt \leq \int_0^{|E|} f^*(t)\; dt. \]
    %
    On the other hand, $(\chi_E f)^* = f^*$ when $E = \{ |f(x)| > t \}$, which gives the second equality.
\end{proof}

For a function $f$ and $t > 0$, we define a family of averages
%
\[ m(t) = \frac{1}{t} \int_0^t f^*(t)\; dt. \]
%
For any fixed $t > 0$, the map $f \mapsto m(t)$ is a norm. Provided our measure space is non-atomic, we have
%
\[ m(t) = \sup_{|E| \leq t} \int_E |f(x)|\; d\mu. \]
%
We define
%
\[ \vvvert f \vvvert_{p,q} = \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} \]
and
%
\[ \vvvert f \vvvert_{p,\infty} = \sup t^{1/p} m(t). \]
%
For $q \geq 1$, each of these functions is a norm, simply because the function $m$ is a norm. On the other hand, since $f^*$ is decreasing, $f^*(t) \leq m(t)$ for all $t$, which shows $\vvvert f \vvvert_{p,q} \geq \| f \|_{p,q}$. If $p = 1$ and $q < \infty$, if $\vvvert f \vvvert_{1,q} < \infty$, then $f = 0$, so these norms are effectively useless. If $q = \infty$, then
%
\[ \vvvert f \vvvert_{1,\infty} = \| f^* \|_{L^1[0,\infty)} = \| f \|_1, \]
%
and therefore doesn't measure the correct norm. But in all other cases, i.e. for $p > 1$ and $q \geq 1$, the norm is comparable to the $L^{p,q}$ norm.

\begin{theorem}
    If $p > 1$,
    %
    \[ \vvvert f \vvvert_{p,q} \leq \frac{p}{p-1} \| f \|_{p,q}. \]
\end{theorem}
\begin{proof}
    We utilize a \emph{Hardy's inequality} technique, which shows that the $L^p$ norm of the averages of a function are comparable to the $L^p$ norm of the function. Applying Minkowski's integral inequality, we conclude that
    %
    \begin{align*}
        \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} &= \left( \frac{q}{p} \int_0^\infty \left( \int_0^1 t^{1/p} f^*(ts)\; ds \right)^q\; \frac{dt}{t} \right)^{1/q}\\
        &\leq \int_0^1 \left( \int_0^\infty \frac{q}{p} (t^{1/p} f^*(ts))^q\; \frac{dt}{t} \right)^{1/q}\; ds\\
        &\leq \left( \int_0^1 s^{- 1/p}\; ds \right) \left( \frac{q}{p} \int_0^\infty (t^{1/p} f^*(t))^q\; \frac{dt}{t} \right)^{1/q}\\
        &\leq \frac{1}{1 - 1/p} \| f \|_{p,q} = \frac{p}{p - 1} \| f \|_{p,q}.
    \end{align*}
    %
    For $q = \infty$, and $t > 0$, we have
    %
    \begin{align*}
        t^{1/p} m(t) &= t^{1/p - 1} \int_0^t f^*(t)\\
        &\leq (\sup_{s > 0} s^{1/p} f^*(s)) t^{1/p - 1} \int_0^t t^{-1/p}\\
        &= \frac{1}{1 - 1/p} \| f \|_{p,\infty} = \frac{p}{p-1} \| f \|_{p,\infty}.
    \end{align*}
    %
    since $t$ was arbitrary, this gives the required bound.
\end{proof}

\end{comment}

\section{Mixed Norm Spaces}

Given two measure spaces $X$ and $Y$, we can form the product measure space $X \times Y$. If we have a norm space $V$ of functions on $X$, with norm $\| \cdot \|_V$ and a norm space $W$ of functions on $Y$, with norm $\| \cdot \|_W$, we can consider a `product norm'; for each function $f$ on $X \times Y$, we can consider the function $y \mapsto \| f(\cdot,y) \|_V$, and take the norm of this function over $Y$, i.e. $\| \| f(\cdot,y) \|_V \|_W$. The most important case of this process is where we fix $0 < p,q \leq \infty$, and consider
%
\[ \| f \|_{L^p(X) L^q(Y)} = \left( \int \left( \int |f(x,y)|^p \; dx \right)^{q/p}\; dy \right)^{1/q}. \]
%
Similarly, we can define $\| f \|_{L^q(Y) L^p(X)}$. Of course, in the case where Fubini's theorem can apply, if $p = q$ and does not equal $\infty$, we have
%
\[ \| f \|_{L^p(X) L^p(Y)} = \| f \|_{L^p(Y) L^p(X)} = \| f \|_{L^p(X \times Y)}. \]
%
If $p = q = \infty$, then

More generally, the biggest norm is always obtained with the largest exponents on the inside.

\begin{theorem}
	If $q \geq p$, $\| f \|_{L^p(X) L^q(Y)} \leq \| f \|_{L^q(Y) L^p(X)}$.
\end{theorem}
\begin{proof}
	We apply complex interpolation.
\end{proof}

\section{Orlicz Spaces}

To develop the class of Orlicz spaces, we note that if $\| f \|_p \leq 1$, and we set $\Phi(t) = t^p$, then
%
\[ \int \Phi \left( |f(x)| \right)\; dx = 1. \]
%
More generally, given any function $\Phi: [0,\infty) \to [0,\infty)$, we might ask if we can define a norm $\| \cdot \|_\Phi$ such that if $\| f \|_\Phi \leq 1$, then
%
\[ \int \Phi \left( |f(x)| \right)\; dx = 1. \]
%
Since a norm would be homogenous, this would imply that if $\| f \|_\Phi \leq A$, then
%
\[ \int \Phi \left( \frac{|f(x)|}{A} \right)\; dx \leq 1. \]
%
If we want these norms to be monotone, we might ask that if $A < B$, then
%
\[ \int \Phi \left( \frac{|f(x)|}{B} \right)\; dx \leq \int \Phi \left( \frac{|f(x)|}{A} \right), \]
%
and the standard way to ensure this is to ask the $\Phi$ is an increasing function. To deal with the property that $\| 0 \| = 0$, we set $\Phi(0) = 0$. In order for $\| \cdot \|_\Phi$ to be a norm, the set of functions $\{ f : \| f \|_\Phi \leq 1 \}$ needs to be convex, and the standard way to obtain this is to assume that $\Phi$ is convex.

In short, we consider an increasing, convex function $\Phi$ with $\Phi(0) = 0$. We then define
%
\[ \| f \|_\Phi = \inf \left\{ A > 0 : \int \Phi \left( \frac{|f(x)|}{A} \right)\; dx \leq 1 \right\}. \]
%
This function is a norm on the space of all $f$ with $\| f \|_\Phi < \infty$. It is easy to verify that $\| f \|_\Phi = 0$ if and only if $f = 0$ almost everywhere, and that $\| \alpha f \|_\Phi = |\alpha| \| f \|_\Phi$. To justify the triangle inequality, we note that if
%
\[ \int \Phi \left( \frac{|f(x)|}{A} \right) \leq 1 \quad\text{and} \quad \int \Phi \left( \frac{|f(x)|}{B} \right) \leq 1, \]
%
then applying convexity gives
%
\begin{align*}
    \int \Phi \left( \frac{|f(x) + g(x)|}{A + B} \right) &\leq \int \Phi \left( \frac{|f(x)| + |g(x)|}{A + B} \right)\\
    &\leq \int \left( \frac{A}{A + B} \right) \Phi \left( \frac{|f(x)|}{A} \right) + \left( \frac{B}{A + B} \right) \Phi \left( \frac{|g(x)|}{B} \right) \leq 1.
\end{align*}
%
Thus we obtain the triangle inequality.

The spaces $L^p(X)$ for $p \in [1,\infty)$ are Orlicz spaces with $\Phi(t) = t^p$. The space $L^\infty(X)$ is not really an Orlicz space, but it can be considered as the Orlicz function with respect to the `convex' function
%
\[ \Phi(t) = \begin{cases} \infty & t > 1, \\ t & t \leq 1. \end{cases} \]
%
More interesting examples of Orlicz spaces include
%
\begin{itemize}
    \item $L \log L$, given by the Orlicz norm induced by $\Phi(t) = t \log(2 + t)$.
    \item $e^L$, defined with respect to $\Phi(t) = e^t - 1$.
    \item $e^{L^2}$, defined with respect to $\Phi(t) = e^{t^2} - 1$.
\end{itemize}
%
One should not think too hard about the constants in the functions defined above, which are included to make $\Phi(0) = 0$. When we are dealing with a finite measure space, they are irrelevant.

\begin{lemma}
  If $\Phi(x) \lesssim \Psi(x)$ for all $x$, then $\| f \|_{\Phi(L)} \lesssim \| f \|_{\Psi(L)}$. If $X$ is finite, and $\Phi(x) \lesssim \Psi(x)$ for sufficiently large $x$, then $\| f \|_{\Phi(L)} \lesssim \| f \|_{\Psi(L)}$.
\end{lemma}
\begin{proof}
  The first proposition is easy, and we now deal with the finite case. We note that the condition implies that for each $\varepsilon > 0$, there exists $C_\varepsilon$ such that $\Phi(x) \leq C_\varepsilon \Psi(x)$ if $|x| \geq \varepsilon$. Assume that $\| f \|_{\Psi(L)} \leq 1$, so that
  %
  \[ \int \Psi(|f(x)|)\; dx \leq 1. \]
  %
  Then convexity implies that for each $A > 0$,
  %
  \[ \int \Psi \left( \frac{|f(x)|}{A} \right) \leq \frac{1}{A}. \]
  %
  Thus
  %
  \begin{align*}
    \int \Phi\left( \frac{|f(x)|}{A} \right)\; dx &\leq \Phi(\varepsilon) |X| + C_\varepsilon \int \Psi \left( \frac{|f(x)|}{A} \right)\\
    &\lesssim \Phi(\varepsilon) |X| + \frac{C_\varepsilon}{A}.
  \end{align*}
  %
  If $\Phi(\varepsilon) \leq 2/|X|$, and $A \geq 2C_\varepsilon$, then we conclude that
  %
  \[ \int \Phi\left( \frac{|f(x)|}{A} \right)\; dx \leq 1. \]
  %
  Thus $\| f \|_{\Phi(L)} \lesssim 1$.
\end{proof}

The Orlicz spaces satisfy an interesting duality relation. Given a function $\Phi$, which we assume is \emph{superlinear}, in the sense that $\Phi(x)/x \to \infty$ as $x \to \infty$, define it's \emph{Young dual}, for each $y \in [0,\infty)$, by
%
\[ \Psi(y) = \sup \{ xy - \Phi(x) : x \in [0,\infty) \}. \]
%
Then $\Psi$ is the smallest function such that $\Phi(x) + \Psi(y) \geq xy$ for each $x,y$. This quantity is finite for each $y$ because $\Phi$ is superlinear; for each $y \geq 0$, there exists $x(y)$ such that $\Phi(x(y)) \geq xy$, and thus the maximum of $xy - \Phi(x)$ is attained for $x \leq x(y)$. In particular, since $\Phi$ is continuous, the supremum is actually attained. Conversely, for each $x_0 \in [0,\infty)$, convexity implies there exists a largest $y$ such that the line $y(x - x_0) + f(x_0) \leq f(x)$ for all $x \in [0,\infty)$. This means that $\Psi(y) = x_0y - x_0$.

We note also that $\Psi(0) = 0$, and $\Psi$ is increasing. Most importantly, the function is convex. Given any $y,z \in [0,\infty)$, and any $x \in [0,\infty)$,
%
\begin{align*}
  x (\alpha y + (1 - \alpha) z) - \Phi(x) &\leq \alpha(xy - \Phi(x)) + (1 - \alpha)(xz - \Phi(x))\\
  &\leq \alpha \Psi(y) + (1 - \alpha) \Psi(z).
\end{align*}
%
Taking infimum over all $x$ gives convexity. The function $\Psi$ is also superlinear, since for any $x \in [0,\infty)$,
%
\[ \lim_{y \to \infty} \frac{\Psi(y)}{y} \geq \lim_{y \to \infty} \frac{xy - \Phi(x)}{y} = x. \]
%
In particular, we can consider the Young dual of $\Psi$.

\begin{lemma}
  If $\Psi$ is the Young dual of $\Phi$, then $\Phi$ is the Young dual of $\Psi$.
\end{lemma}
\begin{proof}
  $\Pi$ is the smallest function such that $\Pi(x) + \Psi(y) \geq xy$. Since $\Phi(x) + \Psi(y) \geq xy$ for each $x$ and $y$, we conclude that $\Pi(x) \leq \Phi(x)$ for each $x$. For each $x$, there exists $y$ such that $\Psi(y) = yx - \Phi(x)$. But this means that $\Phi(x) = yx - \Psi(y) \leq \Pi(x)$.
\end{proof}

Given the Orlicz space $\Phi(L)$ for superlinear $\Phi$, we can consider the Orlicz space $\Psi(L)$, where $\Psi$ is the Young dual of $\Phi$. The inequality $xy \leq \Phi(x) + \Psi(y)$, then
%
\[ |f(x) g(x)| \leq \Phi(|f(x)|) + \Psi(|g(x)|), \]
%
so if $\| f \|_{\Phi(L)}, \| g \|_{\Psi(L)} \leq 1$, then
%
\[ \left| \int f(x) g(x) \right| \leq \int |f(x)| |g(x)| \leq \int \Phi(|f(x)|) + \int \Psi(|g(x)|) \leq 2. \]
%
Thus in general, we have
%
\[ \left| \int f(x) g(x) \right| \leq 2 \| f \|_{\Phi(L)} \| g \|_{\Psi(L)}, \]
%
a form of H\"{o}lder's inequality. The duality between convex functions extends to a duality between the Orlicz spaces.

\begin{theorem}
  For any superlinear $\Phi$ with Young dual $\Psi$,
  %
  \[ \| f \|_{\Phi(L)} \sim \sup \left\{ \int fg : \| g \|_{\Psi(L)} \leq 1 \right\}. \]
\end{theorem}
\begin{proof}
  Without loss of generality, assume $\| f \|_{\Phi(L)} = 1$. The version of H\"{o}lder's inequality proved above shows that
  %
  \[ \| f \|_{\Phi(L)} \lesssim 1. \]
  %
  Conversely, for each $x$, we can find $g(x)$ such that $f(x) g(x) = \Phi(|f(x)|) + \Psi(|g(x)|$. Provided $\| g \|_{\Psi(L)} < \infty$, we have
  %
  \[ \int fg = \int \Phi(|f(x)|) + \int \Psi(|g(x)|) \geq 1 + \| g \|_{\Psi(L)}. \]
  %
  Assuming $f \in L^\infty(X)$, we may choose $g \in L^\infty(X)$. For such a choice of function, $\| g \|_{\psi(L)} < \infty$, which implies the result. Taking an approximation argument then gives the result in general.
\end{proof}

Let us now consider some examples of duality.

\begin{example}
  If $\Phi(x) = x^p$, for $p \geq 1$, and $1 = 1/p + 1/q$, then it's Young dual $\Psi$ satisfies
  % q = p/(p-1)
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - x^p = y^{1 + q/p} / p^{q/p} - y^q / p^q = y^q [p^{-q/p} - p^{-q}].
  \end{align*}
  %
  Thus the Young dual corresponds, up to a constant, to the conjugate dual in the $L^p$ spaces.
\end{example}

\begin{example}
  Suppose $X$ has finite measure. If $\Phi(t) = e^t - 1$, then it's dual satisfies, for large $y$,
  %
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - (e^x - 1)\\
    &= y \log y - (y - 1) \sim y \log y.
  \end{align*}
  %
  This is comparable to $y \log (y + 2)$ for large $y$. Thus $L \log L$ is dual to $e^L$.
\end{example}

\begin{example}
  Suppose $X$ has finite measure. If $\Phi(x) = e^{x^2} - 1$, then for $y \geq 2$,
  %
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - (e^{x^2} - 1) \sim y \log(y/2)^{1/2}.
  \end{align*}
  %
  Thus the dual of $e^{L^2}$ is the space $L (\log L)^{1/2}$.
\end{example}

There is a generalization of both the Lorentz spaces and the Orlicz spaces, known as the Lorentz-Orlicz spaces, but these come up so rarely in analysis that we do not dwell on these norms.














\chapter{Interpolation Theory}

One of the most fundamental tools in the `hard style' of mathematical analysis, involving explicit quantitative estimates on quantities that arises in basic methods of mathematics, is the theory of interpolation. The main goal of interpolation is to take two estimates, and blend them together to form a family of intermediate estimates. Often each estimate will focus on one component of the problem at hand (an estimate in terms of the decay of the function at $\infty$, an estimate involving the growth of the derivative, or the low frequency the function is, etc). By interpolating, we can optimize and obtain an estimate which simultaneously takes into account multiple features of the function. As should be expected, our main focus will be on the \emph{interpolation of operators}.

\section{Convex Interpolation}

The most basic way to interpolate is using the notion of convexity. Given two inequalities $A_0 \leq B_0$ and $A_1 \leq B_1$, for any parameter $0 \leq \theta \leq 1$, if we define the additive weighted averages $A_\theta = (1 - \theta) A_0 + \theta A_1$ and $B_\theta = (1 - \theta) B_0 + \theta B_1$, then we conclude $A_\theta \leq B_\theta$ for all $\theta$. Similarily, we can consider the weighted multiplicative averages $A_\theta = A_0^{1 - \theta} A_1^\theta$ and $B_\theta = B_0^{1 - \theta}B_1^\theta$, in which case we still have $A_\theta \leq B_\theta$. Note that the additive averages are obtained by taking the unique linear function between two values, and the multiplicative averages are obtained by taking the unique log-linear function between two values. In particular, if $A_\theta$ is defined to be any convex function, then $A_\theta \leq (1 - \theta) A_0 + \theta A_1$, and if $B_\theta$ is logarithmically convex, so that $\log B_\theta$ is convex, then $B_\theta \leq B_0^{1 - \theta} B_1^\theta$. Thus convexity provides us with a more general way of interpolating estimates, which is what makes this property so useful in analysis, enabling us to simplify estimates.

\begin{example}
    For a fixed, measurable function $f$, the map $p \mapsto \| f \|_p$ is a log convex function. This statement is precisely H\"{o}lder's inequality, since the inequality
    %
    \[ \| f \|_{\theta p + (1 - \theta) q} \leq \| f \|_p^\theta \| f \|_{q}^{1-\theta} \]
    %
    says
    %
    \[ \| |f|^{\theta p} |f|^{(1 - \theta) q} \|_1^{1/(\theta p + (1 - \theta) q)} \leq \| f^{\theta p} \|_{1/\theta}^{\theta} \| f^{(1-\theta)q} \|_{1/(1-\theta)}^{1-\theta} \]
    %
    which is precisely H\"{o}lder's inequality. Note this implies that if $p_0 < p_\theta < p_1$, then $L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X)$.
\end{example}

\begin{example}
    The weak $L^p$ norm is log convex, because if $F(t) \leq A_0^{p_0}/t^{p_0}$, and $F(t) \leq A_1^{p_1}/t^{p_1}$, then we can apply scalar interpolation to conclude that if $p_\theta = (1 - \alpha) p_0 + \alpha p_1$,
    %
    \[ F(t) \leq \frac{A_0^{(1 - \alpha) p_0}A_1^{\alpha p_1}}{t^{(1 - \alpha)p_0 + \alpha p_1}} = \frac{A_\theta^{p_\theta}}{t^{p_\theta}} \]
    %
    where $p_\theta$ is the harmonic weighted average between $p_0$ and $p_1$, and $A_\theta$ the geometric weighted average. Using this argument, interpolating slightly to the left and right of $p_\theta$, we can conclude that if $p_0 < p_\theta < p_1$, then $L^{p_0,\infty}(X) \cap L^{p_1,\infty}(X) \subset L^{p_\theta}(X)$.
\end{example}

\section{Complex Interpolation}

Another major technique to perform an interpolation is to utilize the theory of complex analytic functions to obtain estimates. The core idea of this technique is to exploit the maximum principle, which says that bounding an analytic function at its boundary enables one to obtain bounds everywhere in the domain of the function. The next result, known as Lindel\"{o}f's theorem, is one of the fundamental examples of the application of complex analysis.

\begin{theorem}[The Three Lines Lemma]
    If $f$ is a holomorphic function on the strip $S = \{ z : \text{Re}(z) \in [a,b] \}$ and there exists constants $A,B,\delta > 0$ such that for all $z \in S$,
    %
    \[ |f(z)| \leq Ae^{Be^{(\pi - \delta)|z|}}. \]
    %
    Then the function $M: [a,b] \to [0,\infty]$ given by
    %
    \[ M(s) = \sup_{s \in \RR} |f(s + it)| \]
    %
    is log convex on $[a,b]$.
\end{theorem}
\begin{proof}
    By a change of variables, we can assume that $a = 0$, and $b = 1$, and we need only show that if there are $A_0, A_1 > 0$ such that
    %
    \[ |f(it)| \leq A_0 \quad\text{and}\quad |f(1 + it)| \leq A_1 \quad \text{for all $t \in \RR$}, \]
    %
    then for any $s \in [a,b]$ and $t \in \RR$,
    %
    \[ |f(s + it)| \leq A_0^{1 - s} A_1^s. \]
    %
    By replacing $f(z)$ with the function $A_0^{1-z} A_1^z f(z)$, we may assume without loss of generality that $A_0 = A_1 = 1$, and we must show that $\| f \|_{L^\infty(S)} \leq 1$. If $|f(s + it)| \to 0$ as $|t| \to \infty$, then for large $N$, we can conclude that $|f(s + it)| \leq 1$ for $s \in [a,b]$ and $|t| \geq N$. But then the maximum principle entails that $|f(s + it)| \leq 1$ for $s \in [a,b]$ and $|t| \leq N$, which completes the proof in this case. In the general case, for each $\varepsilon > 0$, define
    %
    \[ u_\varepsilon(z) = \exp(- 2 \varepsilon \sin((\pi - \varepsilon) z + \varepsilon/2)). \]
    %
    Then if $z = s + it$,
    %
    \[ |u_\varepsilon(z)| = \exp(- \varepsilon [e^{(\pi - \varepsilon) t} + e^{-(\pi - \varepsilon) t}] \sin((\pi - \varepsilon) s + \varepsilon/2)), \]
    %
    So, in particular, $|u_\varepsilon(z)| \leq 1$, and there exists a constant $C$ such that if $z \in S$,
    %
    \[ |u_\varepsilon(z)| \leq e^{- C \varepsilon^2 e^{(\pi - \varepsilon) |z|}} \]
    %
    Note that if $\varepsilon < \delta$, then as $|\text{Im}(z)| \to \infty$,
    %
    \[ |f(z) u_\varepsilon(z)| \leq A e^{B e^{(\pi - \delta) |z|} - C \varepsilon^2 e^{(\pi - \varepsilon) |z|} } \to 0. \]
    %
    Applying the previous case to the function $|f(z) u_\varepsilon(z)|$, we conclude that for any $\varepsilon > 0$,
    %
    \[ |f(z)| \leq \frac{1}{|u_\varepsilon(z)|}. \]
    %
    Thus
    %
    \[ |f(z)| \leq \lim_{\varepsilon \to 0} \frac{1}{|u_\varepsilon(z)|} = 1, \]
    %
    which completes the proof.
\end{proof}

\begin{remark}
    The function $e^{-ie^{\pi i s}}$ shows that the assumption of the three lines lemma is essentially tight. In particular, this means there is no family of holomorphic functions $g_\varepsilon$ which decays faster than double exponentially, and pointwise approximates the identity as $\varepsilon \to 0$.
\end{remark}

\begin{remark}
    Similar variants can be used to show that if $f$ is a holomorphic function on an annulus, then the supremum over circles centered around the origin is log convex in the radius of the circle (a result often referred to as the three circles lemma).
\end{remark}

\begin{example}
    Here we show how we can use the three lines lemma to prove that the $L^p$ norms are log convex. If $f = \sum a_n \chi_{E_n}$ is a simple function, then the function
    %
    \[ g(s) = \int |f|^s = \sum |a_n|^s |E_n| \]
    %
    is analytic in $s$, and satisfies the growth condition of the three lines lemma because each term of the sum is exponential in growth. Since $|g(s)| \leq |g(\sigma)|$, the three lines lemma implies that $g$ is log convex on the real line. By normalizing the function $f$ and the underlying measure, given $p_0$, $p_1$, we may assume $\| f \|_{p_0} = \| f \|_{p_1} = 1$, and it suffices to prove that $\| f \|_{p_\theta} \leq 1$ for all $p_\theta \in [p_0, p_1]$. But the log convexity of $g$ guarantees this is true, since $|g(p)| = \| f \|_p^p$. A standard limiting argument then gives the inequality for all functions $f$.
\end{example}

\begin{example}
    Let $f$ be a holmomorphic function on a strip $S = \{ z : \text{Re}(z) \in [a,b] \}$, such that if $z = a + it$, or $z = b + it$, for some $t \in \RR$,
    %
    \[ |f(z)| \leq C_1 (1 + |z|)^\alpha. \]
    %
    Then there exists a constant $C'$ such that for any $z \in S$,
    %
    \[ |f(z)| \leq C_2 (1 + |z|)^\alpha. \]
\end{example}
\begin{proof}
    The function
    %
    \[ g(z) = \frac{f(z)}{(1 + z)^\alpha} \]
    %
    is holomorphic on $S$, and if $z = a + it$ or $z = b + it$,
    %
    \[ |g(z)| \leq \frac{C_1 (1 + |z|)^\alpha}{|1 + z|^\alpha} \lesssim 1. \]
    %
    Thus the three lines lemma implies that $|g(z)| \lesssim 1$ for all $z \in S$, so
    %
    \[ |f(z)| \lesssim |1 + z|^\alpha \lesssim (1 + |z|)^\alpha. \qedhere \]
\end{proof}

\section{Interpolation of Operators}

A major part of modern harmonic analysis is the study of operators, i.e. maps from function spaces to other function spaces. We are primarily interested in studying \emph{linear operators}, i.e. operators $T$ such that $T(f + g) = T(f) + T(g)$, and $T(\alpha f) = \alpha T(f)$, and also \emph{sublinear operators}, such that $|T(\alpha f)| = |\alpha| |T(f)|$ and $|T(f + g)| \leq |Tf| + |Tg|$. Even if we focus on linear operators, it is still of interest to study sublinear operators because one can study the \emph{uniform boundedness} of a family of operators $\{ T_k \}$ by means of the function $T^*(f)(x) = \max (T_k f)(x)$. This is the method of \emph{maximal functions}. Another important example are the $l^p$ sums
%
\[ (S^p f)(x) = \left( \sum |T_k(x)|^p \right). \]
%
These two examples are specific examples where we have a family of operators $\{ T_y \}$, indexed by a measure space $Y$, and we define an operator $S$ by taking $Sf$ to be the norm of $\{ T_y f \}$ in the variable $y$.

Here we address the most basic case of operator interpolation. As we vary $p$, the $L^p$ norms provide different ways of measuring the height and width of functions. Let us consider a simple example. Suppose that for an operator $T$, we have a bound
%
\[ \| Tf \|_{L^1(Y)} \leq \| f \|_{L^1(X)} \quad\text{and}\quad \| Tf \|_{L^\infty(Y)} \leq \| f \|_{L^\infty(X)}. \]
%
The first inequality shows that the width of $Tf$ is controlled by the width of $f$, and the second inequality says the height of $Tf$ is controlled by the height of $f$. If we take a function $f \in L^p(X)$, for some $p \in (1,\infty)$, then we have some control over the height of $f$, and some control of the width. In particular, this means we might expect some control over the width and height of $Tf$, i.e. for each $p$, a bound
%
\[ \| Tf \|_{L^p(Y)} \leq \| f \|_{L^p(X)}. \]
%
This is the idea of interpolation on the $L^p(X)$ spaces.

\section{Complex Interpolation of Operators}

The first theorem we give is the Riesz-Thorin theorem, which utilizes complex interpolation to give such a result. In the next theorem, we work with a linear operator $T$ which maps simple functions $f$ on a measure space $X$ to functions on a measure space $Y$. For the purposes of applying duality, we make the mild assumption that for each simple function $g$,
%
\[ \int |(Tf)(y)| |g(y)|\; dy < \infty. \]
%
Our goal is to obtain $L^p$ bounds on the function $T$. The Hahn-Banach theorem then guarantees that $T$ has a unique extension to a map defined on all $L^p$ functions.

\begin{theorem}[Riesz-Thorin]
    Let $p_0,p_1 \in (0,\infty]$ and $q_0,q_1 \in [1,\infty]$. Suppose that
    %
    \[ \| Tf \|_{L^{q_0}(Y)} \leq A_0 \| f \|_{L^{p_0}(X)} \quad \text{and} \| Tf \|_{L^{q_1}(Y)} \leq A_1 \| f \|_{L^{p_1}(X)}.  \]
    %
    Then for any $\theta \in (0,1)$, if
    %
    \[ 1/p_\theta = (1 - \theta)/p_0 + \theta/p_1 \quad\text{and}\quad 1/q_\theta = (1 - \theta)/q_0 + \theta/q_1, \]
    %
    then
    %
    \[ \| Tf \|_{L^{q_\theta}(Y)} \leq A_\theta \| f \|_{L^{p_\theta}(X)}, \]
    %
    where $A_\theta = A_0^{1 - \theta} A_1^\theta$.
\end{theorem}
\begin{proof}
    If $p_0 = p_1$, the proof follows by the log convexity of the $L^p$ norms of a function. Thus we may assume $p_0 \neq p_1$, so $p_\theta$ is finite in any case of interest. By normalizing the measures on both spaces, we may assume $A_0 = A_1 = 1$. By duality and homogeneity, it suffices to show that for any two simple functions $f$ and $g$ such that $\| f \|_{q_\theta} = \| g \|_{q_\theta^*} = 1$,
    %
    \[ \left| \int_Y (Tf) g\; dy \right| \leq 1. \]
    %
    Our challenge is to make this inequality complex analytic so we can apply the three lines lemma. We write $f = F_0^{1 - \theta} F_1^\theta a$, where $F_0$ and $F_1$ are non-negative simple functions with $\| F_0 \|_{L^{p_0}(X)} = \| F_1 \|_{L^{p_1}(X)} = 1$, and $a$ is a simple function with $|a(x)| = 1$. Similarily, we can write $g = G_0^{1-\theta} G_1^\theta b$. We now write
    %
    \[ H(s) = \int_Y T(F_0^{1 - s} F_1^s a) G_0^{1-s} G_1^s b\; dy. \]
    %
    Since all functions involved here are simple, $H(s)$ is a linear combination of positive numbers taken to the power of $1-s$ or $s$, and is therefore obviously an entire function in $s$. Now for all $t \in \RR$, we have
    %
    \[ \| F_0^{1-it} F_1^{it} a \|_{L^{p_0}(X)} = \| F_0 \|_{L^{p_0}(X)} = 1, \]
    \[ \| G_0^{1-it} G_1^{it} b \|_{L^{q_0}(Y)} = \| G_0 \|_{L^{q_0}(X)} = 1. \]
    %
    Therefore
    %
    \begin{align*}
      |H(it)| &= \left| \int T(F_0^{1 - it} F_1^{it} a) G_0^{1-it} G_1^{it} b\; dy \right| \leq 1.
    \end{align*}
    %
    Similarily, $|H(1 + it)| \leq 1$ for all $t \in \RR$. An application of Lindel\"{o}f's theorem implies $|H(s)| \leq 1$ for all $s$. Setting $s = \theta$ completes the argument.
\end{proof}

If, for each $p,q$, we let $F(1/p,1/q)$ to be the operator norm of a linear operator $T$ viewed as a map from $L^p(X)$ to $L^q(Y)$, then the Riesz-Thorin theorem says that $F$ is a log-convex function. In particular, the set of $(1/p,1/q)$ such that $T$ is bounded as a map from $L^p(X)$ to $L^q(Y)$ forms a convex set. If this is true, we often say $T$ is of \emph{strong type} $(p,q)$.

\begin{example}
  For any two integrable functions $f,g \in L^1(\RR^d)$, we can define an integrable function $f * g \in L^1(\RR^d)$ almost everywhere by the integral formula
  %
  \[ (f * g)(x) = \int f(y) g(x-y)\; dy. \]
  %
  If $f \in L^1(\RR^d)$ and $g \in L^p(\RR^d) \cap L^1(\RR^d)$, for some $p \geq 1$, then Minkowski's integral inequality implies
  %
  \begin{align*}
      \| f * g \|_p &= \left( \int |(f * g)(x)|^p\; dx \right)^{1/p} \leq \int \left( \int |f(y)g(x-y)|^p dx\; \right)^{1/p} dy\\
      &= \int |f(y)| \| g \|_{L^p(\RR^d)} = \| f \|_{L^1(\RR^d)} \| g \|_{L^p(\RR^d)}.
  \end{align*}
  %
  H\"{o}lder's inequality implies that if $f \in L^p(\RR^d)$ and $g \in L^q(\RR^d)$, where $p$ and $q$ are conjugates of one another, then
  %
  \begin{align*}
    \left| \int f(y) g(x-y)\; dy \right| \leq \int |f(y-x)| |g(x)| \leq \| f \|_{L^p(\RR^d)} \| g \|_{L^q(\RR^d)}.
  \end{align*}
    %
    Thus we have the bound
    %
    \[ \| f * g \|_{L^\infty(\RR^d)} \leq \| f \|_{L^p(\RR^d)} \| g \|_{L^q(\RR^d)}. \]
    %
    Now that these mostly trivial results have been proved, we can apply convolution. For each $f \in L^1(\RR^d) \cap L^p(\RR^d)$, we have a convolution operator $T: L^1(\RR^d) \to L^1(\RR^d)$ defined by $Tg = f * g$. We know that $T$ is of strong type $(1,p)$, and of type $(q,\infty)$, where $q$ is the harmonic conjugate of $p$, and $T$ has operator norm $1$ with respect to each of these types. But the Riesz Thorin theorem then implies that if $1/r = \theta + (1 - \theta)/q$, then $T$ is bounded as a map from $L^r(\RR^d)$ to $L^{p/\theta}(\RR^d)$ with operator norm one. Reparameterizing gives \emph{Young's convolution inequality}. Note that we never really used anything about $\RR^d$ here other than it's translational structure, and as such Young's inequality continues to apply in the theory of any modular locally compact group. In particular, the Haar measure $\mu$ on such a group is only defined up to a scalar multiple, and if we swap $\mu$ with $\alpha \mu$, for some $\alpha > 0$, then Young's inequality for this measure implies
    %
    \[ \lambda^{1 + 1/r} \| f * g \|_r = \lambda^{1/p + 1/q} \| f \|_p \| g \|_p \]
    %
    which is a good way of remembering that we must have $1 + 1/r = 1/p + 1/q$. 
\end{example}

\begin{example}
Let $X$ be a measure space with $\sigma$ algebra $\Sigma_0$, and let $\Sigma \subset \Sigma_0$ be a $\sigma$ finite sub $\sigma$ algebra. Then $L^2(X,\Sigma)$ is a closed subspace of $L^2(X,\Sigma_0)$, and so there is an orthogonal projection operator $\EE(\cdot|\Sigma): L^2(X,\Sigma_0) \to L^2(X,\Sigma)$, which we call the \emph{conditional expectation operator}. The properties of the projection operator imply that for any $f,g \in L^2(X, \Sigma_0)$,
%
\[ \int \EE(f|\Sigma) \overline{g} = \int f \overline{g} = \int \EE(f|\Sigma) \overline{\EE(g|\Sigma)}. \]
%
If $g \in L^2(X,\Sigma)$, then
%
\[ \int \EE(f|\Sigma) \overline{g} = \int f \overline{g}. \]
%
This gives a full description of $\EE(f|\Sigma)$. In particular, if $u \in L^\infty(X,\Sigma_0)$, then for each $g \in L^2(X,\Sigma)$
%
\[ \int \EE(uf|\Sigma) \overline{g} = \int f [u\overline{g}] = \int u \EE(f|\Sigma) \overline{g}. \]
%
Since this is true for all $g \in L^2(X,\Sigma)$, we find $\EE(uf|\Sigma) = u \EE(f|\Sigma)$. Moreover, if $0 \leq f \leq g$, then $\EE(f|\Sigma) \leq \EE(g|\Sigma)$. This is easy to see because if $f \geq 0$, and $F = \{ x : \EE(f|\Sigma) < 0 \}$, then if $|F| \neq 0$,
%
\[ 0 > \int \EE(f|\Sigma) \mathbf{I}_F = \int f \mathbf{I}_F \geq 0. \]
%
Thus $|F| = 0$, and so $\EE(f|\Sigma) \geq 0$ almost everywhere.

Like all other orthogonal projection operators, conditional expectation is a contraction in the $L^2$ norm, i.e. $\| \mathbf{E}(f|\Sigma) \|_{L^2(X)} \leq \| f \|_{L^2(X)}$. We now use interpolation to show that conditional expectation is strong $(p,p)$, for all $1 \leq p \leq \infty$. It suffices to prove the operator is strong $(1,1)$ and strong $(\infty,\infty)$. So suppose $f \in L^2(X,\Sigma_0) \cap L^\infty(X,\Sigma_0)$. If $|E| < \infty$, then $\mathbf{I}_E \in L^2(X)$, so
%
\[ |\EE(f|\Sigma)| \mathbf{I}_E = |\EE(\mathbf{I}_E f | \Sigma)| \leq \EE(\mathbf{I}_E |f| | \Sigma) \leq \| f \|_\infty \mathbf{E}(\mathbf{I}_E|\Sigma) = \| f \|_\infty \mathbf{I}_E. \]
%
Since $\Sigma$ is a sigma finite sigma algebra, we can take $E \to \infty$ to conclude $\| \EE(f|\Sigma) \|_\infty \leq \| f \|_\infty$. The case $(1,1)$ can be obtained by duality, since conditional expectation is self adjoint, or directly, since if $f \in L^1(X,\Sigma_0) \cap L^2(X,\Sigma_0)$, then for any set $E \in \Sigma$ with $|E| < \infty$,
%
\[ \int |\EE(f|\Sigma)| \mathbf{I}_E \leq \int \EE(|f||\Sigma) \mathbf{I}_E = \int_E |f| \mathbf{I}_E \leq \| f \|_1. \]
%
Since $\Sigma$ is $\sigma$ finite, we can take $E \to \infty$ to conclude $\| \EE(f|\Sigma) \|_1 \leq \| f \|_1$. Thus the Riesz interpolation theorem implies that for each $1 \leq p \leq \infty$, $\| \EE(f|\Sigma) \|_p \leq \| f \|_p$.

Since $L^2(X,\Sigma_0)$ is dense in $L^p(X,\Sigma_0)$ for all $1 \leq p < \infty$, there is a unique extension of the conditional expectation operator from $L^p(X,\Sigma_0)$ to $L^p(X,\Sigma_0)$. For $p = \infty$, there are infinitely many extensions of the conditional expectation operator from $L^\infty(X,\Sigma_0)$ to $L^\infty(X,\Sigma_0)$. However, there is a \emph{unique} extension such that for each $f \in L^2(\Sigma_0)$ and $g \in L^\infty(\Sigma)$, $\EE(fg|\Sigma) = g \EE(f|\Sigma)$. This is because for any $E \in \Sigma$ with $|E| < \infty$, $\EE(f \mathbf{I}_E | \Sigma) = \mathbf{I}_E \EE(f|\Sigma)$ is uniquely defined since $f \mathbf{I}_E \in L^2(\Sigma_0)$, and taking $E \to \infty$ by $\sigma$ finiteness.

A simple consequence of the uniform boundedness of these operators on the various $L^p$ spaces is that if $\Sigma_1, \Sigma_2, \dots$ are a family of $\sigma$ algebras, and $\Sigma_\infty$ is the smallest $\sigma$ algebra containing all sets in $\bigcup_{i = 1}^\infty \Sigma_i$, then for each $1 \leq p < \infty$, and for each $f \in L^p(\Sigma_0)$, $\lim_{i \to \infty} \EE(f|\Sigma_i) = \EE(f|\Sigma_\infty)$. This is because the operators $\{ \EE(\cdot|\Sigma_i) \}$ are uniformly bounded. The limit equation holds for any simple function $f$ composed of sets in $\bigcup_{i = 1}^\infty \Sigma_i$, and a $\sigma$ algebra argument can then be used to show this family of simple functions is dense in $L^p(\Sigma_0)$.
\end{example}

It was an important observation of Elias-Stein that complex interpolation can be used not only with a single operator $T$, but with an `analytic family' of operators $\{ T_s \}$, one for each $s$, such that for each pair of simple functions $f$ and $g$, the function
%
\[ \int (T_s f)(y) g(y) \]
%
is analytic in $s$. Thus bounds on $T_{0+it}$ and $T_{1 + it}$ imply intermediary bounds on all other operators, provided that we still have at most doubly exponential growth. The next theorem gives an example application.

\begin{theorem}[Stein-Weiss Interpolation Theorem]
  Let $T$ be a linear operator, and let $w_0, w_1: X \to [0,\infty)$ and $v_0, v_1 : Y \to [0,\infty)$ be weights which are integrable on every finite-measure set. Suppose that
  %
  \[ \| Tf \|_{L^{q_0}(X,v_0)} \leq A_0 \| f \|_{L^{p_0}(X,w_0)}\quad\text{and}\quad \| Tf \|_{L^{q_1}(X,v_1)} \leq A_1 \| f \|_{L^{p_1}(X,w_0)}. \]
  %
  Then for any $\theta \in (0,1)$,
  %
  \[ \| Tf \|_{L^{q_\theta}(X,v_\theta)} \leq A_\theta \| f \|_{L^{p_\theta}(X,w_\theta)}, \]
  %
  where $w_\theta = w_0^{1-\theta} w_\theta$ and $v_\theta = v_0^{1-\theta} v_1^\theta$.
\end{theorem}
\begin{proof}
  Fix a simple function $f$ with $\| f \|_{L^{p_\theta}(X,w_\theta)}$. We begin with some simplifying assumptions. A monotone convergence argument, replacing $w_i(t)$ with
  %
  \[ w_i'(y) = \begin{cases} w_i(y) &: \varepsilon \leq w_i(t) \leq 1/\varepsilon, \\ 0 &: \text{otherwise}, \end{cases} \]
  %
  and then taking $\varepsilon \to 0$, enables us to assume without loss of generality that $w_0$ and $w_1$ are both bounded from below and bounded from above. Truncating the support of $Tf$ enables us to assume that $Y$ has finite measure. Since $f$ has finite support, we may also assume without loss of generality that $X$ has finite support, and by applying the dominated convergence theorem we may replace the weights $v_i$ with
  %
  \[ v_i'(x) = \begin{cases} v_i(x) &: \varepsilon \leq v_i(x) \leq 1/\varepsilon, \\ 0 &: \text{otherwise}, \end{cases} \]
  %
  and then take $\varepsilon \to 0$. Thus we can assume that the $v_i$ are bounded from above and below. Restricting to the support of $X$, we can also assume $X$ has finite measure.

  For each $s$, consider the operator $T_s$ defined by
  %
  \[ T_s f = w_0^{\frac{1-s}{q_0}} w_1^{\frac{s}{q_1}} T \left( f v_0^{- \frac{1-s}{p_0}} v_1^{-\frac{s}{p_1}} \right). \]
  %
  The fact that all functions involved are simple means that the family of operators $\{ T_s \}$ is analytic. Now for all $t \in \RR$
  %
  \[ \| T_{it} f \|_{L^{q_0}(Y)} = \| T f \|_{L^{q_0}(Y,w_0)} \leq A_0 \| f v_0^{-1/p_0} \|_{L^{p_0}(X,v_0)} = A_0 \| f \|_{L^{p_0}(X)}. \]
  %
  For similar reasons, $\| T_{1 + it} f \|_{L^{q_1}(Y)} \leq A_1 \| f \|_{L^{p_0}(X,v_0)}$. Thus the Stein variant of the Riesz-Thorin theorem implies that
  %
  \[ \| T_\theta f \|_{L^{q_\theta}(Y)} \leq A_\theta \| f \|_{L^{p_\theta}(X)}. \]
  %
  But this, of course, is equivalent to the bound we set out to prove.
\end{proof}

\section{Real Interpolation of Operators}

Now we consider the case of real interpolation. One advantage of real interpolation is that it can be applied to sublinear as well as linear operators, and requires weaker endpoint estimates that the complex case. A disadvantage is that, usually, the operator under study cannot vary, and we lose out on obtaining explicit bounds.

A strong advantage to using real interpolation is that the criteria for showing boundedness at the endpoints can be reduced considerably. Let us give names for the boundedness we will want to understand for a particular operator $T$.
%
\begin{itemize}
  \item We say $T$ is \emph{strong type} $(p,q)$ if $\| Tf \|_{L^q(Y)} \lesssim \| f \|_{L^p(X)}$.
  
  \item We say $T$ is \emph{weak type} $(p,q)$ if $\| Tf \|_{L^{q,\infty}(Y)} \lesssim \| f \|_{L^p(X)}$.

  \item We say $T$ is \emph{restricted strong type} $(p,q)$ if we have a bound
  %
  \[ \| Tf \|_{L^q(Y)} \lesssim HW^{1/p} \]
  %
  for any sub-step functions with height $H$ and width $W$. Equivalently, for any set $E$,
  %
  \[ \| T(\mathbf{I}_E) \|_{L^q(Y)} \lesssim |E|^{1/p}. \]

  \item We say $T$ is \emph{restricted weak type} $(p,q)$ if we have a bound
  %
  \[ \| Tf \|_{L^{q,\infty}(Y)} \lesssim HW^{1/p} \]
  %
  for all sub-step functions with height $H$ and width $W$. Equivalently, for any set $E$,
  %
  \[ \| T(\mathbf{I}_E) \|_{L^{q,\infty}(Y)} \lesssim |E|^{1/p}. \]
\end{itemize}
%
An important tool for us will be to utilize duality to make our interpolation argument `bilinear'. Let us summarize this tool in a lemma. Proving the lemma is a simple application of Theorem \ref{weakdualitytheorem}.

\begin{lemma}
  Let $0 < p < \infty$ and $0 < q < \infty$. Then an operator $T$ is restricted weak-type $(p,q)$ if and only if for any finite measure sets $E \subset X$ and $F \subset Y$, there is $F' \subset Y$ with $|F'| \geq \alpha |F|$ such that
  %
  \[ \int_{F'} |T(\mathbf{I}_E)| \lesssim_\alpha |E|^{1/p} |F|^{1-1/q}. \]
\end{lemma}

Scalar interpoation leads to a simple version of real interpolation, which we employ as a subroutine to obtain a much more powerful real interpolation principle.

\begin{lemma}
  Let $0 < p_0,p_1 < \infty$, $0 < q_0,q_1 < \infty$. If $T$ is restricted weak type $(p_0,q_0)$ and $(p_1,q_1)$, then $T$ is restricted weak type $(p_\theta,q_\theta)$ for all $\theta \in (0,1)$.
\end{lemma}
\begin{proof}
  By assumption, if $E \subset X$ and $F \subset Y$, then there is $F_0, F_1 \subset Y$ with $|F_i| \geq (3/4)|F|$ such that
  %
  \[ \int_{F_i} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_i} |F_i|^{1 - 1/q_i}. \]
  %
  If we let $F_\theta = F_0 \cap F_1$, then $|F_\theta| \geq |F|/2$, and for each $i$,
  %
  \[ \int_{F_\theta} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_i} |F_\theta|^{1 - 1/q_i}. \]
  %
  Scalar interpolation implies
  %
  \[ \int_{F_\theta} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_\theta} |F_\theta|^{1 - 1/q_\theta}, \]
  %
  and thus we have shown
  %
  \[ \| T(\mathbf{I}_E) \|_{q_\theta,\infty} \lesssim |E|^{1/p_\theta}. \]
  %
  This is sufficient to show $T$ is restricted weak type $(p_\theta,q_\theta)$.
\end{proof}

\begin{theorem}[Marcinkiewicz Interpolation Theorem]
  Let $0 < p_0,p_1 < \infty$, $0 < q_0,q_1 < \infty$, and suppose $T$ is restricted weak type $(p_i,q_i)$, with constant $A_i$, for each $i$. Then, for any $\theta \in (0,1)$, if $q_\theta > 1$, then for any $0 < r < \infty$, then
  %
  \[ \| Tf \|_{L^{q_\theta,r}(Y)} \lesssim A_\theta \| f \|_{L^{p_\theta,r}(X)}, \]
  %
  with implicit constants depending on $p_0, p_1, q_0$, and $q_1$.
\end{theorem}
\begin{proof}
  By scaling $T$, and the measures on $X$ and $Y$, we may assume that $\| f \|_{L^{p_\theta,r}(X)} \leq 1$, and that $T$ is restricted type $(p_i,q_i)$ with constant $1$, so that for any step function $f$ with height $H$ and width $W$,
  %
  \[ \| Tf \|_{L^{q_i,\infty}(Y)} \leq \| f \|_{L^{p_i}(X)}. \]
  %
  By duality, using the fact that $q_\theta > 1$, it suffices to show that for any simple function $g$ with $\| g \|_{L^{q_\theta',r'}(Y)} = 1$,
  %
  \[ \int |Tf| |g| \leq 1. \]
  %
  Using the previous lemma, we can `adjust' the values $q_0,q_1$ so that we can assume $q_0,q_1 > 1$. We can perform a horizontal layer decomposition, writing
  %
  \[ f = \sum_{i = -\infty}^\infty f_i, \quad\text{and}\quad g = \sum_{i = -\infty}^\infty g_i, \]
  %
  where $f_i$ and $g_i$ are sub-step functions with width $2^i$ and heights $H_i$ and $H_i'$ respectively, and if we write $A_i = H_i 2^{i/p_\theta}$, and $B_i = H_i' 2^{i/q_\theta}$, then
  %
  \[ \| A \|_{l^r(\ZZ)}, \| B \|_{l^{r'}(\ZZ)} \lesssim 1. \]
  %
  Applying the restricted weak type inequalities, we know for each $i$ and $j$,
  %
  \[ \int |Tf_i| |g_j| \lesssim H_i H_j \min_{k \in \{0,1\}} \left[ 2^{i/p_k + j(1 - 1/q_k)} \right]. \]

  Applying sublinearity (noting that really, the decomposition of $f$ and $g$ is finite, since both functions are simple). Thus
  %
  \begin{align*}
    \int |Tf| |g| &\leq \sum_{i,j} \int |Tf_i| |g_j|\\
    &\lesssim \sum_{i,j} H_i H_j' \min_{k \in \{0,1\}} \left[ 2^{i/p_k + j(1 - 1/q_k)} \right]\\
    &\lesssim \sum_{i,j} A_i B_j \min_{k \in \{ 0, 1 \}} \left[ 2^{i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k)} \right].
  \end{align*}
  %
  If $i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k) = \varepsilon(i + \lambda j)$, where $\varepsilon = (1/p_k - 1/p_\theta)$. We then have
  %
  \[ \sum_{i,j} A_i B_j \min_{k \in \{ 0, 1 \}} \left[ 2^{i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k)} \right] \sim \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \sum_i A_i B_{k - \lfloor i/\lambda \rfloor}. \]
  %
  Applying H\"{o}lder's inequality,
  %
  \begin{align*}
    \sum_i A_i B_{k - \lfloor i/\lambda \rfloor} &\leq \| A \|_{l^r(\ZZ)} \left( \sum_i |B_{k - \lfloor i/\lambda \rfloor}|^{r'} \right)^{1/r'}\\
    &\lesssim \lambda^{1/r'} \| A \|_{l^r(\ZZ)} \| B \|_{l^{r'}(\ZZ)} \lesssim 1.
  \end{align*}
  %
  Thus we conclude that
  %
  \begin{align*}
    \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \sum_i A_i B_{k - \lfloor i/\lambda \rfloor} &\lesssim \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \lesssim_\varepsilon 1. \qedhere
  \end{align*}
\end{proof}

There are many variants of the real interpolation method, but the general technique almost always remains the same: incorporate duality, decompose inputs, often dyadically, bound these decompositions, and then sum up.









\chapter{The Theory of Distributions}

The theory of distributions is a tool which enables us to justify formal manipulations which occur in harmonic analysis, without the technical issues which occur from having to interpret such manipulations analytically. For instance, the ordinary integral formulation of the Fourier transform is only defined for $L^1$ functions, whereas the theory of tempered distributions enables us to define the Fourier transform of essentially any function we would ever want to take the Fourier transform of. Similarily, we can only classically differentiate a particular class of functions, but the theory of distributions enables us to define the derivative of almost any function that occurs in analysis. These reasons make distribution theory a cornerstone in the formulation of many problems in modern harmonic analysis and partial differential equations.

The power of measure theory is that it enables us to study a very general class of functionsome more. The problem is that as we study more general classes of functions, the operations we can perform on this class become more and more restricted. Nonetheless, $C^\infty_c(\RR^d)$ is dense in every function space we consider, and we can apply all the fundamental analytical operations in this region, obtaining a general result by a density argument. The theory of distributions provides an alternate viewpoint.

From the perspective of set theory, functions $f: X \to Y$ are a way of assigning values in $Y$ to each point in $X$. However, in analysis this is not often the way we view functions. For instance, in measure theory, we are used to identifying functions which are equal almost everywhere, so that functions in this setting are only defined `almost everywhere'. In distribution theory, we view functions as `integrands', whose properties are understand by integration against a family of `test functions'. For instance, recall that for $1 \leq p < \infty$, the dual space of $L^p(\RR^d)$ is $L^q(\RR^d)$. Thus we can think of elements $f \in L^q(\RR^d)$ as `integrands', whose properties can be understood by integration against elements of $L^p(\RR^d)$, i.e. through the linear functional $\Lambda[f]$ defined for each $\psi \in L^p(\RR^d)$ by setting
%
\[ \Lambda[f](\psi) = \int_{\RR^d} f(x) \psi(x)\; dx. \]
%
Similarily, the dual space of $C(K)$, where $K$ is a compact topological space, is the space $M(K)$ of finite Borel measures on $K$. Thus we can think of measures as a family of `generalized functions'. For each measure $\mu \in M(K)$, we consider the linear functional $\Lambda[\mu]$, defined for each $\psi \in C(K)$, we set
%
\[ \Lambda[\mu](\psi) = \int_K \psi(x) d\mu(x). \]
%
Notice that as we shrink the family of test functions, the resultant family of `generalized functions' becomes larger and larger, and so elements can behave more and more erratically. A distribution is a `generalized function' tested against functions in $C_c^\infty(\RR^d)$. Since most operations in analysis can be applied to elements of $C_c^\infty(\RR^d)$, most importantly, differentiation, we can use duality to extend these operations to distributions. Moreover, since $C_c^\infty(\RR^d)$ is contained in most of the other function spaces, distributions are one of the largest family of generalized functions.

\begin{remark}
  From the perspective of physics, viewing functions as integrands is completely natural. Points in space are idealizations which do not correspond to real world phenomena. One can never measure the exact value of some quantity of a function at a point, but rather only understand the function by looking at it's averages over a small region around that point. Thus a `function' can be understood by the averages with respect to a family of integrands, known as test functions, since they test the value of the function over a region. As we make the family of integrands smaller and smaller, a `function' can be behave more and more erratically. A distribution is an `integrand' with respect to the space $C^\infty_c(\RR^d)$ of infinitely differentiable functions with compact support. Since these functions are incredibly analytically nice, distributions are allowed to behave incredibly erratically, but we can still extend the operations of differentiation and integration to them.
\end{remark}

\section{The Space of Test Functions}

\begin{remark}
  This section is technical, and requires a strong knowledge of functional analysis, in particular the theory of locally convex topological spaces. It can be skipped without too much confusion.
\end{remark}

We fix an open subset $\Omega$ of $\RR^n$, and let $C_c^\infty(\Omega)$ denote the family of all smooth functions on $\Omega$ with compact support. Our goal is to equip $C_c^\infty(\Omega)$ with a complete locally convex topology, so that we can consider the dual space $C_c^\infty(\Omega)^*$ of {\emph distributions} on $\Omega$. We could equip $C_c^\infty(\Omega)$ with a locally convex, metrizable topology with respect to the seminorms
%
\[ \| f \|_{C^n(\Omega)} = \max_{|\alpha| \leq n} \| D^\alpha f \|_{L^\infty(\Omega)} \]
%
However, the resultant topology on $C_c^\infty(\Omega)$ isn't always complete.

\begin{example}
    Let $\Omega = \RR$, pick a bump function $\phi \in C_c^\infty(\RR)$ supported on $[0,1]$ with $\phi > 0$ on $(0,1)$, and define
    %
    \[ \psi_m(x) = \phi(x-1) + \frac{\phi(x-2)}{2} + \dots + \frac{\phi(x-m)}{m} \]
    %
    Then $\psi_m$ is compactly supported on $[1,m]$, and Cauchy, since for $m_1 \geq m_0$,
    %
    \[ \| \psi_{m_0} - \psi_{m_1} \|_{C^n(\RR)} = \frac{ \max_{r \leq n} \| D^r \phi \|_{L^\infty(\RR^d)}}{m_0+1} \lesssim_n 1/m_0. \]
    %
    However, the sequence $\{ \psi_m \}$ does not converge to any element of $C_c^\infty(\RR)$, since the sequence converges uniformly to the function
    %
    \[ \psi(x) = \sum_{n = 1}^\infty \psi(x-n) \]
    %
    an element of $C^\infty(\RR)$ which is not compactly supported.
\end{example}

We can assign $C_c^\infty(\Omega)$ a slightly stronger locally convex topology which makes is complete, but no longer metrizable. The process here is quite general. For each compact set $K \subset \Omega$, the subspace $C_c^\infty(K)$ of smooth functions compactly supported on $K$ is a complete metric space, since limits of functions cannot `escape' the set. Since $C_c^\infty(\Omega) = \bigcup_K C_c^\infty(K)$, we might be able to give $C_c^\infty(\Omega)$ a complete metric space structure by strengthening the topology by forcing limits to lie in a particular set of compact support. We now declare a convex topology, by considering the family of all sets $\{ \phi + W \}$ as a basis, where $\phi$ ranges over all elements of $C_c^\infty(\Omega)$, and $W$ ranges over all convex, balanced subsets of $C_c^\infty(\Omega)$ such that $W \cap C_c^\infty(K)$ is open for each compact set $K \subset \Omega$.

\begin{theorem}
    This gives a basis of a Hausdorff topology on $C_c^\infty(\Omega)$.
\end{theorem}
\begin{proof}
    If $\phi_1 + W_1$ and $\phi_2 + W_2$ both contain $\phi$, then $\phi - \phi_1 \in W_1$ and $\phi - \phi_2 \in W_2$. The functions $\phi, \phi_1$, and $\phi_2$ are all supported on some compact set $K$. By continuity of multiplication on $C_c^\infty(K)$, and the fact that $W_n \cap C_c^\infty(K)$ is open, there is a small constant $\delta$ such that $\phi - \phi_n \in (1 - \delta) W_n$ for each $n \in \{ 1, 2 \}$. The convexity of the $W_n$ implies that $\phi - \phi_n + \delta W_n \subset W_n$. But then $\phi + \delta W_n \subset \phi_n + W_n$, and so $\phi + \delta (W_1 \cap W_2) \subset (\phi_1 + W_1) \cap (\phi_2 + W_2)$. Thus we have verified the family of sets specified above is a basis. Now we show $C_c^\infty(\Omega)$ is Hausdorff under this topology. Suppose $\phi$ is in every open neighbourhood of the origin, then in particular, for each $\varepsilon > 0$, $\phi$ lies in the set $W_\varepsilon = \{ f \in C_c^\infty(\Omega): \| f \|_{L^\infty(\Omega)} < \varepsilon \}$, and it is easy to see these sets are open. Since $\bigcap_{\varepsilon > 0} W_\varepsilon = \{ 0 \}$, this means $\phi = 0$.
\end{proof}

\begin{remark}
    This technique can be formulated more abstractly to give a locally convex topological structure to the direct limit of locally convex spaces. From this perspective, we also see why our metrization doesn't work; if $X = \lim X_n$, with each $X_n$ a locally convex metrizable space, then we cannot give $X$ a complete metrizable topology such that each $X_n$ is an embedding and has empty interior in $X$, because this would contradict the Baire category theorem. In particular, this means that the topology we have given to $C_c(\Omega)$ cannot be metrizable, and therefore the space cannot be first countable. Later we will see a more explicit proof of this.
\end{remark}

\begin{theorem}
    $C_c^\infty(\Omega)$ is a locally convex space.
\end{theorem}
\begin{proof}
    Fix $\phi$ and $\psi$, and consider any neighbourhood $W$ of the origin. By convexity, we have $(\phi + W/2) + (\psi + W/2) \subset (\phi + \psi) + W$. This shows addition is continuous. To show multiplication is continuous, fix $\lambda$, $\phi$, and a neighbourhood $W$ of the origin. Then $\phi$ is supported on some compact set $K$, and $W \cap C_c^\infty(K)$ is open, in particular absorbing, so there is $\varepsilon > 0$ such that if $|\alpha| < \varepsilon$, $\alpha \phi \in W/2$. Then if $|\gamma - \lambda| < \varepsilon$, then because $W$ is balanced and convex,
    %
    \begin{align*}
        \gamma \left(\phi + \frac{W}{2(|\lambda| + \varepsilon)} \right) &= \lambda \phi + (\gamma - \lambda) \phi + \frac{\gamma}{2(|\lambda| + \varepsilon)} W\\
        &\subset \lambda \phi + W/2 + W/2 \subset \lambda \phi + W
    \end{align*}
    %
    so multiplication is continuous.
\end{proof}

\begin{theorem}
    For each compact set $K \subset \Omega$, the canonical embedding of $C_c^\infty(K)$ in $C_c^\infty(\Omega)$ is continuous.
\end{theorem}
\begin{proof}
    We shall prove a convex, balanced neighbourhood $V$ is open in $C_c^\infty(\Omega)$ if and only if $C_c^\infty(K) \cap V$ is open in $C_c^\infty(K)$ for each $K$. Since $V$ is open, $V$ is the union of convex, balanced sets $W_\alpha$ with $W_\alpha \cap C_c^\infty(K)$ open in $C_c^\infty(K)$ for each $K$. But then $V \cap C_c^\infty(K) = (\bigcup W_\alpha) \cap C_c^\infty(K)$ is open in $C_c^\infty(K)$. The converse is true by definition of the topology. But this statement means exactly that the map $C_c^\infty(K) \to C_c^\infty(\Omega)$ is an embedding, because it is certainly continuous, and if $W$ is a convex neighbourhood of the origin equal to the set of $\phi$ supported on $K$ with $\| \phi \|_{C^n(K)} \leq \varepsilon$ for some $n$, then the image is the intersection of $C_c^\infty(K)$ with the set of all $\phi$ supported on $\Omega$ satisfying the inequality, which is open. This shows that the map is open onto its image, hence an embedding.
\end{proof}

It is difficult to see from the definition above why the topology is much stronger than the previous one given. We can see this more numerically by introducing the topology in terms of seminorms. The topology we have given $C_c^\infty(\Omega)$ is the same as the locally convex topology introduced by all norms $\| \cdot \|$ on the space which are continuous when restricted to each $C_c^\infty(K)$. As an example, if we choose an increasing family $U_1, U_2, \dots$ of precompact open sets whose closure is contained in $\Omega$, then any compact set $K$ is contained in some $U_N$ for large enough $N$, and for any increasing sequence $\alpha_1, \alpha_2, \dots$ of positive constants and increasing sequence $k_1, k_2, \dots$ of positive integers the norm
%
\[ \| f \| = \min_{\text{supp}(f) \subset U_n} \alpha_n \| f \|_{C^{k_n}(U_n)} \]
%
is well defined on $C_c^\infty(\Omega)$ and continuous. But this means that if $f_1, f_2, \dots \to 0$, then $\| f \| \to 0$ for any choice of constants $\alpha_n$ and $k_n$, so asymptotically as we approach the boundary of $\Omega$ (or $\infty$, if $\Omega$ is unbounded), the $L^\infty$ norms of the $f_n$ and all of their derivatives must converge arbitrarily fast outside certain compact sets. The next theorem shows that this implies that the union of the domains $f_n$ must actually be precompact. It is this `uniform compactness' that gives us completeness.

\begin{theorem}
    $E$ is a bounded subset of $C_c^\infty(\Omega)$ if and only if $E$ is contained in $C_c^\infty(K)$ for some compact set $K$, and there is a sequence of constants $\{ M_n \}$ such that $\| \phi \|_{C^n(\Omega)} \leq M_n$ for all $\phi \in E$.
\end{theorem}
\begin{proof}
    We shall now prove that if $E$ is not contained in some $C_c^\infty(K)$ for any compact set $K \subset \Omega$, then $E$ is not bounded. If our assumption is true, we can find functions $\phi_n \in E$ and a set of points $x_n \in X$ with no limit point such that $\phi_n(x_n) \neq 0$. For each $n$, set
    %
    \[ W_n = \left\{ \psi \in C_c^\infty(\RR^d): |\psi(x_n)| < n^{-1} |\phi_n(x_n)| \right\}. \]
    %
    Certainly $W_n$ is convex and balanced, and for each compact set $K$, if $\psi \in W_n \cap C_c^\infty(K)$, then there is $\varepsilon > 0$ such that $|\psi(x_n)| < n^{-1} |\phi_n(x_n)| - \varepsilon$. Thus if $\eta \in C_c^\infty(K)$ satisfies $\| \eta \|_{L^\infty(\RR^d)} < \varepsilon$, then $\psi + \eta \in W_n$. In particular, this means $W_n \cap C_c^\infty(K)$ is open in $C_c^\infty(K)$ for each $K$, so $W_n$ is open.

    Now we claim $W = \bigcap_{n = 1}^\infty W_n$ is open. Certainly this set is convex and balanced. Moreover, each compact set $K$ contains finitely many of the points $\{ x_n \}$, so $W \cap C_c^\infty(K)$ can be replaced by a finite intersection of the $W_n$, and is therefore open. Since $\phi_n \not \in nW$ for all $n$, this implies that $E$ is not bounded. The fact that $\| \cdot \|_{C^n(\Omega)}$ specifies the topological structure of $C_c^\infty(K)$ for each compact $K$ now shows that if $E$ is bounded, there exists constants $\{ M_n \}$ such that $\| \phi \|_{C^n(\Omega)} \leq M_n$ for all $\phi \in E$. The converse property follows because $C_c^\infty(K)$ is embedded in $C_c^\infty(\Omega)$.
\end{proof}

\begin{corollary}
    $C_c^\infty(\Omega)$ has the Heine Borel property.
\end{corollary}
\begin{proof}
    This follows because if $E$ is bounded and closed, it is a closed and bounded subset of some $C_c^\infty(K)$ for some $K$, hence $E$ is compact since $C_c^\infty(K)$ satisfies the Heine-Borel property (this can be proved by a technical application of the Arzela-Ascoli theorem).
\end{proof}

\begin{corollary}
    $C_c^\infty(\Omega)$ is quasicomplete.
\end{corollary}
\begin{proof}
    If $\phi_1, \phi_2, \dots$ is a Cauchy sequence in $C_c^\infty(\Omega)$, then the sequence is bounded, hence contained in some common $C_c^\infty(K)$. Since the sequence is Cauchy, they converge in $C_c^\infty(K)$ to some $\phi$, since $C_c^\infty(K)$ is complete, and thus the $\phi_n$ converge to $\phi$ in $C_c^\infty(\Omega)$.
\end{proof}

It is often useful to use the fact that we can perform a `separation of variables' to a smooth function. This is done formally in the following manner. Say $f \in C_c^\infty(\RR^d)$ is a {\it tensor function} if there are $f_1, \dots, f_n \in C_c^\infty(\RR)$ such that $f(x) = f_1(x_1) \dots f_n(x_n)$. We write $f = f_1 \otimes \dots \otimes f_n$. Since the product of two tensor functions is a tensor function, the family of all finite sums of tensor functions forms an algebra.

\begin{theorem}
    Finite sums of tensor functions are dense in $C_c^\infty(\RR^d)$.
\end{theorem}
\begin{proof}
    Recall from the theory of multiple Fourier series that if $f \in C^\infty(\RR^d)$ is $N$ periodic, in the sense that $f(x + n) = f(x)$ for all $x \in \RR^d$ and $n \in (N \ZZ)^d$, then there are coefficients $a_m$ for each $m \in \ZZ^n$ such that $f = \lim_{M \to \infty} S_M f$, where the convergence is dominated by the sminorms $\| \cdot \|_{C^n(\RR^d)}$, for all $n > 0$, and
    %
    \[ (S_M f)(x) = \sum_{\substack{m \in \ZZ^d\\|m| \leq M}} a_m e^{\frac{2 \pi i m \cdot x}{N}}. \]
    %
    Note that since
    %
    \[ e^{\frac{2 \pi i m \cdot x}{N}} = \prod_{k = 1}^d e^{2 \pi i m_ix_i/N} \]
    %
    is a tensor product, $S_M f$ is a finite sum of tensor functions. If $\phi \in C_c^\infty(\RR^d)$ is compactly supported on $[-N,N]^d$, we let $f$ be a $10N$ periodic function which is equal to $\phi$ on $[-N,N]^d$. We then find coefficients $\{ a_m \}$ such that $S_M f$ converges to $f$. If $\psi: \RR \to \RR$ is a compactly supported bump function equal to one on $[-N,N]^d$, and vanishing outside of $[-2N,2N]^d$, then $\psi^{\otimes d} S_M f$ converges to $\psi$ as $M \to \infty$, and each is a finite sum of tensor functions.
\end{proof}

Because $C_c^\infty(\Omega)$ is the limit of metrizable spaces, it's linear operators still have many of the same properties as metrizable spaces.

\begin{theorem}
    If $T: C_c^\infty(\Omega) \to X$ is a map from $C_c^\infty(\Omega)$ to some locally convex space $X$, then the following are equivalent:
    %
    \begin{itemize}
        \item[(1)] $T$ is continuous.
        \item[(2)] $T$ is bounded.
        \item[(3)] If $\{ \phi_n \}$ converges to zero, then $\{ T\phi_n \}$ converges to zero.
        \item[(4)] For each compact set $K \subset \Omega$, $T$ is continuous restricted to $C_c^\infty(K)$.
    \end{itemize}
\end{theorem}
\begin{proof}
    We already known that (1) implies (2). If $T$ is bounded, and we have a sequence $\{ \phi_n \}$ converging to zero, then the sequence is bounded, hence contained in some $C_c^\infty(K)$. Thend $T$ is bounded as a map from $C_c^\infty(K)$ to $X$, hence $\{ T\phi_n \} \to 0$. (3) implies (4) holds because each $C_c^\infty(K)$ is metrizable, and any convergent sequence is contained in some common $C_c^\infty(K)$. To prove that (4) implies (1), we let $V$ be a convex, balanced, open subset of $X$. Then $T^{-1}(V) \cap C_c^\infty(K)$ is open for each $K$, and $T^{-1}(V)$ is convex and balanced, so $T^{-1}(V)$ is an open set.
\end{proof}

Because convergence is so strict in $C_c^\infty(\Omega)$, almost every operation we want to perform on smooth functions is continuous in this space.
%
\begin{itemize}
    \item Since $f \mapsto D^\alpha f$ is a continuous operator from $C_c^\infty(K)$ to itself, it is therefore continuous on the entire space $C_c^\infty(\Omega)$. More generally, any linear differential operator with coefficients in $C_c^\infty(\Omega)$ is a continuous operator from $C_c^\infty(\Omega)$ to itself.

    \item The inclusion $C_c^\infty(\Omega) \to L^p(\Omega)$ is continuous. To prove this, it suffices to prove for each compact $K$, the inclusion $C_c^\infty(K) \to L^p(\Omega)$ is continuous, and this follows because $\| f \|_{L^p(\Omega)} \leq |K|^{1/p} \| f \|_\infty$.

    \item If $f \in L^1(\RR^d)$ is compactly supported, then for any $g \in C_c^\infty(\RR^d)$, $f * g \in C_c^\infty(\RR^d)$. This is because $f * g$ is continuous since $g \in L^\infty(\RR^n)$, and it's support is contained in the algebraic sums of the support of $f$ and $g$, as well as the identity $D^\alpha(f * g) = f * (D^\alpha g)$. In fact, the map $g \mapsto f * g$ is a continuous operator on $C_c^\infty(\RR^n)$. This is because if we restrict our attention to $C_c^\infty(K)$, and $f$ has supported on $K'$, then our convolution operator maps into the compact set $K+K'$, and since
    %
    \[ \| D^\alpha (g * f) \|_{L^\infty(K + K')} = \| D^\alpha g * f \|_{L^\infty(K + K')} \leq \| D^\alpha g \|_{L^\infty(K)} \| f \|_{L^1(K')}, \]
    %
    we conclude
    %
    \[ \| g * f \|_{C^n(K+K')} \leq \| g \|_{C^n(K)} \| f \|_{L^1(K')}, \]
    %
    which gives continuity of the operator as a map from $C_c^\infty(K)$ to $C_c^\infty(K+K')$. Since the latter space embeds in $C_c^\infty(\RR^n)$, we obtain continuity of the operator on $C_c^\infty(\RR^n)$.
\end{itemize}

\begin{theorem}
    If a map $T: C_c^\infty(K) \to C_c^\infty(\RR^n)$ is continuous, then the image of $C_c^\infty(K)$ is actually $C_c^\infty(K')$ for some compact set $K'$.
\end{theorem}
\begin{proof}
    Suppose there is a sequence $x_1, x_2, \dots$ with no limit point and smooth functions $f_1, f_2, \dots$ compactly supported on $C_c^\infty(K)$ such that $(Tf_n)(x_n) \neq 0$. But then for any sequence $\alpha_n$ whatsoever, we cannot have $\alpha_n Tf_n$ converging to zero, hence $\alpha_n f_n$ cannot converge to zero. But this is clearly not true, for if we let
    %
    \[ \alpha_n = \frac{1}{2^n \| f_n \|_{C^n}} \]
    %
    Then for any fixed $m$, $\| f_n \|_{C^m}$ is eventually bounded above by $1/2^n$ and therefore converges to zero. Thus such a sequence $x_n$ cannot exist, and therefore the image of $T$ is supported on some compact set $K'$.
\end{proof}

Thus the topology on the space $C_c^\infty(\RR^d)$ is as strict as can be. As a consequence, we shall see that the weak $*$ topology on $C_c^\infty(\RR^d)^*$ is essentially the weakest notion of convergence available in analysis, which makes it surprising that we still be able to recover the continuity of many operators on the dual space.

\section{The Space of Distributions}

We now have the tools to explain the idea of a distribution. If $f$ is a locally integrable function defined on $\Omega$, then the map
%
\[ \Lambda[f](\phi) = \int f(x) \phi(x)\; dx \]
%
is a {\it continuous} linear functional defined for each $\phi \in C_c^\infty(\Omega)$. The functional $\Lambda[f]$ determines $f$ up to a set of measure zero, and so we can safely identify $\Lambda[f]$ with $f$, and think of $f$ `distributionally'. The idea of the theory of distributions is to treat any continuous linear functional $\Lambda$ on $C_c^\infty(\Omega)$ as if it were given by integration against a function as nice as possible. Using the properties of integration for these integration, we can usually cheat out a definition of operations usually only applicable to functions that works for all distributions. Thus the operations of analysis generalize to an incredibly large family of objects. As an example, if $f$ was continuously differentiable, then we would find
%
\[ \int f'(x) \phi(x)\; dx = - \int f(x) \phi'(x)\; dx \]
%
Since the right hand side is defined independantly of how nice the function $f(x)$ is, we could define the {\it derivative} of a continuous linear functional $\Lambda$ as
%
\[ \Lambda'(\phi) = - \Lambda(\phi') \]
%
and more generally, for a linear functional on $n$ dimensional space, we could define $(D^\alpha \Lambda)(\phi) = (-1)^{|\alpha|} \Lambda(D^\alpha \phi)$.

\begin{example}
    Let $H(x) = \mathbf{I}(x > 0)$ denote the {\it Heaviside step function}. Then $H$ is locally integrable, and so for any test function $\phi$, we calculate
    %
    \[ \int H'(x) \phi(x)\; dx = - \int H(x) \phi'(x) = - \int_0^\infty \phi'(x) = \phi(0) \]
    %
    Thus the `derivative' of the Heaviside step function is the Dirac delta. It is not a function, but if we were to think of it as a `generalized function', it would be zero everywhere except at the origin, where it is infinitely peaked.
\end{example}

\begin{example}
    Consider the Dirac delta function at the origin, which is the distribution $\delta(f) = f(0)$. Then
    %
    \[ \delta'(f) = - \delta(f') = - f'(0) \]
    %
    which is a distribution which doesn't arise from integration with respect to a locally integrable function nor a Radon measure. Thus the `derivative' of an infinitely peaked function at the origin is the negation of a derivative.
\end{example}

In general, we define a {\bf distribution} to be a continuous linear functional on the space of test functions $C_c^\infty(\Omega)$. In the last section, our exploration of continuous linear transformations on $C_c^\infty(\Omega)$ guarantees that a linear functional $\Lambda$ on $C_c^\infty(\Omega)$ is continuous if and only if for every compact $K \subset X$ there is an integer $n_k$ such that $|\Lambda \phi| \lesssim_K \| \phi \|_{C^{n_k}}$ for $\phi \in C_c^\infty(K)$. If one integer $n$ works for all $K$, and $n$ is the smallest integer with such a property, we say that $\Lambda$ is a distribution of \emph{order $n$}. If such an $n$ doesn't exist, we say the distribution has infinite order. If such an $n$ doesn't exist, we say the distribution has infinite order.

\begin{example}
    If $\mu$ is a locally finite Borel measure, or a finite complex valued measure, then we can define
    %
    \[ \Lambda[\mu](\phi) = \int \phi(x) d\mu(x) \]
    %
    Thus $\Lambda[\mu]$ is a distribution, since if $\phi$ is supported on $K$, then
    %
    \[ |\Lambda[\mu](\phi)| \leq \mu(K) \| \phi \|_{L^\infty(K)} \]
    %
    Thus $\Lambda[\mu]$ is a distribution of order zero.
\end{example}

\begin{example}
    Not all distributions arise from functions or measures. For instance, if $\phi \in C_c^\infty(\RR)$, then
    %
    \[ \text{p.v} \int \frac{\phi(x)}{x} = \lim_{\varepsilon \to 0} \int_{|x| > \varepsilon} \frac{\phi(x)}{x}\; dx \]
    %
    exists. This is because the values of $1/x$ on either side of the real axis cancel each other out in the integral. More rigorously, if the support of $\phi$ is contained in $[-N,N]$, then
    %
    \[ \left| \int_{|x| > \varepsilon} \frac{\phi(x)}{x} \right| = \left| \int_{\varepsilon < |x| < N} \frac{\phi(x) - \phi(0)}{x} \right| \]
    %
    The mean value theorem implies $\phi(x) - \phi(0) = x\phi'(y)$ for some $y$ between zero and $x$, so
    %
    \[ \left| \int_{|x| \leq \varepsilon} \frac{\phi(x) - \phi(0)}{x} \right| \leq 2 \varepsilon \| \phi \|_{C^1(\RR)} \]
    %
    From this, we can conclude that these values are Cauchy as $\varepsilon \to 0$, hence the principal value exists, and moreover, if $\phi$ is compactly supported on $[-N,N]$, 
    %
    \[ \left| \text{p.v.} \int \frac{\phi(x)}{x} \right| \lesssim_N \| \phi \|_{C^1(\RR^d)} \]
    %
    Thus this linear functional is actually continuous, hence a distribution, and it is not induced by any function or measure. This distribution is the derivative of the distribution induced by the locally integrable function $\log |x|$, since an integration by parts shows that for each $\phi \in C_c^\infty(\RR^d)$,
    %
    \begin{align*}
        - \int \log |x| \phi'(x) &= \lim_{\varepsilon \to 0} \int_{|x| \geq \varepsilon} \log |x| \phi'(x)\\
        &= \lim_{\varepsilon \to 0} \left( \log(\varepsilon) \cdot \left( \phi(x) - \phi(-x) \right) + \int_{|x| \geq \varepsilon} \frac{\phi(x)}{x} \right)\\
        &= \text{p.v.} \int \frac{\phi(x)}{x}\; dx.
    \end{align*}
\end{example}

As we stated before, given any distribution $\Lambda$, we can define it's {\it derivative} $D^\alpha \Lambda$ to be the distribution
%
\[ D^\alpha \Lambda (\phi) = (-1)^{|\alpha|} \Lambda(D^\alpha \phi) \]
%
which is continuous since the derivative operation is continuous on $C_c^\infty(\Omega)$. Just as the partial derivatives commutes on $C_c^\infty(\Omega)$, the partial differentiation operation commutes on the the space of distributions, i.e. $D^\alpha D^\beta \Lambda = D^\beta D^\alpha \Lambda$, and we take the common value to be $D^{\alpha + \beta} \Lambda$. If $D^\alpha f$ is continuous, then we already know an integration by parts gives $D^\alpha \Lambda[f] = \Lambda[D^\alpha f]$, so we can think of the distribution derivative as a true generalization of the usual derivative. On the other hand, in general the distribution derivative may disagree with the usual derivative if the function is less well behaved. If $P$ is a polynomial, we have
%
\[ P(D)(\Lambda)(\phi) = \Lambda(P(-D)(\phi)) \]
%
if we understand the polynomial applications of derivatives linearly.

\begin{example}
    Let $f$ be a left continuous function on the real line with bounded variation and with $f(-\infty) = 0$. Then $f'$ exists almost everywhere in the classical sense, and $f' \in L^1(\RR)$. By Fubini's theorem, if we let $\mu$ be the measure defined by $\mu([a,b)) = f(b) - f(a)$, then for any $\phi \in C_c^\infty(\RR)$,
    %
    \begin{align*}
        \int_{-\infty}^\infty \phi(x) d\mu(x) &= - \int_{-\infty}^\infty \int_x^\infty \phi'(y)\; dy\; d\mu(x)\\
        &= - \int_{-\infty}^\infty \phi'(y) \int_{-\infty}^y d\mu(x)\; dy\\
        &= - \int_{-\infty}^\infty \phi'(y) f(y) dy
    \end{align*}
    %
    and we know $f(-\infty) = 0$. Thus we find $\smash{\Lambda[f'] = \Lambda[\mu]}$. In particular, we only have $\smash{\Lambda[f]' = \Lambda[f'}]$ if $\smash{f' dx = \mu}$, which only holds if $f$ is absolutely continuous.
\end{example}

If $f \in L^1_{\text{loc}}(\RR^n)$, and $g$ is $C^\infty$, then $fg$ is locally integrable. The identity
%
\[ \int (f(x)g(x)) \phi(x)\; dx = \int f(x) (g(x) \phi(x))\; dx \]
%
enables us to define the product of a $C^\infty(\Omega)$ function with a distribution. Given any distribution $\Lambda$, we define $(f \Lambda)(\phi) = \Lambda(f \phi)$. To see why $f \Lambda$ is a distribution, fix a compact set $K$, and pick $A$ and $N$ such that for any $\phi \in C_c^\infty(K)$, $|\Lambda(f)| \leq A \| f \|_{N,K}$. The Leibnitz rule tells us that
%
\[ D^\alpha(f \phi) = \sum_{\lambda + \gamma = \alpha} C_{\lambda \gamma} D^\lambda f D^\gamma \phi \]
%
and so
%
\[ |\Lambda(f \phi)| \leq A \| f \phi \|_{N,K} \leq N A \left( \max |C_{\lambda \gamma}| \| D^\lambda f \|_{L^\infty(K)} \right) \| \phi \|_{C^N(K)} \]
%
so $f \Lambda$ is a distribution with the same order as $\Lambda$. It is important that $f$ is a smooth function, so that $fg$ is smooth for each function $g$.

Since $C_c^\infty(X)^*$ is the dual space of a topological vector space, we can give it a natural topology, the weak $*$ topology. Thus a net of distributions $\Lambda_\alpha$ converges to $\Lambda$ if and only if $\Lambda_\alpha(\phi) \to \Lambda(\phi)$ for all test functions $\phi$. This gives a further topology on the space of measures and functions, and we often write $f_\alpha \to f$ `in the distribution sense' if we have a convergence $\Lambda[f_\alpha] \to \Lambda[f]$ for the corresponding distributions. Since the convergence in $C_c^\infty(\Omega)$ is incredibly strict, convergence of distributions is incredibly weak. The following is thus quite a surprising result.

\begin{theorem}
    Suppose that $\Lambda_1, \Lambda_2, \dots$ are a sequence of distributions such that for a fixed test function $\phi$,
    %
    \[ \Lambda \phi = \lim \Lambda_n \phi \]
    %
    exists. Then $\Lambda$ is a distribution, and $D^\alpha \Lambda_n \to D^\alpha \Lambda$ for each $\alpha$.
\end{theorem}
\begin{proof}
    Fix a compact set $K$. Then the Banach Steinhaus theorem guarantees that $\Lambda$ restricted to $C_c^\infty(K)$ is a continuous functional, and we know this implies $\Lambda$ is continuous in general. The fact that $D^\alpha \Lambda_n \to D^\alpha \Lambda$ is trivial, because for a fixed $\phi$, $D^\alpha \phi \in C_c^\infty(X)$, so
    %
    \[ D^\alpha \Lambda(\phi) = (-1)^{|\alpha|} \Lambda(D^\alpha \phi) = (-1)^{|\alpha|} \lim \Lambda_n(D^\alpha \phi) = \lim D^\alpha \Lambda_n(\phi) \]
    %
    Thus the sequence weakly converges to $D^\alpha \Lambda$.
\end{proof}

A similar application of the Banach Steinhaus theorem guarantees that if $g_n \to g$ in $C^\infty(\RR^n)$, and $\Lambda_n \to \Lambda$ in the distributional sense, then $g_n \Lambda_n$ converges to $g \Lambda$ in the distributional sense. Thus the space of distributions is a topological $C^\infty(\RR^n)$ module.

\section{Localization of Distribuitions}

Just as we can consider the local behaviour of functions around a point, we can consider the local behaviour of a distribution around points, and this local behaviour contains most of the information of the distribution. For instance, given an open subset $U$ of $X$, we say two distributions $\Lambda$ and $\Psi$ are equal on $U$ if $\Lambda \phi = \Psi \phi$ for every test function $\phi$ compactly supported in $U$. We recall the notion of a partition of unity, which, for each open cover $U_\alpha$ of Euclidean space, gives a family of $C^\infty$ functions $\psi_\alpha$ which are positive, {\it locally finite}, in the sense that only finitely many functions are positive on each compact set, and satisfy $\sum \psi_\alpha = 1$ on the union of the $U_\alpha$.

\begin{theorem}
    If $X$ is covered by a family of open sets $U_\alpha$, and $\Lambda$ and $\Psi$ are locally equal on each $U_\alpha$, then $\Lambda = \Psi$. If we have a family of distributions $\Lambda_\alpha$ which agree with one another on $U_\alpha \cap U_\beta$, then there is a unique distribution $\Lambda$ locally equal to each $\Lambda_\alpha$.
\end{theorem}
\begin{proof}
    Since we can find a $C^\infty$ partition of unity $\psi_\alpha$ compactly supported on the $U_\alpha$, upon which we find if $\phi$ is supported on $K$, then finitely many of the $\psi_\alpha$ are non-zero on $K$, and so
    %
    \[ \Lambda(\phi) = \sum \Lambda(\psi_\alpha \phi) = \sum \Psi(\psi_\alpha \phi) = \Psi(\phi) \]
    %
    Thus $\Lambda = \Psi$. Conversely, if we have a family of distributions $\Lambda_\alpha$ like in the hypothesis, then we can find a partition of unity $\psi_{\alpha \beta}$ subordinate to $U_\alpha \cap U_\beta$, and we can define
    %
    \[ \Lambda(\phi) = \sum \Lambda_\alpha(\psi_{\alpha \beta} \phi) = \sum \Lambda_\beta(\psi_{\alpha \beta} \phi) \]
    %
    The continuity is verified by fixing a compact $K$, from which there are only finitely many nonzero $\psi_{\alpha \beta}$ on $K$, and the fact that this definition is independant of the partition of unity follows from the first part of the theorem.
\end{proof}

In the language of modern commutative algebra, the association of $C_c^\infty(U)^*$ to each open subset $U$ of $\Omega$ gives a sheaf structure to $\Omega$. Given a distribution $\Lambda$, we might have $\Lambda(\phi) = 0$ for every $\phi$ supported on some open set $U$. The complement of the largest open set $U$ for which this is true is called the {\bf support} of $\Lambda$. If $f$ vanishes on a neighbourhood of the support of $\Lambda$, then by definition of the support, $\Lambda f = 0$. The neighbourhood condition is important -- $\delta'$ is supported on $\{ 0 \}$, since $\delta$ is, but it certainly doesn't vanish on $f$ if $f(0) = 0$.

\begin{theorem}
    If a distribution has precompact support, the distribution has finite order, and extends uniquely to a continuous linear functional on $C^\infty(X)$.
\end{theorem}
\begin{proof}
    Let $\Lambda$ be a distribution supported on a compact set. If $\psi$ is a function with compact support with $\psi(x) = 1$ on the support of $\Lambda$, then $\psi \Lambda = \Lambda$, because for any $\phi$, $\phi - \phi \psi$ is supported on a set disjoint from the support of $\Lambda$. But if $\psi$ is supported on $K$, then there is $N$ such that for any $\phi \in C_c^\infty(K)$,
    %
    \[ |\Lambda(\phi)| \lesssim \| \phi \|_{N,K} \]
    %
    and so for any other compact set $K$,
    %
    \[ |\Lambda(\phi)| = |\Lambda(\phi \psi)| \lesssim \| \phi \psi \|_{N,K} \lesssim \| \psi \|_{C^N(K)} \| \phi \|_{C^N(K)} \]
    %
    which shows $\Lambda$ has order $N$. We have shown that $\Lambda$ is continuous with respect to the seminorm $\| \cdot \|_{C^N(K)}$ on $C^\infty(X)$, and so by the Hahn Banach theorem, $\Lambda$ extends uniquely to a continuous functional on $C^\infty(X)$.
\end{proof}

\begin{example}
    If $\Lambda(\phi) = \sum_{|\alpha| \leq N} \lambda_\alpha D^\alpha \phi(x)$, then $\Lambda$ is supported on $x$. Conversely, every distribution $\Lambda$ supported on $x$ is of this form. We know $\Lambda$ must have finite order $N$, and consider $\phi$ with $D^\alpha \phi(x) = 0$ for all $|\alpha| \leq N$. We claim $\Lambda(\phi) = 0$. Fix $\varepsilon > 0$, and choose a compact neighbourhood $K$ of the origin with $|D^\alpha \phi(x)| < \varepsilon$ on $K$ for all $|\alpha| = N$. Then for $|\alpha| < N$, the mean value theorem implies that, by induction,
    %
    \[ |D^\alpha \phi(x)| \leq \varepsilon n^{N - |\alpha|} |x|^{N-|\alpha|} \]
    %
    Find $A$ such that for functions $\phi$ supported on $K$,
    %
    \[ |\Lambda(\phi)| \leq A \| \phi \|_{C^N(K)} \]
    %
    Fix a bump function $\psi$ with support on the ball of radius one and $\psi(x) = 1$ in a neighbourhood of the origin, and define $\psi_\delta(x) = \psi(x/\delta)$. If $\delta$ is small enough, then $\psi$ is supported on $K$, and because $\Lambda$ is supported on $x$,
    %
    \begin{align*}
        |\Lambda(\phi)| &= |\Lambda(\phi \psi_\delta)| \leq A \| \phi \psi_\delta \|_{C^N(K)}\\
        &\leq A \sum_{|\alpha + \beta| = N} |c_{\alpha \beta}| \| D^\alpha \phi \|_\infty \| D^\beta \psi_\delta \|\\
        &\leq A \| \psi \|_{C^N} \sum_{|\alpha + \beta| = N} |c_{\alpha \beta}| \delta^{|\beta| - |\alpha|} \| D^\beta \phi \|_{L^\infty(K)}\\
        &\leq \varepsilon A \left( \sum_{|\alpha + \beta| = N} |c_{\alpha \beta}| n^{N - |\beta|} \right)
    \end{align*}
    %
    We can then let $\varepsilon \to 0$ to conclude $\Lambda(\phi) = 0$. But this means that $\Lambda(\phi)$ is a linear function of the partial derivatives of $\phi$ with order $\leq N$, completing the proof.
\end{example}

\begin{example}
    If $\delta$ is the Dirac delta distribution, then $f \delta = f(0) \delta$ for any smooth function $f$. Thus, in particular, $x \delta = 0$. Conversely, if $\Lambda$ is any distribution with $x \Lambda = 0$, then $\Lambda$ is a multiple of the Dirac delta distribution. To see this, we note that this would imply $\Lambda(f) = 0$ for all functions $f$ such that $f/x$ is also smooth and compactly supported. In particular, this is true if the support of $f$ does not contain the origin. Thus $\Lambda$ is supported on the origin, hence there are constants $a_n$ such that
    %
    \[ \Lambda f = \sum_{n = 0}^N a_n f^{(n)}(0) \]
    %
    But $(xf)^{(n)}(0) = n f^{(n-1)}(0)$ only vanishes for all $f$ when $n = 0$, so $\Lambda$ is a multiple of the Dirac delta distribution. A more simple way to see this is that if $f$ is compactly supported on $[-N,N]$, the function
    %
    \[ g(x) = \frac{f(x) - f(0)}{x} = \int_0^1 f'(tx)\; dt \]
    %
    is smooth, and $f = f(0) + xg$. Since $\Lambda$ and $x \Lambda$ have bounded support, they extend uniquely to $C^\infty(\Omega)$, and so $\Lambda f = f(0) \Lambda 1 + \Lambda(xg) = f(0) \Lambda 1$.
\end{example}

In many other ways, distributions act like functions. For instance, any distribution $\Lambda$ can be uniquely written as $\Lambda_1 + i \Lambda_2$ for two distributions $\Lambda_1, \Lambda_2$ that are real valued for any real-valued smooth continuous function. However, we cannot write a real-valued distribution as the difference of two positive distributions, i.e. those which are non-negative when evaluated at any non-negative functional. Given a non-negative functional $\Lambda$,  we define $\Lambda f$ for a compactly supported continuous function $f \geq 0$ as
%
\[ \Lambda f = \sup \{ \Lambda g: g \in C_c^\infty(\RR^n), g \leq f \} \]
%
and then in general define $\Lambda (f^+ - f^-) = \Lambda f^+ - \Lambda f^-$. Then $\Lambda$ is obviously a positive extension of $\Lambda$ to all continuous functions, and is linear. But then the Riesz representation theorem implies that there is a positive Radon measure such that $\Lambda = \Lambda_\mu$, completing the proof.

\section{Derivatives of Continuous Functions}

One of the main reasons to consider the theory of distributions is so that we can take the derivative of any function we want. We now show that, at least locally, every distribution is the derivative of some continuous function, which means the theory of distributions is essentially the minimal such class of objects which enable us to take derivatives of continuous functions.

\begin{theorem}
    If $\Lambda$ is a distribution on $\Omega$, and $K$ is a compact set, then there is a continuous function $f$ and $\alpha$ such that for every $\phi$,
    %
    \[ \Lambda \phi = (-1)^{|\alpha|} \int_\Omega f(x) (D^\alpha \phi)(x)\; dx \]
\end{theorem}
\begin{proof}
    TODO
\end{proof}

\begin{theorem}
    If $K$ is compact, contained in some open subset $V$, which in turn is a subset of $\Omega$, and $\Lambda$ has order $N$, then there exists finitely many continuous functions $f_\beta \in C(\Omega)$ supported on $V$, for each $|\beta| \leq N + 2$, with supports on $V$, and with $\Lambda = \sum D^\beta f_\beta$.
\end{theorem}

\begin{theorem}
    If $\Lambda$ is a distribution on $\Omega$, then there exists continuous functions $g_\alpha$ on $\Omega$ such that each compact set $K$ intersects the supports of finitely many of the $g_\alpha$, and $\Lambda = \sum D^\alpha g_\alpha$. If $\Lambda$ has finite order, then only finitely many of the $g_\alpha$ are nonzero.
\end{theorem}

\section{Convolutions of Distributions}

Using the convolution of two functions as inspiration, we will not define the convolution of a distribution $\Lambda$ with a test function $\phi$, and under certain conditions, the convolution of two distributions. Recall that if $f,g \in L^1(\RR^n)$, then their convolution is the function in $L^1(\RR^n)$ defined by
%
\[ (f * g)(x) = \int f(y) g(x - y)\; dy \]
%
If we define the translation operators $(T_y g)(x) = g(x-y)$, then $(f * g)(x) = \int f(y) (T_x g^*)(y)\; dy$, where $g^*$ is the function defined by $g^*(x) = g(-x)$. Thus, if $\Lambda$ is any distribution on $\RR^n$, and $\phi$ is a test function on $\RR^n$, we can define a function $\Lambda * \phi$ by setting $(\Lambda * \phi)(x) = \Lambda(T_x \phi^*)$. Notice that since
%
\begin{align*}
    \int (T_x f)(y) g(y)\; dy &= \int f(y-x) g(y)\; dy = \int f(y) g(x+y)\; dy\\
    &= \int f(y) (T_{-x}g)(y)\; dy,
\end{align*}
%
so we can also define the translation operators on distributions by setting $(T_x \Lambda)(\phi) = \Lambda (T_{-x} \phi)$. One mechanically verifies that convolution commutes with translations, i.e. $T_x (\Lambda * \phi) = (T_x \Lambda) * \phi = \Lambda * (T_x \phi)$.

\begin{theorem}
    $\Lambda * \phi$ is $C^\infty$, and $D^\alpha(\Lambda * \phi) = (D^\alpha \Lambda) * \phi = \Lambda * (D^\alpha \phi)$.
\end{theorem}
\begin{proof}
    It is easy to calculate that
    %
    \begin{align*}
        (D^\alpha \Lambda * \phi)(x) &= (D^\alpha \Lambda)(\phi^*_x) = (-1)^{|\alpha|} \Lambda(D^\alpha (T_x \phi^*))\\
        &= \Lambda(T_x (D^\alpha \phi)^*) = (\Lambda * D^\alpha \phi)(x)
    \end{align*}
    %
    If $e$ is a unit vector, and we set $\Delta_h = h^{-1} (1 - T_{he})$, then $\Delta_h \phi$ converges to $D_e \phi$ in $C_c^\infty(\RR^n)$, and as such,
    %
    \begin{align*}
        \Delta_h(\Lambda * \phi)(x) &= \frac{(\Lambda * \phi)(x) - (\Lambda * \phi)(x - he)}{h}\\
        &= \frac{\Lambda(T_x \phi^* - T_{-he} (T_x \phi^*)}{h} = \Lambda(T_x(\Delta_h \phi^*))
    \end{align*}
    %
    and this converges to $\Lambda(D_e \phi^*) = (\Lambda * D_e \phi)(x)$ as $h \to 0$. Iteration of this fact gives the general result.
\end{proof}

\begin{theorem}
    If $\phi, \psi \in C_c^\infty(\RR^n)$, then $\Lambda * (\phi * \psi) = (\Lambda * \phi) * \psi$.
\end{theorem}
\begin{proof}
    Let $\phi$ and $\psi$ be supported on $K$. We calculate
    %
    \[ (\phi * \psi)^*(x) = \int \phi^*(x + y) \psi(y)\; dy = \int (T_y \phi)^*(x) \psi(y)\; dy \]
    %
    since the map $y \mapsto (T_y \phi)^* \psi(y)$ is continuous, and vanishes out of the compact set $K$, so that we have a $C_c^\infty(K)$ valued integral
    %
    \[ (\phi * \psi)^* = \int_K \psi^*(y) T_y \phi^*\; ds \]
    %
    This means precisely that
    %
    \begin{align*}
        (\Lambda * (\phi * \psi))(0) &= \Lambda((\phi * \psi)^*) = \int_K \psi^*(y) \Lambda(T_y \phi^*)\; dy\\
        &= \int_K \psi^*(y) (\Lambda * \phi)(y)\; dy = ((\Lambda * \phi) * \psi)(0)
    \end{align*}
    %
    The commutativity in general results from applying the commutativity of the translation operators.
\end{proof}

A net $\phi_\alpha$ is known as an {\it approximate identity} in the space of distributions if $\Lambda * \phi_\alpha \to \Lambda$ as distributions for every distribution $\phi$, and an approximate identity in the space of test functions if $\psi * \phi_\alpha \to \psi$ in $C_c^\infty(\RR^n)$.

\begin{theorem}
    If $\phi_\alpha$ is a family of non-negative functions in $C_c^\infty(\RR^n)$ which are eventually supported on every neighbourhood of the origin, and integrate to one, then $\phi_\alpha$ is an approximation to the identity in the space of test functions and in the space of distributions.
\end{theorem}
\begin{proof}
    It is easy to verify that if $f$ is a continuous function, then $f * \phi_\delta$ converges locally uniformly to $f$ as $\delta \to 0$. But now we calculate that if $f \in C_c^\infty(\RR^n)$, then $D^\alpha(f * \phi_\delta) = (D^\alpha f) * \phi_\delta$ converges locally uniformly to $D^\alpha \phi$, which gives that $f * \phi$ converges to $f$ in $C_c^\infty(\RR^n)$. Now if $\Lambda$ is a distribution, and $\psi$ is a test function, then continuity gives
    %
    \begin{align*}
        \Lambda(\psi^*) &= \lim_{\delta \to 0} \Lambda(\phi_\delta * \psi) = \lim_{\delta \to 0} (\Lambda * (\phi_\delta * \psi))(0)\\
        &= \lim_{\delta \to 0} ((\Lambda * \phi_\delta) * \psi)(0) = \lim_{\delta \to 0} (\Lambda * \phi_\delta)(\psi^*)
    \end{align*}
    %
    and $\psi$ was arbitrary.
\end{proof}

If $\Lambda$ is a distribution on $\RR^n$, then the map $\phi \mapsto \Lambda * \phi$ is a linear transformation from $C_c^\infty(\RR^n)$ into $C^\infty(\RR^n)$, which commutes with translations. It is also continuous. To see this, we consider a fixed compact $K$, and consider the map from $C_c^\infty(K)$ to $C^\infty(\RR^n)$. We can apply the closed graph theorem to prove continuity, so we assume the existence of $\phi_1, \phi_2, \dots$ converging to $\phi$ in $C_c^\infty(K)$ and $\Lambda * \phi_1, \Lambda * \phi_2, \dots$ converges to $f$. It suffices to show $f = \Lambda * \phi$. But we calculate
%
\[ f(x) = \lim (\Lambda * \phi_n)(x) = \lim \Lambda(T_x \phi^*_n) = \Lambda (\lim T_x \phi^*_n) = \Lambda(T_x \phi^*) = (\Lambda * \phi)(x) \]
%
where we have used the fact that $T_x \phi_n^*$ converges to $T_x \phi^*$ in $C_c^\infty(\RR^n)$. Suprisingly, the converse is true.

\begin{theorem}
    If $L: C_c^\infty(\RR^n) \to C^\infty(\RR^n)$ and commutes with translations, then there is a distribution $\Lambda$ such that $L(\phi) = \Lambda * \phi$.
\end{theorem}
\begin{proof}
    If $L(\phi) = \Lambda * \phi$, then we would have
    %
    \[ \Lambda(\phi) = (\Lambda * \phi^*)(0) = L(\phi^*)(0) \]
    %
    and we take this as the definition of $\Lambda$. $\Lambda$ is continuous because all the operations here are continuous, and because $L$ commutes with translations, we conclude
    %
    \[ (\Lambda * \phi)(x) = \Lambda(T_x \phi^*) = L(T_{-x} \phi)(0) = L(\phi)(x) \]
    %
    which gives the theorem.
\end{proof}

We now move onto the case where a distribution $\Lambda$ has compact support. Then $\Lambda$ extends to a continuous functional on $C^\infty(\RR^n)$, and we can define the convolution $\Lambda * \phi$ if $\phi \in C^\infty(\RR^n)$. The same techniques as before verify that translations and derivatives are carried into the convolution.

\begin{theorem}
    If $\phi$ and $\Lambda$ have compact support, then $\Lambda * \phi$ has compact support.
\end{theorem}
\begin{proof}
    Let $\phi$ and $\Lambda$ be supported on $K$. Then $(\Lambda * \phi)(x) = \Lambda(T_x \phi^*)$. Since $T_x \phi^*$ is supported on $x - K$, for $x$ large enough $x-K$ is disjoint from $K$, and so $\Lambda * \phi$ vanishes outside of $K + K$.
\end{proof}

\begin{theorem}
    If $\Lambda$ and $\psi$ have compact support, and $\phi \in C^\infty(\RR^n)$, then
    %
    \[ \Lambda * (\phi * \psi) = (\Lambda * \phi) * \psi = (\Lambda * \psi) * \phi \]
\end{theorem}
\begin{proof}
    Let $\Lambda$ and $\psi$ be supported on some balanced compact set $K$. Let $V$ be a bounded, balanced open set containing $K$. If $\phi_0$ is a function with compact support equal to $\phi$ on $V + K$, then for $x \in V$,
    %
    \[ (\phi * \psi)(x) = \int \phi(x - y) \psi(y)\; dy = \int \phi_0(x - y) \psi(y)\; dy = (\phi_0 * \psi)(x) \]
    %
    Thus
    %
    \[ (\Lambda * (\phi * \psi))(0) = (\Lambda * (\phi_0 * \psi))(0) = ((\Lambda * \psi) * \phi_0)(0) \]
    %
    But $\Lambda * \psi$ is supported on $K + K$, so $((\Lambda * \psi) * \phi_0)(0) = ((\Lambda * \psi) * \phi)(0)$. Now we also calculate
    %
    \[ (\Lambda * (\phi * \psi))(0) = ((\Lambda * \phi_0) * \psi)(0) = ((\Lambda * \phi) * \psi)(0) \int (\Lambda * \phi_0)(-y) \psi(y) \]
    %
    where the last fact follows because $\Lambda * \phi_0$ agrees with $\Lambda * \phi$ on $K$. The general fact follows by applying the translation operators.
\end{proof}

Now we come to the grand finale, defining the convolution of two distributions. Given two distributions $\Lambda$ and $\Psi$, one of which has compact support, we define the linear operator
%
\[ L(\phi) = \Lambda * (\Psi * \phi) \]
%
Then $L$ commutes with translations, and is continuous, because if we have $\phi_1, \phi_2, \dots$ converging to $\phi$ in $C_c^\infty(K)$, then $\Psi * \phi_n$ converges to $\Psi * \phi$ in $C^\infty(\RR^n)$. If $\Psi$ is supported on a compact support $C$, then the $\Psi * \phi_n$ have common compact support $C + K$, and actually converge in $C_c^\infty(C + K)$, hence $\Lambda * (\Psi * \phi_n)$ converges to $\Lambda * (\Psi * \phi)$. Conversely, if $\Lambda$ has compact support, then $\Psi * \phi_n$ converges in $C^\infty(\RR^n)$, which implies $\Lambda * (\Psi * \phi_n)$ converges to $\Lambda * (\Psi * \phi)$ in $C^\infty(\RR^n)$. Thus $L$ corresponds to a distribution, and we define this distribution to be $\Lambda * \Psi$.

\begin{theorem}
    If $\Lambda$ and $\Psi$ are distributions, one of which has compact support, then $\Lambda * \Psi = \Psi * \Lambda$. Let $S_\Lambda$ and $S_\Psi$, and $S_{\Lambda * \Psi}$ denote the supports of $\Lambda$, $\Psi$, and $\Lambda * \Psi$. Then $\Lambda * \Psi = \Psi * \Lambda$, and $S_{\Lambda * \Psi} \subset S_\Lambda + S_\Psi$.
\end{theorem}
\begin{proof}
    We calculate that for any two test functions $\phi$ and $\psi$,
    %
    \[ (\Lambda * \Psi) * (\phi * \psi) = \Lambda * (\Psi * (\phi * \psi)) = \Lambda * ((\Psi * \phi) * \psi) \]
    %
    If $\Lambda$ has compact support, then
    %
    \[ \Lambda * ((\Psi * \phi) * \psi) = (\Lambda * \psi) * (\Psi * \phi) \]
    %
    Conversely, if $\Psi$ has compact support, then
    %
    \[ \Lambda * ((\Psi * \phi) * \psi) = \Lambda * (\psi * (\Psi * \phi)) = (\Lambda * \psi) * (\Psi * \phi) \]
    %
    We also calculate
    %
    \begin{align*}
        \Psi * ((\Lambda * \phi) * \psi) &= \Psi * (\Lambda * (\phi * \psi)) = \Psi * (\Lambda * (\psi * \phi))\\
        &= \Psi * ((\Lambda * \psi) * \phi) = (\Psi * \phi) * (\Lambda * \psi)
    \end{align*}
    %
    But since convolution is commutative, we have
    %
    \[ ((\Lambda * (\Psi * \phi)) * \psi) = \Lambda * ((\Psi * \phi) * \psi) = \Psi * ((\Lambda * \phi) * \psi) = (\Psi * (\Lambda * \phi)) * \psi \]
    %
    Since $\psi$ was arbitrary, we conclude
    %
    \[ (\Lambda * \Psi) * \phi = \Lambda * (\Psi * \phi) = \Psi * (\Lambda * \phi) = (\Psi * \Lambda) * \phi \]
    %
    and now since $\phi$ was arbitrary, we conclude $\Lambda * \Psi = \Psi * \Lambda$. Now we know convolution is commuatative, we may assume $S_\Psi$ is compact. The support of $\Psi * \phi^*$ lies in $S_\Psi - S_\phi$. But this means that if $S_\phi - S_\Psi$ is disjoint from $S_\Lambda$, which means exactly that $S_\phi$ is disjoint from $S_\Lambda + S_\Psi$, then
    %
    \[ (\Lambda * \Psi)(\phi) = (\Lambda * (\Psi * \phi))(0) = 0 \]
    %
    and this gives the support of $\Lambda * \Psi$.
\end{proof}

This means that the convolution of two distributions with compact support also has compact support. This means that if we have three distributions $\Lambda, \Psi$, and $\Phi$, two of which have compact support, then the distributions $\Lambda * (\Psi * \Phi)$ and $(\Lambda * \Psi) * \Phi$ are well defined, so convolution is associative and commutative. We calculate that for any test function $\phi$,
%
\[ (\Lambda * (\Psi * \Phi)) * \phi = \Lambda * (\Psi * (\Phi * \phi)) \]
\[ ((\Lambda * \Psi) * \Phi) * \phi = (\Lambda * \Psi) * (\Phi * \phi) \]
%
If $\Phi$ has compact support, then $\Phi * \phi$ has compact support, and so we can move $(\Lambda * \Psi)$ into the equation to prove equality. If $\Phi$ does not have compact support, then $\Lambda$ and $\Psi$ have compact support, and
%
\[ \Lambda * (\Psi * \Phi) = \Lambda * (\Phi * \Psi) \]
%
and we can apply the previous case to obtain that this is equal to $(\Lambda * \Phi) * \Psi$. Repeatedly applying the previous case brings this to what we want.

\begin{theorem}
    If $\Lambda$ and $\Psi$ are distributions, then
    %
    \[ D^\alpha(\Lambda * \Psi) = (D^\alpha \Lambda) * \Psi = \Lambda * (D^\alpha \Psi) \]
\end{theorem}
\begin{proof}
    The Dirac delta function $\delta$ satisfies
    %
    \[ (\delta * \phi)(x) = \int \phi(y) \delta(x-y)\; dy = \phi(x) \]
    %
    so $\delta * \phi = \phi$. Now $D^\alpha \delta$ is also supported at $x$, since
    %
    \[ (D^\alpha \delta)(\phi) = (-1)^{|\alpha|} \int \delta(x) (D^\alpha \phi)(x)\; dx = (-1)^{|\alpha|} (D^\alpha \phi)(0) \]
    %
    which means that for any distribution $\Lambda$, then $(D^\alpha \delta) * \Lambda$ has compact support,
    %
    \[ (((D^\alpha \delta) * \Lambda) * \phi)(0) = (D^\alpha \delta)((\Lambda * \phi)^*) = (-1)^{|\alpha|} D^\alpha (\Lambda * \phi)^* = ((D^\alpha \Lambda) * \phi)(0) \]
    %
    which verifies that $(D^\alpha \delta) * \Lambda = \delta * (D^\alpha \Lambda)$. But now we find
    %
    \[ D^\alpha(\Lambda * \Psi) = (D^\alpha \delta) * \Lambda * \Psi = ((D^\alpha \delta) * \Lambda) * \Psi = D^\alpha \Lambda * \Psi \]
    \[ D^\alpha(\Lambda * \Psi) = D^\alpha(\Psi * \Lambda) = (D^\alpha \Psi) * \Lambda = \Lambda * (D^\alpha \Psi) \]
    %
    which verifies the theorem in general.
\end{proof}

\section{Schwartz Space and Tempered Distributions}

We have already encountered the fact that Fourier transforms are well behaved under differentiation and multiplication by polynomials. If we let $\mathcal{S}(\RR^d)$ denote a class of functions under which to study this phenomenon, it must be contained in $L^1(\RR^d)$ and $C^\infty(\RR^d)$, and also be closed under multiplication by polynomials. The differentiability and polynomial closure imply that the elements of $\mathcal{S}(\RR^d)$ must have rapid decay properties: For any non-negative integer $m$ and multi-index $\alpha$, there exists a constant $C_{\alpha,\beta}$ such that
%
\[ |f_\alpha(x)| \leq \frac{C_{\alpha,m}}{1 + |x|^m}. \]
%
We take this as a \emph{definition} of the space $\mathcal{S}(\RR^d)$. That is, for each non-negative integer $n$ and $m$, we consider the seminorm
%
\[ \| f \|_{n,m} = \sup_{|\beta| \leq n} \| (1 + |x|)^m f_\beta \|_{L^\infty(\RR^d)}. \]
%
We then consider
%
\[ \mathcal{S}(\RR^d) = \left\{ f: \RR^d \to \RR: \text{for all}\ n,m, \| f \|_{n,m} < \infty \right\}. \]
%
Elements of $\mathcal{S}(\RR^d)$ are known as \emph{Schwartz functions}, and $\mathcal{S}(\RR^d)$ is known as the \emph{Schwartz space}. The seminorms naturally give $\mathcal{S}(\RR^d)$ the structure of a Fr\'{e}chet space. Sometimes, it is more convenient to use the equivalent family of seminorms $\| f \|_{\alpha, \beta} = \| x^\alpha f_\beta \|_{L^\infty(\RR^d)}$, because $x^\alpha$ often behaves more nicely under various operations. It is obvious that $\mathcal{S}(\RR^d)$ is separated by the seminorms defined on it, because $\| \cdot \|_{L^\infty(\RR^d)} = \| \cdot \|_{0,0}$ is a norm used to define the space. We now show the choice of seminorms make the space complete.

\begin{theorem}
    $\mathcal{S}(\RR^d)$ is a complete metric space.
\end{theorem}
\begin{proof}
    Let $\{ f_1,f_2, \dots \}$ be a Cauchy sequence with respect to the seminorms. This implies that for each integer $m$, and multi-index $\alpha$, the sequence of functions $(1 + |x|)^m (f_k)_\alpha$ is Cauchy in $L^\infty(\RR^d)$. Since $L^\infty(\RR^d)$ is complete, there are functions $g_{m,\alpha}$ such that $(1 + |x|)^m (f_k)_\alpha$ converges uniformly to $g_{m,\alpha}$. If we set $f = g_{0,0}$, then it is easy to see using the basic real analysis of uniform continuity that $f$ is infinitely differentiable, and $(1 + |x|)^m f_\alpha = g_{m,\alpha}$. This shows that $f \in C^\infty(\RR^d)$. The sequence $\{ f_k \}$ is bounded in $\mathcal{S}(\RR^d)$, since it is Cauchy. And since $\| f_k - f \|_{n,m} \to 0$ for each $n$ and $m$, this implies that $\| f \|_{n,m} < \infty$ for each $n$ and $m$. Thus $f \in \mathcal{S}(\RR^d)$, and $f_k \to f \in \mathcal{S}(\RR^d)$.
\end{proof}

\begin{example}
    The Gaussian function $\phi: \RR^d \to \RR$ defined by $\phi(x) = e^{-|x|^2}$ is Schwartz. For any multi-index $\alpha$, there is a polynomial $P_\alpha$ of degree at most $|\alpha|$ such that $\phi_\alpha = P_\alpha \phi$; this can be established by a simple induction. But this means that for each fixed $\alpha$, $|P_\alpha(x)| \lesssim 1 + |x|^{|\alpha|}$. Since $e^{-|x|^2} \lesssim 1/(1 + |x|)^{m + |\alpha|}$ for any fixed $m$ and $\alpha$, we find
    %
    \[ | (1 + |x|)^m \phi_\alpha| \leq (1 + |x|)^m |P_\alpha \phi| \lesssim \frac{1 + |x|^{|\alpha| + m}}{1 + |x|^{|\alpha| + m}} = 1. \]
    %
    Since $m$ and $\alpha$ were arbitrary, this shows $\phi$ is Schwartz.
\end{example}

\begin{example}
    The space $C^\infty_c(\RR^d)$ consists of all compactly supported $C^\infty$ functions. If $f \in C^\infty_c(\RR^d)$, then $f$ is Schwartz. This is because for each $\alpha$ and $m$, $(1 + |x|)^m f_\alpha$ is a continuous function vanishing outside a compact set, and is therefore bounded.
\end{example} 

Because of the sharp control we have over functions in $\mathcal{S}(\RR^d)$, almost every analytic operation we want to perform on $\mathcal{S}(\RR^d)$ is continuous. To show that an operator $T$ on $\mathcal{S}(\RR^d)$ is bounded, it suffices to show that for each $n$ and $m$, there is $n'$, $m'$ such that $\| Tf \|_{n,m} \lesssim_{n,m} \| f \|_{n',m'}$. For a functional $\Lambda: \mathcal{S}(\RR^d) \to \RR$, it suffices to show that there exists $n$ and $m$ such that $|\Lambda f| \lesssim \| f \|_{n,m}$. The minimal such choice of $n$ is known as the {\bf order} of $\Lambda$. We normally do not care about the constant behind the operators for these norms, since the norms are not translation invariant and therefore highly sensitive to the positions of various operations. We really just care about proving the existence of such a constant.

\begin{lemma}
    If $g$ is a function, with $g$ and all it's derivatives subpolynomial, then the map $f \mapsto gf$ is a bounded operator on $\mathcal{S}(\RR^d)$.
\end{lemma}
\begin{proof}
    Fix $n$, and find values $A$ and $M$, depending only on $n$ and $g$, such that for any $|\beta| \leq n$,
    %
    \[ |g_\beta(x)| \leq A \cdot (1 + |x|)^M. \]
    %
    Consider $|\alpha| \leq n$. Then the Leibnitz formula implies that
    %
    \begin{align*}
        (1 + |x|)^m |(gf)_\alpha| &\leq 2^{|\alpha|} \sum_{\beta \leq \alpha} (1 + |x|)^m |g_\beta f_{\alpha-\beta}|\\
        &\leq A \cdot 2^n \sum_{\beta \leq \alpha} (1 + |x|)^{m+M} |f_{\alpha-\beta}|\\
        &\leq A \cdot 4^n \| f \|_{n,m+M}.
    \end{align*}
    %
    Thus $\| gf \|_{n,m} \lesssim_{n,m} \| f \|_{n,m+M}$, which implies the operator is bounded.
\end{proof}

If $f$ and $g$ are Schwartz functions, and $|\alpha| \leq n$, then the Leibnitz formula again implies that if $k + k' = m$, then
%
\begin{align*}
    (1 + |x|)^m (gf)_\alpha &\lesssim_n \sum_{\beta \leq \alpha} (1 + |x|)^m g_\beta f_{\alpha - \beta} \lesssim_n \| f \|_{n,k} \| g \|_{n,k'}
\end{align*}
%
Thus $\| gf \|_{n,m} \lesssim_{n,m} \| f \|_{n,k} \| g \|_{n,k'}$, so $(f,g) \mapsto fg$ is a continuous bilinear operator on $\mathcal{S}(\RR^d) \times \mathcal{S}(\RR^d)$. Most importantly, we have shown the product of two Schwartz functions is Schwartz.

\begin{theorem}
    The following sublinear operators are all bounded on $\mathcal{S}(\RR^n)$.
    %
    \begin{itemize}
        \item For each $h \in \RR^n$, the translation operator $(T_h f)(x) = f(x - h)$.

        \item For each $\xi \in \RR^n$, the modulation operator $(M_\xi f)(x) = e(\xi \cdot x) f(x)$.

        \item The $L^p$ norms $\| f \|_{L^p(\RR^n)}$, for $1 \leq p \leq \infty$.

        \item The Fourier transform.
    \end{itemize}
    %
    Furthermore, the Fourier transform is an isomorphism of $\mathcal{S}(\RR^n)$.
\end{theorem}
\begin{proof}
%   Let $(T_h f)(x) = f(x - h)$. We calculate that if $|\alpha| \leq n$, then
    %
%   \begin{align*}
%       (1 + |x|^m) (T_h f)_\alpha &= T_h((1 + |x + h|^m) f_\beta)\\
%       &\leq 2^m T_h((1 + |x|^m + |h|^m) f_\alpha)\\
%       &\leq 2^m |h|^m \| f_\alpha \|_{n,0} + 2^m \| f \|_{n,m}.
%   \end{align*}
    %
%   Thus $\| T_h f \|_{n,m} \leq 2^m(1 + |h|^m) \| f \|_{n,m}$, so $T_h$ is continuous.

%   Similarily, we calculate using the Leibnitz formula and the formula for the derivatives of $e(\xi \cdot x)$ that if $|\alpha| \leq n$, then
    %
%   \[ (1 + |x|^m) |(e(\xi \cdot x) f)_\alpha| \leq 4^n (2\pi)^n (1 + |\xi|^n) \| f \|_{n,m} \]
    %
%   Thus $\| M_\xi f \|_{n,m} \leq (8 \pi)^n (1 + |\xi|^n) \| f \|_{n,m}$.

%   For any Schwartz function $f$, and $|\alpha| \leq n$,
    %
%   \[ f(x) \leq \frac{\| f \|_{0,d+1}}{1 + |x|^{d+1}} \]
    %
%   Integrating this equation gives
    %
%   \[ \| f_\alpha \|_{L^1(\RR^d)} \leq 2^d \| f \|_{0,d+1}. \]
    %
%   Thus $\| \cdot \|_1$ is a bounded norm on the space. Interpolation then shows that for any $1 < p < \infty$,
    %
%   \[ \| f \|_{L^p(\RR^d)} \leq \| f \|_{L^1(\RR^d)}^{1 - 1/p} \| f \|_{L^\infty(\RR^d)}^{1/p} \leq \| f \|_{L^1(\RR^d)} + \| f \|_{L^\infty(\RR^d)} \leq 2 \| f \|_{0,d+1}. \]
    %
%   This implies $\| \cdot \|_{L^p(\RR^d)}$ is bounded.

%   A simple calculation using the Leibnitz formula shows that if $|\alpha| \leq n$,
    %
%   \begin{align*}
%       (1 + |x|^m) |\mathcal{F}(f)_\alpha| &\leq |\mathcal{F}(f)_\alpha| + \sum_{k = 1}^d |x_k^m \mathcal{F}(f)_\alpha|\\
%       &\leq (2 \pi)^n \left( \| \mathcal{F} f \|_{L^\infty(\RR^d)} + \sum_{k = 1}^d |\mathcal{F}((x^\alpha f)_{me_k})| \right)\\
%       &\leq n! (2 \pi)^n 2^m (n+1) \max_{0 \leq k \leq d} \max_{1 \leq l \leq m} \left( \| \mathcal{F} f \|_{L^\infty(\RR^d)} + \sum_{k = 1}^n \max_{1 \leq l \leq m} \| \mathcal{F}(f_{le_k}) \|_{L^\infty(\RR^d)} \right)\\
%       &\leq n! (2 \pi)^n 2^m \left( \| f \|_{L^1(\RR^d)} + \sum_{k = 1}^n \max_{1 \leq l \leq m} \| f_{le_k} \|_{L^1(\RR^d)} \right)\\
%       &\leq n! (2 \pi)^n 2^m 2^d (n+1) \| f \|_{n,d+1}.
%   \end{align*}

%   there are constants $c_{\alpha \beta \gamma}$ for each $\gamma \leq \alpha \wedge \beta$ such that
    %
%   \begin{align*}
%       |x^\alpha \mathcal{F}(f)_\beta| &= (2 \pi)^{|\beta|} |x^\alpha \cdot \mathcal{F}(x^\beta f)|\\
%       &= (2\pi)^{|\beta| - |\alpha|} \mathcal{F}((x^\beta f)_\alpha)\\
%       &\leq (2\pi)^{|\beta| - |\alpha|} \sum_{\gamma \leq \alpha \wedge \beta} c_{\alpha \beta \gamma} |\mathcal{F}(x^{\beta - \gamma} f_{\alpha - \gamma})|.
%   \end{align*}
    %
%   This calculation shows
    %
%   \begin{align*}
%       \| \mathcal{F} f \|_{\alpha,\beta} &\lesssim_{\alpha,\beta} \sum \| \mathcal{F}(x^{\beta - \gamma} f_{\alpha - \gamma}) \|_{L^\infty(\RR^n)}\\
%       &\leq \sum \| x^{\beta - \gamma} f_{\alpha - \gamma} \|_{L^1(\RR^n)}.
%   \end{align*}
    %
%   The right hand side is a continuous function of $f$, so the Fourier transform is bounded. The smoothness of the Schwartz space implies that $\mathcal{F}$ is a bijective map. But then the open mapping theorem implies that $\mathcal{F}^{-1}$ is a bounded operation, and therefore $\mathcal{F}$ is a homeomorphism.

    We leave all but the last point as exercises. Here it will be convenient to use the norms $\| \cdot \|_{\alpha,\beta}$ as well as the norms $\| \cdot \|_{n,m}$. If $|\alpha| \leq m$, $|\beta| \leq n$, then we can use the Leibnitz formula to conclude that
    %
    \begin{align*}
        |\xi^\alpha \mathcal{F}(f)_\beta| &\lesssim_{\alpha,\beta} \mathcal{F}((x^\beta f)_\alpha)\\
        &\lesssim_{\alpha,\beta} \max_{\gamma \leq \alpha \wedge \beta} |\mathcal{F}(x^{\beta - \gamma} f_{\alpha - \gamma})|\\
        &\lesssim_{\alpha,\beta} \max_{\gamma \leq \alpha \wedge \beta} \| x^{\beta - \gamma} f_\gamma \|_{L^1(\RR^d)}\\
        &\leq \max_{\gamma \leq \alpha \wedge \beta} \| (1 + |x|)^{|\beta|} f_\gamma \|_{L^1(\RR^d)} \lesssim \| f \|_{|\alpha|,|\beta|+d+1}.
    \end{align*}
    %
    Thus $\mathcal{F}$ is a bounded linear operator on $\mathcal{S}(\RR^d)$. Since all Schwartz functions are arbitrarily smooth, the Fourier inversion formula applies to all Schwartz functions, and so $\mathcal{F}$ is a bijective bounded linear operator with inverse $\mathcal{F}^{-1}$. The open mapping theorem then immediately implies that $\mathcal{F}^{-1}$ is bounded.
\end{proof}

\begin{corollary}
    If $f$ and $g$ are Schwartz, then $f * g$ is Schwartz.
\end{corollary}
\begin{proof}
    Since $f * g = \mathcal{F}^{-1}(\mathcal{F}(f) \mathcal{F}(g))$, this fact follows from the fact that the product of two Schwartz functions is Schwartz.
\end{proof}

Now we get to the interesting part of the theory. We have defined a homeomorphic linear transform from $\mathcal{S}(\RR^d)$ to itself. The theory of functional analysis then says that we can define a dual map, which is a homeomorphism from the dual space $\mathcal{S}(\RR^d)^*$ to itself. Note the inclusion map $C_c^\infty(\RR^d) \to \mathcal{S}(\RR^d)$ is continuous, and $C_c^\infty(\RR^d)$ is dense in $\mathcal{S}(\RR^d)$. This implies that we have an injective, continuous map from $\mathcal{S}^*(\RR^d)$ to $(C_c^\infty)^*(\RR^d)$, so every functional on the Schwarz space can be identified with a distribution. We call such distributions {\bf tempered}. They are precisely the linear functionals on $C_c^\infty(\RR^d)$ which have a continuous extension to $\mathcal{S}(\RR^d)$. Intuitively, this corresponds to an asymptotic decay condition.

\begin{example}
    For any $f \in L^1_{\text{loc}}(\RR^d)$, we define $\Lambda[f]$ to be the distribution
    %
    \[ \Lambda[f](\phi) = \int f(x) \phi(x)\; dx \]
    %
    But this distribution is not always tempered. If $f \in L^p(\RR^d)$ for some $p$, then, applying H\"{o}lder's inequality, we obtain that
    %
    \[ |\Lambda[f](\phi)| \leq \| f \|_{L^p(\RR^d)} \| \phi \|_{L^q(\RR^d)}. \]
    %
    Since $\| \cdot \|_{L^q(\RR^d)}$ is a continuous norm on $\mathcal{S}(\RR^d)$, this shows $\Lambda[f]$ is bounded. More generally, if $f \in L^1_{\text{loc}}(\RR^d)$, and $f(x) (1 + |x|)^{-m}$ is in $L^p(\RR^d)$ for some $m$, then $\Lambda[f]$ is a tempered distribution. If $p = \infty$, such a function is known as {\bf slowly increasing}.
\end{example}

\begin{example}
    For any Radon measure, $\mu$, we can define a distribution
    %
    \[ \Lambda[\mu](\phi) = \int \phi(x) d\mu(x) \]
    %
    But this distribution is not always tempered. If $|\mu|$ is finite, the inequality $\| \Lambda[\mu](\phi) \| \leq \| \mu \| \| \phi \|_{L^\infty(\RR^d)}$ gives boundedness. More generally, if $\mu$ is a measure such that $|\mu(x)|/(1 + |x|^\alpha)$ is finite for some $k$, then $\mu$ is known as a {\bf tempered measure}, and also acts as a tempered distribution, since
    %
    \[ |\Lambda[\mu](\phi)| \leq \| \mu(x)/(1 + |x|^\alpha) \| \| \phi \|_{L^\infty(\RR^d, 1 + |x|^\alpha)}. \]
\end{example}

\begin{example}
    Suppose $\Lambda$ is a distribution supported on a compact set $K$. Then $\Lambda$ is tempered, since if $\psi$ is a compactly supported bump function on $K$, then for any Schwarz function $\phi$ we can define $\Lambda(\phi) = \Lambda(\psi \phi)$, which is continuous.
\end{example}

\begin{example}
    The function $1/x$ is not locally integrable on $\RR$, since it is not defined near the origin. However, we can associate the value with a distribution. If $\phi$ is a Schwartz function, we define the {\bf principal value}
    %
    \[ \text{p.v.} \int_{-\infty}^\infty \frac{\phi(x)}{x}\; dx = \lim_{\varepsilon \to 0} \int_{|x| \geq \varepsilon} \frac{\phi(x)}{x}\; dx \]
    %
    Since $\int_{\varepsilon \leq |x| \leq 1} dx/x = 0$ for any $\varepsilon \leq 1$, we can write
    %
    \[ \int_{|x| \geq \varepsilon} \frac{\phi(x)}{x} = \int_{|x| \geq 1} \frac{\phi(x)}{x} + \int_{\varepsilon \leq |x| \leq 1} \frac{\phi(x) - \phi(0)}{x} \]
    %
    Since $\phi$ has rapid decay, the first integral is well defined. Since $\phi$ is differentiable at the origin, the second integral is bounded for all $\varepsilon \geq 0$. But this means that
    %
    \[ \lim_{\varepsilon \to 0} \frac{\phi(x)}{x} = \int_{|x| \geq 1} \frac{\phi(x)}{x} + \int_{|x| \leq 1} \frac{\phi(x) - \phi(0)}{x} \]
    %
    Thus it is evident that the principal value exists, and
    %
    \[ \left| \text{p.v.} \int_{-\infty}^\infty \frac{\phi(x)}{x}\; dx \right| \lesssim \| \phi \|_{L^1(\RR)} + \| \phi' \|_{L^\infty(\RR)} \]
    %
    so this functional is a tempered distribution of order 1, and is denoted by $\text{p.v.}(1/x)$. It is intimately connected to the theory of the Hilbert transform. 
\end{example}

Using the same techniques as for distributions, the derivative $\Lambda_\alpha$ of a tempered distribution $\Lambda$ is tempered, as is $\phi \Lambda$, whenever $\phi$ is a Schwartz function, or $f \Lambda$, where $f$ is a polynomial.

To remind the reader, we think of a distribution $\Lambda$ as corresponding to arbitrarily regular function $f$ such that
%
\[ \Lambda(\phi) = \int f(x) \phi(x)\; dx \]
%
If we can justify an identity with respect to this operation which removes the reliance of regularity on $f$, we can normally swap $f$ with a general distribution, and use it to define the operation on all distributions.

We now apply this process to define the Fourier transform of a tempered distribution. The multiplication formula
%
\[ \int \widehat{f}(x) g(x) = \int f(x) \widehat{g}(x) \]
%
provides the perfect situation. It says that for $f \in L^1(\RR^d)$, $\Lambda_{\mathcal{F}(f)}(g) = \Lambda_f(\mathcal{F}(g))$. If we want to generalize the Fourier transform to be defined on distributions, we better have $\mathcal{F}(\Lambda_f) = \Lambda_{\mathcal{F}(f)}$ for all integrable $f$. In particular, this motivates us to define the general Fourier transform of a tempered distribution $\Lambda$ as $\mathcal{F}(\Lambda)(\phi) = \Lambda \left( \mathcal{F}(\phi) \right)$. Similarily, we can define the inverse Fourier transform, which are the dual maps of the Fourier transforms and it's inverse, so they are obviously homeomorphisms of the space of tempered distributions.

\begin{theorem}
    If $\Lambda$ is tempered,
    %
    \[ \mathcal{F}(\Lambda_\alpha) = (-2 \pi i \xi)^\alpha \mathcal{F}(\Lambda)\quad\text{and}\quad \mathcal{F}((-2\pi i \xi)^\alpha \Lambda)) = \mathcal{F}(\Lambda)_\alpha. \]
\end{theorem}

\begin{example}
    Consider the constant function $1$. Then
    %
    \[ 1(\phi) = \int \phi(x)\; dx \]
    %
    and so
    %
    \[ \widehat{1}(\phi) = \int \widehat{\phi}(\xi)\; d\xi = \phi(0) = \delta(\phi) \]
    %
    so $\widehat{1}$ is the Dirac delta distribution $\delta$. Similarily,
    %
    \[ \widehat{\delta}(\phi) = \widehat{\phi}(0) = \int \phi(x)\; dx = 1(\phi) \]
    %
    so the Fourier transform of the Dirac delta function is the constant 1 function.
\end{example}

\begin{example}
    We know $((-2 \pi i x)^\alpha)^\ft = ((- 2 \pi i x)^\alpha \cdot 1)^\ft = \delta_\alpha$, which essentially provides us a way to compute the Fourier transform of any polynomial.
\end{example}

\begin{theorem}
    If $\mu$ is a finite measure, $\widehat{\mu}$ is a uniformly continuous bounded function with $\| \widehat{\mu} \|_{L^\infty(\RR^d)} \leq \| \mu \|$, and
    %
    \[ \widehat{\mu}(\xi) = \int e(- x \cdot \xi) d\mu(x) \]
    %
    The function $\widehat{\mu}$ is also smooth if $\mu$ has moments of all orders, i.e. $\int |x|^k d\mu(x) < \infty$ for all $k > 0$.
\end{theorem}
\begin{proof}
    Let $\phi \in \mathcal{S}(\RR^d)$. We then calculate that
    %
    \[ \widehat{\mu} \cdot \phi \]

    If $f$ is integrable, we can apply Fubini's theorem to conclude
    %
    \begin{align*}
        \int \widehat{f}(x) d\mu(x) &= \int \int f(\xi) e(- \xi \cdot x) d\xi\; d\mu(x)\\
        &= \int f(\xi) \int e(- \xi \cdot x) d\mu(x)\; d\xi\\
        &= \int f(\xi) \widehat{\mu}(\xi)\; d\xi
    \end{align*}
    %
    This gives that the distribution $\widehat{\mu}$ is given by integration with respect the required function. It is easy to check that $\| \widehat{\mu} \|_{L^\infty(\RR^d)} \leq \| \mu \|$. Moreover, $\widehat{\mu}$ is continuous, since by the dominated convergence theorem,
    %
    \[ \widehat{\mu}(\xi + \eta) - \widehat{\mu}(\xi) = \int e(-\xi \cdot x) (e(- \eta \cdot x) - 1) d\mu(x) \]
    %
    as $h \to 0$, the values of the function in the integral converge pointwise to $0$, and so the uniform continuity follows by the dominated convergence theorem. 

    To show $\widehat{\mu}$ is smooth if it has all moments, we calculate that if $|\eta| = 1$, and $t \in \RR$, then
    %
    \[ \frac{\widehat{\mu}(\xi + t \eta) - \widehat{\mu}(\xi)}{t} = \int e(- \xi \cdot x)(e(-t \eta \cdot x) - 1)\; d\mu(x). \]
\end{proof}

Not being compactly supported, we cannot compute the convolution of tempered distributions with all $C^\infty$ functions. Nonetheless, if $\phi$ is Schwartz, and $\Lambda$ is tempered, then the definition $(\Lambda * \phi)(x) = \Lambda(T_x \phi^*)$ certainly makes sense, and gives a $C^\infty$ function satisfying $D^\alpha(\Lambda * \phi) = (D^\alpha \Lambda) * \phi = \Lambda * (D^\alpha \phi)$. This function is slowly increasing, since it has polynomial growth. We know for some $N > 0$, for any Schwartz $\phi$,
%
\[ |\Lambda(\phi)| \lesssim \sup \{ |x^\alpha| |D^\beta \phi| : |\alpha|, |\beta| \leq N, k > 0 \} \]
%
TODO: FINSIH THIS. Because $\Lambda * \phi$ is tempered, this means that we can consider the Fourier transform $\smash{\widehat{\Lambda * \phi}}$. If $\psi$ is compactly supported, then
%
\[ (\Lambda * \phi)^\ft \left(\widehat{\psi} \right) = s \]
%
TODO: FINISH, which proves $\widehat{\Lambda * \phi} = \widehat{\Lambda} \widehat{\phi}$.

\begin{example}
    It is often useful to know the Fourier transform of the radial functions $f(x) = 1/|x|^\alpha$ on $\RR^d$, for $\alpha < d$, so that the function is locally integrable. Since $f$ satisfies a multiplicative symmetry $f(tx) = t^{-\alpha} f(x)$, the multiplicative Haar measure $dt/t$ become very useful in the analysis of this function. We calculate that the multiplicative convolution of this character against a Gaussian gives, for $\alpha > 0$, by a change of variables,
    %
    \[ \int_0^\infty t^\alpha e^{- \pi t^2 |x|^2}\; \frac{dt}{t} = \frac{1}{2\pi^{\alpha/2} |x|^\alpha} \int_0^\infty s^{\alpha/2} e^{-s} \frac{ds}{s} = \frac{\Gamma(\alpha/2)}{2 \pi^{\alpha/2} |x|^\alpha} \]
    %
    Let $g(x)$ denote the left hand side of the equation. Then if $\phi$ is an arbitrary Schwarz function, for $\alpha < d$, using Fubini's theorem,
    %
    \begin{align*}
        \int g(x) \phi^\vee(x)\; dx &= \int \int \int_0^\infty t^\alpha e^{- \pi t^2 |x|^2}\; \phi(\xi) e(\xi \cdot x)\; \frac{dt}{t}\; d\xi\; dx\\
        &= \int \phi(\xi) \int_0^\infty t^\alpha \int e^{- \pi t^2 |x|^2} e(\xi \cdot x)\; dx\; \frac{dt}{t}\; d\xi\\
        &= \int \phi(\xi) \int_0^\infty t^{\alpha - d} e^{- \pi |\xi|^2/t^2}\; \frac{dt}{t}\; d\xi\\
        &= \int \frac{\Gamma((d-\alpha)/2)}{2\pi^{(d-\alpha)/2} |\xi|^{d - \alpha}} \phi(\xi)\; d\xi
    \end{align*}
    %
    Thus, putting these two calculations together, we conclude
    %
    \[ \frac{\Gamma(\alpha/2)}{2 \pi^{\alpha/2}} (1/|x|^\alpha)^\ft = \frac{\Gamma((d-\alpha)/2)}{2 \pi^{(d-\alpha)/2} |\xi|^{d-\alpha}} \]
    %
    which can be simplified to
    %
    \[ (1/|x|^\alpha)^\ft = \frac{\Gamma((d-\alpha)/2)}{\Gamma(\alpha/2)} \pi^{\alpha-d/2} \frac{1}{|\xi|^{d-\alpha}} \]
    %
    Thus the Fourier transforms $|x|^{-\alpha}$ for $\alpha \in (0,d)$ map into themselves. For $\alpha \geq d$, we need to work with principal values TODO:
\end{example}

\section{Convolution Operators}

It is know that if $T: D(\RR^d) \to C^\infty(\RR^d)$ is any continuous linear functional commuting with translations, it is given by convolution from some distribution. If this convolution is with respect to some tempered distribution, then the transformation extends from a map from $\mathcal{S}(\RR^d)$ to $C^\infty(\RR^d)$. Studying the class of operators which commute with translations is very important because these operators occur again and again in Harmonic analysis. To begin with, with rely on a regularity result on the differentiation of functions in $L^p$ spaces.

\begin{lemma}
    If $f \in L^p(\RR^d)$, has derivatives in the $L^p$ norm of all orders $\leq d+1$, then $f$ is almost everywhere equal to a continuous function $g$ such that
    %
    \[ |g(0)| \lesssim \sum_{|\alpha| \leq n + 1} \| D^\alpha f \|_p \]
    %
    where the hidden constant depends only on $n$ and $p$.
\end{lemma}
\begin{proof}
    s
\end{proof}

\begin{theorem}
    If $T: L^p(\RR^d) \to L^q(\RR^d)$ is bounded, linear, and commutes with translations, then there exists a unique tempered distribution $\Lambda$ such that $T(\phi) = \Lambda * \phi$ for all $\phi \in \mathcal{S}(\RR^d)$
\end{theorem}
\begin{proof}
    If $T$ commutes with translations, then for any Schwartz function $\phi$, $T\phi$ has derivatives in the $L^q$ norm of all orders, since $\Delta_{h,e}(T \phi) = T(\Delta_{h,e} \phi)$, and $\Delta_{h,e} \phi$ converges to $D_e \phi$ in the $L^q$ norm, since the $L^q$ norm is continuous in Schwartz space. In particular, we find $D^\alpha (T\phi) = T(D^\alpha \phi)$. Thus $T\phi$ is equal to a continuous function $g_\phi$ with
    %
    \[ |g_\phi(0)| \lesssim \sum_{|\alpha| \leq n+1} \| D^\alpha(T\phi) \|_q = \sum_{|\alpha| \leq n+1} \| T(D^\alpha \phi) \|_q \leq \| T \| \sum_{|\alpha| \leq n+1} \| D^\alpha \phi \|_q \]
    %
    The map $\phi \mapsto g_\phi(0)$ is therefore continuous on $\mathcal{S}(\RR^d)$, and therefore defines a tempered distribution $\Lambda$, and the fact that $T(\phi) = \Lambda * \phi$ then holds by the translation invariance of $T$.
\end{proof}

\begin{remark}
    It therefore follows that if $T: L^p(\RR^d) \to L^q(\RR^d)$ is bounded, linear, and commutes with translations, then for any Schwartz function $\phi$, $T\phi$ is $C^\infty$, and is slowly increasing, as is all of it's derivatives.
\end{remark}

For each $p$ and $q$, we will let $(L^p,L^q)$ denote the space of tempered distributions which define a continuous linear map from $L^p(\RR^d)$ to $L^q(\RR^d)$, in the sense that the map $\phi \mapsto \Lambda * \phi$ is continuous as a map from $\mathcal{S}(\RR^d)$ to $L^q(\RR^d)$, and, by the Hahn-Banach theorem, extends uniquely to a linear map on the whole space. In general, a characterization of such distributions is unknown except in a few situations.

\begin{example}
    The distributions in $(L^2, L^2)$ are Fourier transforms of elements of $L^\infty(\RR^d)$. The $L^\infty$ norm of the element corresponds to the norm of the convolution operator. To see this, if $\Lambda$ is a distribution, and $\Phi$ is the Gaussian distribution, $\Phi(x) = e^{-\pi|x|^2}$, then $\Lambda * \Phi$ is an $L^2$ function, since $\Phi$ is in $L^2$, and as such we conclude by the Plancherel theorem that $(\Lambda * \Phi)^\ft = \Phi \Lambda^\ft$ is an element of $L^2(\RR^d)$. Thus we can think of $\widehat{\Lambda} = e^{\pi |x|^2} (\Lambda * \Phi)^\ft$ as a function $f$. Plancherel's theorem implies that for any Schwarz function $\phi$,
    %
    \[ \| f \widehat{\phi} \|_2 = \| \Lambda * \phi \|_2 \lesssim \| \phi \|_2 = \| \widehat{\phi} \|_2 \]
    %
    But this means that $f \in L^\infty(\RR^d)$, for if there is a set $E$ of positive measure where $|f| \geq M$, we can find $\widehat{\phi}$ with $\widehat{\phi} = 1$ on $E$ and with $\| \widehat{\phi} \|_2 = |E| + \varepsilon$, and then $\| f \widehat{\phi} \|_2 \geq M \| \widehat{\phi} \|_2$. Note that over $L^2(\mathbf{T})$, the only convolution operators are given by the distributions given by a Fourier series with bounded coefficients.
\end{example}

\begin{example}
    The distributions in $(L^1, L^1)$ are precisely the finite Borel measures. The total variation of the measure corresponds to the norm of the convolution operator. It is clear that if $\mu$ is a Borel measure, then $\| \mu * \phi \|_1 \leq \| \mu \|_1 \| \phi \|_1$. Conversely, if $\Lambda \in (L^1, L^1)$, and $\Phi_\delta$ is the Gauss kernel, then we set $\Lambda_\delta = \Lambda * \Phi_\delta$. By assumption, $\Lambda_\delta$ is an $L^1$ function, and so $\Lambda$, $\| \Lambda_\delta \|_1 \lesssim \| \Phi_\delta \|_1 = 1$. This implies that the $\Lambda_\delta$ are uniformly bounded in $L^1$, so by the Banach Alaoglu theorem, since $L^1(\RR^d)$ embeds itself in $M(\RR^d)$, which is the dual of $C_0(\RR^d)$, some subsequence of the $\Lambda_\delta$ converge weakly to some measure $\mu$. We claim $\Lambda = \Lambda_\mu$. To prove this, fix some Schwartz function $\phi$. If we let $\phi_\delta = \phi * \Phi_\delta$, then $D^\alpha \phi_\delta = (D^\alpha \phi) * \Phi_\delta$ converges uniformly to $D^\alpha \phi$, so $\phi_\delta$ converges to $\phi$ in $\mathcal{S}(\RR^d)$, and so $\Lambda(\phi)$ is the limit of $\Lambda(\phi_\delta)$. But
    %
    \begin{align*}
        \Lambda(\phi_\delta) &= \Lambda(\Phi_\delta * \phi) = (\Lambda * (\Phi_\delta * \phi)^*)(0)\\
        &= ((\Lambda * \Phi_\delta) * \phi^*)(0)\\
        &= \Lambda_\delta(\phi)
    \end{align*}
    %
    and we know some subsequence converges to $\int \phi(x) d\mu(x)$. But we know that overall the values converge to $\Lambda(\phi)$, which implies
    %
    \[ \Lambda(\phi) = \int \phi(x) d\mu(x) \]
    %
    Since $\phi$ was an arbitrary Schwartz function, we can now apply the density of $\mathcal{S}(\RR^d)$ in $L^1(\RR^d)$ to conclude that for any integrable function $f$,
    %
    \[ \Lambda(f) = \int f(x) d\mu(x) \]
    %
    This classifies the $(L^1, L^1)$ distributions.
\end{example}

We also have a duality theorem.

\begin{theorem}
    For any two $(p,q)$, $(L^p,L^q) = (L^{q^*}, L^{p^*})$.
\end{theorem}









\chapter{Sobolev Spaces}

Let $\Omega$ be an open subset of $\RR^d$. A natural problem when studying smooth functions $\phi \in C_c^\infty(\Omega)$ is to obtain estimates on the partial derivatives of $\phi$. For instance, one can consider the norms
%
\[ \| \phi \|_{C^n(\Omega)} = \max_{|\alpha| \leq n} \| D^\alpha f \|_{L^\infty(\Omega)}. \]
%
The space $C_c^\infty(\Omega)$ is not complete with respect to this norm, but it's completion is the space $C^n_b(\Omega)$ of $n$ times bounded continuously differentiable functions on $\Omega$, which still consists of regular functions. Unfortunately, such estimates are only encountered in the most trivial situations. As in the non-smooth case, one can often get much better estimates using the $L^p$ norms of the derivatives, i.e. considering the norms
%
\[ \| \phi \|_{W^{n,p}(\Omega)} = \left( \sum_{|\alpha| \leq p} \| D^\alpha \phi \|_{L^p(\Omega)}^p \right)^{1/p}. \]
%
As might be expected, $C_c^\infty(\Omega)$ is not complete with respect to the $W^{n,p}(\Omega)$ norm. However, it's completion cannot be identified with a family of $n$ times differentiable functions. Instead, to obtain a satisfactory picture of the compoetion under this norm, a Banach space we will denote by $W^{n,p}(\Omega)$, we must take a distribution approach.

For each multi-index $\alpha$, if $f$ and $f_\alpha$ are locally integrable functions on $\Omega$, we say $f_\alpha$ is a weak derivative for $f$ if for any $\phi \in C_c^\infty(\Omega)$,
%
\[ \int_\Omega f_\alpha(x) \phi(x)\; dx = (-1)^{|\alpha|} \int_\Omega f(x) \phi_\alpha(x)\; dx. \]
%
In other words, this is the same as the derivative of $f$ viewed as a distribution on $\Omega$. We define $W^{n,p}$ to be the space of all functions $f \in L^p(\Omega)$ such that for each $|\alpha| \leq n$, a weak derivative $f_\alpha$ exists and is an element of $L^p(\Omega)$. We then define
%
\[ \| f \|_{W^{n,p}(\Omega)} = \left( \sum_{|\alpha| \leq n} \| f_\alpha \|_{L^p(\Omega)} \right)^{1/p}. \]
%
Where this sum is treated as a maximum in the case $p = \infty$. Later on we will be able to show this space is a complete Banach space.

\begin{example}
  Let $B$ be the open unit ball in $\RR^d$, and let $u(x) = |x|^{-s}$, where $s < n-1$. For which $p$ is $u \in W^{1,p}(B)$? We calculate by an integration by parts that if $\phi \in C_c^\infty(B)$, we fix $\varepsilon > 0$ and write
  %
  \[ \int_B \phi_i(x) u(x)\; dx = \int_{|x| \leq \varepsilon} \phi_i(x) u(x) + \int_{\varepsilon < |x| \leq 1} \phi_i(x) u(x). \]
  %
  The integral on the $\varepsilon$ ball is neglible since $s < n$. Since $u$ is smooth away from the origin, it's distributional derivative agrees with it's standard derivative, which is
  %
  \[ u_i(x) = \frac{- \alpha x_i}{|x|^{s + 2}}. \]
  %
  Thus $|u_i| \lesssim 1/|x|^{s + 1}$. An integration by parts gives
  % in the $i$'th direction, and we calculate $\nabla u(x) = -\alpha x |x|^{-\alpha-2}$. Thus an integration by parts gives
  %
  \[ \int_{\varepsilon < |x| \leq 1} \phi_i(x) u(x) = \int_{|x| = \varepsilon} \phi(x) u(x) \nu_i\ dS + \int_{\varepsilon < |x| \leq 1} \frac{s \phi(x) x_i}{|x|^{s + 2}}\; dx, \]
  %
  where $\nu_i$ is the normal vector to the sphere pointing inward. Since $s < n-1$, the surface integral tends to zero as $\varepsilon \to 0$. Thus the weak derivative of $u$ is equal to the standard derivative. Consequently, $u \in W^{1,p}(B)$ if $s < n/p - 1$.
\end{example}

\begin{example}
  If $\{ r_k \}$ is a countable, dense subset of $B$, then we can define
  %
  \[ u(x) = \sum_{k = 1}^\infty \frac{|x - r_k|^{-s}}{2^k} \]
  %
  Then $u \in W^{1,p}(B)$ if $0 < \alpha < n/p - 1$, yet $u$ has a dense family of singularities, and thus does not behave like any differentiable function we would think of.
\end{example}

\begin{theorem}
  For each $k \in \mathbf{N}$ and $1 \leq p \leq \infty$, $W^{k,p}(\Omega)$ is a Banach space.
\end{theorem}
\begin{proof}
  It is easy to verify that $\| \cdot \|_{W^{k,p}}$ is a norm on $W^{k,p}(\Omega)$. Let $\{ u_n \}$ be a Cauchy sequence in $W^{k,p}(\Omega)$. In particular, this means that $\{ D^\alpha u_n \}$ is a Cauchy sequence in $L^p(\Omega)$ for each multi-index $\alpha$ with $|\alpha| \leq k$. In particular, these are functions $v_\alpha$ such that $D^\alpha u_n$ converges to $v_\alpha$ in the $L^p$ norm for each $\alpha$. Thus it suffices to prove that if $v = \lim u_n$, then $D^\alpha v = v_\alpha$ for each $\alpha$. But this follows because the H\"{o}lder inequality implies that for each fixed $\phi \in C_c^\infty(\Omega)$,
  %
  \begin{align*}
    (-1)^{|\alpha|} \int \phi_\alpha(x) v(x)\; dx &= \lim_{n \to \infty} (-1)^{|\alpha|} \phi_\alpha u_n(x)\; dx\\
    &= \lim_{n \to \infty} \int \phi(x) (D^\alpha u_n)(x)\; dx\\
    &= \int \phi(x) v_\alpha(x)\; dx.
  \end{align*}
  %
  Thus $W^{k,p}(\Omega)$ is complete.
\end{proof}

\section{Smoothing}

It is often useful to be able to approximate elements of $W^{k,p}(\Omega)$ by elements of $C^\infty(\Omega)$. This is mostly possible. If $u \in W^{k,p}(\Omega)$, and $\{ \eta_\varepsilon \}$ is a family of smooth mollifiers, then, viewing $u$ as a function on $\RR^n$ supported on $\Omega$, we can consider the convolution $u^\varepsilon = u * \eta_\varepsilon$, i.e. the function defined by setting
%
\[ u^\varepsilon(x) = \int_\Omega u(x - y) \eta_\varepsilon(y)\; dy. \]
%
This is just normal convolution, where we identify the function $u$ with the function $u \mathbf{I}_\Omega$ on $\RR^d$. Then $u^\varepsilon$ is a smooth function on $\RR^d$ supported on a $\varepsilon$ thickening of $\Omega$. However, $u^\varepsilon$ does not necessarily converge to $u$ in $W^{k,p}(\Omega)$ as $\varepsilon \to 0$, since the behaviour of the convolution can cause issues at the boundary of $\Omega$, where the distributional derivative $D^\alpha(u \mathbf{I}_\Omega)$ does not behave like a locally integrable function. This is the only problem, however.

\begin{theorem}
  If $U \Subset \Omega$, then $\lim_{\varepsilon \to 0} \| u^\varepsilon - u \|_{L^p(U)} = 0$.
\end{theorem}
\begin{proof}
  For each $\varepsilon > 0$, let $U^\varepsilon = \{ x \in \Omega: d(x,\partial \Omega) > \varepsilon \}$. If $x \in \Omega^\varepsilon$, then
  %
  \[ ((D^\alpha u) * \eta_\varepsilon)(x) = (u_\alpha \mathbf{I}_\Omega * \eta_\varepsilon)(x), \]
  %
  since the convolution only depends on the behaviour of $D^\alpha u$ on a $\varepsilon$ ball around $x$, which is contained in the interior of $\Omega$. We can apply standard results about mollifiers to conclude that $u_\alpha \mathbf{I}_\Omega * \eta_\varepsilon$ converges to $u_\alpha \mathbf{I}_\Omega$ in $L^p(\RR^d)$ as $\varepsilon \to 0$. Since $U \Subset \Omega$, we have $U \subset U^\varepsilon$ for small enough $\varepsilon$, and so $(D^\alpha u) * \eta_\varepsilon$ converges to $u_\alpha$ in $L^p(U)$ as $\varepsilon \to 0$. Since this is true for each $\alpha$ with $|\alpha| \leq k$, we obtain the result.
\end{proof}

If we are a little more careful, then we can fully approximate elements of $W^{k,p}(\Omega)$ by smooth functions on $U$.

\begin{theorem}
  $C^\infty_c(\Omega) \cap W^{k,p}(\Omega)$ is dense in $W^{k,p}(\Omega)$.
\end{theorem}
\begin{proof}
  Consider a family of open sets $\{ V_n \}$ such that $V_n \Subset \Omega$ for each $n$, and $U = \bigcup V_n$. Then we can consider a smooth partition of unity $\{ \xi_n \}$ subordinate to the cover $\{ V_n \}$. For each $u \in W^{k,p}(\Omega)$, we can write $u = \sum_n u \xi_n$. In particular, this means that for each $\varepsilon > 0$, there is $N$ such that $\| \sum_{n = N+1}^\infty u \xi_n \|_{W^{k,p}(\Omega)} \leq \varepsilon$. For each $n \in \{ 1, \dots, N \}$, we can find $\delta_n$ small enough that the $\delta_n$ thickening of $V_n$ is compactly contained in $\Omega$. If $\varepsilon_n$ is small enough, we find $(u \xi_n)^{\varepsilon_n}$ is supported on the $\delta_n$ thickening of $V_n$, and $\| (u \xi_n)^{\varepsilon_n} - u \xi_n \|_{W^{k,p}(V_n)} \leq \varepsilon / N$. But we then find
  %
  \begin{align*}
    \| u - \sum_{n = 1}^N (u \xi_n)^{\varepsilon_n} \|_{W^{k,p}(\Omega)} \leq \varepsilon + \sum_{n = 1}^N \| u \xi_n - (u \xi_n)^{\varepsilon_n} \|_{W^{k,p}(\Omega)} \leq 2\varepsilon.
  \end{align*}
  %
  Thus $C_c^\infty(\Omega)$ is dense in $W^{k,p}(\Omega)$.
\end{proof}

Approximation by elements of $C^\infty(\overline{\Omega})$ requires some more care, and additional assumptions on the behaviour of $\partial \Omega$.












\chapter{Basics of Integral Operators}






Using analytic interpolation, we can obtain a weighted version of Schur's test.

\begin{theorem}
  Let $K: X \times Y \to \CC$ be an integral kernel, and suppose there are weights $w_X: X \to [0,\infty)$ and $w_Y: Y \to [0,\infty)$ such that for each $x \in X$ and $y \in Y$,
  %
  \[ \int |K(x,y)| w_X(x) dx \leq A w_Y(y) \quad\text{and}\quad \int |K(x,y)| w_Y(y) dy\leq Bw_X(x). \]
  %
  Then the corresponding integral operators $T_K$ is of strong type $(L^2,L^2)$.
\end{theorem}
\begin{proof}
  We apply the Stein-Weiss interpolation theorem. The first estimate says that $\| K w_X / w_Y \|_{L^1(X) L^\infty(Y)} \leq A$, and the second estimate says that $\| K w_Y / w_X \|_{L^1(Y) L^\infty(X)} \leq B$. Thus Schur's test implies $T_{Kw_X/w_Y}$ is bounded from $L^\infty(X)$ to $L^\infty(Y)$, and $T_{Kw_Y/w_X}$ is bounded from $L^1(X)$ to $L^1(Y)$. Thus for each $\theta$, Stein-interpolation implies the operator $T_{K w_X^{2\theta - 1} w_Y^{1-2\theta}}$ is bounded from $L^{1/\theta}(X)$ to $L^{1/\theta}(Y)$. In particular, our result is obtained if we set $\theta = 1/2$.
\end{proof}












\chapter{Riemann Theory of Trigonometric Series}

Using the techniques of measure theory, we can actually prove that the Fourier series is essentially the unique way of representing a function on any part of its domain as a trigonometric series.

\begin{lemma}
  For any sequence $u_n$ and set $E$ of finite measure,
  %
  \[ \lim_{n \to \infty} \int_E \cos^2(nx + u_n)\; dx = |E|/2 \]
\end{lemma}
\begin{proof}
  We have
  %
  \[ \cos^2(nx + u_n) = \frac{1 + \cos(2nx + 2u_n)}{2} = \frac{1}{2} + \frac{\cos(2nx) \cos(2u_n) - \sin(2nx) \sin(2u_n)}{2} \]
  %
  Since $\cos(2u_n)$ and $\sin(2u_n)$ are bounded, we have $\int \chi_E(x) \cos(2nx)$ and $\int \chi_E(x) \sin(2nx) \to 0$ as $n \to \infty$, and the same is true for the latter component of the sum since $\cos(2u_n)$ and $\sin(2u_n)$ are bounded, we conclude that
  %
  \[ \int_E \cos^2(nx + u_n) = \int \chi_E(x) \cos^2(nx + u_n) = |E|/2 \]
  %
  completing the proof.
\end{proof}

\begin{theorem}[Cantor-Lebesgue Theorem]
  If, for some pair of sequences $a_0, a_1, \dots$ and $b_0, b_1, \dots$ are chosen such that
  %
  \[ \sum_{n = 0}^\infty a_n \cos(2 \pi nx) + b_n \sin(2 \pi nx) \]
  %
  converges on a set of positive measure in $[0,1]$, then $a_n, b_n \to 0$.
\end{theorem}
\begin{proof}
  Let $E$ be the set of points upon which the trigonometric series converges. We write $a_n \cos(2 \pi n x) + b_n \sin(2 \pi n x) = r_n \cos(nx + c_n)$. The result of the theorem is then precisely that $r_n \to 0$. If this is not true, then we must have $\cos(nx + c_n) \to 0$ for every $x \in E$. In particular, the dominated convergence theorem implies that
  %
  \[ \lim_{n \to \infty} \int_E \cos(nx + c_n)^2\; dx = 0 \]
  %
  Yet we know this tends to $|E|/2$ as $n \to \infty$, which is a contradiction.
\end{proof}

TODO: EXPAND ON THIS FACT.






\section{Convergence in $L^p$ and the Hilbert Transform}

We now move onto a more 20th century viewpoint on Fourier series, namely, those to do with operator theory. Under this viewpoint, the properties of convergence are captured under the boundedness of certain operators on function spaces, allowing us to use the modern theory of functional analysis to it's full extent on our problems. However, unlike in most of basic functional analysis, where we assume all operators we encounter are bounded to begin with, in harmonic analysis we more often than not are given an operator defined only on a subset of spaces, and must prove the continuity of such an operator to show it is well defined on all of space. We will illustrate this concept through the theory of the circular Hilbert transform, and its relation to the norm convergence of Fourier series.

A {\bf Fourier multiplier} is a linear transform $T$ associated with a given sequence of scalars $\lambda_n$, for $n \in \ZZ$. It is defined for any trigonometric polynomial $f = \sum_{|n| \leq N} c_n e_n$ as $Tf = \sum_{|n| \leq N} \lambda_n c_n e_n$. The trigonometric polynomials are dense in $L^p(\mathbf{T})$, for each $p < \infty$. An important problem is determining whether $T$ is therefore figuring out whether the operator can be extended to a {\it continuous operator} on the entirety of $L^p$. Because the trigonometric polynomials are dense in $L^p$, in the light of the Hahn Banach theorem it suffices to prove an inequality of the form $\| Tf \| \lesssim \| f \|$. Here are some examples of Fourier operators we have already seen.

\begin{example}
    The truncation operator $S_N$ is the transform associated with the scalars $\lambda_n = [|n| \leq N]$. The truncation is continuous, since for any integrable function $f$, the Fourier coefficients are uniformly bounded by $\| f \|_1$, so $\| S_N f \|_1 \leq N \| f \|_1$. Similarily, the F\'{e}jer truncation $\sigma_N$ associated to the multipliers $\lambda_N = [|n| \leq N](1 - |n|/N)$ is continuous on all integrable functions. These operators are easy to extend precisely because the nonzero multipliers have finite support.
\end{example}

\begin{example}
    In the case of the Abel sum, $A_r$, associated with $\lambda_n = r^{|n|}$, $A_r$ extends in a continuous way to all integrable functions, since
    %
    \[ |A_r f| = \left| \sum r^{|n|} \widehat{f}(n) e_n(t) \right| \leq \| f \|_1 \sum r^{|n|} = \| f \|_1 \left( 1 + \frac{2}{1 - r} \right) \]
    %
    Thus the map is bounded.
\end{example}

To understand whether the truncations $S_N f$ of $f$ converge to $f$ in the $L^p$ norms, rather than pointwise, we turn to the analysis of an operator which is the core of the divergence issue, known as the {\bf Hilbert transform}. It is a Fourier multiplier operator $H$ associated with the coeficients
%
\[ \lambda_n = \frac{\text{sgn}(n)}{i} = \begin{cases} +1/i & n > 0 \\ 0 & n = 0 \\ -1/i & n < 0 \end{cases} \]
%
Because
%
\[ [|n| \leq N] = \frac{\text{sgn}(n + N) - \text{sgn}(n-N)}{2} + \frac{[n = N] + [n = -N]}{2} \]
%
we conclude
%
\[ S_n f = \frac{i \left( e_{-n} H(e_n f) - e_n H(e_{-n} f) \right)}{2} + \frac{\widehat{f}(n) e_n + \widehat{f}(-n) e_{-n}}{2} \]
%
Since the operators $f \mapsto \widehat{f}(n) e_n$ are bounded in all the $L^p$ spaces since they are continuous in $L^1(\mathbf{T})$, we conclude that the operators $S_n$ are uniformly bounded as endomorphisms on $L^p(\mathbf{T})$ provided that $H$ is bounded as an operator from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$. Since $S_n f$ converges to $f$ in $L^p$ whenever $f$ is a trigonometric polynomial, this would establish that $S_n f$ converges to $f$ in the $L^p$ norm for any function $f$ in $L^p(\mathbf{T})$. Later on, as a special case of the Hilbert transform on the real line, we will be able to prove that $H$ is a bounded operator on $L^p(\mathbf{T})$ for all $1 < p < \infty$, and as a result, we find that $S_N f \to f$ in $L^p$ for all such $p$. Unfortunately, $H$ is not bounded from $L^1(\mathbf{T})$ to itself, and correspondingly, $S_N f$ does not necessarily converge to $f$ in the $L^1$ norm for all integrable $f$.

For now, we explore some more ideas in how we can analyze the Hilbert transform via convolution, the dual of Fourier multipliers. The fact that $\smash{\widehat{f * g} = \widehat{f} \widehat{g}}$ implies that if their is an integrable function $g$ whose Fourier coefficients corresponds to the multipliers of an operator $T$, then $f * g = Tf$ for any trigonometric polynomial $f$, and by the continuity of convolution, this is the unique extension of the Fourier multiplier operator. In the theory of distributions, one generalizes the family of objects one can take the Fourier series from integrable functions to a more general family of objects, such that every sequence of Fourier coefficients is the Fourier series of some {\it distribution}. One can take the convolution of any such distribution $\Lambda$ with a $C^\infty$ function $f$, and so one finds that $\Lambda * f = Tf$ for any trigonometric polynomial $f$. There is a theorem saying that {\it all} continuous translation invariant operators from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$ are given by convolution with a Fourier multiplier operator. In practice, we just compute the convolution kernel which defines the Fourier multiplier, but it is certainly a satisfying reason to justify the study of Fourier multipliers. For instance, a natural question is to ask which Fourier multipliers result in bounded operations in space.

\begin{theorem}
    A Fourier multiplier is bounded from $L^2(\mathbf{T})$ to itself if and only if the coefficients are bounded.
\end{theorem}
\begin{proof}
    If a Fourier multiplier is given by $\lambda_n$, then for some trigonometric polynomial $f$,
    %
    \[ \| Tf \|_2^2 = \sum \left|\widehat{Tf}(n) \right|^2 = \sum |\lambda_n|^2 \left| \widehat{f}(n) \right|^2 \]
    %
    If the $\lambda_n$ are bounded, then we can obtain from this formula the bound
    %
    \[ \| Tf \|_2^2 \leq \max |\lambda_n| \| f \|_2^2 \]
    %
    Conversely, if $Tf$ is bounded, then
    %
    \[ |\lambda_n^2| = \| T(e_n) \|_2^2 \leq \| T \|^2 \]
    %
    so the $\lambda_n$ are bounded.
\end{proof}

\begin{corollary}
    The Hilbert transform is a bounded endomorphism on $L^2(\mathbf{T})$. Note that we already know that $S_N f \to f$ in the $L^2$ norm.
\end{corollary}

The terms of the Hilbert transform cannot be considered the Fourier coefficients of any integrable function. Indeed, they don't vanish as $n \to \infty$. Nonetheless, we can use Abel summation to treat the Hilbert transform as convolution with an appropriate operator. For $0 < r < 1$, consider, for $z = e^{it}$,
%
\[ K_r(z) = \sum_{n \in \ZZ} \frac{\text{sgn}(n)}{i} r^{|n|} z^n = K * P_r \]
%
Since we know the Hilbert transform is continuous in $L^2(\mathbf{T})$, we can conclude that, in particular, for any $C^\infty$ function $f$,
%
\[ H f = \lim_{r \to 1} K * (P_r * f) = \lim_{r \to 1} (K * P_r) * f = \lim_{r \to 1} K_r * f \]
%
So it suffices to determine the limit of the $K_r$. We find that
%
\begin{align*}
    \sum_{n = 1}^\infty \frac{(rz)^n - (r \overline{z})^n}{i} &= \frac{r}{i} \left( \frac{1}{\overline{z} - r} - \frac{1}{z - r} \right) = \frac{r}{i} \frac{z - \overline{z}}{|z|^2 - 2r \text{Re}(z) + r^2}\\
    &= \frac{2r \sin(t)}{1 - 2r \cos(t) + r^2} = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r \sin^2(t/2)}\\
    &= \cot(t/2) + O \left( \frac{(1 - r)^2}{t^3} \right)
\end{align*}
%
Thus $K_r(t)$ tends to $\cot(t/2)$ locally uniformly away from the origin. But
%
\[ K_r(t) = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r\sin^2(t/2)} = O \left( \frac{t}{(1 - r)^2} \right) \]
%
If $f$ is any $C^\infty$ function on $\mathbf{T}$, then
%
\[ \left| \int_{|t| \geq \varepsilon} [K_r(t) - \cot(t/2)] f(t) \right| \lesssim (1 - r)^2 \| f \|_\infty \int_{|t| \geq \varepsilon} \frac{dt}{|t|^3} \lesssim \frac{(1 - r)^2 \| f \|_\infty}{\varepsilon^2} \]
%
\begin{align*}
    \left| \int_{|t| < \varepsilon} K_r(t) f(t)\; dt \right| &\leq \int_0^\varepsilon |K_r(t)||f(t) - f(-t)|\\
    &\lesssim \int_0^\varepsilon |tK_r(t)||f'(0)| \lesssim \frac{|f'(0)|}{(1 - r)^2} \int_0^\varepsilon t^2 \lesssim \| f' \|_\infty \frac{\varepsilon^3}{(1 - r)^2}
\end{align*}
%
\[ \left| \int_{|t| < \varepsilon} \cot(t/2) f(t)\; dt \right| \lesssim \int_0^\varepsilon \frac{|f(t) - f(-t)|}{t} \lesssim \varepsilon f'(0) \]
%
Thus
%
\[ \left| \int K_r(t) f(t)\; dt - \int \cot(t/2) f(t)\; dt \right| \lesssim \frac{(1 - r)^2}{\varepsilon^2} \| f \|_\infty + \left( \frac{\varepsilon^3}{(1 - r)^2} + \varepsilon \right) \| f' \|_\infty \]
%
Choosing $\varepsilon = (1 - r)^\alpha$ for some $2/3 < \alpha < 1$ shows that for sufficiently smooth $f$,
%
\[ (Hf)(x) = \lim_{r \to 1} \int \cot(t/2) f(x - t)\; dt \]


\section{A Divergent Fourier Series}

Analysis was built to analyze continuous functions, so we would hope the method of fourier expansion would work for all continuous functions. Unfortunately, this is not so. The behaviour of the Dirichlet kernel away from the origin already tells us that the convergence of Fourier series is subtle. We shall take advantage of this to construct a continuous function with divergent fourier series at a point.

To start with, we shall consider the series
%
\[ f(t) \sim \sum_{n \neq 0} \frac{e_n(t)}{n} \]
%
where $f$ is an odd function equaling $i(\pi - t)$ for $t \in (0,\pi]$. Such a function is nice to use, because its Fourier representation is simple, yet very close to diverging. Indeed, if we break the series into the pair
%
\[ \sum_{n = 1}^\infty  \frac{e_n(t)}{n}\ \ \ \ \ \ \ \ \ \ \sum_{n = -\infty}^{-1} \frac{e_n(t)}{n} \]
%
Then these series no longer are the Fourier representations of a Riemann integrable function. For instance, if $g(t) \sim \sum_{n = 1}^\infty \frac{e_n(t)}{n}$, then the Abel means

$A_r(f)(t) = $

\section{Conjugate Fourier Series}

When $f$ is a real-valued integrable function, then $\overline{\widehat{f}(-n)} = \widehat{f}(n)$. Thus we formally calculate that
%
\[ \sum_{n = -\infty}^\infty \widehat{f}(n) e_n(t) = \text{Re} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) \]
%
This series defines an analytic function in the interior of the unit circle since the coefficients are bounded. Thus the sum is a harmonic function in the interior of the unit circle. The imaginary part of this sum is
%
\[ \text{Im} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) = \Re \left( -i \sum_{n = -\infty}^\infty \text{sgn}(n) \widehat{f}(n) e_n(t) \right) \]
%
The right hand side is known as the conjugate series to the Fourier series $\widehat{f}(n)$. It is closely related to the study of a function $\tilde{f}$ known as the {\it conjugate function}.







\chapter{Oscillatory Integrals}

The goal of the theory of oscillatory integrals is to obtain estimates of integrals with highly oscillatory integrals, where standard techniques such as taking in absollute values, or various spatial decomposition strategies, fail completely to give tight estimates. A typical oscillatory integral is of the form
%
\[ I(\lambda) = \int e(\lambda \Phi(x)) \psi(x)\; dx \]
%
where $\Phi$ is the \emph{phase}, $\psi$ is the \emph{amplitude}, and $\lambda$ is a parameter measuring the degree of oscillation, often allowed to increase to large values. Obtaining bounds on these integrals for large $\lambda$ requires techniques to control cancellation properties of integrals, so decomposition techniques like those found in the theory of singular integrals completely fail here.

\begin{example}
    The most basic example of an oscillatory integral is the Fourier transform, where for each function $f \in L^1(\RR)$, and each $\xi \in \RR$, we consider the quantity
    %
    \[ \widehat{f}(\xi) = \int_{-\infty}^\infty e(-\xi x) f(x)\; dx \]
    %
    This $f$ plays the role of the amplitude, we have a phase function $\Phi(x) = x$, and $\xi$ takes the role of $\lambda$. In the basic theory of the Fourier transform, we showed that one has qualitative decay in this oscillatory integral for any $f \in L^1(\RR)$, a consequence of the Riemann-Lebesuge lemma. If $f$ was appropriately smooth, i.e. Schwartz, then $\widehat{f}$ also exhibited polynomial decay properties. One of the main applications of the theory of oscillatory integrals is to show that Fourier transforms of measures have fast decay properties, which has applications in many different areas of analysis.
\end{example}

There are two modern tools to estimate oscillatory integrals. The first, the principle of stationary phase, states that if $\Phi$ is smooth, and $\nabla \Phi$ has an isolated family of zeroes, then the oscillatory integral asymptotics can be localized to regions around the values $x_0$ with $\nabla \Phi(x_0) = 0$. Heuristically, each zero $x_0$ contributes $\psi(x_0) e ( \lambda \Phi(x_0) )$, times the volume of the region around $x_0$ where $\Phi$ deviates by $O(1/\lambda)$ to the overall asymptotics. The second method, known as the method of steepest descent, uses complex analysis to shift domains of integration to a domain where less oscillation occurs, and standard dyadic decomposition strategies can be employed. However, this method seems to only work for single-variable oscillatory integrals, and therefore has limited applicability in many problems.

\section{The Principle of Stationary Phase}

The basic principle of the theory of stationary phase is that the asymptotics of the integral are determined by the points where $\nabla \Phi$ vanishes. The fact that we can reduce our analysis to critical points is because an oscillatory principle whose phase has no critical points exhibits rapid decay. Let us consider a simple example of an oscillatory integral, i.e.
%
\[ I(\lambda) = \int_0^1 e^{i \lambda \phi(x)}\; dx, \]
%
where $\phi: [0,1] \to \RR$ is Borel measurable. Taking in absolute values shows that $|I(\lambda)| \leq 1$ for all $\lambda$. If $\phi$ is constant, then $I(\lambda) = e^{i \lambda \phi}$ has magnitude one for all $\lambda$, so this inequality is sharp. But if $\phi$ varies, we expect $I$ to decay as $\lambda \to \infty$, and so we hope to determine what properties guarantee that $|I(\lambda)| \ll 1$. For instance, the Esse\'{e}n concentration inequality relates the lack of concentration of the distribution of $\phi$ to the \emph{average} decay of $I$.

\begin{theorem}[Esse\'{e}n Concentration Inequality]
  Let $\phi: [0,1] \to \RR$ be Borel measurable, and for each $\lambda \in \RR$, set
  %
  \[ I(\lambda) = \int_0^1 e^{i \lambda \phi(x)}\; dx. \]
  %
  Then for any $\varepsilon > 0$,
  %
  \[ \sup_{\phi_0 \in \RR} |\{ x \in [0,1]: |\phi(x) - \phi_0| \leq \varepsilon \}| \lesssim \varepsilon \int_0^{1/\varepsilon} |I(\lambda)|\; d\lambda. \]
\end{theorem}
\begin{proof}
  For any choice of $\phi_0$, we may replace $\phi$ with $\phi - \phi_0$, reducing the analysis to the case where $\phi_0 = 0$. Similarily, replacing $\phi$ with $\phi/\varepsilon$ reduces us to the situation where $\varepsilon = 1$. Thus we must show
  %
  \[ |\{ x \in [0,1]: |\phi(x)| \leq 1 \}| \lesssim \int_0^1 |I(\lambda)|\; d\lambda. \]
  %
  Now let $\psi$ be an integrable function supported on $[0,1]$. By Fubini's theorem,
  %
  \[ \int_0^1 \psi(\lambda) I(\lambda)\; d\lambda = \int_0^1 \widehat{\psi}(- \phi(x) / 2 \pi)\; dx. \]
  %
  In particular, this means that
  %
  \[ \left| \int_0^1 \widehat{\psi}(- \phi(x) / 2\pi)\; dx \right| \leq \| \psi \|_{L^\infty[0,1]} \int_0^1 |I(\lambda)|\; d\lambda. \]
  %
  If we choose a bounded function $\psi$ such that $\widehat{\psi}$ is non-negative, and bounded below on $[-2\pi,2\pi]$, then
  %
  \[ \left| \int_0^1 \widehat{\psi}(- \phi(x) / 2 \pi)\; dx \right| \gtrsim |\{ x \in [0,1]: |\phi(x)| \leq 1 \}|, \]
  %
  and so the claim follows easily.
\end{proof}

Thus if large cancellation happens in $I(\lambda)$ for the average $\lambda$, this automatically implies that $\phi$ cannot be concentrated around any particular point.  Conversely, we want to show that if $\phi$ is significantly varying, then $I$ exhibits some cancellation properties. The condition that $\phi'$ is bounded below is not sufficient to guarantee cancellation, as the next example shows, if $\phi$ has oscillation at wavelength $1/\lambda$.

\begin{example}
  Fix $\lambda_0 \in \ZZ$, and let $\phi(x) = 2 \pi x + f(\lambda_0 x) / \lambda_0$, where $f$ is smooth and 1-periodic, $\| f' \|_{L^\infty(\RR/\ZZ)} \leq 1$, and
  %
  \[ \int_0^1 e^{2 \pi i x + i f(x)}\; dx \neq 0. \]
  %
  For instance, we could take $f(x) = x/2$. Then $|\phi'(x)|$ is bounded below independantly of $\lambda_0$. Since $\phi(x + 1/\lambda_0) = \phi(x) + 2 \pi / \lambda_0$, we find $e^{i \lambda_0 \phi(x)}$ is $1/\lambda_0$ periodic. In particular, this means
  %
  \[ I(\lambda_0) = \int_0^1 e^{\lambda_0 i \phi(x)} = \int_0^1 e^{2 \pi i x + i f(x)}\; dx. \]
  %
  which is comparable to 1, independantly of $\lambda_0$.
\end{example}

One way to get around this condition is by controlling $\phi''$ in addition to controlling $\phi'$.

\begin{theorem}
  Let $\phi: \RR \to \RR$ be smooth, with $|\phi'(x)| \geq A$ and $|\phi''(x)| \leq B$ for all $x \in [0,1]$, where $A,B > 0$. Then for all $\lambda > 0$, we find $|I(\lambda)| \lesssim s$ 
\end{theorem}


\begin{theorem}
    If $\Phi$ and $\psi$ are smooth, compactly supported functions with $\nabla \Phi(x) \neq 0$ for all $x$ in the support of $\psi$, then $I(\lambda) \lesssim 1/\lambda^N$.
\end{theorem}
\begin{proof}
    Set $a = (\nabla \Phi)/|\nabla \Phi|^2$. Then for any smooth functions $f$ and $g$, integrating by parts, we obtain that
    %
    \[ \int \frac{a \cdot \nabla f(x)}{i \lambda} g(x)\; dx = - \int f(x) \frac{(\nabla \cdot (ag))(x)}{i \lambda}\; dx \]
    %
    Set
    %
    \[ D(f) = (i \lambda)^{-1} (a \cdot \nabla f)\ \ \ \ \ D^*(f) = - (i\lambda)^{-1} (\nabla \cdot (af)) \]
    %
    Note that $D(e(\lambda \Phi)) = e(\lambda \Phi)$, so $D^N(e(\lambda \Phi)) = e(\lambda \Phi)$ for all integers $N$, and so
    %
    \[ I(\lambda) = \int D^N(e(\lambda \Phi)) \phi = \int e(\lambda \Phi) (D^*)^N(\psi) \]
    %
    Taking absolute values in the last integral gives that
    %
    \[ |I(\lambda)| \leq \int |(D^*)^N(\psi)| \lesssim \frac{1}{\lambda^N} \]
    %
    which gives the required bounds.
\end{proof}

Of course, if $\Phi$ changes suitably rapidly around a point $x$, in the sense that $\nabla \Phi$ is nonsingular, then as we increase $\lambda$, the oscillatory factor in the integral is allowed to oscillate at a fast enough rate that $\psi$ is effectively constant, and so the integral has so much cancellation that we get rapid decay. Note, however, that this depends on $\psi$ being effectively constant, i.e. smooth. If $\psi$ and $\Phi$ are only $C^N$ functions, then we can only get a $|\lambda|^{-N}$ decay rate. A particularly revealing example is where we take the Fourier transform of the characteristic function of an interval $[a,b]$ (smooth, albeit at the two endpoints where we get a sharp jump), where
%
\[ \int_a^b e(- \lambda x)\; dx = \frac{e(\lambda b) - e(\lambda a)}{2 \pi i \lambda} \]
%
which has only a rate $1/|\lambda|$ decay. Note, however, if we are taking an oscillatory integral `on an interval' $[a,b]$, where $\psi$ and $\Phi$ are both $C^N$, and for all $n \leq N$, $\Phi^{(n)}(a) = \Phi^{(n)}(b)$ and $\psi^{(n)}(a) = \psi^{(n)}(b)$, then we can still get $1/|\lambda|^N$ decay using the same proof as above, except now the integration by parts must take into account the endpoints of the integral, which now cancel to a suitably high degree.

\section{Scaling}

To hint at the multidimensional theory, we now focus solely on the single-variable theory. This simplifies the situation considerably, and we shall find there is an essentially complete theory of such oscillatory integrals in one dimension. Note that we now have
%
\[ D(f) = (i\lambda \phi')^{-1} f'\ \ \ \ \ D^*(f) = -(i \lambda)^{-1} (f/\phi)' \]
%
In particular, we attempt to guess the asymptotic development of the oscillatory integral
%
\[ \int e(\lambda \phi(x)) \psi(x) \]
%
where the derivatives of $\phi$ may vanish at suitable points, yet for a suitably high $n$, $\phi^{(n)}$ does not vanish on the support of $\psi$. In particular, suppose that we want to find the best constant $\alpha$, such that there exists a constant $C_n$ such that for any $\phi$ and interval $[a,b]$ such that $|\phi^{(n)}(x)| \geq 1$ on $(a,b)$, then
%
\[ \left| \int_a^b e(\lambda \phi(x))\; dx \right| \leq C_n/|\lambda|^\alpha \]
%
If $\phi(x) = x^n$, then the change of variables $y = \beta x$ implies that if we have a best constant $\alpha$ which works for all $\phi$, then we must have $\alpha = 1/k$. Indeed, this estimate, known to Van der Corput, says this result is true.

\begin{theorem}
    There exists a constant $C_n$ such that if $\phi$ is smooth in $(a,b)$ with $|\phi^{(n)} \geq 1|$ for all $x \in (a,b)$, then
    %
    \[ \left| \int_a^b e(\lambda \phi(x)) \right| \leq C_n \lambda^{-1/n} \]
    %
    where $n \geq 2$, or $n = 1$, under the extra assumptions that $\phi'$ is monotonic.
\end{theorem}
\begin{proof}
    Consider first $n = 1$. Then, using the operator $D$, we have
    %
    \begin{align*}
        \int_a^b e(\lambda \phi)\; dx &= \int_a^b D(e(i \lambda \phi))\; dx = \int_a^b e(\lambda \phi) D^*(1)\; dx + \frac{e(\lambda b)/\phi'(b) - e(\lambda a)/\phi'(a)}{i \lambda}
    \end{align*}
    %
    The boundary terms are collectively bounded by $2/|\lambda|$, and we can bound the integration term, using the monotonicity of $\phi'$, by
    %
    \begin{align*}
        \left| \int_a^b e(\lambda \phi) D^*(1)\; dx \right| &\leq |\lambda|^{-1} \int_a^b |(1/\phi')'|\; dx \leq |\lambda|^{-1} \left| \int_a^b (1/\phi')'\; dx \right|\\
        &= |\lambda|^{-1} \left| \frac{1}{\phi'(b)} - \frac{1}{\phi'(a)} \right| \leq |\lambda|^{-1}
    \end{align*}
    %
    so we can set $C_1 = 3$. We now prove the remaining inequalities by induction, using an integration by parts. Suppose that (by replacing $\phi$ with its negation if necessary) $\phi^{(n+1)}(x) \geq 1$ on $[a,b]$. Let $x_0$ be the point at which $|\phi^{(n)}(x)|$ is minimized. Without loss of generality, we may assume that $|\phi^{(n)}(x)$ TODO: FINISH THIS ARGUMENT, GIVES $C_n = 5 \cdot 2^{n-1} - 2$.
\end{proof}

\begin{remark}
    If $|\phi^{(n)}(x)| \geq \mu$, then $|\phi^{(n)}(x)/\mu| \geq 1$, and so substituting into the previous result establishes that $|I(\lambda)| \leq C_m / |\mu \lambda|^{1/n}$.
\end{remark}

\begin{remark}
    If $n = 1$, and $\phi'$ is not monotonic, we can choose $\phi$ to grow suitably slowly on intervals of the form $[0,\pi] + 2 \pi n$, and $\phi$ to grow much faster on intervals of the form $[\pi, 2\pi] + 2 \pi n$. It then follows that $\int_0^{2 \pi N} \sin(\phi(x))$ is unbounded as we let $N \to \infty$, which prevents us from extending the result completely to the one dimensional case.
\end{remark}

Continuing in the simpler, one dimensional case, we now consider a {\it nondegenerate} critical point $x$, where $\Phi'(x) = 0$, but $\Phi''(x) \neq 0$. A good instance of this occurs where $\Phi(x) = x^2$, where we find
%
\[ \int e(\lambda x^2) \psi(x)\; dx = \sum_{k = 0}^N C_k \lambda^{-1/2-k} + O(|\lambda|^{-3/2-N}) \]
%
This is obtained by noting that the Fourier transform of the Gaussian implies
%
\[ \int e^{- sx^2} \psi(x)\; dx = (\pi/s)^{1/2} \int e^{- \pi^2 \xi^2/ s} \widehat{\psi}(\xi)\; d\xi \]
%
Since both sides are analytic, and they make sense for $\Re(s) > 0$, we can take $s \to -i\lambda$ to conclude that
%
\[ \int e(\lambda x^2) \psi(x)\; dx = \left( \frac{\pi}{i \lambda} \right)^{1/2} \int e(-\pi^2 \xi^2/\lambda) \widehat{\psi}(x)\; dx \]
%
Expanding the exponential $e(u^2)$ gives the required bounds. Thus we can expect a critical, nondegenerate point to give a $O(\lambda^{-1/2})$ error bound.

\begin{corollary}
    If an amplitude $\psi$ is present, then
    %
    \[ \left| \int_a^b e(\lambda \Phi(x)) \psi(x)\; dx \right| \leq 8 \left( \int_a^b |\psi'(x)|\; dx + |\psi(b)| \right) \lambda^{-1/2} \]
\end{corollary}
\begin{proof}
    Integrating by parts, if $J(x) = \int_a^x e(\lambda \Phi(u))\; du$, then
    %
    \[ \int_a^b e(\lambda \Phi(x)) \psi(x)\; dx = J(b)\psi(b) - \int_a^b J(x) \psi'(x)\; dx \]
    %
    and then since $|J(x)| \leq 8\lambda^{-1/2}$, the proposition follows. TODO: ADDRESS MULTIDIMENSIONAL CASE.
\end{proof}

\begin{example}
    The Bessel functions
    %
    \[ J_m(r) = \frac{1}{2\pi} \int_0^{2\pi} e(r \sin(x)) e_m(-x)\; dx \]
    %
    occur naturally in many areas of analysis. The definition of the functions can be seen as an oscillatory integral, with $\lambda = r$, $\Phi(x) = \sin(x)$, and $\psi(x) = e_m(-x)/2\pi$. Split $[0,2\pi]$ into two intervals, the first upon which $\cos(x) \geq 1/\sqrt{2}$, the second where $\sin(x) \geq 1/\sqrt{2}$. On the first part, we may apply the corollary above to obtain a $O(r^{-1/2})$ bound, and on the second, we can apply the first to obtain a $O(r^{-1})$ bound. Summing these two bounds up gives the theorem.
\end{example}

\section{Surface Carried Measures}

\begin{theorem}
    If a hypersurface $\Sigma$ has non-vanishing Gauss curvature at each point in the support of a surface carried measure $\mu$, then
    %
    \[ |\widehat{\mu}(\xi)| = O(|\xi|^{-(d-1)/2}) \]
    %
    s
\end{theorem}





\section{Restriction Theorems}

If $f \in L^p(\RR^n)$, then the Hausdorff Young theorem says that $\widehat{f}$ is a function in $L^q(\RR^n)$, where $q$ is the dual of $p$. If $f \in L^1(\RR^n)$, then $\smash{\widehat{f}}$ is actually continuous, so you can meaningfully discuss the behaviour of the Fourier transform when restricted to low dimensional hypersurfaces, for instance, on a sphere of a fixed radius. However, in general $\widehat{f}$ will only be defined almost everywhere, and so it is unclear whether one can form a well defined restriction of the Fourier transform.

The general situation is as follows. If $\mu$ is a measure carried on a compact surface $M$, for a fixed $p$, does there exist an estimate 
%
\[ \| \widehat{f} \|_{L^q(M,\mu)} \lesssim \| f \|_{L^p(\RR^n)} \]
%
for Schwartz functions $f$. If this is true, we can apply a density argument to show that the restriction operator $\smash{R(f) = \widehat{f}|_M}$ uniquely extends to a well defined continuous linear operator from $L^p(\RR^n)$ to $L^q(M,\mu)$.

We begin by determining a duality result to the restriction calculation. Assuming our functions are suitably regular, we calculate
%
\begin{align*}
    \int_M (Rf)(\xi) \overline{g(\xi)}\; d\mu(\xi) &= \int_M \left( \int_{\RR^n} f(x) e(- \xi \cdot x)\; dx \right) \overline{g(\xi)}\; d\mu(\xi)\\
    &= \int_{\RR^n} f(x) \overline{\int_M g(\xi) e(\xi \cdot x)\; d\mu(\xi)}\; dx 
\end{align*}
%
which implies the formal adjoint of the map $R$ is the {\bf extension operator}
%
\[ (R^* f)(x) = \int_M e(\xi \cdot x) f(\xi) d\mu(\xi) \]
%
which extends a function in frequency space supported on $M$ to a function on the entirety of phase space. By duality properties, $R$ is continuous as an operator from $L^p(\RR^n)$ to $L^q(M,\mu)$ if and only if $R^*$ is continuous as an operator from $L^{q^*}(M,\mu)$ to $L^{p^*}(\RR^n)$. We also calculate
%
\[ ((R^* R)f)(x) = \int_{\RR^n} \left( \int_M e(\xi \cdot (x-y))\; d\mu(\xi) \right) f(y)\; dy = \left( f * \widecheck{\mu} \right)(x) \]
%
So if $R$ is $(p,2)$ continuous, $R^*$ is $(2,p^*)$ continuous, and so $R^*R$ is $(p,p^*)$ continuous. Conversely, if we know that $R^*R$ is $(p,p^*)$ continuous, then we find that for $f \in L^p(\RR^n)$, H\"{o}lder's inequality implies
%
\[ \| Rf \|_{L^2(M,\mu)}^2 = (Rf,Rf)_M = ((R^* R)f, f)_{\RR^d} \leq \| R^*R \|_{p \to p^*} \| f \|_p^2 \]
%
and so we conclude that $\| R \|_{p \to 2} \leq \sqrt{\| R^* R\|_{p \to p^*}}$.

We now prove that $R$ is $(2n+2/n+3, 2)$ continuous, assuming that $M$ has non-zero Gaussian curvature at each point. The previous paragram implies that it suffices to show that it is enough to show that $R^*R$ is $(p,p^*)$ continuous, where $p = (2n+2)/(n+3)$ and $p^* = (2n+2)/(n-1)$. Since
%
\[ (R^*R)(f) = f * \widecheck{\mu} \]
%
We shall verify this using Stein's interpolation theorem. Consider the family of kernels $k_s$, where $\smash{k_s = \widecheck{K_s}}$, and $K_s = \gamma_s |x_n - \varphi(x')|^{s-1}_+ \varphi_0(x)$, where $\gamma_s = s(s+1) \dots (s + N) e^{s^2}$
