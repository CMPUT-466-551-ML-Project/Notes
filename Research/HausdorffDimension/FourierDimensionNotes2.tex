\documentclass[12pt,reqno]{article}

%\documentclass[dvipsnames,letterpaper,12pt]{article}

\usepackage[margin = 1in]{geometry}
\usepackage{amsmath,amssymb,graphicx,mathabx,accents}
\usepackage{enumerate,mdwlist}

%\setlist[enumerate]{label*={\normalfont(\Alph*)},ref=(\Alph*)}

\numberwithin{equation}{section}

\usepackage{amsthm}

\usepackage{verbatim}

\usepackage{nag}

\DeclareMathOperator{\minkdim}{\dim_{\mathbf{M}}}
\DeclareMathOperator{\hausdim}{\dim_{\mathbf{H}}}
\DeclareMathOperator{\lowminkdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\upminkdim}{\overline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\fordim}{\dim_{\mathbf{F}}}

\DeclareMathOperator{\lhdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\lmbdim}{\underline{\dim}_{\mathbf{MB}}}

\DeclareMathOperator{\RR}{\mathbf{R}}
\DeclareMathOperator{\ZZ}{\mathbf{Z}}
\DeclareMathOperator{\QQ}{\mathbf{Q}}
\DeclareMathOperator{\TT}{\mathbf{T}}

\DeclareMathOperator{\B}{\mathcal{B}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem*{remark}{Remark}

\DeclareMathOperator{\EE}{\mathbf{E}}
\DeclareMathOperator{\PP}{\mathbf{P}}

\DeclareMathOperator{\DQ}{\mathcal{Q}}
\DeclareMathOperator{\DR}{\mathcal{R}}

\newcommand{\psitwo}[1]{\| {#1} \|_{\psi_2(L)}}
\newcommand{\TV}[2]{\| {#1} \|_{\text{TV}({#2})}}








\title{Salem Sets Avoiding Rough Configurations}
\author{Jacob Denson}

\begin{document}

\maketitle

\begin{abstract}
Geometric measure theory explores the relationship between the geometry of a subset of Euclidean space, and regularity properties of the family of Borel measures supported on that set. From the perspective of harmonic analysis, it is often popular to explore what structural information can be gathered from the Fourier analytic properties of measures supported on a set. In this paper, we study the relationship between the Fourier analytic properties of a set and the existence of patterns on the set. In particular, given a `rough pattern', in the sense of \cite{OurPaper}, we construct a family of sets which generically avoids this pattern, and which supports measures with fast Fourier decay.
\end{abstract}

\section{Introduction}

A useful statistic associated with any Borel set $E \subset \RR^d$ is it's \emph{Fourier dimension}. Given a finite Borel measure $\mu$ on $\RR^d$, we define it's Fourier dimension, $\fordim(\mu)$, to be the supremum of all $s \in [0,d]$ such that
%
\begin{equation} \label{fordim}
    \sup \left\{ |\widehat{\mu}(\xi)| |\xi|^{s/2} : \xi \in \RR^d \right\} < \infty.
\end{equation}
%
The Fourier dimension of a Borel set $E \subset \RR^d$, denoted $\fordim(E)$, is then the supremum of $\fordim(\mu)$, over all Borel probability measures $\mu$ supported on $E$. A particularly tractable family of sets in this scheme are \emph{Salem sets}, those sets whose Fourier dimension agrees with their Hausdorff dimension. Most classical fractal sets are not Salem, often having Fourier dimension zero. Nonetheless, the sets we construct in this paper are Salem.

\begin{theorem} \label{maintheorem}
    Let $0 \leq s < dn$, and let $Z \subset \RR^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $s$. Then there exists a compact Salem set $X \subset [0,1]^d$ with dimension
    %
    \[ \beta = \min \left( \frac{nd - \alpha}{n-1}, d \right) \]
    %
    such that for any distinct points $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

\begin{remark}
    Theorem \ref{maintheorem} strengthens the main result of \cite{OurPaper}. Unlike in \cite{OurPaper}, the case of the problem $0 \leq \alpha < d$ is still interesting, since the trivial construction $[0,\pi]^d - \pi(Z)$ is not necessarily a Salem set, where $\pi(x_1, \dots, x_n) = x_1$ is projection onto the first coordinate. For instance, $[0,1] - \QQ$
\end{remark}

A well-known result in this pattern avoidance setting is that sets with large Fourier dimension satisfy many algebraic relations. More precisely, if integer coefficients $m_1, \dots, m_n \in \ZZ$ are fixed, and we consider a compact set $X \subset \RR$ with $\fordim(X) > 2/n$, then the sum set $m_1 X + \dots + m_n X$ contains an open interval. It follows by a slight modification of these coefficients that if $X \subset \RR$ and $\fordim(X) > 2/n$, then there exists $m_1, \dots, m_n \in \ZZ$, distinct points $x_1, \dots, x_n \in X$, and an additional integer $a \in \ZZ$, such that
%
\begin{equation} \label{intequation}
    m_1 x_1 + \dots + m_n x_n = a.
\end{equation}
%
It is an interesting to determine how tight this result is. In \cite{Korner2}, T.W. K\"{o}rner constructs a Salem set $X$ with Fourier dimension $1/(n-1)$ such that for non-zero $m \in \ZZ^n$, and $a \in \ZZ$, $X$ does not contain distinct points $x_1, \dots, x_n$ solving \eqref{intequation}. If, for each nonzero $m \in \ZZ^n$ and $a \in \ZZ$, we consider the set
%
\[ Z_{m,a} = \left\{ (x_1, \dots, x_n) \in [0,1]^n : m_1x_1 + \dots + m_n x_n = a \right\}, \]
%
then $Z_{m,a}$ is a subset of an $n-1$ dimensional hyperplane, and thus can be easily seen to have Minkowski dimension $n-1$. It follows that we can apply Theorem \ref{maintheorem} to $Z = \bigcup \{ Z_{m,a} : m \neq 0, a \in \ZZ \}$ to obtain a Salem set $X \subset [0,1]$ with dimension
%
\[ \frac{n - (n-1)}{n - 1} = \frac{1}{n-1}, \]
%
such that $(x_1, \dots, x_n) \not \in Z$ for each distinct $x_1, \dots, x_n \in X$. Thus $X$ avoids solutions to $\eqref{intequation}$ for all nonzero $m \in \ZZ^n$ and $a \in \ZZ$. Thus we see Theorem \ref{maintheorem} generalizes K\"{o}rner's result, and thus shows the result depends little on the arithmetic properties of the pattern K\"{o}rner avoids, but rather, depends only on the `thickness' of the family of tuples $(x_1, \dots, x_n)$ satisfying the pattern. Since we expect Theorem \ref{maintheorem} to be tight for general sets, an improvement to K\"{o}rner's construction must rely more heavily on the algebraic properties of the pattern involved.

Since we are working with \emph{compact} sets avoiding patterns, working in $\RR^d$ is not significantly different from working in a periodic domain $\TT^d = \RR^d / \ZZ^d$, and working in this space has several advantages over the Euclidean case. For a finite measure $\mu$ on $\TT^d$, we can define it's Fourier dimension $\fordim(\mu)$ as the supremum of all $0 \leq s \leq d$ such that
%
\begin{equation} \label{fordimtorus}
    \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{s/2} < \infty.
\end{equation}
%
We can then define the Fourier dimension of any Borel set $E \subset \TT^d$ as the supremum of $\fordim(\mu)$, over all Borel measures $\mu$ supported on $E$. Similarily, $\TT^d$ has a natural quotient metric induced from $\RR^d$, so we can consider open balls $B_\varepsilon(x + \ZZ^d)$, and thus define the Hausdorff dimension of finite Borel measures and sets on $\TT^d$. It is a simple consequence of the Poisson summation formula that if $\mu$ is a compactly supported measure on $\RR^d$, then \eqref{fordim} is equivalent to the more discrete condition
%
\begin{equation} \label{discretefordim}
    \sup_{\xi \in \ZZ^d} |\widehat{\mu}(\xi)| |\xi|^{s/2} < \infty.
\end{equation}
%
A proof is given in \cite[Lemma 39]{myThesis}. In particular, if $\mu^*$ is the \emph{periodization} of $\mu$, i.e. the measure on $\TT^d$ such that for any $f \in C(\TT^d)$,
%
\[ \int_{\TT^d} f(x)\; d\mu^*(x) = \int_{\RR^d} f(x + \ZZ^d)\; d\mu(x), \]
%
then \eqref{discretefordim} implies $\fordim(\mu^*) = \fordim(\mu)$. Since $\mu$ is compactly supported, it is also simple to see that $\hausdim(\mu^*) = \hausdim(\mu)$. Thus Theorem \ref{maintheorem} is clearly equivalent to it's periodic variant, introduced below.

\begin{theorem} \label{periodictheorem}
    Let $0 \leq \alpha < dn$, and let $Z \subset \TT^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Then there exists a compact Salem set $X \subset \TT^d$ with dimension
    %
    \[ \beta = \min \left( \frac{dn - \alpha}{n-1}, d \right) \]
    %
    such that for any distinct points $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

To construct our set, we rely on a Baire-category argument. Thus we consider a complete metric space $\mathcal{X}$, whose elements consist of pairs $(E,\mu)$, where $E$ is a subset of $\TT^d$, and $\mu$ is a probability measure supported on $E$. We then show that for \emph{quasi-all} elements $(E,\mu) \in \mathcal{X}$, $E$ is a Salem set, and is pattern avoiding, in the sense that the set of pairs $(E,\mu)$ which do not satisfy these properties is a set of first category in $\mathcal{X}$. It follows that Theorem \ref{periodictheorem} holds in a `generic' sense for elements of $\mathcal{X}$.

Once we have setup the appropriate metric space $\mathcal{X}$, our approach is quite similar to the construction in \cite{OurPaper}, relying on a random selection procedure, which is now exploited to give high probability bounds on the Fourier transform of the measures we study. The use of the Baire category approach in this paper, rather than an algorithmic, `nested set' approach, is mostly of an aesthetic nature, avoiding the complex queuing method and dyadic decomposition strategy required in the nested set approach; our approach can, with some care, be converted into a queuing procedure like in \cite{OurPaper}. But the Baire category argument makes our proof simpler to read, giving us the `infinitisimal argument' for free from the discrete case analysis, and has the advantage that it indicates that Salem sets of a specified dimension `generically' avoid a given rough pattern. Moreover, the proof of the Baire category theorem is in some senses, `hidden' in the queuing method, so the two methods are, aside from small technical differences, equivalent to one another.

\section{Notation} \label{notationSection}

\begin{itemize}
    \item For a positive integer $N$, we let $[N] = \{ 1, \dots, N \}$.

    \item Given a metric space $\Omega$, $x \in \Omega$, and $\varepsilon > 0$, we shall let $B_\varepsilon(x)$ denote the open ball of radius $\varepsilon$ around $x$. For a given set $E \subset \Omega$ and $\varepsilon > 0$, we let
    %
    \[ E_\varepsilon = \bigcup_{x \in E} B_\varepsilon(x), \]
    %
    denote the \emph{$\varepsilon$-thickening} of the set $E$. A subset of $\Omega$ is of \emph{first category} in $\Omega$ if it is the countable union of closed sets with nonempty interior. We say a property holds \emph{quasi-always}, or a property is \emph{generic} in $\Omega$ if the set of points in $\Omega$ failing to satisfy that property form a set of first category.

    \item We let $\TT^d = \RR^d/\ZZ^d$. Given $x \in \TT$, we let
    %
    \[ |x| = \min \{ |x + n| : n \in \ZZ \}, \]
    %
    and for $x \in \TT^d$, we let
    %
    \[ |x| = \sqrt{|x_1|^2 + \dots + |x_d|^2}. \]
    %
    The canonical metric on $\TT^d$ is then $d(x,y) = |x - y|$, for $x,y \in \TT^d$.

    \item Suppose $\mathbf{E} = \TT^d$ or $\mathbf{E} = \RR^d$. For $\alpha \in [0,d]$ and $\delta > 0$, we define the Hausdorff content of a Borel set $E \subset \mathbf{E}$ as
    %
    \[ H^\alpha_\delta(E) = \inf \left\{ \sum_{i = 1}^\infty \varepsilon_i^\alpha : E \subset \bigcup_{i = 1}^\infty B_{\varepsilon_i}(x_i)\ \text{and $\varepsilon_i \leq \delta$ for all $i \in \mathbf{N}$} \right\}. \]
    %
    The $\alpha$ dimensional Hausdorff measure of $E$ is equal to
    %
    \[ H^\alpha(E) = \lim_{\delta \to 0} H^\alpha_\delta(E). \]
    %
    The Hausdorff dimension $\hausdim(E)$ of a Borel set $E$ is then the infinum over all $s \in [0,d]$ such that $H^s(E) = \infty$, or alternatively, the supremum over all $s \in [0,d]$ such that $H^s(E) = 0$. Frostman's lemma says that if we define the Hausdorff dimension $\hausdim(\mu)$ of a finite Borel measure $\mu$ as the supremum of all $s \in [0,d]$ such that
    %
    \begin{equation} \label{hausdim}
        \sup \left\{ \mu(B_\varepsilon(x)) \cdot \varepsilon^{-\alpha} : x \in \RR^d, \varepsilon > 0 \right\} < \infty,
    \end{equation}
    %
    then $\hausdim(E)$ is the supremum of $\hausdim(\mu)$, over all Borel probability measures $\mu$ supported on $E$, analogous to the definition of the Fourier dimension of a set $E$ given in the introduction.

    \item For $\mathbf{E} = \RR^d$ or $\mathbf{E} = \TT^d$, and for a measurable set $E$, we let $|E|$ denote it's standard Lebesgue measure. We define the lower and upper Minkowski dimension of a compact Borel set $E \subset \mathbf{E}$ as
    %
    \[ \lowminkdim(E) = \liminf_{\varepsilon \to 0} \log_\varepsilon|E_\varepsilon| \quad\text{and}\quad \upminkdim(E) = \limsup_{\varepsilon \to 0} \log_\varepsilon |E_\varepsilon| \]
    %
    respectively.

    \item We will make several uses of \emph{Hoeffding's Inequality} to control the deviations of independent families of random variables. The version of Hoeffding's inequality we use states that if $\{ X_1, \dots, X_N \}$ is an independent family of mean-zero random variables, such that for each $i$, there exists a constant $A_i \geq 0$ such that $|X_i| \leq A_i$ almost surely, then for each $t \geq 0$,
    %
    \[ \PP \left( |X_1 + \dots + X_N| \geq t \right) \leq 2 \exp \left(\frac{-t^2}{2(A_1^2 + \dots + A_N^2)} \right). \]
    %
    Proofs are given in many probability textbooks, for instance, in Chapter 2 of \cite{Vershynin}.
    \begin{comment}

    \item Our random construction involves a probabilistic concentration of measure argument. Define a convex function $\psi_2: [0,\infty) \to [0,\infty)$ by setting
    %
    \[ \psi_2(t) = e^{t^2} - 1, \]
    %
    The function $\psi_2$ induces an Orlicz norm on the family of scalar valued random variables over a probability space by setting, for each random variable $X$,
    %
    \[ \psitwo{X} = \inf \left\{ A \in (0,\infty) : \EE(\psi_2(|X|/A)) \leq 1 \right\}. \]
    %
    The family of random variables with $\psitwo{X} < \infty$ are known as \emph{subgaussian random variables}. Here are the important properties of subgaussian random variables which we use in this paper:
    %
    \begin{itemize}
        \item If $\psitwo{X} \leq A$, then for each $t \geq 0$,
        %
        \[ \PP \left( |X| \geq t \right) \leq 10 \exp \left( -t^2/10A^2 \right). \]
        %
        Thus Subgaussian random variables have Gaussian tails.

        \item If $|X| \leq A$ almost surely, then $\psitwo{X} \leq 10 A$. Thus bounded random variables are subgaussian.

    %\item (Centering) For any random variable $X$,
    %
    %\[ \psitwo{X - \EE(X)} \lesssim \psitwo{X}. \]
    
    %\item (Union Bound) If $X_1, \dots, X_N$ are random variables, then
    %
    %\[ \psitwo{X_1 + \dots + X_N} \leq \psitwo{X_1} + \dots + \psitwo{X_N}. \]
    
        \item If $X_1, \dots, X_N$ are \emph{independent}, then
        %
        \[ \psitwo{X_1 + \dots + X_N} \leq 10 \left( \psitwo{X_1}^2 + \dots + \psitwo{X_N}^2 \right)^{1/2}. \]
        %
        This is an equivalent way to state \emph{Hoeffding's Inequality}, and we refer to an application of this inequality as an application of Hoeffding's inequality.
    \end{itemize}
    %
    Roughly speaking, if $X$ is a random variable with $\psitwo{X} \leq A$, we can think of $X$ as being sharply concentrated in the region $[-A,A]$. The Orlicz norm thus provides a convenient way to quantify concentration phenomena.
    %
    \begin{remark}
        The constants involved in these statements are suboptimal, but will suffice for our purposes. Proofs can be found in Chapter 2 of \cite{Vershynin}.
    \end{remark}

    \end{comment}
\end{itemize}

Throughout this paper, we will need to consider a standard mollifier. The next theorem gives the existence of a mollifier with the properties we require; in the remainder of the paper, we fix a single instance of such a mollifier. The proofs are not particular enlightening or novel, and thus for most it will suffice to read the statements of the theorems as a setup for later sections.

\begin{theorem} \label{equationASFGCISIX}
    There exists a smooth probability density $\phi \in C^\infty(\TT^d)$ such that $\phi(x) = 0$ for $|x| \geq 2/5$, and such that for each $x \in \TT^d$
    %
    \[ \sum_{k \in \{ 0, 1 \}^d} \phi(x + k/2) = 2^d. \]
\end{theorem}
\begin{proof}
    Let $\psi$ be a non-negative smooth function on $\TT$ such that $\psi(x) = \psi(- x)$ for all $x \in \TT$, $\psi(x) = 1$ for $|x| \leq 1/10$, $\psi(x) = 0$ for $|x| \geq 2/10$, and $0 \leq \psi(x) \leq 1$ for all $x \in \TT$. Then define $\eta$ to be the non-negative, $C^\infty$ function
    %
    \[ \eta(x) = \frac{1}{2} - \frac{\psi(x) + \psi(x + 1/2)}{2}. \]
    %
    If we define
    %
    \[ \phi_0(x) = 2(\psi(x) + \eta(x)), \]
    %
    then $\phi_0(x) + \phi_0(x + 1/2) = 2$ for all $x \in \TT$. Moreover, if $|x| \geq 2/5$, then $\psi(x) = 0$, and since this implies $|x + 1/2| \leq 1/10$, we find $\eta(x) = 0$. Thus $\phi_0(x) = 0$ for $|x| \geq 2/5$. But the condition $\phi_0(x) + \phi_0(x + 1/2) = 2$ implies that $\phi_0$ is a probability density function. Thus it suffices to define
    %
    \[ \phi(x_1, \dots, x_d) = \phi_0(x_1) \dots \phi_0(x_d). \qedhere \]
\end{proof}

For each $\varepsilon \in (0,1)$, we can then define $\phi_\varepsilon \in C^\infty(\TT^d)$ by writing
%
\[ \phi_\varepsilon(x) = \begin{cases} \varepsilon^{-d} \phi(x/\varepsilon) &: |x| < \varepsilon, \\ 0 &: \text{otherwise}. \end{cases} \]
%
Then the following properties hold:
%
\begin{enumerate}
    \item For each $\varepsilon \in (0,1)$, $\phi_\varepsilon$ is a smooth probability density, and $\phi_\varepsilon(x) = 0$ for $|x| \geq \varepsilon$.

    \item For any positive integer $N$, if $\varepsilon = 1/N$ and $x \in \TT^d$,
    %
    \begin{equation} \label{equation5550002352124124512}
        \sum_{k \in [2N]^d} \phi_{1/N}(x + k/2N) = (2N)^d.
    \end{equation}

    \item For each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{approximationtoidentitypointwiseconvergence}
        \lim_{\varepsilon \to 0} \widehat{\phi_\varepsilon}(\xi) = 1.
    \end{equation}
        
    \item For each $T > 0$, and for all $\varepsilon > 0$ and non-zero $k \in \ZZ^d$,
    %
    \begin{equation} \label{molificationdecaybound}
        |\widehat{\phi_\varepsilon}(k)| \lesssim_T \varepsilon^{-T} |k|^{-T}.
    \end{equation}
\end{enumerate}

\section{A Metric Space Controlling Fourier Dimension}

In order to work with a Baire category type argument, we must construct an appropriate metric space appropriate for our task. Though in later sections we will specify $\beta$ as in Theorem \ref{maintheorem}, in this section we let $\beta$ be an arbitrary element of $(0,d]$. We proceed as in \cite{Korner2}, forming our metric space as a combination of two simpler metric spaces:
%
\begin{itemize}
    \item We let $\mathcal{E}$ denote the family of all compact subsets of $\TT^d$. If, for two compact sets $E,F \in \mathcal{E}$, we consider their Hausdorff distance
    %     
    \[ d_H(E,F) = \inf \{ \varepsilon > 0 : E \subset F_\varepsilon\ \text{and}\ F \subset E_\varepsilon \}, \]
    %
    then $(\mathcal{E},d_H)$ forms a complete metric space. We note that if a sequence $\{ E_k \}$ converges to a set $E$ in the Hausdorff distance, then $E$ is the collection of all values $\lim_{k \to \infty} x_k$, where $\{ x_k \}$ is a convergent sequence with $x_k \in E_k$ for each $k$.

    \item We let $M(\beta)$ consist of the class of all finite Borel measures $\mu$ on $\TT^d$ such that for each $\varepsilon > 0$, the quantity
    %
    \[ \| \mu \|_{M(\beta,\varepsilon)} = \sup_{\xi \in \ZZ^d} \widehat{\mu}(\xi) |\xi|^{\beta/2 - \varepsilon} \]
    %
    is finite. Then $\| \cdot \|_{M(\beta,\varepsilon)}$ is a seminorm, and the collection of all such seminorms for $\varepsilon \in (0,\beta/2]$ gives $M(\beta)$ the structure of a Frech\'{e}t space. Under this topology, a sequence of probability measures $\{ \mu_k \}$ converges to a probability measure $\mu$ in $M(\beta)$ if and only if for any $\varepsilon > 0$, $\lim_{k \to \infty} \| \mu_k - \mu \|_{M(\beta,\varepsilon)} = 0$.
\end{itemize}

\begin{comment}
\begin{theorem}
    $M(\beta)$ is a Frech\'{e}t space.
\end{theorem}
\begin{proof}
    Let $\{ \mu_k \}$ be a Cauchy sequence in $M(\beta)$. By the Banach-Alaoglu theorem, we can find a finite Borel measure $\mu$ such that some subsequence $\{ \mu_{k_i} \}$ of the sequence $\{ \mu_k \}$ converges weakly to $\mu$. Then for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationAAGDDTYY8}
        \lim_{i \to \infty} \widehat{\mu_{k_i}}(\xi) = \widehat{\mu}(\xi).
    \end{equation}
    %
    Since $\{ \mu_k \}$ is Cauchy, for each $\varepsilon > 0$ there exists a constant $M_\varepsilon > 0$ such that for each $k$,
    %
    \begin{equation} \label{equationGFDSCCSI9}
        \| \mu_k \|_{M(\beta,\varepsilon)} \leq M_\varepsilon.
    \end{equation}
    %
    But combining \eqref{equationAAGDDTYY8} with \eqref{equationGFDSCCSI9} shows that for each $\varepsilon > 0$,
    %
    \begin{equation} \label{equationFGSCIS991}
        \| \mu \|_{M(\beta,\varepsilon)} \leq M_\varepsilon < \infty.
    \end{equation}
    %
    In particular, $\mu \in M(\beta)$. Now fix $\varepsilon_0 > 0$ and $\varepsilon > 0$. Because $\{ \mu_k \}$ is Cauchy, there exists $k_0$ such that for $k_1,k_2 \geq k_0$,
    %
    \begin{equation} \label{equationGGSIC8823}
        \| \mu_{k_1} - \mu_{k_2} \|_{M(\beta,\varepsilon_0)} \leq \varepsilon.
    \end{equation}
    %
    But then combining \eqref{equationAAGDDTYY8} and\eqref{equationGGSIC8823} shows that for $k \geq k_0$,
    %
    \begin{equation} \label{equationGGSCSXXX}
        \| \mu - \mu_k \|_{M(\beta,\varepsilon_0)} \leq \varepsilon.
    \end{equation}
    %
    Since $\varepsilon_0$ and $\varepsilon$ were arbitrary, \eqref{equationGGSCSXXX} shows that $\mu_k$ converges to $\mu$ in the topology determined by the seminorms of $M(\beta)$. If we consider a decreasing family $\{ \varepsilon_k \}$ such that $\varepsilon_k \to 0$, then $M(\beta)$ is clearly topologized by the subfamily of seminorms $\{ \| \cdot \|_{M(\beta,\varepsilon_k)} \}$, so $M(\beta)$ is metrizable. Thus we conclude that $M(\beta)$ is a Frech\"{e}t space.
\end{proof}
\end{comment}

We now consider a fusion of the metric spaces $\mathcal{E}$ and $M(\beta)$. We let $\mathcal{X}$ be the collection of all pairs $(E,\mu) \in \mathcal{E} \times M(\beta)$, where $\mu$ is a probability measure with $\text{supp}(\mu) \subset E$. Then $\mathcal{X}$ is a closed subset of $\mathcal{E} \times M(\beta)$, and thus a complete metrizable space. We remark that for any $\varepsilon > 0$ and $(E,\mu) \in \mathcal{X}$,
%
\begin{equation} \label{equationGFSCSC4}
    \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = 0.
\end{equation}
%
which follows from the fact that $\| \mu \|_{M(\beta,\varepsilon/2)}$ is finite.
\begin{comment}

\begin{theorem}
    $\mathcal{X}$ is a closed subset of $\mathcal{E} \times M(\beta)$.
\end{theorem}
\begin{proof}
    Suppose $\{ (E_k,\mu_k) \}$ is a sequence of elements of $\mathcal{X}$ converging to some tuple $(E,\mu) \in \mathcal{E} \times M(\beta)$. Fix $\varepsilon > 0$. Since $E_k \to E$ in the Hausdorff dimension, there exists $k_0$ such that for $k \geq k_0$, $E_k \subset E(\varepsilon)$. Since $\mu_k \to \mu$ weakly, this implies that $\mu$ is a probability measure, and that $\text{supp}(\mu) \subset E(\varepsilon)$. Taking $\varepsilon \to 0$ shows that $\text{supp}(\mu) \subset E$. Again for a fixed $\varepsilon > 0$, applying the triangle inequality and the reverse triangle inequality combined with \eqref{equationGFSCSC4} applied to $\mu_k$, we conclude
    %
    \[ \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi) - \widehat{\mu_k}(\xi)| \leq \| \mu - \mu_k \|_{M(\beta,\varepsilon)}. \]
    %
    Taking $k \to \infty$ shows that
    %
    \[ \lim_{|\xi| \to \infty} |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi)| = 0, \]
    %
    which completes the proof.
\end{proof}

\end{comment}

\begin{remark}
    One might like to work with the smaller space $\tilde{\mathcal{X}} \subset \mathcal{X}$ of pairs $(E,\mu) \in \mathcal{X}$ with $\text{supp}(\mu) = E$. But $\tilde{\mathcal{X}}$ is not a closed subset of $\mathcal{E} \times M(\beta)$, and so is not a complete metrizable space under the product topology. As a consolation, we note that one can prove that quasi-all elements of $\mathcal{X}$ belong to $\tilde{\mathcal{X}}$, though we will not use this fact in the paper.
\end{remark}

A density approach allows us to work with smooth measures for the remainder of the methods in this paper.

\begin{lemma} \label{smoothdensitylemma}
    The set of all $(E,\mu)$ with $\mu \in C^\infty(\TT^d)$ is dense in $\mathcal{X}$.
\end{lemma}
\begin{proof}
    Consider $(E,\mu) \in \mathcal{X}$. For each $\delta > 0$, consider $\mu_\delta = \mu * \phi_\delta$. Then $\mu_\delta \in C^\infty(\TT^d)$. If we set $E_\delta = E \cup \text{supp}(\mu_\delta)$, then we claim
    %
    \begin{equation} \label{equationFFSPCOS}
        \lim_{\delta \to 0}\; (E_\delta, \mu_\delta) = (E,\mu).
    \end{equation}
    %
    Since $\text{supp}(\mu_\delta) \subset E(\delta)$, we conclude that
    %
    \begin{equation} \label{equationFFSICSI}
        d_H(E,E_\delta) \leq \delta.
    \end{equation}
    %
    Thus $E_\delta \to E$ under the Hausdorff distance. Now fix $\varepsilon_0 \in (0,\beta/2)$ and $\varepsilon > 0$. For each $\xi \in \ZZ^d$, $|\widehat{\mu_\delta}(\xi)| = |\widehat{\phi_\delta}(\xi)| |\widehat{\mu}(\xi)|$, so
    %
    \begin{equation} \label{equationFFSCI}
        |\xi|^{\beta/2 - \varepsilon_0} |\mu_\delta(\xi) - \mu(\xi)| = |\xi|^{\beta/2 - \varepsilon_0} |\widehat{\phi_\delta}(\xi) - 1| |\widehat{\mu}(\xi)|.
    \end{equation}
    %
    Since $(E,\mu) \in \mathcal{X}$, there exists $R$ such that for $|\xi| \geq R$,
    %
    \begin{equation} \label{equationDIICSIC}
        |\widehat{\mu}(\xi)| \leq \varepsilon |\xi|^{\varepsilon_0-\beta/2}.
    \end{equation}
    %
    Applying the standard $(L^1,L^\infty)$ bound for the Fourier transform to $\phi_\delta$, we find
    %
    \begin{equation} \label{equationDPDSPCOXX}
        |\widehat{\phi_\delta}(\xi)| \leq 1.
    \end{equation}
    %
    Combining \eqref{equationFFSCI}, \eqref{equationDIICSIC}, and \eqref{equationDPDSPCOXX}, we conclude that for $|\xi| \geq R$,
    %
    \begin{equation} \label{equationDSCISIIXX}
        |\xi|^{\beta/2 - \varepsilon_0} |\mu_\delta(\xi) - \mu(\xi)| \leq 2 \varepsilon.
    \end{equation}
    %
    By \eqref{approximationtoidentitypointwiseconvergence}, we conclude that there exists $\delta_0$ such that for $\delta \leq \delta_0$ and $|\xi| \leq R$,
    %
    \begin{equation} \label{equationDISCIIS}
        |\widehat{\phi_\delta}(\xi) - 1| \leq \varepsilon |\xi|^{\varepsilon_0 - \beta/2}.
    \end{equation}
    %
    The $(L^1,L^\infty)$ bound for the Fourier transform imply that
    %
    \begin{equation} \label{equationFSCISIXX}
        |\widehat{\mu}(\xi)| \leq 1
    \end{equation}
    %
    But from \eqref{equationFSCISIXX} and \eqref{equationDISCIIS} applied to \eqref{equationFFSCI}, we find that for $\delta \leq \delta_0$ and $|\xi| \leq R$,
    %
    \begin{equation} \label{equatioNFISISCISI}
        |\xi|^{\beta/2 - \varepsilon_0} |\mu_\delta(\xi) - \mu(\xi)| \leq \varepsilon.
    \end{equation}
    %
    Putting together \eqref{equationDSCISIIXX} and \eqref{equatioNFISISCISI}, we find that for $\delta \leq \delta_0$,
    %
    \begin{equation} \label{equationDAIWOIC}
        \| \mu_\delta - \mu \|_{M(\beta,\varepsilon_0)} \leq 2\varepsilon.
    \end{equation}
    %
    Since $\varepsilon$ and $\varepsilon_0$ were arbitrary, \eqref{equationDAIWOIC} and \eqref{equationFFSICSI} imply the required convergence property.
\end{proof}

Our main way of constructing approximations to $(E_0,\mu_0) \in \mathcal{X}$ is to multiply $\mu_0$ by a smooth function $f$. For instance, we might choose $f$ in such a way as to remove certain points from the support of $\mu_0$ which may contribute to the formation of a particular pattern. As long as $f$ is small enough in $M(\beta)$, this introduces a neglible amount of error.

\begin{lemma} \label{LemmaTTSICICS}
    Consider a smooth finite measure $\mu_0$ on $\TT^d$, as well as a smooth probability density function $f$. If we define $\mu = f \mu_0$, then
    %
    \[ \| \mu - \mu_0 \|_{M(\beta,\varepsilon)} \lesssim_{d,\mu_0} \| f \|_{M(\beta,\varepsilon)}. \]
\end{lemma}
\begin{proof}
    Since $\widehat{\mu} = \widehat{f} * \widehat{\mu_0}$, and $\widehat{f}(0) = 1$, for each $\xi \in \ZZ^d$ we have
    %
    \begin{equation} \label{equationPPYTUECUUCS}
    \begin{split}
        |\xi|^{\beta/2 - \varepsilon} |\widehat{\mu}(\xi) - \widehat{\mu_0}(\xi)| &= |\xi|^{\beta/2 - \varepsilon}| \left| \sum_{\eta \neq \xi} \widehat{f}(\xi - \eta) \widehat{\mu_0}(\eta) \right|.
    \end{split}
    \end{equation}
    %
    If $|\eta| \leq |\xi|/2$, then $|\xi|/2 \leq |\xi - \eta| \leq 2 |\xi|$, so
    %
    \begin{equation} \label{equationPPDOSO}
        |\xi|^{\beta/2 - \varepsilon} |\widehat{f}(\xi - \eta)| \leq \| f \|_{M(\beta,\varepsilon)} |\xi|^{\beta/2 - \varepsilon} |\xi-\eta|^{\varepsilon-\beta/2} \leq 2^{\beta/2 - \varepsilon} \| f \|_{M(\beta,\varepsilon)} \lesssim_d \| f \|_{M(\beta,\varepsilon)}.
    \end{equation}
    %
    Since $\mu_0$ is smooth, for any $T \geq 0$ and $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationGGIDISCXJIX}
        |\xi|^T |\widehat{\mu_0}(\xi)| \lesssim_{T,\mu_0} 1.
    \end{equation}
    %
    Thus we can combine the bounds \eqref{equationPPDOSO} and \eqref{equationGGIDISCXJIX}, with $T = d+1$, to conclude that
    %
    \begin{equation} \label{equationGGPSOVVCSI}
    \begin{split}
        |\xi|^{\beta/2 - \varepsilon} \left| \sum_{0 \leq |\eta| \leq |\xi|/2} \widehat{f}(\eta) \widehat{\mu_0}(\xi - \eta) \right| &\lesssim_{\mu_0,d} \left( 1 + \sum_{0 < |\eta| \leq |\xi|/2} \frac{1}{|\xi|^{d+1}} \right) \| f \|_{M(\beta,\varepsilon)} \lesssim_d \| f \|_{M(\beta,\varepsilon)}.
    \end{split}
    \end{equation}
    %
    On the other hand, we note that \eqref{equationPPDOSO} implies that for all $\eta \neq \xi$,
    %
    \begin{equation} \label{equationGGDPSOX}
    \begin{split}
        |\widehat{f}(\xi - \eta)| \leq \| f \|_{M(\beta,\varepsilon)},
    \end{split}
    \end{equation}
    %
    Thus applying \eqref{equationGGIDISCXJIX} and \eqref{equationGGDPSOX}, with $T = 3d/2$ we conclude that
    %
    \begin{equation} \label{equationGGHOODPPS}
    \begin{split}
        |\xi|^{\beta/2 - \varepsilon} \left| \sum_{\substack{|\eta| > |\xi|/2\\ \eta \neq \xi}} \widehat{f}(\xi - \eta) \widehat{\mu_0}(\eta) \right| &\lesssim_{d,\mu_0} |\xi|^{\beta/2 - \varepsilon} \sum_{|\eta| > |\xi|/2} \frac{\| f \|_{M(\beta,\varepsilon)}}{|\eta|^{3d/2}} \lesssim_d \| f \|_{M(\beta,\varepsilon)}.
    \end{split}
    \end{equation}
    %
    Combining \eqref{equationPPYTUECUUCS}, \eqref{equationGGPSOVVCSI} and \eqref{equationGGHOODPPS} completes the proof.
\end{proof}

The next lemma shows that provided that, for $K$ points $x_1, \dots, x_K \in \TT^d$, that if enough square root cancellation occurs in the exponential sum
%
\[ \frac{1}{K} \sum_{i = 1}^K e^{2 \pi i (x_i \cdot \xi)}, \]
%
then a smooth function $f$ localized to these $K$ points has the appropriate Fourier decay that might be expected by the mass of it's support.

\begin{lemma} \label{Lemma65493}
    Fix $C > 0$, $\varepsilon_1, \varepsilon_2 > 0$, and $\delta > 0$. Consider $K$ points $x_1, \dots, x_K \in \TT^d$ such that if
    %
    \[ D(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i), \]
    %
    then for each $\xi \in \ZZ^d$ with $0 < |\xi| \leq K^{1/\beta + \varepsilon_2}$,
    %
    \begin{equation} \label{equationFFOSOXPFFGHI}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Then there exists $K_0$, depending on $C$, $\varepsilon$, $d$, and $\varepsilon_1$, such that if $K \geq K_0$, $\varepsilon_0 \geq C^{-1} K^{-1/\beta}$, and we define
    %
    \[ f(x) = \frac{1}{K} \sum_{i = 1}^K \phi_{\varepsilon_0}(x - x_i), \]
    %
    then $\| f \|_{M(\beta,\varepsilon_1)} \leq \delta$.
\end{lemma}
\begin{proof}
    Noting that $f = D * \phi_{\varepsilon_0}$, we find that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_{\varepsilon_0}}|.
    \end{equation}
    %
    The standard $(L^1,L^\infty)$ bound for the Fourier transform implies that
    %
    \begin{equation} \label{equationGGHOUSUSXXCCX}
        \| \widehat{\phi_{\varepsilon_0}} \|_{L^\infty(\ZZ^d)} \leq \| \phi_{\varepsilon_0} \|_{L^1(\TT^d)} = 1.
    \end{equation}
    %
    For $0 < |\xi| \leq K^{1/\beta}$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationGGHOUSUSXXCCX} to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
        |\widehat{f}(\xi)| \leq \left[ C \log(K)^{1/2} K^{-\varepsilon_1/\beta} \right] |\xi|^{\varepsilon_1 - \beta/2}.
    \end{equation}
    %
    As $K \to \infty$, $\log(K)^{1/2} K^{-\varepsilon_1/\beta} \to 0$, so we conclude from \eqref{equationGGIOHISI99234} there exists $K_0$ depending on $d$, $\varepsilon_1$, $C$, and $\delta$, such that for $K \geq K_0$,
    %
    \begin{equation} \label{equation663sdDDDCC}
        |\widehat{f}(\xi)| \leq \delta |\xi|^{\varepsilon_1-\beta/2}.
    \end{equation}
    %
    If $K^{1/\beta} \leq |\xi| \leq K^{1/\beta + \varepsilon_2}$, we note that \eqref{molificationdecaybound} implies $\widehat{\phi_{\varepsilon_0}}(\xi) \lesssim_d \varepsilon_0^{-\beta/2} |\xi|^{-\beta/2}$, which together with \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS}, and the bound $\varepsilon_0 \geq C^{-1} K^{-1/\beta}$, imply
    %
    \begin{equation} \label{equationGGOOSC66341}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_d \left( C K^{-1/2} \varepsilon_0^{-\beta/2} K^{-\varepsilon_1/\beta} \log(K)^{1/2} \right) |\xi|^{\varepsilon_1-\beta/2}\\
        &\leq \left( C^{1 + \beta/2} K^{-\varepsilon_1/\beta} \log(K)^{1/2} \right) |\xi|^{\varepsilon_1 - \beta/2}.
    \end{split}
    \end{equation}
    %
    Again, we find that as $K \to \infty$, $K^{-\varepsilon_1/\beta} \log(K)^{1/2} \to 0$, so we conclude from \eqref{equationGGOOSC66341} that there exists $K_0$ depending only on $\delta$, $C$, $d$, and $\varepsilon_1$, such that if $K \geq K_0$, then
    %
    \begin{equation} \label{equationUUUDDDCII777}
        |\widehat{f}(\xi)| \leq \delta |\xi|^{\varepsilon_1-\beta/2}.
    \end{equation}
    %
    If $|\xi| \geq K^{1/\beta + \varepsilon_2}$, we apply \eqref{molificationdecaybound} for $T \geq \beta/2$ together with the bound $\varepsilon_0 \geq C^{-1} K^{-1/\beta}$ to conclude
    %
    \begin{equation} \label{equationGGUSCCCYVSSXX998723}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_T \varepsilon_0^{-T} |\xi|^{-T}\\
        &\leq \left[ C^T K^{T/\beta} |\xi|^{\beta/2 - T} \right] |\xi|^{-\beta/2}\\
        &\leq \left[ C^T K^{1/2 + (\beta/2 - T) \varepsilon_1} \right] |\xi|^{-\beta/2}.
    \end{split}
    \end{equation}
    %
    If we choose $T > \beta/2 + 1/2 \varepsilon_1$, then as $K \to \infty$, $K^{1/2 + (\beta/2 - T) \varepsilon_1} \to 0$. Thus we conclude from \eqref{equationGGUSCCCYVSSXX998723} that there exists a constant $K_0$ depending on $C$, $\delta$, $d$, and $\varepsilon_1$, such that for $K \geq K_0$,
    %
    \begin{equation} \label{equationBBCDSGDCC77}
        |\widehat{f}(\xi)| \leq \delta B(\xi) |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2} = \delta A(\xi).
    \end{equation}
    %
    Combining \eqref{equation663sdDDDCC}, \eqref{equationUUUDDDCII777}, and \eqref{equationBBCDSGDCC77} shows that there exists a constant $K_0$ depending on $C$, $\delta$, $d$, and $\varepsilon_1$ such that for $K \geq K_0$, $\| f \|_{M(\beta,\varepsilon_1)} \leq \delta$.
\begin{comment}


%    For any $\varepsilon > 0$, we get the result without $D$ for $|\xi| \gtrsim 1/\varepsilon^{1 + \varepsilon}$. If $\widehat{D}(\xi) \leq K^{-1/2} \log(1 + K)^{1/2}$
%
% Last bound: |\xi| \gtrsim_T K^{1/\beta + O(1/T)} / \delta^{O(1/T)}
% Second Bound: |\xi| \gtrsim_T K^{1/\beta} \log(1 + K)^{O(1/T)}
% First Bound: 
%
% K^{-1/2} \log(1 + K)^{1/2} \leq 
%
%    $\varepsilon^{-T} \lesssim B(\xi) |\xi|^{T-\beta/2} \log(1 + |\xi|)^{1/2}$
%
    Noting that $f = D * \phi_{\varepsilon_0}$, we find that
    %
    \begin{equation} \label{equation6666GGCIS}
        |\widehat{f}| = |\widehat{D}| |\widehat{\phi_{\varepsilon_0}}|.
    \end{equation}
    %
    The standard $(L^1,L^\infty)$ bound for the Fourier transform implies that
    %
    \begin{equation} \label{equationGGHOUSUSXXCCX}
        \| \widehat{\phi_{\varepsilon_0}} \|_{L^\infty(\ZZ^d)} \leq \| \phi_{\varepsilon_0} \|_{L^1(\TT^d)} = 1.
    \end{equation}
    %
    For $0 \leq |\xi| \leq K^{1/\beta}$, we combine \eqref{equationFFOSOXPFFGHI}, \eqref{equation6666GGCIS} and \eqref{equationGGHOUSUSXXCCX} to conclude that
    %
    \begin{equation} \label{equationGGIOHISI99234}
        |\widehat{f}(\xi)| \lesssim_{d,C} |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2}.
    \end{equation}
    %
    If $K^{1/\beta} \leq |\xi| \leq K^{1/\beta + \varepsilon}$, we note that \eqref{molificationdecaybound} implies $\widehat{\phi_{\varepsilon_0}}(\xi) \lesssim_\beta \varepsilon_0^{-\beta/2} |\xi|^{-\beta/2}$, which together with \eqref{equationFFOSOXPFFGHI} and \eqref{equation6666GGCIS} implies
    %
    \begin{equation} \label{equationGGOOSC66341}
        |\widehat{f}(\xi)| \leq C K^{-1/2} \log(K)^{1/2} \varepsilon_0^{-\beta/2} |\xi|^{-\beta/2} \lesssim_d \left( C K^{-1/2} \varepsilon_0^{-\beta/2} \right) |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2}.
    \end{equation}
    %
    If $\varepsilon_0 \geq C^{-1} K^{-1/\beta}$, we conclude that 
    %
    \begin{equation} \label{equationUUUDDDCII777}
        |\widehat{f}(\xi)| \lesssim_{d,C} |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2}.
    \end{equation}
    %
    If $|\xi| \geq K^{1/\beta + \varepsilon}$, we apply \eqref{molificationdecaybound} for $T \geq \beta/2$ together with the bound $\varepsilon_0 \geq C^{-1} K^{-1/\beta}$ to \eqref{equation6666GGCIS} to conclude
    %
    \begin{equation} \label{equationGGUSCCCYVSSXX998723}
    \begin{split}
        |\widehat{f}(\xi)| &\lesssim_T \varepsilon_0^{-T} |\xi|^{-T}\\
        &\leq \left[ \frac{C^T K^{T/\beta} |\xi|^{\beta/2 - T}}{\log(1 + |\xi|)^{1/2}} \right] |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2}\\
        &\leq \left[ \frac{C^T K^{1/2 + (\beta/2 - T) \varepsilon}}{\log(1 + K^{1/\beta + \varepsilon})^{1/2}} \right] |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2}.
    \end{split}
    \end{equation}
    %
    If we choose $T > \beta/2 + 1/2 \varepsilon$, then the value in the brackets in \eqref{equationGGUSCCCYVSSXX998723} decays as $K \to \infty$. Thus we conclude from \eqref{equationGGUSCCCYVSSXX998723} that
    %
    \begin{equation} \label{equationBBCDSGDCC77}
        |\widehat{f}(\xi)| \lesssim_{C,d,\varepsilon} |\xi|^{-\beta/2} \log(1 + |\xi|)^{1/2}.
    \end{equation}
    %
    Combining \eqref{equationGGIOHISI99234}, \eqref{equationUUUDDDCII777}, and \eqref{equationBBCDSGDCC77} completes the proof.
\end{comment}
\end{proof}

Independence of random variables is sufficient to obtain square root cancellation.

\begin{lemma} \label{LemmaGISCICS1}
    Fix a large integer $K$, let $X_1, \dots, X_K$ be independant uniformly distributed random variables on $\TT^d$. Set
    %
    \[ D(x) = \sum_{k = 1}^K \delta(x - x_k) \]
    %
    and
    %
    \[ B = \{ \xi \in \ZZ^d: |\xi| \leq K^{1/\beta + 1} \}. \]
    %
    Then there exists a constant $C$, depending only on $d$, such that
    %
    \[ \PP \left( \| \widehat{D} \|_{L^\infty(B)} \leq C K^{-1/2} \log(K)^{1/2} \right) \leq 1/10. \]
\end{lemma}
\begin{proof}
    For each $\xi \in \ZZ^d$ and $k \in \{ 1, \dots, K \}$, consider the random variable $C(\xi,k) = K^{-1} e^{2 \pi i (\xi \cdot X_k)}$. Then for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationPPDOCS999223}
        \sum_{k = 1}^K C(\xi,k) = \widehat{D}(\xi).
    \end{equation}
    %
    We also note that for each $\xi$ and $k$,
    %
    \begin{equation} \label{equationGFDSCSXAOOO99}
        |C(\xi,k)| = K^{-1},
    \end{equation}
    %
    Moreover, for $\xi \neq 0$,
    %
    \begin{align*}
        \EE(C(\xi,k)) = K^{-1} \int_{\TT^d} e^{2 \pi i (\xi \cdot x)}\; dx = 0.
    \end{align*}
    %
    Since the family of random variables $\{ C(\xi,1), \dots, C(\xi,K) \}$ is independent for a fixed non-zero $\xi$, we can apply Hoeffding's inequality together with \eqref{equationPPDOCS999223} and \eqref{equationGFDSCSXAOOO99} to conclude that for all $t \geq 0$,
    %
    \begin{equation} \label{equationDDISCCOXOSPP998323}
        \PP \left( |\widehat{D}(\xi)| \geq t \right) \leq 2 e^{-Kt^2/2}.
    \end{equation}
    %
    A union bound obtained by applying \eqref{equationDDISCCOXOSPP998323} over all $|\xi| \leq K^{1/\beta+1}$, combined with \eqref{equationDDISCCOXOSPP998323}, shows that if
    %
    \[ B = \{ \xi \in \ZZ^d : |\xi| \leq K^{1/\beta + 1} \}, \]
    %
    then there exists a constant $C \geq 1$ depending only on $d$, such that
    %
    \begin{equation} \label{equationPPDOCS2424}
        \PP \left( \| \widehat{D} \|_{L^\infty(B)} \geq t \right) \leq \exp \left( C \log(K) - \frac{5K t^2}{C} \right).
    \end{equation}
    %
    But then, setting $t = CK^{-1/2} \log(K)^{1/2}$ in \eqref{equationPPDOCS2424} completes the proof.
\end{proof}

It is a general heuristic that quasi-all sets are as `thin as possible' with respect to the Hausdorff metric. In particular, we should expect the Hausdorff dimension and Fourier dimension of a generic element of $\mathcal{X}$ to be as low as possible. For each $(E,\mu) \in \mathcal{X}$, the condition that $\mu \in M(\beta)$ implies that $\fordim(\mu) \geq \beta$, so $\fordim(E) \geq \beta$. Thus we might expect that for quasi-all $(E,\mu) \in M(A)$, the set $E$ has both Hausdorff dimension and Fourier dimension equal to $\beta$. This turns out to be the correct assumption.

\begin{lemma}
    For quasi-all $(E,\mu) \in \mathcal{X}$, $E$ is a Salem set of dimension $\beta$.
\end{lemma}
\begin{proof}
    We shall assume $\beta < d$ in the proof, since the case $\beta = d$ is trivial. Since the Hausdorff dimension of a measure is an upper bound for the Fourier dimension, it suffices to show that quasi-all $\mu \in M(A)$ have Hausdorff dimension at most $\beta$. For each $\alpha > \beta$ and $\delta, s > 0$, and let $A(\alpha,\delta,s) = \{ (E,\mu) \in \mathcal{G}: H^\alpha_\delta(E) < s \}$. Then $A(\alpha,\delta,s)$ is an open subset of $\mathcal{X}$, and
    %
    \[ \bigcap_{n = 1}^\infty \bigcap_{m = 1}^\infty \bigcap_{k = 1}^\infty A(\beta + 1/n, 1/m, 1/k) \]
    %
    is precisely the family of $(E,\mu) \in \mathcal{X}$ such that $E$ has Hausdorff dimension at $\beta$.
%
    %Certainly any $E$ in this family must have $H^\alpha(E) = 0$ for all $\alpha > \beta$, so $\hausdim(E) \leq \beta$. But the condition that $\mu \in M(A)$ implies $\fordim(\mu) \geq \beta$. Thus
    %
    %\[ \beta \leq \fordim(\mu) \leq \fordim(E) \leq \hausdim(E) \leq \beta, \]
    %
    %hence all these quantities are equal to $\beta$.
    Thus it suffices to show that $A(\alpha,\delta,s)$ is dense in $\mathcal{X}$ for $\alpha \in (\beta,d)$ and $\delta, s > 0$. Fix $(E_0,\mu_0) \in \mathcal{X}$, $\alpha \in (\beta,d)$, $\delta > 0$, $s > 0$, and $\varepsilon_1 > 0$. We aim to show that for each $\varepsilon > 0$, there exists $(E,\mu) \in A(\alpha,\delta,s)$ such that $d_H(E,E_0) \leq \varepsilon$ and $\| \mu - \mu_0 \|_{M(\beta,\varepsilon_1)} \leq \varepsilon$. Without loss of generality, in light of Lemma \ref{smoothdensitylemma}, we may assume that $\mu_0 \in C^\infty(\TT^d)$.

    Fix a large integer $K$. Lemma \ref{LemmaGISCICS1} shows that there exists a constant $C$ depending only on $d$, as well as $K$ points $x_1, \dots, x_K \in \TT^d$ such that if
    %
    \[ D(x) = \sum_{k = 1}^K \delta(x - x_k), \]
    %
    then for each $|\xi| \leq K^{1/\beta + 1}$,
    %
    \begin{equation} \label{equationDDVVIXXSX23}
        |\widehat{D}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
    %
    Using \eqref{equationDDVVIXXSX23} to apply Lemma \ref{Lemma65493}, and then applying Lemma \ref{LemmaTTSICICS}, we conclude that there exists $K_0$ depending on $C$, $\delta$, $d$, and $\varepsilon_1$, such that if $K \geq K_0$ and $\varepsilon_0 = K^{-1/\beta}$, and if
    %
    \[ \mu(x) = \frac{1}{K} \left( \sum_{k = 1}^K \phi_{\varepsilon_0}(x - x_k) \right) \mu_0(x), \]
    %
    then
    %
    \begin{equation} \label{equationYYUDUSC4434}
        \| \mu - \mu_0 \|_{M(\beta,\varepsilon_1)} \leq \varepsilon.
    \end{equation}
    %
    Since $\mu$ is supported on $K$ balls of radius $\varepsilon_0$, and for $K \geq \delta^{-1/\beta}$, so that $\varepsilon_0 \leq \delta$, we find that
    %
    \begin{equation} \label{equationGGSCPXX22}
        H^\alpha_\delta(\text{supp}(\mu)) \leq K \varepsilon_0^\alpha = K^{1 - \alpha/\beta}.
    \end{equation}
    %
    Since $\alpha > \beta$, \eqref{equationGGSCPXX22} implies that for suitably large $K$,
    %
    \begin{equation} \label{equationGGSXSOF9923}
        H^\alpha_\delta(\text{supp}(\mu)) \leq s.
    \end{equation}
    %
    Now let
    %
    \[ E = \text{supp}(\mu) \cup \{ y_1, \dots, y_N \}, \]
    %
    where $\{ y_1, \dots, y_N \} \subset E_0$ is a $\varepsilon$ net of $E_0$. Equation \eqref{equationGGSXSOF9923} implies that $H^\alpha_\delta(E) \leq s$ for sufficiently large $K$, so $(E,\mu) \in A(\alpha,\delta,s)$. Since $\text{supp}(\mu) \subset E$,
    %
    \begin{equation} \label{equationGGISIICV222}
        d_H(E,E_0) \leq \varepsilon.
    \end{equation}
    %
    Thus we have proved what was required to be shown.
\end{proof}

\begin{comment}

\section{Random Segments of Measures}

Several times, in this paper, we rely on a simple random segmentation applied to a given smooth measure. Here we collect some simple calculations we use quite often to bound the Fourier transforms of these random segmentations. We begin with a general result that enables us to control the high frequency terms of a smooth measure.

\begin{theorem} \label{lemma6213}
    Consider a smooth measure $\mu_0$ on $\TT^d$, $K$ points $x_1, \dots, x_K \in \TT^d$, $\varepsilon_0, \varepsilon_1 > 0$, and $T > 0$. Then there exists a constant $C$ depending solely on $\mu_0$, $d$, $\varepsilon_1$, and $T$, such that if
    %
    \[ \nu(x) = \left( \frac{1}{K} \sum_{i = 1}^K \phi_{\varepsilon_0}(x - x_i) \right) \cdot \mu_0(x), \]
    %
    then for $|\xi| \geq (1/\varepsilon_0)^{1+\varepsilon_1}$, $|\widehat{\nu}(\xi)| \leq C |\xi|^{-T}$.
\end{theorem}
\begin{proof}
    Define a finite measure
    %
    \begin{equation} \label{equationAAA}
        \alpha(x) = \frac{1}{K} \sum_{i = 1}^K \delta(x - x_i).
    \end{equation}
    %
    Then $\nu = (\alpha * \phi_{\varepsilon_0}) \mu_0$, so
    %
    \begin{equation} \label{equation3AFVV43}
        \widehat{\nu} = (\widehat{\alpha} \widehat{\phi_{\varepsilon_0}}) * \widehat{\mu_0}.
    \end{equation}
    %
    The standard $(L^1,L^\infty)$ bound for the Fourier transform shows that
    %
    \begin{equation} \label{equation2191294fAA}
        \| \widehat{\alpha} \|_{L^\infty(\ZZ^d)} \leq \alpha(\TT^d) = 1.
    \end{equation}
    % If random enough, $|\alpha^| \leq K^{-1/2}$
    %
    Combining \eqref{equation3AFVV43} with \eqref{equation2191294fAA} shows that for each $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equationBGQPS23}
        |\widehat{\nu}(\xi)| \leq \sum_{\eta \in \ZZ^d} |\widehat{\phi_{\varepsilon_0}}(\eta)| |\widehat{\mu_0}(\xi-\eta)|.
    \end{equation}
    %
    Since $\mu_0$ is smooth, for any $S > 0$ and $\xi \in \ZZ^d$,
    %
    \begin{equation} \label{equation78234125}
        |\widehat{\mu_0}(\xi)| \lesssim_S |\xi|^{-S}.
    \end{equation}
    %
    If $|\eta| \leq |\xi|/2$, $|\xi - \eta| \geq |\xi|/2$, so \eqref{equation78234125} implies that $|\widehat{\mu_0}(\xi - \eta)| \lesssim_S |\eta|^{-S}$ for all $S > 0$. Combined with the trivial bound $\| \widehat{\phi_{\varepsilon_0}} \|_{L^\infty(\ZZ^d)} \leq 1$ we find that
    %
    \begin{equation} \label{equation12412AGEIVOOV}
        \sum_{0 \leq |\eta| \leq |\xi|/2} |\widehat{\phi_{\varepsilon_0}}(\eta)| |\widehat{\mu_0}(\xi-\eta)| \lesssim_{d,S} \frac{1}{|\xi|^{S-d}}.
    \end{equation}
    %
    Conversely, if $|\eta| \geq 2 |\xi|$, then $|\xi - \eta| \geq |\eta|/2$, so a simple dyadic partition of the sum onto annular regions where $|\eta| \sim 2^k |\xi|$, each bounded using \eqref{equation78234125}, combined with the trivial bound $\| \widehat{\phi_{\varepsilon_0}} \|_{L^\infty(\ZZ^d)} \leq 1$, shows that for each $S > d$,
    %
    \begin{equation} \label{equationADWCP124}
        \sum_{|\eta| \geq 2 |\xi|} |\widehat{\phi_{\varepsilon_0}}(\eta)| |\widehat{\mu_0}(\xi-\eta)| \lesssim_{d,S} \frac{1}{|\xi|^{S-d}}.
    \end{equation}
    %
    Finally, if $|\xi|/2 \leq |\eta| \leq 2|\xi|$, then we employ \eqref{molificationdecaybound} together with the bound $\| \widehat{\mu_0} \|_{L^\infty(\ZZ^d)} \leq 1$, to conclude that
    %
    \begin{equation} \label{equationAFVGUREWIS}
        \sum_{|\xi|/2 \leq |\eta| \leq 2 |\xi|} |\widehat{\phi_{\varepsilon_0}}(\eta)| |\widehat{\mu_0}(\xi-\eta)| \lesssim_{d,S} \frac{(1/\varepsilon_0)^S}{|\xi|^{S-d}} = \frac{1}{|\xi|^d} \frac{(1/\varepsilon_0)^S}{|\xi|^{S-T-2d}} \frac{1}{|\xi|^T}.
    \end{equation}
    %
    If $|\xi| \geq (1/\varepsilon_0)^{S/(S - T - 2d)} = (1/\varepsilon_0)^{1 + O_T(1/S)}$, we conclude from \eqref{equationAFVGUREWIS} that
    %
    \begin{equation} \label{equationTTCCSSDWETF}
        \sum_{|\xi|/2 \leq |\eta| \leq 2 |\xi|} |\widehat{\phi_{\varepsilon_0}}(\eta)| |\widehat{\mu_0}(\xi-\eta)| \lesssim_{d,T} \frac{1}{|\xi|^d} \frac{1}{|\xi|^T}.
    \end{equation}
    %
    Taking $S$ suitably large relative to $\varepsilon_1$ and $T$, and then combining \eqref{equation12412AGEIVOOV}, \eqref{equationADWCP124}, and \eqref{equationTTCCSSDWETF} with \eqref{equationBGQPS23}, the claim is proved.
%    we conclude that for each $\varepsilon_1 > 0$, if $S$ is taken suitably large relative to $\varepsilon_1$ and $T$, there exists a constant $C$ depending only on $\mu_0$, $d$, and $\varepsilon_1$, such that if $|\xi| \geq (1/\varepsilon_0)^{1 + \varepsilon_1}$, then
    %
%    \[ |\widehat{\nu}(\xi)| \leq \frac{CK}{|\xi|^d} \frac{1}{|\xi|^T}. \qedhere \]
\end{proof}

Next, we produce a theorem that enables us to control low frequency terms using Hoeffding's inequality to control the deviation of a random variable from it's expectation.

\begin{theorem} \label{randomFourierTheorem}
    Let $\mu_0$ be a smooth measure on $\TT^d$. Consider a positive integer $K$, and some $\varepsilon_0 > 0$, and take any independant family of $K$ random vectors $\{ X_1, \dots, X_K \}$ in $\TT^d$ such that for each $x$ in the support of $\mu_0$,
    %
    \begin{equation} \label{equationA}
        \EE \left( \frac{1}{K} \sum_{i = 1}^K \phi_{\varepsilon_0}(x - X_i) \right) = 1.
    \end{equation}
    %
    Define a smooth measure
    %
    \[ \nu(x) = \left( \frac{1}{K} \sum_{i = 1}^K \phi_{\varepsilon_0}(x - X_i) \right) \cdot \mu_0(x), \]
    %
    and a set of frequencies
    %
    \[ D_\alpha = \{ \xi \in \ZZ^d : |\xi| \leq K^{1/\alpha} \}. \]
    %
    Then for each $\alpha > 0$, there exists a constant $C$, depending only on $\mu_0$, $d$, and $\alpha$, such that with probability greater than or equal to $4/5$,
    %
    \begin{equation} \label{equationBCCGWDASCI}
        |\nu(\TT^d) - 1| \leq C K^{-1/2},
    \end{equation}
    %
    and
    %
    \begin{equation} \label{equationBBEOFIDOAOXXS}
        \| \widehat{\mu_0} - \widehat{\nu} \|_{L^\infty(D_\alpha)} \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
\end{theorem}

\begin{remark}
    The measure constructed in Theorem \ref{randomFourierTheorem} is `essentially' a probability measure, with total mass equal to one plus a small error term. In particular, normalizing, defining a probability measure
    %
    \[ \mu(x) = \frac{\nu(x)}{\nu(\TT^d)}, \]
    %
    then if \eqref{equationBCCGWDASCI} and \eqref{equationBBEOFIDOAOXXS} hold, they also imply that there exists a constant $C$ depending only on $\mu_0$, $d$, and $\alpha$, such that
    %
    \begin{equation}
        \| \widehat{\mu_0} - \widehat{\mu} \|_{L^\infty(D_\alpha)} \leq C K^{-1/2} \log(K)^{1/2}.
    \end{equation}
\end{remark}

%\begin{remark}
%    The simplest example of inputs to which this lemma applies is obtained by fixing two integers $N$ and $M$, letting $I = [2N]^d$ (so $K = N^d$, and for each $i \in [2N]^d$, defining $X_i = i/N + j(i)/NM$, where $j(i)$ is chosen from $[M]^d$ uniformly at random, such that the family $\{ j(i) : i \in [2N]^d \}$ is independant. Equation \eqref{equationA} is then justified by \eqref{equation5550002352124124512}.
%\end{remark}

%\begin{remark}
%    Another example is obtaing by considering $K$ independant and uniformly distributed random variables $\{ X_1, \dots, X_K \}$ on $\TT^d$. Here the choice of $\varepsilon_0$ is arbitrary.
%\end{remark}

Theorem \ref{randomFourierTheorem} follows by taking a union bound to the results of the following two lemmas.

\begin{lemma} \label{nuboundlemma}
    There exists a constant $C$ depending only on $\mu_0$ and $d$ such that
    %
    \[ \PP \left( |\nu(\TT^d) - 1 | \geq C K^{-1/2} \right) \leq 1/10. \]
\end{lemma}
\begin{proof}
    For each $i \in \{ 1, \dots, K \}$, set
    %
    \[ Y_i = \frac{1}{K} \int_{\TT^d} \phi_{\varepsilon_0}(x - X_i)\; d\mu_0(x). \]
    %
    Then
    %
    \begin{equation} \label{equation2194012512905}
        |Y_i| \leq \frac{\| \mu_0 \|_{L^\infty(\TT^d)}}{K} \lesssim_{\mu_0} 1/K.
    \end{equation}
    %
    Moreover,
    %
    \begin{equation} \label{equation12931029}
        \sum_{i = 1}^K Y_i = \nu(\TT^d).
    \end{equation}
    %
    The family of random variables $\{ Y_1, \dots, Y_K \}$ are independant, so we can apply Hoeffding's inequality together with \eqref{equation2194012512905} and \eqref{equation12931029} to conclude that there exists a constant $C$ depending only on $\mu_0$ and $d$, such that for any $t \geq 0$,
    %
    \begin{equation} \label{equation190609190249019}
        \PP \left( |\nu(\TT^d) - \EE(\nu(\TT^d))| \geq t \right) \leq 2 \exp \left( - \frac{5 K t^2}{C^2} \right).
    \end{equation}
    %
    Noting that \eqref{equationA} implies $\EE(\nu(\TT^d)) = 1$, it suffices to set $t = CK^{-1/2}$ in \eqref{equation190609190249019}.
\end{proof}

\begin{lemma} \label{lemma532952}
    For each $\alpha > 0$, there exists a constant $C$, depending only on $\mu_0$, $d$, and $\alpha$, such that
    %
    \[ \PP \left( \| \widehat{\nu} - \widehat{\mu_0} \|_{L^\infty(D_\alpha)} \geq C K^{-1/2} \log(K)^{1/2} \right) \leq 1/10. \]
\end{lemma}
\begin{proof}
    For each $i \in \{ 1, \dots, K \}$, let $\nu_i(x) = K^{-1} \phi_{\varepsilon_0}(x - X_i) \mu_0(x)$. Then for each $\xi \in \ZZ^d$, define $Y_i(\xi) = \widehat{\nu_i}(\xi)$. For each $i$ and $\xi$, the standard $(L^1,L^\infty)$ bound on the Fourier transform implies
    %
    \begin{equation} \label{equation123102}
    \begin{split}
        |Y_i(\xi)| \leq \frac{\nu_i(\TT^d)}{K} \leq \frac{\| \mu_0 \|_{L^\infty(\TT^d)}}{K} \lesssim_{\mu_0} \frac{1}{K}.
    \end{split}
    \end{equation}
    %
    For a fixed $\xi \in \ZZ^d$, the family of random variables $\{ Y_1(\xi), \dots, Y_K(\xi) \}$ are independant and moreover,
    %
    \begin{equation} \label{equation998321521422}
        \sum_{i = 1}^K Y_i(\xi) = \widehat{\nu}(\xi).
    \end{equation}
    %
    Thus Hoeffding's inequality together with \eqref{equation123102} and \eqref{equation998321521422} imply that
    %
    \begin{equation} \label{equation19041209}
        \PP \left( \left| \widehat{\nu}(\xi) - \EE(\widehat{\nu}(\xi)) \right| \geq t \right) \leq 2 \exp \left( - K t^2 /\; \| \mu_0 \|_{L^\infty(\TT^d)}^2 \right)
    \end{equation}
    %
    for all $t \geq 0$. Applying a union bound to \eqref{equation19041209} over all $|\xi| \leq K^{1/\alpha}$, we conclude that there exists a constant $C$, depending only on $\alpha$, $d$, and $\mu_0$, such that for each $t \geq 0$,
    %
    \begin{equation} \label{equation1290419205129051920}
        \PP \left( \| \widehat{\nu} - \EE(\widehat{\nu}) \|_{L^\infty(D_\alpha)} \geq t \right) \leq \exp \left( C \log(K) - \frac{5 K t^2}{C} \right).
    \end{equation}
    %
    We can make $C$ as large as we want, so in particular, we assume $C \geq 1$. Noting that \eqref{equationA} implies $\EE(\widehat{\nu}) = \widehat{\mu_0}$ and setting $t = C K^{-1/2} \log(K)^{1/2}$ in \eqref{equation1290419205129051920} completes the proof.
\end{proof}

Combining Theorem \ref{lemma6213} and Theorem \ref{randomFourierTheorem}, we can control both large and small frequency terms in the Fourier series of a smooth random measure.

\begin{theorem}
    Fix $A > 0$, $\alpha \in (0,d]$, and $\varepsilon > 0$, and a sequence of positive integers $\{ B(\xi) : \xi \in \ZZ^d \}$ such that $B(\xi) \to \infty$ as $|\xi| \to \infty$. Then consider a smooth measure $\mu_0$ on $\TT^d$. Consider the measure $\nu$ as defined in Theorem \ref{randomFourierTheorem}, where
    %
    \[ \varepsilon \geq (AK)^{-1/\alpha}, \]
    %
    and define
    %
    \[ \mu(x) = \nu(x) / \nu(\TT^d). \]
    %
    Then there exists a constant $C$, depending on $\mu_0$, $d$, $A$, and $\varepsilon$ such that for all $\xi \in \ZZ^d$,
    %
    \[ |\widehat{\mu}(\xi) - \widehat{\mu_0}(\xi)| \leq B(\xi) |\xi|^{-\alpha/2} \log(1 + |\xi|)^{1/2}. \]
    %

\end{theorem}
\begin{proof}
    

    Fix $\alpha_2 \in (\alpha_1, \alpha_0)$ and $\alpha_3 \in (\alpha_1,\alpha_2)$, pick $\varepsilon_1$ such that $(1 + \varepsilon_1)/\alpha_0 = 1/\alpha_2$, and let $T = 1 + \alpha_1/2$. Then Theorem \ref{lemma6213} and Theorem \ref{randomFourierTheorem} imply that there exists a constant $C > 0$, depending only on $\mu_0$, $d$, $\alpha_0$, and $\alpha_1$, such that with probability greater than or equal to $4/5$,
    %
    \begin{equation} \label{equationGHLHPOX}
        |\nu(\TT^d) - 1| \leq C K^{-1/2},
    \end{equation}
    %
    \begin{equation} \label{equationGGLAPSOCCXXS}
        \| \widehat{\mu_0} - \widehat{\nu} \|_{L^\infty(D_{\alpha_3})} \leq C K^{-1/2} \log(K)^{1/2},
    \end{equation}
    %
    and for $|\xi| \geq (1/\varepsilon_0)^{1 + \varepsilon_1} = (A K^{1/\alpha_0})^{1 + \varepsilon_1} = A^{\alpha_0 / \alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPFOSOXIS}
        |\widehat{\nu}(\xi)| \leq C |\xi|^{-T}.
    \end{equation}
    %
    Now \eqref{equationGHLHPOX} and \eqref{equationGGLAPSOCCXXS} imply that
    %
    \begin{equation} \label{equationPPGOSIZZAAS}
    \begin{split}
         \| \widehat{\mu_0} - \widehat{\mu} \|_{L^\infty(D_{\alpha_3})} &\leq \| \widehat{\mu_0} - \widehat{\nu} \|_{L^\infty(D_{\alpha_3})} + \| \widehat{\nu} - \widehat{\mu} \|_{L^\infty(D_{\alpha_3})}\\
         &\lesssim_{\mu_0, d, \alpha_0, \alpha_1} K^{-1/2} \log(K)^{1/2} + \left( 1 - \frac{1}{\nu(\TT^d)} \right)\\
         &\lesssim_{\mu_0, d,\alpha_0,\alpha_1} K^{-1/2} \log(K)^{1/2}.
    \end{split}
    \end{equation}
    %
    Thus \eqref{equationPPGOSIZZAAS} implies that for $|\xi| \leq K^{1/\alpha_3}$,
    %
    \[ |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \lesssim_{\mu_0,d,\alpha_0,\alpha_1} K^{-1/2} \log(K)^{1/2} \leq |\xi|^{-\alpha_1/2} K^{[\alpha_1/\alpha_3-1]/2} \log(K)^{1/2}. \]
    %
    Since $\alpha_1/\alpha_3 - 1 < 0$, and the implicit constants do not depend on $K$, we conclude there is $K_0$, depending on $\mu_0$, $d$, $\alpha_0$, $\alpha_1$, and $\varepsilon$, such that for $K \geq K_0$, and $|\xi| \leq K^{1/\alpha_3}$,
    %
    \begin{equation} \label{equationDFCSPSOA}
        |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \leq \varepsilon \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Similarily, \eqref{equationGHLHPOX} and \eqref{equationPPFOSOXIS} imply that for $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPSDSXSA}
        |\widehat{\mu}(\xi)| \lesssim_{\mu_0, d, \alpha_0, \alpha_1} |\xi|^{-1} |\xi|^{-\alpha_1/2} \lesssim_{A,\alpha_0,\alpha_2} K^{-1/\alpha_2} |\xi|^{-\alpha_1/2} \leq K^{-1/\alpha_1} |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Since the implicit constants in \eqref{equationPPSDSXSA} do not depend on $K$, there exists $K_0$, depending on $\mu_0, d, \alpha_0, \alpha_1$, $\alpha_3$, $A$, and $\varepsilon > 0$, such that for $K \geq K_0$ and $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationGGPCOSPS}
        |\widehat{\mu}(\xi)| \leq (\varepsilon/2) \cdot |\xi|^{-\alpha_1/2}.
    \end{equation} 
    %
    Since $\mu_0$ is smooth, there exists $K_0$, depending on $A$, $\mu_0$, $\varepsilon$, $\alpha_0$, and $\alpha_2$, such that if $K \geq K_0$, and $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPPOSXSVIII}
        |\widehat{\mu_0}(\xi)| \leq (\varepsilon/2) \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Combining \eqref{equationGGPCOSPS} and \eqref{equationPPPOSXSVIII}, we conclude that if $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationGGDCISIXXS}
        |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \leq \varepsilon \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    If $K_0$ is large enough, depending on $A$, $\alpha_0$, and $\alpha_2$, such that $A^{\alpha_0/\alpha_2} K_0^{1/\alpha_2} \leq K_0^{1/\alpha_3}$, \eqref{equationDFCSPSOA} and \eqref{equationGGDCISIXXS} are sufficient to prove the required bounds. All that remains is to remove the explit reliance of $K_0$ on $\alpha_2$ and $\alpha_3$, but this can be done by making $\alpha_2$ and $\alpha_3$ explicit functions of $\alpha_0$ and $\alpha_1$, i.e. setting $\alpha_2 = \alpha_0/2 + \alpha_1/2$ and $\alpha_3 = \alpha_0/4 + 3\alpha_1/4$.
\end{proof}

\begin{theorem}
    Fix $A > 0$, $\alpha_0 \in (0,d]$, and a smooth measure $\mu_0$ on $\TT^d$. Consider the measure $\nu$ as defined in Theorem \ref{randomFourierTheorem}, where
    %
    \[ (AK)^{-1/\alpha_0} \leq \varepsilon_0 \leq 2 (AK)^{-1/\alpha_0}, \]
    %
    and define
    %
    \[ \mu(x) = \frac{\nu(x)}{\nu(\TT^d)}. \]
    %
    Then, for any $\alpha_1 \in (0,\alpha_0)$ and $\varepsilon > 0$, there exists $K_0$ depending on $\mu_0$, $\alpha_1$, and $d$, such that for $K \geq K_0$, with probability greater than or equal to $4/5$,
    %
    \[ \sup_{\xi \in \ZZ^d} \left( |\widehat{\mu}(\xi) - \widehat{\mu_0}(\xi)| \right) |\xi|^{\alpha_1/2} \leq \varepsilon. \]
\end{theorem}
\begin{proof}
    Fix $\alpha_2 \in (\alpha_1, \alpha_0)$ and $\alpha_3 \in (\alpha_1,\alpha_2)$, pick $\varepsilon_1$ such that $(1 + \varepsilon_1)/\alpha_0 = 1/\alpha_2$, and let $T = 1 + \alpha_1/2$. Then Theorem \ref{lemma6213} and Theorem \ref{randomFourierTheorem} imply that there exists a constant $C > 0$, depending only on $\mu_0$, $d$, $\alpha_0$, and $\alpha_1$, such that with probability greater than or equal to $4/5$,
    %
    \begin{equation} \label{equationGHLHPOX}
        |\nu(\TT^d) - 1| \leq C K^{-1/2},
    \end{equation}
    %
    \begin{equation} \label{equationGGLAPSOCCXXS}
        \| \widehat{\mu_0} - \widehat{\nu} \|_{L^\infty(D_{\alpha_3})} \leq C K^{-1/2} \log(K)^{1/2},
    \end{equation}
    %
    and for $|\xi| \geq (1/\varepsilon_0)^{1 + \varepsilon_1} = (A K^{1/\alpha_0})^{1 + \varepsilon_1} = A^{\alpha_0 / \alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPFOSOXIS}
        |\widehat{\nu}(\xi)| \leq C |\xi|^{-T}.
    \end{equation}
    %
    Now \eqref{equationGHLHPOX} and \eqref{equationGGLAPSOCCXXS} imply that
    %
    \begin{equation} \label{equationPPGOSIZZAAS}
    \begin{split}
         \| \widehat{\mu_0} - \widehat{\mu} \|_{L^\infty(D_{\alpha_3})} &\leq \| \widehat{\mu_0} - \widehat{\nu} \|_{L^\infty(D_{\alpha_3})} + \| \widehat{\nu} - \widehat{\mu} \|_{L^\infty(D_{\alpha_3})}\\
         &\lesssim_{\mu_0, d, \alpha_0, \alpha_1} K^{-1/2} \log(K)^{1/2} + \left( 1 - \frac{1}{\nu(\TT^d)} \right)\\
         &\lesssim_{\mu_0, d,\alpha_0,\alpha_1} K^{-1/2} \log(K)^{1/2}.
    \end{split}
    \end{equation}
    %
    Thus \eqref{equationPPGOSIZZAAS} implies that for $|\xi| \leq K^{1/\alpha_3}$,
    %
    \[ |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \lesssim_{\mu_0,d,\alpha_0,\alpha_1} K^{-1/2} \log(K)^{1/2} \leq |\xi|^{-\alpha_1/2} K^{[\alpha_1/\alpha_3-1]/2} \log(K)^{1/2}. \]
    %
    Since $\alpha_1/\alpha_3 - 1 < 0$, and the implicit constants do not depend on $K$, we conclude there is $K_0$, depending on $\mu_0$, $d$, $\alpha_0$, $\alpha_1$, and $\varepsilon$, such that for $K \geq K_0$, and $|\xi| \leq K^{1/\alpha_3}$,
    %
    \begin{equation} \label{equationDFCSPSOA}
        |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \leq \varepsilon \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Similarily, \eqref{equationGHLHPOX} and \eqref{equationPPFOSOXIS} imply that for $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPSDSXSA}
        |\widehat{\mu}(\xi)| \lesssim_{\mu_0, d, \alpha_0, \alpha_1} |\xi|^{-1} |\xi|^{-\alpha_1/2} \lesssim_{A,\alpha_0,\alpha_2} K^{-1/\alpha_2} |\xi|^{-\alpha_1/2} \leq K^{-1/\alpha_1} |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Since the implicit constants in \eqref{equationPPSDSXSA} do not depend on $K$, there exists $K_0$, depending on $\mu_0, d, \alpha_0, \alpha_1$, $\alpha_3$, $A$, and $\varepsilon > 0$, such that for $K \geq K_0$ and $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationGGPCOSPS}
        |\widehat{\mu}(\xi)| \leq (\varepsilon/2) \cdot |\xi|^{-\alpha_1/2}.
    \end{equation} 
    %
    Since $\mu_0$ is smooth, there exists $K_0$, depending on $A$, $\mu_0$, $\varepsilon$, $\alpha_0$, and $\alpha_2$, such that if $K \geq K_0$, and $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationPPPOSXSVIII}
        |\widehat{\mu_0}(\xi)| \leq (\varepsilon/2) \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    Combining \eqref{equationGGPCOSPS} and \eqref{equationPPPOSXSVIII}, we conclude that if $|\xi| \geq A^{\alpha_0/\alpha_2} K^{1/\alpha_2}$,
    %
    \begin{equation} \label{equationGGDCISIXXS}
        |\widehat{\mu_0}(\xi) - \widehat{\mu}(\xi)| \leq \varepsilon \cdot |\xi|^{-\alpha_1/2}.
    \end{equation}
    %
    If $K_0$ is large enough, depending on $A$, $\alpha_0$, and $\alpha_2$, such that $A^{\alpha_0/\alpha_2} K_0^{1/\alpha_2} \leq K_0^{1/\alpha_3}$, \eqref{equationDFCSPSOA} and \eqref{equationGGDCISIXXS} are sufficient to prove the required bounds. All that remains is to remove the explit reliance of $K_0$ on $\alpha_2$ and $\alpha_3$, but this can be done by making $\alpha_2$ and $\alpha_3$ explicit functions of $\alpha_0$ and $\alpha_1$, i.e. setting $\alpha_2 = \alpha_0/2 + \alpha_1/2$ and $\alpha_3 = \alpha_0/4 + 3\alpha_1/4$.
\end{proof}

\section{A Complete Metric Space of Generically Salem Sets}

\begin{comment}

\begin{lemma}
    For quasi-all $(E,\mu) \in \mathcal{X}$, $\text{supp}(\mu) = E$.
\end{lemma}
\begin{proof}
    For each closed set $K \subset \TT^d$ with nonempty interior, let $A(K)$ be the family of all $(E,\mu) \in X$ such that $E \cap K \neq \emptyset$ and $\mu(K) = 0$. The set $A(K)$ is clearly closed in $X$. Moreover, this set is nowhere dense; Fix $(E,\mu) \in A(K)$ and $\varepsilon > 0$. Then we can find a smooth probability density $\psi \in C^\infty(\TT^d)$ supported on $K^\circ \cap E_\varepsilon$. We then define $\mu_\varepsilon = (1 - \varepsilon) \mu + \varepsilon \psi$. Now
    %
    \[ \| \mu - \mu_\varepsilon \|_A \leq \varepsilon \left( \| \mu \|_A + \| \psi \|_A \right) \lesssim \varepsilon. \]
    %
    Moreover, $\mu_\varepsilon$ is supported on $\overline{E_\varepsilon}$, so
    %
    \[ d_X((E,\mu), (\overline{E_\varepsilon}, \mu_\varepsilon)) \lesssim \varepsilon. \]
    %
    If we let $A = \bigcup_{n = 1}^\infty A(K_n)$, where $\{ K_n \}$ is the family of all closed cubes in $\TT^d$ whose corners have rational coordinates, then quasi-all $(E,\mu) \in X$ belong to $A^c$. But $A^c$ is precisely the family of pairs $(E,\mu)$ with $\text{supp}(\mu) = E$.
\end{proof}

\end{comment}

All that now remains is to show that quasi-all elements of $\mathcal{X}$ avoid the given set $Z$; just as with the proof above, the advantage of the Baire category approach is that we can reduce our calculations to discussing only a couple scales at once, which allows us to focus solely on the discrete, quantitative question at the heart of the problem.

\section{Random Avoiding Sets} 

In the last section, our results held for an arbitrary $\beta \in (0,d]$. But in this section, we assume
%
\[ \beta = \frac{dn - \alpha}{n - 1/2}, \]
%
which will enable us to avoid the pattern $Z$.

\begin{lemma}
    For quasi-all $(E,\mu)$, for any distinct points $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$.
\end{lemma}
\begin{proof}
    The set $Z \subset \RR^{dn}$ is the countable union of sets with lower Minkowski dimension at most $\alpha$. For a closed set $W \subset \TT^{dn}$ with Minkowski dimension $\alpha$, and $s > 0$, consider the set
    %
    \[ B(W,s) = \left\{ (E,\mu) \in \mathcal{X}: \begin{array}{c}
            \text{for all $x_1, \dots, x_n \in E$ such that}\\
            \text{$|x_i - x_j| \geq s$ for $i \neq j$, $(x_1, \dots, x_n) \not \in W$}
        \end{array} \right\}. \]
    %
    Then $B(W,s)$ is an open subset of $\mathcal{X}$. If $Z$ is a countable union of closed sets $\{ Z_k \}$ with lower Minkowski at most $\alpha$, then clearly the set
    %
    \[ \bigcup_{k = 1}^\infty \bigcup_{n = 1}^\infty B(Z_k,1/n) \]
    %
    consists of the family of sets $(E,\mu)$ such that for distinct $x_1, \dots, x_n \in E$, $(x_1, \dots, x_n) \not \in Z$. Thus it suffices to show that $B(W,s)$ is dense in $\mathcal{X}$ for any $s > 0$, and any closed set $W$ with lower Minkowski dimension at most $\alpha$. So we fix a set $W \subset \RR^{dn}$, $(E_0,\mu_0) \in \mathcal{X}$. Our goal is to show that for any $\varepsilon_1 > 0$ and $\varepsilon > 0$, we can find $(E,\mu) \in B(W,s)$ with $d_H(E,E_0) \leq \varepsilon$ and $\| \mu - \mu_0 \|_{M(\beta,\varepsilon_1)} \leq \varepsilon$. We may assume $\mu_0 \in C^\infty(\TT^d)$ by Lemma \ref{smoothdensitylemma}.

    Since $W$ has lower Minkowski dimension at most $\alpha$, we can find an arbitrarily small $\varepsilon_0 > 0$ such that
    %
    \begin{equation} \label{equationGGSCSAS}
        |W_{\varepsilon_0}| \leq \varepsilon_0^{dn - \alpha}.
    \end{equation}
    %
    Applying Fubini's theorem to \eqref{equationGGSCSAS}, we conclude that we can find a $\varepsilon$-cover $\{ z_1, \dots, z_N \}$ of $E$ such that for each $k \in \{ 1, \dots, N \}$ and $i \in \{ 1, \dots, d \}$,
    %
    \begin{equation} \label{equationFISIJCISJIX123}
        H^{d-1} \left( (\TT^{i-1} \times z_k \times \TT^{d-i}) \cap W_{\varepsilon_0} \right) \leq 2d \varepsilon^{-1} \varepsilon_0^{dn-\alpha},
    \end{equation}
    %
    where $N$ is independant of $\varepsilon_0$. Now fix a large integer $K$ such that
    %
    \[ (1/10)K^{-1/\beta} \leq \varepsilon_0 \leq K^{-1/\beta}. \]
    %
    As $\varepsilon_0 \to 0$, $K \to \infty$, as we may take $K$ as large as we like. Then let $X_1, \dots, X_K$ be independent and uniformly distributed on $\TT^d$. For each distinct set of indices $k_1, \dots, k_n \in \{ 1, \dots, K \}$, the random vector $X_k = (X_{k_1}, \dots, X_{k_n})$ is uniformly distributed on $\TT^{nd}$, and so \eqref{equationGGSCSAS} implies
    %
    \begin{equation} \label{equationGGASDCJWIJSFGGGG}
        \PP(d(X_k,W) \leq \varepsilon_0) \leq |W_{\varepsilon_0}| \leq \varepsilon_0^{dn - \alpha}.
    \end{equation}
    %
    If $M_0$ denotes the number of indices $i$ such that $d(X_i,W) \leq \varepsilon_0$, then by linearity of expectation we conclude from \eqref{equationGGASDCJWIJSFGGGG} that
    %
    \begin{equation} \label{equationDDASGVV}
        \EE(M_0) \leq K^n \varepsilon_0^{dn - \alpha}.
    \end{equation}
    %
    Applying Markov's inequality to \eqref{equationDDASGVV}, we conclude that
    %
    \begin{equation} \label{equationFGGGSC}
        \PP(M_0 \geq 10 K^n \varepsilon_0^{dn - \alpha}) \leq 1/10.
    \end{equation}
    %
    Similarily for each $i \in \{ 1, \dots, d \}$, for each collection of distinct indices $k_1, \dots, \widehat{k_i}, \dots, k_n \in \{ 1, \dots, K \}$ and $k_i \in \{ 1, \dots, N \}$, we can consider the random vector
    %
    \[ Z_{i,k} = (X_{k_1}, \dots, X_{k_{i-1}}, z_k, X_{k_{i+1}}, \dots, X_{k_n}), \]
    %
    which is uniformly distributed on the hyperplane $\TT^{i-1} \times z_{k_i} \times \TT^{d-i}$. Thus \eqref{equationFISIJCISJIX123} implies that
    %
    \begin{equation} \label{equationDAIJIOJCIOWJCI112FF}
        \PP(d(Z_k,W) \leq \varepsilon_0) \leq H^{d-1} \left( (\TT^{i-1} \times z_{k_i} \times \TT^{d-i}) \cap W_{\varepsilon_0} \right) \leq 2d \varepsilon^{-1} \varepsilon_0^{dn - \alpha}.
    \end{equation}
    %
    If $M_i$ denotes the number of indices $(k_1, \dots, k_n)$ such that $d(Z_{k,i},W) \leq \varepsilon_0$, then by linearity of expectation, we conclude from \eqref{equationDAIJIOJCIOWJCI112FF} that
    %
    \[ \EE(M_i) \leq (N K^{n-1}) (2d \varepsilon^{-1} \varepsilon_0^{dn-\alpha}). \]
    %
    Markov's inequality then implies that 
    %
    \begin{equation} \label{equationWDOIAWDIOJCC232}
        \PP(M_i \geq 20 d^2 N K^{n-1} \varepsilon^{-1} \varepsilon_0^{dn - \alpha}) \leq 1/10d.
    \end{equation}
    %
    A union bound applying \eqref{equationWDOIAWDIOJCC232} repeatedly shows that
    %
    \begin{equation} \label{equationIOJSOCIJSIJCI2341424}
        \PP \left( \sum M_i \geq 20 d^2 N K^{n-1} \varepsilon^{-1} \varepsilon_0^{dn-\alpha} \right) \leq 1/10.
    \end{equation}
    %
    Taking a union bound to \eqref{equationFGGGSC}, \eqref{equationIOJSOCIJSIJCI2341424}, and the result of Lemma \ref{LemmaGISCICS1}, we conclude that there exists $K$ points $x_1, \dots, x_K \in \TT^d$ and a constant $C$ depending on $d$ and $\beta$ such that the following statements hold:
    %
    \begin{itemize}
        \item If we define
        %
        \[ D_0(x) = \frac{1}{K} \sum_{k = 1}^K \delta(x - x_k) \]
        %
        then for $|\xi| \leq K^{1/\beta + 1}$,
        %
        \begin{equation} \label{equationGGGISCI11242}
            |\widehat{D_0}(\xi)| \leq C K^{-1/2} \log(K)^{1/2}.
        \end{equation}

        \item Let $S_0$ be the set of indices $k_1 \in \{ 1, \dots, K \}$ with the property that we can find distinct $k_1, k_2, \dots, k_n \in \{ 1, \dots, K \}$ such that if $x = (x_{k_1}, \dots, x_{k_n})$, then $d(x, W) \leq \varepsilon_0$. Then
        %
        \begin{equation} \label{equationGGSC99124}
            \#(S_0) \leq 10 K^n \varepsilon_0^{nd-\alpha}.
        \end{equation}

        \item Let $S_1$ be the set of indices $k_2 \in \{ 1, \dots, K \}$ with the property that we can find $k_1 \in \{ 1, \dots, N \}$ and distinct indices $k_3, \dots, k_n \in \{ 1, \dots, K \}$ such that if $z = (z_{k_1}, x_{k_2}, \dots, x_{k_n})$, then $d(z,W) \leq \varepsilon_0$. Then
        %
        \begin{equation} \label{equationFISJFISCJICJIWIJ23235215413}
            \#(S_1) \leq 20 d^2 N K^{n-1} \varepsilon^{-1} \varepsilon_0^{dn - \alpha}
        \end{equation}

        \item For $i \in \{ 2, \dots, d \}$, let $S_i$ be the set of indices $k_1 \in \{ 1, \dots, K \}$ with the property that we can find $k_i \in \{ 1, \dots, N \}$ and distinct indices $k_1, \dots, \widehat{k_i}, \dots, k_n \in \{ 1, \dots, K \}$ such that if $z = (x_{k_1}, \dots, x_{k_{i-1}}, z_k, x_{k_{i+1}}, \dots, x_{k_n})$, then $d(z,W) \leq \varepsilon_0$. Then
        %
        \begin{equation} \label{equationADIOJWIODJW2324S}
            \#(S_i) \leq 20 d^2 N K^{n-1} \varepsilon^{-1} \varepsilon_0^{dn - \alpha}.
        \end{equation}
    \end{itemize}
    %
    We then set $S = S_0 \cup S_1 \cup \dots \cup S_d$. Since $\varepsilon_0 \leq K^{-1/\beta}$, \eqref{equationGGSC99124}, \eqref{equationFISJFISCJICJIWIJ23235215413}, and \eqref{equationADIOJWIODJW2324S} imply that if $K \geq N$, then
    %
    \begin{equation} \label{equationDIJIOJIOJ}
        \#(S) \leq (20d^3/\varepsilon) \cdot K^{1/2}.
    \end{equation}
    %
    In particular, \eqref{equationGGGISCI11242} and \eqref{equationDIJIOJIOJ} imply that if
    %
    \[ D_1(x) = \sum_{k \not \in S} \delta(x - x_k), \]
    %
    then for each $|\xi| \leq K^{1/\beta + 1}$,
    %
    \begin{equation} \label{equationGGSCSIAXAXXXSFGG}
        |\widehat{D_1}(\xi)| \leq (C+20 d^3/\varepsilon) K^{-1/2} \log(K).
    \end{equation}
    %
    Since $\varepsilon_0 \geq (1/10) K^{-1/\beta}$, we can apply Lemmas \ref{LemmaTTSICICS} and \ref{Lemma65493} in conjunction with \eqref{equationGGSCSIAXAXXXSFGG}, which means we find that there is $K_0$ depending on $C$, $\varepsilon$, $d$, and $\varepsilon_1$, such that if $K \geq K_0$ and
    %
    \[ \mu(x) = \left( \sum_{k \not \in S} \phi_{(d^{-1/2}/2) \varepsilon_0}(x - x_k) \right) \mu_0(x), \]
    %
    then
    %
    \begin{equation} \label{equationvVVV323285853S}
        \| \mu - \mu_0 \|_{M(\beta,\varepsilon_1)} \leq \varepsilon.
    \end{equation}
    %
    Thus $\mu$ and $\mu_0$ are sufficiently close for suitably large $K$.

    Suppose that $y_1, \dots, y_n \in \text{supp}(\mu)$, with $|y_i - y_j| \geq \varepsilon_0$ for $i \neq j$. By definition of $\mu$, we can therefore find distinct $x_{k_1}, \dots, x_{k_n}$ such that for each $i$,
    %
    \begin{equation} \label{equationFFISICSIC223}
        |x_{k_i} - y_i| \leq (d^{-1/2}/2) \varepsilon_0.
    \end{equation}
    %
    If we set $x = (x_{k_1}, \dots, x_{k_n})$ and $y = (y_1, \dots, y_n)$, then \eqref{equationFFISICSIC223} implies
    %
    \begin{equation} \label{equationFISICISCI232222452}
        |x - y| \leq (\varepsilon_0/2).
    \end{equation}
    %
    Since $i_1 \not \in S_0$, $d(x,W) \geq \varepsilon_0$, which combined with \eqref{equationFISICISCI232222452} implies
    %
    \begin{equation} \label{equationSICSICI}
        d(y,W) \geq d(x,W) - |x - y| \geq \varepsilon_0/2.
    \end{equation}
    %
    Thus in particular we conclude $y \not \in W$. Similarily, if $i \in \{ 1, \dots, d \}$, $k \in \{ 1, \dots, N \}$ and we consider $y_1, \dots, \widehat{y_i}, \dots, y_n \in \text{supp}(\mu)$ with $|y_i - y_j| \geq \varepsilon_0$ for $i \neq j$, then we can find distinct $x_{k_1}, \dots, \widehat{x_{k_i}}, \dots, x_{k_n}$ such that for each $i$,
    %
    \begin{equation} \label{equationFJICJISJC435236523}
        |x_{k_i} - y_i| \leq (d^{-1/2}/2) \varepsilon_0.
    \end{equation}
    %
    If $x = (x_{k_1}, \dots, x_{k_{i-1}}, z_k, x_{k_{i+1}}, \dots, x_{k_n})$ and $y = (y_{k_1}, \dots, y_{k_{i-1}}, z_k, y_{k_{i+1}}, \dots, y_{k_n})$, then \eqref{equationFJICJISJC435236523} implies that
    %
    \begin{equation} \label{equationFIOFJIOVJOIVJ3241523}
        |x - y| \leq (\varepsilon_0/2).
    \end{equation}
    %
    But since we know $x_1 \not \in S_i$ for $i > 1$, and $x_2 \not \in S_i$ for $i = 1$, we know $d(x,W) \geq \varepsilon_0$, which together with \eqref{equationFIOFJIOVJOIVJ3241523} implies that
    %
    \begin{equation} \label{equationZSIDOSIDJOI}
        d(y,W) \geq d(x,W) - |x - y| \geq \varepsilon_0/2.
    \end{equation}
    %
    Thus $y \not \in W$. All this argument goes to show is that if we set $E = \text{supp}(\mu) \cup \{ z_1, \dots, z_N \})$, then $(E,\mu) \in B(W,s)$. But $d_H(E,E_0) \leq \varepsilon$, which combined with \eqref{equationvVVV323285853S} completes our argument.
\end{proof}

\begin{thebibliography}{9}

\bibitem{Korner1}
    T.W. K\"{o}rner,
    \textit{Measures on Independent Sets, A Quantitative Version of Rudin's Theorem}.

\bibitem{Korner2}
    T.W. K\"{o}rner,
    \textit{Fourier Transforms of Measures and Algebraic Relations on Their Supports}.

\bibitem{OurPaper}
    Jacob Denson, Malabika Pramanik, Joshua Zahl,
    \textit{Large Sets Avoiding Rough Patterns}.

\bibitem{myThesis}
    Jacob Denson,
    \textit{Cartesian Products Avoiding Patterns}.

\bibitem{Vershynin}
    Roman Vershynin,
    \textit{High Dimensional Probability},
    Cambridge Series in Statistical and Probabilistic Mathematics,
    2018.

\end{thebibliography}

\end{document}