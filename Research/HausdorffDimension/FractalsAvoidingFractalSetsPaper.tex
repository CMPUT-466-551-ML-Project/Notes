\documentclass[dvipsnames,letterpaper,12pt]{article}

\usepackage[margin = 1.0in]{geometry}
\usepackage{amsmath,amssymb,graphicx,mathabx,accents, enumitem}

\setlist[enumerate]{label*={\normalfont(\Alph*)},ref=(\Alph*)}

\numberwithin{equation}{section}

\usepackage{tikz, tkz-berge, tkz-graph}
\usetikzlibrary{patterns,arrows,decorations.pathreplacing}

\usepackage{color,xcolor}
\definecolor{crimsonred}{RGB}{132,22,23}
\definecolor{darkblue}{RGB}{72,61,139}

\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem*{example}{Example}
\newtheorem*{remark}{Remark}

\DeclareMathOperator{\minkdim}{\dim_{\mathbf{M}}}
\DeclareMathOperator{\hausdim}{\dim_{\mathbf{H}}}
\DeclareMathOperator{\lowminkdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\upminkdim}{\overline{\dim}_{\mathbf{M}}}

\DeclareMathOperator{\lhdim}{\underline{\dim}_{\mathbf{M}}}
\DeclareMathOperator{\lmbdim}{\underline{\dim}_{\mathbf{MB}}}

\DeclareMathOperator{\RR}{\mathbf{R}}
\DeclareMathOperator{\ZZ}{\mathbf{Z}}
\DeclareMathOperator{\QQ}{\mathbf{Q}}
\DeclareMathOperator{\Prob}{\mathbf{P}}
\DeclareMathOperator{\Expect}{\mathbf{E}}

\DeclareMathOperator{\B}{\mathcal{B}}









\title{Large Sets Avoiding Rough Patterns}
\author{Jacob Denson\thanks{University of British Columbia, Vancouver BC, \{denson, malabika, jzahl\}@math.ubc.ca.} \and Malabika Pramanik\footnotemark[1] \and Joshua Zahl\footnotemark[1]}

\begin{document}

\maketitle

\begin{abstract}
	The pattern avoidance problem seeks to construct a set $X\subset \RR^d$ with large dimension that avoids a prescribed pattern such as three term arithmetic progressions, or more general patterns such as avoiding points $x_1, \dots, x_n$ such that $f(x_1, \dots, x_n) = 0$ (three term arithmetic progressions are specified by the pattern $x_1 - 2x_2 + x_3 = 0$). Previous work on the subject has considered patterns described by polynomials, or by functions $f$ satisfying certain regularity conditions. We consider the case of `rough patterns.
	% DISCUSS: SHOULD WE INCLUDE THE FACT THAT WE USE HAUSDORFF DIMENSION?
	There are several problems that fit into the framework of rough pattern avoidance. As a first application, if $Y \subset [0,1]$ is a set with Minkowski dimension $\alpha$, we construct a set $X \subset [0,1]$ with Hausdorff dimension $1-\alpha$ so that $X+X$ is disjoint from $Y$. As a second application, given a set $Y$ of dimension close to one, we can construct a subset $X \subset Y$ of dimension $1/2$ that avoids isosceles triangles. [{\bf{TODO:}} I'd like to replace this with a rectifiability statement]
\end{abstract}









% DISCUSS: Typography: You shouldn't use \ell unless you have script characters for r and s, i.e. scripts for other lengths.

% DISCUSS: Typography: It's bad style to use Math Bolded font and Math blackboard font simultaneously in a paper. We need to decide whether we want to use one or the other, and stick with it.

% DISCUSS: Why discuss additive combinatorics if we are publishing an article in a harmonic analysis journal, and it is never used or mentioned again?

% DISCUSS: The geometry in Maga's theorem is more easy to understand than Keleti's theorem. Easing the reader into the problem is more important than assigning credit?

A major question in modern geometric measure theory is whether sets with sufficiently large Hausdorff dimension necessarily contain copies of certain patterns. For example, the main result of \cite{Maga} constructs a set $X \subset \RR^2$ with full Hausdorff dimension such that no four points in $X$ form the vertices of a parallelogram. On the other hand, Theorem 6.8 of \cite{Matilla} shows that each set $X \subset \RR^d$ with Hausdorff dimension exceeding one must contain three colinear points. There is currently no comprehensive theorem  for these types of problems, and the threshold dimension at which patterns are guaranteed can vary for different patterns, or not even exist at all. In this paper, we provide lower bounds for the threshold by solving the pattern avoidance problem; constructing sets with large dimension avoiding patterns.

One natural way to approach the pattern avoidance problem is to find general methods for constructing pattern avoiding sets by exploiting a particular geometric feature of the pattern. In \cite{Mathe}, M\'{a}th\'{e} shows that, given a pattern specified by a countable union of rational coefficient bounded degree polynomials $f_1, f_2, \dots$ in $nd$ variables, one can construct a set $X \subset \RR^d$ such that for every collection of distinct points $x_1, \dots, x_n$, and each index $k$, $f_k(x_1, \dots, x_n) \neq 0$. In \cite{MalabikaRob}, Fraser and the second author consider a related problem where the polynomials $f_k$ are replaced with full rank $C^1$ functions.

% DISCUSS: Why discuss the intersection with equal points if this isn't part of the problem statement. If you feel this is a useful perspective, move this to the discussion in Section 6.

% DISCUSS: SAY "WE SAY THIS AVOIDS THIS PATTERN IF..."

Rather than avoiding the zeroes of a function, in this paper, we fix $Z \subset \RR^{dn}$, and construct sets $X$ such that for any distinct $x_1, \dots, x_n \in X$, $(x_1, \dots, x_n) \not \in Z$. We then say $X$ avoids the pattern specified by $Z$. For instance, if $Z = \{ (x_1,x_2,x_3) \in (\RR^d)^3 : (x_1,x_2,x_3)\ \text{are colinear} \}$, then $X \subset \RR^d$ avoids the pattern specified by $Z$ precisely when $X$ does not contain three colinear points. Our problem generalizes the problem statements considered in \cite{Mathe} and \cite{MalabikaRob} if we set $Z = \bigcup_{k = 1}^\infty f_k^{-1}(0)$. From this perspective, M\'{a}th\'{e} constructs sets avoiding a set $Z$ formed from a countable union of algebraic varieties, while Fraser and the second author construct sets avoiding a set $Z$ formed from the countable union of $C^1$ manifolds.

The advantage of the formulation of pattern avoidance we consider is that it is now natural to consider `rough' sets $Z \subset \RR^{dn}$ which are not naturally specified as the zero set of a function. In particular, in this paper we consider $Z$ formed from the countable union of sets, each with lower Minkowski dimension bounded above by some $\alpha$. In contrast with previous work, no further assumptions are made on $Z$. The dimension of the avoiding set $X$ we will eventually construct depends only on the codimension $nd - \alpha$ of the set $Z$, and the number of variables $n$.

\begin{theorem}\label{mainTheorem}
	Let $Z$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$, with $d \leq \alpha < dn$. Then there exists a set $X \subset [0,1)^d$ with Hausdorff dimension at least $(nd - \alpha)/(n-1)$ such that whenever $x_1, \dots, x_n \in X$ are distinct, then $(x_1, \dots, x_n) \not \in Z$.
\end{theorem}

\begin{remark}
	When $\alpha < d$, the pattern avoidance problem is trivial, since $X = [0,1)^d - \pi(Z)$ is full dimensional and solves the pattern avoidance problem, where $\pi \colon \RR^{dn} \to \RR^d$ is the projection map onto the first coordinate. The case $\alpha = dn$ is trivial as well, since we can set $X = \emptyset$.

	%And given only a lower Minkowski dimension bound on the sets which form $Z$, we cannot do any better than a zero dimensional set since it is possible for $Z$ to be $\RR^{dn}$, in which case solutions to the pattern avoidance problem can consist of at most $n-1$ points.
\end{remark}

% DISCUSS: Without mentioning why this result can only be developed because our method can be applied to very rough sets, the application doesn't seem exciting at all.

When $Z$ is a countable union of smooth manifolds, Theorem \ref{mainTheorem} generalizes Theorem 1.1 and 1.2 from \cite{MalabikaRob}. Section \ref{futureWorkSection} is devoted to a comparison of our methods with \cite{MalabikaRob}, as well as other general pattern avoidance methods. But our result is more interesting when it can be applied to truly `rough' sets. One surprising application to our method is obtained by considering a `rough' set $Y$ in addition to a set $Z$, and finding a set $X \subset Y$ of large dimension avoiding $Z$. Previous methods in the literature fundamentally exploit the ability to select points on the entirety of Euclidean space, and so it remains unlikely that we can obtain any result of this form using their methods, unless $Y$ is suitably flat, i.e. a smooth surface. To contrast this, our result even applies for certain sets $Y$ which are of Cantor type. We discuss applications of our result in Section 5.

% DISCUSS: Our method isn't randomized.

Theorem \ref{mainTheorem} is proved using a Cantor-type construction, a common theme in the surrounding literature, described explicitly in Section \ref{discretizationsection}. For a sequence of decreasing lengths $\{ l_n \}$ with $l_n \to 0$, the construction specifies a selection mechanism for a nested family of sets $X_n \to X$, with $X_n$ a union of sidelength $l_n$ cubes and avoiding $Z$ at scales close to $l_n$. Our {\it key} contribution to this process is using the probabilistic method to guarantee the existence of efficient selections at each scale, described in Section 2. This selection also assigns mass uniformly on intermediate scales, akin to \cite{MalabikaRob}, ensuring that the selection procedure at a single scale is the sole reason for the Hausdorff dimension we calculate in Section 4. Furthermore, the randomization allows us to avoid the complicated queueing techniques in \cite{KeletiDimOneSet} and \cite{MalabikaRob}, which has the additional benefit that we can confront the entire behaviour of $Z$ at scales close to $l_n$ simultaneously during the $n$th step of the construction.










\section{Frequently Used Notation and Terminology}\label{notationSection}

Our argument heavily depends upon discretizing sets into unions of cubes. Throughout our argument, we use the following notation:

% DISCUSS: DOES THE SECTION PARTITIONING HELP?

\begin{enumerate}%[label=\Alph*]
	\item A {\it dyadic scale} is a length $l$ equal to $2^{-k}$ for some non-negative integer $k$.

	\item Given a length $l > 0$, we let $\B^d_l$  denote the family of all half open cubes in $\RR^d$ with sidelength $l$ and corners on the lattice $(l \cdot \ZZ)^d$. That is,
	%
	\[ \B^d_l = \{ [a_1, a_1 + l] \times \cdots \times [a_d, a_d+l] : a_k \in l \cdot \ZZ \}. \]
	%
	If $E \subset \RR^d$, $\B^d_l(E)$ is the family of cubes in $\B^d_l$ intersecting $E$, i.e.
	%
	\[ \B^d_l(E) = \{ I \in \B^d_l: I \cap E = \emptyset \}. \]

	\item The {\it lower Minkowski dimension} of a compact set $Z \subset \RR^d$ are defined as
	%
%	\begin{equation} \label{minkdimdef}
\[		\lowminkdim(Z) = \liminf_{l \to 0} \frac{\log(\# \B^d_l(Z))}{\log(1/l)}. \]
%	\end{equation}

	\item If $0\leq\alpha\leq d$ and $\delta>0$, we define the dyadic Hausdorff content of a set $E\subset\RR^d$ as 
		%
	\[ H^\alpha_\delta(E) = \inf \left\{ \sum_{k = 1}^m l_k^\alpha : E \subset \bigcup_{k = 1}^m I_k\ \text{and}\ I_k \in \B^d_{l_k}, l_k \leq \delta\ \text{for all $k$} \right\}. \]
	%


	The $\alpha$ dimensional dyadic Hausdorff measure $H^\alpha$ on $\RR^d$ is $H^\alpha(E) = \lim_{\delta \to 0} H_\delta^\alpha(E)$. 
	The {\it Hausdorff dimension} of a set $E$ is $\hausdim(E) = \inf \{ \alpha \geq 0 : H^\alpha(E) = 0 \}$.
% \end{enumerate}

% In Section 2, we solve a discrete version of Theorem \ref{mainTheorem}. Non-diagonal cubes will play an important role in this process. 

% \begin{enumerate}
	\item \label{stronglyNonDiagonalDef}Given $I \in \B^{dn}_l$, we can decompose $I$ as $I_1 \times \cdots \times I_n$ for unique cubes $I_1, \dots, I_n \in \B_l^d$. We say $I$ is {\it strongly non-diagonal} if the cubes $I_1, \dots, I_n$ are distinct. Strongly non-diagonal cubes will play an important role in Section \ref{discretesection}, when we solve a discrete version of Theorem \ref{mainTheorem}. 
% \end{enumerate}

% In Section 3, we discretize the set $Z$ in the hypothesis of Theorem \ref{mainTheorem} into a union of boxes. Our argument is aided by the following definitions:

% \begin{enumerate}
	\item\label{strongCoverDefn} Adopting the terminology of \cite{KatzTao}, we say a collection of sets $U_1, \dots, U_n$ is a {\it strong cover} of a set $E$ if $E \subset \limsup U_k$, which means every element of $E$ is contained in infinitely many of the sets $U_k$. This idea will be useful in Section \ref{discretizationsection}.  
% \end{enumerate}

% Once $X$ has been constructed, in Section 4 we show it has the Hausdorff dimension required by Theorem \ref{mainTheorem}. Here we use a Frostman's lemma type approach.

% \begin{enumerate}
	\item\label{frostmanItem} A {\it Frostman measure} of dimension $\alpha$ is a non-zero compactly supported probability measure $\mu$ on $\RR^d$ such that for every cube $I$ of sidelength $l$, $\mu(I) \lesssim l^\alpha$.
%	\begin{equation}\label{muICondition}
%	\mu(I) \lesssim l^\alpha.
%	\end{equation}
	Note that a measure $\mu$ satisfies this inequality for every cube $I$ if and only if it satisfies the inequality for cubes whose sidelengths are dyadic scales.  

	 {\it Frostman's lemma} says that
	%
	\[ \hausdim(E) = \sup \left\{ \alpha: \begin{array}{c} \text{there is an}\ \alpha\ \text{dimensional Frostman}\\
	\text{measure supported on $E$} \end{array} \right\}. \]
\end{enumerate}









\section{Avoidance at Discrete Scales}\label{discretesection}

% DISCUSS: Z_s doesn't cover Z, just a segment of it.

In this section we describe a method for avoiding $Z$ at a single scale. This will be applied in Section \ref{discretizationsection} at many scales to construct a set $X$ avoiding $Z$ at all scales. The single scale technique is the core part of our construction, and the efficiency with which we can avoid $Z$ at a single scale has direct consequences on the Hausdorff dimension of the set $X$ that we construct.

At a single scale, we solve a discretized version of the problem, where all sets are unions of cubes at two dyadic scales $l \geq s$. In the discrete setting, $Z$ is replaced by a union of cubes in $\B^{dn}_s$, denoted by $Z_s$. Given a set $E$, which is a union of cubes in $\B_l^d$, our goal is to construct a union of cubes in $\B_s^d(E)$, denoted $F$, such that $F^n$ is disjoint from the strongly non-diagonal cubes of $Z_s$ (see Definition \ref{stronglyNonDiagonalDef}).

In order to ensure the final set $X$ obtained in Theorem \ref{mainTheorem} has large Hausdorff dimension regardless of the rapid decay of scales used in the construction of $X$, it is crucial that $F$ is spread uniformly over $E$. We achieve this by decomposing $E$ into sub-cubes in $\B_r^d$ for some intermediate scale $r \in (s,l)$, and distributing $F$ evenly among as many of these intermediate sub-cubes as possible. The following lemma shows this is possible provided we have an upper bound on the volume of $Z_s$.

% DISCUSS: Sure we can assume that r^{dn} (# B_r^d(E)) > |Z_s|, but we never actually use this in our proof, so this seems an inappropriate use of this grammar.

\begin{lemma} \label{discretelemma}
	Fix three dyadic scales $l \geq r \geq s$. Let $E$ be a union of cubes in $\B^d_l$, and let $Z_s$ be a union of cubes in $\B^d_s$ such that
	%
	\begin{equation}\label{discretelemmahypothesis}
		|Z_s| \leq l^d r^{d(n-1)}/2.
	\end{equation}
	%
	Then there exists a set $F \subset E$, which is a union of cubes in $\B^d_s$, satisfying the following three properties:
	%
	\begin{enumerate}
		\item\label{avoidanceItem} \emph{Avoidance}: For any distinct $J_1, \dots, J_n \in \B^d_s(F)$, $J_1 \times \dots \times J_n \not \in \B_s^{dn}(Z_s)$.
		\item\label{nonConcentrationItem} \emph{Non-Concentration}: For any $I \in \B_r^d(E)$, there is at most one $J \in \B_s^d(F)$ with $J \subset I$.
		\item\label{largeSizeItem} \emph{Large Size}: For any $I \in \B^d_l(E)$, $\# \B^d_s(F \cap I) \geq \# \B^d_r(I) / 2 = (l/r)^d / 2$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	For each $I \in B_r^d(E)$, let $J_I$ be a random element of $\B^d_s(I)$ chosen independently with uniform probability. Define a random set
	%
	\begin{equation} \label{Udefinition}
		U = \bigcup \{ J_I : I \in \B^d_s(I) \}.
	\end{equation}
	%
	By construction, for any $I \in B^d_s(I)$, $U$ contains exactly one subcube $J \in \B_s^d$ with $J \subset I$, so $U$ satisfies Property \ref{nonConcentrationItem}. Our construction also implies $\# \B_s^d(U \cap I) = \# \B_r^d(I)$ for any $I$, 
	% DISCUSS: WHY MAKE THE READER HAVE TO THINK HERE? THE THIRD EQUALITY WOULD HELP?
	so $U$ satisfies Property \ref{largeSizeItem}. Unfortunately, $U$ might not satisfy Property \ref{avoidanceItem}. %We will address this problem next. %We will show that with non-zero probability, we can remove at most $|Z_s| r^{-dn}$ cubes from $U$ to obtain Property \ref{avoidanceItem}, so that Property \ref{nonConcentrationItem} and \ref{largeSizeItem} remain to be true.
	% DISCUSS: OF COURSE WE'LL ADRESS THIS QUESTION NEXT, THE PROOF IS SO TINY?

	For each cube $J \in \B_s^d(E)$, there is a unique `parent' cube $I \in \B_r^d(E)$ such that $J \subset I$. Since $I$ contains $(r/s)^d$ elements of $\B^d_s(E)$, and $J_I$ is chosen uniformly at random, we find
	%
	\begin{equation} \label{singleCubeProb}
		\Prob(J \subset U) = \Prob(J_I = J) = (s/r)^d.
	\end{equation}
	%
	Here the probability measure $\Prob(\cdot)$ is taken with respect to the randomly chosen set $U$ defined in \eqref{Udefinition}. Since the cubes $J_I$ are chosen independantly, if $J_1, \dots, J_k$ are distinct cubes in $\B^d_s(E)$, then \eqref{singleCubeProb} combined with Property \ref{nonConcentrationItem} shows
	%
	\begin{equation}\label{jointprob}
		\Prob(J_1, \dots, J_k \in U) = \begin{cases} (s/r)^{dk} &: \text{if $J_1, \dots, J_k$ have distinct parents} \\ 0 &: \text{otherwise} \end{cases}.
	\end{equation}
	%
	Let $K = J_1 \times \dots \times J_n \in \B^{dn}_s(Z_s)$ be a strongly non-diagonal cube. Since the cubes $J_1, \dots, J_n$ are distinct, we can apply \eqref{jointprob} to conclude
	%
	\begin{equation}\label{probaKSubsetUn}
		\Prob(K \subset U^n) = \Prob(J_1, \dots, J_k \in U) \leq (s/r)^{dn}.
	\end{equation}
	%
	Define a random collection of cubes
	%
%	\begin{equation}\label{KUDef}
	\[
		\mathcal{K}(U)=\{ K \in \B_s^{dn}(Z_s) \colon U\in U^n,\ K\ \textrm{strongly non-diagonal}  \}.
	\]
%	\end{equation}
	%
	By \eqref{probaKSubsetUn} and linearity of expectation,
	%
	\begin{equation}\label{expectedNumberOfCubes}
		\Expect(\# \mathcal{K}(U)) = \sum_K \Prob(K \subset U^n) \leq \# \B_s^{dn}(Z_s) \cdot (s/r)^{dn} = |Z_s| r^{-dn},
	\end{equation}
	%
	where $K$ ranges over strongly non-diagonal cubes in $\B^{dn}_s(Z_s)$. In particular, \eqref{expectedNumberOfCubes} implies that there exists at least one (non-random) set $U_0$ such that
	%
	\begin{equation}\label{KU0Small}
		\# \mathcal{K}(U_0) \leq \Expect(\# \mathcal{K}(U)) \leq |Z_s| r^{-dn} \leq (l/r)^d/2.
	\end{equation}
	%
	In the last inequality, we applied the assumption that $|Z_s| \leq l^d r^{d(n-1)}/2$.

	We define
	%
	\begin{equation}\label{defnOfF}
		F = U_0 - \{ \pi(K)\colon K\in \mathcal{K}(U_0),\ K\ \textrm{strongly non-diagonal} \},
	\end{equation} 
	%
	where $\pi\colon \B_s^{dn}\to \B_s^d$ projects a set $J_1\times\cdots\times J_n \in \B_s^{dn}$ to $J_1 \in \B_s^d$. It now suffices to verify that $F$ satisfies each of the properties required:
	%
	\begin{itemize}
		\item Given any strongly non-diagonal cube $J_1 \times \cdots \times J_n \in \B_s^{dn}(Z_s)$, either $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(U_0^n)$, or $J_1 \times \cdots \times J_n \in \B_s^{dn}(U_0^n)$. If the former occurs then $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(F^n)$ since $F\subset U_0$, while if the latter occurs then $K \in \mathcal{K}(U_0)$, so $J_1 \not \in \B_s^d(F)$. In either case, $J_1 \times \cdots \times J_n \not \in \B_s^{dn}(F^n)$, so $F$ satisfies Property \ref{avoidanceItem}.

		\item Since $F\subset U_0$, and $U_0$ satisfies Property \ref{nonConcentrationItem}, $F$ also satisfies Property \ref{nonConcentrationItem}.

		\item We note that $\B^d_s(U_0) = \B^d_r(E) = \B^d_l(E) (l/r)^d$. Combined with \eqref{KU0Small}, this implies
		%
		\begin{equation} \label{FLowerBound}
		\begin{split}
			\B^d_s(F) = \B^d_s(U_0) - \mathcal{K}(U_0) &\geq \B^d_r(E) - (l/r)^d/2 = \B^d_l(E) (l/r)^d - (l/r)^d/2.
		\end{split}
		\end{equation}
		%
		Let $I_1, \dots, I_N$ enumerate all cubes in $\B^d_l(E)$, so $N = \B^d_l(E)$. Then we know
		%
		\begin{equation} \label{BdFDecomposition}
			\# \B^d_s(F) = \# \B^d_s(F \cap I_1) + \dots + \# \B^d_s(F \cap I_N).
		\end{equation}
		%
		Property \ref{nonConcentrationItem} implies that for any index $i$,
		%
		\begin{equation} \label{maxLocalBound}
			\# \B^d_s(F \cap I_i) \leq \B^d_r(I_i) = (l/r)^d.
		\end{equation}
		%
		If there is an index $i$ for which $\# \B^d_s(F \cap I_i) < (l/r)^d/2$, then \eqref{BdFDecomposition} and \eqref{maxLocalBound} imply
		%
		\begin{align*}
			\# \B^d_s(F) \leq (l/r)^d/2 + (N - 1)(l/r)^d = (l/r)^d(N - 1/2) = (l/r)^d(\B^d_l(E) - 1/2).
		\end{align*}
		%
		Applying \eqref{discretelemmahypothesis}, we continue the calculation, concluding
		%
		\[ \# \B^d_s(F) \leq (l/r)^d \B^d_l(E) - (l/r)^d/2 < (l/r)^d \B^d_l(E) - |Z_s| r^{-dn}. \]
		%
		This contradicts \eqref{FLowerBound}, so for any index $i$, we must have $\# \B^d_s(F \cap I_i) \geq (l/r)^d/2$. Thus the set $F$ satisfies Property \ref{largeSizeItem}. \qedhere
	\end{itemize}
\end{proof}

\begin{remark}
	While the existence of the set $F$ in Lemma \ref{discretelemma} was obtained by probabilistic techniques, we emphasize that it's existence is a purely deterministic statement. One can find a candidate $F$ constructively by checking all of the finitely many possible choice of $U$ to find one particular choice $U_0$ which satisfies $\eqref{KU0Small}$, and then defining $F$ by \eqref{defnOfF}.
	%The advantage of the probabilistic argument is that we are able to find an explicit bound for the minimal cardinality of $\mathcal{K}(U)$. 
	Thus the set we obtain in Theorem \ref{mainTheorem} exists by purely constructive means.
\end{remark}

% DISCUSS: THIS PARAGRAPH IS IMPORTANT, BECAUSE IT SHOWS WHY THE LEMMA IS THE MOST IMPORTANT ASPECT TO OBTAINING THE DIMENSION BOUND.
Our inability to select almost every cube in Lemma \ref{discretelemma} means that repeated applications of the result will lead to a loss in Hausdorff dimension. In fact, in the worst case, applying the lemma causes us to lose as much Hausdorff dimension as is permitted by Theorem 1. To see why, we will later see that if $Z$ is the countable union of sets with lower Minkowski dimension $\alpha$, the scale $s$ discretization $Z_s$ satisfies $|Z_s| \leq s^{dn - \alpha - \varepsilon}$, for some small positive $\varepsilon$ converging to zero as $s \to 0$. In the worst case, however, it is certainly possible that $|Z_s| \geq s^{dn - \alpha}$. In this situation, we can only apply Lemma \ref{discretelemma} if $s^{dn - \alpha} \leq l^d r^{d(n-1)}/2$, which implies $r \geq s^{(dn - \alpha)/d(n-1)}$. If we combine this inequality with Property \ref{nonConcentrationItem} of Lemma \ref{discretelemma}, we conclude
%
%\begin{equation} \label{boxCountingBound}
\[	\frac{\log \# \B^d_s(F)}{\log(1/s)} \leq \frac{\log \# \B^d_r(E)}{\log(1/s)} = \frac{\log |E| r^{-d}}{\log(1/s)} = \frac{d \log(1/r) - \log |E|^{-1}}{\log(1/s)} \leq \frac{dn - \alpha}{n - 1}. \]
%\end{equation}
%
Given a set $F = \bigcap F_k$, where $\{ F_k \}$ are infinitely many sets obtained from an application of Lemma \ref{discretelemma} at a sequence of scales $\{ s_k \}$ with $s_k \to 0$ as $k \to \infty$, then we can show% \eqref{boxCountingBound} shows
%
%\begin{equation} \label{badDimension}
\[	\hausdim(F) \leq \lim_{s_k \to 0} \frac{\log \# \B^d_{s_k}(F_k)}{\log(1/s_k)} \leq \frac{dn - \alpha}{n-1}. \]
%\end{equation}
%
Comparing this to the Hausdorff dimension of the set $X$ obtained in Theorem \ref{mainTheorem}, we see that we must be very careful to ensure applications of the discrete lemma are the only place in our proof where dimension is lost.

\begin{remark}
	Lemma \ref{discretelemma} is the core of our avoidance technique. The remaining argument is fairly modular. If, for a special case of $Z$, one can improve Lemma \ref{discretelemma} using a different proof technique so that a better bound can be placed on the number of cubes discarded, then the remaining parts of our paper can be applied near verbatim to yield a set $X$ with larger Hausdorff dimension to Theorem \ref{mainTheorem}. The dimension this new technique yields can then be found by an analogous calculation to the last pragraph.
\end{remark}










\section{Fractal Discretization}\label{discretizationsection}
In this section we will construct the set $X$ by applying Lemma \ref{discretelemma} at many scales. Since $Z$ is a countable union of compact sets with Minkowski dimension at most $\alpha$, there exists a strong cover (see Definition \ref{strongCoverDefn}) of $Z$ by cubes restricted to a sequence of dyadic scales $\{ l_k \}$. We will select this strong cover so that the scales $l_k$ converge to 0 very quickly.

\begin{lemma} \label{coveringlemma}
	Let $Z \subset \RR^{dn}$ be a countable union of compact sets, each with lower Minkowski dimension at most $\alpha$. Let $\{ \varepsilon_k \}$ be a sequence of positive numbers and let $\{ f_k \}$ be a sequence of functions from $(0,\infty)$ to $(0,\infty)$. Then there exists a sequence of dyadic lengths $\{ l_k \}$ and compact sets $\{ Z_k \}$ such that
	%
	\begin{enumerate}
		\item For each index $k \geq 2$, $l_k \leq f_{k-1}(l_{k-1})$.
		\item For each index $k$, $Z_k$ is a union of cubes in $\B^{dn}_{l_k}$.
		\item $Z$ is strongly covered by the sets $\{ Z_k \}$.
		\item For each index $k$, $\# \B^{dn}_{l_k}(Z_k) \leq 1/l_k^{\alpha + \varepsilon_k}$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	Let $Z$ be the union of sets $\{ Y_k \}$ with $\lowminkdim(Y_k) \leq \alpha$ for any $k$. Let $m_1, m_2, \dots$ be a sequence of integers that repeats each integer infinitely often. For each positive integer $k$, since $\lowminkdim(Y_{m_k}) \leq \alpha$, definition (C) implies that there exists arbitrarily small lengths $l$ which satisfy $\# \B_l^{dn}(Y_{m_k}) \leq 1/l^{\alpha + (\varepsilon_k/2)}$. Replacing $l$ with a dyadic scale at most twice the size of $l$, there are infinitely many {\it dyadic} scales $l$ with
	%
	\begin{equation} \label{minkdimimplication}
		\# \B^{dn}_l(Y_{m_k}) \leq \frac{1}{(l/2)^{\alpha + \varepsilon_k}} \leq \frac{2^{dn}}{l^{\alpha + (\varepsilon_k/2)}} = \frac{\left( 2^{dn} l^{\varepsilon_k/2} \right)}{l^{\alpha + \varepsilon_k}}.
	\end{equation}
	%
	In particular, we may select a dyadic length $l$ such that $2^{dn} l^{\varepsilon_k/2} \leq 1$, and, if $k \geq 2$, also satisfying $l \leq f_{k-1}(l_{k-1})$. The first constraint together with \eqref{minkdimimplication} implies $\# \B^{dn}_l(Y_{m_k}) \leq 1/l^{\alpha + \varepsilon_k}$. We then set $l_k = l$, and define $Z_k$ to be the union of all cubes in $\B_{l_k}^{dn}(Y_{m_k})$.
\end{proof}

We now construct $X$ by avoiding the various discretizations of $Z$ at each scale. The aim is to find a nested decreasing family of discretized sets $\{ X_k \}$ with $X = \bigcap X_k$. One condition guaranteeing that $X$ avoids $Z$ is that $X_k^n$ is disjoint from {\it strongly non-diagonal} cubes in $Z_k$.

\begin{lemma} \label{stronglydiagonal}
	Let $Z \subset \RR^{dn}$ and let $\{ l_k \}$ be a sequence of lengths converging to zero. For each index $k$, let $Z_k$ be a union of cubes in $\B^{dn}_{l_k}$, and suppose the sets $\{ Z_k \}$ strongly cover $Z$. For each index $k$, let $X_k$ be a union of cubes in $\B^d_{l_k}$. Suppose that for any $k$, $X_k^n$ avoids strongly non-diagonal cubes in $Z_k$. If $X = \bigcap X_k$, then $(x_1, \dots, x_n) \not \in Z$ for any distinct $x_1, \dots, x_n \in X$.
\end{lemma}
\begin{proof}
	Let $z \in Z$ be a point with distinct coordinates $z_1, \dots, z_n$. Set
	%
	\[ \Delta = \{ (w_1, \dots, w_n) \in \RR^{dn}: \text{there exists $i \neq j$ such that $w_i = w_j$} \}. \]
	%
	Then $d(\Delta,z) > 0$, where $d$ is the Hausdorff distance between $\Delta$ and $z$. Since $\{ Z_k \}$ strongly covers $Z$, there is a subsequence $\{ k_m \}$ such that $z \in Z_{k_m}$ for any index $m$. For suitably large $m$, the sidelength $l_k$ cube $I$ in $Z_{k_m}$ containing $z$ is disjoint from $\Delta$. But this means $I$ is strongly non-diagonal, and so $z \not \in X_{k_m}^n$. In particular, $z$ is not an element of $X^n$.
\end{proof}

% DISCUSS: Technically we are proving Theorem 1 for the whole paper, and we don't finish the proof here?

We are now ready to construct the set $X$ in Theorem \ref{mainTheorem}. Let $l_0 = 1$ and $X_0 = [0,1)^d$. For each $k \geq 1$, define $\varepsilon_k = c/k$, where we view $c = (dn - \alpha)/4$ as a irrelevant constant small enough that $dn - \alpha - 2\varepsilon_k > 0$ for any $k$. We set
%
\begin{equation}\label{defnFK}
	f_k(x) = \min \left( (x^d/2)^{1/\varepsilon_{k+1}}, x^{k^2} \right).
%	f_k(x)=\min \left( x^{k^2}, (x^d4^{-k-1})^{\frac{1}{\varepsilon_{k+1}d(n-1)}} \right).
\end{equation}
%
Apply Lemma \ref{coveringlemma} to $Z$ with this choice of $\{\varepsilon_k\}$ and $\{f_k\}$; let $\{l_k\}$ be the resulting sequence of length scales and let $\{Z_k\}$ be the resulting strong cover of $Z$. Observe that \eqref{defnFK} implies that for any index $k$,
%
\begin{equation} \label{boundOnLk}
	l_{k+1}^{\varepsilon_{k+1}} \leq l_k^d/2 \quad \text{and} \quad l_{k+1} \leq l_k^{k^2}.
\end{equation}
%
For each index $k \geq 1$, define $l = l_k$, $s = l_{k+1}$, and $r = l_{k+1}^{(dn - \alpha - 2\varepsilon_{k+1})/d(n-1)}$. Observe that $X_k$ is a non-empty union of cubes in $\B^d_l$; that $Z_{k+1}$ is a union of cubes in $\B^{dn}_s$; and that
%
\[ |Z_{k+1}| \leq s^{dn - \alpha - \varepsilon_{k+1}} = r^{d(n-1)} s^{\varepsilon_{k+1}} \leq l^d r^{d(n-1)}/2. \]
%
Setting $Z_s = Z_{k+1}$, we are therefore justified in applying Lemma \ref{discretelemma} with the choices of $l$, $r$, and $s$ described above, and with $\varepsilon = \varepsilon_{k+1}$. We obtain a set $F \subset X_k$ which is a union of cubes in $\B^d_s(E)$ satisfying Properties \ref{avoidanceItem}, \ref{nonConcentrationItem}, and \ref{largeSizeItem} from the lemma, and we define $X_{k+1} = F$. Property \ref{avoidanceItem} implies $X_{k+1}$ avoids strongly non-diagonal cubes in $Z_{k+1}$, so if we define $X = \bigcap X_k$, then Lemma \ref{stronglydiagonal} implies $(x_1, \dots, x_n) \not \in Z$ for any distinct $x_1, \dots, x_n \in X$.









\section{Dimension Bounds}\label{dimensionsection}

To complete the proof of Theorem \ref{mainTheorem}, we must show that $\dim_{\mathbf{H}}(X) \geq \beta$, where
%
\[ \beta = \frac{dn - \alpha}{n - 1}. \]
%
This section proves this claim. We begin with a rough outline of our proof strategy. Recall that from the previous section, we have a decreasing sequence of lengths $\{ l_k \}$. At the scale $l_k$, $X$ looks like a set with dimension $\beta - O(1/k)$. As $k \to \infty$, $\beta - O(1/k) \to \beta$, so $X$ looks $\beta$ dimensional at the discrete scales. To obtain the complete dimension bound, it then suffices to interpolate to get a $\beta$ dimensional behaviour at all intermediate scales. In this construction, as in \cite{MalabikaRob}, the rapid decay of the lengths $\{ l_k \}$ means interpolating poses a significant difficulty. We avoid this difficulty because of the uniform way that we have selected cubes in consecutive scales. This will imply that between the scales $l_k$ and $r_{k+1}$, $X$ behaves like a full dimensional set.

The most convenient way to examine the dimension of $X$ at various scales is to use Frostman's lemma. We construct a probability measure $\mu$ supported on $X$ such that for all $\varepsilon > 0$, for all lengths $l$, and for all $I \in \B^d_l$, $\mu(I) \lesssim_\varepsilon l^{\beta - \varepsilon}$. For each $\varepsilon > 0$, the measure $\mu$ is a Frostman measure with dimension at least $\beta - \varepsilon$ (see Definition \ref{frostmanItem}). This implies that $\hausdim(X) \geq \beta$. The advantage of this approach is that once a natural choice of $\mu$ is fixed, it is easy to understand the behaviour of $X$ at a scale $l$ by looking at the behaviour of $\mu$ restricted to cubes at the scale $l$.

We define the measure $\mu$ we will use recursively on $\bigcup_{i = 1}^\infty \B^d_{l_i}$. We initially set $\mu [0,1)^d = 1$. Given $I \in \B^d_{l_{k+1}}$, we find a parent cube $I' \in \B^d_{l_k}$ with $I \subset I'$. If $I \subset X_{k+1}$, then we set
%
\[ \mu(I) = \frac{\mu(I')}{\# \B^d_{l_k}(X_{k+1} \cap I)}. \]
%
Otherwise, if $I \not \subset X_{k+1}$, we set $\mu(I) = 0$. Notice
%
\[ \mu(I') = \sum_{I \in \B^d_{l_{k+1}}(X_{k+1})} \frac{\mu(I')}{\# \B^d_{l_{k+1}}(X_{k+1} \cap I')} = \sum_{I \in \B^d_{l_{k+1}}(I')} \mu(I). \]
%
so mass is maintained at each stage of the construction. The mass distribution principle then implies that $\mu$ extends to a measure on the entire Borel sigma algebra.
%
%We construct $\mu$ as an exterior measure by setting
%
%\[ \mu(E) = \inf \left\{ \sum_{i = 1}^\infty p(I_i): E \subset \bigcup_{i = 1}^\infty I_i\ \text{and}\ I_i \subset \bigcup_{j = 1}^\infty \B^d_{l_j}\ \text{for each $i$}  \right\} \]
%
%It is easy to see that $p$ is finitely additive. This means that we have a cover of some set $E$ by some cubes $\{ I_i \}$, then for each $\varepsilon$, we can refine each $I_i$ with sidelength greater than $\varepsilon$ into finitely many smaller cubes with sidelength smaller than $t$, obtaining a cover of $E$ by cubes $\{ J_i \}$, such that the sidelength of each $J_i$ is smaller than $\varepsilon$, and $\sum p(J_i) = \sum p(I_i)$. This can be easily used to show $\mu$ is a metric outer measure, and hence is measurable on all Borel sets. The fact that $\mu(I) \leq p(I)$ for each $I \in \bigcup_{i = 1}^\infty \B^d_{l_i}$ will be very useful for passing from discrete bounds to continuous bounds. Since $p(I) = 0$ for any cube $I$ in $\B^d_{l_i}$ not contained in $X_i$, $\mu$ is supported on $X_k$ for each $k$, and in particular, $\mu$ is supported on $X$. 
The remainder of this section is devoted to showing that $\mu$ is a Frostman measure of dimension $\beta - \varepsilon$ for any $\varepsilon > 0$.

% General principle:
% Let Q_k be all dyadic cubes of sidelength 1/2^k.
% For each mu, define E_k(mu) = sum_{Q in Q_k} mu(Q)/2^k * (Lebesgue measure restricted to Q).
% Then |E_k(\mu)| <= |mu|, so E_k is a continuous operator on finite Borel measures.
% Given mu_1, mu_2, ... in M[0,1] such that E_i(f_j) = f_i, for i < j,
% let mu be a weak * limit of the mu_i.
% The E_i are continuous on weak *, so E_i(mu) = mu_i for all i.

\begin{lemma} \label{mubound}
	If $I \in \B^d_{l_k}$, then
	%
%	\begin{equation}
\[		\mu(I) \leq 2^k \left[ \frac{r_k \dots r_1}{l_{k-1} \dots l_1} \right]^d. \]
%	\end{equation}
\end{lemma}
\begin{proof}
	We prove the theorem inductively on $k$. For $k = 0$, the theorem is obvious, because $\mu(I) \leq 1$. For the purposes of induction, let $I \in \B^d_{l_k}$, together with a parent cube $I' \in \B^d_{l_{k-1}}$ with $I \subset I'$. If $\mu(I) > 0$, $I \subset X_k$, so $I' \subset X_{k-1}$. Because $X_k$ was obtained from $X_{k-1}$ via an application of Lemma 1, Property \ref{largeSizeItem} of that lemma states that $\# \B^d_{l_k}(X_k \cap I) \geq (l_k/r_{k+1})^d/2$, so together with the inductive hypothesis, we conclude
	%
%	\begin{equation} \label{oneStepBound}
\[		\mu(I) = \frac{\mu(I')}{\# \B^d_{l_k}(X_k \cap I)} \leq \frac{2 \mu(I')}{(l_{k-1}/r_k)^d} \leq \frac{2 \cdot 2^{k-1} \left[ \frac{r_{k-1} \dots r_1}{l_{k-2} \dots l_1} \right]^d}{(r_k/l_{k-1})^d} = 2^k \left[ \frac{r_k \dots r_1}{l_{k-1} \dots l_1} \right]^d. \qedhere \]
\end{proof}

Treating all parameters in \eqref{mubound} which depend on indices smaller than $k$ as essentially constant, we `conclude' that $\mu(I) \lesssim r_k^d \lesssim l_k^{\beta - 2d \cdot \varepsilon_{k+1}}$. The bounds in \eqref{boundOnLk} imply $l_k$ decays very rapidly, which enables us to ignore quantities depending on previous indices, and obtain a true inequality.

\begin{corollary}
	There exists $c > 0$ such that for all $I \in \B^d_{l_k}$, $\mu(I) \lesssim l_k^{\beta - c/k}$.
\end{corollary}
\begin{proof}
	Given $\varepsilon > 0$, Lemma \ref{mubound}, the inequality $l_k \leq l_{k-1}^{(k-1)^2}$ from \eqref{boundOnLk}, and the fact that there exists a constant $c_0$ such that $\varepsilon_{k+1} = c_0/k$, we find
	%
	\begin{align*}
		\mu(I) &\leq 2^k \left[ \frac{r_k \dots r_1}{l_{k-1} \dots l_1} \right]^d \leq \left( \frac{2^k}{l_{k-1}^d \dots l_1^d} \right) l_k^{\beta - c_0/k}\\
		&= \left( \frac{2^k l_k^{2d/k}}{l_{k-1}^{d(k-1)}} \right) l_k^{\beta - c_0/k - 2d/k} \leq \left( 2^k l_{k-1}^{(2d/k)(k-1)^2 - d(k-1)} \right) l_k^{\beta - (c_0 + 2d)/k} = o \left(l_k^{\beta - (c_0 + 2d)/k} \right), %\tag*{\qedhere}
	\end{align*}
	%
	so we can then set $c = c_0 + 2d$.
\end{proof}

Corollary 3 gives a clean expression of the $\beta$ dimensional behaviour of $\mu$ at discrete scales. To obtain a Frostman measure bound at {\it all} scales, we need to apply a covering argument. This is where the uniform mass assignment technique comes into play. Because $\mu$ behaves like a full dimensional set between the scales $l_k$ and $r_{k+1}$, we won't be penalized for making the gap between $l_k$ and $r_{k+1}$ arbitrarily large. This is essential to our argument, because $l_k$ decays faster than $2^{-k^m}$ for any $m > 0$.

\begin{lemma} \label{frostmanBound}
	If $l$ is dyadic and $I \in \B_l^d$, then $\mu(I) \lesssim_k l^{\beta - c/k}$ for each integer $k$.
\end{lemma}
\begin{proof}
	We begin by assuming $l \leq l_k$. To bound $\mu(I)$, we apply a covering argument, which breaks into cases depending on the size of $l$ in proportion to the scales $l_k$ and $r_k$:
	%
	\begin{itemize}
		\item If $r_{k+1} \leq l \leq l_k$, we can cover $I$ by $(l/r_{k+1})^d$ cubes in $\B^d_{r_{k+1}}$. Because of Property \ref{nonConcentrationItem} and \ref{largeSizeItem} of Lemma \ref{discretelemma}, we know that the mass of each cube in $\B^d_{r_{k+1}}$ is bounded by at most $2 (r_{k+1}/l_{k+1})^d$ times the mass of a cube in $\B_{l_k}^d$. Thus
		%
		\[ \mu(I) \lesssim (l/r_{k+1})^d (2(r_{k+1}/l_k)^d) l_k^{\beta - c/k} \leq 2l^d/l_k^{d - \beta + c/k} \leq 2l^{\beta - c/k}, \]
		%
		where we used the fact that $d - \beta + c/k \geq 0$, so $l_k^{d - \beta + c/k} \geq l^{d - \beta + c/k}$.

		\item If $l_{k+1} \leq l \leq r_{k+1}$, we can cover $I$ by a single cube in $\B^d_{r_{k+1}}$. Because of Property \ref{nonConcentrationItem} of Lemma \ref{discretelemma}, each cube in $\B^d_{r_{k+1}}$ contains at most one cube of $\B^d_{l_{k+1}}(X_{k+1})$, so
		%
		\[ \mu(I) \lesssim l_{k+1}^{\beta - c/k} \leq l^{\beta - c/k}. \]

		\item If $l \leq l_{k+1}$, there certainly exists $m$ such that $l_{m+1} \leq l \leq l_m$, and one of the previous cases yields that $\mu(I) \lesssim l^{\beta - c/m} \leq l^{\beta - c/k}$.
	\end{itemize}
	%
	If $l \geq l_k$, then $\mu(I) \leq 1 \lesssim_k l_k^{\beta - c/k} \leq l^{\beta - c/k}$, so $\mu(I) \lesssim_k l^{\beta - O(1/k)}$ for arbitrary dyadic $l$.
\end{proof}

Applying Frostman's lemma to Lemma \ref{frostmanBound} gives $\hausdim(X) \geq \beta - c/k$ for each $k > 0$. Taking $k \to \infty$ proves the needed dimension bound. Since we have already shown in Section \ref{discretizationsection} that $(x_1, \dots, x_n) \not \in Z$ for any distinct $x_1, \dots, x_n \in X$, this concludes the proof of Theorem \ref{mainTheorem}.









\section{Applications}\label{applications}

As discussed in the introduction, Theorem 1 generalizes Theorems 1.1 and 1.2 from \cite{MalabikaRob}. In this section, we present two applications of Theorem \ref{mainTheorem} in settings where previous methods cannot obtain any results.

\begin{theorem}[Sum-sets avoiding specified sets]
	Let $Y \subset \RR^d$ be a countable union of sets of Minkowski dimension at most $\alpha$. Then there exists a set $X \subset \RR^d$ with Hausdorff dimension at least $1 - \alpha$ such that $X + X$ is disjoint from $Y$.
\end{theorem}
\begin{proof}
	Define $Z = Z_1 \cup Z_2$, where
	%
	\[ Z_1 = \{ (x,y) : x + y \in Y \} \quad \text{and} \quad Z_2 = \{ (x,y): y \in Y/2 \}. \]
	%
	Since $Y$ is a countable union of sets of Minkowski dimension at most $\alpha$, $Z$ is a countable union of sets with lower Minkowski dimension at most $1 + \alpha$. Applying Theorem \ref{mainTheorem} with $d = 1$, $n = 2$, giving a set $X \subset \RR^d$ with Hausdorff dimension $1 - \alpha$ avoiding $Z$. Since $X$ avoids $Z_1$, whenever $x,y \in X$ are distinct, $x + y \not \in Y$. Since $X$ avoids $Z_2$, $X \cap (Y/2) = \emptyset$, and thus for any $x \in X$, $x + x \not \in Y$. Thus $X + X$ is disjoint from $Y$.
\end{proof}

\begin{remark}
	One weakness of our result is that as the number of variables $n$ increases, the dimension of $X$ tends to zero. If we try and make the $n$-fold sum $X + \cdots + X$ disjoint from $Y$, current techniques only yield a set of dimension $(1 - \alpha)/(n-1)$. We have ideas on how to improve our main result when $Z$ is `flat', in addition to being low dimension, which will enable us to remove the dependence of $\hausdim(X)$ on $n$. In particular, we expect to be able to construct a set $X$ of dimension $1 - \alpha$, such that $X$ is disjoint from $Y$, and $X$ is closed under addition, and multiplication by rational numbers. In particular, given a $\QQ$ subspace $V$ of $\RR^d$ with dimension $\alpha$, we can always find a `complementary' $\QQ$ vector space $W$ with complementary fractional dimension $d - \alpha$ such that $V \cap W = (0)$.
\end{remark}

One of the most interesting uses of our method is to construct subsets of fractals avoiding patterns. In \cite{MalabikaRob}, Fraser and the second author show that if $\gamma$ is a $C^2$ curve with non-vanishing curvature, then there exists a set $E \subset \gamma$ of Hausdorff dimension $1/2$ that does not contain isoceles triangles. Our method can extend this result from the case of curves to more general sets, which gives an example of the flexibility of our method. For simplicity, we stick to an analysis of planar sets.

\begin{theorem}[Restricted sets avoiding isoceles triangles]
	Let $Y \subset \RR^2$ and let $\pi: \RR^2 \to \RR$ be an orthogonal projection such that $\pi(Y)$ has non-empty interior. Let $d$ be an arbitrary metric on $\RR^2$. Suppose that
	%
	\[ Z_0 = \{ (y_1, y_2, y_3) \in Y^3: d(y_1,y_2) = d(y_1,y_3) \} \]
	%
	is the countable union of sets with lower Minkowski dimension at most $\alpha$, for $\varepsilon \geq 0$. Then there exists a set $X \subset Y$ with dimension at least $(3 - \alpha)/2$ so that no triple of points $(x_1, x_2, x_3) \in X^3$ form the vertices of an isoceles triangle.
\end{theorem}
\begin{proof}
	Without loss of generality, by translation and rescaling, assuming $\pi(Y)$ contains $[0,1]$. Form the set
	%
	\[ Z = \pi(Z_0) = \{ (\pi(y_1), \pi(y_2), \pi(y_3)) : y \in Z_0 \} \]
	%
	Then $Z$ is the projection of an $\alpha$ dimensional set, and therefore has dimension at most $\alpha$. Applying Theorem \ref{mainTheorem} with $d = 1$ and $n = 3$, we construct a set $X_0 \subset [0,1]$ with Hausdorff dimension at least $(3 - \alpha)/2$ such that for any distinct $x_1,x_2,x_3 \in X_0$, $(x_1,x_2,x_3) \not \in Z$. Thus if we form a set $X$ by picking, from each $x \in X_0$, a single element of $\pi^{-1}(x)$, then $X$ avoids isoceles triangles, and has Hausdorff dimension at least as large as $X_0$.
\end{proof}

To see that Theorem 3 indeed generalizes the result of Fraser and the second author, observe that if $d$ is the Euclidean metric, then for every pair of points $x,y \in \RR^2$, the set
%
\[ \{ z \in \RR^2: d(x,z) = d(y,z) \} \]
%
is the perpendicular bisector $B_{xy}$ of $x$ and $y$. If $\gamma$ is a compact portion of a smooth curve with non-vanishing curvature, then the number of points in $\gamma \cap B_{xy}$ is bounded independantly of $x$ and $y$. Thus the set $Z_0$ in the statement of Theorem 3 has Minkowski dimension at most 2, and we can find a set with Hausdorff dimension $(3 - 2)/2 = 1/2$ on the curve avoiding isoceles triangles.

Results about slice of measures, such as those detailed in Chapter 6 of \cite{Matilla}, show that for any one dimensional set $Y$, for almost every line $L$, $L \cap Y$ consists of a finite collection of points. This suggests that if $Y$ is any set with fractional dimension one, then $Z_0$ has dimension at most 2. This implies that we can find a subset of $Y$ with dimension $1/2$ avoiding curves. We are unsure if this is true for every set with dimension one, but we provide two examples suggesting this is true for a generic set. The first result shows that for any $\varepsilon > 0$, there is an infinite family of Cantor-type sets with dimension $1 + \varepsilon$ such that $Z_0$ has dimension at most $2 + \varepsilon$. The second shows that for any rectifiable curve, $Z_0$ has dimension at most $2$. Thus Theorem 3 can be applied in settings where $Y$ is incredibly `rough', i.e. totally disconnected.

To study the first example, we consider a probabilistic model for a Cantor-type set which almost surely has the required properties. This model is obtained by considering a nested decreasing family of discretized random sets $\{ C_k \}$, with each $C_k$ a union of sidelength $1/2^k$ squares. First, we fix $p \in [0,1]$. Then we set $C_0 = [0,1]^2$. To construct $C_{k+1}$, we split each sidelength $1/2^k$ cube in $C_k$ into four sidelength $1/2^{k+1}$ squares, and keep each square in $C_{k+1}$ with probability $p$. To study this model, we employ some results about tail bounds and asymptotics for branching processes.

\begin{lemma} \label{randomdimension}
	If $p > 1/4$, then almost surely, either $C = \emptyset$ or $C$ has Minkowski dimension $2 - \log_2(1/p)$. Furthermore, $C \neq \emptyset$ with non-zero probability.
\end{lemma}
\begin{proof}
	Let $p > 1/4$. For each $k$, let $Z_k$ denote the number of sidelength $1/2^k$ cubes in $[0,1]^2$. Then the sequence $\{ Z_k \}$ is a branching process, where each cube can produce between zero and four subcubes, with each of these four cubes kept with probability $p$. Thus $\Expect[Z_{k+1}|Z_k] = (4p) Z_k$. Since $4p > 1$, A simple calculation, summarized in Theorem 8.1 of \cite{Harris}, shows that the process $W_k = Z_k / (4p)^k$ is an $L^2$ bounded martingale, and so there exists a random variable $W$ such that $W_k \to W$ almost surely, and $\mathbf{E}(W|W_k) = W_k$ for all $k$. Whenever $W$ is non-zero,
	%
	\[ \minkdim(C) = \lim_{k \to \infty} \frac{\log Z_k}{k \log 2} = \lim_{k \to \infty} \frac{\log(W_k/W) + \log(W (4p)^k)}{k \log 2} = 2 - \log_2(1/p). \]
	%
	Since $\mathbf{E}(W) = \mathbf{E}(\mathbf{E}(W|W_0)) = \mathbf{E}(W_0) = 1$, $W$ is non-zero with positive probability.
\end{proof}

Similar asymptotics for branching processes show that the set $Z_0$ associated with $C$ as in Theorem 3 almost surely has Minkowski dimension $3 - \alpha$. We do this first by proving a supplementary result.

%We say a stochastic process $\{ Z_k \}$ is a $(p,M)$ {\it sub-branching process}, for $p \geq 0$ and $M > 0$, if there exists a branching process $\{ \tilde{Z_k} \}$ such that $Z_k \leq \tilde{Z}_k$ and $\mathbf{E}(\tilde{Z}_{k+1}|\tilde{Z}_k) = M \tilde{Z}_k$ holds for all $k$, and the branching process has extinction probability $p$. In the following, we assume that the offspring law of any branching process takes only finitely many values, so we have an upper bound on the maximum number of offspring that can be produced in each iteration.

\begin{lemma}\label{branchingtrick}
	Let $\{ Z_k \}$ be a supercritical branching process with extinction probability $q$. If we set $\tilde{M} = q + M$, then there exists small positive constants $\lambda$ and $\varepsilon$, depending only on the offspring law of $\{ Z_k \}$, such that $\Prob(Z_k \geq k \tilde{M}^k) \lesssim \exp \left(-\lambda k^{1 + \varepsilon} \right)$.
\end{lemma}
\begin{proof}
	Let $q_0, q_1, \dots, q_M$ denote the offspring law for the branching process, so $q = q_0$. Then there exists a grid of i.i.d discrete random variables $X_{ij}$ with $\Prob(X_{ij} = k) = q_k$ such that
	%
	\[ Z_{k+1} = \sum_{j = 1}^{Z_k} X_{ij}. \]
	%
	Now consider the branching process $\{ \tilde{Z}_k \}$ defined by setting $\tilde{Z}_0 = 1$, and
	%
	\[ \tilde{Z}_{k+1} = \sum_{j = 1}^{\tilde{Z}_k} \max(X_{ij}, 1). \]
	%
	We find $Z_k \leq \tilde{Z}_k$, and if $\tilde{M} = q + M$, then
	%
	\[ \Expect(\tilde{Z}_{k+1}|\tilde{Z}_k) = \left( q + \sum_{k = 1}^N k q_k \right) \tilde{Z}_k = (q + M) \tilde{Z}_k = \tilde{M} \tilde{Z}_k. \]
	%
	Most importantly for our purposes, $\{ \tilde{Z}_k \}$ has zero chance of extinction. Theorem 5 of \cite{Athreya} implies that for such a supercritical branching process, there exists $\lambda > 0$ depending only on the offspring distribution of $\tilde{Z}$, such that if $\tilde{W}_k = \tilde{Z}_k / \tilde{M}^k$, and $\tilde{W} = \lim \tilde{W}_k$, then
	% TODO: lambda = \theta_1^{1/3} min(1,\theta_1)^{2/3},
	% where theta_1 = inf \tilde{M}^n log g_{n-1}(e^{theta_0}), where g_{n-1} is the n-1'th iterate of g, where g is the inverse function of the generating function of the branching process.
	%
	\[ \Prob(| \tilde{W} - \tilde{W}_k | \geq t) \lesssim \exp \left( - \lambda t^{2/3} \tilde{M}^{k/3} \right) \]
	%
	In particular, this means
	%
	\begin{align*}
		\Prob \left( Z_k \geq (1 + \tilde{W}) \tilde{M}^k \right) &\leq \Prob( \tilde{Z}_k \geq (1 + \tilde{W}) \tilde{M}^k )\\
		&\leq \Prob \left( | \tilde{W} \tilde{M}^k - \tilde{Z}_k | \geq \tilde{M}^k \right)\\
		&= \Prob \left( | \tilde{W} - \tilde{W}_k| \geq 1 \right) \lesssim \exp \left( - \lambda \tilde{M}^{k/3} \right),
	\end{align*}
	%
	Theorem 2 of \cite{Biggins} implies that as $t \to \infty$, there are constants $C$ and $\varepsilon > 0$ depending only on the offspring distribution of $\tilde{Z}$ such that
	%
	\[ - \log \Prob(\tilde{W} \geq t) \geq (C + o(1)) t^{1 + \varepsilon} \]
	%
	In particular, there exists a small constant $\lambda$ such that
	%
	\[ \Prob(1 + \tilde{W} \geq k) \leq \exp \left( - \lambda k^{1 + \varepsilon} \right) \]
	%
	Applying a union bound gives
	%
	\begin{align*}
		\Prob(Z_k \geq k \tilde{M}^k ) &\leq \Prob( Z_k \geq (1 + \tilde{W}) \tilde{M}^k ) + \Prob(1 + \tilde{W} \geq k)\\
		&\lesssim \exp \left( - \lambda \tilde{M}^{k/3} \right) + \exp \left( - \lambda k^{1 + \varepsilon} \right) \lesssim \exp \left( - \lambda k^{1 + \varepsilon} \right). \qedhere
	\end{align*}
\end{proof}

\begin{theorem}
	If $p > 1/2$, then almost surely, $Z_0$ associated with $C$ has lower Minkowski dimension at most $5 - 3 \log_2(1/p)$.
\end{theorem}
\begin{proof}
	Fix $N$, and for any index $k$ let $\delta_k = 1/2^{Nk}$. Given a line $L$, let $I$ be a sidelength $\delta_k$ square intersecting the $\delta_k$ thickened line $L_{\delta_k}$. Then $L$ passes from one edge of $I$ to another edge, and so if we split $I$ into $4^N$ sidelength $\delta_{k+1}$ squares, then $L_{\delta_{k+1}}$ intersects at most $5 \cdot 2^N$ of these boxes. Conditioned on $I$ being contained in $C_{kN}$, each of these subboxes occurs in $C_{(k+1)N}$ with probability $p^N$. We let $Z_k(L)$ denote the number of sidelength $1/2^{Nk}$ boxes in $C_{Nk}$ intersecting $L_{\delta_k}$. We now find $\tilde{Z_k}(L) \geq Z_k(L)$ by adding {\it exactly} $5 \cdot 2^N$ potential subboxes of each box at each subsequent stage, then $\tilde{Z_k}(L)$ is a branching process, whose offspring distribution is independant of $L$. Since each subbox is added with probability $p^N$, the extinction probability of $\tilde{Z_k}$ is $(1 - p^N)^{5 \cdot 2^N}$. Also, $\mathbf{E}(\tilde{Z}_{k+1}(L)|\tilde{Z}_k(L)) = 5 \cdot (2p)^N \tilde{Z}_k$.  Setting $M = 5 (2p)^N$ and $q = (1 - p^N)^{5 \cdot 2^N}$, Lemma \ref{branchingtrick} shows that there exists positive constants $\lambda$ and $\varepsilon$, independant of $L$, such that if $\tilde{M} = M + q$,
	%
	\[ \Prob \left( \tilde{Z}_k(L) \geq k \tilde{M}^k \right) \lesssim \exp(- \lambda k^{1 + \varepsilon}). \]
	%
	Elementary bounds on the logarithm show that
	%
	\[ 5 \cdot 2^N \log(1 - p^N) \leq \frac{-5 (2p)^N}{2 - p^N} \leq -5(2p)^N \]
	%
	so if $p > 1/2$,
	%
	\[ q = (1 - p^N)^{5 \cdot 2^N} \leq e^{-5 (2p)^N} \leq 1 \leq 5(2p)^N \]
	%
	and this implies $\tilde{M} \leq 10 (2p)^N$, so we have shown
	%
	\[ \Prob ( \tilde{Z}_k(L) \geq k 10^k (2p)^N) \lesssim \exp( - \lambda k^{1 + \varepsilon}). \]
	%
	This gives an upper bound on $\tilde{Z}_k(L)$ up to a superexponentially decaying term in $k$.

	For each $k$, we now find lines $L_{k,1}, \dots, L_{k,M}$ such that for any line $L$, there exists $i$ such that $[0,1]^d \cap L_{\delta_k/2} \subset (L_{k,i})_{\delta_k}$. If we do this efficiently, then we can guarantee that $M \leq B \cdot 4^{kN}$, where $B$ is a sufficiently large constant. Applying a union bound, we find that
	%
	\[ \Prob \left( \text{there is $i$ such that}\ Z_k(L_{k,i}) \geq k 10^k (2p)^{kN} \right) \lesssim B \cdot 4^{kN} \exp(-c k^\lambda) \]
	%
	But since $\lambda > 1$, we therefore find
	%
	\[ \sum_{k = 1}^\infty \Prob \left( \text{there is $i$ such that}\ Z_k(L_{k,i}) \geq k 10^k (2p)^{kN} \right) < \infty \]
	%
	Applying Borel-Cantelli, we conclude that almost surely, it is eventually true for sufficiently large $k$ that $Z_k(L_{k,i}) \leq k 10^k (2p)^{kN}$ for all $i$. In particular, the number of cubes intersecting $L_{\delta_k/2}$ for any line $L$ is upper bounded by $k10^k (2p)^{kN}$.

	Almost surely, Lemma \ref{randomdimension} shows that for sufficiently large $k$ we can cover $C_{kN}$ by $O(2^{\alpha kN})$ boxes $I_1, \dots, I_M \in \B^2_{\delta_k}$, with $\alpha = 2 - \log_2(1/p)$. There exists a constant $A$ such that for any $i$ and $j$, if $d(I_i, I_j) > A \delta_k$, then there exists a line $L_{ij}$ such that as $x$ ranges over all points in $I_i$, and $y$ over all points in $I_j$,
	%
	\[ \bigcup_{x,y} B_{xy} \cap [0,1]^2 \subset (L_{ij})_{\delta_k/2} \]
	%
	This means that $Z_0 \cap (I_i \times I_j \times [0,1]^2) \subset I_i \times I_j \times (L_{ij})_{\delta_k/2}$, and the last paragraph implies that $(L_{ij})_{\delta_k/2}$ is covered by $k 10^k (2p)^{kN}$ cubes in $\B^2_{l_k}[0,1]^2$. On the other hand, if $d(I_i,I_j) < A \delta_k$, we can apply the obvious bound that $Z_0 \cap (I_i \times I_j \times [0,1]^2) \subset I_i \times I_j \times C_{kN}$, and $C_{kN}$ is coverable by $O(2^{\alpha kN})$ boxes. Thus we conclude that almost surely, for sufficiently large $k$,
	%
	\begin{align*}
		\# \B^6_{\delta_k}(Z_0) &= \sum_{i,j} \B^6_{\delta_k}(Z_0 \cap (I_i \times I_j \times [0,1]^2)) \\
		&\leq \sum_i \left( \sum_{d(I_i,I_j) \leq A \delta_k} \# \B^6_{\delta_k}(Z_0 \cap (I_i \times I_j \times (L_{ij})_{\delta_k/2})) \right)\\
		&\quad\quad+ \left( \sum_{d(I_i,I_j) > A \delta_k} \# \B^6_{\delta_k}(Z_0 \cap (I_i \times I_j \times C_{kN})) \right)\\
		&\leq \sum_i \left( \sum_{d(I_i,I_j) \leq A \delta_k} \# \B^2_{\delta_k}((L_{ij})_{\delta_k/2}) \right) + \left( \sum_{d(I_i,I_j) > A \delta_k} \# \B^2_{\delta_k}(C_{kN}) \right)\\
		&\lesssim \sum_i 2^{\alpha kN} \cdot k 10^k (2p)^{kN} + 2^{\alpha kN} \lesssim 2^{2\alpha kN} k 10^k (2p)^{kN}
	\end{align*}
	%
	Thus we conclude that almost surely,
	%
	\begin{align*}
		\minkdim(Z_0) &= \lim_{k \to \infty} \frac{\log \left( \# \B^6_{\delta_k}(Z_0) \right)}{\log(1/\delta_k)}\\
		&\leq \lim_{k \to \infty} \frac{\log(2^{2 \alpha kN} k 10^k (2p)^{kN}) + O(1)}{\log(2^{kN})}\\
		&= \lim_{k \to \infty} \frac{2 \alpha k N \log(2) + k \log 10 + kN \log(2p)}{kN \log(2)}\\
		&= 2 \alpha + 3/N + 1 - \log_2(1/p)\\
		&= 5 - 3\log_2(1/p) + 3/N
	\end{align*}
	%
	Taking $N \to \infty$, we obtain the required result.
\end{proof}

TODO: does a projection of $C$ have non-empty interior almost surely?

\begin{corollary}
	If $p = 1/2^{1 - \varepsilon}$, then conditioned on $C$ having Minkowski dimension $1 + \varepsilon$, we can find a subset $X$ of $C$ avoiding isoceles triangles with $\hausdim(X) \geq 1/2 - (3/2) \varepsilon$.
\end{corollary}










\section{Relation to Literature, and Future Work}\label{futureWorkSection}

Our result is part of a growing body of work finding general methods to find sets avoiding patterns. The main focus of this section is comparing our method to the two other major results in the literature. \cite{MalabikaRob} constructs sets with dimension $k/(n-1)$ avoiding the zero sets of rank $k$ $C^1$ functions. In \cite{Mathe}, sets of dimension $d/l$ are constructed avoiding a degree $l$ algebraic hypersurface specified by a polynomial with rational coefficients.

We can view our result as a robust version of Pramanik and Fraser's result. Indeed, if we try and avoid the zero set of a $C^1$ rank $k$ function, then we are really avoiding a dimension $dn - k$ dimensional manifold. Our method gives a dimension
%
\[ \frac{dn - (dn - k)}{n - 1} = \frac{k}{n - 1} \]
%
set, which is exactly the result obtained in \cite{MalabikaRob}.

That our result generalizes \cite{MalabikaRob} should be expected because the technical skeleton of our construction is heavily modeled after their construction technique. Their result also reduces the problem to a discrete avoidance problem. But they {\it deterministically} select a particular side length $S$ cube in every side length $R$ cube. For arbitrary $Z$, this selection procedure can easily be exploited for a particularly nasty $Z$, so their method must rely on smoothness in order to ensure some cubes are selected at each stage. Our discrete avoidance technique was motivated by other combinatorial optimization problems, where adding a random quantity prevents inefficient selections from being made in expectation. This allows us to rely purely on combinatorial calculations, rather than employing smoothness, and greatly increases the applicability of the sets $Z$ we can apply our method to. Furthermore, it shows that the underlying problem is robust to changes in dimension; slightly `thickening' $Z$ only slightly perturbs the dimension of $X$.

One useful technique in \cite{MalabikaRob}, and its predecessor \cite{KeletiDimOneSet}, is the use of a Cantor set construction `with memory'; a queue in the construction algorithm for their sets allows storage of particular discrete versions of the problem to be stored, and then retrieved at a much later stage of the construction process. This enables them to `separate' variables in the discrete version of the problem, i.e. instead of forming a single set $F$ from a set $E$, they from $n$ sets $F_1, \dots, F_n$ from disjoint sets $E_1, \dots, E_n$. The fact that our result is more general, yet does not rely on this technique is an interesting anomaly. An obvious advantage is that the description of the technique is much more simple. But an additional advantage is that we can attack `one scale' of the problem at a time, rather than having to rely on stored memory from a vast number of steps before the current one. We believe that we can exploit the single scale approach to the problem to generalize our theorem to a much wider family of `dimension $\alpha$' sets $Z$, which we plan to discuss in a later paper.

As a generalization of the result in \cite{MalabikaRob}, our result has the same issues when compared to the result of \cite{Mathe}. When the parameter $n$ is large, the dimension of our result suffers greatly, as with the $n$ fold sum application in the last section. Furthermore, our result can't even beat trivial results if $Z$ is almost full dimensional, as the next example shows.

\begin{example}
	Consider an $\alpha$ dimensional set of angles $Y$, and try and find $X \subset \RR^2$ such that the angle formed from any collection of three points in $X$ avoids $Y$. If we form the set
	%
	\[ Z = \left\{ (x,y,z): \text{There is $\theta \in Y$}\ \text{such that}\ \frac{(x - y) \cdot (x - z)}{|x - y||x - z|} = \cos \theta \right\} \]
	%
	Then we can find $X$ avoiding $Z$. But one calculates that $Z$ has dimension $3d + \alpha - 1$, which means $X$ has dimension $(1 - \alpha) / 2$. Provided the set of angles does not contain $\pi$, the trivial example of a straight line beats our result.
\end{example}

Nonetheless, we still believe our method is a useful inspiration for new techniques in the `high dimensional' setting. Most prior literature studies sets $Z$ only implicitly as zero sets of some regular function $f$. The features of the function $f$ imply geometric features of $Z$, which are exploited by these results. But some geometric features are not obvious from the functional perspective; in particular, the fractional dimension of the zero set of $f$ is not an obvious property to study. We believe obtaining methods by looking at the explicit geometric structure of $Z$ should lead to new techniques in the field, and we already have several ideas in mind when $Z$ has geometric structure in addition to a dimension bound, which we plan to publish in a later paper.

We can compare our randomized selection technique to a discrete phenomenon that has been recently noticed, for instance in \cite{BaloghMorrisSamotij}. There, certain combinatorial problems can be rephrased as abstract problems on hypergraphs, and one can then generalize the solutions of these problems using some strategy to improve the result where the hypergraph is sparse. Our result is a continuous analogue of this phenomenon, where sparsity is represented by the dimension of the set $Z$ we are trying to avoid. One can even view Lemma 1 as a solution to a problem about independent sets in hypergraphs. In particular, we can form a hypergraph by taking the cubes $\B^d_s(E)$ as vertices, and adding an edge $(I_1, \dots, I_n)$ between $n$ distinct cubes $I_k \in \B^d_s(E)$ if $I_1 \times \dots \times I_n$ intersects $Z_s$. An independent set of cubes in this hypergraph corresponds precisely to a set $F$ with $F^n$ disjoint except on a discretization of the diagonal. And so Lemma 1 really just finds a `uniformly chosen' independent set in a sparse graph. Thus we really just applied the discrete phenomenon at many scales to obtain a continuous version of the phenomenon.








\bibliographystyle{amsplain}
\bibliography{FractalsAvoidingFractalSetsPaper}

\end{document}