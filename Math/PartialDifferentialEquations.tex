\input{../style.tex}

\title{Partial Differential Equations}
\author{Jacob Denson}

\begin{document}

\pagenumbering{gobble}

\maketitle

\tableofcontents

\pagenumbering{arabic}

\chapter{Introduction}

Physicists were the first to consider partial differential equations. Physical problems provided the insight for many of the basic techniques to solving partial differential equations, and it removes something from the subject to forget the physical motivations for partial differential equations. In this chapter, we derive the four main partial differential equations which began the study of partial differential equations. These equations all involve the most important partial differential operator, the {\bf Laplacian} operator
%
\[ \Delta = \sum \frac{\partial^2}{\partial x_i^2} = \text{div} \circ \nabla \]
%
We can interpret the value $\Delta f(x)$ as giving the average difference $f(y) - f(x)$ in an infinitisimal neighbourhood of $x$. In fact, for any function $f$ twice differentiable at $x$, there are universal constants $C_n > 0$ depending on the dimension of space upon which
%
\[ \frac{1}{v(B_r)} \int_{B_r} [f(x+y) - f(x)] dy = C_n r^2 (\Delta f)(x) + o(r^3) \]
%
so, once appropriately scaled, $(\Delta f)(x) r^2$ is the second order approximation of the average value of how $f$ differs in a ball of radius $r$ around $x$.

\section{The Heat Equation}

Consider a region $\Omega$ in space, where we fix a temperature on the boundary, and then allow tempuerature to fluctuate on the interior on its own volition. Let $u(t,x)$ represent a density for the temperature at $x \in \Omega$ at time $t$. Given a subregion $D \subset \Omega$, the value
%
\[ \frac{d}{dt} \int_D u(t,x)\ dx = \int_D \frac{\partial u}{\partial x}(t,x)\ dx \]
%
represents the rate of energy entering $D$. Newton's law of cooling says that the rate of energy leaving $D$ is proportional to the difference in temperatures between the boundary of the body and its immediate surroundings. To a first order, this is approximated by
%
\[ \int_{\partial D} (\nabla u)(x) \cdot \widehat{n}(x) \]
%
where $\widehat{n}(x)$ is the outward pointing unit vector varying about the boundary. The divergence theorem implies that
%
\[ \int_{\partial D} (\nabla u)(x) \cdot \widehat{n}(x)\ dx = \int_D \text{div}(\nabla u)(x)\ dx = \int_D (\Delta u)(x)\ dx \]
%
By conservation of energy, we therefore find that
%
\[ \int_D \frac{\partial u}{\partial t}(t,x)\ dx = k \int_D (\Delta u)(x)\ dx \]
%
where $k > 0$ is some constant of proportionality. Since this holds irrespective of the domain $D$ chosen, we conclude that heat must satisfy the partial differential equation
%
\[ \frac{\partial u}{\partial t} = k \Delta u \]
%
throughout the entire domain $\Omega$. This is the {\bf heat equation}. We note that the equation can also be applied to understand the diffusion of anything over time in some region, provided the rate of diffusion is linearly related to the change of concentration.

\section{Wave Equation}

Consider a one dimensional string in two dimensions, or a two dimensional membrane in three dimensions, which is fixed on in boundary, but allowed to vibrate up or down on its interior. Let $\Omega$ denote the region upon which the object lies before it begins vibrating. Let $u(t,x)$ denote the displacement of a point $x \in \Omega$ at time $t$ from the plane. The average displacement over a region $D$ is therefore equal to
%
\[ \frac{1}{v(D)} \int_D u(t,x)\ dx \]
%
For a single point mass, Hooke's law tells us that a point under tension will experience a force proportional to its distance from equilibrium. Here, our membrane has no equilibrium position, but if we fix $x$, and consider a small neighbourhood around $x$, the force at $x$ should be proportional to the difference between $u(t,x)$ and the average of $u(t,y)$ on a small neighbourhood $D$ around $x$. Using the fact that this difference is proportional to $v(D)^2 (\Delta f)(x)$ for nice enough small neighbourhoods $D$, we can absorb constants and we find that the average force in a small region $D$ is equal to
%
\[ \frac{1}{v(D)} \int_D k v(D)^2 (\Delta f)(x) = kv(D) \int_D k (\Delta u)(x) \]
%
Applying Newton's law, assuming that $u(t,x)$ has constant density $\rho$, we conclude that the average force in $D$ is also equal to
%
\[ \rho v(D) \int_D \frac{\partial^2 u}{\partial t^2}(t,x) \ dx \]
%
And therefore
%
\[ \rho v(D) \int_D \frac{\partial^2 u}{\partial t^2}(t,x) = k v(D) \int_D (\Delta u)(t,x) \]
%
Dividing by $v(D)$, and then taking the equation over all subregions $D$ of $\Omega$, we conclude that
%
\[ \rho \frac{\partial^2 u}{\partial t^2} = k \Delta u \]
%
This is the {\bf wave equation}.

\section{Laplace and Poisson's equations}

A special case to solutions of both the heat equation and the wave equation is Laplace's equation
%
\[ \Delta u = 0 \]
%
which looks for functions whose average difference in values around each point are essentially equal to zero. twice continously differentiable solutions to Laplace's equation are known as {\bf harmonic}. In terms of the heat equation, $u$ gives {\it steady state} temperature distributions which stay constant throughout time. In terms of the wave equation, $u$ also gives stead state wave distributions, because we assume the membrane upon which $u$ is defined is fixed at the boundary, so that if
%
\[ \frac{\partial^2 u}{\partial t^2} = 0 \]
%
then $u$ is in fact constant. More generally, we can try and solve the partial differential equation
%
\[ - \Delta u = f \]
%
where $f$ is some given function. This generalization of Laplace's equation is known as {\bf Poisson's equation}, and arises in many contexts, like in Electrostatics, where solving the Poisson equation amounts to finding a charge potential $u$ for a given charge distribution $f$.

\section{The Theory of Partial Differential Equations}

In general, a partial differential equation is an equation involving a function and some of its partial derivatives. The utopian goal of the theory of partial differential equations is to {\it solve} a given partial differential equation, which means to find all functions which solve the equation, possibly assuming some additional restriction on the class of solutions, such as how the solution behaves at the boundary of the functions definition. In the best scenario, we can find explicit formulae for all of the solutions to the partial differential equations, but even in the case of ordinary differential equations, we know that this is not possible, so we instead deduce qualitative properties of the solutions.

For ordinary differential equations, there is a satisfying {\it existence and uniqueness} theory guaranteeing that a given differential equations is solvable, and uniquely solvable given some initial conditions. For a general partial differential equation, we have no such theory. Instead, we must argue for ourself whether a partial differential equation given to us is {\it well posed}, in the sense that it has a solution, the solution is unique given certain conditions, and whether the solution depends continuously based on the initial conditions. In some cases, we may have to enlarge the variety of functions we consider to solve the equation. As an example, the PDE
%
\[ \frac{\partial u}{\partial t} + \frac{\partial (f \circ u)}{\partial x} = 0 \]
%
governs the motion of shock waves in physics. In real life, the behavior of these waves is highly discontinuous, and as such we should not expect a solution to this equation to even be differentiable. It is true that this equation has no differentiable solutions, but if we enlarge the class of functions which can solve this equation to the class of {\it generalized} or {\it weak solutions}, then we do have a uniqueness theory.

To summarize, the theory of partial differential equations focuses on three phenomena:
%
\begin{itemize}
    \item (Existence) Does a solution to a partial differential equation exist, and if so, is it possible to express the solution in a formula.

    \item (Uniqueness) Given initial conditions, is the solution to a given partial differential equation unique?

    \item (Regularity) Are the solutions to a given differential equation differentiable, and to what extent?
\end{itemize}
%
In these notes we discuss our ability to answer these types of questions.

\chapter{Solving Classical Partial Differential Equations}

\section{The Transport Equation}

The easiest PDE to analyze is the {\bf transport equation}
%
\[ \frac{\partial u}{\partial t} = \sum a_i \frac{\partial u}{\partial x_i} \]
%
It is essentially an exercise in basic multivariate calculus to prove this functions' uniqueness and existence. Remember that given a vector $v$ in $\mathbf{R}^n$, then we have an equality of operators of the form
%
\[ D_v = \sum v_i \frac{\partial}{\partial x_i} \]
%
In terms of the function $u(t,x)$, we can view the transport equation as saying that $D_v(u) = 0$, where $v = (1,-a_1, \dots, -a_n) = (1,-a)$. Basic calculus tells us that the only differentiable functions to satisfy this equation are those functions $u$ which do not depend on $v$, in the sense that
%
\[ u(t + u,x - ua) = u(t,x) \]
%
Thus given any set of values on a subplane not parallel to $v$, there is a unique solution $u$ taking this set of values on the subplane. For explicitness, if we are given the values $u(0,x) = g(x)$ for some function $g$, then we can write
%
\[ u(t,x) = g(x - ta) \]
%
If $g$ is differentiable, then $u$ will also be differentiable and satisfy the equation, and if furthermore, $g$ is $C^k$, $u$ will also be $C^k$. If $g$ is not differentiable, then the $u$ we defined above may not be differentiable, so won't solve the equation in the classical sense. However, the $u$ given above turns out to be a {\it weak solution} to the equation above, which shows that even the most basic partial differentiable equations have non-differentiable solutions.

To make things harder, let's consider the generalized non-homogenous equation
%
\[ \frac{\partial u}{\partial t} = f + \sum a_i \frac{\partial u}{\partial x_i} \]
%
Given any particular solution $u$ and a fixed $x$, consider the function
%
\[ z(s) = u(t + s, x - as) \]
%
Then
%
\[ z'(s) = \frac{\partial u}{\partial t} - \sum a_i \frac{\partial u}{\partial x_i} = f(t + s, x - as) \]
%
It therefore follows that
%
\[ u(t + s, x - as) = u(t,x) + \int_0^s f(t+y,x-ay) dy \]
%
It follows that if we are given initial conditions $u(0,x) = g(x)$, then we have unique solutions of the form
%
\[ u(t,x) = g(x-ta) + \int_0^t f(x + (s-t)a,s) ds \]
%
Note that our method of solving this differential equation amounted to reducing the partial differential equation to an ordinary differential equation. This is the {\it method of characteristics} which we will discuss later.

\section{The Laplacian and Fundamental Solutions}

Provided a partial differential equation is linear, then a linear combination of solutions to the partial differential equation is also a solution to the partial differential equation. A good strategy to finding {\it all} solutions to PDEs of this form is to find a set of explicit solutions to the PDE, and then to find arbitrary solutions by taking arbitrary linear combinations of explicit solutions. We begin by analyzing Laplace's equation $\Delta u = 0$, which is linear. To begin with, note that the differential operator is invariant under rotations.

\begin{theorem}
    $(\Delta u) \circ T = \Delta (u \circ T)$ for any rotation $T$.
\end{theorem}
\begin{proof}
    We note that $\Delta u$ is the trace of the Hessian matrix
    %
    \[ (Hu)(x) = \left( \frac{\partial^2 u}{\partial x_ix_j} \right) = D(\nabla u)(x) \]
    %
    Now the chain rule implies $D(u \circ T)(x) = (Du)(Tx) \cdot T$, so
    %
    \begin{align*}
        \nabla (u \circ T)(x) &= [D(u \circ T)(x)]^T = [(Du)(Tx) \cdot T]^T\\
        &= T^T \cdot (Du)(Tx)^T = T^T \cdot (\nabla u)(Tx) = (T^T \circ \nabla u \circ T)(x)
    \end{align*}
    %
    The equation $\nabla (u \circ T) = T^T \circ \nabla u \circ T$ essentially says that the gradient doesn't change when we change coordinates by a rotation. Now we find
    %
    \begin{align*}
        H(u \circ T)(x) &= D(\nabla (u \circ T))(x) = D(T^T \circ \nabla u \circ T)(x)\\
        &= T^T \cdot D(\nabla u)(Tx) \cdot T = T^T \cdot (Hu)(Tx) \cdot T
    \end{align*}
    %
    In particular, if $T^T = T^{-1}$, then $H(u \circ T)(x)$ is similar to $(Hu)(Tx)$, and therefore they have the same trace, so $\Delta (u \circ T)(x) = (\Delta u) (Tx)$.
\end{proof}

Since $\Delta u = 0$ is an equation with rotational symmetry, it makes sense to find solutions which are rotationally symmetric. These will form our explicit solutions we can use to construct other solutions. So suppose we have a rotationally symmetric function $u(x) = f(r)$. In order to analyze this, we need to use spherical coordinates. Note that since $r^2 = \sum x_i^2$, we can differentiate both sides by $x_i$ to conclude $r_{x_i} = (x_i/r)$. Thus
%
\[ \frac{\partial u}{\partial x_i} = f'(r) (x_i/r)\ \ \ \ \ \frac{\partial^2 u}{\partial x_i^2} = f''(r) \frac{x_i^2}{r^2} - f'(r) \left( \frac{1}{r} - \frac{x_i^2}{r^3} \right) \]
%
Summing up, we conclude that $u$ is harmonic if and only if
%
\[ (\Delta u)(x) = f''(r) + \frac{n-1}{r} f'(r) = 0 \]
%
This shows
%
\[ \frac{f''(r)}{f'(r)} = -\frac{n-1}{r} \]
%
So integrating both sides in terms of $r$, we conclude that
%
\[ \log(f'(r)) = A - (n-1) \log(r) \]
\[ f'(r) = \frac{e^A}{r^{n-1}} = \frac{\tilde{A}}{r^{n-1}} \]
%
For $n = 2$, we conclude that $f(r) = \tilde{A} \log(r) + B$, and for $n = 1$, we conclude that
%
\[ f(r) = \frac{\tilde{A}}{r^{n-2}} + B \]
%
These solutions motivate us to define the {\bf fundamental solution of the Laplacian}, which is
%
\[ \Phi(x) = \begin{cases} \frac{-\log \| x \|}{2\pi} & n = 2\\ \frac{1}{n(n-2)\alpha(n)}\frac{1}{\|x\|^{n-2}} & n > 2 \end{cases} \]
%
where $\alpha(n)$ denotes the volume of the unit ball in $\mathbf{R}^n$. The only problem with the fundamental solution is that it {\it doesn't solve Laplace's equation in $\mathbf{R}^n$}. Indeed, $\Phi(x) \to \infty$ as $x \to 0$, and so we often write $\Delta \Phi = \delta$, where $\delta$ is the Dirac delta function at the origin, which we can interpret rigorously when we introduce the theory of weak solutions to PDEs.

%\section{Appendix: The Laplacian}

%Using Taylor's theorem, we write
%
%\begin{align*}
%    f(x + y) &= f(x) + \langle (\nabla f)(x), y \rangle + \frac{1}{2} \sum_{i \leq j} y_iy_j f_{x_ix_j}(x) + \sum_{i \leq j \leq k} h_{ijk}(y) y_iy_jy_k
%\end{align*}
%
%where $h_{ijk}(y) \to 0$ as $y \to 0$. Note that since $y_i$ and $y_iy_j$ are odd functions of $i$ for $i \neq j$, the average value over a region symmetric in the $i$'th axis is equal to zero, and in particular for a ball of radius $r$, we find
%
%\[ \int_{B_r} y_i = \int_{B_r} y_iy_j = 0 \]
%
%If we let $\alpha(n)$ denote the volume of an $n$ dimensional unit ball, which can be calculated recursively by the formula
%
%\[ \alpha(n) = \alpha(n-1) \int_{-\pi/2}^{\pi/2} \cos^n(u)\ du \]
%
%with $\alpha(1) = 2$. We then find that
%
%\begin{align*}
%    \frac{1}{v(B^n_r)} \int_{B^n_r} [f(x+y) - f(x)] dy &= \sum \frac{f_{x_i}^2(x)}{2 v(B^n_r)} \int_{B^n_r} y_i^2 + \sum_{i \leq j \leq k} \frac{1}{v(B^n_r)} \int_{B^n_r} h_{ijk}(y) y_iy_jy_k\\
%    &= \sum \frac{f_{x_i^2}(x)}{v(B_r^n)} \int_0^r v\left(B^{n-1}_{\sqrt{1-y^2}}\right) y^2 dy + o(r^3)\\
%    &= (\Delta f)(x) \frac{\alpha(n-1)}{\alpha(n)} r^{-n} \int_0^r y^2(1-y^2)^{\frac{n-1}{2}} dy + o(r^3)\\
%    &= (\Delta f)(x) \frac{\alpha(n-1)}{\alpha(n)} r^2 \int_0^{\pi/2} [\cos^n(t) - \cos^{n+2}(t)] dt + o(r^3)\\
%    &= (\Delta f)(x) \frac{\alpha(n-1)}{\alpha(n)} r^2 (W_n/n) + o(r^3)
%\end{align*}
%
%So, up to a scalar factor depending on the dimension of the Laplacian, $(\Delta f)(x)$ measures the average difference in a small neighbourhood about the point.

\begin{thebibliography}{9}

\bibitem{evans}
Lawrence C. Evans
\textit{Partial Differential Equations}

\end{thebibliography}

\end{document}