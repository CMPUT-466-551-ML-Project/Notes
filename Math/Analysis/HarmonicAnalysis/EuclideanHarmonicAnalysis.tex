%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = HarmonicAnalysis.tex

\part{Euclidean Harmonic Analysis}

Here, we try and describe the more modern approaches to real-variable harmonic analysis, as developed by the \emph{Calderon-Zygmund school} in the 1960s and 1970s. Almost all of the problems we consider can be phrased as showing some operator is bounded as a map between functions spaces. Given some function $f$ lying in a space $V$, we have an associated function $Tf$ lying in some space $W$. The main goal of the techniques in this part of the book attempt to understand how quantitative control on certain properties of $f$ imply quantitative control on properties of $Tf$. In particular, given some quantity $A(f)$ associated with each $f \in V$, and a quantity $B(g)$ defined for all $g \in W$, our goal is to understand whether a general bound $B(Tf) \lesssim A(f)$ is possible for all functions $f \in V$, i.e. whether these exists a universal constant $C > 0$ such that $B(Tf) \leq C \cdot A(f)$ for all $f \in V$.

A core technique we employ here is the method of \emph{decomposition}. We write $f = \sum_k f_k$, where the function $f_k$ have particular properties, perhaps being concentrated in a particular region of space, or having a Fourier transform concentrated in a particular region. These concentration properties often simplify the analysis of the operator $T$, enabling us to obtain bounds $B(Tf_k) \lesssim A(f_k)$ for each $n$. Provided that the operator $T$, and the quantities $A$ and $B$ are `stable under addition', we can then obtain the bound $B(Tf) \leq A(f)$ by `summing' up the related quantities. The stability of $A$ and $B$ is often obtained by assuming these quantities are \emph{norms} on their respective function spaces, i.e. that there exists norms $\| \cdot \|_V$ and $\| \cdot \|_W$ such that $A(f) = \| f \|_V$ for each $f \in V$ and $B(g) = \| g \|_W$ for each $g \in W$. The stability of $T$ under addition is obtained by assuming linearity, or at least sub-linearity, in the sense that for each $f_1, f_2 \in V$,
%
\[ \| T(f_1 + f_2) \|_W \leq \| T f_1 \|_W + \| Tf_2 \|_W. \]
%
We can then use the triangle inequality to conclude that
%
\[ \| Tf \|_W \leq \sum_k \| Tf_k \|_W \lesssim \sum_k \| f_k \|_V. \]
%
Thus if $\sum_k \| f_k \|_V \lesssim \| f \|_V$, our argument is complete. This will be true, for instance, if there exists $\varepsilon > 0$ such that $\| f_k \|_V \lesssim 2^{- \varepsilon k} \| f \|_V$. This can often be obtained if we employ a \emph{dyadic decomposition technique}. For such decompositions, it is also possible to generalize are technique not only to norms, but also to \emph{quasinorms}, i.e. maps $\| \cdot \|$ which are homogeneous and satisfy a \emph{quasi-triangle inequality} $\| v + w \| \lesssim \| v \| + \| w \|$.

\begin{lemma}
    Suppose $\| \cdot \|_V$ is a quasi-norm on a vector space $V$, and under the topology induced by $\| \cdot \|_V$, we can write $f = \sum_{k = 1}^\infty f_k$, where there is $\varepsilon > 0$ and $C > 0$ such that for each $n$, $\| f_k \|_V \leq C \cdot 2^{-\varepsilon k}$. Then $\| f \|_V \lesssim_\varepsilon C$.
\end{lemma}

\begin{remark}
	Thus if $T$ is sublinear and we have $\| Tf_k \|_W \lesssim \| f_k \|_V$ and $\| f_k \|_V \lesssim 2^{- \varepsilon k} \| f \|_V$, we conclude $\| Tf_k \|_W \lesssim 2^{-\varepsilon k} \| f \|_V$, and then by sublinearity and the lemma applied to $\| \cdot \|_W$, we conclude
	%
	\[ \| Tf \|_W \leq \| \sum_k Tf_k \|_W \lesssim_\varepsilon \| f \|_V. \]
	%
	A slight modification of the proof below even gives this claim provided $T$ is \emph{quasi sublinear}, in the sense that for all $f_1, f_2 \in V$, $\| T(f_1 + f_2) \|_W \lesssim \| Tf_1 \|_V + \| Tf_2 \|_V$ for all $f_1, f_2 \in V$. However, such operators occur so rarely in practice that it isn't worth concentrating on them.
\end{remark}

\begin{proof}
	Pick $A > 0$ such that $\| f_1 + f_2 \|_V \leq A \cdot (\| f_1 \|_V + \| f_2 \|_V)$ for all $f_1$ and $f_2$. If $A < 2^{\varepsilon}$, we can write apply the quasitriangle inequality iteratively to conclude
    %
    \begin{align*}
        \| f \| &\leq C \cdot \sum_{k = 1}^\infty A^k \| f_k \|_V \leq C \cdot \left( \sum_{k = 1}^\infty (A 2^{-\varepsilon})^k \right) \leq C \cdot \left( \frac{1}{1 - A 2^{-\varepsilon}} \right) \lesssim_\varepsilon C.
    \end{align*}
    %
    In general, fix $N$, and write $f = f^1 + \dots + f^N$, where $f^m = \sum_{k = 0}^\infty f_{m + Nk}$. Then $\| f_{m + Nk} \|_V \leq C \cdot 2^{- N \varepsilon k}$, and if $N$ is chosen large enough that $A < 2^{N \varepsilon}$, we can apply the previous case to conclude that $\| f^m \|_V \lesssim_\varepsilon C$. Then we can apply the quasi-triangle inequality to conclude that $\| f \| \lesssim_\varepsilon C$.
\end{proof}

We can even apply the method of decomposition in the presence of suitably large polynomial decay.

\begin{lemma}
    Suppose $\| \cdot \|_V$ is a quasinorm on a function space $V$. Then there exists $t$ such that for all $s > t$, if $f = \sum_{k = 1}^\infty f_k$, and if $\| f_k \|_V \leq C \cdot k^{-s}$, for $s > t$, then $\| f \|_V \lesssim_s C$.
\end{lemma}
\begin{proof}
    As in the previous lemma, pick $A > 0$ such that $\| f_1 + f_2 \|_V \leq A (\| f_1 \|_V + \| f_2 \|_V)$ for all $f_1,f_2 \in V$. We perform a decomposition of dyadic type, writing $f = \sum_{m = 0}^\infty f^m$, where
    %
    \[ f^m = \sum_{k = 2^m}^{2^{m+1} - 1} f_k. \]
    %
    By splitting up the sum into a binary tree, we can ensure that
    %
    \[ \| f^m \|_V \lesssim A^{m+1} \sum_{k = 2^m}^{2^{m+1} - 1} \| f_k \|_V \leq C \cdot A^{m+1} \sum_{k = 2^m}^{2^{m+1} - 1} k^{-s} \lesssim C (A 2^{1-s})^m. \]
    %
    If $s > 1 + \lg(A)$, the previous lemma applies that $\| f \|_V \lesssim C$.
\end{proof}

In this part of the notes, we define the various classes of quasi-norms we will study, describe the general methods which make up the Calderon-Zygmund theory, and find applications to geometric measure theory, complex analysis, partial differential equations, and analytic number theory.





\chapter{Monotone Rearrangement Invariant Norms}

In this chapter, we discuss common families of \emph{monotone, rearrangement invariant quasinorms} that occur in harmonic analysis. The general framework is as follows. For each function $f$, we associate it's \emph{distribution function} $F: [0,\infty) \to [0,\infty]$ given by $F(t) = |\{ x : |f(x)| > t \}|$. A \emph{rearrangement invariant space} is a subspace $V$ of the collection of measurable complex-valued functions on some measure space $X$, equipped with a quasi-norm $\| \cdot \|$, satisfying the following two properties:
%
\begin{itemize}
    \item \emph{Monotonicity}: If $|f(x)| \leq |g(x)|$ for all $x \in X$, then $\| f \| \leq \| g \|$.

    \item \emph{Rearrangement-Invariance}: If $f$ and $g$ have the same distribution function, then $\| f \| = \| g \|$.
\end{itemize}
%
A monotone rearrangement-invariant norm essentially provides a way of quantifying the height and width of functions on $X$. It has no interest in the `shape' of the objects studied, because of the property of rearrangement invariance. In a particular problem, one picks the norm best emphasizing a particular family of features useful in the problem.

There are two very useful classes of functions useful for testing the behaviour of translation invariant norms:
%
\begin{itemize}
    \item The \emph{indicator functions} $\mathbf{I}_E(x) = \mathbf{I}(x \in E)$, for a measurable set $E$.
    \item The \emph{simple functions} $f = \sum_{i = 1}^n a_i \mathbf{I}_{E_i}$, for disjoint sets $E_i$.
\end{itemize}
%
The class of all simple functions forms a vector space, and for almost all the monotone rearrangement invariant norm we consider in this section, this vector space will form a dense subspace of the class of all functions. This means that when we want to study how an operator transforms the height and width of functions, the behaviour of the operator on simple functions often reflects the behaviour of an arbitrary function.

\section{The $L^p$ norms}

For $p \in (0,\infty)$, we define the $L^p$ norm on measurable function on a measure space $X$ by
%
\[ \| f \|_p = \left( \int |f(x)|^p\; dx \right)^{1/p}. \]
%
For $p = \infty$, we define
%
\[ \| f \|_\infty = \min \left\{ t \geq 0: |f(x)| \leq t\ \text{almost surely} \right\}. \]
%
These are the most fundamental monotone, rearrangement invariant norms. The space of functions $f$ with $\| f \|_p < \infty$ is denoted by $L^p(X)$. The most important spaces to consider here are the space $L^1(X)$, consisting of absolutely square integrable functions, $L^\infty(X)$, consisting of almost-everywhere bounded functions, and $L^2(X)$, consisting of square integrable functions. The main motivation for the introduction of the other $L^p$ spaces is that much of the quantitative theory for $p \in \{ 1, \infty \}$ is rather trivial, in the sense that it is easy to see when certain operators are bounded on these spaces, or unbounded.

As $p$ increases, the $L^p$ norm of a particular function $f$ gives more control over the height of the function $f$, and weaker control on values where $f$ is particular small. At one extreme, $L^\infty(X)$ only has control over the height of a function, and no control over it's width. Conversely, one can think of $L^0(X)$ as being the space of functions with finite support, though no natural norm exists on this space of functions solely classifying width. After all, such a quantity couldn't be homogenous, since the width of $f$ and $\alpha f$ are the same for each $\alpha \neq 0$. Thus the space $L^0(X)$ isn't so interesting to us from a quantitative perspective.

\begin{example}
  If $f(x) = |x|^{-s}$ for $x \in \RR^d$ and $s > 0$, then integration by radial coordinates shows that
  %
  \[ \int_{\varepsilon \leq |x| \leq M} \frac{1}{|x|^{s p}}\; dx \approx \int_\varepsilon^M r^{d-1 - ps}\; dr = \frac{M^{d - p s} - \varepsilon^{d - p s}}{d - p s}. \]
  %
  This quantity remains finite as $\varepsilon \to 0$ if and only if $d > p s$, and finite as we let $M \to \infty$ if and only if $d < p s$. Thus if $p < d/s$, $f$ is \emph{locally} in $L^p$, in the sense that $f \in L^p(B)$ for every bounded $B \in \RR^d$. The class of functions for which this condition holds is denoted $L^p_{\text{loc}}(X)$. Conversely, if $p > d/s$, then for every domain $B$ separated from the origin, $f \in L^p(B)$. For $p = d/s$, the function $f$ fails to be $L^p(\RR^d)$, but only `by a logarithm', in the sense that
  %
  \[ \int_{\varepsilon \leq |x| \leq M} \frac{1}{|x|^{s p}}\; dx \approx \int_\varepsilon^M \frac{dr}{r} = \log(M/\varepsilon). \]
  %
  We will later find `weaker' versions of the $L^p$ norm, and $f$ will have finite version of these norms.
\end{example}

The last example shows that, roughly speaking, control on the $L^p$ norm of a function for large values of $p$ prevents the formation of higher order singularities, and control of the norm for small values of $p$ ensures that functions have large decay at infinity.

\begin{example}
  If $s = A \chi_E$, and we set $H = |A|$ and $W = |E|$, then $\| s \|_p = W^{1/p} H$. As $p \to \infty$, the value of $\| s \|_p$ depends more and more on $H$, and less on $W$, and in fact $\lim_{p \to \infty} \| s \|_p = H$. If $s = \sum A_n \chi_{E_n}$, and $|A_m|$ is the largest constant from all other values $A_n$, then as $p$ becomes large, $|A_m|^p$ overwhelms all other terms. We calculate that as $p \to \infty$,
  %
  \[ \| s \|_p = \left( \sum |E_n| |A_n|^p \right)^{1/p} = |A_m|^p (|E_m| + o(1))^{1/p} = |A_m| (1 + o(1)). \]
  %
  This implies $\| s \|_p \to |A_m|$ as $p \to \infty$. But as $p \to 0$, $\lim_{p \to 0} \| f \|_p$ does not in general exist, even for step functions with finite support. Nonetheless, we can conclude that $\lim_{p \to 0} \| s \|_p^p = \sum |E_n|$, which is the measure of the support of $s$.
\end{example}

As $p \to \infty$, the width of a function is disregarded completely by the $L^p$ norm, motivating the definition of \emph{the $L^\infty$ norm}; Given a measurable $f$, we define $\| f \|_\infty$ to be the smallest number such that $|f| \leq \| f \|_\infty$ almost surely. We then define $L^\infty(X)$ to be the space of measurable functions $f$ for which $\| f \|_\infty < \infty$. We have already shown $\| s \|_p \to \| s \|_\infty$ if $s$ is a simple function, and the density of such functions gives a general result.

\begin{theorem}
    Let $p \in (0,\infty)$. If $f \in L^p(X) \cap L^\infty(X)$, then
    %
    \[ \lim_{t \to \infty} \| f \|_t = \| f \|_\infty. \]
\end{theorem}
\begin{proof}
    Without loss of generality, assume $p \geq 1$. Consider the norm $\| \cdot \|$ on $L^p(X) \cap L^\infty(X)$ given by
    %
    \[ \| f \| = \| f \|_p + \| f \|_\infty. \]
    %
    Then $L^p(X) \cap L^\infty(X)$ is complete with respect to this metric. For each $t \in [p,\infty)$, define $T_t(f) = \| f \|_t$. Then the functions $\{ T_t \}$ are uniformly bounded in the norm $\| \cdot \|$, since if $p = \theta t$, then
    %
    \[ |T_t(f)| = \| f \|_t \leq \| f \|_p^\theta \| f \|_\infty^{1-\theta} \leq \| f \|^\theta \| f \|^{1-\theta} = \| f \|. \]
    %
    For any $\varepsilon > 0$, we can find a step function $s$ with $\| s - f \|_p, \| s - f \|_\infty \leq \varepsilon$. This means that for all $t \in (p,\infty)$,$\| s - f \|_t \leq \varepsilon$. And so
    %
    \begin{align*}
        \Big| T_t(f) - \| f \|_\infty \Big| &\leq |T_t(f) - T_t(s)| + |T_t(s) - \| s \|_\infty| + |\| s \|_\infty - \| f \|_\infty| \leq 2\varepsilon + o(1). 
    \end{align*}
    %
    Taking $\varepsilon \to 0$ gives the result.
\end{proof}

Abusing notation, we define $\| f \|_0^0 = | \text{supp} f | = | \{ x: f(x) \neq 0 \} |$, and let $L^0(X)$ be the space of functions with finite support. We know that for any simple function $s$, $\| s \|_p^p \to \| s \|_0^0$ as $p \to 0$. If $f \in L^0(X) \cap L^p(X)$ for some $p \in (0,\infty)$, then the monotone and dominated convergence theorems implies that
%
\[ \| f \|_0^0 = \int \mathbf{I}(f(x) \neq 0) = \int \left( \lim_{t \to 0} |f(x)|^t \right)\; dx = \lim_{t \to 0} \int |f(x)|^t\; dx = \lim_{t \to 0} \| f \|_t^t. \]
%
Thus the space $L^0(X)$ lies at the opposite end of the spectrum to $L^\infty$.

The fact that $\| f \|_0^0$ is a norm taken to the `power of zero' implies that many nice norm properties of the $L^p$ spaces fail to hold for $L^0(X)$. For instance, homogeneity no longer holds; in fact, for each $\alpha \neq 0$,
%
\[ \| \alpha f \|_0^0 = \| f \|_0^0. \]
%
It does, however, satisfy the triangle inequality $\| f + g \|_0^0 \leq \| f \|_0^0 + \| g \|_0^0$, which follows from a union bound on the supports of the functions.

\begin{example}
  Let $p < q$, and suppose $f \in L^p(X) \cap L^q(X)$. For any $r \in (p,q)$, the $L^r$ norm emphasizes the height of $f$ less than the $L^q$ norm, and emphasizes the width of $f$ less than the $L^p$ norm. In particular, we find that for any $\lambda \geq 0$,
  %
  \begin{align*}
    \| f \|_r^r = \int_{\RR} |f(x)|^r\; dx &= \int_{|f(x)| \leq 1} |f(x)|^r\; dx + \int_{|f(x)| > 1} |f(x)|^r\; dx\\
    &\leq \int_{|f(x)| \leq 1} |f(x)|^p\; dx + \int_{|f(x)| > 1} |f(x)|^q\; dx\\
    &\leq \| f \|_p^p + \| f \|_q^q < \infty.
  \end{align*}
  %
  In particular, this shows $f \in L^r(X)$.
\end{example}

\begin{remark}
    The bound obtained in the last example can be improved by using scaling symmetries. For any $A > 0$,
    %
    \[ \| f \|_r^r = \frac{\| Af \|_r^r}{A^r} \leq \frac{\| Af \|_p^p + \| Af \|_q^q}{A^r} \leq \frac{A^p \| f \|_p^p + A^q \| f \|_q^q}{A^r}. \]
    %
    If $1/r = \theta/p + (1 - \theta)/q$, and we set $A = \| f \|_q^{q/(p-q)} / \| f \|_p^{p/(p-q)}$, then the above inequality implies $\| f \|_r \leq 2 \| f \|_p^\theta \| f \|_q^{1 - \theta}$, which is a homogenous equality. The constant 2 can be removed in the equation using the {\it tensor power trick}. If we consider the function on $X^n$ defined by $f^{\otimes n}(x_1, \dots, x_n) = f(x_1) \dots f(x_n)$, then $\| f^{\otimes n} \|_r = \| f \|_r^n$, and so
    %
    \[ \| f \|_r = \| f^{\otimes n} \|_r^{1/n} \leq \left( 2 \| f^{\otimes n} \|_p^\theta \| f^{\otimes n} \|_q^{1-\theta} \right)^{1/n} = 2^{1/n} \| f \|_p^\theta \| g \|_q^{1-\theta}. \]
    %
    We can then take $n \to \infty$ to conclude that $\| f \|_r \leq \| f \|_p^\theta \| f \|_q^{1-\theta}$.
\end{remark}

The argument in the last remark is an instance of \emph{real interpolation}; In order to conclude some fact about a function which lies `between' two other functions we know how to deal with, we split the function up into two parts lying in the other spaces, deal with them separately, and then put them back together to get some equality. One can then apply various symmetry considerations (homogeneity and the tensor power trick being two examples) to eliminate extraneous constants. We now also show how to prove this inequality using convexity, which illustrates another core technique. In the next theorem, $1/\infty = 0$.

\begin{theorem}[H\"{o}lder]
  If $0 < p,q \leq \infty$ and $1/p + 1/q = 1/r$, $\| f g \|_r \leq \| f \|_p \| g \|_q$.
\end{theorem}
\begin{proof}
  The case where $p$ or $q$ is $\infty$ is left as an exercise to the reader. In the other case, by moving around exponents, we may simplify to the case where $r = 1$. The theorem depends on the log convexity inequality, such that for $A,B \geq 0$ and $0 \leq \theta \leq 1$, $A^\theta B^{1 - \theta} \leq \theta A + (1 - \theta) B$. But since the logarithm is concave, we calculate
  %
  \[ \log(A^\theta B^{1 - \theta}) = \theta \log A + (1 - \theta) \log B \leq \log(\theta A + (1 - \theta) B), \]
  %
  and we can then exponentiate. To prove H\"{o}lder's inequality, by scaling $f$ and $g$, which is fine by homogeneity, we may assume that $\| f \|_p = \| g \|_q = 1$. Then we calculate
  %
  \begin{align*}
    \| f g \|_1 &= \int |f(x)| |g(x)| = \int |f(x)|^{p/p} |g(x)|^{q/q}\\
    &\leq \int \frac{|f(x)|^p}{p} + \frac{|g(x)|^q}{q} = \frac{1}{p} + \frac{1}{q} = 1 = \| f \|_p \| g \|_q.
  \end{align*}
  %
  If $p = \infty$, $q = 1$, then the inequality is trivial, since we have the pointwise inequality $|f(x) g(x)| \leq \| f \|_\infty |g(x)|$ almost everywhere, which we can then integrate.
\end{proof}

\begin{remark}
  Note that $A^\theta B^{1-\theta} \leq \theta A + (1 - \theta) B$ is an \emph{equality} if and only if $A = B$, or $\theta \in \{ 0, 1 \}$. In particular, following through the proof above shows that if $\| f \|_p = \| g \|_q = 1$, we must have $|f(x)|^{1/p} = |g(x)|^{1/q}$ almost everywhere. In general, this means H\"{o}lder's inequality is sharp if and only if $|f(x)|^{1/p}$ is a constant multiple of $|g(x)|^{1/q}$.
\end{remark}

The next inequality is known as the \emph{triangle inequality}.

\begin{corollary} \label{lptriangleinequality}
  Given $f$,$g$, and $p \geq 1$, $\| f + g \|_p \leq \| f \|_p + \| g \|_p$.
\end{corollary}
\begin{proof}
  The inequality when $p = 1$ is obtained by integrating the inequality $|f(x) + g(x)| \leq |f(x)| + |g(x)|$, and the case $p = \infty$ is equally trivial. When $1 < p < \infty$, by scaling we can assume that $\| f \|_p + \| g \|_p = 1$. Then we can apply H\"{o}lder's inequality combined with the $p = 1$ case to conclude
  %
  \begin{align*}
    \int |f(x) + g(x)|^p &\leq \int |f(x)| |f(x) + g(x)|^{p-1} + |g(x)| |f(x) + g(x)|^{p-1}\\
    &\leq \| f \|_p \| (f + g)^{p-1} \|_q + \| g \|_p \| (f + g)^{p-1} \|_q = \| f + g \|_{p}^{p-1}
  \end{align*}
  %
  Thus $\| f + g \|_p^p \leq \| f + g \|_p^{p-1}$, and simplifying gives $\| f + g \|_p \leq 1$.
\end{proof}

\begin{remark}
  Suppose $\| f + g \|_p = \| f \| + \| g \|_p$. Following through the proof given above shows that both applications of H\"{o}lder's inequality must be sharp. And this is true if and only if $|f(x)|^p$ and $|g(x)|^p$ are scalar multiples of $|f(x) + g(x)|^p$ almost everywhere. But this means $|f(x)|$ and $|g(x)|$ are scalar multiples of $|f(x) + g(x)|$. If $|f(x)| = A|f(x) + g(x)|$ and $|g(x)| = B|f(x) + g(x)|$. If $g \neq 0$, this implies there is $C$ such that $|f(x)| = C |g(x)|$ for some $C > 0$. Thus we can write $f(x) = C e^{i \theta(x)} g(x)$, and we must have
  %
  \[ \| f + g \|_p^p = \int |1 + C e^{i \theta(x)}|^p |g(x)|^p = (1 + C)^p \int |g(x)|^p \]
  %
  so $|1 + Ce^{i \theta(x)}| = |1 + C|$ almost everywhere but this can only be true if $e^{i \theta(x)} = 1$ almost everywhere, so $f = C g$. Thus the triangle inequality is only sharp is $f$ and $g$ are positive scalar multiples of one another.
\end{remark}

This discussion leads to a useful heuristic: Unless $f$ and $g$ are `aligned' in a certain way, the triangle inequality is rarely sharp. For instance, if $f$ and $g$ have disjoint support, we calculate that
%
\[ \| f + g \|_p = \left( \| f \|_p^p + \| g \|_p^p \right)^{1/p} \]
%
For $p > 1$, this is always sharper than the triangle inequality.

If $p < 1$, then the proof of Corollary \ref{lptriangleinequality} no longer works, and in fact, is no longer true. In fact, if $f$ and $g$ are non-negative functions, then we actually have the \emph{anti} triangle inequality
%
\[ \| f + g \|_p \geq \| f \|_p + \| g \|_p, \]
%
as proved in the next theorem.

\begin{theorem}
    If $p \geq 1$, then for any functions $f_1, \dots, f_N \geq 0$,
    %
    \begin{equation} \label{triangleInequality} ( \| f_1 \|_p^p + \dots + \| f_N \|_p^p )^{1/p} \leq \| f_1 + \dots + f_N \|_p \leq \| f_1 \|_p + \dots + \| f_N \|_p. \end{equation}
    %
    If $p \leq 1$, then the inequality reverses, i.e. for any positive functions $f_1, \dots, f_N$,
    %
    \begin{equation} \label{antiTriangleInequality} \| f_1 \|_p + \dots + \| f_N \|_p \leq \| f_1 + \dots + f_N \|_p \leq (\| f_1 \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \end{equation}
\end{theorem}
\begin{proof}
    The upper bound in \eqref{triangleInequality} is just obtained by applying the triangle inequality iteratively. To obtain the lower bound, we note that for $A_1, \dots, A_N \geq 0$,
    %
    \[ (A_1 + \dots + A_N)^p \geq A_1^p + \dots + A_N^p, \]
    %
    One can prove this from induction from the inequality $(A_1 + A_2)^p \geq A_1^p + A_2^p$, which holds when $A_2 = 0$, and the derivative of the left hand side is greater than the right hand side for all $A_2 \geq 0$. But then setting $A_k = f_k$ and then integrating gives
    %
    \[ \| f_1 + \dots + f_N \|_p^p \geq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \]
    %
    Now assume $0 < p < 1$. We begin by proving the lower bound in \ref{antiTriangleInequality}. We can assume $N = 2$, and $\| f_1 \|_p + \| f_2 \|_p = 1$, and then it suffices to show $\| f_1 + f_2 \|_p \geq 1$. For any $\theta \in (0,1)$, and $A,B \geq 0$, concavity implies
    %
    \[ (A + B)^p = (\theta (A/\theta) + (1 - \theta) (B/(1-\theta)))^p \geq \theta^{1-p} A^p + (1 - \theta)^{1-p} B^p. \]
    %
    Thus setting $A = f_1(x)$, $B = f_2(x)$, and $\theta = \| f_1 \|_p$, so that $1 - \theta = \| f_2 \|_p$, and then integrating, we find
    %
    \[ \| f_1 + f_2 \|_p^p \geq \theta + (1 - \theta) = 1. \]
    %
    On the other hand, the inequality $(A_1 + \dots + A_N)^p \leq A_1^p + \dots + A_N^p$, which holds for $A_1, \dots, A_N \geq 0$, can be applied with $f_k = A_k$ and integrated to yield
    %
    \[ \| f_1 + \dots + f_N \|_p^p \leq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \qedhere \]
\end{proof}

Thus the triangle inequality is not satisfied for the $L^p$ norms when $p < 1$. This is one of the deficiencies which leads the $L^p$ theories for $0 < p < 1$ to be rather deficient when compared to the case with $p \geq 1$. One way to fix this is to use the theory of Hardy spaces. We note that for $p < 1$, we do have a \emph{quasi} triangle inequality.

\begin{theorem} \label{quasitriangleinequalitylp}
    For $f_1, \dots, f_N \in L^p(X)$, with $0 < p < 1$,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \]
\end{theorem}
\begin{proof}
    By H\"{o}lder's inequality applied to sums,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq (\| f \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \qedhere \]
\end{proof}

This result is sharp, i.e. if we take a disjoint family of sets $\{ E_1, E_2, \dots \}$ with $|E_i| = 1$ for each $i$, and then set $f_i = \mathbf{I}_{E_i}$, then the inequality is sharp for each $N$.

\begin{remark}
    When $p < 1$, the space $L^p(X)$ is \emph{not} normable. To see why, we look at the topological features of $L^p(X)$. Fix $\varepsilon > 0$, and let $C$ be a convex set containing all functions $f$ with $\| f \|_p < \varepsilon$. Thus, in particular, $C$ contains all step functions $H \mathbf{I}_E$ where $H |E|^{1/p} < \varepsilon$. But if we now find a countable sequence of disjoint sets $\{ E_k \}$, each with positive measure, and for each $k$, define $H_k = (\varepsilon/2) |E_k|^{-1/p}$, then for any $N$, the function
    %
    \[ f_N = (H_1/N) \mathbf{I}_{E_1} + \dots + (H_N/N) \mathbf{I}_{E_N} \]
    %
    lies in $C$, and
    %
    \[ \| f_N \|_p = (1/N) (H_1^p |E_1| + \dots + H_N^p |E_N|)^{1/p} = (\varepsilon/2) N^{1/p - 1} \]
    %
    as $N \to \infty$, the $L^p$ norm of $f_N$ becomes unbounded. In particular, this means that we have proven that every bounded convex subset of $L^p(X)$ has empty interior, and a norm space certainly does not have this property.
\end{remark}

As we have mentioned, as $p \to \infty$, the $L^p$ norm excludes functions with large peaks, or large height, and as $p \to 0$, the $L^p$ norm excludes functions with large tails, or large width. They form a continuously changing family of functions as $p$ ranges over the positive numbers. In general, there is no inclusion of $L^p(X)$ in $L^q(X)$ for any $p,q$, except in two circumstances which occur often enough to be mentioned.

\begin{example}
  If $X$ is a finite measure space, and $0 < p \leq q \leq \infty$, $L^p(X) \subset L^q(X)$. H\"{o}lder's inequality implies $\| f \|_p = \| f \chi_X \|_p \leq \| f \|_q |X|^{1/p-1/q}$. Taking $q \to \infty$, we conclude $\| f \|_p \leq | X |^{1/p} \| f \|_\infty$. One can best remember the constants here by the formula
  %
  \[ \left( \fint |f(x)|^p \right)^{1/p} \leq \left( \fint |f(x)|^q \right)^{1/q}. \]
  %
  In particular, when $X$ is a probability space, the $L^p$ norms are increasing.
\end{example}

\begin{example}
  On the other hand, suppose the measure space is {\it granular}, in the sense that there is $\varepsilon > 0$ such that either $|E| = 0$ or $|E| \geq \varepsilon$ for any measurable set $E$. Then $L^q(X) \subset L^p(X)$ for $0 < p \leq q \leq \infty$. First we check the $q = \infty$ case, which follows by the trivial estimate
  %
  \[ \int |f(x)|^p \geq \varepsilon \| f \|_\infty, \]
  %
  so $\| f \|_\infty \leq \| f \|_p \varepsilon^{-1/p}$. But then applying log convexity, if $p \leq q < \infty$, we can write $1/q = \theta/p$ for $0 < \theta \leq 1$, and then log convexity shows
  %
  \[ \| f \|_q = \| f \|_p^\theta \| f \|_\infty^{1-\theta} \leq \varepsilon^{-(1 - \theta)/p} \| f \|_p = \varepsilon^{-1/p - 1/q} \| f \|_p. \]
  %
  If $\varepsilon = 1$, which occurs if $X = \ZZ$, then the $L^p$ norms are decreasing in $p$. This gives the best way to remember the constants involved, since the measure $\mu(E) = |E|/\varepsilon$ is one granular, and so
  %
  \[ \left( \frac{1}{\varepsilon} \int |f(x)|^q\; dx \right)^{1/q} \leq \left( \frac{1}{\varepsilon} \int |f(x)|^p\; dx \right)^{1/p}. \]
\end{example}

%\begin{example}
%  Controlling additional properties of the function offers similar properties as for control on the measure space. If $|f(x)| \leq M$ for almost all $x$, then for $p \leq q$,
  %
%  \[ \| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}. \]
  %
%  Conversely, if $|f(x)| \geq M$ whenever $f(x) \neq 0$, then
  %
%  \[ \| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}. \]
  %
  
%\end{example}

\begin{remark}
  We can often use such results in spaces which are not granular by coarsening the sigma algebra. For instance, the Lebesgue measure is $\varepsilon^d$ granular over the sigma algebra generated by the length $\varepsilon$ cubes whose corner's lie on the lattice $(\ZZ/\varepsilon)^d$, and if a function is measurable with respect to such a $\sigma$ algebra we call the function $\varepsilon$ granular.
\end{remark}

\begin{remark}
  If we let $X = \{ 1, \dots, N \}$, then $X$ is both finite and granular, so all $L^p$ norms are comparable. In particular, if $p \leq q$,
  %
  \[ \| f \|_q \leq \| f \|_p \leq N^{1/p - 1/q} \| f \|_q. \]
  %
  The left hand side of this inequality becomes sharp when $f$ is concentrated at a single point, i.e. $f(n) = \mathbf{I}(n = 1)$. On the other hand, the left hand side becomes sharp when $f$ is constant, i.e. $f(n) = 1$ for all $n$.
\end{remark}

\begin{example}
    We can obtain similar $L^p$ bounds by controlling the functions $f$ involved, rather than the measure space. For instance, if $|f(x)| \leq M$, and $p \leq q$, then then $\| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}$, which follows by log convexity. On the other hand, if $|f(x)| \geq M$ on the support of $f$, then $\| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}$.
\end{example}

\begin{theorem}
  If $p_\theta$ lies between $p_0$ and $p_1$, then
  %
  \[ L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X) \subset L^{p_0}(X) + L^{p_1}(X) \]
\end{theorem}
\begin{proof}
  If $\| f \|_{p_0}, \| f \|_{p_1} < \infty$, then for any $p_\theta$ between $p_0$ and $p_1$,
  %
  \[ \| f \chi_{|f| \leq 1} \|_{p_\theta}^{p_\theta} = \int_{|f| \leq 1} |f|^{p_\theta} \leq \int_{|f| \leq 1} |f|^{p_0} < \infty \]
  \[ \| f \chi_{|f| > 1} \|_{p_\theta}^{p_\theta} = \int_{|f| > 1} |f|^{p_\theta} \leq \int_{|f| > 1} |f|^{p_1} < \infty \]
  %
  Applying the triangle inequality, we conclude that $\| f \|_{p_\theta} < \infty$. In the case where $p_1 = \infty$, then $f \chi_{|f| > 1}$ is bounded, and must have finite support if $p_0 < \infty$, which shows this integral is bounded. Note the inequalities above show that we can split any function with finite $L^{p_\theta}$ norm into the sum of a function with finite $L^{p_0}$ norm and another with finite $L^{p_1}$ norm.
\end{proof}

\begin{remark}
  This theorem is important in the study of interpolation theory, because if we have two linear operators $T_{p_0}$ defined on $L^{p_0}(X)$ and $T_{p_1}$ on $L^{p_1}(X)$, and they agree on $L^{p_0}(X) \cap L^{p_1}(X)$, then there is a unique linear operator $T_{p_\theta}$ on $L^{p_\theta}(X)$ which agrees with these two functions, and we can consider the boundedness of such a function with respect to the $L^{p_\theta}$ norms.
\end{remark}

The last property of the $L^p$ norms we want to focus on is the principle of \emph{duality}. Given any values of $p$ and $q$ with $1/p + 1/q = 1$, H\"{o}lder's inequality implies that if $f \in L^p(X)$ and $g \in L^q(X)$, then $fg \in L^1(X)$. In particular, for each function $g \in L^q(X)$, the map
%
\[ \lambda: f \mapsto \int f(x)g(x)\; dx \]
%
is a linear functional on $L^p(X)$. H\"{o}lder's inequality implies that $\| \lambda \| \leq \| g \|_q$. But this is actually an \emph{equality}. In particular, if $1 < p < \infty$, one can show these are \emph{all} linear functionals. For $p \in \{ 1, \infty \}$, the dual space of $L^p(X)$ is more subtle. But, since in harmonic analysis we concentrate on quantitative bounds, the following theorem often suffices as a replacement.

\begin{theorem}
    If $1 \leq p < \infty$, and $f \in L^p(X)$, then
    %
    \[ \| f \|_p = \sup \left\{ \int f(x)g(x) : \| g \|_q = 1 \right\}. \]
    %
    If the underlying measure space is $\sigma$ finite, then this claim also holds for $p = \infty$.
\end{theorem}
\begin{proof}
    Suppose that $1 \leq p < \infty$. Given $f$, we define
    %
    \[ g(x) = \frac{1}{\| f \|_p^{p-1}} \text{sgn}(f(x)) |f(x)|^{p-1}. \]
    %
    If $\| f \|_p < \infty$, then
    %
    \[ \| g \|_q^q = \frac{1}{\| f \|_p^{pq - q}} \int |f(x)|^{pq-q} = \frac{1}{\| f \|_p^p} \| f \|_p^p = 1, \]
    %
    and
    %
    \[ \int f(x) g(x) = \frac{1}{\| f \|_p^{p-1}} \int |f(x)|^p = \| f \|_p. \]
    %
    On the other hand, suppose $\| f \|_p = \infty$. Then there exists a sequence of step functions $s_1 \leq s_2 \leq \dots \to |f|$. Each $s_k$ lies in $L^p(X)$, but the monotone convergence theorem implies that $\| s_k \|_p \to \infty$. For each $k$, find a function $g_k \geq 0$ with $\| g_k \|_q = 1$, and $\int g_k(x) s_k(x) \geq \| s_k \|_p / 2$. Then
    %
    \[ \int g_k(x) \text{sgn}(f(x)) f(x) = \int g_k(x) |f(x)| \geq \int g_k(x) s_k(x) \geq \| s_k \|_p / 2 \to \infty, \]
    %
    this completes the proof in this case. 

    Now we take the case $p = \infty$. Given any $f$, fix $\varepsilon > 0$. Then we can find a set $E$ with $0 < |E| < \infty$ such that $|f(x)| \geq \| f \|_\infty - \varepsilon$ for $x \in E$. If $g(x) = \text{sgn}(f(x)) \mathbf{I}_E / |E|$, then $\| g \|_1 = 1$, and
    %
    \[ \int f(x) g(x) = \frac{1}{|E|} \int_E |f(x)| \geq \| f \|_\infty - \varepsilon. \]
    %
    Taking $\varepsilon \to 0$ completes the claim.
\end{proof}

\section{Decreasing Rearrangements}

 The properties of a functions distribution are best reflected quite simply in the \emph{distribution function} of the function $f$, i.e. the function $F: [0,\infty) \to [0,\infty)$ given by $F(t) = |\{ x : |f(x)| > t \}|$, and any rearrangement invariant norm on $f$ should be a function of $F$. The function $F$ is right-continuous and decreasing, but has a jump discontinuity whenever $\{ x : |f(x)| = t \}$ is a set of positive measure. We denote distributions of functions $g$ and $h$ by $G$ and $H$.

\begin{lemma}
  Given a function $f$ and $g$, $\alpha \in \mathbf{C}$, and $t,s > 0$, then
  %
  \begin{itemize}
    \item If $|g| \leq |f|$, then $G \leq F$.
    \item If $g = \alpha f$, then $G(t) = F(t/|\alpha|)$.
    \item If $h = f + g$, then $H(t+s) \leq F(t) + G(s)$.
    \item If $h = fg$, then $H(ts) \leq F(t) + G(s)$.
  \end{itemize}
\end{lemma}
\begin{proof}
    The first point follows because $\{ x : |g(x)| > t \} \subset \{ x : |f(x)| > t \}$, and the second because $\{ x : |\alpha f(x)| > t \} = \{ x : |f(x)| > t/|\alpha| \}$. The third point follows because if $|f(x) + g(x)| \geq t + s$, then either $|f(x)| \geq t$ or $|g(x)| \geq s$. Finally, if $|f(x) g(x)| \geq ts$, then $|f(x)| \geq t$ or $|g(x)| \geq s$.
\end{proof}

We can simplify the study of the distribution of $f$ even more by defining the \emph{decreasing rearrangement} of $f$, a decreasing function $f^*: [0,\infty) \to [0,\infty)$ such that $f^*(s)$ is the \emph{smallest} number $t$ such that $F(t) \leq s$. Effectively, $f^*(s)$ is the inverse of $F$:
%
\begin{itemize}
    \item If there is a unique $t$ with $F(t) = s$, then $f^*(s) = t$.
    \item If there are multiple values $t$ with $F(t) = s$, let $f^*(s)$ be the \emph{smallest} such value.
    \item If there are no values $t$ with $F(t) = s$, then we pick the first value $t$ with $F(t) < s$.
\end{itemize}
%
We find
%
\[ \{ s : f^*(s) > t \} = \{ s : s < F(t) \} = [0,F(t)), \]
%
which has measure $F(t)$. This is the most important property of $f^*$; it is a decreasing function on the line which has the same distribution as the function $|f|$. It is also the unique such function which is right continuous. Thus our intuition when analyzing monotone, rearrangement invariant norms is not harmed if we focus on right continuous decreasing functions.

\begin{theorem}
    The function $f^*$ is right continuous.
\end{theorem}
\begin{proof}
    We note that $F(t) > s$ if and only if $t < f^*(s)$. Since $f^*$ is decreasing, for any $s \geq 0$, we automatically have $f^*(s^+) \leq f^*(s)$. If $f^*(s^+) < f^*(s)$, then
    %
    \[ s < F \left( f^*(s^+) \right) \leq F(f^*(s)) \leq s, \]
    %
    which gives a contradiction, so $f^*(s) = f^*(s^+)$.
\end{proof}

\begin{remark}
    We have a jump discontinuity at a point $s$ wherever $F$ is flat, and $f^*$ is flat wherever $F$ has a jump discontinuity.
\end{remark}

In particular, when understanding intuition about monotone rearrangement invariant norms, one is allowed to focus on non-increasing, right continuous functions on $(0,\infty)$. For instance, this means that these norms do not care about the number of singularities that a function has, since all these singularities `pile up' in the decreasing rearrangement.

\section{Weak Norms}

The weak $L^p$ norms are obtained as a slight `refinement' of the $L^p$ norms.

\begin{theorem}
  If $\phi$ is an increasing, differentiable function on the real line with $\phi(0) = 0$, then
  %
  \[ \int_X \phi(|f(x)|) = \int_0^\infty \phi'(t) F(t)\; dt \]
\end{theorem}
\begin{proof}
  An application of Fubini's theorem is all that is needed to show
  %
  \begin{align*}
    \int_X \phi(|f(x)|)\; dx &= \int_X \int_0^{|f(x)|} \phi'(t)\; dt\; dx\\
    &= \int_0^\infty \phi'(t) \int_{|f(x)| > t}\; dx\; du\\
    &= \int_0^\infty \phi'(t) F(t)\; dt. \qedhere
  \end{align*}
\end{proof}

As a special case we find
%
\[ \| f \|_p = \left( p \int_0^\infty F(t) t^p \frac{dt}{t} \right)^{1/p}. \]
%
For this to be true, $F(t)$ must tend to zero `logarithmically faster' than $1/t^p$. Indeed, we find
%
\[ F(t) = |\{ |f|^p > t^p \}| \leq \frac{1}{t^p} \int |f|^p = \frac{\| f \|_p^p}{t^p}, \]
%
a fact known as \emph{Chebyshev's inequality}. But a bound $F(t) \lesssim 1/t^p$ might be true even if $f \not \in L^p(\RR^d)$. This leads to the \emph{weak $L^p$ norm}, denoted by $\| f \|_{p,\infty}$, which is defined to be the smallest value $A$ such that $F(t) \leq (A/t)^p$ for all $t$. We let $L^{p,\infty}(X)$ denote the space of all functions $f$ for which $\| f \|_{p,\infty} < \infty$. By Chebyshev's inequality, $\| f \|_{p,\infty} \leq \| f \|_p$ for any function $f$. The reason that the value $A$ occurs within the brackets is so that the norm is homogenous; if $g = \alpha f$, and $\| f \|_{p,\infty} = A$, then
%
\[ G(t) = F(t/|\alpha|) \leq \left( \frac{A |\alpha|}{t} \right)^p, \]
%
so $\| \alpha f \|_{p,\infty} = |\alpha| \| f \|_p$. The weak norms do not satisfy a triangle inequality, but they do satisfy a quasitriangle inequality. This can be proven quite simply from the property that if $f = f_1 + \dots + f_N$, and $\alpha_1, \dots, \alpha_N \in [0,1]$ satisfy $\alpha_1 + \dots + \alpha_N = 1$, then
%
\[ F(t) = F_1(\alpha_1 t) + \dots + F_N(\alpha_N t). \]
%
Thus if $f = g + h$, then
%
\[ F(t) \leq G(t/2) + H(t/2) \leq \frac{\| g \|_{p,\infty}^p + \| h \|_{p,\infty}^p}{t^p} \lesssim_p \left( \frac{\| g \|_{p,\infty} + \| h \|_{p,\infty}}{t} \right)^p. \]
%
Thus $\| f + g \|_{p,\infty} \lesssim \| f \|_{p,\infty} + \| g \|_{p,\infty}$. We can measure the degree to which the weak $L^p$ norm fails to be a norm by determining how much the triangle inequality fails for the sum of $N$ functions, instead of just one function.

\begin{theorem}[Stein-Weiss Inequality]
  Let $f_1, \dots, f_N$ be functions. If $p > 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty}. \]
  %
  If $p = 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{1,\infty} \lesssim \log N \left[ \| f_1 \|_{1,\infty} + \dots + \| f_N \|_{1,\infty} \right]. \]
  %
  If $0 < p < 1$, then
  %
  \[ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \left( \| f_1 \|_{p,\infty}^p + \dots + \| f_N \|_{p,\infty}^{1/p} \right)^{1/p} \]
\end{theorem}
\begin{proof}
    Begin with the case $p \geq 1$. Without loss of generality, assume $\| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty} = 1$. Fix $t > 0$. For each $k \in [1,N]$, define
    %
    \[ g_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \geq t/2, \\ 0 &: \text{otherwise}, \end{cases} \]
    %
    and
    %
    \[ h_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \leq \| f_k \|_{p,\infty} \cdot (t/2), \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    Also define $j_k = f_k - g_k - h_k$. Then write $f = f_1 + \dots + f_N$, $g = g_1 + \dots + g_N$, $h = h_1 + \dots + h_N$, and $j = j_1 + \dots + j_N$. Note that $\| h \|_\infty \leq t/2$, so
    %
    \[ \{ x : |f(x)| \geq t \} \subset \{ x : |g(x)| \geq t/4 \} \cup \{ x : |j(x)| \geq t/4 \}. \]
    %
    Each $g_k$ is supported on a set of measure at most $\| f_k \|_{p,\infty}^p \cdot (2/t)^p$. We conclude that $g$ is supported on a set of measure at most
    %
    \[ (2/t)^p \sum_{k = 1}^N \| f_k \|_{p,\infty}^p \leq (2/t)^p. \]
    %
    If $p > 1$, then the measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded by
    %
    \begin{align*}
        \frac{4}{t} \int |j(x)|\; dx &\leq \frac{4}{t} \sum_{k = 1}^N \int |j_k(x)|\\
        &= \frac{4}{t} \sum_{k = 1}^N \int_{\| f_k \|_{p,\infty} (t/2)}^{t/2} \frac{\| j_k \|_{p,\infty}^p}{s^p}\; ds\\
        &= \frac{2^{p+1}}{p-1} \frac{1}{t^p} \sum_{k = 1}^N \| j_k \|_{p,\infty}^p \left( \frac{1}{\| f_k \|_{p,\infty}^{p-1}} - 1 \right) \\
        &\leq \frac{2^{p+1}}{p-1} \frac{1}{t^p} \sum_{k = 1}^N \| f_k \|_{p,\infty}^p \left( \frac{1}{\| f_k \|_{p,\infty}^{p-1 }} - 1 \right)\\
        &\leq \frac{2^{p+1}}{p-1} \frac{1}{t^p}.
    \end{align*}
    %
    Thus in total, we conclude the measure of $\{ x: |f(x)| \geq t \}$ is at most
    %
    \[ \frac{2^p}{t^p} + \frac{2^{p+1}}{p - 1} \frac{1}{t^p} \lesssim_p \frac{1}{t^p}. \]
    %
    If $p = 1$, then the measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded
    %
    \begin{align*}
        (4/t) \int |j(x)|\; dx &\leq (4/t) \sum_{k = 1}^N \int |j_k(x)|\\
        &= (4/t) \sum_{k = 1}^N \int_{\| f_k \|_{1,\infty} (t/2)}^{t/2} \frac{\| j_k \|_{1,\infty}}{s}\; ds\\
        &= (4/t) \sum_{k = 1}^N \| f_k \|_{1,\infty} \log(1/\| f_k \|_{1,\infty}).
    \end{align*}
    %
    Now the maximum of $x_1 \log(1/x_1) + \dots + x_N \log(1/x_N)$, subject to the constraint that $x_1 + \dots + x_N = 1$, is maximized by taking $x_k = 1/N$ for all $N$, which gives a maximal bound of $\log(N)$. In particular, we find that
    %
    \[ (2/t) \sum_{k = 1}^N \| f_k \|_{1,\infty} \log(1/\| f_k \|_{1,\infty}) \leq (2 \log N)/t. \]
    %
    Thus in total, we conclude the measure of $\{ x: |f(x)| \geq t \}$ is at most
    %
    \[ 2(1 + \log N)/t \lesssim \log N / t. \]
    %
    If $p < 1$, we may assume without loss of generality that
    %
    \[ \| f_1 \|_{p,\infty}^p + \dots + \| f_N \|_{p,\infty}^p = 1. \]
    %
    Then, we perform the same decomposition as before, with functions $\{ g_k \}$, $\{ h_k \}$, and $\{ j_k \}$, defined the same as before, except that
    %
    \[ h_k(x) = \begin{cases} f_k(x) &: |f_k(x)| \leq \| f_k \|_{p,\infty}^p \cdot (t/2), \\ 0 &: \text{otherwise}. \end{cases} \]
    %
    The function $g_k$ has support at most $\| f_k \|_{p,\infty}^p \cdot (2/t)^p$, and thus $g$ has total support
    %
    \[ \sum \| f_k \|_{p,\infty}^p (2/t)^p = (2/t)^p. \]
    %
    The measure of $\{ x : |j(x)| \geq t/4 \}$ is bounded by
    %
    \begin{align*}
      \frac{4}{t} \int |j(x)|\; dx &\leq \frac{4}{t} \sum_{k = 1}^N \int_{\| f_k \|_{p,\infty}^p (t/2)}^{t/2} \frac{\| f_k \|_{p,\infty}^p}{s^p}\; ds\\
      &\leq \frac{2^{p+1}}{t^p} \frac{1}{1 - p} \sum_{k = 1}^N \| f_k \|_{p,\infty}^{p + p(1-p)}\\
      &= \frac{2^{p+1}}{t^p} \frac{1}{1 - p} \max \| f_k \|_{p,\infty}^{p(1-p)} \lesssim_p \frac{1}{t^p},
    \end{align*}
    %
    Combining the two bounds gives that $\| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p 1$.
\end{proof}

\begin{remark}
  For $p = 1$, compare this \emph{logarithmic} failure to be a norm with the \emph{polynomial} failure to be a norm found in the norms $\| \cdot \|_p$, when $p < 1$, in Theorem \ref{quasitriangleinequalitylp}.
\end{remark}

For $p = 1$, the Stein-Weiss inequality is asymptotically tight in $N$.

\begin{example}
  Let $X = \RR$. For each $k$, let
  %
  \[ f_k(x) = \frac{1}{|x - k|}. \]
  %
  Then $\| f_k \|_{1,\infty} \lesssim 1$ is bounded independantly of $k$. If $|x| \leq N$, there are integers $k_1, \dots, k_N > 0$ such that $|x - k_i| \leq 2i$, so
  %
  \[ f(x) \geq \sum_{i = 1}^N \frac{1}{|x - k_i|} \geq \sum_{i = 1}^N \frac{1}{2i} \gtrsim \log(N). \]
  %
  Thus $\| f \|_{1,\infty} \gtrsim N \log N \gtrsim \log N \sum \| f_k \|_{1,\infty}$.
\end{example}

The weak $L^p$ norms provide another monotone translation invariant norm, and it oftens comes up when finer tuning is needed in certain interpolation arguments, especially when dealing with maximal functions.

\begin{example}
  If $f = H \mathbf{I}_E$, with $|E| = W$, then
  %
  \[ F(t) = W \cdot \mathbf{I}_{[0,H)}. \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \sup_{0 \leq t < H} W t^p \right)^{1/p} = W^{1/p} H^p = \| f \|_p. \]
  %
  If $f = H_1 \mathbf{I}_{E_1} + H_2 \mathbf{I}_{E_2}$, with $|E_1| = W_1$ and $|E_2| = W_2$, with $H_1 \leq H_2$, then
  %
  \[ F(t) = \begin{cases} W_1 + W_2 &: t < H_1, \\ W_2 &: t < H_2, \\ 0 &: \text{otherwise.} \end{cases} \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \max((W_1 + W_2) H_1^p, W_2 H_2^p) \right)^{1/p} = \max((W_1 + W_2)^{1/p} H_1, W_2^{1/p} H_2). \]
\end{example}

\begin{example}
    The function $f(x) = 1/|x|^s$ does not lie in any $L^p(\RR^d)$, but lies in $L^{p,\infty}$ precisely when $p = d/s$, since
    %
    \[ \left| \{ 1/|x|^{ps} > t \} \right| = \left| \left\{ |x| \leq \frac{1}{t^{1/ps}} \right\} \right|\ \propto_d\ \frac{1}{t^{d/ps}}. \]
\end{example}

Before we move on, we consider a form of duality for the weak norm, at least when $p > 1$.

\begin{theorem}
	If $p > 1$, and $X$ is $\sigma$ finite, then
	%
	\[ \| f \|_{p,\infty} \sim_p \sup_{|E| < \infty} \frac{1}{|E|^{1-1/p}} \int_E |f(x)|\; dx \]
\end{theorem}
\begin{proof}
	Suppose $\| f \|_{p,\infty} < \infty$. If we write $f = \sum f_k$, where $f_k = \mathbf{I}_{F_k} f$, and $F_k = \{ x: 2^{k-1} < |f(x)| \leq 2^k \}$, then $|F_k| \leq \| f \|_{p,\infty}^p 2^{-kp}$. Thus
	%
	\[ \left| \int_E |f_k(x)| \right| \leq 2^k \| f \|_{p,\infty}^p 2^{-kp} = \| f \|_{p,\infty}^p 2^{k(1-p)}. \]
	%
	Fix some integer $n$. Then
	%
	\begin{align*}
		\int_E |f(x)|\; dx &\leq \sum_{k = -\infty}^{n-1} \int_E |f_k(x)|\; dx + \sum_{k = n}^\infty \int_E |f_k(x)|\; dx\\
		&\leq |E| 2^{n-1} + \| f \|_{p,\infty}^p \sum_{k = n}^\infty 2^{k(1-p)}\\
		&\lesssim_p |E| 2^n + \| f \|_{p,\infty}^p 2^{-k(1-p)}.
	\end{align*}
	%
	If we let $2^n \sim \| f \|_{p,\infty} |E|^{1/p}$, then we conclude
	%
	\[ \int_E |f(x)|\; dx \lesssim_p |E|^{1 - 1/p} \| f \|_{p,\infty}. \]
	%
	Conversely, write 
	%
	\[ A = \sup_{|E| < \infty} \frac{1}{|E|^{1-1/p}} \int_E |f(x)|\; dx/ \]

	%
	If $G_t = \{ x: |f(x)| \geq t \}$, then
	%
	\[ |G_t| \leq \frac{1}{t} \int_{G_t} |f(x)|\; dx \leq \frac{A |G_t|^{1 - 1/p}}{t}, \]
	%
	so
	%
	\[ |G_t| \leq \frac{A^p}{t}, \]
	%
	which gives $\| f \|_{p,\infty} \leq A$.
\end{proof}

For $p \leq 1$, the spaces $L^{p,\infty}(X)$ are not normable, as seen by the tightness of the Stein-Weiss inequality. Nonetheless, we still have a certain `duality' property, that is often useful in the analysis of operators on these spaces. Most useful is it's application when $p = 1$.

\begin{theorem} \label{weakdualitytheorem}
  Let $0 < p < \infty$, and let $f \in L^{p,\infty}(X)$, and let $\alpha \in (0,1)$. Then the following are equivalent:
  %
  \begin{itemize}
    \item $\| f \|_{p,\infty} \lesssim_{\alpha,p} A$.

    \item For any set $E \subset X$ with finite measure, there is $E' \subset E$ with $|E'| \geq \alpha |E|$ such that
    %
    \[ \int_{E'} |f(x)|\; dx \lesssim_{\alpha,p} A |E'|^{1 - 1/p}. \]
  \end{itemize}
\end{theorem}
\begin{proof}
  By homogeneity, assume $\| f \|_{p,\infty} \leq 1$, so that if $F$ is the distribution of $f$, $F(t) \leq 1/t^p$. If $|E| = (1-\alpha)^{-1} / t_0^p$, and we set
  %
  \[ E' = \{ x: |f(x)| \leq t_0 \}, \]
  %
  then
  %
  \[ |E'| \geq |E| - F(t_0) = \frac{(1 - \alpha)^{-1} - 1}{t_0^p} = \alpha |E|, \]
  %
  and
  %
  \[ \int_{E'} |f(x)| \leq t_0 |E'| \lesssim_\alpha |E'|^{1-1/p}. \]
  %
  Conversely, suppose Property (2) holds. For each $k$, set
  %
  \[ E_k = \{ x: 2^k \leq |f(x)| < 2^{k+1} \}. \] 
  %
  Then there exists $E_k'$ with $|E_k'| \geq \alpha |E_k|$ and
  %
  \[ \int_{E_k'} |f(x)|\; dx \leq |E_k'|^{1 - 1/p} \]
  %
  On the other hand,
  %
  \[ \int_{E_k'} |f(x)|\; dx \geq 2^k |E_k'|. \]
  %
  Rearranging this equation gives $|E_k'| \leq 2^{-pk}$, and so $|E_k| \lesssim_\alpha 2^{-pk}$. But this means
  %
  \[ F(2^N) = \sum_{k = N}^\infty |E_k| \lesssim_{\alpha,p} 2^{-Np}, \]
  %
  and this implies $\| f \|_{p,\infty} \lesssim_{\alpha,p} 1$.
\end{proof}

\section{Lorentz Spaces}

Recall that we can write
%
\[ \| f \|_p = \left( p \int_0^\infty F(t) t^p \frac{dt}{t} \right)^{1/p}. \]
%
Thus $F(t) t^p$ is integrable with respect to the Haar measure on $\RR^+$. But if we change the integrality condition to the condition that $F(t) t^p \in L^q(\RR^+)$ for some $0 < q \leq \infty$, we obtain a different integrability condition, giving rise to a monotone, translation-invariant norm. Thus leads us to the definition of the \emph{Lorentz norms}. For each $0 < p,q < \infty$, we define the Lorentz norm
%
\[ \| f \|_{p,q} = p^{1/q} \| t F^{1/p} \|_{L^q(\RR^+)} \]
%
The \emph{Lorentz space} $L^{p,q}(X)$ as the space of functions $f$ with $\| f \|_{p,q} < \infty$. We can define the norm in terms of $f^*$ as well.

\begin{lemma}
  For any measurable $f: X \to \RR$, $\| f(t) \|_{p,q} = \| s^{1/p} f^*(s) \|_{L^q(\RR^+)}$.
\end{lemma}
\begin{proof}
  First, assume $f^*$ has non-vanishing derivative on $(0,\infty)$, and that $f$ is bounded, with finite support. An integration by parts gives
  %
  \[ \| f \|_{p,q} = p^{1/q} \left( \int_0^\infty t^{q-1} F(t)^{q/p}\; dt \right)^{1/q} = \left( \int_0^\infty t^q F(t)^{q/p - 1} (-F'(t))\; dt \right)^{1/q}. \]
  %
  If we set $s = F(t)$, then $f^*(s) = t$, and $ds = F'(t) dt$, and so
  %
  \[ \left( \int_0^\infty t^q F(t)^{q/p - 1} F'(t)\; dt \right)^{1/q} = \left( \int_0^\infty f^*(s)^q s^{q/p - 1} ds \right)^{1/q} = \| s^{1/p} f^* \|_{L^q(\RR^+)}. \]
  %
  This gives the result in this case. The general result can then be obtained by applying the monotone convergence theorem to an arbitrary $f^*$ with respect to a family of smooth functions.
\end{proof}

The definition of the Lorentz space may seem confusing, but we really only require various special cases in most applications. Aside from the weak $L^p$ norms $\| \cdot \|_{p,\infty}$ and the $L^p$ norms $\| \cdot \|_p = \| \cdot \|_{p,p}$, the $L^{p,1}$ norms and $L^{p,2}$ norms also occur, the first, because of the connection with integrability, and the second because we may apply orthogonality techniques. As $q \to 0$, the norms $\| \cdot \|_{p,q}$ give stronger control over the function $f$.

\begin{theorem}
    For $q < r$, $\| f \|_{p,r} \lesssim_{p,q,r} \| f \|_{p,q}$.
\end{theorem}
\begin{proof}
    First we treat the case $r = \infty$. We have
    %
    \begin{align*}
        s_0^{1/p} f^*(s_0) &= \left( (p/q) \int_0^{s_0} [s^{1/p} f^*(s_0)]^q \frac{ds}{s} \right)^{1/q}\\
        &\leq \left( (p/q) \int_0^{s_0} [s^{1/p} f^*(s)]^q \frac{ds}{s} \right)\\
        &\leq (p/q)^{1/q} \| f \|_{p,q}.
    \end{align*}
    %
    When $r < \infty$, we can interpolate, calculating
    %
    \begin{align*}
      \| f \|_{p,r} &= \left( \int_0^\infty [s^{1/p} f^*(s)]^r \frac{ds}{s} \right)^{1/r}\\
    &\leq \| f \|_{p,\infty}^{1 - q/r} \| f \|_{p,q}^{q/r} \leq (p/q)^{p(1/q - 1/r)} \| f \|_{p,q}. \qedhere
    \end{align*}
\end{proof}

The fact that multiplying a function by a constant dilates the distribution implies that the Lorentz norm is homogeneous. We do not have a triangle inequality for the Lorentz norms, but we have a quasi triangle inequality.

\begin{theorem}
	For each $p,q > 0$, $\| f_1 + f_2 \|_{p,q} \lesssim_{p,q} \| f_1 \|_p + \| f_2 \|_q$.
\end{theorem}
\begin{proof}
    We calculate that if $g = f_1 + f_2$,
    %
    \begin{align*}
    \| g \|_{p,q} &= \left( q \int_0^\infty \left[t G(t)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\leq \left( q \int_0^\infty \left[ t (F_1(t/2) + F_2(t/2))^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\lesssim \left( q \int_0^\infty \left[ t \left( F_1(t) + F_2(t) \right)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\lesssim_p \left( q \int_0^\infty t^q \left( F_1(t)^{q/p} + F_2(t)^{q/p} \right) \frac{dt}{t} \right)^{1/q}\\
    &\lesssim_q  \left( q \int_0^\infty t^q F_1(t)^{q/p} \frac{dt}{t} \right)^{1/q} +  \left( q \int_0^\infty t^q F_2(t)^{q/p} \frac{dt}{t} \right)^{1/q}\\
    &= \| f_1 \|_{p,q} + \| f_2 \|_{p,q}. \qedhere
  \end{align*}
\end{proof}

\section{Dyadic Layer Cake Decompositions}

An important trick to utilizing Lorentz norms is by utilizing a dyadic layer cake decomposition. The dyadic layer cake decompositions enable us to understand a function by breaking it up into parts upon which we can control the height or width of a function. We say $f$ is a \emph{sub step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \leq W$, and $|f(x)| \leq H$. A \emph{quasi step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \sim W$ and on $E$, $|f(x)| \sim H$.

\begin{remark}
  It might seem that sub step functions of height $H$ and width $W$ can take on a great many different behaviours, rather than that of a step function with height $H$ and width $W$. However, from the point of view of monotone, translation invariant norms, this isn't so. This is because using the binary expansion of real numbers, for every sub-step function $f$ of height $H$ and width $W$, we can find sets $\{ E_k \}$ such that
  %
  \[ f(x) = H \sum_{k = 1}^\infty 2^{-k} \mathbf{I}_{E_k}, \]
  %
  where $|E_k| = 1$. Thus bounds on step functions that are stable under addition tend to automatically imply bounds on substep functions.
\end{remark}

We start by discussing the \emph{vertical dyadic layer cake decomposition}. We define, for each $k \in \ZZ$,
%
\[ f_k(x) = f(x) \mathbf{I}(2^{k-1} < |f(x)| \leq 2^k) \]
%
Then we set $f = \sum f_k$. Each $f_k$ is a quasi step function with height $2^k$ and width $F(2^{k-1}) - F(2^k)$. We can also perform a \emph{horizontal layer cake decomposition}. If we define $H_k = f^*(2^k)$, and set
%
\[ f_k(x) = f(x) \mathbf{I}(H_{k-1} < |f(x)| \leq H_k), \]
%
then $f_k$ is a substep function with height $H_k$ and width $2^k$. These decompositions are best visualized with respect to the representation $f^*$ of $f$, in which case the decomposition occurs over particular intervals.

\begin{theorem}
    The following values $A_1, \dots, A_4$ are all comparable up to absolute constant depending only on $p$ and $q$:
    %
    \begin{enumerate}
        \item \label{onebound} $\| f \|_{p,q} \leq A_1$.

        \item \label{twobound} We can write $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a quasi-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[ 2^k W_k^{1/p} \right]^q \right)^{1/q} \leq A_2. \]

        \item \label{threebound} We can write $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a sub-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[2^{k} W_k^{1/p} \right]^q \right)^{1/q} \leq A_3. \]

        \item \label{fourbound} We can write $f(x) = \sum_{k \in \ZZ} f_k$, where $f_k$ is a sub-step function with width $2^k$ and height $H_k$, where $\{ H_k \}$ is a decreasing family of functions, and
        %
        \[ \left( \sum_{k \in \ZZ} \left[H_k 2^{k/p} \right]^q \right)^{1/q} \leq A_4. \]
    \end{enumerate}
\end{theorem}
\begin{proof}
    It is obvious that we can always select $A_3 \leq A_2$. Next, we bound $A_2$ in terms of $A_1$ by performing a vertical layer cake decomposition on $f$. If we write $f = \sum_{k \in \ZZ} f_k$, then $f_k$ is supported on a set with measure $W_k = F(2^{k-1}) - F(2^k) \leq F(2^{k-1})$, and so
    %
    \begin{align*}
        \sum_{k \in \ZZ} [2^k W_k^{1/p}]^q &\leq \sum_{k \in \ZZ} [2^k F(2^{k-1})^{1/p}]^q\\
        &\lesssim_q \sum_{k \in \ZZ} [2^{k-1} F(2^k)^{1/p}]^q\\
        &\lesssim \sum_{k \in \ZZ} \int_{2^{k-1}}^{2^k} [tF(t)^{1/p}]^q\; \frac{dt}{t} \lesssim_q \| f \|_{p,q}^q \leq A_1^q.
    \end{align*}
    %
    Thus $A_2 \lesssim_q A_1$. Next, we bound $A_4$ in terms of $A_1$. Perform a horizontal layer cake decomposition, writing $f = \sum f_k$, where $f_k$ is supported on a set with measure $W_k \leq 2^k$, and $H_{k+1} \leq |f_k(x)| \leq H_k$. Then a telescoping sum shows
    %
    \begin{align*}
        H_k 2^{k/p} &= \left( \sum_{m = 0}^\infty (H_{k+m}^q - H_{k+m+1}^q) 2^{kq /p} \right)^{1/q}\\
        &\lesssim_q \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t 2^{k/p}]^q \frac{dt}{t} \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q}
    \end{align*}
    %
    Thus
    %
    \[ \left( \sum_{k \in \ZZ} [H_k 2^{k/p}]^q \right)^{1/q} \leq \left( \int_0^\infty [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q} \lesssim_q A_1. \]
    %
    Thus $A_4 \lesssim_q A_1$. It remains to bound $A_1$ by $A_4$ and $A_3$. Given $A_3$, we can write $|f(x)| \leq \sum 2^k \mathbf{I}_{E_k}$, where $|E_k| \leq W_k$. We then find
    %
    \[ F(2^k) \leq \sum_{m = 1}^\infty W_{k+m}. \]
    %
    Thus
    %
    \[ \int_{2^{k-1}}^{2^k} [t F(t)^{1/p}]^q \frac{dt}{t} \lesssim \left[ 2^k \left(\sum_{m = 0}^\infty W_k \right)^{1/p} \right]^q. \]
    %
    Thus if $q \leq p$,
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \ZZ} \left[2^k \left( \sum_{m = 0}^\infty W_{k+m} \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{k \in \ZZ} \sum_{m = 0}^\infty \left[ 2^k W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty 2^{-qm} \sum_{k \in \ZZ} \left[ 2^{k+m} W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( A_3^q \sum_{m = 0}^\infty 2^{-mq} \right)^{1/q} \lesssim_q A_3.
    \end{align*}
    %
    If $q \geq p$, we can employ the triangle inequality for $l^{q/p}$ to write
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \ZZ} \left[2^k \left( \sum_{m = 0}^\infty W_{k + m}  \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \left( \sum_{k \in \ZZ} 2^{kq} W_{k+m}^{q/p} \right)^{p/q} \right)^{1/p}\\
        &\leq \left( A_3^p \sum_{m = 0}^\infty 2^{-mq} \right)^{1/p} \lesssim_{p,q} A_3.
    \end{align*}
    %
    The bound of $A_1$ in terms of $A_4$ involves the same `shifting' technique, and is left to the reader.
\end{proof}

\begin{remark}
    Heuristically, the theorem above says that if $f = \sum_{k \in \ZZ} f_k$, where $f_k$ is a quasi-step function with width $H_k$ and width $W_k$, and if either $\{ H_k \}$ and $\{ W_k \}$ grow faster than powers of two, then
    %
    \[ \| f \|_{p,q} \sim_{p,q} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}. \]
    %
    Thus the $L^{p,q}$ norm has little interaction between elements of the sum when the sum occurs over dyadically different heights or width. This is one reason why we view the $q$ parameter as a `logarithmic' correction of the $L^p$ norm. In particular, if we can write $f = f_1 + \dots + f_N$, and $q_1 < q_2$, then the last equation, combined with a $l^{q_1}$ to $l^{q_2}$ norm bound, gives
    %
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^{q_1} \right)^{1/q_1} \leq N^{1/q_1 - 1/q_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p} \right]^{q_2} \right)^{1/q_2} \]
    %
    This implies
    %
    \[ \| f \|_{p,q_2} \lesssim_{p,q_1,q_2} \| f \|_{p,q_1} \lesssim_{p,q_1,q_2} N^{1/q_1 - 1/q_2} \| f \|_{p,q_2}. \]
    %
    In particular, this occurs if there exists a constant $C$ such that $C \leq |f(x)| \leq C \cdot 2^N$ for all $x$. On the other hand, if we vary the $p$ parameter, we find that for $p_1 < p_2$,
    %
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} \leq \max(W_k)^{1/p_1 - 1/p_2} \left( \sum_{k \in \ZZ} \left[H_k W_k^{1/p_2} \right]^q \right)^{1/q}, \]
    \[ \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} \leq \left( \frac{1}{\min(W_k)} \right)^{1/p_1 - 1/p_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q}. \]
    %
    which gives
    %
    \[ \min(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q} \lesssim_{p_1,p_2,q} \| f \|_{p_1,q} \lesssim_{p_1,p_2,q} \max(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q}. \]
    %
    Both of these inequalities can be tight. Because of the dyadic decomposition of $f$, we find $\max(W_k) \geq 2^N \min(W_k)$, so these two norms can differ by at least $2^{N(1/p_1 - 1/p_2)}$, and at \emph{most} if the $f_k$ occur over consecutive dyadic values, which is \emph{exponential} in $N$. Conversely, if the heights change dyadically, we find that
    % q = q'p_2/p-1
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} &\leq \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^{qp_2/p_1} \right)^{(p_1/p_2)/q}\\
        &\leq \max(H_k)^{1 - p_1/p_2} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{(p_1/p_2)/q}
    \end{align*}
    %
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} &\lessapprox \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_1} \right]^{qp_1/p_2} \right)^{(p_2/p_1)/q}\\
        &\leq \left( \frac{1}{\min(H_k)} \right)^{p_2/p_1 - 1} \left( \sum_{k \in \ZZ} \left[ H_k W_k^{1/p_2} \right]^q \right)^{(p_2/p_1)/q}
    \end{align*}
    %
    where $\lessapprox$ denotes a factor ignoring polynomial powers of $N$ occuring from the estimate. Thus
    %
    \[ \min(H_k)^{p_2 - p_1} \| f \|_{p_1,q}^{p_1} \lessapprox_{p_1,p_2,q} \| f \|_{p_2,q}^{p_2} \lesssim_{p_1,p_2,q} \max(H_k)^{p_2-p_1} \| f \|_{p_1,q}^{p_1} \]
    %
    again, these inequalities can be both tight, and $\max(H_k) \geq 2^N \min(H_k)$, with equality if the quasi step functions from which $f$ is composed occur consecutively dyadically.
\end{remark}

\begin{example}
    Consider the function $f(x) = |x|^{-s}$. For each $k$, let
    %
    \[ E_k = \{ x : 2^{-(k+1)/s} \leq |x| < 2^{-k/s} \} \]
    %
    and define $f_k = f \mathbf{I}_{E_k}$. Then $f_k$ is a quasi-step function with height $2^k$, and width $1/2^{dk/s}$. We conclude that if $p = d/s$, and $q < \infty$,
    %
    \[ \| f \|_{p,q} \sim_{p,q,d} \left( \sum_{k = -\infty}^\infty 2^{qk(1 - d/ps)} \right)^{1/q} = \infty. \]
    %
    Thus the function $f$ lies exclusively in $L^{p,\infty}(\RR^d)$.
\end{example}

A simple consequence of the layer cake decomposition is H\"{o}lder's inequality for Lorentz spaces.

\begin{theorem}
    If $0 < p_1,p_2,p < \infty$ and $0 < q_1,q_2,q < \infty$ with
    %
    \[ 1/p = 1/p_1 + 1/p_2 \quad \text{and} \quad 1/q = 1/q_1 + 1/q_2, \]
    %
    then
    %
    \[ \| f g \|_{p,q} \lesssim_{p_1,p_2,q_1,q_2} \| f \|_{p_1,q_1} \| g \|_{p_2,q_2}. \]
\end{theorem}
\begin{proof}
    Without loss of generality, assume $\| f \|_{p_1,q_1} = \| g \|_{p_2, q_2} = 1$. Perform horizontal layer cake decompositions of $f$ and $g$, writing $|f| \leq \sum_{k \in \ZZ} H_k \mathbf{I}_{E_k}$ and $|g| \leq \sum_{k \in \ZZ} H_k' \mathbf{I}_{F_k}$, where $|E_k|, |F_k| \leq 2^k$. Then
    %
    \[ |fg| \leq \sum_{k,k' \in \ZZ} H_k H_k' \mathbf{I}_{E_k \cap F_{k'}} \]
    %
    For each fixed $k$, $|E_{k + m} \cap F_m| \leq 2^m$, and so
    %
    \begin{align*}
        \left\| \sum_{m \in \ZZ} H_{k + m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q} &\lesssim_{p,q} \left( \sum_{m \in \ZZ} [H_{k+m} H_m' 2^{m/p}]^q \right)^{1/q}\\
        &= \left( \sum_{m \in \ZZ} \left[ (H_{k+m} 2^{m/p_1}) (H_m 2^{m/p_2}) \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m \in \ZZ} [H_{k+m} 2^{m/p_1} ]^{q_1} \right)^{1/q_1} \left( \sum_{m \in \ZZ} [H_m' 2^{m/p_2}]^{q_2} \right)^{1/q_2}\\
        &\lesssim_{p,q,p_1,q_1,p_2,q_2} 2^{-k/p_1}\\
    \end{align*}
    %
    Summing over $k > 0$ gives that
    %
    \[ \left\| \sum_{k \geq 0} \sum_{m \in \ZZ} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\| \lesssim_{p,q,p_1,q_1,p_2,q_2} 1 \]
    %
    By the quasitriangle inequality, it now suffices to obtain a bound
    %
    \[ \left\| \sum_{k < 0} \sum_{m \in \ZZ} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q}. \]
    %
    This is done similarily, but using the bound $|E_{k+m} \cap F_m| \leq 2^{k+m}$ instead of the other bound.
\end{proof}

\begin{corollary}
    If $p > 1$ and $q > 0$, $L^{p,q}(X) \subset L^1_{\text{loc}}(X)$.
\end{corollary}
\begin{proof}
    Let $E$ have finite measure and let $f \in L^{p,q}(X)$. Then the H\"{o}lder's inequality for Lorentz spaces shows
    % 1 = 1/p + 1/p_2 = 1/q + 1/q_2
    %
    \[ \| f \|_{L^1(E)} = \| \mathbf{I}_E f \|_{L^1(X)} \lesssim_{p,q} |E|^{1 - 1/p} \| f \|_{p,q} < \infty. \qedhere \]
\end{proof}

Finally, we consider the duality of the $L^{p,q}$ norms. If $1 < p < \infty$, and $1 < q < \infty$, then $L^{p,q}(X)^* = L^{p',q'}(X)$. When $q = 1$ or $q = \infty$, things are more complex, but the following theorem often suffices. When $p = 1$, things get more tricky, so we leave this case out.

\begin{theorem}
    Let $1 < p < \infty$ and $1 \leq q < \infty$. Then if $f \in L^{p,q}(X)$,
    %
    \[ \| f \|_{p,q} \sim \sup \left\{ \int fg : \| g \|_{p',q'} \leq 1 \right\}. \]
\end{theorem}
\begin{proof}
    Without loss of generality, we may assume $\| f \|_{p,q} = 1$. We may perform a vertical layer cake decomposition, writing $f = \sum_{k \in \ZZ} f_k$, where $2^{k-1} \leq |f_k(x)| \leq 2^k$, is supported on a set with width $W_k$, and
    %
    \[ \left( (2^k W_k^{1/p})^q \right) \sim_{p,q} 1. \]
    %
    Define $a_k = 2^k W_k^{1/p}$, and set $g = \sum_{k \in \ZZ} g_k$, where $g_k(x) = a_k^{q-p} \text{sgn}(f_k(x)) |f_k(x)|^{p-1}$. Then
    %
    \begin{align*}
        \int f(x) g(x) &= \sum_{k \in \ZZ} \int f_k(x) g_k(x) = \sum_{k \in \ZZ} a_k^{q-p} \int |f_k(x)|^p\\
        &\gtrsim_p \sum_{k \in \ZZ} a_k^{q-p} W_k 2^{kp} = \sum_{k \in \ZZ} a_k^q \gtrsim_{p,q} 1.
    \end{align*}
    %
    We therefore need to show that $\| g \|_{p',q'} \lesssim 1$. We note $|g_k(x)| \lesssim a_k^{q-p} 2^{kp}$, and has width $W_k$. The gives a decomposition of $g$, but neither the height nor the widths necessarily in powers of two. Still, we can fix this since the heights increase exponentially; define
    %
    \[ H_k = \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2}. \]
    %
    Then $|g_k(x)| \lesssim_{p,q} H_k$, and $H_{k+1} \geq 2^{p/2} H_k$. In particular, if we pick $m$ such that $2^{mp/2} \geq 1$, then for any $l \leq m$, the sequence $H_{km + l}$, as $k$ ranges over values, increases dyadically, and so by the quasitriangle inequality for the $L^{p',q'}$ norm, and then the triangle inequality in $l^q$, we find
    % W_k = a_k^p/ 2^{kp}
    \begin{align*}
        \| g \|_{p',q'} &\lesssim_{m,p,q} \left( \sum [H_k W_k^{1/p'}]^{q'} \right)^{1/q'}\\
        &\lesssim \left( \sum_{k \in \ZZ} \left[ \left( \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2} \right) (a_k 2^{-k})^{p-1} \right]^{q'} \right)^{1/q'}\\
        &\lesssim_p \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} \sum_{l = 0}^\infty a_{k-l}^{q-p} 2^{-lp/2} \right]^{q'} \right)^{1/q'}\\
        &\lesssim \sum_{l = 0}^\infty 2^{-lp/2} \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'}.
    \end{align*}
    %
    Applying's H\"{o}lder's inequality shows
    %
    \begin{align*}
        \left( \sum_{k \in \ZZ} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'} &\leq  \left( \sum_{k \in \ZZ} a_k^q \right)^{(p-1)/q} \left( \sum_{k \in \ZZ} a_{k-l}^q \right)^{(q-p)/q}\\
        &\lesssim_{p,q} \| f \|_{p,q}^{q-1} \lesssim_{p,q} 1. \qedhere
    \end{align*}
\end{proof}

\begin{remark}
    This technique shows that if $f = \sum f_k$, where $f_k$ is a quasi-step function with measure $W_k$ and height $2^{ck}$, then we can find $m$ such that $cm > 1$, and then consider the $m$ functions $f^1, \dots, f^m$, where $f_i = \sum f_{km + i}$. Then the functions $f_{km + i}$ have heights which are separated by powers of two, and so the quasi-triangle inequality implies
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_m \sum_{i = 1}^m \| f^i \|_{p,q}\\
        &\lesssim_{p,q} \sum_{i = 1}^m \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\lesssim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}
    \end{align*}
    %
    On the other hand,
    %
    \begin{align*}
        \| f \|_{p,q} &\gtrsim \max_{1 \leq i \leq m} \| f^i \|_{p,q}\\
        &\sim \max_{1 \leq i \leq m} \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\gtrsim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}.
    \end{align*}
    %
    Thus the dyadic layer cake decomposition still works in this setting.
\end{remark}

We remark that if $1 < p < \infty$ and $1 \leq q \leq \infty$, then for each $f \in L^{p,q}$, the value
%
\[ \sup \left\{ \int fg : \| g \|_{p',q'} \leq 1 \right\} \]
%
gives a norm on $L^{p,q}(X)$ which is comparable with the $L^{p,q}$ norm. In particular, this implies that for $p > 1$ and $q \geq 1$,
%
\[ \| f_1 + \dots + f_N \|_{p,q} \lesssim_{p,q} \| f_1 \|_{p,q} + \dots + \| f_N \|_{p,q}, \]
%
so that the triangle inequality has constants independent of $N$. We can also use a layer cake decomposition to get a version of the Stein-Weiss inequality for Lorentz norms.

\begin{theorem}
	For each $1 < q < \infty$, there is $\alpha(q) > 0$ such that for any functions $f_1, \dots, f_N$,
	%
	\[ \| f_1 + \dots + f_N \|_{1,q} \lesssim (\log N)^{\alpha(q)} \left( \| f_1 \|_{1,q} + \dots + \| f_N \|_{1,q} \right). \]
\end{theorem}
\begin{proof}
	For values $A$ and $B$ in this argument, we write $A \lessapprox B$ if there exists $\alpha$ such that $A \lesssim (\log N)^\alpha B$. Given $f_1, \dots, f_N$, write $f_i = \sum_{j = -\infty}^\infty f_{ij}$, where $f_{ij}$ has width $W_{ij}$ and height $2^j$. If we assume, without loss of generality, that $\| f_1 \|_{1,q} + \dots + \| f_N \|_{1,q} = 1$, then
	%
	\[ \sum_{i = 1}^N \left( \sum_{j = -\infty}^\infty (2^j W_{ij})^q \right)^{1/q} \lesssim_q 1 \]
	%
	Thus we want to show $\| f_1 + \dots + f_N \|_{1,q} \lessapprox_q 1$. Our first goal is to upper bound the measure of the set
	%
	\[ E = \{ x: 2^{k-1} < |f_1(x) + \dots + f_N(x)| \leq 2^k  \} \]
	%
	The measure of the set $E$ is upper bounded by the measure of the set
	%
	\[ E' = \left\{ x: 2^{k-2} < \left|\sum_{j = k - \lg(N)}^k f_{1j}(x) + \dots + f_{Nj}(x) \right| \leq 2^{k+1} \right\} \]
	%
	Applying the usual Stein-Weiss inequality, we have
	%
	\[ \left\| \sum_{i = 1}^N \sum_{j = k - \lg N}^k f_{ij} \right\|_{1,\infty} \lessapprox \sum_{i = 1}^N \sum_{j = k - \lg N}^k \| f_{ij} \|_{1,\infty} \lesssim \sum_{i = 1}^N \sum_{j = k - \lg N}^k \| f_{ij} \|_{1,\infty} \lesssim_q \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \]
	%
	Thus we conclude
	%
	\[ |E'| \lessapprox_q 2^{-k} \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \]
	%
	This implies that
	%
	\[ \| f_1 + \dots + f_N \|_{1,q} \lessapprox_q \left( \sum_{k = -\infty}^\infty \left( \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \right)^q \right)^{1/q}. \]
	%
	Applying Minkowski's inequality, we conclude
	%
	\begin{align*}
		\left( \sum_{k = -\infty}^\infty \left( \sum_{i = 1}^N \sum_{j = k - \lg N}^k W_{ij} 2^j \right)^q \right)^{1/q} &\lesssim \sum_{i = 1}^N \left( \sum_{k = -\infty}^\infty \left( \sum_{j = k - \lg N}^k W_{ij 2^j} \right)^q \right)^{1/q}\\
		&\lessapprox \sum_{i = 1}^N \left( \sum_{k = -\infty}^\infty \sum_{j = k - \lg N}^k W_{ij}^q 2^{qj} \right)^{1/q}\\
		&\lessapprox \sum_{i = 1}^N \left( \sum_{j = -\infty}^\infty W_{ij}^q 2^{qj} \right)^{1/q} \lesssim 1. \qedhere
	\end{align*}
\end{proof}

\begin{comment}

\section{Normability of the Lorentz Spaces}

Though the Lorentz norms do not satisfy the triangle inequality, the space $L^{p,q}(X)$ is still a `Banach-able' space when $p > 1$, and $q \geq 1$. First off, the standard proof shows the norm gives a complete quasimetric, since a Cauchy sequence in the $L^{p,q}$ norm converges to a function almost everywhere, which is easily verified to have finite $L^{p,q}$ norm. The easiest way to define a norm is to through the decreasing rearrangement.

\begin{lemma}
    For any measurable set $E$,
    %
    \[ \int_E |f(x)|\; dx \leq \int_0^{|E|} f^*(t)\; dt. \]
    %
    and
    %
    \[ \int_{\{ |f(x)| > t \}} |f(x)|\; dx = \int_0^{F(t)} f^*(t)\; dt. \]
\end{lemma}
\begin{proof}
    If $g \leq f$, $g^* \leq f^*$. Thus $(\chi_E f)^* \leq f^*$, so
    %
    \[ \int_E |f(x)|\; dx = \int \chi_E |f(x)| = \int_0^\infty (\chi_E f)^*(t)\; dt = \int_0^{|E|} (\chi_E f)^*(t)\; dt \leq \int_0^{|E|} f^*(t)\; dt. \]
    %
    On the other hand, $(\chi_E f)^* = f^*$ when $E = \{ |f(x)| > t \}$, which gives the second equality.
\end{proof}

For a function $f$ and $t > 0$, we define a family of averages
%
\[ m(t) = \frac{1}{t} \int_0^t f^*(t)\; dt. \]
%
For any fixed $t > 0$, the map $f \mapsto m(t)$ is a norm. Provided our measure space is non-atomic, we have
%
\[ m(t) = \sup_{|E| \leq t} \int_E |f(x)|\; d\mu. \]
%
We define
%
\[ \vvvert f \vvvert_{p,q} = \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} \]
and
%
\[ \vvvert f \vvvert_{p,\infty} = \sup t^{1/p} m(t). \]
%
For $q \geq 1$, each of these functions is a norm, simply because the function $m$ is a norm. On the other hand, since $f^*$ is decreasing, $f^*(t) \leq m(t)$ for all $t$, which shows $\vvvert f \vvvert_{p,q} \geq \| f \|_{p,q}$. If $p = 1$ and $q < \infty$, if $\vvvert f \vvvert_{1,q} < \infty$, then $f = 0$, so these norms are effectively useless. If $q = \infty$, then
%
\[ \vvvert f \vvvert_{1,\infty} = \| f^* \|_{L^1[0,\infty)} = \| f \|_1, \]
%
and therefore doesn't measure the correct norm. But in all other cases, i.e. for $p > 1$ and $q \geq 1$, the norm is comparable to the $L^{p,q}$ norm.

\begin{theorem}
    If $p > 1$,
    %
    \[ \vvvert f \vvvert_{p,q} \leq \frac{p}{p-1} \| f \|_{p,q}. \]
\end{theorem}
\begin{proof}
    We utilize a \emph{Hardy's inequality} technique, which shows that the $L^p$ norm of the averages of a function are comparable to the $L^p$ norm of the function. Applying Minkowski's integral inequality, we conclude that
    %
    \begin{align*}
        \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} &= \left( \frac{q}{p} \int_0^\infty \left( \int_0^1 t^{1/p} f^*(ts)\; ds \right)^q\; \frac{dt}{t} \right)^{1/q}\\
        &\leq \int_0^1 \left( \int_0^\infty \frac{q}{p} (t^{1/p} f^*(ts))^q\; \frac{dt}{t} \right)^{1/q}\; ds\\
        &\leq \left( \int_0^1 s^{- 1/p}\; ds \right) \left( \frac{q}{p} \int_0^\infty (t^{1/p} f^*(t))^q\; \frac{dt}{t} \right)^{1/q}\\
        &\leq \frac{1}{1 - 1/p} \| f \|_{p,q} = \frac{p}{p - 1} \| f \|_{p,q}.
    \end{align*}
    %
    For $q = \infty$, and $t > 0$, we have
    %
    \begin{align*}
        t^{1/p} m(t) &= t^{1/p - 1} \int_0^t f^*(t)\\
        &\leq (\sup_{s > 0} s^{1/p} f^*(s)) t^{1/p - 1} \int_0^t t^{-1/p}\\
        &= \frac{1}{1 - 1/p} \| f \|_{p,\infty} = \frac{p}{p-1} \| f \|_{p,\infty}.
    \end{align*}
    %
    since $t$ was arbitrary, this gives the required bound.
\end{proof}

\end{comment}

\section{Mixed Norm Spaces}

Given two measure spaces $X$ and $Y$, we can form the product measure space $X \times Y$. If we have a norm space $V$ of functions on $X$, with norm $\| \cdot \|_V$ and a norm space $W$ of functions on $Y$, with norm $\| \cdot \|_W$, we can consider a `product norm'; for each function $f$ on $X \times Y$, we can consider the function $y \mapsto \| f(\cdot,y) \|_V$, and take the norm of this function over $Y$, i.e. $\| \| f(\cdot,y) \|_V \|_W$. The most important case of this process is where we fix $0 < p,q \leq \infty$, and consider
%
\[ \| f \|_{L^p(X) L^q(Y)} = \left( \int \left( \int |f(x,y)|^p \; dx \right)^{q/p}\; dy \right)^{1/q}. \]
%
Similarly, we can define $\| f \|_{L^q(Y) L^p(X)}$. We have a duality theory here; for each $1 \leq p,q < \infty$ and any $f$ with $\| f \|_{L^p(X) L^q(Y)} < \infty$, the standard $L^p$ and $L^q$ duality gives
%
\[ \| f \|_{L^p(X) L^q(Y)} = \sup \left\{ \int_{X \times Y} f(x,y) h(x,y)\; dx\;dy : \| h \|_{L^{p^*}(X) L^{q^*}(Y)} \leq 1 \right\}. \]
%
It is often important to interchange norms, and we find the biggest quantity obtained by interchanging norms is always obtained with the largest exponents on the inside.

\begin{theorem}
	If $q \geq p \geq 1$, $\| f \|_{L^p(X) L^q(Y)} \leq \| f \|_{L^q(Y) L^p(X)}$.
\end{theorem}
\begin{proof}
  If $p = q$, then the Fubini-Tonelli theorem implies that
  %
  \[ \| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)}. \]
  %
  If $p = 1$, then this result is precisely the Minkowski inequality. We now apply complex interpolation to obtain the result in general. In fact, a simple variation of the proof of Riesz-Thorin using the duality established above gives the result.
\end{proof}

Two special cases are that pointwise maxima dominate individual maxima
%
\[ \sup_n \| f_n \|_{L^p(X)} \leq \left\| \sup_n f_n \right\|_{L^p(X)} \]
%
and that we have the triangle inequality
%
\[ \left\| \sum_n f_n \right\|_{L^p(X)} \leq \sum_n \| f_n \|_{L^p(X)} \]
%
for $p \geq 1$.

It turns out that if $q > p$ and $\| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)}$, then $|f|$ is a tensor product. Thus switching mixed norms is likely only efficient if the functions we are working with are close to tensor products.

\begin{theorem}
  Suppose $q > p$, $f$ is a function on $X \times Y$, and
  %
  \[ \| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^q(Y) L^p(X)} < \infty. \]
  %
  Then there exists $f_1(x)$ and $f_2(y)$ such that for any $x \in X$ and $y \in Y$, $|f(x,y)| = |f_1(x)| |f_2(y)|$.
\end{theorem}
\begin{proof}
  Expanding this equation out, we conclude
  %
  \[ \left( \int_Y \left( \int_X |f(x,y)|^p\; dx \right)^{q/p}\; dy \right)^{1/q} = \left( \int_X \left( \int_Y |f(x,y)|^q\; dy \right)^{p/q}\; dx \right)^{1/p}. \]
  %
  Setting $g(x,y) = |f(x,y)|^p$, we see that Minkowski's integral inequality is tight for $g$, i.e.
  %
  \[ \left( \int_Y \left( \int_X |g(x,y)|\; dx \right)^{q/p}\; dy \right)^{p/q} = \left( \int_X \left( \int_Y |g(x,y)|^{q/p}\; dy \right)^{p/q}\; dx \right). \]
  %
  Thus it suffices to show that to show the theorem for $p = 1$ and $q > 1$. Recall the standard proof of Minkowski's inequality, i.e. that by H\"{o}lder's inequality
  %
  \begin{align*}
    \int_Y \left( \int_X |f(x,y)|\; dx \right)^p\; dy &= \int_X \left[ \int_Y |f(x_1,y)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^{p-1}\; dy \right]\; dx_1\\
    &\leq \int_X \left[ \left( \int_Y |f(x_1,y)|^p\; dy \right)^{1/p} \left( \int_Y \left( \int_X |f(x_2,y)|\; dx_2 \right)^{(p-1)p^*}\; dy \right)^{1/p^*} \right]\; dx_1 \\
    &= \left[ \int_X \left( \int_Y |f(x_1,y)|^p\; dy \right)^{1/p}\; dx_1 \right] \left[ \int_Y \left( \int_X |f(x_2,y)|\; dx_2 \right)^p \right]^{1/p^*}.
  \end{align*}
  %
  and rearranging gives Minkowski's inequality. If this inequality is tight, then our application of H\"{o}lder's inequality is tight for almost every $x_1 \in X$. Since $\int |f(x_2,y)|\; dx_2 \neq 0$ for all $y$ unless $f = 0$, it follows that there exists $\lambda(x_1)$ for almost every $x_1 \in X$ such that for almost every $y \in Y$,
  %
  \[ |f(x_1,y)|^p = |\lambda(x_1)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^{p^*(p-1)} = |\lambda(x_1)| \left( \int_X |f(x_2,y)|\; dx_2 \right)^p. \]
  %
  Setting $f_1(x) = |\lambda(x)|^{1/p}$ and $f_2(y) = \int_X |f(x,y)|\; dx$ thus completes the proof.
\end{proof}

TODO: Show that if $q < p$ and $\| f \|_{L^p(X) L^q(Y)} = \| f \|_{L^p(Y) L^q(X)} < \infty$, then $|f|$ is a tensor product. Thus interchanging norms is only a good idea if we think the worst case example in a problem is a tensor-product like function.

\section{Orlicz Spaces}

To develop the class of Orlicz spaces, we note that if $\| f \|_p \leq 1$, and we set $\Phi(t) = t^p$, then
%
\[ \int \Phi \left( |f(x)| \right)\; dx = 1. \]
%
More generally, given any function $\Phi: [0,\infty) \to [0,\infty)$, we might ask if we can define a norm $\| \cdot \|_\Phi$ such that if $\| f \|_\Phi \leq 1$, then
%
\[ \int \Phi \left( |f(x)| \right)\; dx = 1. \]
%
Since a norm would be homogenous, this would imply that if $\| f \|_\Phi \leq A$, then
%
\[ \int \Phi \left( \frac{|f(x)|}{A} \right)\; dx \leq 1. \]
%
If we want these norms to be monotone, we might ask that if $A < B$, then
%
\[ \int \Phi \left( \frac{|f(x)|}{B} \right)\; dx \leq \int \Phi \left( \frac{|f(x)|}{A} \right), \]
%
and the standard way to ensure this is to ask the $\Phi$ is an increasing function. To deal with the property that $\| 0 \| = 0$, we set $\Phi(0) = 0$. In order for $\| \cdot \|_\Phi$ to be a norm, the set of functions $\{ f : \| f \|_\Phi \leq 1 \}$ needs to be convex, and the standard way to obtain this is to assume that $\Phi$ is convex.

In short, we consider an increasing, convex function $\Phi$ with $\Phi(0) = 0$. We then define
%
\[ \| f \|_\Phi = \inf \left\{ A > 0 : \int \Phi \left( \frac{|f(x)|}{A} \right)\; dx \leq 1 \right\}. \]
%
This function is a norm on the space of all $f$ with $\| f \|_\Phi < \infty$. It is easy to verify that $\| f \|_\Phi = 0$ if and only if $f = 0$ almost everywhere, and that $\| \alpha f \|_\Phi = |\alpha| \| f \|_\Phi$. To justify the triangle inequality, we note that if
%
\[ \int \Phi \left( \frac{|f(x)|}{A} \right) \leq 1 \quad\text{and} \quad \int \Phi \left( \frac{|f(x)|}{B} \right) \leq 1, \]
%
then applying convexity gives
%
\begin{align*}
    \int \Phi \left( \frac{|f(x) + g(x)|}{A + B} \right) &\leq \int \Phi \left( \frac{|f(x)| + |g(x)|}{A + B} \right)\\
    &\leq \int \left( \frac{A}{A + B} \right) \Phi \left( \frac{|f(x)|}{A} \right) + \left( \frac{B}{A + B} \right) \Phi \left( \frac{|g(x)|}{B} \right) \leq 1.
\end{align*}
%
Thus we obtain the triangle inequality.

The spaces $L^p(X)$ for $p \in [1,\infty)$ are Orlicz spaces with $\Phi(t) = t^p$. The space $L^\infty(X)$ is not really an Orlicz space, but it can be considered as the Orlicz function with respect to the `convex' function
%
\[ \Phi(t) = \begin{cases} \infty & t > 1, \\ t & t \leq 1. \end{cases} \]
%
More interesting examples of Orlicz spaces include
%
\begin{itemize}
    \item $L \log L$, given by the Orlicz norm induced by $\Phi(t) = t \log(2 + t)$.
    \item $e^L$, defined with respect to $\Phi(t) = e^t - 1$.
    \item $e^{L^2}$, defined with respect to $\Phi(t) = e^{t^2} - 1$.
\end{itemize}
%
One should not think too hard about the constants in the functions defined above, which are included to make $\Phi(0) = 0$. When we are dealing with a finite measure space, they are irrelevant.

\begin{lemma}
  If $\Phi(x) \lesssim \Psi(x)$ for all $x$, then $\| f \|_{\Phi(L)} \lesssim \| f \|_{\Psi(L)}$. If $X$ is finite, and $\Phi(x) \lesssim \Psi(x)$ for sufficiently large $x$, then $\| f \|_{\Phi(L)} \lesssim \| f \|_{\Psi(L)}$.
\end{lemma}
\begin{proof}
  The first proposition is easy, and we now deal with the finite case. We note that the condition implies that for each $\varepsilon > 0$, there exists $C_\varepsilon$ such that $\Phi(x) \leq C_\varepsilon \Psi(x)$ if $|x| \geq \varepsilon$. Assume that $\| f \|_{\Psi(L)} \leq 1$, so that
  %
  \[ \int \Psi(|f(x)|)\; dx \leq 1. \]
  %
  Then convexity implies that for each $A > 0$,
  %
  \[ \int \Psi \left( \frac{|f(x)|}{A} \right) \leq \frac{1}{A}. \]
  %
  Thus
  %
  \begin{align*}
    \int \Phi\left( \frac{|f(x)|}{A} \right)\; dx &\leq \Phi(\varepsilon) |X| + C_\varepsilon \int \Psi \left( \frac{|f(x)|}{A} \right)\\
    &\lesssim \Phi(\varepsilon) |X| + \frac{C_\varepsilon}{A}.
  \end{align*}
  %
  If $\Phi(\varepsilon) \leq 2/|X|$, and $A \geq 2C_\varepsilon$, then we conclude that
  %
  \[ \int \Phi\left( \frac{|f(x)|}{A} \right)\; dx \leq 1. \]
  %
  Thus $\| f \|_{\Phi(L)} \lesssim 1$.
\end{proof}

The Orlicz spaces satisfy an interesting duality relation. Given a function $\Phi$, which we assume is \emph{superlinear}, in the sense that $\Phi(x)/x \to \infty$ as $x \to \infty$, define it's \emph{Young dual}, for each $y \in [0,\infty)$, by
%
\[ \Psi(y) = \sup \{ xy - \Phi(x) : x \in [0,\infty) \}. \]
%
Then $\Psi$ is the smallest function such that $\Phi(x) + \Psi(y) \geq xy$ for each $x,y$. This quantity is finite for each $y$ because $\Phi$ is superlinear; for each $y \geq 0$, there exists $x(y)$ such that $\Phi(x(y)) \geq xy$, and thus the maximum of $xy - \Phi(x)$ is attained for $x \leq x(y)$. In particular, since $\Phi$ is continuous, the supremum is actually attained. Conversely, for each $x_0 \in [0,\infty)$, convexity implies there exists a largest $y$ such that the line $y(x - x_0) + f(x_0) \leq f(x)$ for all $x \in [0,\infty)$. This means that $\Psi(y) = x_0y - x_0$.

We note also that $\Psi(0) = 0$, and $\Psi$ is increasing. Most importantly, the function is convex. Given any $y,z \in [0,\infty)$, and any $x \in [0,\infty)$,
%
\begin{align*}
  x (\alpha y + (1 - \alpha) z) - \Phi(x) &\leq \alpha(xy - \Phi(x)) + (1 - \alpha)(xz - \Phi(x))\\
  &\leq \alpha \Psi(y) + (1 - \alpha) \Psi(z).
\end{align*}
%
Taking infimum over all $x$ gives convexity. The function $\Psi$ is also superlinear, since for any $x \in [0,\infty)$,
%
\[ \lim_{y \to \infty} \frac{\Psi(y)}{y} \geq \lim_{y \to \infty} \frac{xy - \Phi(x)}{y} = x. \]
%
In particular, we can consider the Young dual of $\Psi$.

\begin{lemma}
  If $\Psi$ is the Young dual of $\Phi$, then $\Phi$ is the Young dual of $\Psi$.
\end{lemma}
\begin{proof}
  $\Pi$ is the smallest function such that $\Pi(x) + \Psi(y) \geq xy$. Since $\Phi(x) + \Psi(y) \geq xy$ for each $x$ and $y$, we conclude that $\Pi(x) \leq \Phi(x)$ for each $x$. For each $x$, there exists $y$ such that $\Psi(y) = yx - \Phi(x)$. But this means that $\Phi(x) = yx - \Psi(y) \leq \Pi(x)$.
\end{proof}

Given the Orlicz space $\Phi(L)$ for superlinear $\Phi$, we can consider the Orlicz space $\Psi(L)$, where $\Psi$ is the Young dual of $\Phi$. The inequality $xy \leq \Phi(x) + \Psi(y)$, then
%
\[ |f(x) g(x)| \leq \Phi(|f(x)|) + \Psi(|g(x)|), \]
%
so if $\| f \|_{\Phi(L)}, \| g \|_{\Psi(L)} \leq 1$, then
%
\[ \left| \int f(x) g(x) \right| \leq \int |f(x)| |g(x)| \leq \int \Phi(|f(x)|) + \int \Psi(|g(x)|) \leq 2. \]
%
Thus in general, we have
%
\[ \left| \int f(x) g(x) \right| \leq 2 \| f \|_{\Phi(L)} \| g \|_{\Psi(L)}, \]
%
a form of H\"{o}lder's inequality. The duality between convex functions extends to a duality between the Orlicz spaces.

\begin{theorem}
  For any superlinear $\Phi$ with Young dual $\Psi$,
  %
  \[ \| f \|_{\Phi(L)} \sim \sup \left\{ \int fg : \| g \|_{\Psi(L)} \leq 1 \right\}. \]
\end{theorem}
\begin{proof}
  Without loss of generality, assume $\| f \|_{\Phi(L)} = 1$. The version of H\"{o}lder's inequality proved above shows that
  %
  \[ \| f \|_{\Phi(L)} \lesssim 1. \]
  %
  Conversely, for each $x$, we can find $g(x)$ such that $f(x) g(x) = \Phi(|f(x)|) + \Psi(|g(x)|$. Provided $\| g \|_{\Psi(L)} < \infty$, we have
  %
  \[ \int fg = \int \Phi(|f(x)|) + \int \Psi(|g(x)|) \geq 1 + \| g \|_{\Psi(L)}. \]
  %
  Assuming $f \in L^\infty(X)$, we may choose $g \in L^\infty(X)$. For such a choice of function, $\| g \|_{\psi(L)} < \infty$, which implies the result. Taking an approximation argument then gives the result in general.
\end{proof}

Let us now consider some examples of duality.

\begin{example}
  If $\Phi(x) = x^p$, for $p \geq 1$, and $1 = 1/p + 1/q$, then it's Young dual $\Psi$ satisfies
  % q = p/(p-1)
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - x^p = y^{1 + q/p} / p^{q/p} - y^q / p^q = y^q [p^{-q/p} - p^{-q}].
  \end{align*}
  %
  Thus the Young dual corresponds, up to a constant, to the conjugate dual in the $L^p$ spaces.
\end{example}

\begin{example}
  Suppose $X$ has finite measure. If $\Phi(t) = e^t - 1$, then it's dual satisfies, for large $y$,
  %
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - (e^x - 1)\\
    &= y \log y - (y - 1) \sim y \log y.
  \end{align*}
  %
  This is comparable to $y \log (y + 2)$ for large $y$. Thus $L \log L$ is dual to $e^L$.
\end{example}

\begin{example}
  Suppose $X$ has finite measure. If $\Phi(x) = e^{x^2} - 1$, then for $y \geq 2$,
  %
  \begin{align*}
    \Psi(y) &= \sup_{x \geq 0} xy - (e^{x^2} - 1) \sim y \log(y/2)^{1/2}.
  \end{align*}
  %
  Thus the dual of $e^{L^2}$ is the space $L (\log L)^{1/2}$.
\end{example}

There is a generalization of both the Lorentz spaces and the Orlicz spaces, known as the Lorentz-Orlicz spaces, but these come up so rarely in analysis that we do not dwell on these norms.














\chapter{Interpolation Theory}

One of the most fundamental tools in the `hard style' of mathematical analysis, involving explicit quantitative estimates on quantities that arises in basic methods of mathematics, is the theory of interpolation. The main goal of interpolation is to take two estimates, and blend them together to form a family of intermediate estimates. Often each estimate will focus on one component of the problem at hand (an estimate in terms of the decay of the function at $\infty$, an estimate involving the growth of the derivative, or the low frequency the function is, etc). By interpolating, we can optimize and obtain an estimate which simultaneously takes into account multiple features of the function. As should be expected, our main focus will be on the \emph{interpolation of operators}.

\section{Convex Interpolation}

The most basic way to interpolate is using the notion of convexity. Given two inequalities $A_0 \leq B_0$ and $A_1 \leq B_1$, for any parameter $0 \leq \theta \leq 1$, if we define the additive weighted averages $A_\theta = (1 - \theta) A_0 + \theta A_1$ and $B_\theta = (1 - \theta) B_0 + \theta B_1$, then we conclude $A_\theta \leq B_\theta$ for all $\theta$. Similarily, we can consider the weighted multiplicative averages $A_\theta = A_0^{1 - \theta} A_1^\theta$ and $B_\theta = B_0^{1 - \theta}B_1^\theta$, in which case we still have $A_\theta \leq B_\theta$. Note that the additive averages are obtained by taking the unique linear function between two values, and the multiplicative averages are obtained by taking the unique log-linear function between two values. In particular, if $A_\theta$ is defined to be any convex function, then $A_\theta \leq (1 - \theta) A_0 + \theta A_1$, and if $B_\theta$ is logarithmically convex, so that $\log B_\theta$ is convex, then $B_\theta \leq B_0^{1 - \theta} B_1^\theta$. Thus convexity provides us with a more general way of interpolating estimates, which is what makes this property so useful in analysis, enabling us to simplify estimates.

\begin{example}
    For a fixed, measurable function $f$, the map $p \mapsto \| f \|_p$ is a log convex function. This statement is precisely H\"{o}lder's inequality, since the inequality
    %
    \[ \| f \|_{\theta p + (1 - \theta) q} \leq \| f \|_p^\theta \| f \|_{q}^{1-\theta} \]
    %
    says
    %
    \[ \| |f|^{\theta p} |f|^{(1 - \theta) q} \|_1^{1/(\theta p + (1 - \theta) q)} \leq \| f^{\theta p} \|_{1/\theta}^{\theta} \| f^{(1-\theta)q} \|_{1/(1-\theta)}^{1-\theta} \]
    %
    which is precisely H\"{o}lder's inequality. Note this implies that if $p_0 < p_\theta < p_1$, then $L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X)$.
\end{example}

\begin{example}
    The weak $L^p$ norm is log convex, because if $F(t) \leq A_0^{p_0}/t^{p_0}$, and $F(t) \leq A_1^{p_1}/t^{p_1}$, then we can apply scalar interpolation to conclude that if $p_\theta = (1 - \alpha) p_0 + \alpha p_1$,
    %
    \[ F(t) \leq \frac{A_0^{(1 - \alpha) p_0}A_1^{\alpha p_1}}{t^{(1 - \alpha)p_0 + \alpha p_1}} = \frac{A_\theta^{p_\theta}}{t^{p_\theta}} \]
    %
    where $p_\theta$ is the harmonic weighted average between $p_0$ and $p_1$, and $A_\theta$ the geometric weighted average. Using this argument, interpolating slightly to the left and right of $p_\theta$, we can conclude that if $p_0 < p_\theta < p_1$, then $L^{p_0,\infty}(X) \cap L^{p_1,\infty}(X) \subset L^{p_\theta}(X)$.
\end{example}

\section{Complex Interpolation}

Another major technique to perform an interpolation is to utilize the theory of complex analytic functions to obtain estimates. The core idea of this technique is to exploit the maximum principle, which says that bounding an analytic function at its boundary enables one to obtain bounds everywhere in the domain of the function. The next result, known as Lindel\"{o}f's theorem, is one of the fundamental examples of the application of complex analysis.

\begin{theorem}[The Three Lines Lemma]
    If $f$ is a holomorphic function on the strip $S = \{ z : \text{Re}(z) \in [a,b] \}$ and there exists constants $A,B,\delta > 0$ such that for all $z \in S$,
    %
    \[ |f(z)| \leq Ae^{Be^{(\pi - \delta)|z|}}. \]
    %
    Then the function $M: [a,b] \to [0,\infty]$ given by
    %
    \[ M(s) = \sup_{s \in \RR} |f(s + it)| \]
    %
    is log convex on $[a,b]$.
\end{theorem}
\begin{proof}
    By a change of variables, we can assume that $a = 0$, and $b = 1$, and we need only show that if there are $A_0, A_1 > 0$ such that
    %
    \[ |f(it)| \leq A_0 \quad\text{and}\quad |f(1 + it)| \leq A_1 \quad \text{for all $t \in \RR$}, \]
    %
    then for any $s \in [a,b]$ and $t \in \RR$,
    %
    \[ |f(s + it)| \leq A_0^{1 - s} A_1^s. \]
    %
    By replacing $f(z)$ with the function $A_0^{1-z} A_1^z f(z)$, we may assume without loss of generality that $A_0 = A_1 = 1$, and we must show that $\| f \|_{L^\infty(S)} \leq 1$. If $|f(s + it)| \to 0$ as $|t| \to \infty$, then for large $N$, we can conclude that $|f(s + it)| \leq 1$ for $s \in [a,b]$ and $|t| \geq N$. But then the maximum principle entails that $|f(s + it)| \leq 1$ for $s \in [a,b]$ and $|t| \leq N$, which completes the proof in this case. In the general case, for each $\varepsilon > 0$, define
    %
    \[ u_\varepsilon(z) = \exp(- 2 \varepsilon \sin((\pi - \varepsilon) z + \varepsilon/2)). \]
    %
    Then if $z = s + it$,
    %
    \[ |u_\varepsilon(z)| = \exp(- \varepsilon [e^{(\pi - \varepsilon) t} + e^{-(\pi - \varepsilon) t}] \sin((\pi - \varepsilon) s + \varepsilon/2)), \]
    %
    So, in particular, $|u_\varepsilon(z)| \leq 1$, and there exists a constant $C$ such that if $z \in S$,
    %
    \[ |u_\varepsilon(z)| \leq e^{- C \varepsilon^2 e^{(\pi - \varepsilon) |z|}} \]
    %
    Note that if $\varepsilon < \delta$, then as $|\text{Im}(z)| \to \infty$,
    %
    \[ |f(z) u_\varepsilon(z)| \leq A e^{B e^{(\pi - \delta) |z|} - C \varepsilon^2 e^{(\pi - \varepsilon) |z|} } \to 0. \]
    %
    Applying the previous case to the function $|f(z) u_\varepsilon(z)|$, we conclude that for any $\varepsilon > 0$,
    %
    \[ |f(z)| \leq \frac{1}{|u_\varepsilon(z)|}. \]
    %
    Thus
    %
    \[ |f(z)| \leq \lim_{\varepsilon \to 0} \frac{1}{|u_\varepsilon(z)|} = 1, \]
    %
    which completes the proof.
\end{proof}

\begin{remark}
    The function $e^{-ie^{\pi i s}}$ shows that the assumption of the three lines lemma is essentially tight. In particular, this means there is no family of holomorphic functions $g_\varepsilon$ which decays faster than double exponentially, and pointwise approximates the identity as $\varepsilon \to 0$.
\end{remark}

\begin{remark}
    Similar variants can be used to show that if $f$ is a holomorphic function on an annulus, then the supremum over circles centered around the origin is log convex in the radius of the circle (a result often referred to as the three circles lemma).
\end{remark}

\begin{example}
    Here we show how we can use the three lines lemma to prove that the $L^p$ norms are log convex. If $f = \sum a_n \chi_{E_n}$ is a simple function, then the function
    %
    \[ g(s) = \int |f|^s = \sum |a_n|^s |E_n| \]
    %
    is analytic in $s$, and satisfies the growth condition of the three lines lemma because each term of the sum is exponential in growth. Since $|g(s)| \leq |g(\sigma)|$, the three lines lemma implies that $g$ is log convex on the real line. By normalizing the function $f$ and the underlying measure, given $p_0$, $p_1$, we may assume $\| f \|_{p_0} = \| f \|_{p_1} = 1$, and it suffices to prove that $\| f \|_{p_\theta} \leq 1$ for all $p_\theta \in [p_0, p_1]$. But the log convexity of $g$ guarantees this is true, since $|g(p)| = \| f \|_p^p$. A standard limiting argument then gives the inequality for all functions $f$.
\end{example}

\begin{example}
    Let $f$ be a holmomorphic function on a strip $S = \{ z : \text{Re}(z) \in [a,b] \}$, such that if $z = a + it$, or $z = b + it$, for some $t \in \RR$,
    %
    \[ |f(z)| \leq C_1 (1 + |z|)^\alpha. \]
    %
    Then there exists a constant $C'$ such that for any $z \in S$,
    %
    \[ |f(z)| \leq C_2 (1 + |z|)^\alpha. \]
\end{example}
\begin{proof}
    The function
    %
    \[ g(z) = \frac{f(z)}{(1 + z)^\alpha} \]
    %
    is holomorphic on $S$, and if $z = a + it$ or $z = b + it$,
    %
    \[ |g(z)| \leq \frac{C_1 (1 + |z|)^\alpha}{|1 + z|^\alpha} \lesssim 1. \]
    %
    Thus the three lines lemma implies that $|g(z)| \lesssim 1$ for all $z \in S$, so
    %
    \[ |f(z)| \lesssim |1 + z|^\alpha \lesssim (1 + |z|)^\alpha. \qedhere \]
\end{proof}

\section{Interpolation of Operators}

A major part of modern harmonic analysis is the study of operators, i.e. maps from function spaces to other function spaces. We are primarily interested in studying \emph{linear operators}, i.e. operators $T$ such that $T(f + g) = T(f) + T(g)$, and $T(\alpha f) = \alpha T(f)$, and also \emph{sublinear operators}, such that $|T(\alpha f)| = |\alpha| |T(f)|$ and $|T(f + g)| \leq |Tf| + |Tg|$. Even if we focus on linear operators, it is still of interest to study sublinear operators because one can study the \emph{uniform boundedness} of a family of operators $\{ T_k \}$ by means of the function $T^*(f)(x) = \max (T_k f)(x)$. This is the method of \emph{maximal functions}. Another important example are the $l^p$ sums
%
\[ (S^p f)(x) = \left( \sum |T_k(x)|^p \right). \]
%
These two examples are specific examples where we have a family of operators $\{ T_y \}$, indexed by a measure space $Y$, and we define an operator $S$ by taking $Sf$ to be the norm of $\{ T_y f \}$ in the variable $y$.

Here we address the most basic case of operator interpolation. As we vary $p$, the $L^p$ norms provide different ways of measuring the height and width of functions. Let us consider a simple example. Suppose that for an operator $T$, we have a bound
%
\[ \| Tf \|_{L^1(Y)} \leq \| f \|_{L^1(X)} \quad\text{and}\quad \| Tf \|_{L^\infty(Y)} \leq \| f \|_{L^\infty(X)}. \]
%
The first inequality shows that the width of $Tf$ is controlled by the width of $f$, and the second inequality says the height of $Tf$ is controlled by the height of $f$. If we take a function $f \in L^p(X)$, for some $p \in (1,\infty)$, then we have some control over the height of $f$, and some control of the width. In particular, this means we might expect some control over the width and height of $Tf$, i.e. for each $p$, a bound
%
\[ \| Tf \|_{L^p(Y)} \leq \| f \|_{L^p(X)}. \]
%
This is the idea of interpolation on the $L^p(X)$ spaces.

\section{Complex Interpolation of Operators}

The first theorem we give is the Riesz-Thorin theorem, which utilizes complex interpolation to give such a result. In the next theorem, we work with a linear operator $T$ which maps simple functions $f$ on a measure space $X$ to functions on a measure space $Y$. For the purposes of applying duality, we make the mild assumption that for each simple function $g$,
%
\[ \int |(Tf)(y)| |g(y)|\; dy < \infty. \]
%
Our goal is to obtain $L^p$ bounds on the function $T$. The Hahn-Banach theorem then guarantees that $T$ has a unique extension to a map defined on all $L^p$ functions.

\begin{theorem}[Riesz-Thorin]
    Let $p_0,p_1 \in (0,\infty]$ and $q_0,q_1 \in [1,\infty]$. Suppose that
    %
    \[ \| Tf \|_{L^{q_0}(Y)} \leq A_0 \| f \|_{L^{p_0}(X)} \quad \text{and} \| Tf \|_{L^{q_1}(Y)} \leq A_1 \| f \|_{L^{p_1}(X)}.  \]
    %
    Then for any $\theta \in (0,1)$, if
    %
    \[ 1/p_\theta = (1 - \theta)/p_0 + \theta/p_1 \quad\text{and}\quad 1/q_\theta = (1 - \theta)/q_0 + \theta/q_1, \]
    %
    then
    %
    \[ \| Tf \|_{L^{q_\theta}(Y)} \leq A_\theta \| f \|_{L^{p_\theta}(X)}, \]
    %
    where $A_\theta = A_0^{1 - \theta} A_1^\theta$.
\end{theorem}
\begin{proof}
    If $p_0 = p_1$, the proof follows by the log convexity of the $L^p$ norms of a function. Thus we may assume $p_0 \neq p_1$, so $p_\theta$ is finite in any case of interest. By normalizing the measures on both spaces, we may assume $A_0 = A_1 = 1$. By duality and homogeneity, it suffices to show that for any two simple functions $f$ and $g$ such that $\| f \|_{q_\theta} = \| g \|_{q_\theta^*} = 1$,
    %
    \[ \left| \int_Y (Tf) g\; dy \right| \leq 1. \]
    %
    Our challenge is to make this inequality complex analytic so we can apply the three lines lemma. We write $f = F_0^{1 - \theta} F_1^\theta a$, where $F_0$ and $F_1$ are non-negative simple functions with $\| F_0 \|_{L^{p_0}(X)} = \| F_1 \|_{L^{p_1}(X)} = 1$, and $a$ is a simple function with $|a(x)| = 1$. Similarily, we can write $g = G_0^{1-\theta} G_1^\theta b$. We now write
    %
    \[ H(s) = \int_Y T(F_0^{1 - s} F_1^s a) G_0^{1-s} G_1^s b\; dy. \]
    %
    Since all functions involved here are simple, $H(s)$ is a linear combination of positive numbers taken to the power of $1-s$ or $s$, and is therefore obviously an entire function in $s$. Now for all $t \in \RR$, we have
    %
    \[ \| F_0^{1-it} F_1^{it} a \|_{L^{p_0}(X)} = \| F_0 \|_{L^{p_0}(X)} = 1, \]
    \[ \| G_0^{1-it} G_1^{it} b \|_{L^{q_0}(Y)} = \| G_0 \|_{L^{q_0}(X)} = 1. \]
    %
    Therefore
    %
    \begin{align*}
      |H(it)| &= \left| \int T(F_0^{1 - it} F_1^{it} a) G_0^{1-it} G_1^{it} b\; dy \right| \leq 1.
    \end{align*}
    %
    Similarily, $|H(1 + it)| \leq 1$ for all $t \in \RR$. An application of Lindel\"{o}f's theorem implies $|H(s)| \leq 1$ for all $s$. Setting $s = \theta$ completes the argument.
\end{proof}

If, for each $p,q$, we let $F(1/p,1/q)$ to be the operator norm of a linear operator $T$ viewed as a map from $L^p(X)$ to $L^q(Y)$, then the Riesz-Thorin theorem says that $F$ is a log-convex function. In particular, the set of $(1/p,1/q)$ such that $T$ is bounded as a map from $L^p(X)$ to $L^q(Y)$ forms a convex set. If this is true, we often say $T$ is of \emph{strong type} $(p,q)$.

\begin{example}
  For any two integrable functions $f,g \in L^1(\RR^d)$, we can define an integrable function $f * g \in L^1(\RR^d)$ almost everywhere by the integral formula
  %
  \[ (f * g)(x) = \int f(y) g(x-y)\; dy. \]
  %
  If $f \in L^1(\RR^d)$ and $g \in L^p(\RR^d) \cap L^1(\RR^d)$, for some $p \geq 1$, then Minkowski's integral inequality implies
  %
  \begin{align*}
      \| f * g \|_p &= \left( \int |(f * g)(x)|^p\; dx \right)^{1/p} \leq \int \left( \int |f(y)g(x-y)|^p dx\; \right)^{1/p} dy\\
      &= \int |f(y)| \| g \|_{L^p(\RR^d)} = \| f \|_{L^1(\RR^d)} \| g \|_{L^p(\RR^d)}.
  \end{align*}
  %
  H\"{o}lder's inequality implies that if $f \in L^p(\RR^d)$ and $g \in L^q(\RR^d)$, where $p$ and $q$ are conjugates of one another, then
  %
  \begin{align*}
    \left| \int f(y) g(x-y)\; dy \right| \leq \int |f(y-x)| |g(x)| \leq \| f \|_{L^p(\RR^d)} \| g \|_{L^q(\RR^d)}.
  \end{align*}
    %
    Thus we have the bound
    %
    \[ \| f * g \|_{L^\infty(\RR^d)} \leq \| f \|_{L^p(\RR^d)} \| g \|_{L^q(\RR^d)}. \]
    %
    Now that these mostly trivial results have been proved, we can apply convolution. For each $f \in L^1(\RR^d) \cap L^p(\RR^d)$, we have a convolution operator $T: L^1(\RR^d) \to L^1(\RR^d)$ defined by $Tg = f * g$. We know that $T$ is of strong type $(1,p)$, and of type $(q,\infty)$, where $q$ is the harmonic conjugate of $p$, and $T$ has operator norm $1$ with respect to each of these types. But the Riesz Thorin theorem then implies that if $1/r = \theta + (1 - \theta)/q$, then $T$ is bounded as a map from $L^r(\RR^d)$ to $L^{p/\theta}(\RR^d)$ with operator norm one. Reparameterizing gives \emph{Young's convolution inequality}. Note that we never really used anything about $\RR^d$ here other than it's translational structure, and as such Young's inequality continues to apply in the theory of any modular locally compact group. In particular, the Haar measure $\mu$ on such a group is only defined up to a scalar multiple, and if we swap $\mu$ with $\alpha \mu$, for some $\alpha > 0$, then Young's inequality for this measure implies
    %
    \[ \lambda^{1 + 1/r} \| f * g \|_r = \lambda^{1/p + 1/q} \| f \|_p \| g \|_p \]
    %
    which is a good way of remembering that we must have $1 + 1/r = 1/p + 1/q$. 
\end{example}

\begin{example}
Let $X$ be a measure space with $\sigma$ algebra $\Sigma_0$, and let $\Sigma \subset \Sigma_0$ be a $\sigma$ finite sub $\sigma$ algebra. Then $L^2(X,\Sigma)$ is a closed subspace of $L^2(X,\Sigma_0)$, and so there is an orthogonal projection operator $\EE(\cdot|\Sigma): L^2(X,\Sigma_0) \to L^2(X,\Sigma)$, which we call the \emph{conditional expectation operator}. The properties of the projection operator imply that for any $f,g \in L^2(X, \Sigma_0)$,
%
\[ \int \EE(f|\Sigma) \overline{g} = \int f \overline{g} = \int \EE(f|\Sigma) \overline{\EE(g|\Sigma)}. \]
%
If $g \in L^2(X,\Sigma)$, then
%
\[ \int \EE(f|\Sigma) \overline{g} = \int f \overline{g}. \]
%
This gives a full description of $\EE(f|\Sigma)$. In particular, if $u \in L^\infty(X,\Sigma_0)$, then for each $g \in L^2(X,\Sigma)$
%
\[ \int \EE(uf|\Sigma) \overline{g} = \int f [u\overline{g}] = \int u \EE(f|\Sigma) \overline{g}. \]
%
Since this is true for all $g \in L^2(X,\Sigma)$, we find $\EE(uf|\Sigma) = u \EE(f|\Sigma)$. Moreover, if $0 \leq f \leq g$, then $\EE(f|\Sigma) \leq \EE(g|\Sigma)$. This is easy to see because if $f \geq 0$, and $F = \{ x : \EE(f|\Sigma) < 0 \}$, then if $|F| \neq 0$,
%
\[ 0 > \int \EE(f|\Sigma) \mathbf{I}_F = \int f \mathbf{I}_F \geq 0. \]
%
Thus $|F| = 0$, and so $\EE(f|\Sigma) \geq 0$ almost everywhere.

Like all other orthogonal projection operators, conditional expectation is a contraction in the $L^2$ norm, i.e. $\| \mathbf{E}(f|\Sigma) \|_{L^2(X)} \leq \| f \|_{L^2(X)}$. We now use interpolation to show that conditional expectation is strong $(p,p)$, for all $1 \leq p \leq \infty$. It suffices to prove the operator is strong $(1,1)$ and strong $(\infty,\infty)$. So suppose $f \in L^2(X,\Sigma_0) \cap L^\infty(X,\Sigma_0)$. If $|E| < \infty$, then $\mathbf{I}_E \in L^2(X)$, so
%
\[ |\EE(f|\Sigma)| \mathbf{I}_E = |\EE(\mathbf{I}_E f | \Sigma)| \leq \EE(\mathbf{I}_E |f| | \Sigma) \leq \| f \|_\infty \mathbf{E}(\mathbf{I}_E|\Sigma) = \| f \|_\infty \mathbf{I}_E. \]
%
Since $\Sigma$ is a sigma finite sigma algebra, we can take $E \to \infty$ to conclude $\| \EE(f|\Sigma) \|_\infty \leq \| f \|_\infty$. The case $(1,1)$ can be obtained by duality, since conditional expectation is self adjoint, or directly, since if $f \in L^1(X,\Sigma_0) \cap L^2(X,\Sigma_0)$, then for any set $E \in \Sigma$ with $|E| < \infty$,
%
\[ \int |\EE(f|\Sigma)| \mathbf{I}_E \leq \int \EE(|f||\Sigma) \mathbf{I}_E = \int_E |f| \mathbf{I}_E \leq \| f \|_1. \]
%
Since $\Sigma$ is $\sigma$ finite, we can take $E \to \infty$ to conclude $\| \EE(f|\Sigma) \|_1 \leq \| f \|_1$. Thus the Riesz interpolation theorem implies that for each $1 \leq p \leq \infty$, $\| \EE(f|\Sigma) \|_p \leq \| f \|_p$.

Since $L^2(X,\Sigma_0)$ is dense in $L^p(X,\Sigma_0)$ for all $1 \leq p < \infty$, there is a unique extension of the conditional expectation operator from $L^p(X,\Sigma_0)$ to $L^p(X,\Sigma_0)$. For $p = \infty$, there are infinitely many extensions of the conditional expectation operator from $L^\infty(X,\Sigma_0)$ to $L^\infty(X,\Sigma_0)$. However, there is a \emph{unique} extension such that for each $f \in L^2(\Sigma_0)$ and $g \in L^\infty(\Sigma)$, $\EE(fg|\Sigma) = g \EE(f|\Sigma)$. This is because for any $E \in \Sigma$ with $|E| < \infty$, $\EE(f \mathbf{I}_E | \Sigma) = \mathbf{I}_E \EE(f|\Sigma)$ is uniquely defined since $f \mathbf{I}_E \in L^2(\Sigma_0)$, and taking $E \to \infty$ by $\sigma$ finiteness.

A simple consequence of the uniform boundedness of these operators on the various $L^p$ spaces is that if $\Sigma_1, \Sigma_2, \dots$ are a family of $\sigma$ algebras, and $\Sigma_\infty$ is the smallest $\sigma$ algebra containing all sets in $\bigcup_{i = 1}^\infty \Sigma_i$, then for each $1 \leq p < \infty$, and for each $f \in L^p(\Sigma_0)$, $\lim_{i \to \infty} \EE(f|\Sigma_i) = \EE(f|\Sigma_\infty)$. This is because the operators $\{ \EE(\cdot|\Sigma_i) \}$ are uniformly bounded. The limit equation holds for any simple function $f$ composed of sets in $\bigcup_{i = 1}^\infty \Sigma_i$, and a $\sigma$ algebra argument can then be used to show this family of simple functions is dense in $L^p(\Sigma_0)$.
\end{example}

It was an important observation of Elias-Stein that complex interpolation can be used not only with a single operator $T$, but with an `analytic family' of operators $\{ T_s \}$, one for each $s$, such that for each pair of simple functions $f$ and $g$, the function
%
\[ \int (T_s f)(y) g(y) \]
%
is analytic in $s$. Thus bounds on $T_{0+it}$ and $T_{1 + it}$ imply intermediary bounds on all other operators, provided that we still have at most doubly exponential growth. The next theorem gives an example application.

\begin{theorem}[Stein-Weiss Interpolation Theorem]
  Let $T$ be a linear operator, and let $w_0, w_1: X \to [0,\infty)$ and $v_0, v_1 : Y \to [0,\infty)$ be weights which are integrable on every finite-measure set. Suppose that
  %
  \[ \| Tf \|_{L^{q_0}(X,v_0)} \leq A_0 \| f \|_{L^{p_0}(X,w_0)}\quad\text{and}\quad \| Tf \|_{L^{q_1}(X,v_1)} \leq A_1 \| f \|_{L^{p_1}(X,w_0)}. \]
  %
  Then for any $\theta \in (0,1)$,
  %
  \[ \| Tf \|_{L^{q_\theta}(X,v_\theta)} \leq A_\theta \| f \|_{L^{p_\theta}(X,w_\theta)}, \]
  %
  where $w_\theta = w_0^{1-\theta} w_\theta$ and $v_\theta = v_0^{1-\theta} v_1^\theta$.
\end{theorem}
\begin{proof}
  Fix a simple function $f$ with $\| f \|_{L^{p_\theta}(X,w_\theta)}$. We begin with some simplifying assumptions. A monotone convergence argument, replacing $w_i(t)$ with
  %
  \[ w_i'(y) = \begin{cases} w_i(y) &: \varepsilon \leq w_i(t) \leq 1/\varepsilon, \\ 0 &: \text{otherwise}, \end{cases} \]
  %
  and then taking $\varepsilon \to 0$, enables us to assume without loss of generality that $w_0$ and $w_1$ are both bounded from below and bounded from above. Truncating the support of $Tf$ enables us to assume that $Y$ has finite measure. Since $f$ has finite support, we may also assume without loss of generality that $X$ has finite support, and by applying the dominated convergence theorem we may replace the weights $v_i$ with
  %
  \[ v_i'(x) = \begin{cases} v_i(x) &: \varepsilon \leq v_i(x) \leq 1/\varepsilon, \\ 0 &: \text{otherwise}, \end{cases} \]
  %
  and then take $\varepsilon \to 0$. Thus we can assume that the $v_i$ are bounded from above and below. Restricting to the support of $X$, we can also assume $X$ has finite measure.

  For each $s$, consider the operator $T_s$ defined by
  %
  \[ T_s f = w_0^{\frac{1-s}{q_0}} w_1^{\frac{s}{q_1}} T \left( f v_0^{- \frac{1-s}{p_0}} v_1^{-\frac{s}{p_1}} \right). \]
  %
  The fact that all functions involved are simple means that the family of operators $\{ T_s \}$ is analytic. Now for all $t \in \RR$
  %
  \[ \| T_{it} f \|_{L^{q_0}(Y)} = \| T f \|_{L^{q_0}(Y,w_0)} \leq A_0 \| f v_0^{-1/p_0} \|_{L^{p_0}(X,v_0)} = A_0 \| f \|_{L^{p_0}(X)}. \]
  %
  For similar reasons, $\| T_{1 + it} f \|_{L^{q_1}(Y)} \leq A_1 \| f \|_{L^{p_0}(X,v_0)}$. Thus the Stein variant of the Riesz-Thorin theorem implies that
  %
  \[ \| T_\theta f \|_{L^{q_\theta}(Y)} \leq A_\theta \| f \|_{L^{p_\theta}(X)}. \]
  %
  But this, of course, is equivalent to the bound we set out to prove.
\end{proof}

\section{Real Interpolation of Operators}

Now we consider the case of real interpolation. One advantage of real interpolation is that it can be applied to sublinear as well as linear operators, and requires weaker endpoint estimates that the complex case. A disadvantage is that, usually, the operator under study cannot vary, and we lose out on obtaining explicit bounds.

A strong advantage to using real interpolation is that the criteria for showing boundedness at the endpoints can be reduced considerably. Let us give names for the boundedness we will want to understand for a particular operator $T$.
%
\begin{itemize}
  \item We say $T$ is \emph{strong type} $(p,q)$ if $\| Tf \|_{L^q(Y)} \lesssim \| f \|_{L^p(X)}$.
  
  \item We say $T$ is \emph{weak type} $(p,q)$ if $\| Tf \|_{L^{q,\infty}(Y)} \lesssim \| f \|_{L^p(X)}$.

  \item We say $T$ is \emph{restricted strong type} $(p,q)$ if we have a bound
  %
  \[ \| Tf \|_{L^q(Y)} \lesssim HW^{1/p} \]
  %
  for any sub-step functions with height $H$ and width $W$. Equivalently, for any set $E$,
  %
  \[ \| T(\mathbf{I}_E) \|_{L^q(Y)} \lesssim |E|^{1/p}. \]

  \item We say $T$ is \emph{restricted weak type} $(p,q)$ if we have a bound
  %
  \[ \| Tf \|_{L^{q,\infty}(Y)} \lesssim HW^{1/p} \]
  %
  for all sub-step functions with height $H$ and width $W$. Equivalently, for any set $E$,
  %
  \[ \| T(\mathbf{I}_E) \|_{L^{q,\infty}(Y)} \lesssim |E|^{1/p}. \]
\end{itemize}
%
An important tool for us will be to utilize duality to make our interpolation argument `bilinear'. Let us summarize this tool in a lemma. Proving the lemma is a simple application of Theorem \ref{weakdualitytheorem}.

\begin{lemma}
  Let $0 < p < \infty$ and $0 < q < \infty$. Then an operator $T$ is restricted weak-type $(p,q)$ if and only if for any finite measure sets $E \subset X$ and $F \subset Y$, there is $F' \subset Y$ with $|F'| \geq \alpha |F|$ such that
  %
  \[ \int_{F'} |T(\mathbf{I}_E)| \lesssim_\alpha |E|^{1/p} |F|^{1-1/q}. \]
\end{lemma}

Scalar interpoation leads to a simple version of real interpolation, which we employ as a subroutine to obtain a much more powerful real interpolation principle.

\begin{lemma}
  Let $0 < p_0,p_1 < \infty$, $0 < q_0,q_1 < \infty$. If $T$ is restricted weak type $(p_0,q_0)$ and $(p_1,q_1)$, then $T$ is restricted weak type $(p_\theta,q_\theta)$ for all $\theta \in (0,1)$.
\end{lemma}
\begin{proof}
  By assumption, if $E \subset X$ and $F \subset Y$, then there is $F_0, F_1 \subset Y$ with $|F_i| \geq (3/4)|F|$ such that
  %
  \[ \int_{F_i} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_i} |F_i|^{1 - 1/q_i}. \]
  %
  If we let $F_\theta = F_0 \cap F_1$, then $|F_\theta| \geq |F|/2$, and for each $i$,
  %
  \[ \int_{F_\theta} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_i} |F_\theta|^{1 - 1/q_i}. \]
  %
  Scalar interpolation implies
  %
  \[ \int_{F_\theta} |T(\mathbf{I}_E)| \lesssim |E|^{1/p_\theta} |F_\theta|^{1 - 1/q_\theta}, \]
  %
  and thus we have shown
  %
  \[ \| T(\mathbf{I}_E) \|_{q_\theta,\infty} \lesssim |E|^{1/p_\theta}. \]
  %
  This is sufficient to show $T$ is restricted weak type $(p_\theta,q_\theta)$.
\end{proof}

\begin{theorem}[Marcinkiewicz Interpolation Theorem]
  Let $0 < p_0,p_1 < \infty$, $0 < q_0,q_1 < \infty$, and suppose $T$ is restricted weak type $(p_i,q_i)$, with constant $A_i$, for each $i$. Then, for any $\theta \in (0,1)$, if $q_\theta > 1$, then for any $0 < r < \infty$, then
  %
  \[ \| Tf \|_{L^{q_\theta,r}(Y)} \lesssim A_\theta \| f \|_{L^{p_\theta,r}(X)}, \]
  %
  with implicit constants depending on $p_0, p_1, q_0$, and $q_1$.
\end{theorem}
\begin{proof}
  By scaling $T$, and the measures on $X$ and $Y$, we may assume that $\| f \|_{L^{p_\theta,r}(X)} \leq 1$, and that $T$ is restricted type $(p_i,q_i)$ with constant $1$, so that for any step function $f$ with height $H$ and width $W$,
  %
  \[ \| Tf \|_{L^{q_i,\infty}(Y)} \leq \| f \|_{L^{p_i}(X)}. \]
  %
  By duality, using the fact that $q_\theta > 1$, it suffices to show that for any simple function $g$ with $\| g \|_{L^{q_\theta',r'}(Y)} = 1$,
  %
  \[ \int |Tf| |g| \leq 1. \]
  %
  Using the previous lemma, we can `adjust' the values $q_0,q_1$ so that we can assume $q_0,q_1 > 1$. We can perform a horizontal layer decomposition, writing
  %
  \[ f = \sum_{i = -\infty}^\infty f_i, \quad\text{and}\quad g = \sum_{i = -\infty}^\infty g_i, \]
  %
  where $f_i$ and $g_i$ are sub-step functions with width $2^i$ and heights $H_i$ and $H_i'$ respectively, and if we write $A_i = H_i 2^{i/p_\theta}$, and $B_i = H_i' 2^{i/q_\theta}$, then
  %
  \[ \| A \|_{l^r(\ZZ)}, \| B \|_{l^{r'}(\ZZ)} \lesssim 1. \]
  %
  Applying the restricted weak type inequalities, we know for each $i$ and $j$,
  %
  \[ \int |Tf_i| |g_j| \lesssim H_i H_j \min_{k \in \{0,1\}} \left[ 2^{i/p_k + j(1 - 1/q_k)} \right]. \]

  Applying sublinearity (noting that really, the decomposition of $f$ and $g$ is finite, since both functions are simple). Thus
  %
  \begin{align*}
    \int |Tf| |g| &\leq \sum_{i,j} \int |Tf_i| |g_j|\\
    &\lesssim \sum_{i,j} H_i H_j' \min_{k \in \{0,1\}} \left[ 2^{i/p_k + j(1 - 1/q_k)} \right]\\
    &\lesssim \sum_{i,j} A_i B_j \min_{k \in \{ 0, 1 \}} \left[ 2^{i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k)} \right].
  \end{align*}
  %
  If $i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k) = \varepsilon(i + \lambda j)$, where $\varepsilon = (1/p_k - 1/p_\theta)$. We then have
  %
  \[ \sum_{i,j} A_i B_j \min_{k \in \{ 0, 1 \}} \left[ 2^{i(1/p_k - 1/p_\theta) + j(1/q_\theta - 1/q_k)} \right] \sim \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \sum_i A_i B_{k - \lfloor i/\lambda \rfloor}. \]
  %
  Applying H\"{o}lder's inequality,
  %
  \begin{align*}
    \sum_i A_i B_{k - \lfloor i/\lambda \rfloor} &\leq \| A \|_{l^r(\ZZ)} \left( \sum_i |B_{k - \lfloor i/\lambda \rfloor}|^{r'} \right)^{1/r'}\\
    &\lesssim \lambda^{1/r'} \| A \|_{l^r(\ZZ)} \| B \|_{l^{r'}(\ZZ)} \lesssim 1.
  \end{align*}
  %
  Thus we conclude that
  %
  \begin{align*}
    \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \sum_i A_i B_{k - \lfloor i/\lambda \rfloor} &\lesssim \sum_{k = -\infty}^\infty \min(2^{\varepsilon k}, 2^{-\varepsilon k}) \lesssim_\varepsilon 1. \qedhere
  \end{align*}
\end{proof}

There are many variants of the real interpolation method, but the general technique almost always remains the same: incorporate duality, decompose inputs, often dyadically, bound these decompositions, and then sum up.









\chapter{The Theory of Distributions}

The theory of distributions is a tool which enables us to justify formal manipulations which occur in harmonic analysis, without the technical issues which occur from having to interpret such manipulations analytically. For instance, the ordinary integral formulation of the Fourier transform is only defined for $L^1$ functions, whereas the theory of tempered distributions enables us to define the Fourier transform of essentially any function we would ever want to take the Fourier transform of. Similarily, we can only classically differentiate a particular class of functions, but the theory of distributions enables us to define the derivative of almost any function that occurs in analysis. These reasons make distribution theory a cornerstone in the formulation of many problems in modern harmonic analysis and partial differential equations.

The power of measure theory is that it enables us to study a very general class of functionsome more. The problem is that as we study more general classes of functions, the operations we can perform on this class become more and more restricted. Nonetheless, $C^\infty_c(\RR^d)$ is dense in every function space we consider, and we can apply all the fundamental analytical operations in this region, obtaining a general result by a density argument. The theory of distributions provides an alternate viewpoint.

From the perspective of set theory, functions $f: X \to Y$ are a way of assigning values in $Y$ to each point in $X$. However, in analysis this is not often the way we view functions. For instance, in measure theory, we are used to identifying functions which are equal almost everywhere, so that functions in this setting are only defined `almost everywhere'. In distribution theory, we view functions as `integrands', whose properties are understand by integration against a family of `test functions'. For instance, recall that for $1 \leq p < \infty$, the dual space of $L^p(\RR^d)$ is $L^q(\RR^d)$. Thus we can think of elements $f \in L^q(\RR^d)$ as `integrands', whose properties can be understood by integration against elements of $L^p(\RR^d)$, i.e. through the linear functional $\Lambda[f]$ defined for each $\psi \in L^p(\RR^d)$ by setting
%
\[ \Lambda[f](\psi) = \int_{\RR^d} f(x) \psi(x)\; dx. \]
%
Similarily, the dual space of $C(K)$, where $K$ is a compact topological space, is the space $M(K)$ of finite Borel measures on $K$. Thus we can think of measures as a family of `generalized functions'. For each measure $\mu \in M(K)$, we consider the linear functional $\Lambda[\mu]$, defined for each $\psi \in C(K)$, we set
%
\[ \Lambda[\mu](\psi) = \int_K \psi(x) d\mu(x). \]
%
Notice that as we shrink the family of test functions, the resultant family of `generalized functions' becomes larger and larger, and so elements can behave more and more erratically. A distribution is a `generalized function' tested against functions in $C_c^\infty(\RR^d)$. Since most operations in analysis can be applied to elements of $C_c^\infty(\RR^d)$, most importantly, differentiation, we can use duality to extend these operations to distributions. Moreover, since $C_c^\infty(\RR^d)$ is contained in most of the other function spaces, distributions are one of the largest family of generalized functions.

\begin{remark}
  From the perspective of physics, viewing functions as integrands is completely natural. Points in space are idealizations which do not correspond to real world phenomena. One can never measure the exact value of some quantity of a function at a point, but rather only understand the function by looking at it's averages over a small region around that point. Thus a `function' can be understood by the averages with respect to a family of integrands, known as test functions, since they test the value of the function over a region. As we make the family of integrands smaller and smaller, a `function' can be behave more and more erratically. A distribution is an `integrand' with respect to the space $C^\infty_c(\RR^d)$ of infinitely differentiable functions with compact support. Since these functions are incredibly analytically nice, distributions are allowed to behave incredibly erratically, but we can still extend the operations of differentiation and integration to them.
\end{remark}

\section{The Space of Test Functions}

\begin{remark}
  This section is technical, and requires a strong knowledge of functional analysis, in particular the theory of locally convex topological spaces. It can be skipped without too much confusion.
\end{remark}

We fix an open subset $\Omega$ of $\RR^n$, and let $C_c^\infty(\Omega)$ denote the family of all smooth functions on $\Omega$ with compact support. Our goal is to equip $C_c^\infty(\Omega)$ with a complete locally convex topology, so that we can consider the dual space $C_c^\infty(\Omega)^*$ of {\emph distributions} on $\Omega$. We could equip $C_c^\infty(\Omega)$ with a locally convex, metrizable topology with respect to the seminorms
%
\[ \| f \|_{C^n(\Omega)} = \max_{|\alpha| \leq n} \| D^\alpha f \|_{L^\infty(\Omega)} \]
%
However, the resultant topology on $C_c^\infty(\Omega)$ isn't always complete.

\begin{example}
    Let $\Omega = \RR$, pick a bump function $\phi \in C_c^\infty(\RR)$ supported on $[0,1]$ with $\phi > 0$ on $(0,1)$, and define
    %
    \[ \psi_m(x) = \phi(x-1) + \frac{\phi(x-2)}{2} + \dots + \frac{\phi(x-m)}{m} \]
    %
    Then $\psi_m$ is compactly supported on $[1,m]$, and Cauchy, since for $m_1 \geq m_0$,
    %
    \[ \| \psi_{m_0} - \psi_{m_1} \|_{C^n(\RR)} = \frac{ \max_{r \leq n} \| D^r \phi \|_{L^\infty(\RR^d)}}{m_0+1} \lesssim_n 1/m_0. \]
    %
    However, the sequence $\{ \psi_m \}$ does not converge to any element of $C_c^\infty(\RR)$, since the sequence converges uniformly to the function
    %
    \[ \psi(x) = \sum_{n = 1}^\infty \psi(x-n) \]
    %
    an element of $C^\infty(\RR)$ which is not compactly supported.
\end{example}

We can assign $C_c^\infty(\Omega)$ a slightly stronger locally convex topology which makes is complete, but no longer metrizable. The process here is quite general. For each compact set $K \subset \Omega$, the subspace $C_c^\infty(K)$ of smooth functions compactly supported on $K$ is a complete metric space, since limits of functions cannot `escape' the set. Since $C_c^\infty(\Omega) = \bigcup_K C_c^\infty(K)$, we might be able to give $C_c^\infty(\Omega)$ a complete metric space structure by strengthening the topology by forcing limits to lie in a particular set of compact support. We now declare a convex topology, by considering the family of all sets $\{ \phi + W \}$ as a basis, where $\phi$ ranges over all elements of $C_c^\infty(\Omega)$, and $W$ ranges over all convex, balanced subsets of $C_c^\infty(\Omega)$ such that $W \cap C_c^\infty(K)$ is open for each compact set $K \subset \Omega$.

\begin{theorem}
    This gives a basis of a Hausdorff topology on $C_c^\infty(\Omega)$.
\end{theorem}
\begin{proof}
    If $\phi_1 + W_1$ and $\phi_2 + W_2$ both contain $\phi$, then $\phi - \phi_1 \in W_1$ and $\phi - \phi_2 \in W_2$. The functions $\phi, \phi_1$, and $\phi_2$ are all supported on some compact set $K$. By continuity of multiplication on $C_c^\infty(K)$, and the fact that $W_n \cap C_c^\infty(K)$ is open, there is a small constant $\delta$ such that $\phi - \phi_n \in (1 - \delta) W_n$ for each $n \in \{ 1, 2 \}$. The convexity of the $W_n$ implies that $\phi - \phi_n + \delta W_n \subset W_n$. But then $\phi + \delta W_n \subset \phi_n + W_n$, and so $\phi + \delta (W_1 \cap W_2) \subset (\phi_1 + W_1) \cap (\phi_2 + W_2)$. Thus we have verified the family of sets specified above is a basis. Now we show $C_c^\infty(\Omega)$ is Hausdorff under this topology. Suppose $\phi$ is in every open neighbourhood of the origin, then in particular, for each $\varepsilon > 0$, $\phi$ lies in the set $W_\varepsilon = \{ f \in C_c^\infty(\Omega): \| f \|_{L^\infty(\Omega)} < \varepsilon \}$, and it is easy to see these sets are open. Since $\bigcap_{\varepsilon > 0} W_\varepsilon = \{ 0 \}$, this means $\phi = 0$.
\end{proof}

\begin{remark}
    This technique can be formulated more abstractly to give a locally convex topological structure to the direct limit of locally convex spaces. From this perspective, we also see why our metrization doesn't work; if $X = \lim X_n$, with each $X_n$ a locally convex metrizable space, then we cannot give $X$ a complete metrizable topology such that each $X_n$ is an embedding and has empty interior in $X$, because this would contradict the Baire category theorem. In particular, this means that the topology we have given to $C_c(\Omega)$ cannot be metrizable, and therefore the space cannot be first countable. Later we will see a more explicit proof of this.
\end{remark}

\begin{theorem}
    $C_c^\infty(\Omega)$ is a locally convex space.
\end{theorem}
\begin{proof}
    Fix $\phi$ and $\psi$, and consider any neighbourhood $W$ of the origin. By convexity, we have $(\phi + W/2) + (\psi + W/2) \subset (\phi + \psi) + W$. This shows addition is continuous. To show multiplication is continuous, fix $\lambda$, $\phi$, and a neighbourhood $W$ of the origin. Then $\phi$ is supported on some compact set $K$, and $W \cap C_c^\infty(K)$ is open, in particular absorbing, so there is $\varepsilon > 0$ such that if $|\alpha| < \varepsilon$, $\alpha \phi \in W/2$. Then if $|\gamma - \lambda| < \varepsilon$, then because $W$ is balanced and convex,
    %
    \begin{align*}
        \gamma \left(\phi + \frac{W}{2(|\lambda| + \varepsilon)} \right) &= \lambda \phi + (\gamma - \lambda) \phi + \frac{\gamma}{2(|\lambda| + \varepsilon)} W\\
        &\subset \lambda \phi + W/2 + W/2 \subset \lambda \phi + W
    \end{align*}
    %
    so multiplication is continuous.
\end{proof}

\begin{theorem}
    For each compact set $K \subset \Omega$, the canonical embedding of $C_c^\infty(K)$ in $C_c^\infty(\Omega)$ is continuous.
\end{theorem}
\begin{proof}
    We shall prove a convex, balanced neighbourhood $V$ is open in $C_c^\infty(\Omega)$ if and only if $C_c^\infty(K) \cap V$ is open in $C_c^\infty(K)$ for each $K$. Since $V$ is open, $V$ is the union of convex, balanced sets $W_\alpha$ with $W_\alpha \cap C_c^\infty(K)$ open in $C_c^\infty(K)$ for each $K$. But then $V \cap C_c^\infty(K) = (\bigcup W_\alpha) \cap C_c^\infty(K)$ is open in $C_c^\infty(K)$. The converse is true by definition of the topology. But this statement means exactly that the map $C_c^\infty(K) \to C_c^\infty(\Omega)$ is an embedding, because it is certainly continuous, and if $W$ is a convex neighbourhood of the origin equal to the set of $\phi$ supported on $K$ with $\| \phi \|_{C^n(K)} \leq \varepsilon$ for some $n$, then the image is the intersection of $C_c^\infty(K)$ with the set of all $\phi$ supported on $\Omega$ satisfying the inequality, which is open. This shows that the map is open onto its image, hence an embedding.
\end{proof}

It is difficult to see from the definition above why the topology is much stronger than the previous one given. We can see this more numerically by introducing the topology in terms of seminorms. The topology we have given $C_c^\infty(\Omega)$ is the same as the locally convex topology introduced by all norms $\| \cdot \|$ on the space which are continuous when restricted to each $C_c^\infty(K)$. As an example, if we choose an increasing family $U_1, U_2, \dots$ of precompact open sets whose closure is contained in $\Omega$, then any compact set $K$ is contained in some $U_N$ for large enough $N$, and for any increasing sequence $\alpha_1, \alpha_2, \dots$ of positive constants and increasing sequence $k_1, k_2, \dots$ of positive integers the norm
%
\[ \| f \| = \min_{\text{supp}(f) \subset U_n} \alpha_n \| f \|_{C^{k_n}(U_n)} \]
%
is well defined on $C_c^\infty(\Omega)$ and continuous. But this means that if $f_1, f_2, \dots \to 0$, then $\| f \| \to 0$ for any choice of constants $\alpha_n$ and $k_n$, so asymptotically as we approach the boundary of $\Omega$ (or $\infty$, if $\Omega$ is unbounded), the $L^\infty$ norms of the $f_n$ and all of their derivatives must converge arbitrarily fast outside certain compact sets. The next theorem shows that this implies that the union of the domains $f_n$ must actually be precompact. It is this `uniform compactness' that gives us completeness.

\begin{theorem}
    $E$ is a bounded subset of $C_c^\infty(\Omega)$ if and only if $E$ is contained in $C_c^\infty(K)$ for some compact set $K$, and there is a sequence of constants $\{ M_n \}$ such that $\| \phi \|_{C^n(\Omega)} \leq M_n$ for all $\phi \in E$.
\end{theorem}
\begin{proof}
    We shall now prove that if $E$ is not contained in some $C_c^\infty(K)$ for any compact set $K \subset \Omega$, then $E$ is not bounded. If our assumption is true, we can find functions $\phi_n \in E$ and a set of points $x_n \in X$ with no limit point such that $\phi_n(x_n) \neq 0$. For each $n$, set
    %
    \[ W_n = \left\{ \psi \in C_c^\infty(\RR^d): |\psi(x_n)| < n^{-1} |\phi_n(x_n)| \right\}. \]
    %
    Certainly $W_n$ is convex and balanced, and for each compact set $K$, if $\psi \in W_n \cap C_c^\infty(K)$, then there is $\varepsilon > 0$ such that $|\psi(x_n)| < n^{-1} |\phi_n(x_n)| - \varepsilon$. Thus if $\eta \in C_c^\infty(K)$ satisfies $\| \eta \|_{L^\infty(\RR^d)} < \varepsilon$, then $\psi + \eta \in W_n$. In particular, this means $W_n \cap C_c^\infty(K)$ is open in $C_c^\infty(K)$ for each $K$, so $W_n$ is open.

    Now we claim $W = \bigcap_{n = 1}^\infty W_n$ is open. Certainly this set is convex and balanced. Moreover, each compact set $K$ contains finitely many of the points $\{ x_n \}$, so $W \cap C_c^\infty(K)$ can be replaced by a finite intersection of the $W_n$, and is therefore open. Since $\phi_n \not \in nW$ for all $n$, this implies that $E$ is not bounded. The fact that $\| \cdot \|_{C^n(\Omega)}$ specifies the topological structure of $C_c^\infty(K)$ for each compact $K$ now shows that if $E$ is bounded, there exists constants $\{ M_n \}$ such that $\| \phi \|_{C^n(\Omega)} \leq M_n$ for all $\phi \in E$. The converse property follows because $C_c^\infty(K)$ is embedded in $C_c^\infty(\Omega)$.
\end{proof}

\begin{corollary}
    $C_c^\infty(\Omega)$ has the Heine Borel property.
\end{corollary}
\begin{proof}
    This follows because if $E$ is bounded and closed, it is a closed and bounded subset of some $C_c^\infty(K)$ for some $K$, hence $E$ is compact since $C_c^\infty(K)$ satisfies the Heine-Borel property (this can be proved by a technical application of the Arzela-Ascoli theorem).
\end{proof}

\begin{corollary}
    $C_c^\infty(\Omega)$ is quasicomplete.
\end{corollary}
\begin{proof}
    If $\phi_1, \phi_2, \dots$ is a Cauchy sequence in $C_c^\infty(\Omega)$, then the sequence is bounded, hence contained in some common $C_c^\infty(K)$. Since the sequence is Cauchy, they converge in $C_c^\infty(K)$ to some $\phi$, since $C_c^\infty(K)$ is complete, and thus the $\phi_n$ converge to $\phi$ in $C_c^\infty(\Omega)$.
\end{proof}

It is often useful to use the fact that we can perform a `separation of variables' to a smooth function. This is done formally in the following manner. Say $f \in C_c^\infty(\RR^d)$ is a {\it tensor function} if there are $f_1, \dots, f_n \in C_c^\infty(\RR)$ such that $f(x) = f_1(x_1) \dots f_n(x_n)$. We write $f = f_1 \otimes \dots \otimes f_n$. Since the product of two tensor functions is a tensor function, the family of all finite sums of tensor functions forms an algebra.

\begin{theorem}
    Finite sums of tensor functions are dense in $C_c^\infty(\RR^d)$.
\end{theorem}
\begin{proof}
    Recall from the theory of multiple Fourier series that if $f \in C^\infty(\RR^d)$ is $N$ periodic, in the sense that $f(x + n) = f(x)$ for all $x \in \RR^d$ and $n \in (N \ZZ)^d$, then there are coefficients $a_m$ for each $m \in \ZZ^n$ such that $f = \lim_{M \to \infty} S_M f$, where the convergence is dominated by the sminorms $\| \cdot \|_{C^n(\RR^d)}$, for all $n > 0$, and
    %
    \[ (S_M f)(x) = \sum_{\substack{m \in \ZZ^d\\|m| \leq M}} a_m e^{\frac{2 \pi i m \cdot x}{N}}. \]
    %
    Note that since
    %
    \[ e^{\frac{2 \pi i m \cdot x}{N}} = \prod_{k = 1}^d e^{2 \pi i m_ix_i/N} \]
    %
    is a tensor product, $S_M f$ is a finite sum of tensor functions. If $\phi \in C_c^\infty(\RR^d)$ is compactly supported on $[-N,N]^d$, we let $f$ be a $10N$ periodic function which is equal to $\phi$ on $[-N,N]^d$. We then find coefficients $\{ a_m \}$ such that $S_M f$ converges to $f$. If $\psi: \RR \to \RR$ is a compactly supported bump function equal to one on $[-N,N]^d$, and vanishing outside of $[-2N,2N]^d$, then $\psi^{\otimes d} S_M f$ converges to $\psi$ as $M \to \infty$, and each is a finite sum of tensor functions.
\end{proof}

Because $C_c^\infty(\Omega)$ is the limit of metrizable spaces, it's linear operators still have many of the same properties as metrizable spaces.

\begin{theorem}
    If $T: C_c^\infty(\Omega) \to X$ is a map from $C_c^\infty(\Omega)$ to some locally convex space $X$, then the following are equivalent:
    %
    \begin{itemize}
        \item[(1)] $T$ is continuous.
        \item[(2)] $T$ is bounded.
        \item[(3)] If $\{ \phi_n \}$ converges to zero, then $\{ T\phi_n \}$ converges to zero.
        \item[(4)] For each compact set $K \subset \Omega$, $T$ is continuous restricted to $C_c^\infty(K)$.
    \end{itemize}
\end{theorem}
\begin{proof}
    We already known that (1) implies (2). If $T$ is bounded, and we have a sequence $\{ \phi_n \}$ converging to zero, then the sequence is bounded, hence contained in some $C_c^\infty(K)$. Thend $T$ is bounded as a map from $C_c^\infty(K)$ to $X$, hence $\{ T\phi_n \} \to 0$. (3) implies (4) holds because each $C_c^\infty(K)$ is metrizable, and any convergent sequence is contained in some common $C_c^\infty(K)$. To prove that (4) implies (1), we let $V$ be a convex, balanced, open subset of $X$. Then $T^{-1}(V) \cap C_c^\infty(K)$ is open for each $K$, and $T^{-1}(V)$ is convex and balanced, so $T^{-1}(V)$ is an open set.
\end{proof}

Because convergence is so strict in $C_c^\infty(\Omega)$, almost every operation we want to perform on smooth functions is continuous in this space.
%
\begin{itemize}
    \item Since $f \mapsto D^\alpha f$ is a continuous operator from $C_c^\infty(K)$ to itself, it is therefore continuous on the entire space $C_c^\infty(\Omega)$. More generally, any linear differential operator with coefficients in $C_c^\infty(\Omega)$ is a continuous operator from $C_c^\infty(\Omega)$ to itself.

    \item The inclusion $C_c^\infty(\Omega) \to L^p(\Omega)$ is continuous. To prove this, it suffices to prove for each compact $K$, the inclusion $C_c^\infty(K) \to L^p(\Omega)$ is continuous, and this follows because $\| f \|_{L^p(\Omega)} \leq |K|^{1/p} \| f \|_\infty$.

    \item If $f \in L^1(\RR^d)$ is compactly supported, then for any $g \in C_c^\infty(\RR^d)$, $f * g \in C_c^\infty(\RR^d)$. This is because $f * g$ is continuous since $g \in L^\infty(\RR^n)$, and it's support is contained in the algebraic sums of the support of $f$ and $g$, as well as the identity $D^\alpha(f * g) = f * (D^\alpha g)$. In fact, the map $g \mapsto f * g$ is a continuous operator on $C_c^\infty(\RR^n)$. This is because if we restrict our attention to $C_c^\infty(K)$, and $f$ has supported on $K'$, then our convolution operator maps into the compact set $K+K'$, and since
    %
    \[ \| D^\alpha (g * f) \|_{L^\infty(K + K')} = \| D^\alpha g * f \|_{L^\infty(K + K')} \leq \| D^\alpha g \|_{L^\infty(K)} \| f \|_{L^1(K')}, \]
    %
    we conclude
    %
    \[ \| g * f \|_{C^n(K+K')} \leq \| g \|_{C^n(K)} \| f \|_{L^1(K')}, \]
    %
    which gives continuity of the operator as a map from $C_c^\infty(K)$ to $C_c^\infty(K+K')$. Since the latter space embeds in $C_c^\infty(\RR^n)$, we obtain continuity of the operator on $C_c^\infty(\RR^n)$.
\end{itemize}

\begin{theorem}
    If a map $T: C_c^\infty(K) \to C_c^\infty(\RR^n)$ is continuous, then the image of $C_c^\infty(K)$ is actually $C_c^\infty(K')$ for some compact set $K'$.
\end{theorem}
\begin{proof}
    Suppose there is a sequence $x_1, x_2, \dots$ with no limit point and smooth functions $f_1, f_2, \dots$ compactly supported on $C_c^\infty(K)$ such that $(Tf_n)(x_n) \neq 0$. But then for any sequence $\alpha_n$ whatsoever, we cannot have $\alpha_n Tf_n$ converging to zero, hence $\alpha_n f_n$ cannot converge to zero. But this is clearly not true, for if we let
    %
    \[ \alpha_n = \frac{1}{2^n \| f_n \|_{C^n}} \]
    %
    Then for any fixed $m$, $\| f_n \|_{C^m}$ is eventually bounded above by $1/2^n$ and therefore converges to zero. Thus such a sequence $x_n$ cannot exist, and therefore the image of $T$ is supported on some compact set $K'$.
\end{proof}

Thus the topology on the space $C_c^\infty(\RR^d)$ is as strict as can be. As a consequence, we shall see that the weak $*$ topology on $C_c^\infty(\RR^d)^*$ is essentially the weakest notion of convergence available in analysis, which makes it surprising that we still be able to recover the continuity of many operators on the dual space.

\section{The Space of Distributions}

We now have the tools to explain the idea of a distribution. If $f$ is a locally integrable function defined on $\Omega$, then the map
%
\[ \Lambda[f](\phi) = \int f(x) \phi(x)\; dx \]
%
is a {\it continuous} linear functional defined for each $\phi \in C_c^\infty(\Omega)$. The functional $\Lambda[f]$ determines $f$ up to a set of measure zero, and so we can safely identify $\Lambda[f]$ with $f$, and think of $f$ `distributionally'. The idea of the theory of distributions is to treat any continuous linear functional $\Lambda$ on $C_c^\infty(\Omega)$ as if it were given by integration against a function as nice as possible. Using the properties of integration for these integration, we can usually cheat out a definition of operations usually only applicable to functions that works for all distributions. Thus the operations of analysis generalize to an incredibly large family of objects. As an example, if $f$ was continuously differentiable, then we would find
%
\[ \int f'(x) \phi(x)\; dx = - \int f(x) \phi'(x)\; dx \]
%
Since the right hand side is defined independantly of how nice the function $f(x)$ is, we could define the {\it derivative} of a continuous linear functional $\Lambda$ as
%
\[ \Lambda'(\phi) = - \Lambda(\phi') \]
%
and more generally, for a linear functional on $n$ dimensional space, we could define $(D^\alpha \Lambda)(\phi) = (-1)^{|\alpha|} \Lambda(D^\alpha \phi)$.

\begin{example}
    Let $H(x) = \mathbf{I}(x > 0)$ denote the {\it Heaviside step function}. Then $H$ is locally integrable, and so for any test function $\phi$, we calculate
    %
    \[ \int H'(x) \phi(x)\; dx = - \int H(x) \phi'(x) = - \int_0^\infty \phi'(x) = \phi(0) \]
    %
    Thus the `derivative' of the Heaviside step function is the Dirac delta. It is not a function, but if we were to think of it as a `generalized function', it would be zero everywhere except at the origin, where it is infinitely peaked.
\end{example}

\begin{example}
    Consider the Dirac delta function at the origin, which is the distribution $\delta(f) = f(0)$. Then
    %
    \[ \delta'(f) = - \delta(f') = - f'(0) \]
    %
    which is a distribution which doesn't arise from integration with respect to a locally integrable function nor a Radon measure. Thus the `derivative' of an infinitely peaked function at the origin is the negation of a derivative.
\end{example}

In general, we define a {\bf distribution} to be a continuous linear functional on the space of test functions $C_c^\infty(\Omega)$. In the last section, our exploration of continuous linear transformations on $C_c^\infty(\Omega)$ guarantees that a linear functional $\Lambda$ on $C_c^\infty(\Omega)$ is continuous if and only if for every compact $K \subset X$ there is an integer $n_k$ such that $|\Lambda \phi| \lesssim_K \| \phi \|_{C^{n_k}}$ for $\phi \in C_c^\infty(K)$. If one integer $n$ works for all $K$, and $n$ is the smallest integer with such a property, we say that $\Lambda$ is a distribution of \emph{order $n$}. If such an $n$ doesn't exist, we say the distribution has infinite order. If such an $n$ doesn't exist, we say the distribution has infinite order.

\begin{example}
    If $\mu$ is a locally finite Borel measure, or a finite complex valued measure, then we can define
    %
    \[ \Lambda[\mu](\phi) = \int \phi(x) d\mu(x) \]
    %
    Thus $\Lambda[\mu]$ is a distribution, since if $\phi$ is supported on $K$, then
    %
    \[ |\Lambda[\mu](\phi)| \leq \mu(K) \| \phi \|_{L^\infty(K)} \]
    %
    Thus $\Lambda[\mu]$ is a distribution of order zero.
\end{example}

\begin{example}
    Not all distributions arise from functions or measures. For instance, if $\phi \in C_c^\infty(\RR)$, then
    %
    \[ \text{p.v} \int \frac{\phi(x)}{x} = \lim_{\varepsilon \to 0} \int_{|x| > \varepsilon} \frac{\phi(x)}{x}\; dx \]
    %
    exists. This is because the values of $1/x$ on either side of the real axis cancel each other out in the integral. More rigorously, if the support of $\phi$ is contained in $[-N,N]$, then
    %
    \[ \left| \int_{|x| > \varepsilon} \frac{\phi(x)}{x} \right| = \left| \int_{\varepsilon < |x| < N} \frac{\phi(x) - \phi(0)}{x} \right| \]
    %
    The mean value theorem implies $\phi(x) - \phi(0) = x\phi'(y)$ for some $y$ between zero and $x$, so
    %
    \[ \left| \int_{|x| \leq \varepsilon} \frac{\phi(x) - \phi(0)}{x} \right| \leq 2 \varepsilon \| \phi \|_{C^1(\RR)} \]
    %
    From this, we can conclude that these values are Cauchy as $\varepsilon \to 0$, hence the principal value exists, and moreover, if $\phi$ is compactly supported on $[-N,N]$, 
    %
    \[ \left| \text{p.v.} \int \frac{\phi(x)}{x} \right| \lesssim_N \| \phi \|_{C^1(\RR^d)} \]
    %
    Thus this linear functional is actually continuous, hence a distribution, and it is not induced by any function or measure. This distribution is the derivative of the distribution induced by the locally integrable function $\log |x|$, since an integration by parts shows that for each $\phi \in C_c^\infty(\RR^d)$,
    %
    \begin{align*}
        - \int \log |x| \phi'(x) &= \lim_{\varepsilon \to 0} \int_{|x| \geq \varepsilon} \log |x| \phi'(x)\\
        &= \lim_{\varepsilon \to 0} \left( \log(\varepsilon) \cdot \left( \phi(x) - \phi(-x) \right) + \int_{|x| \geq \varepsilon} \frac{\phi(x)}{x} \right)\\
        &= \text{p.v.} \int \frac{\phi(x)}{x}\; dx.
    \end{align*}
\end{example}

As we stated before, given any distribution $\Lambda$, we can define it's {\it derivative} $D^\alpha \Lambda$ to be the distribution
%
\[ D^\alpha \Lambda (\phi) = (-1)^{|\alpha|} \Lambda(D^\alpha \phi) \]
%
which is continuous since the derivative operation is continuous on $C_c^\infty(\Omega)$. Just as the partial derivatives commutes on $C_c^\infty(\Omega)$, the partial differentiation operation commutes on the the space of distributions, i.e. $D^\alpha D^\beta \Lambda = D^\beta D^\alpha \Lambda$, and we take the common value to be $D^{\alpha + \beta} \Lambda$. If $D^\alpha f$ is continuous, then we already know an integration by parts gives $D^\alpha \Lambda[f] = \Lambda[D^\alpha f]$, so we can think of the distribution derivative as a true generalization of the usual derivative. On the other hand, in general the distribution derivative may disagree with the usual derivative if the function is less well behaved. If $P$ is a polynomial, we have
%
\[ P(D)(\Lambda)(\phi) = \Lambda(P(-D)(\phi)) \]
%
if we understand the polynomial applications of derivatives linearly.

\begin{example}
    Let $f$ be a left continuous function on the real line with bounded variation and with $f(-\infty) = 0$. Then $f'$ exists almost everywhere in the classical sense, and $f' \in L^1(\RR)$. By Fubini's theorem, if we let $\mu$ be the measure defined by $\mu([a,b)) = f(b) - f(a)$, then for any $\phi \in C_c^\infty(\RR)$,
    %
    \begin{align*}
        \int_{-\infty}^\infty \phi(x) d\mu(x) &= - \int_{-\infty}^\infty \int_x^\infty \phi'(y)\; dy\; d\mu(x)\\
        &= - \int_{-\infty}^\infty \phi'(y) \int_{-\infty}^y d\mu(x)\; dy\\
        &= - \int_{-\infty}^\infty \phi'(y) f(y) dy
    \end{align*}
    %
    and we know $f(-\infty) = 0$. Thus we find $\smash{\Lambda[f'] = \Lambda[\mu]}$. In particular, we only have $\smash{\Lambda[f]' = \Lambda[f'}]$ if $\smash{f' dx = \mu}$, which only holds if $f$ is absolutely continuous.
\end{example}

If $f \in L^1_{\text{loc}}(\RR^n)$, and $g$ is $C^\infty$, then $fg$ is locally integrable. The identity
%
\[ \int (f(x)g(x)) \phi(x)\; dx = \int f(x) (g(x) \phi(x))\; dx \]
%
enables us to define the product of a $C^\infty(\Omega)$ function with a distribution. Given any distribution $\Lambda$, we define $(f \Lambda)(\phi) = \Lambda(f \phi)$. To see why $f \Lambda$ is a distribution, fix a compact set $K$, and pick $A$ and $N$ such that for any $\phi \in C_c^\infty(K)$, $|\Lambda(f)| \leq A \| f \|_{N,K}$. The Leibnitz rule tells us that
%
\[ D^\alpha(f \phi) = \sum_{\lambda + \gamma = \alpha} C_{\lambda \gamma} D^\lambda f D^\gamma \phi \]
%
and so
%
\[ |\Lambda(f \phi)| \leq A \| f \phi \|_{N,K} \leq N A \left( \max |C_{\lambda \gamma}| \| D^\lambda f \|_{L^\infty(K)} \right) \| \phi \|_{C^N(K)} \]
%
so $f \Lambda$ is a distribution with the same order as $\Lambda$. It is important that $f$ is a smooth function, so that $fg$ is smooth for each function $g$.

Since $C_c^\infty(X)^*$ is the dual space of a topological vector space, we can give it a natural topology, the weak $*$ topology. Thus a net of distributions $\Lambda_\alpha$ converges to $\Lambda$ if and only if $\Lambda_\alpha(\phi) \to \Lambda(\phi)$ for all test functions $\phi$. This gives a further topology on the space of measures and functions, and we often write $f_\alpha \to f$ `in the distribution sense' if we have a convergence $\Lambda[f_\alpha] \to \Lambda[f]$ for the corresponding distributions. Since the convergence in $C_c^\infty(\Omega)$ is incredibly strict, convergence of distributions is incredibly weak. The following is thus quite a surprising result.

\begin{theorem}
    Suppose that $\Lambda_1, \Lambda_2, \dots$ are a sequence of distributions such that for a fixed test function $\phi$,
    %
    \[ \Lambda \phi = \lim \Lambda_n \phi \]
    %
    exists. Then $\Lambda$ is a distribution, and $D^\alpha \Lambda_n \to D^\alpha \Lambda$ for each $\alpha$.
\end{theorem}
\begin{proof}
    Fix a compact set $K$. Then the Banach Steinhaus theorem guarantees that $\Lambda$ restricted to $C_c^\infty(K)$ is a continuous functional, and we know this implies $\Lambda$ is continuous in general. The fact that $D^\alpha \Lambda_n \to D^\alpha \Lambda$ is trivial, because for a fixed $\phi$, $D^\alpha \phi \in C_c^\infty(X)$, so
    %
    \[ D^\alpha \Lambda(\phi) = (-1)^{|\alpha|} \Lambda(D^\alpha \phi) = (-1)^{|\alpha|} \lim \Lambda_n(D^\alpha \phi) = \lim D^\alpha \Lambda_n(\phi) \]
    %
    Thus the sequence weakly converges to $D^\alpha \Lambda$.
\end{proof}

A similar application of the Banach Steinhaus theorem guarantees that if $g_n \to g$ in $C^\infty(\RR^n)$, and $\Lambda_n \to \Lambda$ in the distributional sense, then $g_n \Lambda_n$ converges to $g \Lambda$ in the distributional sense. Thus the space of distributions is a topological $C^\infty(\RR^n)$ module.

\section{Localization of Distribuitions}

Just as we can consider the local behaviour of functions around a point, we can consider the local behaviour of a distribution around points, and this local behaviour contains most of the information of the distribution. For instance, given an open subset $U$ of $X$, we say two distributions $\Lambda$ and $\Psi$ are equal on $U$ if $\Lambda \phi = \Psi \phi$ for every test function $\phi$ compactly supported in $U$. We recall the notion of a partition of unity, which, for each open cover $U_\alpha$ of Euclidean space, gives a family of $C^\infty$ functions $\psi_\alpha$ which are positive, {\it locally finite}, in the sense that only finitely many functions are positive on each compact set, and satisfy $\sum \psi_\alpha = 1$ on the union of the $U_\alpha$.

\begin{theorem}
    If $X$ is covered by a family of open sets $U_\alpha$, and $\Lambda$ and $\Psi$ are locally equal on each $U_\alpha$, then $\Lambda = \Psi$. If we have a family of distributions $\Lambda_\alpha$ which agree with one another on $U_\alpha \cap U_\beta$, then there is a unique distribution $\Lambda$ locally equal to each $\Lambda_\alpha$.
\end{theorem}
\begin{proof}
    Since we can find a $C^\infty$ partition of unity $\psi_\alpha$ compactly supported on the $U_\alpha$, upon which we find if $\phi$ is supported on $K$, then finitely many of the $\psi_\alpha$ are non-zero on $K$, and so
    %
    \[ \Lambda(\phi) = \sum \Lambda(\psi_\alpha \phi) = \sum \Psi(\psi_\alpha \phi) = \Psi(\phi) \]
    %
    Thus $\Lambda = \Psi$. Conversely, if we have a family of distributions $\Lambda_\alpha$ like in the hypothesis, then we can find a partition of unity $\psi_{\alpha \beta}$ subordinate to $U_\alpha \cap U_\beta$, and we can define
    %
    \[ \Lambda(\phi) = \sum \Lambda_\alpha(\psi_{\alpha \beta} \phi) = \sum \Lambda_\beta(\psi_{\alpha \beta} \phi) \]
    %
    The continuity is verified by fixing a compact $K$, from which there are only finitely many nonzero $\psi_{\alpha \beta}$ on $K$, and the fact that this definition is independant of the partition of unity follows from the first part of the theorem.
\end{proof}

In the language of modern commutative algebra, the association of $C_c^\infty(U)^*$ to each open subset $U$ of $\Omega$ gives a sheaf structure to $\Omega$. Given a distribution $\Lambda$, we might have $\Lambda(\phi) = 0$ for every $\phi$ supported on some open set $U$. The complement of the largest open set $U$ for which this is true is called the {\bf support} of $\Lambda$. If $f$ vanishes on a neighbourhood of the support of $\Lambda$, then by definition of the support, $\Lambda f = 0$. The neighbourhood condition is important -- $\delta'$ is supported on $\{ 0 \}$, since $\delta$ is, but it certainly doesn't vanish on $f$ if $f(0) = 0$.

\begin{theorem}
    If a distribution has precompact support, the distribution has finite order, and extends uniquely to a continuous linear functional on $C^\infty(X)$.
\end{theorem}
\begin{proof}
    Let $\Lambda$ be a distribution supported on a compact set. If $\psi$ is a function with compact support with $\psi(x) = 1$ on the support of $\Lambda$, then $\psi \Lambda = \Lambda$, because for any $\phi$, $\phi - \phi \psi$ is supported on a set disjoint from the support of $\Lambda$. But if $\psi$ is supported on $K$, then there is $N$ such that for any $\phi \in C_c^\infty(K)$,
    %
    \[ |\Lambda(\phi)| \lesssim \| \phi \|_{N,K} \]
    %
    and so for any other compact set $K$,
    %
    \[ |\Lambda(\phi)| = |\Lambda(\phi \psi)| \lesssim \| \phi \psi \|_{N,K} \lesssim \| \psi \|_{C^N(K)} \| \phi \|_{C^N(K)} \]
    %
    which shows $\Lambda$ has order $N$. We have shown that $\Lambda$ is continuous with respect to the seminorm $\| \cdot \|_{C^N(K)}$ on $C^\infty(X)$, and so by the Hahn Banach theorem, $\Lambda$ extends uniquely to a continuous functional on $C^\infty(X)$.
\end{proof}

\begin{example}
    If $\Lambda(\phi) = \sum_{|\alpha| \leq N} \lambda_\alpha D^\alpha \phi(x)$, then $\Lambda$ is supported on $x$. Conversely, every distribution $\Lambda$ supported on $x$ is of this form. We know $\Lambda$ must have finite order $N$, and consider $\phi$ with $D^\alpha \phi(x) = 0$ for all $|\alpha| \leq N$. We claim $\Lambda(\phi) = 0$. Fix $\varepsilon > 0$, and choose a compact neighbourhood $K$ of the origin with $|D^\alpha \phi(x)| < \varepsilon$ on $K$ for all $|\alpha| = N$. Then for $|\alpha| < N$, the mean value theorem implies that, by induction,
    %
    \[ |D^\alpha \phi(x)| \leq \varepsilon n^{N - |\alpha|} |x|^{N-|\alpha|} \]
    %
    Find $A$ such that for functions $\phi$ supported on $K$,
    %
    \[ |\Lambda(\phi)| \leq A \| \phi \|_{C^N(K)} \]
    %
    Fix a bump function $\psi$ with support on the ball of radius one and $\psi(x) = 1$ in a neighbourhood of the origin, and define $\psi_\delta(x) = \psi(x/\delta)$. If $\delta$ is small enough, then $\psi$ is supported on $K$, and because $\Lambda$ is supported on $x$,
    %
    \begin{align*}
        |\Lambda(\phi)| &= |\Lambda(\phi \psi_\delta)| \leq A \| \phi \psi_\delta \|_{C^N(K)}\\
        &\leq A \sum_{|\alpha + \beta| = N} |c_{\alpha \beta}| \| D^\alpha \phi \|_\infty \| D^\beta \psi_\delta \|\\
        &\leq A \| \psi \|_{C^N} \sum_{|\alpha + \beta| = N} |c_{\alpha \beta}| \delta^{|\beta| - |\alpha|} \| D^\beta \phi \|_{L^\infty(K)}\\
        &\leq \varepsilon A \left( \sum_{|\alpha + \beta| = N} |c_{\alpha \beta}| n^{N - |\beta|} \right)
    \end{align*}
    %
    We can then let $\varepsilon \to 0$ to conclude $\Lambda(\phi) = 0$. But this means that $\Lambda(\phi)$ is a linear function of the partial derivatives of $\phi$ with order $\leq N$, completing the proof.
\end{example}

\begin{example}
    If $\delta$ is the Dirac delta distribution, then $f \delta = f(0) \delta$ for any smooth function $f$. Thus, in particular, $x \delta = 0$. Conversely, if $\Lambda$ is any distribution with $x \Lambda = 0$, then $\Lambda$ is a multiple of the Dirac delta distribution. To see this, we note that this would imply $\Lambda(f) = 0$ for all functions $f$ such that $f/x$ is also smooth and compactly supported. In particular, this is true if the support of $f$ does not contain the origin. Thus $\Lambda$ is supported on the origin, hence there are constants $a_n$ such that
    %
    \[ \Lambda f = \sum_{n = 0}^N a_n f^{(n)}(0) \]
    %
    But $(xf)^{(n)}(0) = n f^{(n-1)}(0)$ only vanishes for all $f$ when $n = 0$, so $\Lambda$ is a multiple of the Dirac delta distribution. A more simple way to see this is that if $f$ is compactly supported on $[-N,N]$, the function
    %
    \[ g(x) = \frac{f(x) - f(0)}{x} = \int_0^1 f'(tx)\; dt \]
    %
    is smooth, and $f = f(0) + xg$. Since $\Lambda$ and $x \Lambda$ have bounded support, they extend uniquely to $C^\infty(\Omega)$, and so $\Lambda f = f(0) \Lambda 1 + \Lambda(xg) = f(0) \Lambda 1$.
\end{example}

In many other ways, distributions act like functions. For instance, any distribution $\Lambda$ can be uniquely written as $\Lambda_1 + i \Lambda_2$ for two distributions $\Lambda_1, \Lambda_2$ that are real valued for any real-valued smooth continuous function. However, we cannot write a real-valued distribution as the difference of two positive distributions, i.e. those which are non-negative when evaluated at any non-negative functional. Given a non-negative functional $\Lambda$,  we define $\Lambda f$ for a compactly supported continuous function $f \geq 0$ as
%
\[ \Lambda f = \sup \{ \Lambda g: g \in C_c^\infty(\RR^n), g \leq f \} \]
%
and then in general define $\Lambda (f^+ - f^-) = \Lambda f^+ - \Lambda f^-$. Then $\Lambda$ is obviously a positive extension of $\Lambda$ to all continuous functions, and is linear. But then the Riesz representation theorem implies that there is a positive Radon measure such that $\Lambda = \Lambda_\mu$, completing the proof.

\section{Derivatives of Continuous Functions}

One of the main reasons to consider the theory of distributions is so that we can take the derivative of any function we want. We now show that, at least locally, every distribution is the derivative of some continuous function, which means the theory of distributions is essentially the minimal such class of objects which enable us to take derivatives of continuous functions.

\begin{theorem}
    If $\Lambda$ is a distribution on $\Omega$, and $K$ is a compact set, then there is a continuous function $f$ and $\alpha$ such that for every $\phi$,
    %
    \[ \Lambda \phi = (-1)^{|\alpha|} \int_\Omega f(x) (D^\alpha \phi)(x)\; dx \]
\end{theorem}
\begin{proof}
    TODO
\end{proof}

\begin{theorem}
    If $K$ is compact, contained in some open subset $V$, which in turn is a subset of $\Omega$, and $\Lambda$ has order $N$, then there exists finitely many continuous functions $f_\beta \in C(\Omega)$ supported on $V$, for each $|\beta| \leq N + 2$, with supports on $V$, and with $\Lambda = \sum D^\beta f_\beta$.
\end{theorem}

\begin{theorem}
    If $\Lambda$ is a distribution on $\Omega$, then there exists continuous functions $g_\alpha$ on $\Omega$ such that each compact set $K$ intersects the supports of finitely many of the $g_\alpha$, and $\Lambda = \sum D^\alpha g_\alpha$. If $\Lambda$ has finite order, then only finitely many of the $g_\alpha$ are nonzero.
\end{theorem}

\section{Convolutions of Distributions}

Using the convolution of two functions as inspiration, we will not define the convolution of a distribution $\Lambda$ with a test function $\phi$, and under certain conditions, the convolution of two distributions. Recall that if $f,g \in L^1(\RR^n)$, then their convolution is the function in $L^1(\RR^n)$ defined by
%
\[ (f * g)(x) = \int f(y) g(x - y)\; dy \]
%
If we define the translation operators $(T_y g)(x) = g(x-y)$, then $(f * g)(x) = \int f(y) (T_x g^*)(y)\; dy$, where $g^*$ is the function defined by $g^*(x) = g(-x)$. Thus, if $\Lambda$ is any distribution on $\RR^n$, and $\phi$ is a test function on $\RR^n$, we can define a function $\Lambda * \phi$ by setting $(\Lambda * \phi)(x) = \Lambda(T_x \phi^*)$. Notice that since
%
\begin{align*}
    \int (T_x f)(y) g(y)\; dy &= \int f(y-x) g(y)\; dy = \int f(y) g(x+y)\; dy\\
    &= \int f(y) (T_{-x}g)(y)\; dy,
\end{align*}
%
so we can also define the translation operators on distributions by setting $(T_x \Lambda)(\phi) = \Lambda (T_{-x} \phi)$. One mechanically verifies that convolution commutes with translations, i.e. $T_x (\Lambda * \phi) = (T_x \Lambda) * \phi = \Lambda * (T_x \phi)$.

\begin{theorem}
    $\Lambda * \phi$ is $C^\infty$, and $D^\alpha(\Lambda * \phi) = (D^\alpha \Lambda) * \phi = \Lambda * (D^\alpha \phi)$.
\end{theorem}
\begin{proof}
    It is easy to calculate that
    %
    \begin{align*}
        (D^\alpha \Lambda * \phi)(x) &= (D^\alpha \Lambda)(\phi^*_x) = (-1)^{|\alpha|} \Lambda(D^\alpha (T_x \phi^*))\\
        &= \Lambda(T_x (D^\alpha \phi)^*) = (\Lambda * D^\alpha \phi)(x)
    \end{align*}
    %
    If $e$ is a unit vector, and we set $\Delta_h = h^{-1} (1 - T_{he})$, then $\Delta_h \phi$ converges to $D_e \phi$ in $C_c^\infty(\RR^n)$, and as such,
    %
    \begin{align*}
        \Delta_h(\Lambda * \phi)(x) &= \frac{(\Lambda * \phi)(x) - (\Lambda * \phi)(x - he)}{h}\\
        &= \frac{\Lambda(T_x \phi^* - T_{-he} (T_x \phi^*)}{h} = \Lambda(T_x(\Delta_h \phi^*))
    \end{align*}
    %
    and this converges to $\Lambda(D_e \phi^*) = (\Lambda * D_e \phi)(x)$ as $h \to 0$. Iteration of this fact gives the general result.
\end{proof}

\begin{theorem}
    If $\phi, \psi \in C_c^\infty(\RR^n)$, then $\Lambda * (\phi * \psi) = (\Lambda * \phi) * \psi$.
\end{theorem}
\begin{proof}
    Let $\phi$ and $\psi$ be supported on $K$. We calculate
    %
    \[ (\phi * \psi)^*(x) = \int \phi^*(x + y) \psi(y)\; dy = \int (T_y \phi)^*(x) \psi(y)\; dy \]
    %
    since the map $y \mapsto (T_y \phi)^* \psi(y)$ is continuous, and vanishes out of the compact set $K$, so that we have a $C_c^\infty(K)$ valued integral
    %
    \[ (\phi * \psi)^* = \int_K \psi^*(y) T_y \phi^*\; ds \]
    %
    This means precisely that
    %
    \begin{align*}
        (\Lambda * (\phi * \psi))(0) &= \Lambda((\phi * \psi)^*) = \int_K \psi^*(y) \Lambda(T_y \phi^*)\; dy\\
        &= \int_K \psi^*(y) (\Lambda * \phi)(y)\; dy = ((\Lambda * \phi) * \psi)(0)
    \end{align*}
    %
    The commutativity in general results from applying the commutativity of the translation operators.
\end{proof}

A net $\phi_\alpha$ is known as an {\it approximate identity} in the space of distributions if $\Lambda * \phi_\alpha \to \Lambda$ as distributions for every distribution $\phi$, and an approximate identity in the space of test functions if $\psi * \phi_\alpha \to \psi$ in $C_c^\infty(\RR^n)$.

\begin{theorem}
    If $\phi_\alpha$ is a family of non-negative functions in $C_c^\infty(\RR^n)$ which are eventually supported on every neighbourhood of the origin, and integrate to one, then $\phi_\alpha$ is an approximation to the identity in the space of test functions and in the space of distributions.
\end{theorem}
\begin{proof}
    It is easy to verify that if $f$ is a continuous function, then $f * \phi_\delta$ converges locally uniformly to $f$ as $\delta \to 0$. But now we calculate that if $f \in C_c^\infty(\RR^n)$, then $D^\alpha(f * \phi_\delta) = (D^\alpha f) * \phi_\delta$ converges locally uniformly to $D^\alpha \phi$, which gives that $f * \phi$ converges to $f$ in $C_c^\infty(\RR^n)$. Now if $\Lambda$ is a distribution, and $\psi$ is a test function, then continuity gives
    %
    \begin{align*}
        \Lambda(\psi^*) &= \lim_{\delta \to 0} \Lambda(\phi_\delta * \psi) = \lim_{\delta \to 0} (\Lambda * (\phi_\delta * \psi))(0)\\
        &= \lim_{\delta \to 0} ((\Lambda * \phi_\delta) * \psi)(0) = \lim_{\delta \to 0} (\Lambda * \phi_\delta)(\psi^*)
    \end{align*}
    %
    and $\psi$ was arbitrary.
\end{proof}

If $\Lambda$ is a distribution on $\RR^n$, then the map $\phi \mapsto \Lambda * \phi$ is a linear transformation from $C_c^\infty(\RR^n)$ into $C^\infty(\RR^n)$, which commutes with translations. It is also continuous. To see this, we consider a fixed compact $K$, and consider the map from $C_c^\infty(K)$ to $C^\infty(\RR^n)$. We can apply the closed graph theorem to prove continuity, so we assume the existence of $\phi_1, \phi_2, \dots$ converging to $\phi$ in $C_c^\infty(K)$ and $\Lambda * \phi_1, \Lambda * \phi_2, \dots$ converges to $f$. It suffices to show $f = \Lambda * \phi$. But we calculate
%
\[ f(x) = \lim (\Lambda * \phi_n)(x) = \lim \Lambda(T_x \phi^*_n) = \Lambda (\lim T_x \phi^*_n) = \Lambda(T_x \phi^*) = (\Lambda * \phi)(x) \]
%
where we have used the fact that $T_x \phi_n^*$ converges to $T_x \phi^*$ in $C_c^\infty(\RR^n)$. Suprisingly, the converse is true.

\begin{theorem}
    If $L: C_c^\infty(\RR^n) \to C^\infty(\RR^n)$ and commutes with translations, then there is a distribution $\Lambda$ such that $L(\phi) = \Lambda * \phi$.
\end{theorem}
\begin{proof}
    If $L(\phi) = \Lambda * \phi$, then we would have
    %
    \[ \Lambda(\phi) = (\Lambda * \phi^*)(0) = L(\phi^*)(0) \]
    %
    and we take this as the definition of $\Lambda$. $\Lambda$ is continuous because all the operations here are continuous, and because $L$ commutes with translations, we conclude
    %
    \[ (\Lambda * \phi)(x) = \Lambda(T_x \phi^*) = L(T_{-x} \phi)(0) = L(\phi)(x) \]
    %
    which gives the theorem.
\end{proof}

We now move onto the case where a distribution $\Lambda$ has compact support. Then $\Lambda$ extends to a continuous functional on $C^\infty(\RR^n)$, and we can define the convolution $\Lambda * \phi$ if $\phi \in C^\infty(\RR^n)$. The same techniques as before verify that translations and derivatives are carried into the convolution.

\begin{theorem}
    If $\phi$ and $\Lambda$ have compact support, then $\Lambda * \phi$ has compact support.
\end{theorem}
\begin{proof}
    Let $\phi$ and $\Lambda$ be supported on $K$. Then $(\Lambda * \phi)(x) = \Lambda(T_x \phi^*)$. Since $T_x \phi^*$ is supported on $x - K$, for $x$ large enough $x-K$ is disjoint from $K$, and so $\Lambda * \phi$ vanishes outside of $K + K$.
\end{proof}

\begin{theorem}
    If $\Lambda$ and $\psi$ have compact support, and $\phi \in C^\infty(\RR^n)$, then
    %
    \[ \Lambda * (\phi * \psi) = (\Lambda * \phi) * \psi = (\Lambda * \psi) * \phi \]
\end{theorem}
\begin{proof}
    Let $\Lambda$ and $\psi$ be supported on some balanced compact set $K$. Let $V$ be a bounded, balanced open set containing $K$. If $\phi_0$ is a function with compact support equal to $\phi$ on $V + K$, then for $x \in V$,
    %
    \[ (\phi * \psi)(x) = \int \phi(x - y) \psi(y)\; dy = \int \phi_0(x - y) \psi(y)\; dy = (\phi_0 * \psi)(x) \]
    %
    Thus
    %
    \[ (\Lambda * (\phi * \psi))(0) = (\Lambda * (\phi_0 * \psi))(0) = ((\Lambda * \psi) * \phi_0)(0) \]
    %
    But $\Lambda * \psi$ is supported on $K + K$, so $((\Lambda * \psi) * \phi_0)(0) = ((\Lambda * \psi) * \phi)(0)$. Now we also calculate
    %
    \[ (\Lambda * (\phi * \psi))(0) = ((\Lambda * \phi_0) * \psi)(0) = ((\Lambda * \phi) * \psi)(0) \int (\Lambda * \phi_0)(-y) \psi(y) \]
    %
    where the last fact follows because $\Lambda * \phi_0$ agrees with $\Lambda * \phi$ on $K$. The general fact follows by applying the translation operators.
\end{proof}

Now we come to the grand finale, defining the convolution of two distributions. Given two distributions $\Lambda$ and $\Psi$, one of which has compact support, we define the linear operator
%
\[ L(\phi) = \Lambda * (\Psi * \phi) \]
%
Then $L$ commutes with translations, and is continuous, because if we have $\phi_1, \phi_2, \dots$ converging to $\phi$ in $C_c^\infty(K)$, then $\Psi * \phi_n$ converges to $\Psi * \phi$ in $C^\infty(\RR^n)$. If $\Psi$ is supported on a compact support $C$, then the $\Psi * \phi_n$ have common compact support $C + K$, and actually converge in $C_c^\infty(C + K)$, hence $\Lambda * (\Psi * \phi_n)$ converges to $\Lambda * (\Psi * \phi)$. Conversely, if $\Lambda$ has compact support, then $\Psi * \phi_n$ converges in $C^\infty(\RR^n)$, which implies $\Lambda * (\Psi * \phi_n)$ converges to $\Lambda * (\Psi * \phi)$ in $C^\infty(\RR^n)$. Thus $L$ corresponds to a distribution, and we define this distribution to be $\Lambda * \Psi$.

\begin{theorem}
    If $\Lambda$ and $\Psi$ are distributions, one of which has compact support, then $\Lambda * \Psi = \Psi * \Lambda$. Let $S_\Lambda$ and $S_\Psi$, and $S_{\Lambda * \Psi}$ denote the supports of $\Lambda$, $\Psi$, and $\Lambda * \Psi$. Then $\Lambda * \Psi = \Psi * \Lambda$, and $S_{\Lambda * \Psi} \subset S_\Lambda + S_\Psi$.
\end{theorem}
\begin{proof}
    We calculate that for any two test functions $\phi$ and $\psi$,
    %
    \[ (\Lambda * \Psi) * (\phi * \psi) = \Lambda * (\Psi * (\phi * \psi)) = \Lambda * ((\Psi * \phi) * \psi) \]
    %
    If $\Lambda$ has compact support, then
    %
    \[ \Lambda * ((\Psi * \phi) * \psi) = (\Lambda * \psi) * (\Psi * \phi) \]
    %
    Conversely, if $\Psi$ has compact support, then
    %
    \[ \Lambda * ((\Psi * \phi) * \psi) = \Lambda * (\psi * (\Psi * \phi)) = (\Lambda * \psi) * (\Psi * \phi) \]
    %
    We also calculate
    %
    \begin{align*}
        \Psi * ((\Lambda * \phi) * \psi) &= \Psi * (\Lambda * (\phi * \psi)) = \Psi * (\Lambda * (\psi * \phi))\\
        &= \Psi * ((\Lambda * \psi) * \phi) = (\Psi * \phi) * (\Lambda * \psi)
    \end{align*}
    %
    But since convolution is commutative, we have
    %
    \[ ((\Lambda * (\Psi * \phi)) * \psi) = \Lambda * ((\Psi * \phi) * \psi) = \Psi * ((\Lambda * \phi) * \psi) = (\Psi * (\Lambda * \phi)) * \psi \]
    %
    Since $\psi$ was arbitrary, we conclude
    %
    \[ (\Lambda * \Psi) * \phi = \Lambda * (\Psi * \phi) = \Psi * (\Lambda * \phi) = (\Psi * \Lambda) * \phi \]
    %
    and now since $\phi$ was arbitrary, we conclude $\Lambda * \Psi = \Psi * \Lambda$. Now we know convolution is commuatative, we may assume $S_\Psi$ is compact. The support of $\Psi * \phi^*$ lies in $S_\Psi - S_\phi$. But this means that if $S_\phi - S_\Psi$ is disjoint from $S_\Lambda$, which means exactly that $S_\phi$ is disjoint from $S_\Lambda + S_\Psi$, then
    %
    \[ (\Lambda * \Psi)(\phi) = (\Lambda * (\Psi * \phi))(0) = 0 \]
    %
    and this gives the support of $\Lambda * \Psi$.
\end{proof}

This means that the convolution of two distributions with compact support also has compact support. This means that if we have three distributions $\Lambda, \Psi$, and $\Phi$, two of which have compact support, then the distributions $\Lambda * (\Psi * \Phi)$ and $(\Lambda * \Psi) * \Phi$ are well defined, so convolution is associative and commutative. We calculate that for any test function $\phi$,
%
\[ (\Lambda * (\Psi * \Phi)) * \phi = \Lambda * (\Psi * (\Phi * \phi)) \]
\[ ((\Lambda * \Psi) * \Phi) * \phi = (\Lambda * \Psi) * (\Phi * \phi) \]
%
If $\Phi$ has compact support, then $\Phi * \phi$ has compact support, and so we can move $(\Lambda * \Psi)$ into the equation to prove equality. If $\Phi$ does not have compact support, then $\Lambda$ and $\Psi$ have compact support, and
%
\[ \Lambda * (\Psi * \Phi) = \Lambda * (\Phi * \Psi) \]
%
and we can apply the previous case to obtain that this is equal to $(\Lambda * \Phi) * \Psi$. Repeatedly applying the previous case brings this to what we want.

\begin{theorem}
    If $\Lambda$ and $\Psi$ are distributions, then
    %
    \[ D^\alpha(\Lambda * \Psi) = (D^\alpha \Lambda) * \Psi = \Lambda * (D^\alpha \Psi) \]
\end{theorem}
\begin{proof}
    The Dirac delta function $\delta$ satisfies
    %
    \[ (\delta * \phi)(x) = \int \phi(y) \delta(x-y)\; dy = \phi(x) \]
    %
    so $\delta * \phi = \phi$. Now $D^\alpha \delta$ is also supported at $x$, since
    %
    \[ (D^\alpha \delta)(\phi) = (-1)^{|\alpha|} \int \delta(x) (D^\alpha \phi)(x)\; dx = (-1)^{|\alpha|} (D^\alpha \phi)(0) \]
    %
    which means that for any distribution $\Lambda$, then $(D^\alpha \delta) * \Lambda$ has compact support,
    %
    \[ (((D^\alpha \delta) * \Lambda) * \phi)(0) = (D^\alpha \delta)((\Lambda * \phi)^*) = (-1)^{|\alpha|} D^\alpha (\Lambda * \phi)^* = ((D^\alpha \Lambda) * \phi)(0) \]
    %
    which verifies that $(D^\alpha \delta) * \Lambda = \delta * (D^\alpha \Lambda)$. But now we find
    %
    \[ D^\alpha(\Lambda * \Psi) = (D^\alpha \delta) * \Lambda * \Psi = ((D^\alpha \delta) * \Lambda) * \Psi = D^\alpha \Lambda * \Psi \]
    \[ D^\alpha(\Lambda * \Psi) = D^\alpha(\Psi * \Lambda) = (D^\alpha \Psi) * \Lambda = \Lambda * (D^\alpha \Psi) \]
    %
    which verifies the theorem in general.
\end{proof}

\section{Schwartz Space and Tempered Distributions}

We have already encountered the fact that Fourier transforms are well behaved under differentiation and multiplication by polynomials. If we let $\mathcal{S}(\RR^d)$ denote a class of functions under which to study this phenomenon, it must be contained in $L^1(\RR^d)$ and $C^\infty(\RR^d)$, and also be closed under multiplication by polynomials. The differentiability and polynomial closure imply that the elements of $\mathcal{S}(\RR^d)$ must have rapid decay properties: For any non-negative integer $m$ and multi-index $\alpha$, there exists a constant $C_{\alpha,\beta}$ such that
%
\[ |f_\alpha(x)| \leq \frac{C_{\alpha,m}}{1 + |x|^m}. \]
%
We take this as a \emph{definition} of the space $\mathcal{S}(\RR^d)$. That is, for each non-negative integer $n$ and $m$, we consider the seminorm
%
\[ \| f \|_{n,m} = \sup_{|\beta| \leq n} \| (1 + |x|)^m f_\beta \|_{L^\infty(\RR^d)}. \]
%
We then consider
%
\[ \mathcal{S}(\RR^d) = \left\{ f: \RR^d \to \RR: \text{for all}\ n,m, \| f \|_{n,m} < \infty \right\}. \]
%
Elements of $\mathcal{S}(\RR^d)$ are known as \emph{Schwartz functions}, and $\mathcal{S}(\RR^d)$ is known as the \emph{Schwartz space}. The seminorms naturally give $\mathcal{S}(\RR^d)$ the structure of a Fr\'{e}chet space. Sometimes, it is more convenient to use the equivalent family of seminorms $\| f \|_{\alpha, \beta} = \| x^\alpha f_\beta \|_{L^\infty(\RR^d)}$, because $x^\alpha$ often behaves more nicely under various operations. It is obvious that $\mathcal{S}(\RR^d)$ is separated by the seminorms defined on it, because $\| \cdot \|_{L^\infty(\RR^d)} = \| \cdot \|_{0,0}$ is a norm used to define the space. We now show the choice of seminorms make the space complete.

\begin{theorem}
    $\mathcal{S}(\RR^d)$ is a complete metric space.
\end{theorem}
\begin{proof}
    Let $\{ f_1,f_2, \dots \}$ be a Cauchy sequence with respect to the seminorms. This implies that for each integer $m$, and multi-index $\alpha$, the sequence of functions $(1 + |x|)^m (f_k)_\alpha$ is Cauchy in $L^\infty(\RR^d)$. Since $L^\infty(\RR^d)$ is complete, there are functions $g_{m,\alpha}$ such that $(1 + |x|)^m (f_k)_\alpha$ converges uniformly to $g_{m,\alpha}$. If we set $f = g_{0,0}$, then it is easy to see using the basic real analysis of uniform continuity that $f$ is infinitely differentiable, and $(1 + |x|)^m f_\alpha = g_{m,\alpha}$. This shows that $f \in C^\infty(\RR^d)$. The sequence $\{ f_k \}$ is bounded in $\mathcal{S}(\RR^d)$, since it is Cauchy. And since $\| f_k - f \|_{n,m} \to 0$ for each $n$ and $m$, this implies that $\| f \|_{n,m} < \infty$ for each $n$ and $m$. Thus $f \in \mathcal{S}(\RR^d)$, and $f_k \to f \in \mathcal{S}(\RR^d)$.
\end{proof}

\begin{example}
    The Gaussian function $\phi: \RR^d \to \RR$ defined by $\phi(x) = e^{-|x|^2}$ is Schwartz. For any multi-index $\alpha$, there is a polynomial $P_\alpha$ of degree at most $|\alpha|$ such that $\phi_\alpha = P_\alpha \phi$; this can be established by a simple induction. But this means that for each fixed $\alpha$, $|P_\alpha(x)| \lesssim 1 + |x|^{|\alpha|}$. Since $e^{-|x|^2} \lesssim 1/(1 + |x|)^{m + |\alpha|}$ for any fixed $m$ and $\alpha$, we find
    %
    \[ | (1 + |x|)^m \phi_\alpha| \leq (1 + |x|)^m |P_\alpha \phi| \lesssim \frac{1 + |x|^{|\alpha| + m}}{1 + |x|^{|\alpha| + m}} = 1. \]
    %
    Since $m$ and $\alpha$ were arbitrary, this shows $\phi$ is Schwartz.
\end{example}

\begin{example}
    The space $C^\infty_c(\RR^d)$ consists of all compactly supported $C^\infty$ functions. If $f \in C^\infty_c(\RR^d)$, then $f$ is Schwartz. This is because for each $\alpha$ and $m$, $(1 + |x|)^m f_\alpha$ is a continuous function vanishing outside a compact set, and is therefore bounded.
\end{example} 

Because of the sharp control we have over functions in $\mathcal{S}(\RR^d)$, almost every analytic operation we want to perform on $\mathcal{S}(\RR^d)$ is continuous. To show that an operator $T$ on $\mathcal{S}(\RR^d)$ is bounded, it suffices to show that for each $n$ and $m$, there is $n'$, $m'$ such that $\| Tf \|_{n,m} \lesssim_{n,m} \| f \|_{n',m'}$. For a functional $\Lambda: \mathcal{S}(\RR^d) \to \RR$, it suffices to show that there exists $n$ and $m$ such that $|\Lambda f| \lesssim \| f \|_{n,m}$. The minimal such choice of $n$ is known as the {\bf order} of $\Lambda$. We normally do not care about the constant behind the operators for these norms, since the norms are not translation invariant and therefore highly sensitive to the positions of various operations. We really just care about proving the existence of such a constant.

\begin{lemma}
    If $g$ is a function, with $g$ and all it's derivatives subpolynomial, then the map $f \mapsto gf$ is a bounded operator on $\mathcal{S}(\RR^d)$.
\end{lemma}
\begin{proof}
    Fix $n$, and find values $A$ and $M$, depending only on $n$ and $g$, such that for any $|\beta| \leq n$,
    %
    \[ |g_\beta(x)| \leq A \cdot (1 + |x|)^M. \]
    %
    Consider $|\alpha| \leq n$. Then the Leibnitz formula implies that
    %
    \begin{align*}
        (1 + |x|)^m |(gf)_\alpha| &\leq 2^{|\alpha|} \sum_{\beta \leq \alpha} (1 + |x|)^m |g_\beta f_{\alpha-\beta}|\\
        &\leq A \cdot 2^n \sum_{\beta \leq \alpha} (1 + |x|)^{m+M} |f_{\alpha-\beta}|\\
        &\leq A \cdot 4^n \| f \|_{n,m+M}.
    \end{align*}
    %
    Thus $\| gf \|_{n,m} \lesssim_{n,m} \| f \|_{n,m+M}$, which implies the operator is bounded.
\end{proof}

If $f$ and $g$ are Schwartz functions, and $|\alpha| \leq n$, then the Leibnitz formula again implies that if $k + k' = m$, then
%
\begin{align*}
    (1 + |x|)^m (gf)_\alpha &\lesssim_n \sum_{\beta \leq \alpha} (1 + |x|)^m g_\beta f_{\alpha - \beta} \lesssim_n \| f \|_{n,k} \| g \|_{n,k'}
\end{align*}
%
Thus $\| gf \|_{n,m} \lesssim_{n,m} \| f \|_{n,k} \| g \|_{n,k'}$, so $(f,g) \mapsto fg$ is a continuous bilinear operator on $\mathcal{S}(\RR^d) \times \mathcal{S}(\RR^d)$. Most importantly, we have shown the product of two Schwartz functions is Schwartz.

\begin{theorem}
    The following sublinear operators are all bounded on $\mathcal{S}(\RR^n)$.
    %
    \begin{itemize}
        \item For each $h \in \RR^n$, the translation operator $(T_h f)(x) = f(x - h)$.

        \item For each $\xi \in \RR^n$, the modulation operator $(M_\xi f)(x) = e(\xi \cdot x) f(x)$.

        \item The $L^p$ norms $\| f \|_{L^p(\RR^n)}$, for $1 \leq p \leq \infty$.

        \item The Fourier transform.
    \end{itemize}
    %
    Furthermore, the Fourier transform is an isomorphism of $\mathcal{S}(\RR^n)$.
\end{theorem}
\begin{proof}
%   Let $(T_h f)(x) = f(x - h)$. We calculate that if $|\alpha| \leq n$, then
    %
%   \begin{align*}
%       (1 + |x|^m) (T_h f)_\alpha &= T_h((1 + |x + h|^m) f_\beta)\\
%       &\leq 2^m T_h((1 + |x|^m + |h|^m) f_\alpha)\\
%       &\leq 2^m |h|^m \| f_\alpha \|_{n,0} + 2^m \| f \|_{n,m}.
%   \end{align*}
    %
%   Thus $\| T_h f \|_{n,m} \leq 2^m(1 + |h|^m) \| f \|_{n,m}$, so $T_h$ is continuous.

%   Similarily, we calculate using the Leibnitz formula and the formula for the derivatives of $e(\xi \cdot x)$ that if $|\alpha| \leq n$, then
    %
%   \[ (1 + |x|^m) |(e(\xi \cdot x) f)_\alpha| \leq 4^n (2\pi)^n (1 + |\xi|^n) \| f \|_{n,m} \]
    %
%   Thus $\| M_\xi f \|_{n,m} \leq (8 \pi)^n (1 + |\xi|^n) \| f \|_{n,m}$.

%   For any Schwartz function $f$, and $|\alpha| \leq n$,
    %
%   \[ f(x) \leq \frac{\| f \|_{0,d+1}}{1 + |x|^{d+1}} \]
    %
%   Integrating this equation gives
    %
%   \[ \| f_\alpha \|_{L^1(\RR^d)} \leq 2^d \| f \|_{0,d+1}. \]
    %
%   Thus $\| \cdot \|_1$ is a bounded norm on the space. Interpolation then shows that for any $1 < p < \infty$,
    %
%   \[ \| f \|_{L^p(\RR^d)} \leq \| f \|_{L^1(\RR^d)}^{1 - 1/p} \| f \|_{L^\infty(\RR^d)}^{1/p} \leq \| f \|_{L^1(\RR^d)} + \| f \|_{L^\infty(\RR^d)} \leq 2 \| f \|_{0,d+1}. \]
    %
%   This implies $\| \cdot \|_{L^p(\RR^d)}$ is bounded.

%   A simple calculation using the Leibnitz formula shows that if $|\alpha| \leq n$,
    %
%   \begin{align*}
%       (1 + |x|^m) |\mathcal{F}(f)_\alpha| &\leq |\mathcal{F}(f)_\alpha| + \sum_{k = 1}^d |x_k^m \mathcal{F}(f)_\alpha|\\
%       &\leq (2 \pi)^n \left( \| \mathcal{F} f \|_{L^\infty(\RR^d)} + \sum_{k = 1}^d |\mathcal{F}((x^\alpha f)_{me_k})| \right)\\
%       &\leq n! (2 \pi)^n 2^m (n+1) \max_{0 \leq k \leq d} \max_{1 \leq l \leq m} \left( \| \mathcal{F} f \|_{L^\infty(\RR^d)} + \sum_{k = 1}^n \max_{1 \leq l \leq m} \| \mathcal{F}(f_{le_k}) \|_{L^\infty(\RR^d)} \right)\\
%       &\leq n! (2 \pi)^n 2^m \left( \| f \|_{L^1(\RR^d)} + \sum_{k = 1}^n \max_{1 \leq l \leq m} \| f_{le_k} \|_{L^1(\RR^d)} \right)\\
%       &\leq n! (2 \pi)^n 2^m 2^d (n+1) \| f \|_{n,d+1}.
%   \end{align*}

%   there are constants $c_{\alpha \beta \gamma}$ for each $\gamma \leq \alpha \wedge \beta$ such that
    %
%   \begin{align*}
%       |x^\alpha \mathcal{F}(f)_\beta| &= (2 \pi)^{|\beta|} |x^\alpha \cdot \mathcal{F}(x^\beta f)|\\
%       &= (2\pi)^{|\beta| - |\alpha|} \mathcal{F}((x^\beta f)_\alpha)\\
%       &\leq (2\pi)^{|\beta| - |\alpha|} \sum_{\gamma \leq \alpha \wedge \beta} c_{\alpha \beta \gamma} |\mathcal{F}(x^{\beta - \gamma} f_{\alpha - \gamma})|.
%   \end{align*}
    %
%   This calculation shows
    %
%   \begin{align*}
%       \| \mathcal{F} f \|_{\alpha,\beta} &\lesssim_{\alpha,\beta} \sum \| \mathcal{F}(x^{\beta - \gamma} f_{\alpha - \gamma}) \|_{L^\infty(\RR^n)}\\
%       &\leq \sum \| x^{\beta - \gamma} f_{\alpha - \gamma} \|_{L^1(\RR^n)}.
%   \end{align*}
    %
%   The right hand side is a continuous function of $f$, so the Fourier transform is bounded. The smoothness of the Schwartz space implies that $\mathcal{F}$ is a bijective map. But then the open mapping theorem implies that $\mathcal{F}^{-1}$ is a bounded operation, and therefore $\mathcal{F}$ is a homeomorphism.

    We leave all but the last point as exercises. Here it will be convenient to use the norms $\| \cdot \|_{\alpha,\beta}$ as well as the norms $\| \cdot \|_{n,m}$. If $|\alpha| \leq m$, $|\beta| \leq n$, then we can use the Leibnitz formula to conclude that
    %
    \begin{align*}
        |\xi^\alpha \mathcal{F}(f)_\beta| &\lesssim_{\alpha,\beta} \mathcal{F}((x^\beta f)_\alpha)\\
        &\lesssim_{\alpha,\beta} \max_{\gamma \leq \alpha \wedge \beta} |\mathcal{F}(x^{\beta - \gamma} f_{\alpha - \gamma})|\\
        &\lesssim_{\alpha,\beta} \max_{\gamma \leq \alpha \wedge \beta} \| x^{\beta - \gamma} f_\gamma \|_{L^1(\RR^d)}\\
        &\leq \max_{\gamma \leq \alpha \wedge \beta} \| (1 + |x|)^{|\beta|} f_\gamma \|_{L^1(\RR^d)} \lesssim \| f \|_{|\alpha|,|\beta|+d+1}.
    \end{align*}
    %
    Thus $\mathcal{F}$ is a bounded linear operator on $\mathcal{S}(\RR^d)$. Since all Schwartz functions are arbitrarily smooth, the Fourier inversion formula applies to all Schwartz functions, and so $\mathcal{F}$ is a bijective bounded linear operator with inverse $\mathcal{F}^{-1}$. The open mapping theorem then immediately implies that $\mathcal{F}^{-1}$ is bounded.
\end{proof}

\begin{corollary}
    If $f$ and $g$ are Schwartz, then $f * g$ is Schwartz.
\end{corollary}
\begin{proof}
    Since $f * g = \mathcal{F}^{-1}(\mathcal{F}(f) \mathcal{F}(g))$, this fact follows from the fact that the product of two Schwartz functions is Schwartz.
\end{proof}

Now we get to the interesting part of the theory. We have defined a homeomorphic linear transform from $\mathcal{S}(\RR^d)$ to itself. The theory of functional analysis then says that we can define a dual map, which is a homeomorphism from the dual space $\mathcal{S}(\RR^d)^*$ to itself. Note the inclusion map $C_c^\infty(\RR^d) \to \mathcal{S}(\RR^d)$ is continuous, and $C_c^\infty(\RR^d)$ is dense in $\mathcal{S}(\RR^d)$. This implies that we have an injective, continuous map from $\mathcal{S}^*(\RR^d)$ to $(C_c^\infty)^*(\RR^d)$, so every functional on the Schwarz space can be identified with a distribution. We call such distributions {\bf tempered}. They are precisely the linear functionals on $C_c^\infty(\RR^d)$ which have a continuous extension to $\mathcal{S}(\RR^d)$. Intuitively, this corresponds to an asymptotic decay condition.

\begin{example}
    For any $f \in L^1_{\text{loc}}(\RR^d)$, we define $\Lambda[f]$ to be the distribution
    %
    \[ \Lambda[f](\phi) = \int f(x) \phi(x)\; dx \]
    %
    But this distribution is not always tempered. If $f \in L^p(\RR^d)$ for some $p$, then, applying H\"{o}lder's inequality, we obtain that
    %
    \[ |\Lambda[f](\phi)| \leq \| f \|_{L^p(\RR^d)} \| \phi \|_{L^q(\RR^d)}. \]
    %
    Since $\| \cdot \|_{L^q(\RR^d)}$ is a continuous norm on $\mathcal{S}(\RR^d)$, this shows $\Lambda[f]$ is bounded. More generally, if $f \in L^1_{\text{loc}}(\RR^d)$, and $f(x) (1 + |x|)^{-m}$ is in $L^p(\RR^d)$ for some $m$, then $\Lambda[f]$ is a tempered distribution. If $p = \infty$, such a function is known as {\bf slowly increasing}.
\end{example}

\begin{example}
    For any Radon measure, $\mu$, we can define a distribution
    %
    \[ \Lambda[\mu](\phi) = \int \phi(x) d\mu(x) \]
    %
    But this distribution is not always tempered. If $|\mu|$ is finite, the inequality $\| \Lambda[\mu](\phi) \| \leq \| \mu \| \| \phi \|_{L^\infty(\RR^d)}$ gives boundedness. More generally, if $\mu$ is a measure such that $|\mu(x)|/(1 + |x|^\alpha)$ is finite for some $k$, then $\mu$ is known as a {\bf tempered measure}, and also acts as a tempered distribution, since
    %
    \[ |\Lambda[\mu](\phi)| \leq \| \mu(x)/(1 + |x|^\alpha) \| \| \phi \|_{L^\infty(\RR^d, 1 + |x|^\alpha)}. \]
\end{example}

\begin{example}
    Suppose $\Lambda$ is a distribution supported on a compact set $K$. Then $\Lambda$ is tempered, since if $\psi$ is a compactly supported bump function on $K$, then for any Schwarz function $\phi$ we can define $\Lambda(\phi) = \Lambda(\psi \phi)$, which is continuous.
\end{example}

\begin{example}
    The function $1/x$ is not locally integrable on $\RR$, since it is not defined near the origin. However, we can associate the value with a distribution. If $\phi$ is a Schwartz function, we define the {\bf principal value}
    %
    \[ \text{p.v.} \int_{-\infty}^\infty \frac{\phi(x)}{x}\; dx = \lim_{\varepsilon \to 0} \int_{|x| \geq \varepsilon} \frac{\phi(x)}{x}\; dx \]
    %
    Since $\int_{\varepsilon \leq |x| \leq 1} dx/x = 0$ for any $\varepsilon \leq 1$, we can write
    %
    \[ \int_{|x| \geq \varepsilon} \frac{\phi(x)}{x} = \int_{|x| \geq 1} \frac{\phi(x)}{x} + \int_{\varepsilon \leq |x| \leq 1} \frac{\phi(x) - \phi(0)}{x} \]
    %
    Since $\phi$ has rapid decay, the first integral is well defined. Since $\phi$ is differentiable at the origin, the second integral is bounded for all $\varepsilon \geq 0$. But this means that
    %
    \[ \lim_{\varepsilon \to 0} \frac{\phi(x)}{x} = \int_{|x| \geq 1} \frac{\phi(x)}{x} + \int_{|x| \leq 1} \frac{\phi(x) - \phi(0)}{x} \]
    %
    Thus it is evident that the principal value exists, and
    %
    \[ \left| \text{p.v.} \int_{-\infty}^\infty \frac{\phi(x)}{x}\; dx \right| \lesssim \| \phi \|_{L^1(\RR)} + \| \phi' \|_{L^\infty(\RR)} \]
    %
    so this functional is a tempered distribution of order 1, and is denoted by $\text{p.v.}(1/x)$. It is intimately connected to the theory of the Hilbert transform. 
\end{example}

Using the same techniques as for distributions, the derivative $\Lambda_\alpha$ of a tempered distribution $\Lambda$ is tempered, as is $\phi \Lambda$, whenever $\phi$ is a Schwartz function, or $f \Lambda$, where $f$ is a polynomial.

To remind the reader, we think of a distribution $\Lambda$ as corresponding to arbitrarily regular function $f$ such that
%
\[ \Lambda(\phi) = \int f(x) \phi(x)\; dx \]
%
If we can justify an identity with respect to this operation which removes the reliance of regularity on $f$, we can normally swap $f$ with a general distribution, and use it to define the operation on all distributions.

We now apply this process to define the Fourier transform of a tempered distribution. The multiplication formula
%
\[ \int_{\RR^d} \widehat{f}(\xi) \widehat{g}(\xi)\; d\xi = \int_{\RR^d} f(x) g(x)\; dx \]
%
gives us the perfect opportunity. It says that if $\Lambda$ is the distribution corresponding to a Schwartz $f \in \mathcal{S}(\RR^d)$, the distribution $\widehat{\Lambda}$ corresponding to $\widehat{f}$, then for any Schwartz $g \in \mathcal{S}(\RR^d)$,
%
\[ \widehat{\Lambda} \left( \widehat{g} \right) = \Lambda(g). \]
%
In particular, this motivates us to define the Fourier transform of \emph{any} tempered distribution $\Lambda$ to be the unique tempered distribution $\widehat{\Lambda}$ such that the equation above holds for all Schwartz $g$. This distribution exists because the Fourier transform is an isomorphism on the space of Schwartz functions. Clearly, the Fourier transform is a homeomorphism on the space of tempered distributions under the weak topology, and moreover, satisfies all the symmetry properties that the ordinary Fourier transform does, once we interpret scalar, rotation, translation, differentiation, etc, in a natural way on the space of distributions.

\begin{example}
    Consider the constant function $1$, interpreted as a tempered distribution on $\RR^d$. Then for any $\phi \in \mathcal{S}(\RR^d)$,
    %
    \[ 1(\phi) = \int \phi(x)\; dx, \]
    %
    Thus for any $\phi \in \mathcal{S}(\RR^d)$,
    %
    \[ \widehat{1} \left( \widehat{\phi} \right) = 1(\phi) = \int \phi(\xi)\; d\xi = \widehat{\phi}(0). \]
    %
    Thus $\widehat{1}$ is the Dirac delta function at the origin. Similarily, the Fourier inversion formula implies that
    %
    \[ \widehat{\delta} \left( \widehat{\phi} \right) = \phi(0) = \int \widehat{\phi}(\xi)\; d\xi = 1 \left( \widehat{\phi} \right) \]
    %
    so the Fourier transform of the Dirac delta function is the constant 1 function.
\end{example}

\begin{example}
  Consider the Riesz Kernel on $\RR^d$, for each $\alpha \in \CC$ with positive real part, as the function
  %
  \[ K_\alpha(x) = \frac{\Gamma(\alpha/2)}{\pi^{\alpha/2}} |x|^{-\alpha}. \]
  %
  Then for $0 < \text{Re}(\alpha) < d$, $\widehat{K_\alpha} = K_{d-\alpha}$. We recall that $\Gamma$ is defined by the integral formula
  %
  \[ \Gamma(s) = \int_0^\infty e^{-t} t^{s-1}\; ds, \]
  %
  where $\text{Re}(s) > 0$. We note that if $p = d/\text{Re}(\alpha)$, $K_\alpha \in L^{p,\infty}(\RR^d)$. The Marcinkiewicz interpolation theorem implies that if $d/2 < \text{Re}(\alpha) < d$, then $K_\alpha$ can be decomposed as the sum of a $L^1(\RR^d)$ function and a $L^2(\RR^d)$ function, and so we can intepret the Fourier transform of $\widehat{K_\alpha}$ using techniques in $L^1(\RR^d)$ and $L^2(\RR^d)$, and moreover, the Marcinkiewicz interpolation theorem implies that
  %
  \[ \| \widehat{K_\alpha} \|_{L^{q,\infty}(\RR^d)} \leq \| K_\alpha \|_{L^{p,\infty}(\RR^d)}. \]
  %
  where $q$ is the dual of $p$. In particualr, the Fourier transform of $K_\alpha$ is a function. We note that $K_\alpha$ obeys multiple symmetries. First of all, $K_\alpha$ is radial, so $\widehat{K_\alpha}$ is also radial. Moreover, $K_\alpha$ is homogenous of degree $-\alpha$, i.e. for each $x \in \RR^d$, $K_\alpha(\varepsilon x) = \varepsilon^{-\alpha} K_\alpha(x)$. This actually uniquely characterizes $K_\alpha$ among all locally integrable functions. Taking the Fourier transform of both sides of the equation for homogeneity, we find
  %
  \[ \varepsilon^{-d} \widehat{K_\alpha}(\xi/\varepsilon) = \varepsilon^{-\alpha} \widehat{K_\alpha}(x). \]
  %
  Thus $\widehat{K_\alpha}$ is homogenous of degree $\alpha - d$. But this uniquely characterizes $\widehat{K_{d-\alpha}}$ out of any distribution, up to multiplicity, so we conclude that for $d/2 < \text{Re}(\alpha) < d$, that $\widehat{K_\alpha}$ is a scalar multiple of $K_{d-\alpha}$. But we know that by a change into polar coordinates, if $A_d$ is the surface area of a unit sphere in $\RR^d$, then
  %
  \begin{align*}
    \int_{\RR^d} K_\alpha(x) e^{- \pi |x|^2}\; dx &= \frac{\Gamma(\alpha/2)}{\pi^{\alpha/2}} \int_{\RR^d} |x|^{-\alpha} e^{-\pi |x|^2}\; dx\\
    &= A_d \frac{\Gamma(\alpha/2)}{\pi^{\alpha/2}} \int_0^\infty r^{d-1-\alpha} e^{- \pi r^2}\; dr\\
    &= A_d \frac{\Gamma(\alpha/2)}{2 \pi^{d/2}} \int_0^\infty s^{(d-\alpha)/2 - 1} e^{-s}\; ds\\
    &= A_d \frac{\Gamma(\alpha/2) \Gamma((d-\alpha)/2)}{\pi^{d/2}}.
  \end{align*}
  %
  But this is also the value of
  %
  \[ \int_{\RR^d} K_{d - \alpha}(x) e^{- \pi |x|^2}, \]
  %
  so we conclude $\widehat{K_\alpha} = K_{d-\alpha}$ if $d/2 < \text{Re}(\alpha) < d$. We could apply Fourier inversion to obtain the result for $0 < \text{Re}(\alpha) < d/2$, but to obtain the case $\text{Re}(\alpha) = d/2$, we must apply something different. For each $s \in \CC$ with $0 < \text{Re}(s) < d$, and for each Schwartz $\phi \in \mathcal{S}(\RR^d)$ we define
  %
  \[ A(s) = \int K_s(\xi) \widehat{\phi}(\xi)\; d\xi = \frac{\Gamma(s/2)}{\pi^{s/2}} \int |\xi|^{-s/2} \widehat{\phi}(\xi)\; d\xi. \]
  %
  and
  %
  \[ B(s) = \int K_{d-s}(\xi) \widehat{\phi}(\xi)\; d\xi = \frac{\Gamma((d-s)/2)}{\pi^{(d-s)/2}} \int |\xi|^{(d-s)/2} \widehat{\phi}(\xi)\; d\xi. \]
  %
  The integrals above converge absolutely for $0 < \text{Re}(s) < d$, and the dominated convergence theorem implies that $A$ and $B$ are both complex differentiable. Since $A(s) = B(s)$ for $d/2 < \text{Re}(s) < d$, analytic continuation implies $A(s) = B(s)$ for all $0 < \text{Re}(s) < d$, completing the proof. For $\text{Re}(\alpha) \geq d$, $K_\alpha$ is no longer locally integrable, and so we must interpret the integral in terms of principal values.
\end{example}

\begin{example}
  Let us consider the complex Gaussian defined, for a given invertible symmetric matrix $T: \RR^d \to \RR^d$, as $G_T(x) = e^{- i \pi (Tx \cdot x)}$. Then
  %
  \[ \widehat{G_T} = e^{- i \pi \sigma/4} |\det(T)|^{-1/2} G_{-T^{-1}}, \]
  %
  where $\sigma$ is the \emph{signature} of $T$, i.e. the number of positive eigenvalues, minus the number of negative eigenvalues, counted up to multiplicity. Thus we need to show that for any Schwartz $\phi \in \mathcal{S}(\RR^d)$,
  %
  \[ e^{-i \pi \sigma/4} |\det(T)|^{-1/2} \int_{\RR^d} e^{i \pi (T^{-1}\xi \cdot \xi)} \widehat{\phi}(\xi)\; d\xi = \int_{\RR^d} e^{- i \pi (Tx \cdot x)} \phi(x)\; dx. \]
  %
  Let us begin with the case $d = 1$, in which case we also prove the theorem when $T$ is a complex symmetric matrix. If $T$ is given by multiplication by $-iz$, and if $\sqrt{\cdot}$ denotes the branch of the square root defined for all non-negative numbers and positive on the real-axis, then we note that when $z = \lambda i$,
  %
  \[ e^{- i \pi \sigma/4} |\det(T)|^{-1/2} = e^{- i \pi \text{sgn}(\lambda)/4} |\lambda|^{-1/2} = \sqrt{z}. \]
  %
  Thus it suffices to prove the analytic family of identities
  %
  \[ \int_{-\infty}^\infty e^{- (\pi/z) \xi^2} \widehat{\phi}(\xi)\; d\xi = \sqrt{z} \int_{-\infty}^\infty e^{-\pi z x^2} \phi(x)\; dx, \]
  %
  where both sides are well defined and analytic whenever $z$ has positive real part. But we already know from the Fourier transform of the Gaussian that this identity holds whenever $z$ is positive and real, and so the remaining identities follows by analytic continuation. We note that the higher dimensional identity is invariant under changes of coordinates in $SO(n)$. Thus it suffices to prove the remaining theorem when $T$ is diagonal. But then everything tensorizes and reduces to the one dimensional case. More generally, if $T = T_0 - i T_1$ is a complex symmetric matrix, which is well defined if $T_1$ is positive semidefinite, then
  %
  \[ \widehat{G_T} = \frac{1}{\sqrt{i \det(T)}} \cdot G_{-T^{-1}}, \]
  %
  which follows from analytic continuation of the case for real $T$.
\end{example}

\begin{example}
    We know $((-2 \pi i x)^\alpha)^\ft = ((- 2 \pi i x)^\alpha \cdot 1)^\ft = \delta_\alpha$, which essentially provides us a way to compute the Fourier transform of any polynomial, i.e. as a linear combination of dirac deltas and the distribution derivatives of dirac deltas, which are derivatives evaluated at points.
\end{example}

\begin{theorem}
    If $\mu$ is a finite measure, $\widehat{\mu}$ is a uniformly continuous bounded function with $\| \widehat{\mu} \|_{L^\infty(\RR^d)} \leq \| \mu \|$, and
    %
    \[ \widehat{\mu}(\xi) = \int e(- 2 \pi i x \cdot \xi) d\mu(x) \]
    %
    The function $\widehat{\mu}$ is also smooth if $\mu$ has moments of all orders, i.e. $\int |x|^k d\mu(x) < \infty$ for all $k > 0$.
\end{theorem}
\begin{proof}
    Let $\phi \in \mathcal{S}(\RR^d)$. We must understand the integral
    %
    \[ \int_{\RR^d} \widehat{\phi}(x)\; d\mu(x). \]
    %
    Applying Fubini's theorem, which applies since $\mu$ has finite mass, we conclude that
    %
    \[ \int_{\RR^d} \widehat{\phi}(x)\; d\mu(x) = \int_{\RR^d} \int_{\RR^d} \phi(\xi) e^{-2 \pi i \xi \cdot x} d\mu(x)\; d\xi = \int_{\RR^d} \phi(\xi) f(\xi)\; d\xi, \]
    %
    where
    %
    \[ f(\xi) = \int_{\RR^d} e^{-2 \pi i \xi x} d\mu(x). \]
    %
    Thus $\widehat{\mu}$ is precisely $f$, and it suffices to show that $\| f \|_{L^\infty(\RR^d)} \leq \| \mu \|$, and that $f$ is uniformly continuous. The inequality follows from a simple calculation of the triangle inequality, and the second inequality follows because for some $y$,
    %
    \begin{align*}
      |f(\xi + \eta) - f(\xi)| &= \left| \int_{\RR^d} e^{-2 \pi i \xi \cdot x} (e^{-2 \pi i \eta \cdot x} - 1)\; d\mu(x) \right|\\
      &\leq \int_{\RR^d} |e^{-2 \pi i \eta \cdot x} - 1|\; d|\mu|(x).
    \end{align*}
    %
    As $\eta \to 0$, the dominated convergence theorem implies that this quantity tends to zero, which proves uniform continuity. On the other hand, if $x_i \mu$ is finite for some $i$, then
    %
    \begin{align*}
      \frac{f(\xi + \varepsilon e_i) - f(\xi)}{\varepsilon} &= \int_{\RR^d} e^{-2 \pi i \xi \cdot x} \frac{(e^{- 2 \pi \varepsilon i x_i} - 1)}{\varepsilon} d\mu(x).
    \end{align*}
    %
    We can apply the dominated convergence theorem to show that as $\varepsilon \to 0$, this quantity converges to the classical partial derivative $f_i$, which has the integral formula
    %
    \[ f_i(\xi) = (-2 \pi i) \int_{\RR^d} e^{-2 \pi i \xi \cdot x} x_i d\mu(x), \]
    %
    which is the Fourier transform of $x_i \mu$. Higher derivatives are similar.
\end{proof}

Not being compactly supported, we cannot compute the convolution of tempered distributions with all $C^\infty$ functions. Nonetheless, if $\phi$ is Schwartz, and $\Lambda$ is tempered, then the definition $(\Lambda * \phi)(x) = \Lambda(T_x \phi^*)$ certainly makes sense, and gives a $C^\infty$ function satisfying $D^\alpha(\Lambda * \phi) = (D^\alpha \Lambda) * \phi = \Lambda * (D^\alpha \phi)$. This function is slowly increasing, since it has polynomial growth. We know for some $N > 0$, for any Schwartz $\phi$,
%
\[ |\Lambda(\phi)| \lesssim \sup \{ |x^\alpha| |D^\beta \phi| : |\alpha|, |\beta| \leq N, k > 0 \} \]
%
TODO: FINSIH THIS. Because $\Lambda * \phi$ is tempered, this means that we can consider the Fourier transform $\smash{\widehat{\Lambda * \phi}}$. If $\psi$ is compactly supported, then
%
\[ (\Lambda * \phi)^\ft \left(\widehat{\psi} \right) = s \]
%
TODO: FINISH, which proves $\widehat{\Lambda * \phi} = \widehat{\Lambda} \widehat{\phi}$.

\section{Convolution Operators}

It is know that if $T: D(\RR^d) \to C^\infty(\RR^d)$ is any continuous linear functional commuting with translations, it is given by convolution from some distribution. If this convolution is with respect to some tempered distribution, then the transformation extends from a map from $\mathcal{S}(\RR^d)$ to $C^\infty(\RR^d)$. Studying the class of operators which commute with translations is very important because these operators occur again and again in Harmonic analysis. To begin with, with rely on a regularity result on the differentiation of functions in $L^p$ spaces.

\begin{lemma}
    If $f \in L^p(\RR^d)$, has derivatives in the $L^p$ norm of all orders $\leq d+1$, then $f$ is almost everywhere equal to a continuous function $g$ such that
    %
    \[ |g(0)| \lesssim \sum_{|\alpha| \leq n + 1} \| D^\alpha f \|_p \]
    %
    where the hidden constant depends only on $n$ and $p$.
\end{lemma}
\begin{proof}
    s
\end{proof}

\begin{theorem}
    If $T: L^p(\RR^d) \to L^q(\RR^d)$ is bounded, linear, and commutes with translations, then there exists a unique tempered distribution $\Lambda$ such that $T(\phi) = \Lambda * \phi$ for all $\phi \in \mathcal{S}(\RR^d)$
\end{theorem}
\begin{proof}
    If $T$ commutes with translations, then for any Schwartz function $\phi$, $T\phi$ has derivatives in the $L^q$ norm of all orders, since $\Delta_{h,e}(T \phi) = T(\Delta_{h,e} \phi)$, and $\Delta_{h,e} \phi$ converges to $D_e \phi$ in the $L^q$ norm, since the $L^q$ norm is continuous in Schwartz space. In particular, we find $D^\alpha (T\phi) = T(D^\alpha \phi)$. Thus $T\phi$ is equal to a continuous function $g_\phi$ with
    %
    \[ |g_\phi(0)| \lesssim \sum_{|\alpha| \leq n+1} \| D^\alpha(T\phi) \|_q = \sum_{|\alpha| \leq n+1} \| T(D^\alpha \phi) \|_q \leq \| T \| \sum_{|\alpha| \leq n+1} \| D^\alpha \phi \|_q \]
    %
    The map $\phi \mapsto g_\phi(0)$ is therefore continuous on $\mathcal{S}(\RR^d)$, and therefore defines a tempered distribution $\Lambda$, and the fact that $T(\phi) = \Lambda * \phi$ then holds by the translation invariance of $T$.
\end{proof}

\begin{remark}
    It therefore follows that if $T: L^p(\RR^d) \to L^q(\RR^d)$ is bounded, linear, and commutes with translations, then for any Schwartz function $\phi$, $T\phi$ is $C^\infty$, and is slowly increasing, as is all of it's derivatives.
\end{remark}

For each $p$ and $q$, we will let $(L^p,L^q)$ denote the space of tempered distributions which define a continuous linear map from $L^p(\RR^d)$ to $L^q(\RR^d)$, in the sense that the map $\phi \mapsto \Lambda * \phi$ is continuous as a map from $\mathcal{S}(\RR^d)$ to $L^q(\RR^d)$, and, by the Hahn-Banach theorem, extends uniquely to a linear map on the whole space. In general, a characterization of such distributions is unknown except in a few situations.

\begin{example}
    The distributions in $(L^2, L^2)$ are Fourier transforms of elements of $L^\infty(\RR^d)$. The $L^\infty$ norm of the element corresponds to the norm of the convolution operator. To see this, if $\Lambda$ is a distribution, and $\Phi$ is the Gaussian distribution, $\Phi(x) = e^{-\pi|x|^2}$, then $\Lambda * \Phi$ is an $L^2$ function, since $\Phi$ is in $L^2$, and as such we conclude by the Plancherel theorem that $(\Lambda * \Phi)^\ft = \Phi \Lambda^\ft$ is an element of $L^2(\RR^d)$. Thus we can think of $\widehat{\Lambda} = e^{\pi |x|^2} (\Lambda * \Phi)^\ft$ as a function $f$. Plancherel's theorem implies that for any Schwarz function $\phi$,
    %
    \[ \| f \widehat{\phi} \|_2 = \| \Lambda * \phi \|_2 \lesssim \| \phi \|_2 = \| \widehat{\phi} \|_2 \]
    %
    But this means that $f \in L^\infty(\RR^d)$, for if there is a set $E$ of positive measure where $|f| \geq M$, we can find $\widehat{\phi}$ with $\widehat{\phi} = 1$ on $E$ and with $\| \widehat{\phi} \|_2 = |E| + \varepsilon$, and then $\| f \widehat{\phi} \|_2 \geq M \| \widehat{\phi} \|_2$. Note that over $L^2(\mathbf{T})$, the only convolution operators are given by the distributions given by a Fourier series with bounded coefficients.
\end{example}

\begin{example}
    The distributions in $(L^1, L^1)$ are precisely the finite Borel measures. The total variation of the measure corresponds to the norm of the convolution operator. It is clear that if $\mu$ is a Borel measure, then $\| \mu * \phi \|_1 \leq \| \mu \|_1 \| \phi \|_1$. Conversely, if $\Lambda \in (L^1, L^1)$, and $\Phi_\delta$ is the Gauss kernel, then we set $\Lambda_\delta = \Lambda * \Phi_\delta$. By assumption, $\Lambda_\delta$ is an $L^1$ function, and so $\Lambda$, $\| \Lambda_\delta \|_1 \lesssim \| \Phi_\delta \|_1 = 1$. This implies that the $\Lambda_\delta$ are uniformly bounded in $L^1$, so by the Banach Alaoglu theorem, since $L^1(\RR^d)$ embeds itself in $M(\RR^d)$, which is the dual of $C_0(\RR^d)$, some subsequence of the $\Lambda_\delta$ converge weakly to some measure $\mu$. We claim $\Lambda = \Lambda_\mu$. To prove this, fix some Schwartz function $\phi$. If we let $\phi_\delta = \phi * \Phi_\delta$, then $D^\alpha \phi_\delta = (D^\alpha \phi) * \Phi_\delta$ converges uniformly to $D^\alpha \phi$, so $\phi_\delta$ converges to $\phi$ in $\mathcal{S}(\RR^d)$, and so $\Lambda(\phi)$ is the limit of $\Lambda(\phi_\delta)$. But
    %
    \begin{align*}
        \Lambda(\phi_\delta) &= \Lambda(\Phi_\delta * \phi) = (\Lambda * (\Phi_\delta * \phi)^*)(0)\\
        &= ((\Lambda * \Phi_\delta) * \phi^*)(0)\\
        &= \Lambda_\delta(\phi)
    \end{align*}
    %
    and we know some subsequence converges to $\int \phi(x) d\mu(x)$. But we know that overall the values converge to $\Lambda(\phi)$, which implies
    %
    \[ \Lambda(\phi) = \int \phi(x) d\mu(x) \]
    %
    Since $\phi$ was an arbitrary Schwartz function, we can now apply the density of $\mathcal{S}(\RR^d)$ in $L^1(\RR^d)$ to conclude that for any integrable function $f$,
    %
    \[ \Lambda(f) = \int f(x) d\mu(x) \]
    %
    This classifies the $(L^1, L^1)$ distributions.
\end{example}

We also have a duality theorem.

\begin{theorem}
    For any two $(p,q)$, $(L^p,L^q) = (L^{q^*}, L^{p^*})$.
\end{theorem}









\chapter{Sobolev Spaces}

Let $\Omega$ be an open subset of $\RR^d$. A natural problem when studying smooth functions $\phi \in C_c^\infty(\Omega)$ is to obtain estimates on the partial derivatives of $\phi$. For instance, one can consider the norms
%
\[ \| \phi \|_{C^n(\Omega)} = \max_{|\alpha| \leq n} \| D^\alpha f \|_{L^\infty(\Omega)}. \]
%
The space $C_c^\infty(\Omega)$ is not complete with respect to this norm, but it's completion is the space $C^n_b(\Omega)$ of $n$ times bounded continuously differentiable functions on $\Omega$, which still consists of regular functions. Unfortunately, such estimates are only encountered in the most trivial situations. As in the non-smooth case, one can often get much better estimates using the $L^p$ norms of the derivatives, i.e. considering the norms
%
\[ \| \phi \|_{W^{n,p}(\Omega)} = \left( \sum_{|\alpha| \leq p} \| D^\alpha \phi \|_{L^p(\Omega)}^p \right)^{1/p}. \]
%
As might be expected, $C_c^\infty(\Omega)$ is not complete with respect to the $W^{n,p}(\Omega)$ norm. However, it's completion cannot be identified with a family of $n$ times differentiable functions. Instead, to obtain a satisfactory picture of the compoetion under this norm, a Banach space we will denote by $W^{n,p}(\Omega)$, we must take a distribution approach.

For each multi-index $\alpha$, if $f$ and $f_\alpha$ are locally integrable functions on $\Omega$, we say $f_\alpha$ is a weak derivative for $f$ if for any $\phi \in C_c^\infty(\Omega)$,
%
\[ \int_\Omega f_\alpha(x) \phi(x)\; dx = (-1)^{|\alpha|} \int_\Omega f(x) \phi_\alpha(x)\; dx. \]
%
In other words, this is the same as the derivative of $f$ viewed as a distribution on $\Omega$. We define $W^{n,p}$ to be the space of all functions $f \in L^p(\Omega)$ such that for each $|\alpha| \leq n$, a weak derivative $f_\alpha$ exists and is an element of $L^p(\Omega)$. We then define
%
\[ \| f \|_{W^{n,p}(\Omega)} = \left( \sum_{|\alpha| \leq n} \| f_\alpha \|_{L^p(\Omega)} \right)^{1/p}. \]
%
Where this sum is treated as a maximum in the case $p = \infty$. Later on we will be able to show this space is a complete Banach space.

\begin{example}
  Let $B$ be the open unit ball in $\RR^d$, and let $u(x) = |x|^{-s}$, where $s < n-1$. For which $p$ is $u \in W^{1,p}(B)$? We calculate by an integration by parts that if $\phi \in C_c^\infty(B)$, we fix $\varepsilon > 0$ and write
  %
  \[ \int_B \phi_i(x) u(x)\; dx = \int_{|x| \leq \varepsilon} \phi_i(x) u(x) + \int_{\varepsilon < |x| \leq 1} \phi_i(x) u(x). \]
  %
  The integral on the $\varepsilon$ ball is neglible since $s < n$. Since $u$ is smooth away from the origin, it's distributional derivative agrees with it's standard derivative, which is
  %
  \[ u_i(x) = \frac{- \alpha x_i}{|x|^{s + 2}}. \]
  %
  Thus $|u_i| \lesssim 1/|x|^{s + 1}$. An integration by parts gives
  % in the $i$'th direction, and we calculate $\nabla u(x) = -\alpha x |x|^{-\alpha-2}$. Thus an integration by parts gives
  %
  \[ \int_{\varepsilon < |x| \leq 1} \phi_i(x) u(x) = \int_{|x| = \varepsilon} \phi(x) u(x) \nu_i\ dS + \int_{\varepsilon < |x| \leq 1} \frac{s \phi(x) x_i}{|x|^{s + 2}}\; dx, \]
  %
  where $\nu_i$ is the normal vector to the sphere pointing inward. Since $s < n-1$, the surface integral tends to zero as $\varepsilon \to 0$. Thus the weak derivative of $u$ is equal to the standard derivative. Consequently, $u \in W^{1,p}(B)$ if $s < n/p - 1$.
\end{example}

\begin{example}
  If $\{ r_k \}$ is a countable, dense subset of $B$, then we can define
  %
  \[ u(x) = \sum_{k = 1}^\infty \frac{|x - r_k|^{-s}}{2^k} \]
  %
  Then $u \in W^{1,p}(B)$ if $0 < \alpha < n/p - 1$, yet $u$ has a dense family of singularities, and thus does not behave like any differentiable function we would think of.
\end{example}

\begin{theorem}
  For each $k \in \mathbf{N}$ and $1 \leq p \leq \infty$, $W^{k,p}(\Omega)$ is a Banach space.
\end{theorem}
\begin{proof}
  It is easy to verify that $\| \cdot \|_{W^{k,p}}$ is a norm on $W^{k,p}(\Omega)$. Let $\{ u_n \}$ be a Cauchy sequence in $W^{k,p}(\Omega)$. In particular, this means that $\{ D^\alpha u_n \}$ is a Cauchy sequence in $L^p(\Omega)$ for each multi-index $\alpha$ with $|\alpha| \leq k$. In particular, these are functions $v_\alpha$ such that $D^\alpha u_n$ converges to $v_\alpha$ in the $L^p$ norm for each $\alpha$. Thus it suffices to prove that if $v = \lim u_n$, then $D^\alpha v = v_\alpha$ for each $\alpha$. But this follows because the H\"{o}lder inequality implies that for each fixed $\phi \in C_c^\infty(\Omega)$,
  %
  \begin{align*}
    (-1)^{|\alpha|} \int \phi_\alpha(x) v(x)\; dx &= \lim_{n \to \infty} (-1)^{|\alpha|} \phi_\alpha u_n(x)\; dx\\
    &= \lim_{n \to \infty} \int \phi(x) (D^\alpha u_n)(x)\; dx\\
    &= \int \phi(x) v_\alpha(x)\; dx.
  \end{align*}
  %
  Thus $W^{k,p}(\Omega)$ is complete.
\end{proof}

\section{Smoothing}

It is often useful to be able to approximate elements of $W^{k,p}(\Omega)$ by elements of $C^\infty(\Omega)$. This is mostly possible. If $u \in W^{k,p}(\Omega)$, and $\{ \eta_\varepsilon \}$ is a family of smooth mollifiers, then, viewing $u$ as a function on $\RR^n$ supported on $\Omega$, we can consider the convolution $u^\varepsilon = u * \eta_\varepsilon$, i.e. the function defined by setting
%
\[ u^\varepsilon(x) = \int_\Omega u(x - y) \eta_\varepsilon(y)\; dy. \]
%
This is just normal convolution, where we identify the function $u$ with the function $u \mathbf{I}_\Omega$ on $\RR^d$. Then $u^\varepsilon$ is a smooth function on $\RR^d$ supported on a $\varepsilon$ thickening of $\Omega$. However, $u^\varepsilon$ does not necessarily converge to $u$ in $W^{k,p}(\Omega)$ as $\varepsilon \to 0$, since the behaviour of the convolution can cause issues at the boundary of $\Omega$, where the distributional derivative $D^\alpha(u \mathbf{I}_\Omega)$ does not behave like a locally integrable function. This is the only problem, however.

\begin{theorem}
  If $U \Subset \Omega$, then $\lim_{\varepsilon \to 0} \| u^\varepsilon - u \|_{L^p(U)} = 0$.
\end{theorem}
\begin{proof}
  For each $\varepsilon > 0$, let $U^\varepsilon = \{ x \in \Omega: d(x,\partial \Omega) > \varepsilon \}$. If $x \in \Omega^\varepsilon$, then
  %
  \[ ((D^\alpha u) * \eta_\varepsilon)(x) = (u_\alpha \mathbf{I}_\Omega * \eta_\varepsilon)(x), \]
  %
  since the convolution only depends on the behaviour of $D^\alpha u$ on a $\varepsilon$ ball around $x$, which is contained in the interior of $\Omega$. We can apply standard results about mollifiers to conclude that $u_\alpha \mathbf{I}_\Omega * \eta_\varepsilon$ converges to $u_\alpha \mathbf{I}_\Omega$ in $L^p(\RR^d)$ as $\varepsilon \to 0$. Since $U \Subset \Omega$, we have $U \subset U^\varepsilon$ for small enough $\varepsilon$, and so $(D^\alpha u) * \eta_\varepsilon$ converges to $u_\alpha$ in $L^p(U)$ as $\varepsilon \to 0$. Since this is true for each $\alpha$ with $|\alpha| \leq k$, we obtain the result.
\end{proof}

If we are a little more careful, then we can fully approximate elements of $W^{k,p}(\Omega)$ by smooth functions on $U$.

\begin{theorem}
  $C^\infty_c(\Omega) \cap W^{k,p}(\Omega)$ is dense in $W^{k,p}(\Omega)$.
\end{theorem}
\begin{proof}
  Consider a family of open sets $\{ V_n \}$ such that $V_n \Subset \Omega$ for each $n$, and $U = \bigcup V_n$. Then we can consider a smooth partition of unity $\{ \xi_n \}$ subordinate to the cover $\{ V_n \}$. For each $u \in W^{k,p}(\Omega)$, we can write $u = \sum_n u \xi_n$. In particular, this means that for each $\varepsilon > 0$, there is $N$ such that $\| \sum_{n = N+1}^\infty u \xi_n \|_{W^{k,p}(\Omega)} \leq \varepsilon$. For each $n \in \{ 1, \dots, N \}$, we can find $\delta_n$ small enough that the $\delta_n$ thickening of $V_n$ is compactly contained in $\Omega$. If $\varepsilon_n$ is small enough, we find $(u \xi_n)^{\varepsilon_n}$ is supported on the $\delta_n$ thickening of $V_n$, and $\| (u \xi_n)^{\varepsilon_n} - u \xi_n \|_{W^{k,p}(V_n)} \leq \varepsilon / N$. But we then find
  %
  \begin{align*}
    \| u - \sum_{n = 1}^N (u \xi_n)^{\varepsilon_n} \|_{W^{k,p}(\Omega)} \leq \varepsilon + \sum_{n = 1}^N \| u \xi_n - (u \xi_n)^{\varepsilon_n} \|_{W^{k,p}(\Omega)} \leq 2\varepsilon.
  \end{align*}
  %
  Thus $C_c^\infty(\Omega)$ is dense in $W^{k,p}(\Omega)$.
\end{proof}

Approximation by elements of $C^\infty(\overline{\Omega})$ requires some more care, and additional assumptions on the behaviour of $\partial \Omega$.











\chapter{Basics of Kernel Operators}

We now consider a very general family of operators, which can be seen as the infinite dimensional analogue of matrix multiplication. We fix two measure spaces $X$ and $Y$, and consider a function $K: X \times Y \to \CC$, which we call a \emph{kernel}. From this kernel, we obtain an induced operator $T_K$ taking functions on $X$ to functions on $Y$, given by the integral formula
%
\[ (T_K f)(y) = \int_X K(x,y) f(x)\; dx. \]
%
Our goal is to understand what properties of $K$ imply boundedness of the operator $T_K$.

\begin{example}
  If $X = Y = \RR^d$, equipped with the Lebesgue measure. If we set $K(x,\xi) = e^{2 \pi i \xi \cdot x}$, then we can use this function as a kernel to obtain an integral operator
  %
  \[ (T_K f)(\xi) = \int f(x) e^{2 \pi i \xi \cdot x}\; dx. \]
  %
  Thus the Fourier transform is a kernel operator.
\end{example}

\begin{example}
  Let $X = \{ 1, \dots, N \}$ and $Y = \{ 1, \dots, M \}$, each equipped with the counting measure. Then each kernel $K$ corresponds to an $M \times N$ matrix $A$, with $A_{ij} = K(j,i)$, and then
  %
  \[ (T_K f)(m) = \sum_{n = 1}^N f(n) K(n,m) = \sum_{n = 1}^N A_{mn} f(n), \]
  %
  so with respect to the standard basis, $T_K$ is just given by matrix multiplication by $A$.
\end{example}

In the case where we are mapping \emph{from} $L^1(X)$, or \emph{into} $L^\infty(Y)$, the conditions on $K$ which determine boundedness are rather trivial. This can be taken as a motivation for introducing the $L^p$ norms, since these norm allow us to study the boundedness properties of $K$ with more detail. Since it is not even obvious that $T_K$ is well defined even for simple functions, in the very weak case where $K$ is measurable, we introduce the sublinear analogue $S_K$, defined by setting
%
\[ (S_K f)(y) = \int |f(x)| |K(x,y)|\; dx. \]
%
Due to the flexibility of non-negative integrals, this operator is defined for any measurable $f$, though the output may be infinite for various values of $y$.

\begin{theorem}
  Fix $q \geq 1$. If $\| K \|_{L^q(Y) L^\infty(X)} < \infty$, then $S_K$ is bounded as an operator from $L^1(X)$ to $L^q(Y)$, with operator norm bounded above by $\| K \|_{L^q(Y) L^\infty(X)}$, with equality if $X$ and $Y$ are $\sigma$ finite. Correspondingly, for each $f \in L^1(X)$, we have
  %
  \[ \int K(x,y) f(x)\; dx < \infty\ \text{for almost every $y$}, \]
  %
  and $\| T_K f \|_{L^q(Y)} \leq \| K \|_{L^q(Y) L^\infty(X)} \| f \|_{L^1(X)}$.
\end{theorem}
\begin{proof}
  Applying Minkowski's inequality, we conclude that
  %
  \begin{align*}
    \| S_K f \|_{L^q(Y)} &= \left( \left( \int |f(x)| |K(x,y)|\; dx \right)^q \right)^{1/q}\\
    &\leq \int \left( \int |f(x)|^q |K(x,y)|^q\; dy \right)^{1/q}\; dx\\
    &\leq \int |f(x)| \| K \|_{L^q(Y)}(x)\; dx\\
    &\leq \| f \|_{L^1(X)} \| K \|_{L^q(Y) L^\infty(X)}.
  \end{align*}
  %
  To show tightness, consider the first case where $K$ can be written as
  %
  \[ \sum_{i = 1}^N \sum_{j = 1}^M a_{ij} \mathbf{I}_{E_i \times F_j}, \]
  %
  where $E_1, \dots, E_N$ are disjoint, finite measure sets in $X$, and $F_1, \dots, F_M$ are disjoint, finite measure sets in $Y$. Then there exists $i \in \{ 1, \dots, N \}$ such that for each $x \in E_i$,
  %
  \[ \left( \int |K(x,y)|^q\; dy \right)^{1/q} = \left( \sum_{j = 1}^M |a_{ij}|^q |F_j| \right)^{1/q} = \| K \|_{L^q(Y) L^\infty(X)}. \]
  %
  If $f = \mathbf{I}_{E_i}$, then $\| f \|_{L^1(X)} = |E_i|$, and
  %
  \begin{align*}
    \left( \left( \int |K(x,y) f(x)|\; dx \right)^q dy \right)^{1/q} &= \left( \sum_{j = 1}^M |F_j| |a_{ij}|^q |E_i|^q \right)^{1/q}\\
    &= \| f \|_{L^1(X)} \| K \|_{L^q(Y) L^\infty(X)}.
  \end{align*}
  %
  Thus $f$ is an extremizer for $S_K$.

  To show this inequality is tight. Let us first consider the case where $q < \infty$. By a monotone convergence result if $X$ and $Y$ are $\sigma$ finite, we may assume that $X$ and $Y$ have finite measure. It then follows that for each $\varepsilon > 0$, there are functions $u_1, \dots, u_n \in L^1(X)$ and $v_1, \dots, v_n \in L^1(Y)$ such that $\| K - u_1 \otimes v_1 - \dots - u_n \otimes v_n \|_{L^1(X \times Y)} < \varepsilon$.
\end{proof}

\begin{lemma}
  BLAH
\end{lemma}
\begin{proof}
  Let $\Pi$ be the family of all sets $E \times F \subset X \times Y$, where $E$ is a measurable subset of $X$, and $F$ is a measurable subset of $Y$. Then $\Pi$ is a $\pi$ system, in the sense that if $E_1 \times F_1, E_2 \times F_2 \in \Pi$, then $(E_1 \times F_1) \cap (E_2 \times F_2) = (E_1 \cap E_2) \times (F_1 \cap F_2) \in \Pi$. Now let
  %
  \[ \Delta = \left\{ G \subset X \times Y: \left( \begin{array}{c} \text{for all $\varepsilon > 0$, there are simple $u_1, \dots, u_n$} \\ \text{on $X$ and $v_1,\dots, v_n$ on $Y$ such that} \\ \| \mathbf{I}_G - \sum u_i \otimes v_i \|_{L^q(Y) L^\infty(X)} < \varepsilon \end{array} \right) \right\}. \]
  %
  If $G \in \Delta$, then $G^c \in \Delta$, since $1 = \mathbf{I}_X \otimes \mathbf{I}_Y$. Thus if $\| \mathbf{I}_G - \sum u_i \otimes v_i \|_{L^q(Y) L^\infty(X)} < \varepsilon$, then
  %
  \[ \mathbf{I}_{G^c} - (\mathbf{I}_X \otimes \mathbf{I}_Y - \sum u_i \otimes v_i) = (1 - \mathbf{I}_G) - (1 - \sum u_i \otimes y_i) = \sum u_i \otimes y_i - \mathbf{I}_G, \]
  %
  and so $\| \mathbf{I}_{G^c} - (\mathbf{I}_X \otimes \mathbf{I}_Y - \sum u_i \otimes v_i) \|_{L^q(Y) L^\infty(X)} < \varepsilon$. If $G_1, G_2, \dots$ are a disjoint family of sets in $\Delta$, then for each $\varepsilon > 0$, and for each $k$ we can find $u_{k1}, \dots, u_{kN_k}$ and $v_{k1}, \dots, v_{kN_k}$ such that
  %
  \[ \| \mathbf{I}_{G_k} - \sum\nolimits_i u_{ki} \otimes v_{ki} \|_{L^q(Y) L^\infty(X)} < \varepsilon / 2^k. \]
  %
  By monotone convergence, if $G = \bigcup G_k$, then for each fixed $x$,
  %
  \[ \lim_{N \to \infty} \int \mathbf{I}_G(x,y) - \sum_{k = 1}^N \mathbf{I}_{G_k}(x,y)\; dx \]
\end{proof}










\chapter{Riemann Theory of Trigonometric Series}

Using the techniques of measure theory, we can actually prove that the Fourier series is essentially the unique way of representing a function on any part of its domain as a trigonometric series.

\begin{lemma}
  For any sequence $u_n$ and set $E$ of finite measure,
  %
  \[ \lim_{n \to \infty} \int_E \cos^2(nx + u_n)\; dx = |E|/2 \]
\end{lemma}
\begin{proof}
  We have
  %
  \[ \cos^2(nx + u_n) = \frac{1 + \cos(2nx + 2u_n)}{2} = \frac{1}{2} + \frac{\cos(2nx) \cos(2u_n) - \sin(2nx) \sin(2u_n)}{2} \]
  %
  Since $\cos(2u_n)$ and $\sin(2u_n)$ are bounded, we have $\int \chi_E(x) \cos(2nx)$ and $\int \chi_E(x) \sin(2nx) \to 0$ as $n \to \infty$, and the same is true for the latter component of the sum since $\cos(2u_n)$ and $\sin(2u_n)$ are bounded, we conclude that
  %
  \[ \int_E \cos^2(nx + u_n) = \int \chi_E(x) \cos^2(nx + u_n) = |E|/2 \]
  %
  completing the proof.
\end{proof}

\begin{theorem}[Cantor-Lebesgue Theorem]
  If, for some pair of sequences $a_0, a_1, \dots$ and $b_0, b_1, \dots$ are chosen such that
  %
  \[ \sum_{n = 0}^\infty a_n \cos(2 \pi nx) + b_n \sin(2 \pi nx) \]
  %
  converges on a set of positive measure in $[0,1]$, then $a_n, b_n \to 0$.
\end{theorem}
\begin{proof}
  Let $E$ be the set of points upon which the trigonometric series converges. We write $a_n \cos(2 \pi n x) + b_n \sin(2 \pi n x) = r_n \cos(nx + c_n)$. The result of the theorem is then precisely that $r_n \to 0$. If this is not true, then we must have $\cos(nx + c_n) \to 0$ for every $x \in E$. In particular, the dominated convergence theorem implies that
  %
  \[ \lim_{n \to \infty} \int_E \cos(nx + c_n)^2\; dx = 0 \]
  %
  Yet we know this tends to $|E|/2$ as $n \to \infty$, which is a contradiction.
\end{proof}

TODO: EXPAND ON THIS FACT.






\section{Convergence in $L^p$ and the Hilbert Transform}

We now move onto a more 20th century viewpoint on Fourier series, namely, those to do with operator theory. Under this viewpoint, the properties of convergence are captured under the boundedness of certain operators on function spaces, allowing us to use the modern theory of functional analysis to it's full extent on our problems. However, unlike in most of basic functional analysis, where we assume all operators we encounter are bounded to begin with, in harmonic analysis we more often than not are given an operator defined only on a subset of spaces, and must prove the continuity of such an operator to show it is well defined on all of space. We will illustrate this concept through the theory of the circular Hilbert transform, and its relation to the norm convergence of Fourier series.

A {\bf Fourier multiplier} is a linear transform $T$ associated with a given sequence of scalars $\lambda_n$, for $n \in \ZZ$. It is defined for any trigonometric polynomial $f = \sum_{|n| \leq N} c_n e_n$ as $Tf = \sum_{|n| \leq N} \lambda_n c_n e_n$. The trigonometric polynomials are dense in $L^p(\mathbf{T})$, for each $p < \infty$. An important problem is determining whether $T$ is therefore figuring out whether the operator can be extended to a {\it continuous operator} on the entirety of $L^p$. Because the trigonometric polynomials are dense in $L^p$, in the light of the Hahn Banach theorem it suffices to prove an inequality of the form $\| Tf \| \lesssim \| f \|$. Here are some examples of Fourier operators we have already seen.

\begin{example}
    The truncation operator $S_N$ is the transform associated with the scalars $\lambda_n = [|n| \leq N]$. The truncation is continuous, since for any integrable function $f$, the Fourier coefficients are uniformly bounded by $\| f \|_1$, so $\| S_N f \|_1 \leq N \| f \|_1$. Similarily, the F\'{e}jer truncation $\sigma_N$ associated to the multipliers $\lambda_N = [|n| \leq N](1 - |n|/N)$ is continuous on all integrable functions. These operators are easy to extend precisely because the nonzero multipliers have finite support.
\end{example}

\begin{example}
    In the case of the Abel sum, $A_r$, associated with $\lambda_n = r^{|n|}$, $A_r$ extends in a continuous way to all integrable functions, since
    %
    \[ |A_r f| = \left| \sum r^{|n|} \widehat{f}(n) e_n(t) \right| \leq \| f \|_1 \sum r^{|n|} = \| f \|_1 \left( 1 + \frac{2}{1 - r} \right) \]
    %
    Thus the map is bounded.
\end{example}

To understand whether the truncations $S_N f$ of $f$ converge to $f$ in the $L^p$ norms, rather than pointwise, we turn to the analysis of an operator which is the core of the divergence issue, known as the {\bf Hilbert transform}. It is a Fourier multiplier operator $H$ associated with the coeficients
%
\[ \lambda_n = \frac{\text{sgn}(n)}{i} = \begin{cases} +1/i & n > 0 \\ 0 & n = 0 \\ -1/i & n < 0 \end{cases} \]
%
Because
%
\[ [|n| \leq N] = \frac{\text{sgn}(n + N) - \text{sgn}(n-N)}{2} + \frac{[n = N] + [n = -N]}{2} \]
%
we conclude
%
\[ S_n f = \frac{i \left( e_{-n} H(e_n f) - e_n H(e_{-n} f) \right)}{2} + \frac{\widehat{f}(n) e_n + \widehat{f}(-n) e_{-n}}{2} \]
%
Since the operators $f \mapsto \widehat{f}(n) e_n$ are bounded in all the $L^p$ spaces since they are continuous in $L^1(\mathbf{T})$, we conclude that the operators $S_n$ are uniformly bounded as endomorphisms on $L^p(\mathbf{T})$ provided that $H$ is bounded as an operator from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$. Since $S_n f$ converges to $f$ in $L^p$ whenever $f$ is a trigonometric polynomial, this would establish that $S_n f$ converges to $f$ in the $L^p$ norm for any function $f$ in $L^p(\mathbf{T})$. Later on, as a special case of the Hilbert transform on the real line, we will be able to prove that $H$ is a bounded operator on $L^p(\mathbf{T})$ for all $1 < p < \infty$, and as a result, we find that $S_N f \to f$ in $L^p$ for all such $p$. Unfortunately, $H$ is not bounded from $L^1(\mathbf{T})$ to itself, and correspondingly, $S_N f$ does not necessarily converge to $f$ in the $L^1$ norm for all integrable $f$.

For now, we explore some more ideas in how we can analyze the Hilbert transform via convolution, the dual of Fourier multipliers. The fact that $\smash{\widehat{f * g} = \widehat{f} \widehat{g}}$ implies that if their is an integrable function $g$ whose Fourier coefficients corresponds to the multipliers of an operator $T$, then $f * g = Tf$ for any trigonometric polynomial $f$, and by the continuity of convolution, this is the unique extension of the Fourier multiplier operator. In the theory of distributions, one generalizes the family of objects one can take the Fourier series from integrable functions to a more general family of objects, such that every sequence of Fourier coefficients is the Fourier series of some {\it distribution}. One can take the convolution of any such distribution $\Lambda$ with a $C^\infty$ function $f$, and so one finds that $\Lambda * f = Tf$ for any trigonometric polynomial $f$. There is a theorem saying that {\it all} continuous translation invariant operators from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$ are given by convolution with a Fourier multiplier operator. In practice, we just compute the convolution kernel which defines the Fourier multiplier, but it is certainly a satisfying reason to justify the study of Fourier multipliers. For instance, a natural question is to ask which Fourier multipliers result in bounded operations in space.

\begin{theorem}
    A Fourier multiplier is bounded from $L^2(\mathbf{T})$ to itself if and only if the coefficients are bounded.
\end{theorem}
\begin{proof}
    If a Fourier multiplier is given by $\lambda_n$, then for some trigonometric polynomial $f$,
    %
    \[ \| Tf \|_2^2 = \sum \left|\widehat{Tf}(n) \right|^2 = \sum |\lambda_n|^2 \left| \widehat{f}(n) \right|^2 \]
    %
    If the $\lambda_n$ are bounded, then we can obtain from this formula the bound
    %
    \[ \| Tf \|_2^2 \leq \max |\lambda_n| \| f \|_2^2 \]
    %
    Conversely, if $Tf$ is bounded, then
    %
    \[ |\lambda_n^2| = \| T(e_n) \|_2^2 \leq \| T \|^2 \]
    %
    so the $\lambda_n$ are bounded.
\end{proof}

\begin{corollary}
    The Hilbert transform is a bounded endomorphism on $L^2(\mathbf{T})$. Note that we already know that $S_N f \to f$ in the $L^2$ norm.
\end{corollary}

The terms of the Hilbert transform cannot be considered the Fourier coefficients of any integrable function. Indeed, they don't vanish as $n \to \infty$. Nonetheless, we can use Abel summation to treat the Hilbert transform as convolution with an appropriate operator. For $0 < r < 1$, consider, for $z = e^{it}$,
%
\[ K_r(z) = \sum_{n \in \ZZ} \frac{\text{sgn}(n)}{i} r^{|n|} z^n = K * P_r \]
%
Since we know the Hilbert transform is continuous in $L^2(\mathbf{T})$, we can conclude that, in particular, for any $C^\infty$ function $f$,
%
\[ H f = \lim_{r \to 1} K * (P_r * f) = \lim_{r \to 1} (K * P_r) * f = \lim_{r \to 1} K_r * f \]
%
So it suffices to determine the limit of the $K_r$. We find that
%
\begin{align*}
    \sum_{n = 1}^\infty \frac{(rz)^n - (r \overline{z})^n}{i} &= \frac{r}{i} \left( \frac{1}{\overline{z} - r} - \frac{1}{z - r} \right) = \frac{r}{i} \frac{z - \overline{z}}{|z|^2 - 2r \text{Re}(z) + r^2}\\
    &= \frac{2r \sin(t)}{1 - 2r \cos(t) + r^2} = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r \sin^2(t/2)}\\
    &= \cot(t/2) + O \left( \frac{(1 - r)^2}{t^3} \right)
\end{align*}
%
Thus $K_r(t)$ tends to $\cot(t/2)$ locally uniformly away from the origin. But
%
\[ K_r(t) = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r\sin^2(t/2)} = O \left( \frac{t}{(1 - r)^2} \right) \]
%
If $f$ is any $C^\infty$ function on $\mathbf{T}$, then
%
\[ \left| \int_{|t| \geq \varepsilon} [K_r(t) - \cot(t/2)] f(t) \right| \lesssim (1 - r)^2 \| f \|_\infty \int_{|t| \geq \varepsilon} \frac{dt}{|t|^3} \lesssim \frac{(1 - r)^2 \| f \|_\infty}{\varepsilon^2} \]
%
\begin{align*}
    \left| \int_{|t| < \varepsilon} K_r(t) f(t)\; dt \right| &\leq \int_0^\varepsilon |K_r(t)||f(t) - f(-t)|\\
    &\lesssim \int_0^\varepsilon |tK_r(t)||f'(0)| \lesssim \frac{|f'(0)|}{(1 - r)^2} \int_0^\varepsilon t^2 \lesssim \| f' \|_\infty \frac{\varepsilon^3}{(1 - r)^2}
\end{align*}
%
\[ \left| \int_{|t| < \varepsilon} \cot(t/2) f(t)\; dt \right| \lesssim \int_0^\varepsilon \frac{|f(t) - f(-t)|}{t} \lesssim \varepsilon f'(0) \]
%
Thus
%
\[ \left| \int K_r(t) f(t)\; dt - \int \cot(t/2) f(t)\; dt \right| \lesssim \frac{(1 - r)^2}{\varepsilon^2} \| f \|_\infty + \left( \frac{\varepsilon^3}{(1 - r)^2} + \varepsilon \right) \| f' \|_\infty \]
%
Choosing $\varepsilon = (1 - r)^\alpha$ for some $2/3 < \alpha < 1$ shows that for sufficiently smooth $f$,
%
\[ (Hf)(x) = \lim_{r \to 1} \int \cot(t/2) f(x - t)\; dt \]


\section{A Divergent Fourier Series}

Analysis was built to analyze continuous functions, so we would hope the method of fourier expansion would work for all continuous functions. Unfortunately, this is not so. The behaviour of the Dirichlet kernel away from the origin already tells us that the convergence of Fourier series is subtle. We shall take advantage of this to construct a continuous function with divergent fourier series at a point.

To start with, we shall consider the series
%
\[ f(t) \sim \sum_{n \neq 0} \frac{e_n(t)}{n} \]
%
where $f$ is an odd function equaling $i(\pi - t)$ for $t \in (0,\pi]$. Such a function is nice to use, because its Fourier representation is simple, yet very close to diverging. Indeed, if we break the series into the pair
%
\[ \sum_{n = 1}^\infty  \frac{e_n(t)}{n}\ \ \ \ \ \ \ \ \ \ \sum_{n = -\infty}^{-1} \frac{e_n(t)}{n} \]
%
Then these series no longer are the Fourier representations of a Riemann integrable function. For instance, if $g(t) \sim \sum_{n = 1}^\infty \frac{e_n(t)}{n}$, then the Abel means

$A_r(f)(t) = $

\section{Conjugate Fourier Series}

When $f$ is a real-valued integrable function, then $\overline{\widehat{f}(-n)} = \widehat{f}(n)$. Thus we formally calculate that
%
\[ \sum_{n = -\infty}^\infty \widehat{f}(n) e_n(t) = \text{Re} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) \]
%
This series defines an analytic function in the interior of the unit circle since the coefficients are bounded. Thus the sum is a harmonic function in the interior of the unit circle. The imaginary part of this sum is
%
\[ \text{Im} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) = \Re \left( -i \sum_{n = -\infty}^\infty \text{sgn}(n) \widehat{f}(n) e_n(t) \right) \]
%
The right hand side is known as the conjugate series to the Fourier series $\widehat{f}(n)$. It is closely related to the study of a function $\tilde{f}$ known as the {\it conjugate function}.







\chapter{Oscillatory Integrals}

The goal of the theory of oscillatory integrals is to obtain estimates of integrals with highly oscillatory integrands, where standard techniques such as taking in absollute values, or various spatial decomposition strategies, fail completely to give tight estimates. A typical oscillatory integral is of the form
%
\[ I(\lambda) = \int e^{\lambda i \phi(x)} \psi(x)\; dx, \]
%
where $\phi$ and $\psi$ are scalar valued functions, known as the \emph{phase} and \emph{amplitude} functions. The value $\lambda$ is a parameter measuring the degree of oscillation. As $\lambda$ increases, oscillation increases, which implies more cancellation should occur on average, hence we should expect $I(\lambda)$ to decay as $\lambda \to \infty$. One of the main problems in the study of oscillatory integrals is to measure the asymptotic decay more precisely.

\begin{example}
    The most basic example of an oscillatory integral is the Fourier transform, where for each function $f \in L^1(\RR)$, and each $\xi \in \RR$, we consider the quantity
    %
    \[ \widehat{f}(\xi) = \int_{-\infty}^\infty e(-\xi x) f(x)\; dx. \]
    %
    Thus $f$ plays the role of the amplitude, the phase function is $\phi(x) = x$, and $\xi$ takes the role of $\lambda$. The basic theory of the Fourier transform hints that we can obtain decay in this integral as $\xi \to \infty$ by exploiting the smoothness of the function $f$.
\end{example}

There are two main tools to estimate oscillatory integrals. The first, the method of steepest descent, uses complex analysis to shift the integral to a domain where less oscillation occurs, so that standard estimation strategies can be exmployed. However, this method seems to have limited applicability to oscillatory integrals over multivariable domains. The second method, known as the method of stationary phase, states that if $\phi$ is smooth, and $\nabla \phi$ has an isolated family of zeroes, then the oscillatory integral asymptotics can be localized to regions around the values $x_0$ with $\nabla \phi(x_0) = 0$. Heuristically, each zero $x_0$ contributes $\psi(x_0) e ( \lambda \phi(x_0) )$, times the volume of the region around $x_0$ where $\phi$ deviates by $O(1/\lambda)$ to the overall asymptotics.

\section{One Dimensional Theory}

Let us begin with a simple example of an oscillatory integral, i.e.
%
\[ I(\lambda) = \int_J e^{i \lambda \phi(x)}\; dx, \]
%
where $J$ is a closed interval, and $\phi: J \to \RR$ is Borel measurable. Taking in absolute values shows that $|I(\lambda)| \leq |J|$ for all $\lambda$. If $\phi$ is constant, then $I(\lambda) = |J| e^{i \lambda \phi}$, so in this case the estimate is sharp. But if $\phi$ varies, we expect $I(\lambda)$ to decay as $\lambda \to \infty$. For instance, the Esse\'{e}n concentration inequality shows that if we are to expect \emph{average} decay in the integral $I$ over a range of $\lambda$, then $\phi$ must not be concentrated around any point.

\begin{theorem}[Esse\'{e}n Concentration Inequality]
  Let $\phi: J \to \RR$ be Borel measurable, and for each $\lambda \in \RR$, set
  %
  \[ I(\lambda) = \int_J e^{i \lambda \phi(x)}\; dx. \]
  %
  Then for any $\varepsilon > 0$,
  %
  \[ \sup_{\phi_0 \in \RR} |\{ x \in [0,1]: |\phi(x) - \phi_0| \leq \varepsilon \}| \lesssim \varepsilon \int_0^{1/\varepsilon} |I(\lambda)|\; d\lambda, \]
  %
  where the implicit constant is independant of $\phi$.
\end{theorem}
\begin{proof}
  By rescaling, we may assume that $J = [0,1]$. Moreover, for any choice of $\phi_0$, we may replace $\phi$ with $\phi - \phi_0$, reducing the analysis to the case where $\phi_0 = 0$. Similarily, replacing $\phi$ with $\phi/\varepsilon$ reduces us to the situation where $\varepsilon = 1$. Thus we must show
  %
  \[ |\{ x \in [0,1]: |\phi(x)| \leq 1 \}| \lesssim \int_0^1 |I(\lambda)|\; d\lambda, \]
  %
  where the implicit constant is independant of the function $\phi$. If $\psi$ is an integrable function supported on $[0,1]$, then Fubini's theorem implies
  %
  \begin{align*}
    \int_0^1 \psi(\lambda) I(\lambda)\; d\lambda &= \int_0^1 \int_0^1 \psi(\lambda) e^{\lambda i \phi(x)}\; d\lambda\; dx\\
    &= \int_0^1 \widehat{\psi}(- \phi(x) / 2 \pi)\; dx.
  \end{align*}
  %
  In particular, this means that
  %
  \[ \left| \int_0^1 \widehat{\psi}(- \phi(x) / 2\pi)\; dx \right| \leq \| \psi \|_{L^\infty[0,1]} \int_0^1 |I(\lambda)|\; d\lambda. \]
  %
  If we choose a bounded function $\psi$ such that $\widehat{\psi}$ is non-negative, and bounded below on $[-2\pi,2\pi]$, then
  %
  \[ \left| \int_0^1 \widehat{\psi}(- \phi(x) / 2 \pi)\; dx \right| \gtrsim |\{ x \in [0,1]: |\phi(x)| \leq 1 \}|, \]
  %
  and so the claim follows easily.
\end{proof}

Thus if large cancellation happens in $I(\lambda)$ for the average $\lambda$, this automatically implies that $\phi$ cannot be concentrated around any particular point.  Conversely, we want to show that if $\phi$ varies significantly, then $I$ exhibits cancellation as $\lambda \to \infty$. The condition that $\phi'$ is bounded below is not sufficient to guarantee cancellation independant of the function $\phi$, as the next example shows, if the integrand oscillated at a wavelength $1/\lambda$.

\begin{example}
  Fix $\lambda_0 \in \ZZ$, and let $\phi(x) = 2 \pi x + f(\lambda_0 x) / \lambda_0$, where $f$ is smooth and 1-periodic, $\| f' \|_{L^\infty(\RR)} \leq \pi$, and
  %
  \[ \int_0^1 e^{2 \pi i x + i f(x)}\; dx \neq 0. \]
  %
  Then for each $x \in \RR$, $\pi \leq |\phi'(x)| \leq 3\pi$, and in particular, is bounded independently of $\lambda_0$. Since $\phi(x + 1/\lambda_0) = \phi(x) + 2 \pi / \lambda_0$, we find $e^{i \lambda_0 \phi(x)}$ is $1/\lambda_0$ periodic. In particular, this means
  %
  \[ I(\lambda_0) = \int_0^1 e^{\lambda_0 i \phi(x)} = \int_0^1 e^{2 \pi i x + i f(x)}\; dx. \]
  %
  which is comparable to 1, independantly of $\lambda_0$.
\end{example}

Controlling $\phi''$ in addition to $\phi'$, however, is sufficient.

\begin{theorem}
  Let $\phi: J \to \RR$ be smooth, and suppose there exists constants $A,B > 0$ with $|\phi'(x)| \geq A$ and $|\phi''(x)| \leq B$ for all $x \in J$. Then for all $\lambda > 0$, we find
  %
  \[ |I(\lambda)| \lesssim \frac{1}{\lambda} \left( \frac{1}{A} + \frac{B}{A^2} |J| \right). \]
\end{theorem}
\begin{proof}
  A dimensional analysis shows that the inequality is invariant under rescalings in $x$ and $\lambda$, so we may assume that $J = [0,1]$, and $\lambda = 1$. An integration by parts shows that
  %
  \begin{align*}
    \int_0^1 e^{i \phi(x)}\; dx &= \int_0^1 \frac{1}{i \phi'(x)} \frac{d}{dx} \left( e^{i \phi(x)} \right)\; dx\\
    &= \left( \frac{e^{i \phi(1)}}{i \phi'(1)} - \frac{e^{i \phi(0)}}{i \phi'(0)} \right) - \int_0^1 \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) e^{i \phi(x)}.
  \end{align*}
  %
  Now
  %
  \[ \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) = - \frac{\phi''(x)}{\phi'(x)^2}, \]
  %
  so taking in absolute values completes the proof.
\end{proof}

One can keep applying absolute values to obtain further bounds in terms of higher order derivatives of $\phi$. For instance, another integration by parts shows that if there is $A,B,C > 0$ such that for $x \in J$, if $\phi'(x) \geq A$, $\phi''(x) \leq B$, and $\phi'''(x) \leq C$, then
%
\[ |I(\lambda)| \lesssim \frac{1}{\lambda} \left( \frac{1}{A} \right) + \frac{1}{\lambda^2} \left( \frac{B}{A^3} + \frac{C}{A^3} |J| + \frac{B^2}{A^4} |J| \right). \]
%
One can keep taking in absolute values, but the $1/\lambda$ decay will still remain. This is to be expected, for instance, if $\phi(x) = x$ and $J = [0,1]$ then
%
\[ \limsup_{\lambda \to \infty} |I(\lambda) \cdot \lambda| = 2, \]
%
so we cannot obtain any better decay than $1/\lambda$ here.

Another option is to not require control on the second derivative of the phase, but instead to assume that $\phi'$ is monotone, which prevents the kind of oscillation present in our counterexample. 

\begin{lemma}[Van der Corput]
  Let $\phi: \RR \to \RR$ be a smooth phase such that $|\phi'(x)| \geq A$ for all $x \in J$, and $\phi'$ is monotone. Then for all $\lambda > 0$ we have
  %
  \[ |I(\lambda)| \lesssim \frac{1}{A \lambda}, \]
  %
  where the implicit constant is independent of $J$.
\end{lemma}
\begin{proof}
  The same integration by parts as before shows that if $J = [a,b]$,
  %
  \begin{align*}
    \int_J e^{\lambda i \phi(x)}\; dx &= \left( \frac{e^{i \phi(b)}}{\lambda i \phi'(b)} - \frac{e^{i \phi(a)}}{i \phi'(a)} \right) + \frac{1}{i\lambda} \int_J \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) e^{i \phi(x)}\; dx.
  \end{align*}
  %
  The two endpoints are $O(1/A \lambda)$. For the second sum, we perform a simple trick. Since $\phi'$ is monotone, so too is $1/\phi'$, so in particular, it's derivative has a constant sign. Thus by the fundamental theorem of calculus,
  %
  \begin{align*}
    \left| \int_J \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) e^{i \phi(x)}\; dx \right| &\leq \int_J \left| \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right)  \right|\; dx\\
    &= \left| \int_J \frac{d}{dx} \left( \frac{1}{\phi'(x)} \right) \right|\; dx\\
    &= \frac{1}{\phi'(b)} - \frac{1}{\phi'(a)}.
  \end{align*}
  %
  Combining these inequalities completes the proof.
\end{proof}

Since the Van der Corput bound does not depend on $|J|$, it can be easily iterated to give a theorem about higher derivatives of a function $\phi$.

\begin{lemma}
  Let $\phi: \RR \to \RR$ be smooth, and suppose there is some $k \geq 2$ such that $|\phi^{(k)}(x)| \geq A$ for all $x \in J$. Then for all $\lambda > 0$, we find
  %
  \[ |I(\lambda)| \lesssim_k \frac{1}{(A \lambda)^{1/k}}, \]
  %
  where the implicit constant is independant of $J$.
\end{lemma}
\begin{proof}
  We perform an induction on $k$, the case $k = 1$ already proven. By scale invariance, we may assume $\lambda = 1$. Now $\phi^{(k-1)}$ is monotone, so for each $\alpha > 0$, outside an interval of length at most $O(\alpha/A)$, $|\phi^{(k-1)}(x)| \geq \alpha$. Thus applying the trivial bound in the excess region, and the case $k - 1$ on the other intervals, we conclude
  %
  \[ |I(\lambda)| \lesssim_k \frac{\alpha}{A} + \alpha^{-1/(k-1)} \]
  %
  Optimizing over $\alpha$, we find $|I(\lambda)| \lesssim_k A^{-1/k}$.
\end{proof}

Let us now consider a one dimensional oscillatory integral with a varying amplitude $\psi$, i.e.
%
\[ I(\lambda) = \int_{-\infty}^\infty e^{i \lambda \phi(x)} \psi(x)\; dx. \]
%
The Van der Corput lemma also applies here.

\begin{lemma}
  Fix $k \geq 1$. Suppose $\psi$ is supported on $[a,b]$, and suppose $|\phi^{(k)}(x)| \geq A$ for all $x \in [a,b]$, with $\phi'$ monotone if $k = 1$. Then 
  %
  \[ |I(\lambda)| \lesssim_k \frac{\| \psi \|_{L^\infty(\RR)} + \| \psi' \|_{L^1(\RR)}}{(A \lambda)^{1/k}}. \]
\end{lemma}
\begin{proof}
  Fix $c_0 \in [a,b]$, and define
  %
  \[ I_0(x) = \int_{c_0}^x e^{i \lambda \phi(t)}\; dt. \]
  %
  The standard Van-der Corput lemma implies that for all $x$,
  %
  \[ |I_0(x)| \lesssim_k \frac{1}{(A \lambda)^{1/k}}. \]
  %
  An integration by parts gives that for any $a < b$,
  %
  \begin{align*}
    \int_a^b \psi(x) e^{i \lambda \phi(x)}\; dx &= \int_a^b \psi(x) I_0'(x)\; dx\\
    &= [\psi(b) I_0(b) - \psi(a) I_0(a)] - \int_a^b \psi'(x) I_0(x)\; dx.
  \end{align*}
  %
  Now
  %
  \[ |\psi(b) I_0(b) - \psi(a) I_0(a)| \lesssim \frac{\| \psi \|_{L^\infty(\RR)}}{(A \lambda)^{1/k}} \]
  %
  and
  %
  \[ \left| \int_a^b \psi'(x) I_0(x)\; dx \right| \lesssim_k \frac{\| \psi' \|_{L^1(\RR)}}{(A \lambda)^{1/k}}. \]
  %
  Putting these two estimates together completes the proof.
\end{proof}

If $\psi$ is smooth and compactly supported, integration by parts is very successful because there are no boundary terms.

\begin{theorem}
    If $\phi$ and $\psi$ are smooth, with $\psi$ compactly supported, and $\phi'(x) \neq 0$ for all $x$ in the support of $\psi$, then for all $N > 0$,
    %
    \[ I(\lambda) \lesssim_N 1/\lambda^N, \]
    %
    where the implicit constants depend on the functions $\phi$ and $\psi$.
\end{theorem}
\begin{proof}
  A single integration by parts gives
  %
  \begin{align*} I(\lambda) &= \frac{1}{\lambda} \int \frac{\psi(x)}{i \phi'(x)} \frac{d}{dx} \left( e^{\lambda i \phi(x)} \right)\\
  &= - \frac{1}{i \lambda} \int \frac{d}{dx} \left( \frac{\psi(x)}{\phi'(x)} \right) e^{i \phi(x)}\\
  &= \frac{1}{i \lambda} \int \frac{\phi'(x) \psi'(x) - \psi(x) \phi''(x)}{\phi'(x)^2}.
  \end{align*}
  %
  Further integration by parts give, for each $N$, that
  %
  \[ I(\lambda) = \lambda^{-N} \int \frac{P(x)}{\phi'(x)^{2N}} e^{i \phi(x)}, \]
  %
  where $P(x)$ is a polynomial function in the derivatives of $\phi$ and $\psi$ up to order $N+1$, in particular, with the same support as $\psi$. Thus we can take in absolute values and integrate to conclude $|I(\lambda)| \lesssim_{\psi,N} \lambda^{-N}$.
\end{proof}

\begin{remark}
  We note that the implicit constants in the theorem for a particular $N$ can be upper bounded uniformly, given uniform upper bounds on the measure of the support of $\psi$, upper bounds on the derivatives of $\phi$ and $\psi$ of order up to $N+1$, and lower bounds on $\phi'$ over the support of $\psi$.
\end{remark}

Let us now move onto a `stationary phase', i.e. a phase $\phi$ whose derivative vanishes at a point. The simplest example of such a phase is the integral
%
\[ I(\lambda) = \int_{-\infty}^\infty e^{i \lambda x^2} \psi(x)\; dx. \]
%
Our heuristics tell us $I(\lambda)$ decays on the order of $\lambda^{-1/2}$, which agrees with the asymptotics we now find.

\begin{theorem}
  Let $\psi \in \mathcal{S}(\RR)$ be a Schwartz amplitude. Then for each $N \geq 0$,
  %
  \[ \int_{-\infty}^\infty \psi(x) e^{\lambda i x^2}\; dx = e^{i \pi / 4} \cdot \pi^{1/2} \cdot \sum_{n = 0}^N \frac{i^n \psi^{(2n)}(0)}{4^n \lambda^{n + 1/2}} + O_{N,\psi}(1/\lambda^{N + 3/2}). \]
\end{theorem}
\begin{comment}
\begin{proof}
  Rescaling, it suffices to prove the theorem when $\psi(x) = 1$ whenever $|x| < 1$. Let $\alpha(x)$ be a smooth function with $\alpha(x) = 1$ for $|x| \geq 1/2$, and with $\alpha(x) = 0$ for $|x| < 1/4$. Then for each $k \geq 1$, define
  %
  \[ \beta_k(x) = \alpha(2^k x) - \alpha(2^{k-1} x). \]
  %
  Then $\beta_k$ is supported on $1/2^{k+2} \leq |x| \leq 1/2^k$, and moreover, for each $x \in \RR$,
  %
  \[ \alpha(x) + \sum_{k = 1}^\infty \beta_k(x) = 1. \]
  %
  It is simple to see that
  %
  \begin{align*}
    \int_{-\infty}^\infty \psi(x) e^{\lambda i x^2}\; dx &= \int_{-\infty}^\infty \alpha(x) \psi(x) e^{\lambda i x^2}\; dx\\
    &\ \ \ \ + \sum_{k = 1}^\infty \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx.
  \end{align*}
  %
  Now $\alpha \psi$ is a compactly supported amplitude supported away from the origin, so for each $N$,
  %
  \[ \left| \int_{-\infty}^\infty \alpha(x) \psi(x) e^{\lambda i x^2}\; dx \right| \lesssim_{\alpha,\psi,N} \lambda^{-N}. \]
  %
  The same argument works for $\beta_1$, and so by rescaling, for each $k$ and $M$,
  %
  \begin{align*}
    \left| \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx \right| &\lesssim_{\alpha,\psi,M} 2^{(2M-1)k} \lambda^{-M}.
  \end{align*}
  %
  In particular, we may sum the inequality for small $k$, and with $M$ an appropriate multiple of $N$, to conclude
  %
  \[ \sum_{k = 1}^{\lg(\lambda^{1/2-\varepsilon})} \left| \int_{-\infty}^\infty \beta_k(x) e^{\lambda i x^2}\; dx \right| \lesssim_{\alpha,\psi,N,\varepsilon} \lambda^{-N}. \]
  %
  If we set
  %
  \[ \gamma(x) = \sum_{k = \lg(\lambda^{1/2-\varepsilon})}^\infty \beta_k(x), \]
  %
  then $\gamma(x) = 0$ for $|x| \geq 1/\lambda^{3/4}$, and $\gamma(x) = 1$ for $|x| \leq 1/4\lambda^{3/4}$. Rescaling, we have
  %
  \[ \int_{-\infty}^\infty \gamma(x) e^{\lambda i x^2} = \lambda^{-3/4} \int_{-\infty}^\infty \gamma(x \cdot \lambda^{3/4}) e^{ix^2 / \lambda^{1/2}}. \]
\end{proof}


IDEA: Sum up dyadically on intervals $|x| \sim 2^k \lambda^{-1/2}$, for $k = 1$ to $k = \lfloor \log( \lambda^{1/2} \varepsilon) - 2 \rfloor$, then hopefully the oscillatory integral with phase $x^2$ and amplitude $\psi(x) \sum_{k = \lfloor \lg(\lambda^{1/2} \varepsilon) - 2 \rfloor}^\infty \beta_k(x/\lambda^{1/2})$ decays arbitrarily fast in $\lambda$?


Then for each $n$, define $\beta_n(x) = \alpha(x/2^n) - \alpha(x/2^{n-1})$. Thus we have $\alpha(x) + \sum_{k = 1}^\infty \beta_k(x) = 1$ for all $x \in \RR$. Moreover, $\beta_k$ is supported on $[-2^n, -$

\end{comment}
\begin{proof}
  Applying the multiplication formula for the Fourier transform, noting that the distributional Fourier transform of $e^{i \lambda x^2}$ is
  %
  \[ e^{i \pi / 4} (\pi/\lambda)^{1/2} e^{-i \pi^2 \xi^2 / \lambda}, \]
  %
  we conclude that
  %
  \[ I(\lambda) = e^{i \pi / 4} (\pi/\lambda)^{1/2} \int_{-\infty}^\infty e^{-i \pi^2 \xi^2 / \lambda} \widehat{\psi}(\xi)\; d\xi. \]
  %
  Now for any $N$, we can write
  %
  \[ e^{-i \pi^2 \xi^2 / \lambda} = \sum_{n = 0}^N \frac{1}{n!} \left( \frac{-i \pi^2 \xi^2}{\lambda} \right)^n + O_N \left( (\xi^2 / \lambda)^{N+1} \right). \]
  %
  Thus substituting in the Taylor series, and then applying the Fourier inversion formula, we find
  %
  \begin{align*}
    I(\lambda) &= e^{i \pi / 4} (\pi/\lambda)^{1/2} \sum_{n = 0}^N \frac{1}{n!} \int_{-\infty}^\infty \left( \frac{-i \pi^2 \xi^2}{\lambda} \right)^n \widehat{\psi}(\xi)\; d\xi + O_{\psi,N} \left( 1/\lambda^{N+3/2}  \right)\\
    &= e^{i \pi / 4} (\pi/\lambda)^{1/2} \sum_{n = 0}^N \frac{i^n}{4^n n!} \frac{1}{\lambda^n} \int_{-\infty}^\infty (2\pi i \xi)^{2n} \widehat{\psi}(\xi)\; d\xi + O_{\psi,N} \left( 1 / \lambda^{N+3/2} \right)\\
    &= e^{i \pi / 4} (\pi/\lambda)^{1/2} \sum_{n = 0}^N \frac{i^n \psi^{(2n)}(0)}{4^n n!} \frac{1}{\lambda^n} + O_{\psi,N} \left( 1 / \lambda^{N+3/2} \right). \qedhere
  \end{align*}
\end{proof}

\begin{remark}
  The implicit constant can be made independent of $\psi$ given uniform upper bounds on
  %
  \[ \int_{-\infty}^\infty |\widehat{\psi}(\xi)| |\xi|^{2(N+1)}\; d\xi. \]
  %
  In particular, this can be obtained by uniform upper bounds on the support of $\psi$, upper bounds on the magnitude of $\psi$, and upper bounds on the magnitude of the $(2N+4)$th derivative of $\psi$.
\end{remark}

It requires only a simple change of variables to extend this theorem to arbitrary quadratic phases. We say a critical point of a function is \emph{non-degenerate} if the second derivative at that point is nonzero.

\begin{theorem}
  Let $\phi$ be a smooth phase with finitely many non-degenerate critical points, and let $\psi$ be a smooth compactly supported amplitude function. Then there exists a sequence of constants $\{ a_n \}$, depending on the derivatives of $\phi$ and $\psi$ at the critical points, such that for each $N \geq 0$,
  %
  \[ I(\lambda) = \lambda^{-1/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_{\phi,\psi,N} ( 1/\lambda^{N+3/2} ). \]
  %
  In particular, if $\phi$ has a single critical point at some $x_0$, then
  %
  \[ a_0 = \sqrt{ \frac{2\pi}{-i \phi''(x_0)} } \cdot e^{\lambda i \phi(x_0)} \psi(x_0). \]
\end{theorem}
\begin{proof}
  By a partition of unity argument, it suffices to prove this theorem assuming that $\phi$ has only a single stationary point, which by translation we may assume to be at the origin, with $\phi(0) = 0$, and that $\phi(x)$ and $\phi'(x)$ are nonzero for all nonzero $x$ in the support of $\psi$. Moreover, rescaling enables us to assume $\phi''(0) = 2$. We can define a function
  %
  \[ y(x) = \text{sgn}(x) \cdot \phi(x)^{1/2}. \]
  %
  Then $y$ is a smooth function in the support of $\phi$. By the change of variables formula, there exists a smooth, compactly supported function $\psi_0(y)$ such that
  %
  \[ I(\lambda) = \int \psi(x) e^{\lambda i \phi(x)}\; dx = \int \psi_0(y) e^{\lambda i y^2}\; dy. \]
  %
  Thus we can apply the previous theorem to conclude that there exists a sequence of constants $\{ a_n \}$ such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-1/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_{\phi,\psi,N}(1/\lambda^{N+3/2}). \]
  %
  The existence in this theorem is a \emph{constructive} existence statement. The proof gives an effective algorithm to produce the constants $a_n$ for any particular phase $\phi$. In particular,
  %
  \[ a_0 = e^{i\pi/4} \pi^{1/2} \psi_0(0) = e^{i\pi/4} \pi^{1/2} \left( \frac{\psi(0)}{y'(0)} \right). \]
  %
  Since
  %
  \begin{align*}
    y'(0) &= \lim_{x \to 0} y'(x) = \lim_{x \to 0} \frac{\phi'(x)}{2 \text{sgn}(x) \phi(x)^{1/2}}\\
    &= \frac{1}{2} \lim_{x \to 0} \frac{\phi'(x)}{x} \left( \frac{x^2}{\phi(x)} \right)^{1/2} = \frac{\phi''(0)}{2 \phi''(0)^{1/2}} = \phi''(0)^{1/2}/2 = 2^{1/2}.
  \end{align*}
  %
  Thus $a_0 = 2^{1/2} e^{i\pi/4} \pi^{1/2} \psi(0)$.
\end{proof}

\begin{remark}
  If we incorporate $\lambda$ into the phase, considering the oscillatory integral
  %
  \[ \int e^{i \phi(x)} \psi(x)\; dx, \]
  %
  then if $\phi$ has a nondegenerate stationary point at $x_0$, the last theorem says that
  %
  \[ \int e^{i \phi(x)} \psi(x)\; dx \approx \left( \frac{2\pi}{-i \phi''(x_0)} \right)^{1/2} e^{i \phi(x_0)} \psi(x_0), \]
  %
  where this approximation gets better and better for larger and larger $\lambda$.
\end{remark}

If the phase $\phi$ has a critical point of order greater than two, than the asymptotics of the oscillatory integral get worse. In particular, if $\phi$ has a zero of order $k$, then around this region $\phi$ differs by $1/\lambda$ on an interval of length $1/\lambda^{1/k}$, so we might $I(\lambda)$ to be proportional to $\lambda^{1/k}$. This is precisely what happens, but our proof will not rely on the Fourier transform since the computation of the Fourier transform of $e^{\lambda ix^k}$ is quite difficult to calculate when $k > 2$. The next proof also works for the case $k = 2$, but the proof is different.

\begin{lemma}
  For any non-negative integers $l$ and $k$, there is a positive constant $A_{kl} > 0$ such that for any $\lambda \in \RR$ and $\varepsilon > 0$,
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-\varepsilon x^k} x^l\; dx = A_{kl} (\varepsilon - i \lambda)^{-(l+1)/k}, \]
  %
  where the $k$th root is the principal root for non-negative complex numbers.
\end{lemma}
\begin{proof}
  If $z = (\varepsilon - i \lambda)^{1/k} x$, and if $\alpha_N$ is the ray between the origin and the point $N (\varepsilon - i \lambda)^{1/k}$, then
  %
  \[ \int_0^N e^{\lambda i x^k} e^{- \varepsilon x^k} x^l\; dx = (\varepsilon - i \lambda)^{-(l+1)/k} \int_{\alpha_N} e^{-z^k} z^l\; dz. \]
  %
  Let $\theta \in (-\pi/2,0]$ be the argument of $(\varepsilon - i \lambda)^{1/k}$, and set $\beta_N$ to be the arc between $N ( \varepsilon - i \lambda)^{1/k}$ and $N (\varepsilon^2 + \lambda^2)^{1/2}$. Then $\beta_N$ has length $O(N)$, with implicit constant depending on $\lambda$ and $\varepsilon$. Moreover, any point $z$ on $\beta_N$ has modulus $N (\varepsilon^2 + \lambda^2)^{1/2}$ and argument less than or equal to $\theta / k$. But this implies that $\text{Re}(z^k) \geq N^k (\varepsilon^2 + \lambda^2)^{k/2} \cos(\theta)$, and so there exists a constant $c$ depending on $\varepsilon$ and $\lambda$ such that $|e^{-z^k}| \leq e^{c N^k}$. But this means that $|z^l e^{-z^k}| \leq N^l e^{-cN^k}$. Thus taking in absolute values gives that
  %
  \[ \lim_{N \to \infty} \int_{\beta_N} e^{-z^k} z^l\; dz = 0. \]
  %
  In particular, applying Cauchy's theorem, we conclude that
  %
  \[ \lim_{N \to \infty} \int_{\gamma_N} e^{-z^k} z^l\; dz = \int_0^\infty e^{-x^k} x^l\; dx. \]
  %
  If we denote the latter integral by $A_{kl} > 0$, then we have shown that
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-\varepsilon x^k} x^l\; dx = A_{kl} \cdot (\varepsilon - i \lambda)^{-(l+1)/k}, \]
  %
  as was required to be shown.
\end{proof}

\begin{remark}
  In particular, this implies that for each $\varepsilon$, there exists constants $A_{kln}$ such that
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-x^k} x^l\; dx = \lambda^{-(l+1)/k} \sum_{n = 0}^\infty A_{kln} \lambda^{-n}. \]
  %
  This is obtained by taking the Laurent series of
  %
  \[ (1 - i\lambda)^{-(l+1)/k} = \lambda^{-(l+1)/k} (\lambda^{-1} - i)^{-(l+1)/k}, \]
  %
  which converges absolutely for $\lambda > 1$. In particular, for each $N$ and for each $\lambda$, we conclude
  %
  \[ \int_0^\infty e^{\lambda i x^k} e^{-x^k} x^l\; dx = \lambda^{-(l+1)/k} \sum_{n = 0}^N A_{kln} \lambda^{-n} + O_N \left(1/\lambda^{n + 1 + 1/k} \right). \]
\end{remark}

\begin{lemma}
  If $\eta$ is compactly supported and smooth, then
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx \right| \lesssim_{l,k,\eta} \lambda^{-(l + 1)/k}. \]
\end{lemma}
\begin{proof}
  Let $\alpha$ be a bump function supported on $[-2,2]$ with $\alpha(x) = 1$ for $|x| \leq 1$. For each $\varepsilon > 0$, write
  %
  \begin{align*}
    \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx &= \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) \alpha(x/\varepsilon)\; dx\\
    &\ \ \ \ + \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx,
  \end{align*}
  %
  where we will bound each term and optimize for a small $\varepsilon$. We trivially have
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) \alpha(x/\varepsilon)\; dx \right| \lesssim_\eta \varepsilon^{l+1}, \]
  %
  We apply an integration by parts to the second integral, noting that $e^{\lambda i x^k}$ is a fixed point of the differential operator
  %
  \[ Df = \frac{1}{\lambda i k x^{k-1}} \frac{df}{dx}. \]
  %
  If we consider the differential operator
  %
  \[ D^*g = \frac{d}{dx} \left( \frac{-f}{\lambda i k x^{k-1}} \right) = \left( \frac{i}{\lambda k} \right) \left( \frac{f'(x)}{x^{k-1}} - \frac{(k-1) f(x)}{x^k} \right), \]
  %
  then for any smooth $f$ and compactly supported $g$,
  %
  \[ \int_{-\infty}^\infty (Df)(x) g(x) = \int_{-\infty}^\infty f(x) (D^* g)(x). \]
  %
  In particular,
  %
  \begin{align*}
    \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx &= \int_{-\infty}^\infty D^N(e^{\lambda i x^k})\; x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx\\
    &= \int_{-\infty}^\infty e^{\lambda i x^k}\; (D^*)^N \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \}\; dx.
  \end{align*}
  %
  Write $g_N(x) = (D^*)^N \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \}$. Since $x^l \eta(x) (1 - \alpha(x/\varepsilon))$ vanishes for $|x| \leq \varepsilon$, so too does $g_N(x)$. For $N \geq l/(k-1)$, and $|x| \geq \varepsilon$, we have
  %
  \[ |g_N(x)| \lesssim_{N,\eta} \lambda^{-N} \varepsilon^{-N} |x|^{l - N(k-1)}, \]
  %
  where the implicit constant depends on upper bounds for the derivatives of $\eta$ of order to $N$. We can thus take in absolute values after integrating by parts to conclude that if $N > (l+1)/(k-1)$, then
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x) (1 - \alpha(x/\varepsilon))\; dx \right| \lesssim_{N,\eta} \lambda^{-N} \varepsilon^{l + 1 - Nk} \]
  %
  Thus we can put the two bounds together to conclude that
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx \right| \lesssim_{N,\eta} \varepsilon^{l+1} + \lambda^{-N} \varepsilon^{l+1-Nk}. \]
  %
  Picking $\varepsilon = \lambda^{-1/k}$ gives
  %
  \[ \left| \int_{-\infty}^\infty e^{\lambda i x^k} x^l \eta(x)\; dx \right| \lesssim_{N,\psi} \lambda^{-(l+1)/k}. \qedhere \]
  %
  But $N$ was chosen depending only on $k$ and $l$, so the implicit constants depend on the correct variables.
%  \[ D^* \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \} = c x^{l-k} \eta(x) (1 - \alpha(x/\varepsilon)) + x^{l+1-k} \eta'(x) (1 - \alpha(x/\varepsilon) - \varepsilon^{-1} x^{l+1-k} \eta(x) \alpha'(x/\varepsilon) \]
%  \[ (D^*)^2 \{ x^l \eta(x) (1 - \alpha(x/\varepsilon)) \} = x^{l-2k} (1 - \alpha(x/\varepsilon))
  %  (d/dx) \{ x^{l+1-2k} \eta(x) (1 - \alpha(x/\varepsilon)) + x^{l+2-2k} \eta'(x) (1 - \alpha(x/\varepsilon) - \varepsilon^{-1} x^{l+2-2k} \eta(x) \alpha'(x/\varepsilon) \} \]
\end{proof}

\begin{remark}
  The implicit constants can be bounded uniformly given uniform upper bounds on the magnitude of the derivatives of $\eta$ of order up to
  %
  \[ \lceil (l+1)/(k-1) \rceil, \]
  %
  and upper bounds on the measure of the support of $\eta$.
\end{remark}

We can now prove the asymptotics for the model case $\phi(x) = x^k$.

\begin{theorem}
  Suppose $\psi$ is a smooth compactly supported amplitude, and $\phi$ is a smooth phase with $\phi'(x) \neq 0$ on the support of $\psi$ except at some point $x_0$, where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, and $\phi^{(k)}(x_0) \neq 0$. Then there is a sequence $\{ a_n \}$ such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-n/k} + O_{\psi,k,N} \left( 1/\lambda^{(N+2)/k} \right). \]
\end{theorem}
\begin{proof}
  Let us begin with the model case $\phi(x) = x^k$. Let $\tilde{\psi}$ be a bump function with $\tilde{\psi}(x) = 1$ for all $x$ with $\psi(x) > 0$. Then
  %
  \[ I(\lambda) = \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} [e^{x^k} \psi(x)] \tilde{\psi}(x)\; dx. \]
  %
  For each $N$, perform a Taylor expansion, writing
  %
  \[ e^{x^k} \psi(x) = \sum_{n = 0}^N a_n x^n + x^{N+1} R_N(x). \]
  %
  Thus if $P_N(x) = \sum_{n = 0}^N a_n x^n$,
  %
  \begin{align*}
    \int_{-\infty}^\infty &e^{\lambda i x^k} e^{-x^k} [e^{x^k} \psi(x)] \tilde{\psi}(x)\; dx\\
    & = \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} P_N(x)\; dx\\
    & + \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} P_N(x) (\tilde{\psi}(x) - 1)\; dx\\
    & + \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} x^{N+1} R_N(x) \tilde{\psi}(x)\; dx.
  \end{align*}
  %
  The first integral can be expanded in the required power series. The second integral, since it is supported away from the origin, is $O_M(\lambda^{-M})$ for any $M > 0$. And in the last lemma we showed the third integral is $O(\lambda^{-(N+2)/k})$, so combining these three terms gives the required result. The general case follows from a change of variables.
\end{proof}

\begin{remark}
  As we saw in the case $k = 2$, if $k$ is even and $n$ is odd then
  %
  \[ \int_{-\infty}^\infty e^{\lambda i x^k} e^{-x^k} x^n = 0. \]
  %
  Thus we can actually improve the asymptotics to the existence of a sequence $\{ a_n \}$ such that
  %
  \[ I(\lambda) = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-2n/k} + O_{\phi,\psi,N} \left( 1 / \lambda^{(2N + 3)/k} \right). \]
\end{remark}

\begin{comment}

Changing variables then proves the result for general $k$'th order phases.

\begin{lemma}
  Let $\psi$ is a compactly supported and smooth amplitude, and $\phi'(x) \neq 0$ on the support of $\psi$, except at some point $x_0$ where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, with $\phi^{(k)}(x_0) \neq 0$, then there exists constants $\{ a_n \}$ depending on the derivatives of $\phi$ and $\psi$ at $x_0$, such that for each $N$,
  %
  \[ \int_{-\infty}^\infty e^{\lambda i \phi(x)} \psi(x)\; dx = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-n/k} + O_{\phi,\psi,N} \left( 1/\lambda^{(N+2)/k} \right). \]
\end{lemma}

\begin{lemma}
  Let $\psi$ is a compactly supported and smooth amplitude, and $\phi'(x) \neq 0$ on the support of $\psi$, except at some point $x_0$ where $\phi'(x_0) = \dots = \phi^{(k-1)}(x_0) = 0$, with $\phi^{(k)}(x_0) \neq 0$, then there exists constants $\{ a_n \}$ depending on the derivatives of $\phi$ and $\psi$ at $x_0$, such that for each $N$,
  %
  \[ \int_{-\infty}^\infty e^{\lambda i \phi(x)} \psi(x)\; dx = \lambda^{-1/k} \sum_{n = 0}^N a_n \lambda^{-n/k} + O_{\phi,\psi,N} \left( 1/\lambda^{(N+2)/k} \right). \]
\end{lemma}
\begin{proof}
  Without loss of generality, we may rescale our integral so that $\phi^{(k)}(x_0) = k!$. Then we can write $\phi(x) = x^k + x^{k+1} R(x)$, where $R(x)$ is a smooth function. A Taylor series approach tells us that
  %
  \[ e^{\lambda i \phi(x)} = e^{\lambda i x^k} \left[ \sum_{n = 0}^M \frac{(\lambda i x^{k+1} R(x))^n}{n!} + Q(x) \right], \]
  %
  where
  %
  \[ Q(x) = \frac{(i\lambda)^{M+1}}{(M+1)!} x^{(k+1)(M+1)} R(x)^{M+1} \int_0^1 e^{\lambda i x^{k+1} R(x) s} (1 - s)^M\; ds \]
  %
  For each $n$, we let
  %
  \[ I_n(\lambda) = \frac{(\lambda i)^n}{n!} \int e^{\lambda i x^k} R(x)^n x^{n(k+1)} \psi(x)\; dx, \]
  %
  and let
  %
  \[ J(\lambda) = \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} R(x)^{M+1} e^{\lambda i x^{k+1} R(x) s} (1 - s)^M \psi(x)\; ds\; dx. \]
  %
  Then
  %
  \[ I(\lambda) = I_1(\lambda) + \dots + I_M(\lambda) + \frac{(i\lambda)^{M+1}}{(M+1)!} J(\lambda), \]
  %
  and so it suffices to obtain asymptotics on each term separately. From the previous argument, we know there are are constants $\{ a_{nm} \}$ such that for each $M$,
  %
  \[ I_n(\lambda) = \lambda^{-1/k} \sum_{m = 1}^M a_{nm} \lambda^{n-m/k} + O_{\psi,R,k,n} \left( 1/ \lambda^{(M+2)/k} \right). \]
  %
  Moreover, we can write
  %
  \[ I_n(\lambda) = \int e^{\lambda i x^k} x^{n(k+1)} \psi_n(x)\; dx, \]
  %
  where $\psi_n(x) = R(x)^n \psi(x)$ is smooth. But then we know
  %
  \[ |I_n(\lambda)| \lesssim_{n,k,\psi,R} 1/\lambda^{n + (n+1)/k}. \]
  %
  In particular, this means that $a_{nm} = 0$ for $m \leq (2k+1)n$. Thus we conclude $I_n(\lambda)$ can be expanded in positive powers of $\lambda^{1/k}$, up to an error $O(1/\lambda^{(M+2)/k})$. If we split the integrand for $J(\lambda)$ using a bump function into values $x$ with $|x| \leq \varepsilon$ and values $|x| \geq \varepsilon$, bound the former by bringing in absolute values, bound the latter using integration by parts, and then optimizing over $\varepsilon$ yields

  To complete the argument, we show that for sufficiently large $M$, we can treat $J$ as an error term. If we define
  %
  \[ \psi_M(x,s) = \psi(x) (1 - s)^M R(x)^{M+1}, \]
  %
  then
  %
  \[ J(\lambda) = \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s)\; dx\; ds. \]
  %
  We introduce a bump function $\alpha$ such that $\alpha(x) = 1$ for $|x| \leq 1$, and vanishes outside for $|x| \geq 2$. For $\varepsilon > 0$, we write
  %
  \begin{align*}
    J(\lambda) &= \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s) \alpha(x/\varepsilon)\; dx\\
    &\ \ \ + \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi_M(x,s) (1 - \alpha(x/\varepsilon))\; dx.
  \end{align*}
  %
  The first integral is $O_{\psi,R,M}(\varepsilon^{(k+1)(M+1)+1})$. For the second, we employ an integration by parts in $x$. The value $e^{\lambda i x^k}$ is a fixed point of the differential operator $Df = f' / \lambda i x^{k-1}$, whose adjoint is
  %
  \[ D^* g = \frac{d}{dx} \left( \frac{g}{\lambda i x^{k-1}} \right). \]
  %
  For each $L$, there exists constants $c_n$ such that
  %
  \[ (D^*)^L g = \frac{1}{\lambda^L} \sum_{n = 0}^L \frac{c_n g^{(n)}}{x^{Lk - n}}. \]
  %
  If we write
  %
  \[ g_n(\lambda,x,s) = \frac{1}{x^{Lk-n}} \frac{d^n}{dx^n} \left\{ x^{(k+1)(M+1)} e^{\lambda i x^{k+1} R(x) s} \psi(x,s) (1 - \alpha(x/\varepsilon)) \right\}, \]
  %
  then our oscillatory integral is bounded by an implicit constant depending on $L$ and $k$, and
  %
  \[ \sum_{n = 0}^L \frac{1}{\lambda^L} \int_{-\infty}^\infty \int_0^1 e^{\lambda i x^k} g_n(x)\; dx. \]
  %
  Now $g_n$ has compact support depending on $\psi$, and vanishes for $|x| \leq \varepsilon$. For $|x| \geq \varepsilon$, we find that
  % \lambda \lesssim_{k,\phi} 1/\varepsilon
  \[ |g_n(\lambda,x,s)| \lesssim_{L,M,k,\alpha,\psi,n} \sum_{m = 0}^n \lambda^m \varepsilon^{m-n} x^{n-Lk+(k+1)(M+1) + km}. \]
  %
  Thus we conclude that for sufficiently large $L$
  %
  \[ |J(\lambda)| \lesssim_{\psi,R,M,L,k,\alpha} \varepsilon^{(k+1)(M+1) + 1} \left( 1 + \varepsilon^{- Lk} \sum_{m = 0}^L \lambda^{m-L} \varepsilon^{(k+1)m} \right). \]
  %
  TODO.
\end{proof}

\end{comment}

Let us now consider some examples of the method of stationary phase in one dimension.

\begin{example}
  The Bessel function of order $m$, denoted $J_m(r)$, is defined to be the oscillatory integral
  %
  \[ J_m(r) = \frac{1}{2\pi} \int_0^{2\pi} e^{i r \sin(\theta)} e^{-i m \theta} d\theta. \]
  %
  We want to use the method of stationary phase to determine the decay of $J_m(r)$ as $r \to \infty$. The amplitude is $\psi(\theta) = (1/2\pi) e^{-im \theta}$, and the phase is $\phi(\theta) = \sin(\theta)$. We note that the phase $\phi(\theta) = \sin(\theta)$ is stationary when $\theta = \pi/2$ and $\theta = 3\pi/2$, and that these stationary points are nondegenerate. Thus we might expect $|J_m(r)| = O_m(r^{-1/2})$. More precisely, we write $1 = \psi_1 + \psi_2 + \psi_3$, where $\psi_1$ is supported in a small neighbourhood of $\pi/2$, $\psi_2$ in a neighbourhood of $3\pi/2$, and $\psi_3$ is supported away from $\pi/2$ and $3\pi/2$. This oscillatory integral is defined over an integral, but the integrand is periodic, so an integration by parts verifies that since $\psi_3$ is supported away from stationary points, for any $N > 0$,
  %
  \[ \frac{1}{2\pi} \int_0^{2\pi} e^{i r \sin(\theta)} e^{-i m \theta} \psi_3(\theta)\; d\theta = O_N(r^{-N}). \]
  %
  Next, we verify using our formula for the stationary phase that
  %
  \begin{align*}
    \frac{1}{2\pi} \int & e^{i r \sin(\theta)} e^{-i m \theta} \psi_1(\theta)\; d\theta\\
    &= \left( \frac{2\pi}{-i \phi''(\pi/2)} \right)^{1/2} \cdot (1/2\pi) e^{i r \sin(\pi/2)} e^{-i m (\pi/2)} \cdot r^{-1/2} + O_m(r^{-3/2})\\
    &= (2\pi)^{-1/2} e^{i(r - m\pi/2 - \pi/4)} r^{-1/2} + O_m(r^{-3/2}).
  \end{align*}
  %
  Similarily,
  %
  \begin{align*}
    \frac{1}{2\pi} \int & e^{i r \sin(\theta)} e^{-i m \theta} \psi_2(\theta)\; d\theta\\
    &= \left( \frac{2\pi}{-i \phi''(3\pi/2)} \right)^{1/2} \cdot (1/2\pi) e^{i r \sin(3\pi/2)} e^{-i m (3\pi/2)} \cdot r^{-1/2} + O_m(r^{-3/2})\\
    &= (2\pi)^{-1/2} e^{-i(r - m\pi/2 - \pi/4)} r^{-1/2} + O_m(r^{-3/2}).
  \end{align*}
  %
  Summing up the three estimates, we conclude
  %
  \[ J_m(r) = (2/\pi r)^{1/2} \cos(r - m\pi/2 - \pi/4) + O_m(r^{-3/2}). \]
\end{example}

\begin{example}
  Consider the Airy function
  %
  \[ \text{Ai}(x) = \int_{-\infty}^\infty e^{i(x \xi + \xi^3/3)}\; d\xi, \]
  %
  which arises as a solution to the differential equation $y'' = xy$. Again, this integral is not defined absolutely. Nonetheless, for a large $N$, an integration by parts shows that for any finite interval $I$ containing only points $x$ with $|x| \geq N$,
  %
  \[ \int_I e^{i(x \xi + \xi^3/3)}\; d\xi = O(1/N), \]
  %
  where the implicit constant is independant of $I$. Thus we can interpret the integral as
  %
  \[ \lim_{n \to \infty} \int_{a_n}^{b_n} e^{i(x \xi + \xi^3/3)}\; d\xi, \]
  %
  where $\{ a_n \}$ and $\{ b_n \}$ are any sequences with $a_n \to -\infty$, $b_n \to \infty$.

  Now consider the phase $\phi(\xi) = x \xi + \xi^3/3$. Then $\phi'(\xi) = x + \xi^2$. When $x$ is negative, there are two stationary points. Thus we can rescale the integral, writing $\nu = x^{-1/2} \xi$, so that
  %
  \[ \text{Ai}(-x) = x^{1/2} \int_{-\infty}^\infty e^{i x^{3/2}(\nu^3/3 - \nu)}\; d\nu. \]
  %
  If we write $\phi_0(\nu) = \nu^3/3 - \nu$, then $\phi_0$ has two stationary points, at $\nu = \pm 1$. These stationary points are non-degenerate, so if we write $1 = \psi_1 + \psi_2 + \psi_3 + \psi_4$, where $\psi_1$ equal to one in a neighbourhood of $1$, $\psi_2$ equal to one in a neighbourhood of $-1$, and $\psi_3$ is supported in the region between $-1$ and $1$, and $\psi_4$ vanishes in all such regions, then we decompose $\text{Ai}(-x)$ as $I_1 + I_2 + I_3 + I_4$. Now the principle of stationary phase tells us that
  %
  \[ I_1 = \pi^{1/2} x^{-1/4} e^{i \pi/4} e^{-2i x^{3/2}/3} + O(x^{-1}) \]
  %
  and
  %
  \[ I_2 = \pi^{1/2} x^{-1/4} e^{-i\pi/4} e^{2i x^{3/2}/3} + O(x^{-1}). \]
  %
  Moreover, $I_3 = O_N(x^{-N})$ for all $N \geq 0$. It remains to show $I_4 = O(x^{-1})$. Indeed, an integration by parts shows that
  %
  \begin{align*}
    I_4 &= x^{1/2} \int_{-\infty}^\infty e^{i x^{3/2} \phi_0(\nu)} \psi_4(\nu)\; d\nu\\
    &= \frac{i}{x} \int_{-\infty}^\infty e^{i x^{3/2} \phi_0(\nu)} \frac{d}{d\nu} \left( \frac{\psi_4(\nu)}{\nu^2 - 1} \right)\; d\nu.
  \end{align*}
  %
  Taking in absolute values shows $|I_4| \lesssim 1/x$. Thus as $x \to \infty$,
  %
  \[ \text{Ai}(-x) = 2 \pi^{1/2} x^{-1/4} \cos((2/3) x^{3/2} - \pi/4) + O(1/x), \]
  %
  which gives the first order asymptotics of the integral.

  On the other hand, let us consider large positive $x$. Then the phase $\phi$ has no critical points, and we therefore expect very fast decay. To achieve this decay, we employ a contour shift, replacing the oscillatory integral with a different oscillatory integral which \emph{has} a stationary point, so we can obtain asymptotics here. If we write $\phi(z) = xz + z^3/3$, then $\phi'(z) = 0$ when $z = \pm i x^{1/2}$. A simple contour shift argument to the line $\RR + i x^{1/2}$ gives
  %
  \begin{align*}
    \text{Ai}(x) &= \int_{-\infty}^\infty e^{i \phi(\xi + ix^{1/2})}\; d\xi\\
    &= e^{-(2/3)x^{3/2}} \int_{-\infty}^\infty e^{-\xi^2 x^{1/2}} e^{i \xi^3/3}\; d\xi.
  \end{align*}
  %
  We have
  %
  \[ \int_{-\infty}^\infty e^{-\xi^2 x^{1/2}} e^{i \xi^3/3}\; d\xi \approx x^{-1/4} \int_{-\infty}^\infty e^{-\xi^2} e^{i x^{-3/4} \xi^3/3}\; d\xi. \]
  %
  Now a Taylor series shows
  %
  \[ e^{i x^{-3/4} \xi^3/3} = 1 + O(x^{-3/4} \xi^3/3), \]
  %
  so, plugging in, we conclude
  %
  \[ \text{Ai}(x) = \pi^{1/2} x^{-1/4} e^{-(2/3) x^{3/2}} + O(x^{-3/4} e^{-(2/3) x^{3/2}}). \]
  %
  Thus Airy's function decreases exponentially as $x \to \infty$.
\end{example}

\begin{example}
  Let us consider the integral quantities
  %
  \[ \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx \]
  %
  where to avoid technicalities we assume $0 \leq \gamma < 2$. These integral quantities are not defined absolutely, so we actually interpret this integral as
  %
  \[ \lim_{\varepsilon \to 0} \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx \]
  %
  If we write $\phi(x) = x \xi + 1/x$, then
  %
  \[ \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx = \int_0^1 e^{i\phi(x)} x^{-\gamma}\; dx. \]
  %
  For $0 < \varepsilon_1 < \varepsilon_2 < \varepsilon$, since $\phi'(x) = \xi - 1/x^2$, an easy integration by parts shows that for $\varepsilon \leq \xi^{-1/2}/2$,
  %
  \begin{equation} \label{riemannsingularityibp}
  \begin{aligned} 
    \int_{\varepsilon_1}^{\varepsilon_2} e^{i\phi(x)} x^{-\gamma}\; dx &= \frac{1}{i \xi} \int_{\varepsilon_1}^{\varepsilon_2} \frac{d}{dx} \left( e^{i \phi(x)} \right) \frac{x^{2-\gamma}}{x^2 - 1/\xi}\; dx\\
    &= \frac{-1}{i \xi} \int_{\varepsilon_1}^{\varepsilon_2} e^{i \phi(x)} \frac{d}{dx} \left( \frac{x^{2-\gamma}}{x^2 - 1/\xi} \right) + O(\varepsilon^{2-\gamma})\\
    &= O(\varepsilon^{2-\gamma}),
  \end{aligned}
  \end{equation}
  %
  where the constant is independent of $\xi$. This implies the limit we study certainly exist. We wish to prove an asymptotic formula for this integral as $\xi \to \infty$. If we write $\phi(x) = x \xi + 1/x$, then
  %
  \[ \int_0^1 e^{i x \xi} e^{i/x} x^{-\gamma}\; dx = \int_0^1 e^{i \phi(x)} x^{-\gamma}. \]
  %
  Since $\phi$ has a nondegenerate stationary point when $x = \xi^{-1/2}$, our heuristics might suggest that if the phase and amplitude were smooth at the origin, then as $\gamma \to \infty$,
  %
  \begin{align*}
    \int_0^1 e^{i\phi(x)} x^{-\gamma} &\approx \left( \frac{2\pi}{-i \phi''(\xi^{-1/2})} \right)^{1/2} e^{i\phi(\xi^{-1/2})} \xi^{\gamma/2}\\
    &= \pi^{1/2} e^{i(2 \xi^{1/2} + \pi/4)} \xi^{\gamma/2 - 3/4}.
  \end{align*}
  %
  We shall show that these heuristics continue to hold, up to an error of $O(\xi^{\gamma/2 - 1})$.

  In an attempt to isolate the critical point, we split the interval $[0,1]$ into three parts, $[0,0.5 \xi^{-1/2}]$, $[0.5 \xi^{-1/2},1.5 \xi^{-1/2}]$, and $[1.5 \xi^{-1/2},1]$, obtaining three integrals $I_1$, $I_2$, and $I_3$. The calculation \eqref{riemannsingularityibp} shows that $|I_1| \lesssim \xi^{\gamma/2 - 1}$, and thus is neglible to our asymptotic formula. To obtain a bound on $I_3$, we use the Van der Corput lemma, noting that $\phi'(x) = \xi - 1/x^2$ is monotone, and $|\phi'(x)| \gtrsim \xi$ for $x \geq 1.5 \xi^{-1/2}$. Thus we find $|I_1| \lesssim \xi^{-1}$, and thus is also neglible to our formula. Thus we are left with the trick part of calculating $I_2$ accurately. It will easiest to do this by renormalizing the integral, i.e. writing $y = \xi^{1/2} x$, and calculating
  %
  \[ I_2 = \int_{0.5 \xi^{-1/2}}^{1.5 \xi^{-1/2}} e^{i \phi(x)} x^{-\gamma}\; dx = \xi^{\gamma/2 - 1/2} \int_{0.5}^{1.5} e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma}\; dy. \]
  %
  We consider a smooth amplitude function $\psi(x)$ supported on the interior of $[0.5,1.5]$. Then since $y + 1/y$ is stationary at $y = 1$, but non-degenerate, we can write
  %
  \[ \int e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma} \psi(y)\; dy = \xi^{-1/4} \pi^{1/2} e^{i(2\xi^{1/2} + 1/4)} + O(\xi^{-1/2}), \]
  %
  from which we obtain our main term. On the other hand, we can apply the Van der Corput lemma to show that
  %
  \[ \int_{0.5}^{1.5} e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma} (1 - \psi(y))\; dy = \int e^{i \xi^{1/2}(y + 1/y)} y^{-\gamma} \psi(y)\; dy = O(\xi^{-1/2}). \]
  %
  Combining all these estimates gives the theorem.

  On the other hand, consider the integral
  %
  \[ I(\xi) = \int_0^1 e^{-i \xi x} e^{i/x} x^{-\gamma}\; dx = \int_0^1 e^{i \phi(x)} x^{-\gamma}, \]
  %
  where $\phi(x) = 1/x - \xi x$ is the phase. Then the phase has no critical points so we can assume that we can large decay for large $\xi$. We decompose the integral onto the intervals $[0,\xi^{-1/2}]$ and $[\xi^{-1/2},1]$, inducing the two quantities $I_1$ and $I_2$. Now applying the Van der Corput lemma to $I_2$ with $|\phi'(x)| = |1/x^2 + \xi| \geq \xi$ for $x \geq 0$, gives $|I_2| \lesssim \xi^{\gamma/2 - 1}$. On the other hand, renormalizing with $y = \xi^{1/2} x$, we have
  %
  \[ I_1 = \xi^{\gamma/2 - 1/2} \int_0^1 e^{i \xi^{1/2} (1/y - y)} y^{-\gamma}\; dy. \]
  %
  For each $n$, we note that for the phase $\phi_0(x) = 1/y - y$, for $1/2^{n+1} \leq y \leq 1/2^n$, we have $|\phi_0'(x)| \gtrsim 4^n$. Thus we can apply the Van der Corput lemma to conclude
  %
  \[ \left| \int_{1/2^{n+1}}^{1/2^n} e^{i \phi_0(x)} y^{-\gamma}\; dy \right| \lesssim \frac{2^{\gamma n}}{4^n \xi^{1/2}}. \]
  %
  Summing up over all $n \geq 0$, we conclude $|I_1| \lesssim \xi^{\gamma/2 - 1}$. Thus $|I(\xi)| \lesssim \xi^{\gamma/2 - 1}$.

  One way to interpret this asymptotic formula is through a \emph{Riemann singularity}, i.e. a tempered distribution $\Lambda$ supported on the half-life $x \geq 0$, that agrees with the oscillatory function $e^{i/x} x^{-\gamma}$ for small $x$, but is compactly supported and smooth away from the origin. We consider the case $0 \leq \gamma < 2$ for simplicity. Thus for Schwartz $f \in \mathcal{S}(\RR)$, we have
  %
  \[ \Lambda(f) = \lim_{\varepsilon \to 0^+} \int_\varepsilon^\infty f(x) e^{i/x} x^{-\gamma} \psi(x)\; dx, \]
  %
  where $\psi$ is smooth and compactly supported, and equals one in a neighbourhood of the origin. An easy integration by parts shows that for a fixed Schwartz $f$, and for $0 < \varepsilon_1 < \varepsilon_2 < \varepsilon$,
  %
  \[ \left| \int_{\varepsilon_1}^{\varepsilon_2} f(x) e^{i/x} x^{-\gamma}\; dx \right| = O\left(\varepsilon^{2-\gamma} \right), \]
  %
  where the implicit constants depend on upper bounds for $f$ and $f'$ in a neighbourhood of the origin. Thus we find $\Lambda(f)$ is well defined, and moreover, $\Lambda$ is a distribution of order one. Since $\Lambda$ is compactly supported, the Paley-Weiner theorem implies that $\widehat{\Lambda}$ is a distribution represented by a locally integrable function, and
  %
  \[ \widehat{\Lambda}(\xi) = \int_0^\infty e^{i/x} x^{-\gamma} \psi(x) e^{-2 \pi \xi i x}\; dx. \]
  %
  Our asymptotics under some small modifications tell us that if $\xi$ is large, then
  %
  \[ \widehat{\Lambda}(-\xi) = 2^{\gamma/2 - 3/4} \pi^{\gamma/2-1/2} e^{i(2^{3/2} \pi^{1/2} \xi^{1/2} + \pi/4)} \xi^{\gamma/2 - 3/4} + O(\xi^{\gamma/2 - 1}). \]
  %
  On the other hand,
  %
  \[ \widehat{\Lambda}(\xi) = O(\xi^{\gamma/2 - 1}), \]
  %
  so the Fourier transform of $\Lambda$ decays much faster to the right than to the left.
\end{example}

\section{Stationary Phase in Multiple Variables}

When we move from a single variable oscillatory integral to a multivariable oscillatory integrals. Thus we consider the oscillatory integral
%
\[ I(\lambda) = \int_{\RR^d} \psi(x) e^{\lambda i \phi(x)}\; dx. \]
%
for large $\lambda$. The method of stationary phase becomes significantly more complicated in this setting because the stationary points of the phase function are no longer necessarily isolated. In certain basic situations, however, we can obtain simple results.

\begin{theorem}
  Let $\phi$ and $\psi$ be smooth functions on $\RR^d$, with $\psi$ compactly supported. If $\nabla \phi$ is nowhere vanishing on the support of $\psi$, then for each $N$, $|I(\lambda)| \lesssim_N \lambda^{-N}$ for all $N$.
\end{theorem}

\begin{proof}
    Set $a = (\nabla \phi)/|\nabla \phi|^2$. Note that $\nabla e^{\lambda i \phi(x)} = (i\lambda) e^{\lambda i \phi(x)} \nabla \phi(x)$ is an eigenfunction of the differential operator $D$ defined such that
    %
    \[ Df(x) = \frac{a \cdot \nabla f}{i \lambda}. \]
    %
    The adjoint operator of $D$ is the operator $D^*$ defined by setting
    %
    \[ D^*f(x) = \frac{\nabla \cdot (af)}{-i\lambda}, \]
    %
    i.e. for any smooth $f$ and $g$, with one of these functions compactly supported,
    %
    \[ \int Df(x) g(x)\; dx = \int f(x) (D^*g)(x)\; dx. \]
    %
    Thus
    %
    \[ I(\lambda) = \int D^N(e^{i \lambda \phi(x)}) \psi(x)\; dx = \int e^{i \lambda \phi(x)} ((D^*)^N\psi)(x)\; dx. \]
    %
    Taking absolute values in the last integral gives that
    %
    \[ |I(\lambda)| \leq \int |(D^*)^N \psi(x)|\; dx \lesssim_{\phi,\psi,N} \frac{1}{\lambda^N}. \qedhere \]
\end{proof}

\begin{remark}
  The implicit constants for a fixed $N$ can be uniformly bounded given a uniform lower bound on $|\nabla \phi|$, and upper bounds on the derivatives of $\phi$ up to order $N+1$, on $\psi$ up to order $N$, and on the measure of the support of $\psi$.
\end{remark}

A tensorization argument establishes the result for a quadratic phase.

\begin{theorem}
  Let $A$ be an invertible $d \times d$ matrix, fix $x_0 \in \RR^d$, and consider the phase $\phi(x) = A(x - x_0) \cdot (x - x_0)$. Then for any compactly supported smooth amplitude $\psi$, there exists constants $\{ a_n \}$ depending only on the derivatives of $\psi$ at the origin, such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-d/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_N(1/\lambda^{N+d/2 +1}). \]
  %
  Moreover,
  %
  \[ a_0 = \frac{(2\pi)^{d/2} \psi(x_0)}{(-i \mu_1)^{1/2} \dots (-i \mu_d)}, \]
  %
  where $\mu_1, \dots, \mu_d$ are the eigenvalues of $A$.
\end{theorem}
\begin{proof}
  Suppose first that $\psi$ is a tensor product of $d$ compactly supported functions in $\RR$. The constant $a_0$ is invariant under affine changes of coordinates. Thus we may assume that $A$ is a diagonal matrix. But then the oscillatory integral splits into the product of single variable integrals, to which we can apply our one-dimensional asymptotics. Since the asymptotics here depend only on the support of $\psi$, and upper bounds on the magnitude of $\psi$ on derivatives up to order $2N + 4$. A density argument then shows the argument generalizes to any smooth $\psi$, with implicit constants depending on upper bounds on the measure of the support of $\psi$, and upper bounds on the derivative of $\psi$ of order up to $2N + (d + 4)$.
\end{proof}

Morse's theorem says that if $x_0$ is a non-degenerate critical point of a smooth function $\phi$, then there exists a coordinate system around $x_0$ and $a_1, \dots, a_d \in \{ \pm 1 \}$ such that, in this coordinate system,
%
\[ \phi(x_0 + t) = a_1 t_1^2 + \dots + a_d t_d^2. \]
%
In one dimension, the same is true if $x_0$ has a higher order critical point, but this does not generalize to higher dimensions, which reflects the lack of as nice a theory in this case. But in the case of functions with finitely many non-degenerate critical points, we can obtain nice asymptotics. Applying Morse's theorem gives the following theorem.

\begin{theorem}
  Let $\phi$ and $\psi$ be smooth functions, with $\psi$ compactly supported. Suppose $\phi$ has only finitely many critical points on the support of $\psi$, each of which being nondegenerate. Then there exists constants $\{ a_n \}$ depending only on finitely many derivatives of $\Phi$ and $\psi$ at the points $x_1, \dots, x_n$, such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-d/2} \sum_{n = 0}^N a_n \lambda^{-n} + O_N(1/\lambda^{N+d/2 +1}). \]
  %
  Moreover, if the critical points of $\psi$ are $x_1, \dots, x_m$, then
  %
  \[ a_0 = \sum_{k = 1}^m \frac{(2\pi)^{d/2} \psi(x_k)}{\prod_{l = 1}^m (-i \mu_l(x_k))^{1/2}}, \]
  %
  where $\mu_1(x_k), \dots, \mu_d(x_k)$ are the eigenvalues of the Hessian of $\phi$ at $x_k$.
\end{theorem}

\section{Surface Carried Measures}

Let us consider oscillatory integrals on a `curved' version of Euclidean space. One most basic example is the Fourier transform of the surface measure of the sphere, i.e.
%
\[ \widehat{\sigma}(\xi) = \int_{S^{d-1}} e^{-2 \pi i \xi x} d\sigma(x). \]
%
Studying the decay of this surface measure is of much interest to many problems in analysis. One can reduce the study of this Fourier transform to the study of Bessel functions, to which we have already developed an asymptotic theory.

\begin{theorem}
  If $\sigma$ is the surface measure on the sphere $S^{d-1}$, then
  %
  \[ \widehat{\sigma}(\xi) = \frac{2\pi \cdot J_{d/2 - 1}(2 \pi |\xi|)}{|\xi|^{d/2 - 1}}. \]
  %
  In particular,
  %
  \[ \widehat{\sigma}(\xi) = \frac{2 \cos(2\pi |\xi| - (d/2 - 1)(\pi/2) - \pi/4)}{|\xi|^{(d-1)/2}} + O_d(1/|\xi|^{(d+1)/2}). \]
\end{theorem}
\begin{proof}
  Since $\sigma$ is rotationally symmetric, so too is $\widehat{\sigma}$. In particular, we can apply Fubini's theorem to conclude that if $V_{d-2}$ is the surface area of the unit sphere in $\RR^{d-2}$, then
  %
  \begin{align*}
    \widehat{\sigma}(\xi) &= \int_{S^{d-1}} e^{-2 \pi |\xi| x_1} d\sigma(x)\\
    &= V_{d-2} \int_{-1}^1 e^{-2 \pi |\xi| t} (1 - t^2)^{d/2-1} dt.
  \end{align*}
  %
  Setting $r = 2 \pi |\xi|$ completes the argument.
\end{proof}

Since the multivariate stationary phase approach is essentially `coordinate independant', we can also generalize the approach to manifolds. If $M$ is a $d$ dimensional Riemmannian manifold, and $\phi$ and $\psi$ are complex-valued functions on the manifold, we can consider the oscillatory integral
%
\[ I(\lambda) = \int_M e^{\lambda i \phi(x)} \psi(x) d\sigma(x), \]
%
where $\sigma$ is the surface measure induced by the metric on $M$. If $\phi$ and $\psi$ are compactly supported, then this integral is well defined in the Lebesgue sense.

\begin{theorem}
  Suppose that $\psi$ is a compactly supported smooth amplitude on a Riemannian manifold $M$, $\phi$ is a smooth phase, and $\nabla \phi$ vanishes on at most finitely many points $x_1, \dots, x_m$ on the support of $\psi$, upon each of which the Hessian $H\phi$ is non-degenerate at each point. Then there exists constants $\{ a_n \}$ such that for each $N$,
  %
  \[ I(\lambda) = \lambda^{-d/2} \sum_{n = 0}^N a_n \lambda^{-n} + O(1/\lambda^{N + d/2 + 1}). \]
  %
  Moreover,
  %
  \[ a_0 = \sum_{k = 1}^m \frac{(2\pi)^{d/2} \psi(x_k)}{\prod_{l = 1}^m (-i \mu_l(x_k))^{1/2}}, \]
  %
  where $\mu_1, \dots, \mu_d$ are the eigenvalues of the Hessian $H\phi$.
\end{theorem}

The theorem is proved by a simple partition of unity approach which reduces to the Euclidean case. It has the following important corollary.

\begin{theorem}
  If a surface $\Sigma$ is a smooth submanifold of $\RR^{d+1}$, and has non-vanishing Gauss curvature, and if $\psi$ is a smooth, compactly supported function on $\Sigma$, then
    %
    \[ |\widehat{\psi \sigma}(\xi)| \lesssim_{\psi,\sigma} \frac{1}{|\xi|^{d/2}}, \]
    %
    where $\sigma$ is the surface measure of $\Sigma$.
\end{theorem}
\begin{proof}
  For each $\xi \in S^d$,
  %
  \[ I_\xi(\lambda) = \int_M e^{\lambda i \phi_\xi(x)} \psi(x)\; d\sigma, \]
  %
  where $\phi_\xi(x) = -2 \pi i \xi \cdot x$. The derivatives of $\phi_\xi$ of order $\leq N$ on $M$ are $O_N(1)$, independently of $\xi$. Similarily, $H_M \phi_\xi$ is uniformly non-degenerate, in the sense that the operator norm of $(H_M \phi_\xi)^{-1}(x)$ is $O(1)$, independently of $\xi$. Working with $\Sigma$ as a local graph, and then applying the curvature condition on $\Sigma$ implies that for each $\xi \in S^d$, $\phi_\xi$ has $O(1)$ stationary points on the support of $\psi$. There also exists a constant $r$ such that if $x$ does not lie in any ball of radius $r$ around a stationary point, then $|\nabla_M \phi_\xi| \gtrsim 1$. Moreover, the Hessian $H_M \phi_\xi$ is uniformly non-degenerate in the radius $r$ balls around the critical point, independently of $\xi$. Thus we can apply the last result to conclude
  %
  \[ I_\xi(\lambda) \lesssim \lambda^{-d/2}, \]
  %
  where the implicit constant is independent of $\xi$, because all the required derivatives are uniformly bounded.
\begin{comment}

  Working locally, since the support of $\mu$ is precompact, we may consider a finite partition of unity $\{ \psi_\alpha \}$ with respect to an open family of sets $\{ U_\alpha \}$ covering $U$, such that for each $\alpha$, there exists a transformation $T$ composed of a rotation, translation, and dilation such that if $B$ is the open unit ball, then there is a smooth function $u: B \to \RR$ with $\nabla u(0) = 0$, such that
  %
  \[ T(U_\alpha) = \left\{ (x,u(x)): x \in B \right\}. \]
  %
  The fact that $\Sigma$ has non-vanishing Gauss curvature implies that the Hessian of $u$ is non-zero at each point, so in particular we may assume that $\nabla u$ does not equal to zero anywhere else on $B$. The asymptotics of the Fourier transform of $\mu \psi_\alpha$ is the same as the Fourier transform of the measure $T_*(\mu \psi_\alpha)$, so we may assume without loss of generality that $U_\alpha$ takes the form $T(U_\alpha)$. Then
  %
  \[ d\sigma = (1 + |\nabla u|^2)^{1/2}\; dx^1 \dots dx^d, \]
  %
  which can be incorporated into $\psi_\alpha$. Thus it suffices to show that for each $\xi = (\xi_0, \xi_1) \in \RR^d$,
  %
  \[ \left| \int_B e^{-2 \pi i(\xi_0 \cdot x + \xi_1 u(x))} \psi(x)\; dx \right| \lesssim_{\psi,u} \frac{1}{(|\xi_0|^2 + \xi_1^2)^{d/4}}. \]
  %
  Let us fix $\xi \in S^d$, and consider the oscillatory integral
  %
  \[ I_\xi(\lambda) = \int_B e^{\lambda i \phi_\xi(x)} \psi(x)\; dx, \]
  %
  where
  %
  \[ \phi_\xi(x) = -2\pi \left( \xi_0 \cdot x + \xi_1 u(x) \right). \]
  %
  Note that
  %
  \[ \nabla \phi_\xi(x) = -2\pi(\xi_0 + \xi_1 \nabla u(x)) \]
  %
  The inverse function theorem combined with our curvature condition tells us that if we choose our neighbourhoods $U_\alpha$ small enough, the map $x \mapsto \nabla u(x)$ is a smooth diffeomorphisms on $B$. In particular, for each $\xi$, there is at most one $x \in B$ such that $\phi_\xi$ is stationary at $x$. Even without the curvature condition, we can conclude that for each $x$, there is at most one $\xi \in S^d$, up to a negation, such that $\phi_\xi$ is stationary at $x$.

  Because of the curvature condition, one can verify that for each $\xi \in \RR^d$, there are $O(1)$ stationary points for the phase $\phi_\xi$. Moreover, if 

  In particular, we conclude that for each $\xi$, there are $O(1)$ stationary points for the phase $\phi(\cdot | \xi)$ on the support of $\psi$.

  The curvature condition implies that, if we have chosen are neighbourhoods small enough, for each $\xi$ there is at most one $x \in B$ such $\phi(\cdot|\xi)$ is stationary at $x$.

  Then $\nabla_x \phi(x|\xi) = -2\pi( \xi_0 + \xi_1 \nabla u(x) )$. In particular, $\phi(\cdot|(0,1))$ has a stationary point at $0$. If we consider $D_x[\nabla_x \phi(x|\xi)] = -2\pi  \xi_1 H_x u(x)$, which is nonsingular by assumption in a neighbourhood of $(0,1)$. Thus there exists a relatively open set $V_\alpha \subset S^d$


  Applying the implicit function theorem, having chosen our sets $\psi_\alpha$ small enough, there exists a relatively open set $V_\alpha \subset S^d$ containing $(0,1)$ such that for each $\xi = (\xi_0,\xi_1) \in V_\alpha$, there is a unique $x(\xi) \in B$ such that $\nabla_x \phi(x(\xi)|\xi) = 0$

  such that for each $\xi \in \RR^d$ and $\alpha$, there is at most one point $x \in U_\alpha$ such that $\xi$ is orthogonal to $T_x(M)$. Moreover, we can find a relatively open subset $V_\alpha$ of $S^{d-1}$ such that for each $\xi \in V_\alpha$, there exists a unique $x \in U_\alpha$ such that $\xi$ is orthogonal to $T_x(M)$.

  we can write
  %
  \[ \widehat{\mu}(\xi) = \sum_\alpha \int e^{-2 \pi i \xi \cdot x} \psi_\alpha(x)\; d\mu. \]
  %


  $\Sigma$ is the smooth graph of a function $f: B \to \RR$, where $B$ is the closed unit ball in $\RR^d$, i.e.
  %
  \[ \Sigma = \{ (x,t) : x \in B, t = f(x) \}. \]
  %
  Then $d\sigma = (1 + |\nabla f|^2)^{1/2} dx^1 \dots dx^d$, and the fact that $\Sigma$ has non-vanishing Gauss curvature implies that the Hessian of $f$ is non-degenerate. It thus suffices to obtain a bound of the form
  %
  \[ \int e^{i (\xi \cdot x) + \eta f(x)} \psi(x)\; dx \lesssim_{\psi} \frac{1}{\sqrt{|\xi|^2 + \eta^2}}. \]
  %
  where $\psi$ is a compactly supported, smooth function on $B$. Fix $(\xi_0, \eta_0)$ such that $\xi_0^2 + \eta_0^2 = 1$, and consider the oscillatory integral
  %
  \[ I(\lambda) = \int_B e^{\lambda i (\xi_0 \cdot x) + \eta_0 f(x)} \psi(x)\; dx \]
  %
  This is an oscillatory integral with phase $\phi(x;\xi_0,\eta_0) = (\xi_0 \cdot x) + \eta_0 f(x)$.

  We are considering the oscillatory integral
  %
  \[ \int e^{-2 \pi i \xi x} d\Sigma(x). \]
  %
  If $\phi(x) = x \cdot \xi$. The nondegeneracy of the Hessian of $\phi$ on the support of $\mu$ corresponds precisely to the nonvanishing of the curvatures of $\Sigma$ on $\mu$. Then we may find a family of 
\end{comment}
\end{proof}

If $\Omega$ is a bounded open subset of $\RR^{d+1}$ whose boundary is a Riemannian manifold with non-zero Gaussian curvature at each point, then it's Fourier transform has decay one order better than the Fourier transform of it's boundary.

\begin{corollary}
  If $\Omega$ is a bounded open subset of $\RR^d$ whose boundary is a Riemannian manifold $\Sigma$ with non-zero Gaussian curvature at each point. If $I_\Omega$ is the indicator function on $\Omega$, then
  %
  \[ |\widehat{I_\Omega}(\xi)| \lesssim_\Omega |\xi|^{-d/2}. \]
\end{corollary}
\begin{proof}
  We have
  %
  \[ \widehat{I_\Omega}(\xi) = \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx \]
  % u div(V) dV = u (V . n) dS - Grad(u) . V dV
  % As long as V is smooth and div(V) is fine
  % If u = e^{-2 \pi i \xi . x}, Grad(u) = (-2\pi i \xi) e^{-2 \pi i \xi . x}
  % If V(x) = x_1
  %
  Then we can apply Stoke's theorem for each $1 \leq k \leq d+1$ to conclude
  %
  \[ \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx = \frac{(-1)^k}{2 \pi i \xi_k} \int_\Sigma e^{-2 \pi i \xi \cdot x} (dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n). \]
  %
  For each $k$, there is a smooth function $\psi_k$ such that
  %
  \[ dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n = \psi_k d\sigma. \]
  %
  Thus applying the last case, we find
  %
  \[ \left| \frac{(-1)^k}{2 \pi i \xi_k} \int_\Sigma e^{-2 \pi i \xi \cdot x} (dx^1 \wedge \dots \wedge \widehat{dx^k} \wedge \dots \wedge dx^n) \right| \lesssim \xi_k^{-1} |\xi|^{-(d-1)/2}. \]
  %
  At each point $\xi$, if we choose $\xi_k$ with the largest value, then $|\xi_k| \sim |\xi|$, so
  %
  \[ \left| \int_\Omega e^{-2 \pi i \xi \cdot x}\; dx \right| \lesssim |\xi|^{-(d+1)/2}. \qedhere \]
\end{proof}

The fact that curved surfaces have Fourier decay has many consequences in harmonic analysis.

\begin{example}
  If $M$ is a hypersurface in $\RR^d$, and $\psi$ is a smooth, compactly supported function on $M$, and $f$ is a smooth, compactly supported function on $\RR^d$, we can define a function $Af$ on $\RR^d$ by defining
  %
  \[ (Af)(y) = \int_M f(y - x) \psi(x)\; d\sigma(x). \]
  %
  We note that $Af$ is really the convolution of $f$ with $\psi \sigma$. Thus
  %
  \[ \widehat{Af}(\xi) = \widehat{f}(\xi) \widehat{\psi d\sigma}(\xi). \]
  %
  For each multi-index $\alpha$, the derivative $(Af)_\alpha$ is equal to
  %
  \[ \int_M f_\alpha(y-x) \psi(x)\; d\sigma(x) = f_\alpha * (\psi \sigma). \]
  %
  In particular, we have
  %
  \[ \widehat{(Af)_\alpha} = (2 \pi i \xi)^\alpha \widehat{f}(\xi) \widehat{\psi \sigma}(\xi). \]
  %
  Since we have shown
  %
  \[ |\widehat{\psi \sigma}(\xi)| \lesssim |\xi|^{-(d-1)/2}, \]
  %
  we conclude that if $|\alpha| \leq k$, where $k = (d-1)/2$,
  %
  \[ \| (Af)_\alpha \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)}. \]
  %
  In particular, this implies that $A$ extends to a unique bounded operator from $L^2(\RR^d)$ to $L^2_k(\RR^d)$, i.e. to a map such that for each $f \in L^2(\RR^d)$, $Af$ is a square integrable function which has square integrable weak derivatives of all orders less than or equal to $k$, and moreover, $\| (Af)_\alpha \|_{L^2(\RR^d)} \lesssim \| f \|_{L^2(\RR^d)}$ for all $|\alpha| \leq k$. Thus the operator $A$ is `smoothening', in a certain sense.

  The operator $A$ is obviously bounded from $L^1(\RR^d)$ to $L^1(\RR^d)$ and $L^\infty(\RR^d)$ to $L^\infty(\RR^d)$, purely from the fact that $\psi \sigma$ is a finite measure. Using curvature and some analytic interpolation, we will now also show that $A$ is bounded from $L^p(\RR^d)$ to $L^q(\RR^d)$, where $p = (d+1)/d$, and $q = d+1$. Interpolation thus yields a number of intermediate estimates. The trick here is to obtain an $(L^1,L^\infty)$ bound for an `improved' version of $A$, and an $(L^2,L^2)$ bound for a `worsened' version of $A$. Interpolating between these two results gives a bound for precisely $A$. It suffices to prove this bound `locally' on $M$, since we can then sum up these bounds, so we may assume that $M$ is given as the graph of some function, i.e. there exists $u$ such that
  %
  \[ M = \{ (x,u(x)):  \} \]


  For each $s$, we write $A_sf = K_s * f$, where
  %
  \[ K_s(x) = \gamma_s |x_d - \phi(x')|_+^{s-1} \psi_0(x). \]
  %
  Here $\gamma_s = s \dots (s + N) e^{s^2}$, where $N$ is some large parameter to be fixed in a moment. The $e^{s^2}$ parameter is to mitigate the growth of $\gamma_s$ as $|\text{Im}(s)| \to \infty$, which allows us to interpolate. The quantity $|u|_+^{s-1}$ is equal to $u^{s-1}$ where $u > 0$, and is equal to 0 when $u \leq 0$. And $\psi_0(x) = \psi(x) (1 + |\nabla_{x'} \phi(x')|^2)^{1/2}$.
\end{example}





\section{Restriction Theorems}

If $f \in L^p(\RR^n)$, then the Hausdorff Young theorem says that $\widehat{f}$ is a function in $L^q(\RR^n)$, where $q$ is the dual of $p$. If $f \in L^1(\RR^n)$, then $\smash{\widehat{f}}$ is actually continuous, so you can meaningfully discuss the behaviour of the Fourier transform when restricted to low dimensional hypersurfaces, for instance, on a sphere of a fixed radius. However, in general $\widehat{f}$ will only be defined almost everywhere, and so it is unclear whether one can form a well defined restriction of the Fourier transform.

The general situation is as follows. If $\mu$ is a measure carried on a compact surface $M$, for a fixed $p$, does there exist an estimate 
%
\[ \| \widehat{f} \|_{L^q(M,\mu)} \lesssim \| f \|_{L^p(\RR^n)} \]
%
for Schwartz functions $f$. If this is true, we can apply a density argument to show that the restriction operator $\smash{R(f) = \widehat{f}|_M}$ uniquely extends to a well defined continuous linear operator from $L^p(\RR^n)$ to $L^q(M,\mu)$.

We begin by determining a duality result to the restriction calculation. Assuming our functions are suitably regular, we calculate
%
\begin{align*}
    \int_M (Rf)(\xi) \overline{g(\xi)}\; d\mu(\xi) &= \int_M \left( \int_{\RR^n} f(x) e(- \xi \cdot x)\; dx \right) \overline{g(\xi)}\; d\mu(\xi)\\
    &= \int_{\RR^n} f(x) \overline{\int_M g(\xi) e(\xi \cdot x)\; d\mu(\xi)}\; dx 
\end{align*}
%
which implies the formal adjoint of the map $R$ is the {\bf extension operator}
%
\[ (R^* f)(x) = \int_M e(\xi \cdot x) f(\xi) d\mu(\xi) \]
%
which extends a function in frequency space supported on $M$ to a function on the entirety of phase space. By duality properties, $R$ is continuous as an operator from $L^p(\RR^n)$ to $L^q(M,\mu)$ if and only if $R^*$ is continuous as an operator from $L^{q^*}(M,\mu)$ to $L^{p^*}(\RR^n)$. We also calculate
%
\[ ((R^* R)f)(x) = \int_{\RR^n} \left( \int_M e(\xi \cdot (x-y))\; d\mu(\xi) \right) f(y)\; dy = \left( f * \widecheck{\mu} \right)(x) \]
%
So if $R$ is $(p,2)$ continuous, $R^*$ is $(2,p^*)$ continuous, and so $R^*R$ is $(p,p^*)$ continuous. Conversely, if we know that $R^*R$ is $(p,p^*)$ continuous, then we find that for $f \in L^p(\RR^n)$, H\"{o}lder's inequality implies
%
\[ \| Rf \|_{L^2(M,\mu)}^2 = (Rf,Rf)_M = ((R^* R)f, f)_{\RR^d} \leq \| R^*R \|_{p \to p^*} \| f \|_p^2 \]
%
and so we conclude that $\| R \|_{p \to 2} \leq \sqrt{\| R^* R\|_{p \to p^*}}$.

We now prove that $R$ is $(2n+2/n+3, 2)$ continuous, assuming that $M$ has non-zero Gaussian curvature at each point. The previous paragram implies that it suffices to show that it is enough to show that $R^*R$ is $(p,p^*)$ continuous, where $p = (2n+2)/(n+3)$ and $p^* = (2n+2)/(n-1)$. Since
%
\[ (R^*R)(f) = f * \widecheck{\mu} \]
%
We shall verify this using Stein's interpolation theorem. Consider the family of kernels $k_s$, where $\smash{k_s = \widecheck{K_s}}$, and $K_s = \gamma_s |x_n - \varphi(x')|^{s-1}_+ \varphi_0(x)$, where $\gamma_s = s(s+1) \dots (s + N) e^{s^2}$
