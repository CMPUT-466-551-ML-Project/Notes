\input{../../style.tex}

\title{Harmonic Analysis}
\author{Jacob Denson}

\begin{document}

\pagenumbering{gobble}
\maketitle
\tableofcontents
\pagenumbering{arabic}

\part{Classical Fourier Analysis}

Deep mathematical knowledge often arises hand in hand with the characterization of symmetry. Nowhere is this more clear than in the foundations of harmonic analysis, where we attempt to understand mathematical `signals' by the `frequencies' from which they are composed. In the mid 18th century, problems in mathematical physics led D. Bernoulli, D'Alembert, Lagrange, and Euler to consider $2 \pi$ periodic functions representable as a trigonometric series
%
\[ f(t) = A + \sum_{m = 1}^\infty B_n \cos(mt) + C_n \sin(mt). \]
%
In his book, Th\'{e}orie Analytique de la Chaleur, published in 1811, Joseph Fourier had the audacity to announce that {\it all} functions were representable in this form, and used it to solve linear partial differential equations in physics. His conviction is the reason the classical theory of harmonic analysis is often named Fourier analysis, where we analyze the degree to which Fourier's proclamation holds, as well as it's paired statement on the real line, that a function $f$ on the real line can be written as
%
\[ f(t) = \int_{-\infty}^\infty A(\xi) \cos(\xi t) + B(\xi) \sin(\xi t)\; d\xi. \]
%
for some functions $A$ and $B$.

In the 1820s, Poisson, Cauchy, and Dirichlet all attempted to form rigorous proofs that `Fourier summation' holds for all functions. Their work is responsible for most of the modern subject of analysis we know today. And in order to interpret the validity of Fourier summation, we will need to utilize all the convergence techniques developed during this time. Under pointwise convergence, the representation of a function by Fourier series need not be unique. Uniform convergence is useful, but a function is not uniformly summable for all functions, even if they are continuous! This means we must introduce more subtle methods to measure convergence.

\chapter{Introduction}

The classic oscillatory functions are the trigonometric ones, given by
%
\[ f(t) = A \cos(st) + B \sin(st) = C \cos(st + \phi). \]
%
We have names for some of these parameters:
%
\begin{itemize}
    \item $\phi$ is the \emph{phase} of the oscillation.
    \item $C$ is the \emph{amplitude}.
    \item $s/2\pi$ is the \emph{frequency} of the oscillation.
\end{itemize}
%
Fourier analysis is the topic of understanding the representations of a function as an analytical combination of these functions. In the discrete, periodic setting, we fix a $2\pi$ periodic function $f: \mathbf{R} \to \mathbf{C}$, and try and find coefficients $\{ A_m \}$ and $\{ B_m \}$ such that
%
\[ f(t) \sim C + \sum_{m = 1}^\infty A_m \cos(mt) + B_m \sin(mt). \]
%
In the continuous setting, we fix a function $f: \mathbf{R} \to \mathbf{C}$, trying to find values $A(s)$ and $B(s)$ such that
%
\[ f(t) \sim C + \int_0^\infty A(s) \cos(st) + B(s) \sin(st)\; ds. \]
%
The main contribution of Fourier was a method to formally find a reliable choice of $A(s)$ and $B(s)$, $A_m$ and $B_m$, which represents $f$. This choice is given by the \emph{Fourier transform} of $f$ in the continuous case, and the \emph{Fourier series} in the discrete case.

\section{Obtaining the Fourier Coefficients}

A \emph{formal trigonometric series} is a formal sum of the form
%
\[ C + \sum_{m = 1}^\infty A_m \cos(mt) + B_m \sin(mt). \]
%
Our goal is to find $\{ A_m \}$, $\{ B_m \}$, and $C$ which `represents' a given function $f$. In particular, we say a $2\pi$ periodic function $f$ \emph{admits a trigonometric expansion} if there is a series such that for each $t \in \mathbf{R}$,
%
\[ f(t) = C + \sum_{m = 1}^\infty A_m \cos(mt) + B_m \sin(mt). \]
%
It is a \emph{very difficult question} to characterize which functions $f$ admit a trigonometric expansion. Nonetheless, in the next chapter we will show that all differentiable functions have a trigonometric expansion, in terms of the Fourier series we will define.

\section{Orthogonality}

The key technique Fourier realized could be used to come up with a canonical trigonometric series for a function is \emph{orthogonality}. Note that the various frequencies of sine functions are orthogonal to one another, in the sense that
%
\[ \int_{-\pi}^\pi \sin(mt) \sin(nt) = \int_{-\pi}^\pi \cos(mt) \cos(nt) = \begin{cases} 0 & : m \neq n, \\ \pi & : m = n. \end{cases} \]
%
and for any $m$ and $n$,
%
\[ \int_{-\pi}^\pi \sin(mt) \cos(nt) = 0. \]
%
This means that for a finite trigonometric sum
%
\[ f(t) = C + \sum_{m = 1}^N A_m \cos(mt) + B_m \sin(mt), \]
%
we have
%
\[ C = \frac{1}{2\pi} \int_{-\pi}^\pi f(t)\; dt, \]
\[ A_m = \frac{1}{\pi} \int_{-\pi}^\pi f(t) \cos(mt)\; dt, \quad\text{and}\quad B_m = \frac{1}{\pi} \int_{-\pi}^\pi f(t) \sin(mt)\; dt. \]
%
These values can be defined even if $f$ is not a trigonometric polynomial. Thus given \emph{any} $2\pi$ periodic function $f$, a reasonable candidate for the coefficients is given by the values $A_m$, $B_m$, and $C$ above.

There is an additional choice of oscillatory functions, which replaces the sine and cosine with a single family of trigonometric functions. Given an integer $m$, we consider the $2\pi$ periodic function complex-valued function $e_m(t) = e^{mit}$. Applying orthogonality again, we find
%
\[ \frac{1}{2\pi} \int_{-\pi}^\pi e_n(t) e_m(-t)\; dt = \frac{1}{2\pi} \int_{-\pi}^\pi e_{n-m}(t) = \begin{cases} 0 & : m \neq n, \\ 1 & : m = n. \end{cases}  \]
%
Thus a natural choice of an expansion
%
\[ f(t) \sim \sum_{m \in \mathbf{Z}} C_m e^{mit}, \]
%
is given by
%
\[ C_m = \frac{1}{2\pi} \int_{-\pi}^\pi f(t) e_m(-t)\; dt. \]
%
Euler's formula $e^{mit} = \cos(mt) + i \sin(mt)$ shows this is the same as the Fourier expansion in sines and cosines. Thus the values $\{ A_m, B_m, C : m \geq 0 \}$ can be recovered from the values of $\{ C_m : m \in \mathbf{Z} \}$. Because of it's elegance, unifying the three families of coefficients, the expansion by complex exponentials is the most standard in modern Fourier analysis.

To summarize, we have shown a $2 \pi$ periodic function $f: \mathbf{R} \to \mathbf{C}$ gives rise to a formal trigonometric series
%
\[ \sum_{m \in \mathbf{Z}} C_m e_m(t). \]
%
Because we will be concentrating on the values $C_m$, it is worth reserving a special notation for them. Given a function $f$, we define the \emph{Fourier coefficients}
%
\[ \widehat{f}(m) = (\mathcal{F} f)(m) = C_m = \frac{1}{2\pi} \int_{-\pi}^\pi f(t) e_m(-t)\; dt. \]
%
The Fourier series representation in terms of complex exponentials will be our choice throughout the rest of these notes. No deep knowledge of the complex numbers is used here. For most purposes, the exponential is just a simple way to represent sums of sines and cosines.

\section{The Fourier Transform}

For a general function $f: \mathbf{R} \to \mathbf{C}$, we cannot \emph{just} on orthogonality, because the functions $\sin(mx)$ are not integrable on the entirety of $\mathbf{R}$. Nonetheless, we can consider the functions $g_N: [-\pi,\pi] \to \mathbf{C}$ by setting $g_N(t) = f(Nt)$, then for $|t| \leq N \pi$, we find
%
\begin{align*}
    f(t) &= g_N(t/N)\\
    &\sim \sum_{m \in \mathbf{Z}} \widehat{g_N}(m) e^{(m/N) it}\\
    &= \frac{1}{2\pi} \sum_{m \in \mathbf{Z}} \left( \int_{-\pi}^\pi f(Ns) e^{-mis}\; ds \right) e^{(m/N) it}\\
    &= \sum_{m \in \mathbf{Z}} \frac{1}{2\pi N} \left( \int_{-\pi N}^{\pi N} f(s) e^{-(m/N)is}\; ds \right) e^{(m/N)it}.
\end{align*}
%
If we take $N \to \infty$, the exterior sum operates like a Riemann sum, and the interior integral becomes unbounded, so we find that, in a sense,
%
\[ f(t) \sim \frac{1}{2\pi} \int_{-\infty}^\infty \left( \int_{-\infty}^\infty f(s) e^{-\xi is}\; ds \right) e^{\xi i t}\; d\xi. \]
%
The interior is the \emph{Fourier transform} of the function $f$, denoted
%
\[ \widehat{f}(\xi) = (\mathcal{F} f)(\xi) = \int_{-\infty}^\infty f(s) e^{- \xi is}\; ds. \]
%
Thus the resultant \emph{Fourier inversion formula} takes the form
%
\[ f(t) \sim \frac{1}{2\pi} \int_{-\infty}^\infty \widehat{f}(\xi) e^{\xi i s}\; ds. \]
%
As the \emph{limit} of a discrete series defined in terms of orthogonality, the Fourier transform possesses many of the same properties at the Fourier series. But the limit does cause technical issues which are not present in the case of Fourier series, and so we begin by concentrating on the Fourier series.

%
%\begin{example}
%    This method can be used to find all harmonic functions $f$ on a rectangle $[0,\pi] \times [0,1]$, such that $f(0,y) = f(\pi,y) = 0$. Let us first attempt to find all separable solutions $f(x,y) = u(x) v(y)$. Then the equations defining harmonic functions tell us that
%    %
%    \[ u''v + v''u = 0 \]
%    %
%    or
%    %
%    \[ \frac{u''}{u} = - \frac{v''}{v} = - \lambda^2 \]
%    %
%    (we assume the constant factor is negative, since the constraints on $u$ would force $f$ to be trivial otherwise). Then we have
%    %
%    \[ u'' = - \lambda^2 u \]
%    %
%    so $u(x) = A \cos(\lambda x) + B \sin(\lambda x)$. The constraints that $u(0) = u(\pi) = 0$ force $A = 0$, and $\lambda \in \mathbf{Z}$. We may similarily solve the equation
%    %
%    \[ v'' = \lambda^2 v \]
%    %
%    to conclude $v(y) = M e^{\lambda y} + N e^{- \lambda y}$, so we obtain the solution set
%    %
%    \[ f(x,y) = \sin(n x) (Ae^{n y} + Be^{-ny}) \]
%    %
%    where $n \in \mathbf{Z}$, $A,B \in \RR$.

%    Now suppose we can write
%    %
%    \[ f(x,y) = \sum_{n = -\infty}^\infty \sin(nx) (A_n e^{ny} + B_n e^{-ny}) \]
%    %
%    Then
%    %
%    \[ f_0(x) = \sum_{n = -\infty}^\infty (A_n + B_n) \sin(nx) \]
%    \[ f_1(x) = \sum_{n = -\infty}^\infty (A_n e^n + B_n e^{-n}) \sin(nx) \]
%    %
%    So if $\widehat{f_0}$ and $\widehat{f_1}$ denote the sine coefficients of $f_0$ and $f_1$, then
%    %
%    \[ A_n + B_n = \widehat{f_0}(n)\ \ \ \ \ A_n e^n + B_n e^{-n} = \widehat{f_1}(n) \]
%    %
%    \[ A_n = \frac{\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}}{e^{n} - e^{-n}} \]
%    %
%    \[ B_n = \widehat{f_0}(n) - \frac{\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}}{e^{n} - e^{-n}} = \frac{e^n \widehat{f_0}(n) - \widehat{f_1}(n)}{e^n - e^{-n}} \]
%    %
%    Thus
%    %
%    \begin{align*}
%        f(x,y) &= \sum_{n = -\infty}^\infty \sin(nx) \left( \frac{(\widehat{f_1}(n) - \widehat{f_0}(n) e^{-n}) e^{ny} + (e^n \widehat{f_0}(n) - \widehat{f_1}(n)) e^{-ny}}{e^n - e^{-n}} \right)\\
%        &= \sum_{n = -\infty}^\infty \frac{\sin(nx)}{e^n - e^{-n}} [(e^{n(1-y)} - e^{n(y-1)}) \widehat{f_0}(n) + (e^{ny} - e^{-ny}) \widehat{f_1}(n)]\\
%        &= \sum_{n = -\infty}^\infty \left( \frac{\sinh n(1-y)}{\sinh n} \widehat{f_0}(n) + \frac{\sinh ny}{\sinh n} \widehat{f_1}(n) \right) \sin(nx)
%    \end{align*}
%\end{example}

%
%First, define the circle group $\mathbf{T}$ to be the set of complex numbers $z$ with $|z| = 1$. Functions from $\mathbf{T}$ to $\RR$ naturally correspond to $2 \pi$-periodic functions; given $g: \mathbf{T} \to \RR$, the correspondence is given by the equation $f(t) = g(e^{it})$. Thus, when defining $2\pi$ periodic functions, we shall make no distinction between a function `defined in terms of $t$' and a function `defined in terms of $z$', after making the explicit identification $z = e^{it}$. Then an expansion of the form
%
%\[ f(t) = \sum_{k = 0}^\infty A_k \cos(kt) + \sum B_k \sin(kt) \]
%
%leads to an expansion
%
%\begin{align*}
%    f(z) &= \sum_{k = 0}^\infty A_k \Re[z^k] + B_k \Im[z^k]\\
%    &= \sum_{k = 0}^\infty A_k \left( \frac{z^k + z^{-k}}{2} \right) - i B_k \left( \frac{z^k - z^{-k}}{2} \right) = \sum_{k = -\infty}^\infty C_k z^k
%\end{align*}
%
%so a Fourier expansion on $[0,2\pi]$ is really just a power series expansion on the circle in disguise.
%
%Thus expanding a real-valued function in the exponentials $e_n(t) = e^{nit}$ is the same as expanding the function in terms of sines and cosines. The complex exponentials $e_n$ have the same orthogonality properties as $\sin$ and $\cos$, so given a function $f$, the coefficients $C_n$ can be found by the expansion
%
%\[ C_n = \frac{1}{2\pi} \int_{-\pi}^\pi f(t) e_n(-t) dt \]

\section{Basic Properties of Fourier Series}

One of the most important properties of the Fourier series is that the coefficients are controlled by reasonable transformations. A basic, but unappreciated property of the Fourier transform is \emph{linearity}: For any two functions $f$ and $g$,
%
\[ \widehat{f+g} = \widehat{f} + \widehat{g}. \]
%
Linearity is \emph{essential} to most methods in this book, and the field of non-linear functionals still has many fundamental underanswered problems. Fourier series are also stable under various other transformations which occur in analysis, which makes the transform useful. We summarize these properties here:
%
\begin{itemize}
    \item If we define $f^*(x) = \overline{f(x)}$, then $\widehat{f^*}(n) = \overline{\widehat{f}(-n)}$.

    \item If $f$ is real-valued, then
    %
    \[ \widehat{f}(-n) = \overline{\widehat{f}(n)}. \]
    %
    Formally, if $f$ is periodic, and $\widehat{f}(m) = A_m + i B_m$, then
    %
    \begin{align*}
        f(t) &\sim \widehat{f}(0) + \sum_{m = 1}^\infty \widehat{f}(n) e_n(t) + \overline{\widehat{f}(n) e_n(t)}\\
        &= \widehat{f}(0) + \sum_{m = 1}^\infty 2 \text{Re}(\widehat{f}(n) e_n(t))\\
        &= \widehat{f}(0) + \sum_{m = 1}^\infty (2A_m) \cos(mt) + (-2B_m) \sin(mt).
    \end{align*}
    %
    If $\widehat{f}(\xi) = A(\xi) + i B(\xi)$, then
    %
    \begin{align*}
        f(t) &\sim \int_0^\infty \widehat{f}(\xi) e^{\xi i t} + \overline{\widehat{f}(\xi) e^{\xi i t}}\\
        &= \int_0^\infty [(2A(\xi)) \cos(\xi t) + (-2 B(\xi)) \sin(\xi t)]\; d\xi.
    \end{align*}
    %
    Thus we get a real-coefficient expansion in sines and cosines.

    \item Define the translation and frequency modulation operators by
    %
    \[ (T_s f)(t) = f(t-s) \quad\text{and}\quad (M_\xi f)(s) = e_\xi(s) f(s). \]
    %
    Then we have
    %
    \[ \widehat{T_s f} = M_{-s} \widehat{f} \quad\text{and}\quad \widehat{M_\xi f} = T_\xi \widehat{f}. \]
    %
    Thus a translation in the spatial domain corresponds to a modulation in the frequency domain, and vice versa. One can see this using the Fourier summation formula, by the formal calculation
    %
    \[ (T_s f)(t) = \sum_{n \in \mathbf{Z}} A_n e_n(t-s) = \sum_{n \in \mathbf{Z}} (A_n e_n(-s)) e_n(t), \]
    \[ (M_s f)(t) = e_s(t) \sum_{n \in \mathbf{Z}} A_n e_n(t) = \sum_{n \in \mathbf{Z}} A_n e_{n+s}(t) = \sum_{n \in \mathbf{Z}} A_{n - s} e_n(t), \]
    %
    and correspondingly, for the Fourier inversion formula.

    \item If $f$ is odd, then $\widehat{f}$ is odd, so formally we have a sine expansion
    %
    \[ f(t) \sim \sum_{m = 1}^\infty \widehat{f}(m) [e_m(t) - e_{-m}(t)] = 2i \sum_{m = 1}^\infty \widehat{f}(m) \sin(mt). \]

    \item If $f$ is even, then $\widehat{f}(-n) = \widehat{f}(n)$, so formally,
    %
    \[ f(t) \sim \widehat{f}(0) + \sum_{m = 1}^\infty \widehat{f}(m) [e_m(t) + e_{-m}(t)] = \widehat{f}(0) + 2 \sum_{m = 1}^\infty \widehat{f}(m) \cos(mt). \]

    \item If $f$ has a derivative $f'$, then for periodic $f$, $\mathcal{F}(f')(n) = in \widehat{f}(n)$, and for nonperiodic $f$, $\mathcal{F}(f')(\xi) = i\xi \widehat{f}(\xi)$. A formal calculation using the Fourier summation formula hints at this, by letting
    %
    \[ \frac{d}{dt} \sum_{n = -\infty}^\infty A_n e_n(t) = \sum_{n = -\infty}^\infty A_n \frac{de_n(t)}{dt} = \sum_{n = -\infty}^\infty (ni A_n) e_n(t). \]
\end{itemize}

All but the last relation can be proved by easy exercises in manipulating periodic integrals, when $f$ is a $2\pi$ periodic measurable function with
%
\[ \int_{-\pi}^\pi |f(x)|\; dx < \infty. \]
%
The space of all such functions will be denoted by $L^1(\mathbf{T})$, which is a Banach space under the norm
%
\[ \| f \|_{L^1(\mathbf{T})} = \frac{1}{2\pi} \int_{-\pi}^\pi |f(x)|\; dx. \]
%
The latter property involving the derivative of $f$ holds by an easy integration by parts. This proof therefore holds whenever $f$ has a weak derivative in $L^1(\mathbf{T})$.

\section{Examples of Expansions}

Before we get to the real work, let's start by computing some Fourier series, to use as examples. We also illustrate the convergence properties of these series, which we shall look at in more detail later.

\begin{example}
    Consider the function $f: [0,\pi] \to \RR$ defined by $f(x) = x(\pi - x)$. Then a series of integration by parts gives that
    %
    \[ \int x(\pi - x) \sin(nx) = \frac{x(\pi - x) \cos(nx)}{n} + \frac{(\pi - 2x) \sin(nx)}{n^2} - \frac{2\cos(nx)}{n^3}. \]
    %
    Thus
    %
    \[ \frac{2}{\pi} \int_0^\pi x(\pi - x) \sin(nx) = \frac{4(1 - \cos(n\pi))}{n^3} = \begin{cases} \frac{8}{\pi n^3} & n\ \text{odd}, \\ 0 & n\ \text{even}. \end{cases}  \]
    %
    Thus we have a formal representation
    %
    \[ f(x) = \sum_{n\ \text{odd}} \frac{8}{\pi n^3} \sin(nx). \]
    %
    This sum converges absolutely and uniformly for $x \in [0,\pi]$. If we extend the domain of $f$ to $[-\pi,\pi]$ by making $f$ odd, then
    %
    \[ \widehat{f}(n) = \begin{cases} \frac{4}{\pi i n^3} & : n\ \text{odd}, \\ 0 & : n\ \text{even}. \end{cases} \]
    %
    In this case, we still have
    %
    \[ f(x) = \sum_{\substack{n\ \text{odd}\\ n > 0}} \frac{4}{\pi i n^3} [e_n(x) - e_n(-x)] = \sum_{n\ \text{odd}} \frac{8}{\pi n^3} \sin(nx). \]
    %
    This sum converges absolutely and uniformly on the entire real line.
\end{example}

\begin{example}
    The tent function
    %
    \[ f(x) = \begin{cases} 1 - \frac{|x|}{\delta} & : |x| < \delta, \\ 0 & : |x| \geq \delta. \end{cases} \]
    %
    is even, and therefore has a purely real Fourier expansion
    %
    \[ \widehat{f}(0) = \frac{\delta}{2\pi},\quad\widehat{f}(n) = \frac{1 - \cos(n\delta)}{\delta \pi n^2}. \]
    %
    Thus we obtain an expansion
    %
    \[ f(x) = \frac{\delta}{2\pi} + \sum_{n \neq 0} \frac{1 - \cos(n\delta)}{\delta \pi n^2} e_n(x) = \frac{\delta}{2 \pi} + 2 \sum_{n = 1}^\infty \frac{1 - \cos(n\delta)}{\delta \pi n^2} \cos(nx). \]
    %
    This sum also converges absolutely and uniformly.
\end{example}

\begin{example}
    Consider the characteristic function
    %
    \[ \chi_{(a,b)}(x) = \begin{cases} 1 & : x \in (a,b), \\ 0 & : x \not \in (a,b). \end{cases} \]
    %
    Then
    %
    \[ \widehat{\chi}_{(a,b)}(n) = \frac{1}{2\pi} \int_a^b e_n(-x) = \frac{e_n(-a) - e_n(-b)}{2\pi i n}. \]
    %
    Hence we may write
    %
    \begin{align*}
        \chi_{(a,b)}(x) &= \frac{b-a}{2\pi} + \sum_{n \neq 0} \frac{e_n(-a) - e_n(-b)}{2 \pi i n} e_n(x)\\
        &= \frac{b-a}{2\pi} + \sum_{n = 1}^\infty \frac{\sin(nb) - \sin(na)}{\pi n} \cos(nx) + \frac{\cos(na) - \cos(nb)}{\pi n} \sin(nx).
    \end{align*}
    %
    This sum does not converge absolutely for any value of $x$ (except when $a$ and $b$ are chosen trivially). To see this, note that
    %
    \[ \left|\frac{e_n(-b) - e_n(-a)}{2 \pi n}\right| = \left| \frac{1 - e_n(b-a)}{2 \pi n} \right| \geq \left| \frac{\sin(n(b-a))}{2 \pi n} \right|, \]
    %
    so that it suffices to show $\sum |\sin(nx)| n^{-1} = \infty$ for every $x \not \in \pi \mathbf{Z}$. This follows because the values of $|\sin(nx)|$ are often large, so that we may apply the divergence of $\sum n^{-1}$. First, assume $x \in (0,\pi/2)$. If
    %
    \[ m \pi - x/2 < nx < m \pi + x/2 \]
    %
    for some $m \in \mathbf{Z}$, then
    %
    \[ m \pi + x/2 < (n+1)x < m \pi + 3x/2 < (m+1) \pi - x/2. \]
    %
    Thus if $nx \in (-x/2,x/2) + \pi \mathbf{Z}$, $(n+1)x \not \in (-x/2,x/2) + \pi \mathbf{Z}$. For $y$ outside of $(-x/2,x/2) + \pi \mathbf{Z}$, we have $|\sin(y)| > |\sin(x/2)|$, and therefore for any $n$,
    %
    \[ \frac{|sin(nx)|}{n} + \frac{|\sin((n+1)x)|}{n+1} > \frac{|\sin(x/2)|}{n+1}. \]
    %
    This means
    %
    \begin{align*}
        \sum_{n = 1}^\infty \frac{|\sin(nx)|}{n} &= \sum_{n = 1}^\infty \frac{|\sin(2nx)|}{2n} + \frac{|\sin((2n+1)x)|}{2n+1}\\
        &> |\sin(x/2)| \sum_{n = 1}^\infty \frac{1}{2n+1} = \infty
    \end{align*}
    %
    In general, we may replace $x$ with $x - k \pi$, with no effect to the values of the sum, so we may assume $0 < x < \pi$. If $\pi/2 < x < \pi$, then
    %
    \[ \sin(nx) = \sin(n(\pi - x)), \]
    %
    and $0 < \pi - x < \pi/2$, completing the proof, except when $x = \pi$, in which case
    %
    \[ \sum_{n = 1}^\infty \left| \frac{1 - e_n(\pi)}{2 \pi n} \right| = \sum_{n\ \text{even}} \left| \frac{1}{\pi n} \right| = \infty. \]
    %
    Thus the convergence of a Fourier series need not be absolute.
\end{example}

\begin{example}
    We can often find formulas for certain Fourier summations from taking the corresponding power series. This is because if we set $z = e^{it}$, then
    %
    \[ \sum_{n = -\infty}^\infty a_n e^{nit} = \sum_{n = -\infty}^\infty a_n z^n \]
    %
    becomes a Laurent series in $z$. For instance, we have a power series expansion
    %
    \[ \log \left( \frac{1}{1-x} \right) = \sum_{k = 1}^\infty \frac{z^k}{k}. \]
    %
    This converges pointwise for every $z \in \mathbf{D}$ but $z = 1$. Thus for $x \not \in 2 \pi \mathbf{Z}$,
    %
    \begin{align*}
        \sum_{k = 1}^\infty \frac{\cos(kx)}{k} &= \Re \left( \log \left( \frac{1}{1 - e(x)} \right) \right) = -\frac{1}{2} \log(2 - 2\cos(x)),\\
        \sum_{k = 1}^\infty \frac{\sin(kx)}{k} &= \Im \left( \log \left( \frac{1}{1 - e(x)} \right) \right) = \arctan \left( \frac{\sin(x)}{1 - \cos(x)} \right).
    \end{align*}
    %
    Here we agree that $\arctan(\pm \infty) = \pm \pi/2$. One can check that, indeed, the Fourier series of these two functions corresponds precisely to these summations. If a power series' radius of convergence exceeds $1$, then it is likely that the corresponding Fourier series taken on the circle will be pleasant, whereas if the power series' radius is equal to $1$, we can expect nasty behaviour on the boundary. In Complex analysis, one avoids talking about the boundary of the holomorphic function's definition, whereas in Fourier analysis we have to embrace the boundary points because this is the domain we are interested in. This makes the theory a little more pathological.
\end{example}

\chapter{Fourier Series}

Let's focus in on the problem we introduced in the last chapter. We write $\mathbf{T} = \RR / 2 \pi \mathbf{Z}$, so that a function $f: \mathbf{T} \to \mathbf{C}$ is a complex-valued $2 \pi$ periodic function on the real line. We then have an induced translation invariant norm on $\mathbf{T}$, given by setting $|t| = \min_{n \in \mathbf{Z}} |t + 2\pi n|$. The Lebesgue measure on $\RR$ induces a natural Borel measure on $\mathbf{T}$, such that for any periodic function $f: \mathbf{T} \to \mathbf{C}$,
%
\[ \int_{\mathbf{T}} f(t)\; dt = \frac{1}{2\pi} \int_{-\pi}^\pi f(t)\; dt. \]
%
For each integrable $f: \mathbf{T} \to \mathbf{C}$, we then have a \emph{formal trigonometric series}
%
\[ \sum_{n = -\infty}^\infty \widehat{f}(n) e_n(t). \]
%
In some sense, $f$ should be able to be approximated by the trigonometric polynomials obtained by truncating this series. However, at this point, we haven't deduced any reason for these sums to converge to $f$ analytically.

To understand the convergence, we define the partial sums
%
\[ S_Nf = \sum_{|n| \leq N} \widehat{f}(n) e_n. \]
%
If $f$ is real-valued, then the complex parts of $\widehat{f}(n)$ and $\widehat{f}(-n)$ cancel out, so $S_N f$ is a real-valued sum of cosines and sines, as in classical Fourier analysis.

An initial hope is that the Fourier series of a function converges pointwise, i.e. that for every $t$, $\lim_{N \to \infty} S_N(f)(t) = f(t)$. This is true if $f$ is periodic and differentiable everywhere. But even if we try and look at continuous periodic functions, the $S_N f$ can diverge. Thus we look for more exotic forms of convergence, and different quantitative descriptions which determine how the Fourier series represents the function $f$.

\section{Unique Representation of a Function?}

If the Fourier series of every function converged pointwise, we could conclude that if $f$ and $g$ have the same Fourier coefficients, they must necessarily be equal. This is clearly not true, for if we alter a function at a point, the Fourier series, defined by averaging over the entire region, remains the same. Nonetheless, if a function is continuous, editing the function at a point will break continuity, so we may have some hope of uniqueness of the expansion.

\begin{theorem}
    If $\widehat{f}(n) = 0$ for all $n$, then $f$ vanishes wherever it is continuous.
\end{theorem}
\begin{proof}
    We shall prove, without loss of generality, that if $f$ is continuous at the origin, then $f(0) = 0$. We treat the real-valued case first. For every trigonometric polynomial $g(x) = \sum a_n e_n(-x)$, we have
    %
    \[ \int_{-\pi}^\pi f(x) g(x) dx = 2 \pi \sum a_n \widehat{f}(n) = 0. \]
    %
    Suppose that $f$ is continuous at zero, and assume without loss of generality assume $f(0) > 0$. Pick $\delta$ such that if $|x| < \delta$, $|f(x)| > f(0)/2$. Consider the trigonometric polynomial
    %
    \[ g(x) = \varepsilon + \cos x = \varepsilon + \frac{e(x) + e(-x)}{2}. \]
    %
    where $\varepsilon$ is small enough that $g(x) > A > 1$ for $|x| < \delta/2$, $P(x) > 0$ for $\delta/2 \leq |x| < \delta$, and $g(x) < B < 1$ for $|x| \geq \delta$. The series of trigonometric polynomials $g_n(x) = (\varepsilon + \cos x)^n$ satisfy
    %
    \begin{align*}
        \left| \int_{\mathbf{T}} g_n(x) f(x) dx \right| &\geq \int_{|x| < \delta} g_n(x) f(x) dx - \left| \int_{\delta \leq |x|} g_n(x) f(x) dx \right|.
    \end{align*}
    %
    H\"{o}lder's inequality then guarantees that as $n \to \infty$,
    %
    \[ \left| \int_{\delta \leq |x|} g_n(x) f(x) dx \right| \lesssim B^n = o(1). \]
    %
    whereas
    %
    \[ \left| \int_{|x| < \delta} g_n(x) f(x) dx \right| \geq \int_{|x| < \delta/2} g_n(x) f(x) \gtrsim A^n. \]
    %
    which increases exponentially fast as $n \to \infty$. Thus we conclude
    %
    \[ 0 = \left| \int_{-\pi}^\pi g_n(x) f(x) dx \right| \gtrsim A^n - o(1). \]
    %
    For suitably large values of $n$, the right hand side is positive, whereas the left hand side is zero, which is impossible. By contradiction, we conclude $f(0) = 0$. In general, if $f$ is complex valued, then we may write $f = u + iv$, where
    %
    \[ u(x) = \frac{f(x) + \overline{f(x)}}{2}\ \ \ \ v(x) = \frac{f(x) - \overline{f(x)}}{2i}. \]
    %
    The Fourier coefficients of $\overline{f}$ all vanish, because the coefficients of $f$ vanish, and so we conclude the coefficients of $u$ and $v$ vanish. $f$ is continuous at $x$ if and only if it is continuous at $u$ and $v$, and we know from the previous case this means that both $u$ and $v$ vanish at that point.
\end{proof}

\begin{corollary}
	If $f,g \in C(\mathbf{T})$ and $\widehat{f} = \widehat{g}$, then $f = g$.
\end{corollary}
\begin{proof}
    Then $f - g$ is continuous with vanishing Fourier coefficients.
\end{proof}

\begin{corollary}
    If $f \in C(\mathbf{T})$ and $\widehat{f} \in L^1(\mathbf{Z})$, $S_N f \to f$ uniformly as $N \to \infty$.
\end{corollary}
\begin{proof}
    If $\sum |\widehat{f}(n)| < \infty$, then we calculate
    %
    \[ |(S_{N + M} f)(x) - (S_N f)(x)| \leq \sum_{k = N+1}^M |\widehat{f}(k)|. \]
    %
    Since the series $\widehat{f}$ is absolutely summable, for any $\varepsilon$, there is sufficiently large $N$, such that the quantity above is bounded uniformly by $\varepsilon$. Thus the functions $\{ S_N f \}$ are a Cauchy sequence in $L^\infty(\mathbf{T})$, and therefore converge uniformly to some function $Sf$, which necessarily must be continuous. Uniform convergence also implies we can interchange integrals to conclude
    %
    \[ \widehat{Sf}(n) = \lim_{N \to \infty} \frac{1}{2\pi} \int_{-\pi}^\pi S_N(f)(t) e_n(-t) = \widehat{f}(n). \]
    %
    Thus $\widehat{Sf} = \widehat{f}$, so $Sf = f$ since both functions are continuous.
\end{proof}

Later we show that if $f \in C^m(\mathbf{T})$, then $\widehat{f}(n) = O(1/|n|^m)$. In particular, if $m \geq 2$, then $S_N f \to f$ uniformly. If $f \in C^\infty(\mathbf{T})$, then this means $\widehat{f}(n) = O(1/|n|^m)$, which implies $S_N f \to f$ uniformly, and moreover, $(S_N f)^{(k)} \to f^{(k)}$ uniformly as well for any $k$. Conversely, take a sequence $a_n$, for $n \in \mathbf{Z}$, with $a_n = O_m(1/|n|^m)$ for all $m$. If we set $f_N = \sum_{|n| \leq N} a_n e_n$, then $f_N$ converges uniformly to some function $f$. But one can verify that the $m$'th derivative of the $f_N$ also converge uniformly to some function, which therefore must be the $m$'th derivative of $f$. Thus $f \in C^\infty(\mathbf{T})$, and $\smash{\widehat{f}(n)} = a_n$. This means there is a perfect duality between infinitely differentiable functions and arbitrarily fast decaying sequences of coefficients. In more advanced contexts, like the theory of distributions, this duality is very useful for studying the Fourier transform.

\section{Quantitative Bounds on Fourier Coefficients}

Using classical analysis, the last section essentially details all the results we can obtain about the Fourier series of a function. Of course, in practical contexts most of the functions dealt with are arbitrarily smooth, so the picture seems rather complete. Nonetheless, we still want to study the qualitative properties of the Fourier series in terms of the qualitative properties of functions. For instance, does the Fourier series of functions which are globally small converge faster than functions which are only small on average. In modern terms, do we get faster convergence rates if $\| f \|_{L^\infty(\mathbf{T})}$ is small rather than just if $\| f \|_{L^1(\mathbf{T})}$ is small. Does the convergence get faster if we consider the convergence with respect to an $L^p$ norm rather than an $L^\infty$ norm? Thus we want to understand the behaviour of the Fourier series with respect to a family of \emph{norm spaces}. Of course, these norms are defined in a more general space of measurable functions, and to apply functional analysis arguments it is essential to `complete' the picture of these norms, so we will find that many of our arguments, initially invented to study smooth functions, also work naturally with arbitrarily integrable functions.

These quantitative estimates are still interesting even if we knew everything there was to know about the pointwise convergence of Fourier series. A series of functions may converge to a function pointwise, whereas none of these individual functions may look like the function they converge to at all. So we may want to look at quantitative measures of how globally similar two functions are. For instance, we might want to know how the Fourier series of a function changes under a small pertubation, and this correponds to understanding quantitative estimates about the operators $S_N$, or the rate of convergence of $S_N f$ to $f$, which might be required if we want to determine how large $N$ must be to approximate $f$.

\begin{example}
	If we consider a square wave $\chi_I$ for some interval $I$, then the techniques of the following section allow us to prove that
    %
    \[ \| \chi_I - S_N \chi_I \|_{L^2(\mathbf{T})} = O(1/\sqrt{N}), \]
    %
    independently of $I$. This means that if we want to simulate square waves with a musical instrument up to some square mean error $\varepsilon$, then we will need $\Omega(\varepsilon^{-2})$ different notes to represent the sound accurately. Thus a piano with 88 keys can only approximate square waves slightly better than a keyboard with 20 keys. If $f$ is $C^{m+1}(\mathbf{T})$, then
    %
    \[ \| f - S_N f \|_{L^2(\mathbf{T})} = O(1/N^{m/2}), \]
    %
    so we require significantly less notes to simulate this sound, i.e. $\Omega(\varepsilon^{-2/m})$. In this case a piano can simulate these sounds much more accurately.
\end{example}

One initial equation which might summarize how well behaved the Fourier series is with respect to suitable norms would be to obtain an estimate of the form $\smash{\| \widehat{f} \|_{L^q(\mathbf{Z})} \lesssim \| f \|_{L^p(\mathbf{T})}}$ for particular values of $p$ and $q$. If this was established, we could conclude that the Fourier series is stable in the $L^q$ norm under small pertubations in the $L^p$ norm. The first inequality we give is trivial, but is certainly tight, i.e. for $f(t) = e_n(t)$.

\begin{theorem}
	For any $f$, $\| \widehat{f} \|_{L^\infty(\mathbf{T})} \leq \| f \|_{L^1(\mathbf{T})}$.
\end{theorem}
\begin{proof}
	We just take absolute values into the oscillatory integral defining the Fourier coefficients, calculating that for any $n$,
	%
	\[ |\widehat{f}(n)| = \left| \int_{\mathbf{T}} f(t) e_n(-t) \right| \leq \frac{1}{2\pi} \int_{\mathbf{T}} |f(t)| = \| f \|_{L^1(\mathbf{T})}, \]
	%
	which was the required bound.
\end{proof}

This proof doesn't really take any deep features of the Fourier coefficients. The same bound holds for any integral
%
\[ \frac{1}{2\pi} \int_{\mathbf{T}} f(t) K(t)\; dt, \]
%
where $|K(t)| \leq 1$ for all $t$. But the bound is still tight, which might be explained by the fact that the Fourier series gives oscillatory information which is not immediately present in the $L^p$ norms of the phase spaces, other than by taking a naive absolute bound into the $L^p$ norm. The only $L^p$ space where we can get a completely satisfactory bound is for $p = 2$, where we can use Hilbert space technique; this should be expected since orthogonality was used to define the Fourier series.

\begin{theorem}
	For any function $f$, $\| \widehat{f} \|_{L^2(\mathbf{Z})} = \| f \|_{L^2(\mathbf{T})}$.
\end{theorem}
\begin{proof}
	With respect to the normalized inner product on the space $L^2(\mathbf{T})$,the calculations of the last chapter tell us that the exponentials are an orthonormal family of functions, in the sense that for distinct $n$ and $m$, $(e_n,e_m) = 0$, and $(e_n,e_n) = 1$. Since $\smash{\widehat{f}(n) = (f,e_n)}$, we apply Bessel's inequality to conclude
    %
    \[ \| \widehat{f} \|_{L^2(\mathbf{Z})} \leq \| f \|_{L^2(\mathbf{T})}. \]
    %
    The exponentials $\{ e_n \}$ are actually an orthonormal basis for $L^2(\mathbf{T})$; This can be seen from the Stone Weirstrass theorem, since trigonometric polynomials separate points, or by results we prove independently, later on in these notes. Thus Parsevel's equality tells us
    %
    \[ \| \widehat{f} \|_{L^2(\mathbf{Z})} = \| f \|_{L^2(\mathbf{T})}. \qedhere \]
\end{proof}

This equality makes the Hilbert space $L^2(\mathbf{T})$ often the best place to understand Fourier expansion techniques, and general results are often achieved by reduction to this well understood case. For instance, the inequality above, combined with the trivial inequality, is easily interpolated using the Riesz-Thorin technique to give the Hausdorff Young inequality.

\begin{theorem}
    If $1 \leq p \leq 2$, $\| \widehat{f} \|_{L^q(\mathbf{Z})} \leq \| f \|_{L^p(\mathbf{T})}$.
\end{theorem}

It might be surprising to note that the Hausdorff Young inequality essentially completes the bounds on the Fourier series with respect to the $L^p$ norms. There is no interesting result one can obtain for $p > 2$ other than the obvious inequality
%
\[ \| \widehat{f} \|_{L^2(\mathbf{Z})} \leq \| f \|_{L^2(\mathbf{T})} \leq \| f \|_{L^p(\mathbf{T})}. \]
%
Thus we can control the magnitude of the Fourier coefficients in terms of the width of the original function, but we are limited in our ability to control the width of the Fourier coefficients in terms of the magnitudes of the original function. This makes sense, because the $L^p$ norm of $f$ measures fairly different aspects of the function than the $L^q$ norm of the Fourier transform of $f$. It is only in the case of the $L^2$ norm where results are precise, and where $p$ is small that we can take a trivial bound, that we get an inequality like the Hausdorff Young result.

\section{Asymptotic Decay of Fourier Series}

The next result, known as Riemann-Lebesgue lemma, shows that the Fourier series of any integrable function decays, albeit arbitrarily slowly. The proof we give is an instance of an important principle in Functional analysis that we will use over and over again. Suppose for each $n$, we have a bounded operator $T_n: X \to Y$ between Banach spaces, and we want to show that for each $x \in X$, $\lim T_n(x) = T(x)$, where $T$ is another bounded operator. Suppose that it is obvious that $\lim T_n(x') = T(x')$ for a dense family of points $X' \subset X$, and the operators $T_n$ are {\it uniformly} bounded. Then for any $x \in X$,
%
\begin{align*}
	\| T_n(x) - T(x) \| &\leq \| T_n(x) - T_n(x') \| + \| T_n(x') - T(x') \| + \| T(x') - T(x) \|.
\end{align*}
%
If we choose $x'$ such that $\| x - x' \| \leq \varepsilon$, then for $n$ large enough we find that $\| T_n(x) - T(x) \| \lesssim \varepsilon$. Since $\varepsilon$ was arbitrary, this means that $\lim_{n \to \infty} T_n(x) = T(x)$. The advantage of the principle is that it is suitably abstract, and can thus be used very flexibly. But the disadvantage is that it is a very soft analytical argument, and cannot be used to obtain results on the rate of convergence of $T_n(x)$ to $T(x)$.

\begin{lemma}[Riemann-Lebesgue]
	If $f \in L^1(\mathbf{T})$, then $\widehat{f}(n) \to 0$ as $|n| \to \infty$.
\end{lemma}
\begin{proof}
	We claim the lemma is true for the characteristic function of an interval $\chi_I$. If $I = [a,b]$, then
    %
    \[ \widehat{\chi_I}(n) = \frac{1}{2\pi} \int_a^b e_n(-t) = \frac{i(e_n(-b) - e_n(-a))}{2 \pi n} = O(1/n). \]
    %
    By linearity of the integral, the Fourier transform of any step function vanishes at $\infty$. But if $\smash{\Lambda_n(f) = \widehat{f}(n)}$, then $|\Lambda_n f| \leq \| \widehat{f} \|_{L^\infty(\mathbf{T})} \leq \| f \|_{L^1(\mathbf{T})}$, which shows that the sequence of functionals $\{ \Lambda_n \}$ are uniformly bounded as maps from $L^1(\mathbf{T})$ to $L^\infty(\mathbf{Z})$. Since $\lim_{|n| \to \infty} \Lambda_n(f) = 0$ for any step function $f$, and the step functions are dense in $L^1(\mathbf{T})$, we conclude that $\lim_{|n| \to \infty} \Lambda_n(f) = 0$ for all $f \in L^1(\mathbf{T})$.
\end{proof}

Even though the Fourier series of any step function decays at a rate $O(1/n)$, it is {\it not} true that a general Fourier series decays at a rate of $O(1/n)$. And in fact, one can provide examples of functions whose Fourier series decay at an arbitrarily slow rate. This is the penalty for using a soft type analytical argument.

Nonetheless, for smooth functions, we can obtain a decay rate. This is an instance of a general result related to the duality between decay and smoothness in phase and frequency space.

\begin{theorem}
	If $f \in C^m(\mathbf{T})$, then $|\widehat{f}(n)| \leq |n|^{-m} \| f^{(m)} \|_{L^1(\mathbf{T})}$.
\end{theorem}
\begin{proof}
	Applying the derivative law for Fourier series $m$ times, we find that
	%
	\[ |\widehat{f}(n)| = |n|^{-m} |\widehat{f^{m}}(n)| \leq |n|^{-m} \| f^{(m)} \|_{L^1(\mathbf{T})}. \qedhere \]
\end{proof}

\begin{remark}
    Suppose that $\mu$ is a measure on $\mathbf{T}$ with finite variation, for which we write $\mu \in M(\mathbf{T})$. Then one can define the Fourier series of $\mu$ by
    %
    \[ \widehat{\mu}(n) = \int_{-\pi}^\pi e_n(-x) d\mu(x). \]
    %
    If $\mu$ is absolutely continuous with respect to the normalized Lebesgue measure on $\mathbf{T}$, and $d\mu = f dx$, then $\widehat{\mu} = \widehat{f}$, so this is an extension of the Fourier series to measures. One can verify that
    %
    \[ \| \widehat{\mu} \|_{L^\infty(\mathbf{Z})} \leq \| \mu \|_{M(\mathbf{T})}. \]
    %
    If $\delta$ is the Dirac delta measure at the origin, i.e. $\mu(E) = 1$ if $0 \in E$, and $\mu(E) = 0$ otherwise, then for all $n$,
    %
    \[ \widehat{\delta}(n) = 1. \]
    %
    Thus the Fourier series of $\delta$ has no decay at all. Once can view this as saying functions are `smoother' than measures, and therefore have a Fourier decay, albeit one that is qualitative rather than quantitative.
\end{remark}

\section{Convolution and Kernel Methods}

The notion of the convolution of two functions $f$ and $g$ is a key tool in Fourier analysis, both as a way to regularize functions, and as an operator that transforms nicely when we take Fourier series. Given two integrable functions $f$ and $g$, we define
%
\[ (f * g)(t) = \int_{\mathbf{T}} f(s) g(t-s)\; ds. \]
%
Thus we smear the values of $g$ with respect to a density function $f$.

\begin{lemma}
	For any $1 \leq p < \infty$, and $f \in L^p(\mathbf{T})$, $\lim_{h \to 0} T_h f = f$ in $L^p(\mathbf{T})$.
\end{lemma}
\begin{proof}
	If $f$ is $C^1(\mathbf{T})$, then $|f(x + h) - f(x)| \lesssim h$ uniformly in $x$, implying that $\| T_h f - f \|_{L^p(\mathbf{T})} \leq \| T_hf - f \|_{L^\infty(\mathbf{T})} \lesssim h$, and so $T_h f \to f$ in all the spaces $L^p(\mathbf{T})$. We have $\| T_h f \|_{L^p(\mathbf{T})} = \| f \|_{L^p(\mathbf{T})}$, so the $T_h$ are a bounded family of operators, and since $C^1(\mathbf{T})$ is dense in $L^p(\mathbf{T})$ for $1 \leq p < \infty$, we conclude that $\lim_{h \to 0} T_h f = f$ for all $f \in L^p(\mathbf{T})$.
\end{proof}

\begin{theorem}
    Convolution has the following properties:
    %
    \begin{itemize}
    	\item If $f \in L^p(\mathbf{T})$ and $g \in L^q(\mathbf{T})$, for $1/p + 1/q = 1$, then $f * g$ is uniformly continuous.

    	\item If $f \in L^p(\mathbf{T})$ and $g \in L^q(\mathbf{T})$, and if we define $r$ so that $1/r = 1/p + 1/q - 1$, with $1 \leq r \leq \infty$, then $f * g$ is defined by the integral formula almost everywhere, and
    	%
    	\[ \| f * g \|_{L^r(\mathbf{T})} \leq \| f \|_{L^p(\mathbf{T})} \| g \|_{L^q(\mathbf{T})}. \]
    	%
    	This is known as {\it Young's inequality} for convolutions.

        \item Convolution is a commutative, associative, bilinear operation.

        \item If $f,g \in L^1(\mathbf{T})$, then $\widehat{f * g} = \widehat{f} \widehat{g}$.

        \item If $f$ has a weak derivative $f'$ in $L^1(\mathbf{T})$, then $f * g$ has a weak derivative in $L^1(\mathbf{T})$, and $(f * g)' = f' * g$. Thus convolution is `additively smoothing'. In particular, if $f \in C^k(\mathbf{T})$ and $g \in C^l(\mathbf{T})$, then $f * g \in C^{k+l}(\mathbf{T})$.

        \item If $f$ is supported on $E$, and $g$ on $F$, then $f * g$ is supported on $E + F$.
    \end{itemize}
\end{theorem}
\begin{proof}
	Suppose $f \in L^p(\mathbf{T})$, and $g \in L^q(\mathbf{T})$, then
	%
	\begin{align*}
		|(f * g)(t - h) - (f * g)(t)| &\leq \int |f(t-h-s) - f(t-s)| |g(s)|\; ds\\
		&\leq \| f_h - f \|_{L^p(\mathbf{T})} \| g \|_{L^q(\mathbf{T})}.
	\end{align*}
	%
	The right hand side is a bound independant of $t$ and converges to zero as $h \to 0$, so $f * g$ is uniformly continuous. Applying H\"{o}lder's inequality again gives that $\| f * g \|_{L^\infty(\mathbf{T})} \leq \| f \|_{L^p(\mathbf{T})} \| g \|_{L^q(\mathbf{T})}$. If $f \in L^p(\mathbf{T})$, and $g \in L^1(\mathbf{T})$, we use Minkowski's inequality to conclude that
	%
	\begin{align*}
		\| f * g \|_{L^p(\mathbf{T})} &= \left( \int \left| \int f(t-s)g(s)\; ds \right|^p\; dt \right)^{1/p}\\
		&\leq \int \left( \int |f(t-s)g(s)|^p\; dt \right)^{1/p}\; ds\\
		&= \int g(s) \| f \|_{L^p(\mathbf{T})}\; ds = \| f \|_{L^p(\mathbf{T})} \| g \|_{L^1(\mathbf{T})}.
	\end{align*}
	%
	Thus $f * g$ is finite almost everywhere. The inequality also implies that
	%
	\[ \| f * g \|_{L^p(\mathbf{T})} \leq \| f \|_{L^1(\mathbf{T})} \| g \|_{L^p(\mathbf{T})} \]
	%
	if $f \in L^1(\mathbf{T})$, and $g \in L^p(\mathbf{T})$. But now implying Riesz-Thorin interpolation gives the general Young's inequality. Elementary applications of change of coordinates and Fubini's theorem establish the commutativity and associativity of convolution for functions $f, g \in L^1(\mathbf{T})$. But $L^1(\mathbf{T}) \cap L^p(\mathbf{T})$ is dense in $L^p(\mathbf{T})$. Since $f * g = g * f$ for a dense family of functions, and convolution is continuous from $L^p(\mathbf{T}) \times L^q(\mathbf{T}) \to L^r(\mathbf{T})$, we obtain the identity holds everywhere. Similarily, one can apply Fubini's theorem to obtain associativity for $f,g,h \in L^1(\mathbf{T})$, and then apply density. To obtain the product identity for the Fourier series, we can apply Fubini's theorem to write
    %
    \begin{align*}
        \widehat{f * g}(n) &= \frac{1}{2\pi} \int_{-\pi}^\pi (f * g)(t) e_n(-t)\ dt\\
        &= \frac{1}{(2\pi)^2} \int_{-\pi}^\pi \int_{-\pi}^\pi f(s)g(t-s) e_n(-t)\ ds\ dt\\
        &= \frac{1}{2 \pi} \int_{-\pi}^\pi f(s) \int_{-\pi}^\pi (L_{-s}g)(t) e_n(-t)\ dt\ ds\\
        &= \frac{1}{2\pi} \int_{-\pi}^\pi f(s) e_n(-s) \widehat{g}(n)\ ds\\
        &= \widehat{f}(n) \widehat{g}(n),
    \end{align*}
    %
    and this is exactly the identity required. To calculate the weak derivative of $f * g$, we fix $\phi \in C^\infty(\mathbf{T})$, and calculate using two applications of Fubini's theorem that
    %
    \begin{align*}
    	\int_{\mathbf{T}} (f' * g)(t) \phi(t)\; dt &= \int_\mathbf{T} \int_{\mathbf{T}} f'(t-s) g(s) \phi(t)\; ds\; dt\\
    	&= \int_{\mathbf{T}} g(s) \int_{\mathbf{T}} f'(t-s) \phi(t)\; dt\; ds\\
    	&= - \int_{\mathbf{T}} g(s) \int_{\mathbf{T}} f(t-s) \phi'(t)\; dt\; ds\\
    	&= - \int_{\mathbf{T}} \left( \int_{\mathbf{T}} g(s) f(t-s)\; ds \right) \phi'(t)\; dt\\
    	&= - \int_{\mathbf{T}} (f * g)(t) \phi'(t)\; dt.
    \end{align*}
    %
    If $f = 0$ a.e outside $E$, and $g = 0$ a.e. outside $F$, then $(f * g)(t)$ can be nonzero only when there is a set $G$ of positive measure such that for any $s \in G$, $f(s) \neq 0$ and $g(t-s) \neq 0$. But this means that $E \cap G \cap (t-F)$ has positive measure, so that there is $s \in E$ such that $t-s \in F$, meaning that $t \in E + F$.
\end{proof}

We know that suitably smooth functions have convergent Fourier series. The advantage of convolution is if we want to study the properties of a function $f$, convolution with a smooth function $g$ gives a smooth function, and provided $\smash{\widehat{g}}$ is close to 1, $\smash{\widehat{f*g}}$ will be close to $\widehat{f}$. If we can establish the convergence properties on the convolution $f * g$, then we can probably obtain results about $f$. From the frequency side, $\sum \widehat{f}(n) e_n$ might not converge, but $\sum a_n \widehat{f}(n) e_n$ might converge for a suitably fast decaying sequence $a_n$. But if $a_n$ is close to one, this sequence might still reflect properties of the original sequence.

To make rigorous the idea of approximating the Fourier series of a function, we introduce families of \emph{good kernels}. A good kernel is a sequence of integrable functions $\{ K_n \}$ on $\mathbf{T}$ bounded in $L^1$ norm, for which
%
\[ \frac{1}{2\pi} \int_{\mathbf{T}} K_n(t) = 1. \]
%
so that integration against $K_n$ operates essentially like an average, and for any $\delta > 0$,
%
\[ \lim_{n \to \infty} \int_{|t| > \delta} |K_n(t)| \to 0. \]
%
Thus the functions $\{ K_n \}$ become concentrated at the origin as $n \to \infty$. If in addition, we have an estimate $\| K_n \|_{L^\infty(\mathbf{T})} \lesssim n$, we say it is an {\bf approximation to the identity}.

\begin{theorem}
	Let $\{ K_n \}$ be a good kernel. Then
	%
	\begin{itemize}
		\item $(K_n * f)(t) \to f(t)$ for any continuity point $t$ of $f$.
		\item $(K_n * f) \to f$ uniformly if $f \in C(\mathbf{T})$, and $K_n * f$ converges to $f$ in $L^p(\mathbf{T})$ if $f \in L^p(\mathbf{T})$, for $1 \leq p < \infty$.
		\item If $K_n$ is an approximation to the identity, $(K_n * f)(t) \to f(t)$ for all $t$ in the Lebesgue set of $f$.
	\end{itemize}
\end{theorem}
\begin{proof}
	The operators $T_nf = K_n * f$ are uniformly bounded as operators on $L^p(\mathbf{T})$. Basic analysis shows that $(K_n * f)(t) \to f(t)$ at each point $t$ where $f$ is continuous, and converges uniformly to $f$ if $f$ is in $C(\mathbf{T})$. But a density argument allows us to conclude that $K_n * f \to f$ in $L^p(\mathbf{T})$ for each $f \in L^p(\mathbf{T})$, for $1 \leq p < \infty$. To obtain pointwise convergence, we calculate
	%
	\[ |(K_n * f)(t) - f(t)| \leq \frac{1}{2\pi} \int_{\mathbf{T}} |f(t - s) - f(t)| |K_n(s)|\; ds. \]
	%
	Let $A(\delta) = \delta^{-1} \int_{|s| < \delta} |f(t-s) - f(t)|$. Then as $\delta \to 0$, $A(\delta) \to 0$ because $t$ is in the Lebesgue set of $f$. And we find that for each $k$, since $|K_n(s)| \lesssim n$,
	%
	\[ \int_{2^k/n < |t| < 2^{k+1}/n} |f(t-s) - f(t)| |K_n(s)| \lesssim \frac{A(2^{k+1}/n)}{2^{k+1}}. \]
	%
	Thus we have a bound
	%
	\[ |(K_n * f)(t) - f(t)| \lesssim \sum_{k = 0}^\infty \frac{A(2^k/n)}{2^k}. \]
	%
	Because $f$ is integrable, $A$ is continuous, and hence bounded. This means that for each $m$,
	%
	\[ |(K_n * f)(t) - f(t)| \lesssim \sum_{k = 0}^m \frac{A(2^k/n)}{2^k} + \| A \|_\infty \sum_{k = m}^\infty \frac{1}{2^k} = \sum_{k = 0}^m \frac{A(2^k/n)}{2^k} + O\left( 1/2^m \right). \]
	%
	For any fixed $m$, the finite sum tends to zero as $n \to \infty$, so we obtain that $|(K_n * f)(t) - f(t)| = o(1) + O(1/2^m)$. Taking $m \to \infty$ proves the result.
\end{proof}

\section{The Dirichlet Kernel}

We calculate that
%
\[ (S_Nf)(t) = \sum_{|n| \leq N} \widehat{f}(n) e_n(t) = \frac{1}{2\pi} \int f(x) \left( \sum_{|n| \leq N} e_n(t - x) \right)\; dx.  \]
%
The bracketed part of the final term in the equation is independant of the function $f$, and is therefore key to understanding the behaviour of the sums $S_N$. We call it the Dirichlet kernel $D_N$, defined as
%
\[ D_N(t) = \sum_{n = -N}^N e_n(t). \]
%
Thus $S_N f = f * D_N$, so analyzing convolution with this kernel gives results about the sums of Fourier series.

\begin{theorem}
	For any integer $N$ and $t \in \RR$,
	%
	\[ D_N(t) = \frac{\sin((N+1/2)t)}{\sin(t/2)}. \]
\end{theorem}
\begin{proof}
	By the geometric series summation formula, we may write
    %
    \begin{align*}
        D_N(t) &= 1 + \sum_{n = 1}^N e_n(t) + e_n(-t) = 1 + e(t) \frac{e_N(t) - 1}{e(t) - 1} + e(-t) \frac{e_N(-t) - 1}{e(-t) - 1}\\
        &= 1 + e(t) \frac{e_N(t) - 1}{e(t) - 1} + \frac{e_N(-t) - 1}{1 - e(t)} = \frac{e_{N+1}(t) - e_N(-t)}{e(t) - 1}\\
        &= \frac{e_{N+1/2}(t) - e_{N+1/2}(-t)}{e_{1/2}(t) - e_{1/2}(-t)} = \frac{\sin((N + 1/2)t)}{\sin(t/2)}.
    \end{align*}
    %
    Thus as $N \to \infty$, $D_N$ oscillates highly rapidly.
\end{proof}


If $D_N$ was a good kernel, then we would obtain that the partial sums of $S_N$ converge uniformly. This initially seems a good strategy, because $(2\pi)^{-1} \int D_N(t) = 1$. However, we find
%
\begin{align*}
    \int_{-\pi}^\pi |D_N(t)| &= \int_{-\pi}^\pi \left| \frac{\sin((N + 1/2)t)}{\sin(t/2)} \right|\\
    &\gtrsim \int_0^\pi \frac{|\sin((N+1/2) t)|}{\sin(t/2)}\\
    &\gtrsim \int_0^\pi \frac{|\sin((N+1/2) t)|}{t}\; dt\\
    &= \int_0^{(N+1/2)\pi} \frac{|\sin(t)|}{t}\\
    &\gtrsim \sum_{n = 0}^N \frac{1}{t} \gtrsim \log(N).
\end{align*}
%
Thus the $L^1$ norm of $D_N$ grows, albeit slowly, to $\infty$. This reflects the fact that $D_N$ oscillates very frequently, and also that the pointwise convergence of the Fourier series is much more subtle than that provided by good kernels. In fact, a simple functional analysis argument shows that pointwise convergence of Fourier series fails for continuous functions.

\begin{theorem}
	There exists $f \in C(\mathbf{T})$ such that $(S_N f)(0)$ diverges as $N \to \infty$.
\end{theorem}
\begin{proof}
	If we consider the linear operators $\Lambda_N f = (S_N f)(0) = (f * D_N)(0)$ as maps from $C(\mathbf{T})$ to $L^1(\mathbf{T})$, and if we let $f$ be a continuous function approximating $\text{sgn}(D_N)$, then we can obtain a sequence $f_N$ such that $|\Lambda_N f_N| = \Omega(\log N) \| f_N \|_\infty$. This implies that $\| \Lambda_N \| \to \infty$ as $N \to \infty$. The uniform boundedness principle thus implies that there exists a {\it single} function $f \in C(\mathbf{T})$ such that $\sup |\Lambda_N f| = \infty$, so $(S_N f)(0)$ diverges as $N \to \infty$.
\end{proof}

\section{Countercultural Methods of Summation}

We now interpret our convergence of series according to a different kernel, so we do get a family of good kernels, and therefore we obtain pointwise convergence for suitable reinterpretations of partial sums. One reason why the Dirichlet kernel fails to be a good kernel is that the Fourier coefficients of the kernel have a sharp drop -- the coefficients are either equal to one or to zero. If we mollify, then we will obtain a family of good kernels. And the best way to do this is to alter our summation methods slightly.

The standard method of summation suffices for much of analysis. Given a sequence $a_0, a_1, \dots$, we define the infinite sum as the limit of partial sums. Some sums, like $\sum_{k = 1}^\infty k$, obviously diverge, whereas other sums, like $\sum 1/n$, `just' fail to converge because they grow suitably slowly towards infinity over time. Since the time of Euler, a new method of summation developed by Cesaro was introduced which `regularized' certain terms by considering averaging the sums over time. Rather than considering limits of partial sums, we consider limits of averages of sums, known as Cesaro means. Letting $s_n = \sum_{k = 0}^n a_k$, we define the Cesaro means
%
\[ \frac{s_0 + \dots + s_n}{n+1}, \]
%
A sequence is Cesaro summable to some value if these averages converge. If the normal summation exists, then the Cesaro limit exists, and is equal to the original sum. However, the Cesaro summation is stronger than normal convergence.

\begin{example}
In the sense of Cesaro, we have $1 - 1 + 1 - 1 + \dots = 1/2$, which reflects the fact that the partials sums do `converge', but to two different numbers $0$ and $1$, which the series oscillates between, and the Cesaro means average these two points of convergence out to give a single method of convergence.
\end{example}

Another notion of regularization sums emerged from Complex analysis, called Abel summation. Given a sequence $\{ a_i \}$, we can consider the power series $\sum a_k r^k$. If this is well defined for $|r| < 1$, we can consider the Abel means $A_r = \sum a_k r^k$, and ask if $\lim_{r \to 1} A_r$ exists, which should be `almost like' $\sum a_k$. If this limit exists, we call it the Abel sum of the sequence.

\begin{example}
    In the Abel sense, we have $1 - 2 + 3 - 4 + 5 - \dots = 1/4$, because
    %
    \[ \sum_{k = 0}^\infty (-1)^k (k + 1) z^k = \frac{1}{(1 + z)^2}. \]
    %
    The coefficients here are $\Omega(N)$, so they can't be Cesaro summable.
\end{example}

%Abel summation is even more general than Cesaro summation.

%\begin{theorem}
%    A Cesaro summable sequence is Abel summable.
%\end{theorem}
%\begin{proof}
%    Let $\{ a_i \}$ be a Cesaro summable sequence, which we may without loss of generality assume converges to $0$. Now $(n + 1)\sigma_n - n \sigma_{n-1} = s_n$, so
    %
%    \[ (1 - r)^2 \sum_{k = 0}^n (k + 1) \sigma_k r^k = (1 - r) \sum_{k = 0}^n s_k r^k = \sum_{k = 0}^n a_k r^k \]
    %
%    As $n \to \infty$, the left side tends to a well defined value for $r < 1$, hence the same is true for $\sum_{k = 0}^n a_k r^k$. Given $\varepsilon > 0$, let $N$ be large enough that $|\sigma_n| < \varepsilon$ for $n > N$, and let $M$ be a bound for all $|\sigma_n|$. Then
    %
%    \begin{align*}
%        \left| (1 - r)^2 \sum_{k = 0}^\infty (k + 1) \sigma_k r^k \right| &\leq (1 - r)^2 \left( \sum_{k = 0}^N (k + 1) |\sigma_k| r^k + \varepsilon \sum_{k = N+1}^\infty (k + 1) r^k \right)\\
%        &= (1 - r)^2 \left( \sum_{k = 0}^N (k + 1) (|\sigma_k| - \varepsilon) r^k + \varepsilon \left[ \frac{r^{n+1}}{1-r} + \frac{1}{(1 - r)^2} \right] \right)\\
%        &\leq (1 - r)^2 M \sum_{k = 0}^N (k + 1) r^k + \varepsilon r^{n+1} (1 - r) + \varepsilon\\
%        &\leq (1 - r)^2 M \frac{(N+1)(N+2)}{2} + \varepsilon r^{n+1} (1 - r) + \varepsilon
%    \end{align*}
    %
%    Fixing $N$, and letting $r \to 1$, we may make the complicated sum on the end as small as possible, so the absolute value of the infinite sum is less than $\varepsilon$. Thus the Abel limit converges to zero.
%\end{proof}

\section{Fejer's Theorem}

Note that the Cesaro means of the Fourier series of $f$ are given by
%
\[ \sigma_N(f) = \frac{S_0(f) + \dots + S_{N-1}(f)}{N} = f * \left( \frac{D_0 + \dots + D_{N-1}}{N} \right) = f * F_N. \]
%
The convergence properties of the Cesaro means therefore relate to the properties of the {\bf Fej\'{e}r kernel} $F_N$. We find that
%
\[ F_N(x) = \sum_{n = -N}^N \left( 1 - \frac{|n|}{N} \right) e_n(t) = \frac{1}{N} \frac{\sin^2(Nx/2)}{\sin^2(x/2)}. \]
%
so the oscillations of the Dirichlet kernel are slightly dampened, and as a result, $F_N$ is an approximation to the identity.

\begin{theorem}[Fej\'{e}r's Theorem] For any $f \in L^1(\mathbf{T})$,
   	\begin{itemize}
   		\item $(\sigma_N f)(x) \to f(x)$ for all $x$ in the Lebesgue set of $f$.
   		\item $\sigma_N f \to f$ uniformly if $f \in C(\mathbf{T})$.
   		\item $\sigma_N f \to f$ in the $L^p$ norm for $1 \leq p < \infty$, if $f \in L^p(\mathbf{T})$.
   	\end{itemize}

\end{theorem}

\begin{corollary}
	If $\widehat{f} = 0$, then $f = 0$ almost everywhere.
\end{corollary}
\begin{proof}
	If $\widehat{f} = 0$, then $\sigma_N f = 0$ for all $N$. But $\sigma_N f \to f$ in $L^1$, which means that $f = 0$ in $L^1(\mathbf{T})$, so $f = 0$ almost everywhere.
\end{proof}

If we look at the Fourier expansion of the trigonometric polynomial $\sigma_N(f)$, we see that
%
\[ \sigma_N f = \sum_{n = -N}^N \frac{N-|n|}{N} \widehat{f}(n) e_n. \]
%
Thus the Fourier coefficients are slowly added to the expansion, rather than a sharp cutoff as with ordinary Dirichlet summation. This is one reason for the nice convergence properties the kernel has as compared to the Dirichlet kernel.

\section{Abel Summation and Harmonics on the Disk}

Relating Abel summations to Fourier series requires a little bit more careful work, since we do not consider limits of finite sums. Note that the Abel sum is
%
\[ A_r(f) = \sum_{n = -\infty}^\infty \widehat{f}(n) r^n e_n(t). \]
%
Thus, if we define the {\it Poisson kernel}
%
\[ P_r(t) = \sum_{n = -\infty}^\infty r^{|n|} e_n(t) \]
%
which is defined by a uniformly convergent series over $\mathbf{T}$, we calculate that $A_r(f) = P_r * f$. Thankfully, we find $P_r$ is a good kernel. To see this, we can apply an infinite geometric series summation to obtain that
%
\begin{align*}
    \sum r^{|n|} e_n(t) &= 1 + \frac{re(t)}{1 - re(t)} + \frac{re(-t)}{1 - re(-t)} = 1 + \frac{2r \cos t - 2r^2}{(1 - re(t))(1 - re(-t))}\\
    &= 1 + \frac{2r \cos t - 2r^2}{1 - 2r \cos t + r^2} = \frac{1 - r^2}{1 - 2r \cos t + r^2}.
\end{align*}
%
As $r \to 1$, the function concentrates at the origin, because as $r \to 1$, if $\delta \leq |t| \leq \pi$, then $1 - \cos t$ is bounded away from the origin, so
%
\begin{align*}
    \left| \frac{1 - r^2}{1 - 2r \cos t + r^2} \right| &= \left| \frac{1 + r}{(1+(1-2\cos t)r) + 2(1 - \cos t) r^2/(1-r)} \right|\\
    &= O \left( \frac{1 - r}{1 - \cos t} \right) = O_\delta(1 - r).
\end{align*}
%
Thus the oscillation in the Poisson kernel cancels out as $r \to 1$, and so the Poisson kernel is a good kernel.

\begin{theorem}
    For any $f \in L^1(\mathbf{T})$,
    %
    \begin{itemize}
        \item $(A_r f)(t) \to f(t)$ for all $x$ in the Lebesgue set of $f$.
        \item $A_r f \to f$ uniformly if $f \in C(\mathbf{T})$.
        \item $A_r f \to f$ in the $L^p$ norm for $1 \leq p < \infty$, if $f \in L^p(\mathbf{T})$.
    \end{itemize}
\end{theorem}

The Poisson kernel is not a trigonometric polynomial, and therefore not quite as easy to work with as the F\'{e}jer kernel. However, it is the real part of the Cauchy kernel
%
\[ \frac{1 + re(t)}{1 - re(t)}. \]
%
and therefore links the study of trigonometric series and the theory of analytic functions. 

\begin{theorem}
    $u(r e^{it}) = (A_r f)(t)$ is $C^\infty(\mathbf{T})$, and harmonic for $r < 1$. Moreover, the function $u$ is the \emph{unique} $C^2(\mathbf{T})$ harmonic function such that as $r \to 1$, $u(re^{it}) \to f$ in the $L^1$ norm.
\end{theorem}
\begin{proof}
    The function $u$ is infinitely differentiable, because of the rapid convergence of the series defining the Poisson kernel. In particular, we note that
    %
    \[ \frac{\partial^2 u}{\partial \theta^2} = - \sum_{n = -\infty}^\infty \widehat{f}(n) |n|^2 r^{|n|} e_n(t), \]
    %
    \[ \frac{\partial u}{\partial r} = \sum_{n = -\infty}^\infty \widehat{f}(n) |n| r^{|n| - 1} e_n(t), \]
    %
    and
    %
    \[ \frac{\partial^2 u}{\partial r^2} = \sum_{n = -\infty}^\infty \widehat{f}(n) |n|(|n| - 1) r^{|n| - 2} e_n(t). \]
    %
    But in polar coordinates, we have
    %
    \begin{align*}
        \Delta u &= \frac{\partial^2 u}{\partial r^2} + \frac{1}{r} \frac{\partial u}{\partial r} + \frac{1}{r^2} \frac{u}{\theta^2}\\
        &= \sum_{|n| \geq 2} \widehat{f}(n) |n|(|n|-1) r^{|n|-2} e_n(t)\\
        &\ \ \ + \sum_{n \neq 0} \widehat{f}(n) |n| r^{|n|-2} e_n(t) - \sum_{n = -\infty}^\infty \widehat{f}(n) |n|^2 r^{|n|-2} e_n(t) = 0.
    \end{align*}
    %
    Thus $u$ is harmonic.

    Conversely, suppose $u \in C^2(\mathbf{T})$ is harmonic. Then we can find $a_n(t)$ such that
    %
    \[ u(re^{it}) = \sum_{n = -\infty}^\infty a_n(r) e_n(t), \]
    %
    where
    %
    \[ a_n(r) = \int_{\mathbf{T}} u(re^{it}) e_n(-t)\; dt. \]
    %
    Then
    %
    \[ \int_{\mathbf{T}} \frac{\partial^2 u}{\partial \theta^2}(re^{it}) e_n(-t)\; dt = -n^2 a_n(r), \]
    %
    and so $a_n''(r) + (1/r) a_n'(r) - (n^2/r^2) a_n(r) = 0$. This is an ordinary differential equation, whose only bounded solutions are given by $a_n(r) = A_n r^{|n|}$. If $u(re^{it}) \to f$ in the $L^1$ norm as $r \to 1$, then we conclude
    %
    \[ A_n = \lim_{r \to 1} \int_{\mathbf{T}} u(re^{it}) e_n(-t)\; dt = \int_{\mathbf{T}} f(t) e_n(-t) = \widehat{f}(n), \]
    %
    so
    %
    \[ u(re^{it}) = \sum \widehat{f}(n) r^{|n|} e_n(t) = g(re^{it}). \qedhere \]
\end{proof}

Thus we can represent any function on $\mathbf{T}$ as a harmonic function on the interior of the unit disk, which is often a useful analysis. The theory of Hardy spaces is a natural extension of this idea.

%If $u$ is only required to converge to $f$ {\it pointwise} on the boundary, then the function we found is no longer required to be unique. Below is an example of a function $u$ which tends to zero pointwise on the boundary, yet does not vanish on the interior of the unit disk.

%\begin{example}
%    If $P_r$ is the Poisson kernel, define $u(r,\theta) = P_r(\theta)$. Then $u$ is harmonic in the unit disk, because $\Delta u = (\Delta P_r)'' = 0$. We calculate
    %
%    \begin{align*}
%        u(r,t) &= \sum_{n = 1}^\infty in r^n [e_n(t) - e_n(-t)]\\
%        &= i \left[ \frac{r e(t)}{(re(t) - 1)^2} - \frac{r e(-t)}{(re(-t) - 1)^2} \right]\\
%        &= i \left[ \frac{re(-t) + r^{-1}e(t) - re(t) - r^{-1}e(-t)}{(re(t) - 1)^2(re(-t) - 1)^2} \right]\\
%        &= \frac{(r - r^{-1}) \sin(t)}{(re(t) - 1)^2(re(-t) - 1)^2}\\
%        &= \frac{(r^2 - 1) \sin(t)}{r (re(t) - 1)^2(re(-t) - 1)^2}
%    \end{align*}
    %
%    In this form, it is easy to see that for a fixed $t$, as $r \to 1$, $u(r,t) \to 0$. However, the denominator tells us this convergence isn't uniform.
%\end{example}

\section{The De la Valle\'{e} Poisson Kernel}

By taking a kernel halfway between the Dirichlet kernel and the Fejer kernel, we can actually obtain important results about ordinary summation. For two integers $M > N$, we define
%
\[ \sigma_{N,M}(f) = \frac{M\sigma_M(f) - N\sigma_N(f)}{M-N}. \]
%
If we take a look at the Fourier expansion of $\sigma_{n,m} f$, we find
%
\[ \sigma_{N,M} f = \sum_{n = -M}^M \frac{M - |n|}{M-N} e_n - \sum_{n = -N}^N \frac{N - |n|}{M-N} e_n = S_N f + \sum_{|n| = N+1}^M \frac{M - |n|}{M - N} e_n. \]
%
So we still have a slow decay in the Fourier coefficients. And as a result, if we look at the associated De la Velle\'{e} Poisson kernel, we find that a suitable subsequence is an approximation to the identity. In particular, for any fixed integer $k$, the sequence $\sigma_{kN,(k+1)N}$ leads to a good kernel. More interestingly, if the Fourier coefficients of $f$ have some decay, then the De la Vall\'{e}e does not differ that much from the ordinary sum, which gives useful results.

\begin{theorem}
	If $\widehat{f}(n) = O(|n|^{-1})$, then for any integers $N$ and $k$, if
    %
    \[ kN \leq M < (k+1)N, \]
    %
    then
	%
	\[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\mathbf{T})} \lesssim 1/k. \]
	%
	Where the implicit constant is independant of $N$ and $k$.
\end{theorem}
\begin{proof}
	We just calculate that, since the Poisson sum has essentially the same weight for low term coefficients as the sum $S_M f$,
	%
	\[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\mathbf{T})} \lesssim \sum_{kN \leq |n| < (k+1)N} |\widehat{f}(n)| \lesssim \sum_{n = kN}^{(k+1)N} \frac{1}{n} \leq \frac{N}{kN} = \frac{1}{k}. \qedhere \]
\end{proof}

\begin{corollary}
	If $f$ is a function with $\widehat{f}(n) = O(|n|^{-1})$,
	%
	\begin{itemize}
		\item $S_Nf$ converges to $f$ in the $L^p$ norm for $1 \leq p < \infty$.
		\item $S_Nf$ converges uniformly to $f$ if $f \in C(\mathbf{T})$.
		\item $(S_N f)(x) \to f(x)$ for each Lebesgue point $x$ of $f$.
	\end{itemize}
\end{corollary}
\begin{proof}
	The idea is quite simple. Fix $N$. Given any $\varepsilon$, we can use the last theorem to find $k$ large enough such that if $kN \leq M < k(N+1)$,
	%
	\[ \| \sigma_{kN,(k+1)N} f - S_M f \|_{L^\infty(\mathbf{T})} \leq \varepsilon. \]
	%
	But this gives the first and second result, up to perhaps a $\varepsilon$ of error. The latter result is given by similar techniques.
\end{proof}

\section{Pointwise Convergence}

One way around around the blowup in the $L^1$ norm of $D_N$ is to consider only functions $f$ which provide a suitable dampening condition on the oscillation of $D_N$ near the origin. This is provided by smoothness of $f$, manifested in various ways. The first thing we note is that the convergence of $(S_N f)(t)$ for a \emph{fixed} $x_0$ depends only \emph{locally} on the function $f$.

\begin{lemma}[Riemann Localization Principle]
    If $f_0$ and $f_1$ agree in an interval around $t_0$, then
    %
    \[ (S_N f_0)(t_0) = (S_N f_1)(t_0) + o(1). \]
\end{lemma}
\begin{proof}
    Let
    %
    \[ X = \{ f \in L^1(\mathbf{T}) : f(x) = 0\ \text{for almost every $x \in (t_0 - \varepsilon, t_0 + \varepsilon$)} \}. \]
    %
    Then $X$ is a closed subset of $L^1(\mathbf{T})$. Note that for all $x \in [-\pi,\pi]$,
    %
    \[ \sin(t/2) \gtrsim t \quad\text{and}\quad \sin((N+1/2)t) \leq 1. \]
    %
    Thus if $|t| \geq \varepsilon$,
    %
    \[ |D_N(t)| = \frac{|\sin((N+1/2)t)|}{|\sin(t/2)|} \lesssim 1/\varepsilon. \]
    %
    In particular, by H\"{o}lder's inequality, the functionals $T_Nf = (S_N f)(t_0)$ are uniformly bounded on $X$, i.e. $\| T_N \| \lesssim 1/\varepsilon$. If $f$ is smooth, and vanishes on $(t_0 - \varepsilon, t_0 + \varepsilon)$, then $T_N f \to 0$ as $N \to \infty$. But the space of such functions is dense in $X$, which implies that $T_N f \to 0$ for \emph{any} $f \in X$. Thus if $f_0, f_1$ are two functions that agree in $(t_0 - \varepsilon, t_0 + \varepsilon)$, then $f_0 - f_1 \in X$, so $(S_N f_0)(t_0) = (S_N f_1)(t_0) + o(1)$. In particular, the pointwise convergence properties of $f_0$ and $f_1$ are equivalent at $t_0$.
\end{proof}

Thus any result about the pointwise convergence of Fourier series must depend on the local properties of a function $f$. Here, we give two of the main criteria, which corresponds to the smoothness of a function about a point $x$: either $f$ is in a sense, `locally Lipschitz', or `locally of bounded variation'.

\begin{theorem}[Dini's Criterion]
    If there exists $\delta$ such that
    %
    \[ \int_{|t| < \delta} \left| \frac{f(x+t) - f(x)}{t} \right|\; dt < \infty, \]
    %
    then $(S_N f)(x) \to f(x)$.
\end{theorem}
\begin{proof}
    Assume without loss of generality that $x = 0$ and $f(x) = 0$. Fix $\varepsilon > 0$, and pick $\delta_0$ such that
    %
    \[ \int_{|t| < \delta_0} \left| \frac{f(t)}{t} \right|\; dt < \varepsilon. \]
    %
    We have
    %
    \begin{align*}
        |(S_N f)(0)| &= \left| \left( \int_{|t| < \delta_0} + \int_{|t| \geq \delta_0} \right) f(t) D_N(t)\; dt \right|.
    \end{align*}
    %
    Now
    %
    \[ \int_{|t| \geq \delta_0} f(t) D_N(t)\; dt = (D_N * \left( \mathbf{I}_{|t| \geq \delta_0} f \right))(0) = S_N( \mathbf{I}_{|t| \geq \delta_0} f )(0) = o(1) \]
    %
    since $f \mathbf{I}_{|t| \geq \delta_0}$ vanishes in a neighbourhood of the origin. On the other hand, we note that $t/\sin(t/2)$ is a bounded function on $\mathbf{T}$, so
    %
    \begin{align*}
        \int_{|t| < \delta_0} f(t) D_N(t)\; dt &= \int_{|t| < \delta_0} \left( \sin((N + 1/2)t) \frac{f(t)}{t} \right) \left( \frac{t}{\sin(t/2)} \right)\; dt\\
        &\lesssim \| f(t)/t \|_{L^1[-\delta_0,\delta_0]} \leq \varepsilon.
    \end{align*}
    %
    Thus, for suitably large $N$, $|(S_N f)(0)| \lesssim \varepsilon$. Since $\varepsilon$ was arbitrary, the proof is complete.
\end{proof}

This proof applies, in particular, if $f$ is locally Lipschitz at $x$. Note the application of the Riemann Lebesgue lemma to show that to analyze the pointwise convergence of $(S_N f)(x)$, it suffices to analyze
%
\[ \lim_{N \to \infty} \int_{|t| < \delta} f(x+t) D_N(t)\; dt \]
%
for any fixed $\delta > 0$.

\begin{lemma}[Jordan's Criterion]
    If $f \in L^1(\mathbf{T})$ locally has bounded variation about $x$, then
    %
    \[ (S_N f)(x) \to \frac{f(x^+) + f(x^-)}{2}. \]
\end{lemma}
\begin{proof}
    By Riemann's localization principle, we may assume $f$ has bounded variation everywhere. Then without loss of generality, we may assume $f$ is an increasing function, since a bounded variation function is the difference of two monotonic functions. Since
    %
    \[ \frac{1}{2\pi} \int_{-\pi}^\pi f(x+t) D_N(t)\; dt = \int_0^\pi [f(x + t) + f(x - t)] D_N(t), \]
    %
    it suffices without loss of generality to show that
    %
    \[ \lim_{N \to \infty} \frac{1}{2\pi} \int_0^\pi f(x+t) D_N(t)\; dt = \frac{f(x+)}{2}. \]
    %
    Since $\int_0^\pi D_N(t) = \pi$, this is equivalent to
    %
    \[ \lim_{N \to \infty} \frac{1}{2\pi} \int_0^\pi [f(x + t) - f(x+)] D_N(t)\; dt = 0. \]
    %
    Because of this, we may assume without loss of generality that $x = 0$ and $f(x+) = 0$. Then by the mean value theorem for integrals (which only applies for monotonic functions), for each $N$, there exists $0 \leq \nu_N \leq \delta$ such that
    %
    \begin{align*}
        \int_0^\pi f(t) D_N(t)\; dt &= \| f \|_\infty \int_{\nu_N}^\pi D_N(t)\; dt.
    \end{align*}
    %
    Now an integration by parts gives
    %
    \begin{align*}
        \int_{\nu_N}^\pi D_N(t) &\lesssim \int_{\nu_N}^\pi \frac{\sin((N + 1/2) t)}{t}\; dt = \int_{\nu_N/(N + 1/2)}^{\pi/(N + 1/2)} \frac{\sin(t)}{t}\; dt \lesssim \frac{1}{N+1/2}.
    \end{align*}
    %
    Thus
    %
    \[ \int_0^\pi f(t) D_N(t) \lesssim \frac{1}{N + 1/2} \to 0. \qedhere \]
\end{proof}

Of course, applying various better decay rates leads to a more uniform version of this theorem. The decay of the Fourier series depends on the decay of the Fourier coefficients of $yg(y)$ and $g(y) \cos(y/2)(y/\sin(y/2))$. In particular, if these coefficients is $O(|n|^{-m})$, then the convergence rate is also $O(|n|^{-m})$. If this decay rate is independent of $x$ for suitable values of $x$, the convergence will be uniform over these values of $x$.

\begin{example}
    Consider the sawtooth function defined on $[-\pi,\pi]$ by $s(t) = t$, and then made periodic on the entire real line. We can easily calculate the Fourier series here, obtaining that
    %
    \[ s(t) = i \sum_{n \neq 0} \frac{(-1)^n e_n(t)}{t} = -2 \sum_{n = 1}^\infty (-1)^n \frac{\sin(nt)}{n}. \]
    %
    Thus for any $t \in (-\pi,\pi)$,
    %
    \[ \sum_{n = 1}^\infty (-1)^n \frac{\sin(nt)}{n} = -t/2 \]
    %
    and
    %
    \[ \sum_{n = 1}^\infty (-1)^n \frac{\sin(n\pi)}{n} = \frac{s(-\pi) + s(\pi)}{2} = 0. \]
\end{example}

\begin{theorem}
    If $\widehat{f}(n) = O(|n|^{-1})$, and $f(t_0-)$ and $f(t_0+)$ exist, then
    %
    \[ (S_N f)(t_0) \to \frac{f(t_0-) + f(t_0+)}{2}. \]
\end{theorem}
\begin{proof}
    The idea of our proof is to break $f$ into a nice continuous function, and the sawtooth function, where we already understand the convergence of Fourier series. Without loss of generality, let $t_0 = \pi$. Define $g(t) = f(t) + (2\pi)^{-1} (f(\pi+) - f(\pi-)) s(t)$ on $(-\pi,\pi)$, where $s$ is the sawtooth function. Then
    %
    \[ \lim_{t \uparrow \pi} g(t) = \lim_{t \downarrow -\pi} g(t) = \frac{f(\pi+) + f(\pi-)}{2}. \]
    %
    Thus $g$ can be defined at $\pi + 2 \pi \mathbf{Z}$ so it is continuous there. Now we find $|\widehat{g}| \lesssim |\widehat{f}| + |\widehat{g}| = O(|n|^{-1})$, and so
    %
    \[ (S_N g)(\pi) \to \frac{f(\pi+) + f(\pi-)}{2}. \]
    %
    We also have $(S_N s)(\pi) \to 0$. Thus
    %
    \[ (S_N f)(\pi) = (S_N g)(\pi) - (S_N s)(\pi) \to \frac{f(\pi+) + f(\pi-)}{2}. \qedhere \]
\end{proof}

% Another way to fix the convergence is to use a more quantitative argument in terms of $L^p$ spaces. It is obvious that $S_N f \to f$ in any feasible norm if $f$ is a trigonometric polynomial, because if $f$ has degree $M$, then $S_N f = f$ for $N \geq M$. The Stone-Weirstrass theorem says that we can uniformly approximate any continuous function on $\mathbf{T}$ by a trigonometric polynomial, so provided we can show that the operators $S_N$ are uniformly bounded in the $L^p$ norm for $1 \leq p < \infty$, we obtain convergence for all $f \in L^p(\mathbf{T})$. The fact that the $S_N$ are not bounded in the $L^\infty$ norm is why the Fourier series can diverge pointwise for continuous functions. In fact, the $S_N$ are not bounded as operators on $L^1(\mathbf{T})$, and as such, Fourier series do not converge in the $L^1$ norm. The reason for this is that if $\{ K_M \}$ is a good kernel, then $S_N(K_M) = D_N * K_M \to D_N$ as $M \to \infty$, and so as $M \to \infty$, we find $\| S_N(K_M) \|_{L^1(\mathbf{T})} = \Omega(\log N)$, hence $\| S_N \|_{L^1(\mathbf{T})}$ is unbounded. Later on, using the theory of conjugate functions, we will show that the operators $S_N$ are uniformly bounded in all $L^p(\mathbf{T})$ for $1 < p < \infty$, and so the Fourier series of any function $f \in L^p(\mathbf{T})$ converges to $f$ in the $L^p$ norm.

\section{Pointwise Behaviour at Discontinuity Points}

This isn't the end of our discussion about points of discontinuity. There is an interesting phenomenon which occurs locally around the point of discontinuity. If $f$ is continuous locally around a discontinuity point $t_0$, $S_N f \to f$ pointwise locally around $t_0$. Thus, being continuous, $S_N f$ must `jump' from $(S_N f)(t_0-)$ to $(S_N f)(t_0+)$ locally around $t_0$. Interestingly enough, we find that the jump is not precise, the jump is overshot and then must be corrected to the left and right of $t_0$. This is known as the {\it Gibb's phenomenon}, after the man who clarified the reason for why this phenomenon occured in physical measurements where first thought to be a defect in the equipment used to take the measurements.

\begin{theorem}
	Given $f$ with finitely many discontinuity points and with $\widehat{f}(n) = O(|n|^{-1})$, in particular one at $t_0$, we find
	%
	\[ \lim_{N \to \infty} (S_N f)(t_0 \pm \pi/N) = f(t_0+) \pm C \cdot \frac{f(t_0+) - f(t_0-)}{2}, \]
	%
	where
	%
	\[ C = 2 \pi \int_0^\pi (\sin x)/x \approx 16.610. \]
\end{theorem}
\begin{proof}
	First consider the jump function $s$. Then
	%
	\begin{align*}
		(S_N s)(\pi + \pi/N) &= -2 \sum_{n = 1}^N \frac{\sin(n\pi/N)}{n} = -2\pi \sum_{n = 1}^N \frac{1}{N} \left( \frac{\sin(n\pi/N)}{\pi n/N} \right).
	\end{align*}
	%
	Here we're just taking averages of values of $\sin(x)/x$ at $x = \pi/N$, $x = 2\pi/N$, and so on and so forth. Thus is a Riemann sum, so as $N \to \infty$, we get that
	%
	\[ (S_N s)(\pi + \pi/N) \to - 2\pi \int_0^\pi \frac{\sin x}{x}. \]
	%
	The same calculations give
	%
	\[ (S_N s)(\pi - \pi/N) \to 2 \pi \int_0^\pi \frac{\sin x}{x}. \]
	%
	In general, given $f$, we can write $f = g + \sum \lambda_j h_j$, where $g$ is continuous, and $h_j$ is a translate of the sawtooth function. Then $S_N g$ converges to $g$ uniformly, and $S_N h_j \to 0$ for all $h_j$ uniformly in an interval outside of their discontinuity point. To see this, we note that an integration by parts gives
	%
	\[ \left| \int_{-\pi}^\pi D_N(y)[s(x-y) - s(x)]\; dy \right| \leq |G_N(x - \pi)|, \]
	%
	where $G_N(y) = -i \sum_{|n| \leq N} e_n(t)/n$, so $G_N' = D_N$. It now suffices to show $G_N(x - \pi) \to 0$ outside a neighbourhood of $\pi$. But if $A(u,t) = \sum_{|n| \leq u} e_n(t)$, summation by parts gives
	%
	\[ \sum_{|n| \leq N} \frac{e_n(t)}{n} = \frac{A(N,t)}{N} + \int_1^N \frac{A(u,t)}{u^2}. \]
	%
	Now a simple geometric sum shows $A(u,t) \lesssim 1/|e(t) - 1|$, so provided $d(t, 2 \pi \mathbf{Z})$ is bounded below, the quantity above tends to zero uniformly. This gives the required result.
\end{proof}

\chapter{Applications}

\section{Tchebychev Polynomials}

If $f$ is everywhere continuous, then for every $\varepsilon$, Fej\'{e}r's theorem says that we can find $N$ such that $\| \sigma_N(f) - f \| \leq \varepsilon$. But $\sigma_N f$ is just a trigonometric polynomial, and so we have shown that with respect to the $L^\infty$ norm, the space of trigonometric polynomials is dense in the space of all continuous functions.  Now if $f$ is a continuous function on $[0,\pi]$, then we can extend it to be even and $2\pi$ periodic, and then the trigonometric series $S_N(f)$ of $f$ will be a cosine series, hence $\sigma_N(f)$ will also be a cosine series, and so for each $\varepsilon$, we can find $N$ and coefficients $a_1, \dots, a_N$ such that
%
\[ \left| f(x) - \sum_{n = 1}^N a_n \cos(nx) \right| < \varepsilon. \]
%
Now we use a surprising fact. For each $n$, there exists a degree $n$ polynomial $T_n$ such that $\cos(nx) = T_n(\cos x)$. This is clear for $n = 0$ and $n = 1$. More generally, we can write
%
\begin{align*}
	\cos((m+1)x) &= \cos((m+1)x) + \cos((m-1)x) - \cos((m-1)x)\\
	&= \cos(mx + x) + \cos(mx - x) - \cos((m-1)x)\\
	&= 2 \cos x \cos(mx) - \cos((m-1)x).
\end{align*}
%
Thus we have the relation  $T_{m+1}(x) = 2xT_m(x) - T_{m-1}(x)$. These polynomials are known as {\bf Tchebyshev polynomials}, enabling us to move between `periodic coordinates' and standard Euclidean coordinates.

\begin{corollary}[Weirstrass]
	The polynomials are uniformly dense in $C[0,1]$.
\end{corollary}
\begin{proof}
	If $f$ is a continuous function on $[0,1]$, we can define $g(t) = f(|\cos(t)|)$. Then $g$ is even, and so for every $\varepsilon > 0$, we can find $a_1, \dots, a_N$ such that
	%
	\[ \left|g(t) - \sum_{n = 1}^N a_n \cos(nt) \right| = \left| g(t) - \sum_{n = 1}^N a_n T_n(\cos t) \right| < \varepsilon. \]
	%
	But if $x = \cos t$, for $\cos t \geq 0$, this equation says
	%
	\[ \left| f(x) - \sum_{n = 1}^N a_n T_n(x) \right| < \varepsilon, \]
	%
	and so we have uniformly approximated $f$ by a polynomial.
\end{proof}

\section{Exponential Sums and Equidistribution}

The next result uses Fourier analysis to characterize the asymptotic distribution of a certain sequence $a_1, a_2, \dots$. In particular, it is most useful in determining when this distribution is distributed when we consider $2 \pi a_1, 2 \pi a_2, \dots$ as elements of $\mathbf{T}$, i.e. so we only care about the fractional part of the numbers, or in other terms their behaviour modulo one. We say the sequence is {\it uniformly distributed} if for any interval $I \subset \mathbf{T}$, $\# \{ 2 \pi a_n \in I : n \leq N \} \sim N |I|$ as $N \to \infty$. By approximating continuous functions by step functions, this implies that if $f: \mathbf{T} \to \mathbf{C}$ is continuous, then
%
\[ \frac{f(2 \pi a_1) + \dots + f(2 \pi a_N)}{N} \to \frac{1}{2\pi} \int_{\mathbf{T}} f(t)\; dt. \]
%
It is the right hand side to which we can apply Fourier summation to obtain a very useful condition. We let $S_Nf$ denote the left hand side of the equation, and $Tf$ the right hand side.

\begin{theorem}[Weyl Condition]
	A sequence $a_1, a_2, \dots \in \mathbf{T}$ is uniformly distributed if and only if for every $n$, as $N \to \infty$, $e_n(2 \pi a_1) + \dots + e_n(2 \pi a_N) = o(N)$.
\end{theorem}
\begin{proof}
	The condition in the theorem implies that for any trigonometric polynomial $f$, $S_Nf \to Tf$. The $S_N$ are uniformly bounded as functions on $L^\infty(\mathbf{T})$, and $T$ is a bounded functional on this space as well. But this means that $\lim S_N f = T f$ for all $f$ in $C(\mathbf{T})$, since this equation holds on the dense subset of trigonometric polynomials.
\end{proof}

This technique enables us to completely characterize the equidistribution behaviour of arithmetic sequences. Given a particular $\gamma$, we consider the equidistribution of the sequence $\gamma, 2 \gamma, \dots$, which depends on the irrationality of $\gamma$.

\begin{example}
	Let $\gamma$ be an arbitrary real number. Then for any $n$, if $e_n(2 \pi \gamma) \neq 1$,
	%
	\[ \sum_{m = 1}^N e_n(2 \pi m \gamma) = \frac{e_n(2 \pi (N + 1) \gamma) - 1}{e_n(2 \pi \gamma) - 1} \lesssim 1 = o(N). \]
	%
	If $\gamma$ is an irrational number, then $e_n(2 \pi \gamma) \neq 1$ for all $n$, which implies that $\gamma, 2\gamma, \dots$ is equidistributed. Conversely, if $e_n(2 \pi \gamma) = 1$ for some $n$, we have
	%
	\[ \sum_{m = 1}^N e_n(a_m) = N. \]
	%
	which is not $o(N)$, so the sequence $\gamma, 2\gamma, \dots$ is {\it not} equidistributed. If $\gamma$ is rational, there certainly is $n$ such that $n \gamma \in \mathbf{Z}$, and so $e_n(2 \pi \gamma) = 1$.
\end{example}

On the other hand, it is still an open research to characterize, for which $\gamma$ the sequence $\gamma, \gamma^2, \gamma^3, \dots$ is equidistributed. Here is an example showing that there are $\gamma$ for which the sequence is not equidistributed.

\begin{example}
	Let $\gamma$ be the golden ratio $(1 + \sqrt{5})/2$. Consider the sequence
	%
	\[ a_n = \left( \frac{1 + \sqrt{5}}{2} \right)^n + \left( \frac{1 - \sqrt{5}}{2} \right)^n = b_n + c_n. \]
	%
	Then one checks that $a_n$ is a kind of Fibonacci sequence, with $a_{n+1} = a_n + a_{n-1}$, and initial conditions $a_0 = 2$, $a_1 = 1$. One checks that $c_n$ is always negative for odd $n$, and positive for even $n$, and tends to zero as $n \to \infty$. Since $a_n$ is an integer, this means that $d(b_n, \mathbf{Z}) = d(\gamma^n, \mathbf{Z}) \to 0$. But this means that the average distribution of the $\gamma^n$ modulo one is concentrated at the origin.
\end{example}

\section{The Isoperimetric Inequality}



\chapter{Physics}

\section{Heat Propagation Into the Ground}

Let us consider an application of the Fourier series taken from Fourier's original work. Consider heat moving from above ground to below ground, and vice versa. If we let $H(t,y)$ denote the temperature at a depth $y$ into the ground at time $t$, for $y > 0$. Assuming that the material of the ground is homogenous, by choosing appropriate units, the differential equation becomes $H_t = H_{yy}$, a variant of the heat equation. We assume that the heat at the surface changes periodically over the days and seasons, so
%
\[ H(t,0) = A \cos(2\pi t / D) + B \cos(2 \pi t/Y) + C, \]
%
where $A,B,C$ are arbitrary constants, $D$ is the length of a day, and $Y$ is the length of a year, so $Y = 365 D$. In our calculation, we assume the regularity condition that $H \in L^\infty [0,\infty)^2$, so the temperature does not magnify infinitely at large depths or large times.

To solve this equation, we use two tricks: linearity, and Fourier series. We can solve the heat equation by solving the three heat equations with initial conditions $H_D(t,0) = \cos(2\pi t/D)$, $H_Y(t,0) = \cos(2 \pi t/Y)$, and $H_C(t,0) = 1$, and then obtain a general solution by letting $H = A H_D + B H_Y + C H_C$. The third equation is easiest: we let $H_C(t,y) = 1$ for all $t$ and $y$. To solve the other equations, we can use variable separation. Assuming $H_D$ and $H_Y$ are bounded, this forces
%
\[ H_D(t,y)\; \propto\; \cos((2 \pi /D) t - (\pi / D)^{1/2} y) e^{- (\pi / D)^{1/2} y}, \]
\[ H_Y(t,y)\; \propto\; \cos((2\pi/Y)t - (\pi/Y)^{1/2} y) e^{- (\pi/Y)^{1/2} y}. \]
%
Thus the temperature in the ground splits into the daily heating effect, the seasonal heating effect, and a constant temperature. From these equations we get several interesting qualitative properties. As we go deeper into the ground, the temperature decays at a rate inversely dependant on the length of time, so even at small depths, the daily temperature becomes neglible, and only the seasonal temperature is important. Experimently, determining the constants in our equation, we determine this happens about half a foot into the ground. Next, the deeper we go in the ground, the more a `time lag' exists, where the seasonal temperature back in time has now travelled to the temperature at the current point in the ground. Experimentally, we determine that about 2-3 metres below ground, the temperature lags by six months. Fourier mentions this is a good depth to build a wine cellar.

\section{Seafaring with Fourier}

Here we discuss two problems in seafaring that can be solved quite accurately with Fourier analysis, first done by Kelvin in the late 1800s. Consider first the problem in determining the error of compass measurement on a ship when taking an initial bearing at harbor travelling. Thus for each angle $\theta$, we consider an error $g(\theta)$ such that if, at an angle $\theta$, we take a measurement $f(\theta)$, then $f(\theta) = \theta + g(\theta)$. Often $g$ is up to 20 degrees, but it will suffice to know $g$ up to an angle of two or three degrees, since other systematic errors in travel disturb the angle the ship actually travels by this amount anyway. And thus experimentally we find it suffices to approximate $g$ by a degree four trigonometric polynomial, i.e. we subtitute $g$ for an approximate value
%
\[ g_1(\theta) = A_0 + A_1 \cos \theta + B_1 \sin \theta + A_2 \cos(2\theta) + B_2 \sin(2\theta). \]
%
We can obtain measurements $g(\theta)$ for certain values of $\theta$ by locating landmarks, and 6 measurements suffice to uniquely identify $g_1$ from all other degree five trigonometric polynomials.

Another seafaring problem is to determine the future height of the tide. We expect the height of the tides to be due to periodic forces in nature. If $h(t)$ is the height of the tide, we might expect by linearity of the wave equation that $h(t) = h_1(t) + h_2(t) + \dots$, where $h_1(t)$ is the height with relation to the rotation of the earth and the moon, $h_2(t)$ the rotation of the earth and the sun, and so on and so forth to more neglible values. Each $h_k$ is periodic with some period $\omega_k$. If we assume that each $h_k$ is a trigonometric polynomial, then there is a way to reduce the calculation of the coefficients to a certain integral formula which one can approximate by taking samples of the height of the tides over time. Unfortunately, one must take a large number of samples to obtain this integral formula, but Kelvin designed one of the first automated calculators to approximate this.

\begin{theorem}
	If $h(t) = \sum_{n = 1}^N A_n \cos(\omega_n t)$, where the $\omega_n$ are all different periods, then for any $S$,
	%
	\[ A_n = \frac{2}{T} \lim_{n \to \infty} \int_S^{S + T} h(t) \cos(\omega_n t)\; dt. \]
\end{theorem}
\begin{proof}
	We just change variables. If $2 \pi N / \omega_n < T \leq 2 \pi (N + 1)/\omega_n$,
	%
	\begin{align*}
		\int_S^{S+T} h(t) \cos(\omega_n t)\; dt &= N \int_0^{2 \pi/ \omega_n} h(t) \cos(\omega_n t)\; dt + O(1)\\
		&= \frac{N}{\omega_n} \int_0^{2 \pi} \frac{1}{N} \sum_{k = 1}^N h(S + t/\omega_n + 2 \pi k / \omega_n) \cos(t)\; dt + O(1).
	\end{align*}
	%
	The average in the integral causes all oscillation not corresponding to $\omega_n$ to cancel out, so
	%
	\[ \frac{2}{T} \int_S^{S+T} h(t) \cos(\omega_n t)\; dt \to \frac{2}{\omega_n} \left( A_n \int_0^{2\pi} \cos^2(t) + B_n \int_0^{2\pi} \cos(t) \sin(t) \right). \qedhere \]
\end{proof}








\chapter{The Fourier Transform}

In the last few chapters, we discussed the role of analyzing the frequency decomposition of a periodic function on the real line. In this chapter, we explore the ways in which we may extend this construction to perform frequency analysis for not necessarily periodic functions on the real line, and more generally, in higher dimensional Euclidean space. The only periodic trigonometric functions on $[0,1]$ on the real line had integer frequencies of the form $2\pi n$, whereas on the real line periodic functions can have frequencies corresponding to any real number. The analogue of the discrete Fourier series formula
%
\[ f(x) = \sum_{k = -\infty}^\infty \widehat{f}(k) e(kx) \]
%
is the Fourier inversion formula
%
\[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e(\xi x)\; d\xi, \]
%
where for each real number $\xi$, we define
%
\[ \widehat{f}(\xi) = \int_{-\infty}^\infty f(x) e(- \xi x)\; dx. \]
%
The function $\widehat{f}$ is known as the {\bf Fourier transform} of the function $f$. It is also denoted by $\mathcal{F}(f)$. The role to which we can justify this formula is the main focus of this chapter. Without too much more work, we will also analyze the Fourier transform on $\RR^n$, which, given $f: \RR^n \to \RR^n$, considers the quantities
%
\[ f(x) \sim \int_{\RR^n} \widehat{f}(\xi) e(\xi \cdot x)\ d\xi,\quad\text{where}\quad \widehat{f}(\xi) = \int_{\RR^n} f(x) e(- \xi \cdot x)\ dx \]
%
for $\xi \in \RR^n$, where $e(t) = \exp(2 \pi i t)$ for any $t \in \RR$.

Later, we will interpret the Fourier transform in a very general manner for a very arbitrary class of functions. But first we must interpret the Fourier transform as a Lebesgue integral, and the weakest assumptions we can make in order to do this are that $f$ is an integrable function, i.e. that $f \in L^1(\RR^d)$. During arguments, we can often assume additional regularity properties of $f$, and then apply density arguments to get the result in general. Most of the properties of the Fourier transform are exactly the same as for Fourier series. The only new phenomenon in the basic theory is that the Fourier transform of an integrable function is continuous.

\begin{theorem}
	For any $f \in L^1(\RR^d)$, $\smash{\| \widehat{f} \|_{L^\infty(\RR^d)} \leq \| f \|_{L^1(\RR^d)}}$, and $\widehat{f} \in C_0(\RR^d)$.
\end{theorem}
\begin{proof}
	For any $\xi \in \RR^d$,
	%
	\[ |\widehat{f}(\xi)| = \left| \int f(x) e(- \xi \cdot x)\; dx \right| \leq \int |f(x)| |e(- \xi \cdot x)|\; dx = \| f \|_{L^1(\RR^d)}. \]
	%
	If $\chi_I$ is the characteristic function of an $n$ dimensional box, i.e.
	%
	\[ I = [a_1,b_1] \times \dots \times [a_n,b_n] = I_1 \times \dots \times I_n, \]
	%
	then
	%
	\[ \widehat{\chi_I}(\xi) = \int_I e(- \xi \cdot x) = \prod_{k = 1}^n \int_{a_k}^{b_k} e(- \xi_k x_k) = \prod_{k = 1}^n \widehat{\chi_{I_k}}(\xi_k). \]
	%
	where
	%
	\[ \widehat{\chi_{I_k}}(\xi_k) = \begin{cases} \frac{e(- \xi_k a_k) - e(- \xi_k b_k)}{2 \pi i \xi_k} & \xi_k \neq 0, \\ b_k - a_k & \xi_k = 0. \end{cases} \]
	%
	L'Hopital's rule shows $\widehat{\chi_{I_k}}$ is a continuous function. We also have the upper bound
	%
	\[ \widehat{\chi_{I_k}}(\xi_k) \lesssim_{I_k} (1 + |\xi_k|)^{-1} \]
	%
	for all $\xi_k \in \RR$, which implies that
	%
	\[ \widehat{\chi_I}(\xi) = \prod \widehat{\chi_{I_k}}(\xi_k) \lesssim_I \prod \frac{1}{1 + |\xi_k|} \lesssim_n \frac{1}{1 + |\xi|}. \]
	%
	Thus $\widehat{\chi_I}(\xi) \to 0$ as $|\xi| \to \infty$. But this implies the Fourier transform of any step function is continuous and vanishes at $\infty$. Since step functions are dense in $L^1(\RR^d)$, a density argument then gives the result for all integrable functions.
\end{proof}

\begin{remark}
	The space
	%
	\[ \mathbf{A}(\RR^d) = \left\{ \widehat{f}: f \in L^1(\RR^d) \right\} \]
	%
	is called the \emph{Fourier algebra}. The last theorem shows $\mathbf{A}(\RR^d) \subset C_0(\RR^d)$, but it is {\it not} the case that $\mathbf{A}(\RR^d) = C_0(\RR^d)$. As of yet, current research cannot give a satisfactory description of the elements of $\mathbf{A}(\RR^d)$.
\end{remark}

\begin{lemma}
	For any $0 \leq a < b < \infty$, independantly of $a$ and $b$,
	%
	\[ \left| \int_a^b \frac{\sin x}{x} \right| = O(1). \]
\end{lemma}
\begin{proof}
	Since $|\sin(x)/x| \leq 1$ for all $x$, we may assume $b > 1$, for otherwise we obtain a trivial bound. This also implies
	%
	\begin{align*}
		\left| \int_a^b \frac{\sin x}{x}\; dx \right| \leq 1 + \left| \int_1^b \frac{\sin x}{x}\; dx \right|.
	\end{align*}
	%
	An integration by parts then shows that
	%
	\[ \left| \int_1^b \frac{\sin x}{x}\; dx \right| \leq \left| \left( \cos 1 - \frac{\cos b}{b} \right) \right| + \left| \int_1^b \frac{\cos x}{x^2}\; dx \right| \lesssim 1. \qedhere \]
\end{proof}

\begin{theorem}
	$\mathbf{A}(\RR) \neq C_0(\RR)$. In particular, $\mathbf{A}(\RR)$ does not contain any odd functions $g$ in $C_0(\RR)$ such that
	%
	\[ \limsup_{b \to \infty} \left| \int_1^b \frac{g(\xi)}{\xi}\; d\xi \right| = \infty. \]
\end{theorem}
\begin{proof}
	Suppose $f \in L^1(\RR)$, and $\widehat{f} \in C_0(\RR)$ is an odd function. Then we know
	%
	\[ \widehat{f}(\xi) = -i \int_{-\infty}^\infty f(x) \sin(2 \pi \xi x)\; dx. \]
	%
	Thus an application of Fubini's theorem shows that
	%
	\[ \left| \int_1^b \frac{\widehat{f}(\xi)}{\xi}\; d\xi \right| = \left| \int_{-\infty}^\infty f(x) \left( \int_1^b \frac{\sin(2 \pi \xi x)}{\xi}\; d\xi \right)\; dx \right|. \]
	%
	But
	%
	\[ \left| \int_1^b \frac{\sin(2 \pi \xi x)}{\xi}\; d\xi \right| = \left| \int_{2 \pi x}^{2 \pi b x} \frac{\sin \xi}{\xi}\; d\xi \right| \lesssim 1. \]
	%
	Thus we obtain that
	%
	\[ \left| \int_1^b \frac{\widehat{f}(\xi)}{\xi}\; d\xi \right| \lesssim \| f \|_{L^1(\RR)}. \qedhere \]
\end{proof}

Elementary properties of integration give the following relations among the Fourier transforms of functions on $\RR^d$. They are strongly related to the translation invariance of the Lebesgue integral on $\RR^d$:
%
\begin{itemize}
	\item If $\overline{f}(x) = \overline{f(x)}$ is the conjugate of a function $f$, then
	%
	\[ (\overline{f})^\ft(\xi) = \int \overline{f(x)} e(- x \cdot \xi)\; dx = \overline{\int f(x) e(x \cdot \xi)} = \overline{\widehat{f}(-\xi)}. \]
	%
	If $f$ is real, the formula above says $\widehat{f}(\xi) = \overline{\widehat{f}(-\xi)}$, and so if we define $a(\xi) = \text{Re}(\widehat{f}(\xi))$, $b(\xi) = \text{Im}(\widehat{f}(\xi))$, then formally we have
	%
	\[ \int_{-\infty}^\infty \widehat{f}(\xi) e(\xi x)\; d\xi = 2 \int_0^\infty a(\xi) \cos(2 \pi \xi x) - b(\xi) \sin(2 \pi \xi x)\; d\xi. \]
	%
	Thus the Fourier representation formula expresses the function $f$ as an integral in sines and cosines.
	
	\item There is a duality between translation and frequency modulation. For $y \in \RR^d$, we define $(T_y f)(x) = f(x - y)$. If $\xi \in \RR^d$, then we define $(M_\xi f)(x) = e(\xi \cdot x) f(x)$. We then find that
	%
	\begin{align*}
		\widehat{T_y f}(\xi) &= \int f(x - y) e(- \xi \cdot x)\; dx\\
		&= e(- \xi \cdot y) \int f(x) e(- \xi \cdot x)\; dx = (M_{-y} \widehat{f})(\xi).
	\end{align*}
	%
	and
	%
	\begin{align*}
		\widehat{M_\xi f}(\eta) = \int e(\xi \cdot x) f(x) e(- \eta \cdot x)\; dx = \widehat{f}(\eta - \xi) = (T_\xi \widehat{f})(\eta).
	\end{align*}
	%
	Thus we conclude $\mathcal{F} \circ T_y = M_{-y} \circ \mathcal{F}$, and $\mathcal{F} \circ M_\xi = T_\xi \circ \mathcal{F}$.

	\item Let $T: \RR^d \to \RR^d$ be an invertible linear transformation. Then a change of variables $y = Tx$ gives
	%
	\begin{align*}
		\widehat{f \circ T}(\xi) &= \int f(Tx) e(-\xi \cdot x)\; dx\\
		&= \frac{1}{|\det(T)|} \int f(y) e(- \xi \cdot T^{-1}y)\; dy\\
		&= \frac{1}{|\det(T)|} \int f(y) e(- T^{-t} \xi \cdot y)\; dy\\
		&= \frac{1}{|\det(T)|} (\widehat{f} \circ T^{-t})(\xi).
	\end{align*}
	%
	Thus we conclude that if $T^*(f) = f \circ T$, then $\mathcal{F} \circ T^* = |\det(T)|^{-1} (T^{-t})^* \circ \mathcal{F}$.

	\item As a special case of the theorem above, if $a \in \RR$ and $(D_a f)(x) = f(ax)$, then
	%
	\[ \widehat{D_a f}(\xi) = a^{-d} \widehat{f}(\xi/a) \]
	%
	If we dilate by a small value of $a$, then the values of $f$ are traced over more slowly, so $D_a f$ has smaller frequencies. But the magnitude of these frequencies is increase to compensate.

	\item If $R \in O_n(\RR)$, then $\widehat{f \circ R}(\xi) = \widehat{f}(R \xi)$, i.e. $\mathcal{F} \circ R^* = R^* \circ \mathcal{F}$. In particular, if $f$ is a radial function, so $f \circ R = f$ for any $R$, then $\widehat{f}(R \xi) = \widehat{f}(\xi)$ for any $R \in O_n(\RR)$, so $\widehat{f}$ is also a radial function. If $f$ is even, so $f(x) = f(-x)$ for all $x$, then $\widehat{f}(\xi) = \widehat{f}(-\xi)$ for all $\xi$, so $\widehat{f}$ is even. Similarily, if $f$ is odd, then $\widehat{f}$ is odd.

	\item Given $f,g \in L^1(\RR^d)$, we define the convolution
	%
	\[ (f * g)(x) = \int f(y) g(x-y)\; dy. \]
	%
	This convolution possesses precisely the same properties as convolution on $\mathbf{T}$. Most importantly for us,
	%
	\[ \mathcal{F}(f * g) = \mathcal{F}(f) \cdot \mathcal{F}(g), \]
	%
	so convolution in phase space is just a product in frequency space.
\end{itemize}

Just as with Fourier series, we have a duality between decay of a function and smoothness of it's transform. We say $f$ has a {\bf strong derivative} $f_k$ in $L^p(\RR^d)$ if the family of functions
%
\[ (\Delta_h f)(x) = \frac{f(x + h e_k) - f(x)}{h} \]
%
converge in $L^p(\RR^d)$ to $f_k$. Essentially, this means that the approximations of $f$ to it's derivative quantitatively converge in the mean. If $f$ has a strong derivative in $L^p(\RR^d)$, then $f_k$ is actually differentiable almost everywhere. However, even if $f$ has a pointwise partial derivative $f_k$, the differences $\Delta_h f$ may not converge to $f_k$ fast enough to conclude that $f$ has a strong derivative. It is fairly easy to prove using the mean value theorem that if $f$ converges to $f_k$ in the $L^\infty$ norm, and $f$ has compact support, then $f$ has a strong derivative in all other $L^p$ spaces. If $f$ is not compactly supported, but decays rapidly at $\infty$, then it is often the case that the $L^p$ derivative will be the same as the classical derivative. In particular, this is true of a Schwartz function.

\begin{theorem}
	If $f \in L^1(\RR^d)$, and $x_k f \in L^1(\RR^d)$, then $\widehat{f}$ has a strong derivative in the $L^\infty$ norm, and $\widehat{f}_k(\xi) = - 2 \pi i (x_k f)^\ft(\xi)$.
\end{theorem}
\begin{proof}
	Note that a change of variables implies
	%
	\[ (\Delta_h \widehat{f})(\xi) = \int f(x) \frac{e(-h x_k) - 1}{h} e(- \xi \cdot x)\; dx = \widehat{g_h}(\xi), \]
	%
	where
	%
	\[ g_h(x) = f(x) \frac{e(h x_k) - 1}{h}. \]
	%
	Note that
	%
	\[ \left| \frac{e(h x_k) - 1}{h} \right| = O(1 + |x_k|). \]
	%
	Since $x_k f$ is integrable, we can apply the dominated convergence theorem. Because $(e(h x_k) - 1)/h$ tends to $-2 \pi i x_k f(x)$ as $h \downarrow 0$, the function $g_h$ tends to $-2\pi i x_k f$ in $L^1(\RR^d)$. Taking Fourier transforms, we conclude that $\Delta_h \widehat{f} = \widehat{g_h}$ converges uniformly to $(-2 \pi i x_k f)^\ft(\xi)$.
\end{proof}

\begin{remark}
	In particular, the Fourier transform of a compactly supported function lies in $C^\infty(\RR^d)$, and has strong derivatives of all orders.
\end{remark}

%\begin{remark}
%	If $f$ no longer has compact support, but $D_k f$ vanishes rapidly at infinity, then we can normally still establish that $D_k f$ is the derivative of $f$ in $L^1(\RR^n)$. Indeed, suppose $|(D_k f)(x)| \leq g(|x|)$, where $g$ is an increasing function with $\int_0^\infty t^{n-1} g(t) < \infty$, then surely $\Delta_h f$ converges to $D_k f$ in $L^1$ on any compact set, which implies that for any $M$, using the mean value theorem again,
	%
%	\begin{align*}
%		\int_{\RR^n} &|(\Delta_h f)(x) - D_k f(x)|\; dx \leq o_M(1) + \int_{|x| > M} |(\Delta_h f)(x)| + |D_k f(x)| \\
%		&\leq o_M(1) + O \left( \int_{|x| > M} g(|x| + |h|)\; dx \right) = o_M(1) + O \left( \int_M^\infty t^{n-1}g(t)\; dt \right)\\
%	\end{align*}
	%
%	If we choose $M$ large enough that the big $O$ term is $\leq \varepsilon$, then we find $\| \Delta_h f - D_k f \|_1 \leq \varepsilon + o_M(1)$, and taking $\varepsilon \to 0$ shows the convergence. This shows the derivatives exist if, for instance, $f$ is a Schwarz function, since then $|D_k f(x)| \lesssim 1/(1 + |x|^{n+1})$.
%\end{remark}

\begin{theorem}
	If $f$ has a strong derivative $f_k$ in the $L^1$ norm, $\widehat{f_k}(\xi) = 2 \pi i \xi_k \widehat{f}(\xi)$.
\end{theorem}
\begin{proof}
	It suffices to note that
	%
	\[ \widehat{\Delta_h f}(\xi) = \frac{e(h \xi_k) - 1}{h} \widehat{f}(\xi). \]
	%
	Since $\Delta_h f \to f_k$ in $L^1$, $\widehat{\Delta_h f} \to \widehat{f_k}$ uniformly, and in particular, converges to $\widehat{f_k}$ pointwise. But we know $\widehat{\Delta_h f}$ converges pointwise to $2 \pi i \xi_k \widehat{f}(\xi)$.
\end{proof}

%\begin{theorem}
%	If $X$ is a homogenous space of functions, the $f * K_\delta$ converges to $f$ in the norm associated with $X$.
%\end{theorem}
%\begin{proof}
%	Given a continuous function function $F: \mathbf{T} \to X$, we define the formal Riemann integral of functions as
	%
%	\[ \int_{\mathbf{T}} F(x)\; dx = \lim_{N \to \infty} \frac{1}{N} \sum_{n = 1}^N F(2 \pi /N) \]
	%
%	which exists for the same reason the Riemann integral of a continuous real valued function exists. Now we can consider the formal function theoretic convolution
	%
%	\[ \int_{\mathbf{T}} K_\delta(x) f_x\; dx \]
	%
%	This is equal to $K_\delta * f$, because the $L^1$ norm lower bounds the norm on $X$, so that the limit with respect to the $L^1$ norm is the same as with respect to the norm on $X$, and
	%
%	\[ s \]
	%
%	\[ \int_{\mathbf{T}} K_\delta(x) f_x\; dx - f = \int_0^{2\pi} K_\delta(x)[f_x - f]\; dx \]
	%
%	If we choose 
%\end{proof}
%
%More generally, if we equip a translation invariant subspace of $L^1(\RR^n)$ with a norm lower bounded up to a constant by the $L^1$ norm which turns the space into a Banach space, then $f * K_\delta$ converges to $f$ in that norm. If in addition, the $K_\delta$ satisfy $|K_\delta(x)| \lesssim \delta^{-n}$, and $|K_\delta(x)| \lesssim \delta/|x|^{n+1}$, then $f * K_\delta$ converges to $f$ almost everywhere. 

\section{Convergence Using Alternative Summation}

As we might expect from the Fourier series theory, the formula
%
\[ f(x) = \int \widehat{f}(\xi) e(\xi \cdot x)\; dx \]
%
does not hold for every integrable $f$, nor even for all continuous $f$. In particular, the Fourier transform of $f$ need not even lie in $L^1(\RR^d)$, so the integral formula may not even make sense. Nonetheless, just as with Fourier series, one can obtain general results by `dampening' the integration.

\begin{example}
	Even if $f$ is a non integrable function, the functions $f(x) e^{-\delta |x|}$ may be integrable for $\delta > 0$. We say $f$ is \emph{Abel summable} to a value $A$ if
	%
	\[ \lim_{\delta \to 0} \int f(x) e^{-\delta |x|}\; dx = A \]
	%
	For each $\delta > 0$ and $f \in L^1(\RR^d)$, we let
	%
	\[ (A_\delta f)(x) = \int \widehat{f}(\xi) e(\xi \cdot x) e^{-\delta |\xi|}\; d\xi. \]
\end{example}

If $f \in L^1(\RR^d)$, then the dominated convergence theorem implies that
%
\[ \int f(x) e^{-\delta |x|}\; dx \to \int f(x)\; dx. \]
%
so $f$ is Abel summable. However, $f$ may be Abel summable even if $f$ is not integrable. For instance, if $f(x) = \sin(x)/x$, then $f$ is not integrable, yet $f$ is Abel summable to $\pi$ over the real line.

\begin{example}
	Similarily, we can consider the Gauss sums
	%
	\[ \int f(x) e^{-\delta |x|^2}\; dx \]
	%
	We say $f$ is Gauss summable to if these values converge as $\delta \to 0$. For $f \in L^1(\RR^d)$, we let
	%
	\[ (G_\delta f)(x) = \int \widehat{f}(\xi) e(\xi \cdot x) e^{-\delta |\xi|^2}\; d\xi. \]
\end{example}

\begin{example}
	For $d = 1$, we can also consider the Fej\'{e}r sums
	%
	\[ (\sigma_\delta f)(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e(\xi \cdot x) \left( \frac{\sin(\delta \pi \xi)}{\delta \pi \xi} \right)^2\; d\xi. \]
\end{example}

\begin{example}
	In basic calculus, the integral of a function $f$ over the entire real line is defined as
	%
	\[ \int_{-\infty}^\infty f(x)\; dx = \lim_{t \to \infty} \int_{-t}^t f(x)\; dx. \]
	%
	These integrals can be written as the integral of $f \chi_{[-t,t]}$, and so in a generalized sense, we can integrate a function $f$ if $f \chi_{[-t,t]}$ is integrable for each $N$, and the integrals of these functions converge as $t \to \infty$. Thus we study
	%
	\[ (S_R f)(x) = \int_{-R}^R \widehat{f}(\xi) e(\xi \cdot x)\; d\xi. \]
\end{example}

Abel summability is more general than the piecewise limit integral considered in the last example, as the next lemma proves.

\begin{lemma}
	Suppose $f \in L^1_{\text{loc}}(\RR^d)$, that
	%
	\[ \lim_{t \to \infty} \int_{-t}^t f(x)\; dx \]
	%
	exists, and that $f(x) e^{-\delta x^2}$ is absolutely integrable for each $\delta > 0$. Then $f$ is Abel summable, and
	%
	\[ \lim_{\delta \to 0} \int_{-\infty}^\infty f(x) e^{-\delta |x|^2} = \lim_{t \to \infty} \int_{-t}^t f(x)\; dx. \]
\end{lemma}
\begin{proof}
	Let
	%
	\[ \lim_{t \to \infty} \int_{-t}^t f(x)\; dx = A. \]
	%
	For each $x \geq 0$, write
	%
	\[ F(x) = \int_{-x}^x f(x)\; dx. \]
	%
	Then $F$ is continuous, and $F(x) \to A$ as $x \to \infty$. We know that $F'(x) = f(x) + f(-x)$, and an integration by parts gives for each $s > 0$,
	%
	\begin{align*}
		\int_{-s}^s f(x) e^{-\delta x^2}\; dx &= \int_0^s [f(x) + f(-x)] e^{-\delta x^2}\; dx = F(s) e^{-\delta s^2} + 2 \delta \int_0^s x F(x) e^{-\delta x^2}\; dx.
	\end{align*}
	%
	Taking $s \to \infty$, using the fact that $F$ is bounded so that $F(s) e^{-\delta s^2} \to 0$, we conclude
	%
	\[ \int f(x) e^{-\delta x^2}\; dx = 2 \delta \int_0^\infty x F(x) e^{-\delta x^2}\; dx. \]
	Given $\varepsilon > 0$, fix $t$ such that $|F(s) - A| \leq \varepsilon$ for $s \geq t$. Then
	%
	\begin{align*}
		\left| \int f(x) e^{-\delta x^2}\; dx - A \right| &\leq 2 \delta \left| \int_0^t x F(x) e^{-\delta x^2}\; dx \right|\\
		&\quad + 2 \delta \varepsilon \left| \int_t^\infty x e^{-\delta x^2} \right|\\
		&\quad + \left| 2 \delta A \int_t^\infty x e^{-\delta x^2}\; dx - A \right|.
	\end{align*}
	%
	The first and second components of this upper bound can each be made smaller than $\varepsilon$ for small enough $\delta$. And
	%
	\[ 2 \delta \int_t^\infty x e^{-\delta x^2}\; dx = e^{-\delta t^2} \]
	%
	So the 3rd term is equal to
	%
	\[ |A| |1 - e^{-\delta t^2}| \]
	%
	and for small enough $\delta$, we can also bound this by $\varepsilon$. Thus we have shown for small enough $\delta$ that
	%
	\[ \left| \int f(x) e^{-\delta x^2}\; dx - A \right| \leq 3 \varepsilon. \]
	%
	It now suffices to take $\varepsilon \to 0$.
\end{proof}

Abel summation is even more general than Gauss summation.

\begin{lemma}
	If $f$ is Gauss summable, and $f(x) e^{-\delta |x|}$ is absolutely integrable for each $\delta > 0$, then $f$ is Abel summable, and
	%
	\[ \lim_{\delta \to 0} \int f(x) e^{-\delta |x|^2}\; dx = \lim_{\delta \to 0} \int f(x) e^{-\delta |x|}\; dx. \]
\end{lemma}
\begin{proof}
	Let
	%
	\[ \lim_{\delta \to 0} \int f(x) e^{-\delta |x|^2}\; dx = A. \]
	%
	If there existed constants $c_n$ and $\lambda_n$ such that $e^{-\delta |x|} = \sum c_n e^{-(\lambda_n \delta |x|)^2}$, this theorem would be easy. This is not exactly true, but we do have the {\it subordination principle}, which says
	%
	\[ e^{-\delta |x|} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\delta^2 |x|^2/4u}\; du. \]
	%
	This formula, which is proved using basic complex analysis, is shown later on in this chapter. Applying Fubini's theorem, this means that
	%
	\[ \int f(x) e^{-\delta |x|} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; dx\; du. \]
	%
	For any fixed $t > 0$, we certainly have
	%
	\[ \lim_{\delta \to 0} \int_t^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; dx\; du = A \int_t^\infty \frac{e^{-u}}{\sqrt{\pi u}} \]
	%
	And this is equal to $A(1 + o(1))$ as $t \to 0$. And now we calculate
	%
	\[ \int_0^t \frac{e^{-u}}{\sqrt{\pi u}} \int f(x) e^{-\delta^2 |x|^2/4u}\; du \leq \left\| \frac{e^{-u}}{\sqrt{\pi u}} \right\|_{L^1[0,t]} \left\| \int f(x) e^{-\delta^2 |x|^2/4u} \right\|_{L^\infty[0,t]} \]
	%
	The left norm tends to zero as $t \to 0$. And as $u \downarrow 0$, the dominated convergence theorem implies that
	%
	\[ \int f(x) e^{-\delta |x|^2/4u} \to 0. \]
	%
	This completes the proof.
\end{proof}

For any family of functions $\Phi_\delta$, we can consider the `$\Phi$ sums'
%
\[ \int f(x) \Phi_\delta(x)\; d\xi \]
%
and the corresponding Fourier transform operators
%
\[ S_\delta(f,\Phi)(x) = \int \widehat{f}(x) e(\xi \cdot x) \Phi_\delta(\xi)\; d\xi. \]
%
We say $f$ is $\Phi$ summable to a value if
%
\[ \int f(x) \Phi_\delta(x)\; d\xi \]
%
converges. In all the examples we will consider, we construct $\Phi$ sums by fixing a function $\Phi \in C_0(\RR^n)$ with $\Phi(0) = 1$, and defining $\Phi_\delta(x) = \Phi(\delta x)$. When this is the case $f(x) \Phi_\delta(x)$ converges to $f(x)$ pointwise for each $x$ as $\delta \to 0$. Thus if $f \in L^1(\RR^d)$, the dominated convergence theorem implies that $f$ is $\Phi$ summable to it's usual integral. We now use these summability kernels to understand the Fourier summation formula.

\begin{theorem}[The Multiplication Formula]
	If $f,g \in L^1(\RR^n)$,
	%
	\[ \int f(x) \widehat{g}(x)\; dx = \int \widehat{f}(\xi) g(\xi)\; dx. \]
\end{theorem}
\begin{proof}
	If $f, g \in L^1(\RR^n)$, then $\widehat{f}$ and $\widehat{g}$ are bounded, continuous functions on $\RR^n$. In particular, $\widehat{f} g$ and $f \widehat{g}$ are integrable. A simple use of Fubini's theorem gives
	%
	\[ \int f(x) \widehat{g}(x)\; dx = \int \int f(x) g(\xi) e(- \xi \cdot x)\; dx\; d\xi = \int g(\xi) \widehat{f}(\xi)\; d\xi. \qedhere \]
\end{proof}

If $\Phi$ is integrable, then the multiplication formula shows
%
\begin{align*}
	S_\delta(f,\Phi) &= \int \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta \xi) d\xi\\
	&= \int f(x) (M_x (\delta_\delta \Phi))^\ft(x)\; dx = \delta^{-n} \int f(x) \cdot \widehat{\Phi} \left( \frac{x - y}{\delta} \right)\; dx.
\end{align*}
%
Thus if we define $K^\Phi_\delta(x) = \delta^{-n} \widehat{\Phi}(-x/\delta)$, then $S_\delta(f,\Phi) = K^\Phi_\delta * f$. Thus we have expressed the summation operators as convolution operations.

We now recall some notions of convolution kernels that help us approximate functions. Recall that if a family of kernels $\{ K_\delta \}$ satisfies
%
\begin{itemize}
	\item For any $\delta > 0$,
	%
	\[ \int K_\delta(\xi)\; d\xi = 1. \]

	\item The values $\{ \| K_\delta \|_{L^1(\RR^n)} \}$ are uniformly bounded in $\delta$.

	\item For any $\varepsilon > 0$,
	%
	\[ \lim_{\delta \to 0} \int_{|\xi| \geq \varepsilon} |K_\delta(\xi)|\; d\xi \to 0. \]
\end{itemize}
%
then the family forms a \emph{good kernel}. If this is the case, then $f * K_\delta$ converges to $f$ in the $L^p$ norms if $f \in L^p(\RR^n)$, and converges to $f$ uniformly if $f$ is continuous and bounded. If we have the stronger conditions that
%
\begin{itemize}
	\item For any $\delta > 0$,
	%
	\[ \int K_\delta(\xi)\; d\xi = 1. \]

	\item $\| K_\delta \|_{L^\infty(\RR^d)} \lesssim 1/\delta^d$.
	\item For any $\delta > 0$ and $\xi \in \RR^d$,
	%
	\[ |K_\delta(\xi)| \lesssim \frac{\delta}{|x|^{d+1}}. \]
\end{itemize}
%
then the family $\{ K_\delta \}$ is an approximation to the identity, and so $(K_\delta * f)(x)$ converges to $f(x)$ for any $x$ in the Lebesgue set of $f$.

\begin{example}
	We obtain the {\it Fej\'{e}r kernel} $F_\delta$ from the initial function
	%
	\[ F(x) = \left( \frac{\sin \pi x}{\pi x} \right)^2 \]
	%
	Using contour integration, we now show
	%
	\[ \widehat{F}(\xi) = \begin{cases} 1 - |\xi| & : |\xi| \leq 1\\ 0 &: |\xi| > 1 \end{cases} \]
	%
	Since this functions is compactly supported, with total mass one, it is easy to see the corresponding Kernel $K^F_\delta$ are an approximation to the identity. Thus $\sigma_\delta f$ converges to $f$ in all the manners described above.

	Since $F$ is an even function, $\widehat{F}$ is even, and so we may assume $\xi \geq 0$. We initially calculate
	%
	\[ \widehat{F}(\xi) = \int_{-\infty}^\infty \left( \frac{\sin(\pi x)}{\pi x} \right)^2 e(- \xi x)\; dx = \frac{1}{\pi} \int_{-\infty}^\infty \left( \frac{\sin x}{x} \right)^2 e(- 2 \xi x) \; dx. \]
	%
	Now we have
	%
	\[ (\sin z)^2 = \left( \frac{e(z) - e(-z)}{2i} \right)^2 = \frac{(2 - e^{2iz}) - e^{-2iz}}{4}. \]
	%
	This means
	%
	\begin{align*}
		\frac{(\sin z)^2}{z^2} e^{- 2 i \xi z} &= \frac{2e^{-2 i \xi z} - e^{-2(\xi + 1) i z}) - e^{-2(\xi - 1)iz}}{4z^2 } = \frac{f_\xi(z) + g_\xi(z)}{4}.
	\end{align*}
	%
	For $\xi \geq 0$, $f_\xi(z)$ is $O_\xi(1/|z|^2)$ in the lower half plane, because if $\text{Im}(z) \leq 0$,
	%
	\[ |2e^{-2 i \xi z} - e^{-2(\xi + 1) z}| \leq 2e^{2\xi} + e^{2(\xi + 1)} = O_\xi(1). \]
	%
	For $\xi \geq 1$, $g_\xi(z)$ is also $O_\xi(1/|z|^2)$ in the lower half plane, because
	%
	\[ |e^{-2(\xi - 1)iz}| \leq e^{2(\xi - 1)}.  \]
	%
	Now since $(\sin x/x)^2 e^{-2 i \xi x}$ can be extended to an entire function on the entire complex plane, which is bounded on any horizontal strip, we can apply Cauchy's theorem and take limits to conclude that
	%
	\begin{align*}
		\widehat{F}(\xi) = \frac{1}{\pi} \int_{-\infty}^\infty \frac{(\sin x)^2}{x^2} e^{-2 i \xi x}\; dx &= \frac{1}{\pi} \int_{-\infty}^{\infty} \frac{(\sin (x - iy)^2}{(x - iy)^2} e^{-2 i \xi x  -2 \xi y}\; dx\\
		&= \frac{1}{4 \pi} \int_{-\infty}^\infty f_\xi(x - iy) + g_\xi(x - iy)\; dx.
	\end{align*}
	%
	If $\xi \geq 1$, the functions $f_\xi$ and $g_\xi$ are both negligible in the lower half plane, and have no poles in the lower half plane, so if we let $\gamma$ denote the curve of length $2 \pi n$ travelling anticlockwise along the lower semicircle with vertices $-n - iy$ and $n - iy$, then because $|z| \geq n$ on $\gamma$,
	%
	\begin{align*}
		\int_{-n}^n f_\xi(x - iy) + g_\xi(x - iy)\; dx &= \int_\gamma f_\xi(z) + g_\xi(z)\; dz\\
		&= \text{length}(\gamma) \| f_\xi + g_\xi \|_{L^\infty(\gamma)}\\
		&= (2 \pi n) O_\xi(1/n^2) = O_\xi(1/n),
	\end{align*}
	%
	and so we conclude that
	%
	\[ \int_{-\infty}^\infty f_\xi(x - iy) + g_\xi(x - iy)\; dx = 0. \]
	%
	This means $\widehat{F}(\xi) = 0$. If $0 \leq \xi \leq 1$, then $f_\xi$ is still small in the lower half plane, so we can conclude that
	%
	\[ \int_{-\infty}^\infty f_\xi(x - iy)\; dx = 0. \]
	%
	But $g_\xi$ is now small in the upper half plane. For $\text{Im}(z) \geq -y$,
	%
	\[ |e^{-2(\xi - 1)iz}| = |e^{2(1 - \xi)iz}| \leq e^{2(1 - \xi)y}, \] 
	%
	so $g_\xi(z) = O_\xi(1/|z|^2)$ in the half plane above the line $\RR - iy$. The only problem now is that $g_\xi$ has a pole in this upper half plane, at the origin. Taking Laurent series here, we find that the residue at this point is $2i(\xi - 1)$. Thus, if we let $\gamma$ be the curve obtained from travelling anticlockwise about the upper semicircle with vertices $-n - iy$ and $n - iy$, then $|z| \geq n - y$ on this curve, and the residue theorem tells us that
	%
	\[ \int_{-n}^n g_\xi(x - iy)\; dx + \int_\gamma g_\xi(z)\; dz = 2\pi i (2i(\xi - 1)) = 4 \pi (1 - \xi), \]
	%
	and we now find that, as with the evaluation of the previous case,
	%
	\[ \int_\gamma g_\xi(z)\; dz \leq (2 \pi n) O_{\xi,y}(1/n^2) = O_{\xi,y}(1/n). \]
	%
	Taking $n \to \infty$, we conclude
	%
	\[ \int_{-\infty}^\infty g_\xi(x - iy)\; dx = 4 \pi (1 - \xi), \]
	%
	and putting this all together, we conclude that $\widehat{F}(\xi) = 1 - \xi$.
%	It is interesting in this particular case to note that
	%
%	\begin{align*}
%		\int_{-1}^1 (1 - |\xi|) e^{2 \pi i\xi x}\; d\xi &= 2 \int_0^1 (1 - \xi) \cos(2 \pi \xi x)\; d\xi\\
%		&= 2 \left( \left. \frac{(1 - \xi) \sin(2 \pi \xi x)}{2 \pi x} - \frac{\cos(2 \pi \xi x)}{(2 \pi x)^2} \right|_0^1 \right)\\
%		&= 2 \frac{1 - \cos(2 \pi x)}{(2 \pi x)^2} = \frac{\sin^2(\pi x)}{(\pi x)^2} = F(x)
%	\end{align*}
	%
%	which is exactly the inversion formula we want for all $L^1$ functions.
\end{example}

\begin{example}
	In the next paragraph, we calculate that if $\Phi(x) = e^{-\pi |x|^2}$, then $\widehat{\Phi} = \Phi$. Thus if we define the \emph{Weirstrass kernel} by
	%
	\[ W_\delta(\xi) = \delta^{-d} e^{-\pi |x|^2/\delta^2}, \]
	%
	then $G_\delta(f) = W_\delta * f$. Since the family $\{ W_\delta \}$ is an approximation to the identity, this shows $G_\delta(f)$ converges to $f$ in all the appropriate senses.

	Since $\Phi$ breaks onto products of exponentials over each coordinate, it suffices to calculate the Fourier transform in one dimension, from which we can obtain the general transform by taking products. In the one dimensional case, since $\Phi'(x) = -2 \pi x e^{- \pi x^2}$ is integrable, we conclude that $\widehat{\Phi}$ is differentiable, and
	%
	\[ (\widehat{\Phi})'(\xi) = (- 2 \pi i \xi \Phi)^\ft(\xi) = i (\Phi')^\ft(\xi) = i (2 \pi i \xi) \widehat{\Phi}(\xi) = - 2 \pi \xi \widehat{\Phi}(\xi) \]
	%
	The uniqueness theorem for ordinary differential equations says that since
	%
	\[ \widehat{\Phi}(0) = \int_{-\infty}^\infty e^{- \pi x^2} = 1 = \Phi(0) \]
	%
	Thus we must have $\widehat{\Phi} = \Phi$.
\end{example}

\begin{example}
	The Fourier transform of the function $e^{- |x|}$ is the \emph{Poisson kernel}
	%
	\[ P(\xi) = \frac{\Gamma((d+1)/2)}{(\pi(1 + |\xi|^2))^{(d+1)/2}} \]
	%
	Later on we show the corresponding scaled kernel $\{ P_\delta \}$ is an approximation to the identity, and thus $A_\delta f = P_\delta * f$ converges to $f$ in all appropriate senses.

	The Abel kernel $A_\delta$ on $\RR^n$ is obtained from the initial function $A(x) = e^{-2 \pi |x|}$. The calculation of the Fourier transform of this function indicates a useful principle in Fourier analysis: one can reduce expressions involving $e^{-x}$ into expressions involving $\smash{e^{-x^2}}$ using the subordination principle. In particular, for $\beta > 0$ we have the formula
	%
	\[ e^{-\beta} = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\beta^2/4u}\; du \]
	%
	We establish this by letting $v = \sqrt{u}$, so
	%
	\[ \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{-\beta^2/4u}\; du = \frac{2}{\sqrt{\pi}} \int_0^\infty e^{-v^2 - \beta^2/4v^2}\; dv = \frac{2e^{-\beta}}{\sqrt{\pi}} \int_0^\infty e^{-(v - \beta/2v)^2}\; dv \]
	%
	But the map $v \mapsto v - \beta/2v$ is measure preserving by Glasser's master theorem, so this integral is
	%
	\[ \frac{2e^{-\beta}}{\sqrt{\pi}} \int_0^\infty e^{-v^2}\; dv = e^{-\beta} \]
	%Because using the theory of residues,
	%
	%\begin{align*}
	%	e^{-\beta} &= \frac{2}{\pi} \int_0^\infty \frac{\cos \beta x}{1 + x^2} = \frac{1}{\pi} \int_{-\infty}^\infty \frac{e^{\beta i x}}{1 + x^2}\; dx\; du\\
	%	&= \frac{1}{\pi} \int_{-\infty}^\infty e^{\beta i x} \int_0^\infty e^{-u} e^{-ux^2}\; du\; dx\\
	%	&= \frac{1}{\pi} \int_0^\infty e^{-u} \int_{-\infty}^\infty e^{-ux^2} e^{\beta i x}\; dx\; du\\
	%	&= \frac{1}{\pi} \int_0^\infty \sqrt{\pi/u} e^{-u} e^{-\beta^2/4u}\; du
	%\end{align*}
	%
	In tandem with Fubini's theorem, this formula implies
	%
	\begin{align*}
		\widehat{A}(\xi) &= \int e^{-2 \pi |x|} e^{- 2 \pi i \xi \cdot x}\; dx = \int \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} e^{- |\pi x|^2/u} e^{-2 \pi i \xi \cdot x}\; du\; dx\\
		&= \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} \int e^{-|\pi x|^2/u} e^{-2 \pi i \xi \cdot x}\; dx\; du = \int_0^\infty \frac{e^{-u}}{\sqrt{\pi u}} (\delta_{\sqrt{\pi/u}} \Phi)^\ft(\xi)\; du\\
		&= \frac{1}{\pi^{(n + 1)/2}} \int_0^\infty e^{-u} u^{(n-1)/2} e^{- u|\xi|^2}\; du
	\end{align*}
	%
	Setting $v = (1 + |\xi|^2) u$, we conclude that since by definition,
	%
	\[ \int_0^\infty e^{-v} v^{(n-1)/2} = \Gamma \left( \frac{n+1}{2} \right) \]
	%
	\[ \widehat{A}(\xi) = \frac{\Gamma((n+1)/2)}{[\pi(1 + |\xi|^2)]^{(n+1)/2}} \]
	%
	Thus the Abel mean is the Fourier inverse of the Poisson kernel on the upper half plane $\mathbf{H}^{n+1}$.

	In order to conclude $\{ P_\delta \}$ is a good kernel, it now suffices to verify that
	%
	\[ \int_{\RR^n} \frac{d\xi}{(1 + |\xi|^2)^{(n+1)/2}} = \frac{\pi^{(n+1)/2}}{\Gamma((n+1)/2)} \]
	%
	The right hand side is half the surface area of the unit sphere in $\RR^{n+1}$. Denoting this quantity by $S_n$, and switching to polar coordinates, we find that
	%
	\[ \int_{\RR^n} \frac{d\xi}{(1 + |\xi|^2)^{(n+1)/2}} = S_{n-1} \int_0^\infty \frac{r^{n-1}}{(1 + r^2)^{(n+1)/2}}\; dr \]
	%
	Setting $r = \tan u$, we find
	%
	\[ \int_0^\infty \frac{r^{n-1}}{(1 + r^2)^{(n+1)/2}}\; dr = \int_0^{\pi/2} (\sin u)^{n-1} du \]
	%
	The theorem now follows from noticing that $S_{n-1} (\sin u)^{n-1}$ is the surface area of the $n-1$ sphere obtained by slicing $S^n$ with the hyperplane $x_n = \cos u$. Fubini's theorem implies that the integral is $S_n/2$, which is what we wanted to verify.
\end{example}

\begin{example}
	We note that
	%
	\[ \int_{-R}^R e(- \xi x)\; dx = \frac{e(- \xi R) - e(\xi R)}{-2 \pi i \xi} = \frac{\sin(2 \pi \xi R)}{\pi \xi}. \]
	%
	so the Fourier transform of $\chi_{[-R,R]}$ is the \emph{Dirichlet kernel}
	%
	\[ D_R(\xi) = \frac{\sin(2 \pi \xi R)}{\pi \xi} \]
	%
	We note that $D_R \not \in L^1(\mathbf{R})$. Thus $D_R$ is {\it not} a good kernel, which makes the convergence rates of $S_R f$ more subtle. Nonetheless, $D_R$ does lie in $L^p(\mathbf{R})$ for all $p > 1$, and is \emph{uniformly bounded} in $L^p(\mathbf{R})$ for all $1 < p < \infty$. This is enough to conclude that for all $1 < p < \infty$, $S_R f \to f$ in $L^p(\mathbf{R})$.
\end{example}

Thus we now know there are a large examples of functions $\Phi \in C_0(\RR^d)$ with $\Phi(0) = 1$, and such that for any $x$ in the Lebesgue set of $f$,
%
\[ f(x) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta x). \]
%
If $\widehat{f}$ is integrable, then the bound $| \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta \xi) | \leq \| \Phi \|_\infty | \widehat{f}(\xi) |$ implies that we can use the dominated convergence theorem to conclude that for any point $x$ in the Lebesgue set of $f$,
%
\[ f(x) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e(\xi \cdot x) \Phi(\delta x) = \int \widehat{f}(\xi) e(\xi \cdot x) \]
%
Thus the inversion theorem holds pointwise almost everywhere.

\begin{theorem}
	If $f$ and $\widehat{f}$, then for any $x$ in the Lebesgue set of $f$,
	%
	\[ f(x) = \int \widehat{f}(\xi) e(\xi \cdot x)\; d\xi. \]
\end{theorem}

We define, for any integrable $f: \RR^n \to \RR$, the \emph{inverse} Fourier transform
%
\[ \widecheck{f}(x) = \int f(\xi) e(\xi \cdot x)\; d\xi \]
%
The inverse transform is also denoted by $\mathcal{F}^{-1}(f)$. The last theorem says that $\mathcal{F}^{-1}$ really is the inverse operator to the operator $\mathcal{F}$, at least on the set of functions $f$ where $\widehat{f}$ is integrable. In particular, this is true if $f$ has strong derivatives in the $L^1$ norm for any multi-index $|\alpha| \leq n+1$, and so the Fourier inversion formula holds for sufficiently smooth functions.

\begin{corollary}
	If $f \in C(\RR)$ is integrable and $\widehat{f} \in L^1(\RR)$, $S_R f \to f$  uniformly.
\end{corollary}
\begin{proof}
	Since $f \in C(\RR$
	The dominated convergence theorem implies that for each $x \in\RR$,
	%
	\[ f(x) = \int_{\RR^n} \widehat{f}(\xi) e(\xi \cdot x) = \lim_{R \to \infty} \int_{-R}^R \widehat{f}(\xi) e(\xi \cdot x) = \lim_{R \to \infty} (S_R f)(x). \]
	%
	And
	%
	\[ \int_{|x| \geq R} \widehat{f}(\xi) e(\xi \cdot x) \leq \| \widehat{f} \|_{L^1(\RR)}. \]
	%
	so the pointwise convergence is uniform.
\end{proof}

\begin{remark}
	This theorem also generalizes to $\RR^n$. Here, the operators $S_R$ are no longer canonically defined, but if we consider any increasing nested family of sets $B_R$ with $\lim B_R = \RR^n$, then the corresponding operators
	%
	\[ S_R f = \int_{B_R} \widehat{f}(\xi) e(\xi \cdot x) \]
	%
	also converge uniformly to $f$.
\end{remark}

\begin{corollary}
	The map $\mathcal{F}: L^1(\RR^d) \to C_0(\RR^d)$ is injective.
\end{corollary}
\begin{proof}
	If $\widehat{f} = 0$, then $\widehat{f}$ is certainly integrable. But this means that the Fourier inversion theorem can apply, giving that for almost every point $x$,
	%
	\[ f(x) = \int_{-\infty}^\infty \widehat{f}(x) e(\xi \cdot x) = 0. \]
	%
	Thus $f = 0$ almost everywhere.
\end{proof}

This corollary is underestimated in utility. Even if the Fourier inversion theorem doesn't hold, we can still view the Fourier transform as another way to represent a function, since the Fourier transform does not lose any information. For instance, it can be used very easily to verify identities involving convolutions.

\begin{corollary}
	For any $\delta_1, \delta_2$,
	%
	\[ W_{\delta_1 + \delta_2} = W_{\delta_1} * W_{\delta_2}\quad\text{and}\quad P_{\delta_1 + \delta_2} = P_{\delta_1} * P_{\delta_2}. \]
\end{corollary}
\begin{proof}
	We recall that
	%
	\[ W_{\delta_1 + \delta_2} = \mathcal{F}(e^{-(\delta_1 + \delta_2) |x|^2}). \]
	%
	But $e^{-(\delta_1 + \delta_2) |x|^2} = e^{-\delta_1 |x|^2} e^{-\delta_2 |x|^2}$ breaks into a product, which allows us to calculate
	%
	\[ \mathcal{F}(e^{-\pi \delta_1 |x|^2} e^{-\pi \delta_2 |x|^2}) = \mathcal{F}(e^{-\pi \delta_1 |x|^2}) * \mathcal{F}(e^{-\pi \delta_2 |x|^2}) = W_{\delta_1} * W_{\delta_2}.  \]
	%
	Thus $W_{\delta_1} * W_{\delta_2} = W_{\delta_1 + \delta_2}$. Similarily, $P_{\delta_1 + \delta_2}$ is the Fourier transform of $e^{-(\delta_1 + \delta_2)|x|}$, which breaks into a product, whose individual Fourier transforms are $P_{\delta_1}$ and $P_{\delta_2}$.
\end{proof}

% TODO: Prove using De la Vallee Poisson that if f^(xi) = O(1/|xi|), then S_R f converges uniformly.

%\begin{theorem}
%	If $f$ is an integrable, function continuous at the origin, and $\widehat{f} \geq 0$, then $\widehat{f}$ is integrable.
%\end{theorem}
%\begin{proof}
%	This follows because
	%
%	\[ f(0) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e^{-\delta |x|} \]
	%
%	By Fatou's lemma,
	%
%	\[ f(0) = \lim_{\delta \to 0} \int \widehat{f}(\xi) e^{-\delta |x|} \geq \int \liminf_{\delta \to 0} \widehat{f}(\xi) e^{-\delta |x|} = \int \widehat{f}(\xi) \]
	%
%	so $\widehat{f}$ is finitely integrable.
%\end{proof}

%Note that this implies that we obtain the general inversion theorem, so in particular, it is only continuous functions, and functions almost everywhere equal to continuous functions, which can have non-negative Fourier transforms.

\section{The $L^2$ Theory}

One integral component of Fourier series on $L^2(\mathbf{T})$ is Plancherel's equality
%
\[ \sum |\widehat{f}(n)|^2 = \frac{1}{2\pi} \int_0^{2\pi} |f(x)|^2 \]
%
On $\RR^n$, we would like to justify that
%
\[ \int |\widehat{f}(\xi)|^2\; d\xi = \int |f(x)|^2\; dx \]
%
However, on the non-compact Euclidean space, a general element of $L^2(\RR^n)$ is not necessarily integrable, so we cannot take it's Fourier transform using the integral formula. Nonetheless, we can take the Fourier transform of an element of $L^1(\RR^n) \cap L^2(\RR^n)$, and we find the equation holds.

\begin{theorem}
	If $f \in L^1(\RR^n) \cap L^2(\RR^n)$, then $\| \widehat{f} \|_2 = \| f \|_2$.
\end{theorem}
\begin{proof}
	The theorem is an easy consequence of the multiplication formula, since
	%
	\[ |\widehat{f}(\xi)| = \widehat{f}(\xi) \overline{\widehat{f}}(\xi), \]
	%
	and
	%
	\[ \left( \overline{\widehat{f}} \right)^\ft(\xi) = \overline{(f^\ft)^\ft(-\xi)} = \overline{f(\xi)}. \]
	%
	This implies
	%
	\[ \int |\widehat{f}(\xi)|^2\; d\xi = \int \widehat{f}(\xi) \overline{\widehat{f}(\xi)}\; d\xi = \int f(x) \overline{f(x)}\; dx = \int |f(x)|^2\; dx. \qedhere \]
\end{proof}

A simple interpolation argument leads to the following corollary, which is a variant of the Hausdorff-Young inequality for functions on $\RR^n$.

\begin{corollary} If $f \in L^1(\RR^n) \cap L^p(\RR^n)$ for $1 \leq p \leq 2$, then
	%
	\[ \| \widehat{f} \|_{L^q(\RR^n)} \leq \| f \|_{L^p(\RR^n)}. \]
	%
	where $2 \leq q \leq \infty$ is the conjugate of $p$.
\end{corollary}

Though the integral formula of an element of $L^2(\RR^n)$ does not make sense, the bounds above provide a canonical way to define the Fourier transform of an element of $L^p(\RR^n)$, for $1 \leq p \leq 2$. The space $L^1(\RR^n) \cap L^p(\RR^n)$ is a dense subset of $L^p(\RR^n)$, so we can use the Hahn-Banach theorem to define the Fourier transform $\mathcal{F}: L^p(\RR^n) \to L^q(\RR^n)$ as the {\it unique} bounded operator agreeing with the integral formula on the common domain. The extended Fourier transform on $L^2(\RR^n)$ is still unitary, because the multiplication formula extends to $L^2(\RR^n)$, so that
%
\[ (\mathcal{F}(f),g) = \int \widehat{f}(\xi) \overline{g(\xi)}\; d\xi = \int f(x) \overline{\widehat{g}(-\xi)}\; dx = (f,\mathcal{F}^{-1}(g)). \]
%
Thus the adjoint of $\mathcal{F}$ is $\mathcal{F}^{-1}$, which means exactly that $\mathcal{F}$ is unitary.

\begin{remark}
	Later on, we will justify the definition of the Fourier transform on an element of $L^p(\RR^n)$, for $2 \leq p \leq \infty$, using the theory of distributions.
\end{remark}


\section{The Hausdorff-Young Inequality}

For functions on $\mathbf{T}$, it is unclear how to provide examples which show why the Hausdorff-Young inequality cannot be extended to give results for $p > 2$. Over $\RR$, we can provide examples which explicitly indicate the tightness of the appropriate constants.

\begin{example}
	Given an integrable function $f$, let $f_r(x) = f(rx)$. Then we find $\widehat{f_r}(\xi) = r^{-n} \widehat{f}(\xi/r)$, and so
	%
	\[ \| f_r \|_{L^p(\RR^n)} = r^{-n/p} \| f \|_{L^p(\RR^n)} \quad \text{and} \quad \| \widehat{f_r} \|_{L^q(\RR^n)} = r^{n/q-n} \| \widehat{f} \|_{L^q(\RR^n)}. \]
	%
	In order for a bound to hold in terms of $p$ and $q$ uniformly for all values of $r$, we need $r^{-n/p} = r^{n/q-n}$, which means $1/q + 1/p = 1$, so $p$ and $q$ must be conjugates of one another.
\end{example}

\begin{example}
	Consider the family of functions $f_s(x) = s^{-n/2} e^{- \pi |x|^2/s}$, where $s = 1 + it$ for some $t \in \RR$. One can easily calcluate that $\widehat{f_s}(\xi) = e^{- \pi s |\xi|^2}$. We calculate
	%
	\[ \| f_s \|_{L^p(\RR^n)} = |s|^{-n/2} \left( \int e^{- (p/|s|^2) \pi |x|^2}\; dx \right)^{1/p} = |s|^{n/p - n/2} p^{-n/p} \]
	%
	whereas $\| \widehat{f_s} \|_q = q^{-n/2}$. Thus to be able  compare the two quantities as $t \to \infty$, we need $n/p - n/2 \leq 0$, so $p \leq 2$. As $t \to \infty$, $\smash{|f_s(x)| \sim t^{-n/2} e^{-\pi |x/t|^2}}$, so the $t$ gives us a decay in $f_s$. However, when we take the Fourier transform the $t$ only corresponds to oscillatory terms. Thus we need $p \leq 2$ so that the decay in $t$ isn't too important in relation to the overall width of the function.
\end{example}

The Hausdorff-Young inequality shows that the Fourier transforms narrowly supported functions into a function with small magnitude. But the example above shows that the Fourier transform is not so good at transforming functions with small magnitude into functions which are narrowly supported, because the Fourier transform can absorb the small magnitude into an oscillatory property not reflected in the norms. Some kind of way of measuring oscillation needs to be considered to get a tighter control on the function. Of course, in hindsight, we should have never expected too much control of the Fourier transform in terms of the $L^p$ norms, since the Fourier transform measures the oscillatory nature of the input function, and oscillatory properties of a function in phase space are not very well reflected in the $L^p$ norms, except when applying certain orthogonality properties with an $L^2$ norm, or destroying the oscillation with an $L^\infty$ norm.

\section{The Poisson Summation Formula}

\section{The Gibbs Phenomenon}

\section{Sums of Random Variables}

We now switch to an application of harmonic analysis to studying sums of random variables probability theory. If $X$ is a random vector, it's probabilistic information is given by it's distribution on $\RR^n$, which can be seen as a measure $\mathbf{P}_X$ on $\RR^n$, with $\mathbf{P}_X(E) = \mathbf{P}(X \in E)$. Given two independant random vectors $X$ and $Y$, $\mathbf{P}_{X+Y}$ is the convolution $\mathbf{P}_X * \mathbf{P}_Y$ between the measures $\mathbf{P}_X$ and $\mathbf{P}_Y$, in the sense that
%
\[ \mathbf{P}_{X+Y}(E) = \int \chi_E(x+y)\; d\mathbf{P}_X(x)\; d\mathbf{P}_Y(y) \]
%
If $d\mathbf{P}_X = f_X \cdot dx$ and $d\mathbf{P}_Y = f_Y \cdot dx$, then $d(\mathbf{P}_X * \mathbf{P}_Y) = (f_X * f_Y) \cdot dx$ is just the normal convolution of functions. This is why harmonic analysis becomes so useful when analyzing sums of independant random variables.

It is useful to express the Fourier transform in a probabilistic language. Given a random variable $X$,
%
\[ \widehat{\mathbf{P}_X}(\xi) = \int e^{i \xi \cdot x} d\mathbf{P}_X(x) \]
%
Thus the natural Fourier transform of a random vector $X$ is the {\bf characteristic function} $\varphi_X(\xi) = \mathbf{E}(e^{i \xi \cdot X})$. It is a continuous function for any random variable $X$. We can also express the properties of the Fourier transform in a probabilistic language.

\begin{lemma}
	Let $X$ and $Y$ be independant random variables. Then
	%
	\begin{itemize}
		\item $\varphi_X(0) = 1$, and $|\varphi_X(\xi)| \leq 1$ for all $\xi$.

		\item (Symmetry) $\varphi_X(\xi) = \overline{\varphi_X(-\xi)}$.

		\item (Convolution) $\varphi_{X+Y} = \varphi_X \varphi_Y$.

		\item (Translation and Dilation) $\varphi_{X+a}(\xi) = e^{i a \cdot \xi} \varphi_X(\xi)$, and $\varphi_{\lambda X}(\xi) = \varphi_X(\lambda \xi)$.

		\item (Rotations) If $R \in O(n)$ is a rotation, then $\varphi_{R(X)}(\xi) = \varphi_X(R(X))$.
	\end{itemize}
\end{lemma}

Using the Fourier inversion formula, if $\varphi_X$ is integrable, then $X$ is a continuous random variable, with density
%
\[ f(x) = \int e^{- i \xi x} \varphi_X(\xi)\; d\xi \]
%
In particular, if $\varphi_X = \varphi_Y$, then $X$ and $Y$ are identically distributed. This already gives interesting results.

\begin{theorem}
	If $X$ and $Y$ are independant normal distributions, then $aX + bY$ is normally distributed.
\end{theorem}
\begin{proof}
	Since $\varphi_{aX+bY}(\xi) = \varphi_X(a \xi) \varphi_Y(b \xi)$, it suffices to show that the product of two such characteristic functions is the characteristic function of a normal distribution. If $X$ has mean $\mu$ and covariance matrix $\Sigma$, then $X \cdot \xi$ has mean $\mu \cdot \xi$ and variance $\xi^T \Sigma \xi$, and one calculates that $\mathbf{E}[e^{i \xi \cdot X}] = e^{- i \mu \cdot \xi - \xi^T \Sigma \xi / 2}$ using similar techniques to the Fourier transform of a Gaussian. One verifies that the class of functions of the form $e^{-i \mu \cdot \xi - \xi^T \Sigma \xi / 2}$ is certainly closed under multiplication and scaling, which completes the proof. 
\end{proof}

Now we can prove the celebrated central limit theorem. Note that if

\begin{theorem}
	Let $X_1, \dots, X_N$ be independant and identically distributed with mean zero and variance $\sigma^2$. If $S_N = X_1 + \dots + X_N$, then
	%
	\[ \mathbf{P}(S_N \leq \sigma \sqrt{N} t) \to \Phi(t) = \frac{1}{\sqrt{2x}} \int_{-\infty}^t e^{-y^2/2}\; dy \]
\end{theorem}
\begin{proof}
	We calculate that
	%
	\[ \varphi_{S_N/\sigma \sqrt{N}}(\xi) = \varphi_X(\xi/\sigma \sqrt{N})^N \]
	%
	Define $R_n(x) = e^{ix} - 1 - (ix) - (ix)^2/2 - \dots - (ix)^n/n!$. Then because of oscillation and the fundamental theorem of calculus,
	%
	\[ |R_0(x)| = \left| i \int_0^x e^{iy}\; dy \right| \leq \min(2,|x|) \]
	%
	Next, since $R_{n+1}'(x) = i R_n$,
	%
	\[ R_{n+1}(x) = i  \int_0^x R_n(y)\; dy \]
	%
	This gives that $|R_n(x)| \leq \min(2|x|^n/n!,|x|^{n+1}/(n+1)!)$. In particular, we conclude
	%
	\[ |\varphi_X(\xi) - 1 - \sigma^2 \xi^2/2| = |\mathbf{E}(R_2(\xi X))| \leq \mathbf{E}|R_2(\xi X)| \leq |\xi|^2 \mathbf{E} \left( \min \left( |X|^2, |\xi X|^3/6 \right) \right) \]
	%
	By the dominated convergence theorem, as $\xi \to 0$, $\varphi_X(\xi) = 1 - \xi^2 \sigma^2/2 + o(\xi^2)$. But this means that
	%
	\[ \varphi_{S_N/\sigma \sqrt{N}}(\xi) = (1 - \xi^2 / 2 N + o(\xi^2/\sigma^2 N))^N = \exp(-\xi^2/2) \]
	%
	This implies the random variables converge weakly to a normal distribution.
\end{proof}

\section{Transforms of Holomorphic Functions}

An interesting thing about the Fourier transform on the real line is that we can apply both real-variable techniques and complex analytic techniques to the study. Just as smoothness of a function corresponded to polynomial decay in it's Fourier transform, we will find that analyticity corresponds to an exponential decay. We let $S_a = \{ z \in \mathbf{C}: |\text{Im}(z)| < a \}$ denote the horizontal strip.

\begin{theorem}
	Let $f$ be holomorphic on $S_a$, integrable on each horizontal line contained in the strip, and such that $f(z) \to 0$ as $|\text{Re}(z)| \to \infty$. Then we find $|\widehat{f}(\xi)| \lesssim_b e^{-2\pi b |\xi|}$ for any $b < a$.
\end{theorem}
\begin{proof}
	For any $b < a$, $R$, and $\xi > 0$, consider the contour $\gamma_R$ obtained from the rectangle $-R$, $R$, $-R-ib$, and $R-ib$. As $R \to \infty$, the integral along the vertical lines of the rectangle tends to zero as $R \to \infty$, so we conclude that
	%
	\begin{align*}
		\int_{-\infty}^\infty f(x)e^{-2\pi i x \xi}\; dx &= \int_{-\infty}^\infty f(x-ib)e^{- 2 \pi i (x - ib) \xi}\; dx\\
		&= e^{-2 \pi i b \xi} \int_{-\infty}^\infty f(x-ib) e^{- 2 \pi i \xi x}\; dx = e^{-2 \pi i b \xi} \widehat{f_b}(\xi)
	\end{align*}
	%
	where $f_b(x) = f(x - ib)$. Thus it suffices to show $|\widehat{f_b}(\xi) - \widehat{f}(\xi)| \lesssim_b 1$. But this follows because we certainly have $\| f_b - f \|_\infty < \infty$ since both functions are bounded, which completes the proof in this case. A similar estimate for $\xi < 0$ also gives the general result.
\end{proof}

It follows that $\widehat{f}$ has exponential decay if $f$ satisfies the hypothesis of the theorem. Thus we can always apply the inverse Fourier transform to conclude
%
\[ f(x) = \int_{-\infty}^\infty \widehat{f}(\xi) e(\xi x)\; d\xi \]
%
In this case, we can actually {\it prove} the equation using complex analysis. 

\begin{theorem}
	A
\end{theorem}
\begin{proof}
	As in the last theorem, the sign of $\xi$ matters. We write
	%
	\[ \int_{-\infty}^\infty \widehat{f}(\xi) e^{2} \]
\end{proof}

\section{Characteristic Functions}




\chapter{Finite Character Theory}

Let us review our achievements so far. We have found several important families of functions on the spaces we have studied, and shown they can be used to approximate arbitrary functions. On the circle group $\mathbf{T}$, the functions take the form of the power maps $\phi_n: z \mapsto z^n$, for $n \in \mathbf{Z}$. The important properties of these functions is that
%
\begin{itemize}
    \item The functions are orthogonal to one another.
    \item A large family of functions can be approximated by linear combinations of the power maps.
    \item The power maps are multiplicative: $\phi_n(zw) = \phi_n(z) \phi_n(w)$.
\end{itemize}
%
The existence of a family with these properties is not dependant on much more than the symmetry properties of $\mathbf{T}$, and we can therefore generalize the properties of the fourier series to a large number of groups. In this chapter, we consider a generalization to any finite abelian group.

The last property of the power maps should be immediately recognizable to any student of group theory. It implies the exponentials are homomorphisms from the circle group to itself. This is the easiest of the three properties to generalize to arbitrary groups; we shall call a homomorphism from a finite abelian group to $\mathbf{T}$ a {\bf character}. For any abelian group $G$, we can put all characters together to form the character group $\Gamma(G)$, which forms an abelian group under pointwise multiplication $(fg)(z) = f(z)g(z)$. It is these functions which are `primitive' in synthesizing functions defined on the group.

\begin{example}
    If $\mu_N$ is the set of $N$th roots of unity, then $\Gamma(\mu_N)$ consists of the power maps $\phi_n: z \mapsto z^n$, for $n \in \mathbf{Z}$. Because
    %
    \[ \phi(\omega)^N = \phi(\omega^N) = \phi(1) = 1 \]
    %
    we see that any character on $\mu_N$ is really a homomorphism from $\mu_N$ to $\mu_N$. Since the homomorphisms on $\mu_N$ are determined by their action on this primitive root, there can only be at most $N$ characters on $\mu_N$, since there are only $N$ elements in $\mu_N$. Our derivation then shows us that the $\phi_N$ enumerate all such characters, which completes our proof. Note that since $\phi_n \phi_m = \phi_{n+m}$, and $\phi_n = \phi_m$ if and only if $n - m$ is divisible by $N$, this also shows that $\Gamma(\mu_N) \cong \mu_N$.
\end{example}

\begin{example}
    The group $\mathbf{Z}_N$ is isomorphic to $\mu_N$ under the identification $n \mapsto \omega^n$, where $\omega$ is a primitive root of unity. This means that we do not need to distinguish functions `defined in terms of $n$' and `defined in terms of $\omega$', assuming the correspondance $n = \omega^n$. This is exactly the same as the correspondence between functions on $\mathbf{T}$ and periodic functions on $\RR$. The characters of $\mathbf{Z}_n$ are then exactly the maps $n \mapsto \omega^{kn}$. This follows from the general fact that if $f: G \to H$ is an isomorphism of abelian groups, the map $f^*: \phi \mapsto \phi \circ f$ is an isomorphism from $\Gamma(H)$ to $\Gamma(G)$.
\end{example}

\begin{example}
    If $K$ is a finite field, then the set $K^*$ of non-zero elements is a group under multiplication. A rather sneaky algebraic proof shows the existence of elements of $K$, known as primitive elements, which generate the multiplicative group of all numbers. Thus $K$ is cyclic, and therefore isomorphic to $\mu_N$, where $N = |K| - 1$. The characters of $K$ are then easily found under the correspondence.
\end{example}

\begin{example}
    For a fixed $N$, the set of invertible elements of $\mathbf{Z}_N$ form a group under multiplication, denoted $\mathbf{Z}_N^*$. Any character from $\mathbf{Z}_N^*$ is valued on the $\varphi(N)$'th roots of unity, because the order of each element in $\mathbf{Z}_N^*$ divides $\varphi(N)$. The groups are in general non-cyclic. For instance, $\mathbf{Z}_8^* \cong \mathbf{Z}_2^3$. However, we can always break down a finite abelian group into cyclic subgroups to calculate the character group; a simple argument shows that $\Gamma(G \times H) \cong \Gamma(G) \times \Gamma(H)$, where we identify $(f,g)$ with the map $(x,y) \mapsto f(x)g(y)$.
\end{example}

\section{Fourier Analysis on Cyclic Groups}

We shall start our study of abstract Fourier analysis by looking at Fourier analysis on $\mu_N$. Geometrically, these points uniformly distribute themselves over $\mathbf{T}$, and therefore $\mu_N$ provides a good finite approximation to $\mathbf{T}$. Functions from $\mu_N$ to $\mathbf{C}$ are really just functions from $[n] = \{ 1, \dots, n \}$ to $\mathbf{C}$, and since $\mu_N$ is isomorphic to $\mathbf{Z}_N$, we're really computing the Fourier analysis of finite domain functions, in a way which encodes the translational symmetry of the function relative to translational shifts on $\mathbf{Z}_N$.

There is a trick which we can use to obtain quick results about Fourier analysis on $\mu_N$. Given a function $f: [N] \to \mathbf{C}$, consider the $N$-periodic function on the real line defined by
%
\[ g(t) = \sum_{n = 1}^N f(n) \chi_{(n-1/2,n+1/2)}(t) \]
%
Classical Fourier analysis of $g$ tells us that we can expand $g$ as an infinite series in the functions $e(n/N)$, which may be summed up over equivalence classes modulo $N$ to give a finite expansion of the function $f$. Thus we conclude that every function $f: [N] \to \mathbf{C}$ has an expansion
%
\[ f(n) = \sum_{m = 1}^N \widehat{f}(m) e(nm) \]
%
where $\widehat{f}(m)$ are the coefficients of the {\bf finite Fourier transform} of $f$. This method certainly works in this case, but does not generalize to understand the expansion of general finite abelian groups.

The correct generalization of Fourier analysis is to analyze the set of complex valued `square integrable functions' on the domain $[N]$. We consider the space $V$ of all maps $f: [N] \to \mathbf{C}$, which can be made into an inner product space by defining
%
\[ \langle f, g \rangle = \frac{1}{N} \sum_{n = 1}^N f(n) \overline{g(n)} \]
%
We claim that the characters $\phi_n: z \mapsto z^n$ are orthonormal in this space, since
%
\[ \langle \phi_n, \phi_m \rangle = \frac{1}{N} \sum_{k = 1}^N \omega^{k(n-m)} \]
%
If $n = m$, we may sum up to find $\langle \phi_n, \phi_m \rangle = 1$. Otherwise we use a standard summation formula to find
%
\[ \sum_{k = 1}^N \omega^{k(n-m)} = \omega^{n-m} \frac{\omega^{N(n-m)} - 1}{\omega^{n-m} -1} \]
%
Since $\omega^{N(n-m)} = 1$, we conclude the sum is zero. This implies that the $\phi_n$ are orthonormal, hence linearly independent. Since $V$ is $N$ dimensional, this implies that the family of characters forms an orthogonal basic for the space. Thus, for any function $f: [N] \to \mathbf{C}$, we have, if we set $\widehat{f}(m) = \langle f, \phi_m \rangle$, then
%
\[ f(n) = \sum_{m = 1}^N \langle f, \phi_m \rangle \phi_m(n) = \sum_{m = 1}^N \widehat{f}(m) e(mn/N) \]
%
This calculation can essentially be applied to an arbitrary finite abelian group to obtain an expansion in terms of Fourier coefficients.

\section{An Arbitrary Finite Abelian Group}

It should be easy to guess how we proceed for a general finite abelian group. Given some group $G$, we study the character group $\Gamma(G)$, and how $\Gamma(G)$ represents general functions from $G$ to $\mathbf{C}$. We shall let $V$ be the space of all such functions from $G$ to $\mathbf{C}$, and on it we define the inner product
%
\[ \langle f, g \rangle = \frac{1}{|G|} \sum_{a \in G} f(a) \overline{g(a)} \]
%
If there's any justice in the world, these characters would also form an orthonormal basis.

\begin{theorem}
    The set $\Gamma(G)$ of characters is an orthonormal set.
\end{theorem}
\begin{proof}
    If $e$ is a character of $G$, then $|e(a)| = 1$ for each $a$, and so
    %
    \[ \langle e, e \rangle = \frac{1}{|G|} \sum_{a \in G} |e(a)| = 1 \]
    %
    If $e \neq 1$ is a non-trivial character, then $\sum_{a \in G} e(a) = 0$. To see this, note that for any $b \in G$, the map $a \mapsto ba$ is a bijection of $G$, and so
    %
    \[ e(b) \sum_{a \in G} e(a) = \sum_{a \in G} e(ba) = \sum_{a \in G} e(a) \]
    %
    Implying either $e(b) = 1$, or $\sum_{a \in G} e(a) = 0$. If $e_1 \neq e_2$ are two characters, then
    %
    \[ \langle e_1, e_2 \rangle = \frac{1}{|G|} \sum_{a \in G} \frac{e_1(a)}{e_2(a)} = 0 \]
    %
    since $e_1/e_2$ is a nontrivial character.
\end{proof}

Because elements of $\Gamma(G)$ are orthonormal, they are linearly independent over the space of functions on $G$, and we obtain a bound $|\Gamma(G)| \leq |G|$. All that remains is to show equality. This can be shown very simply by applying the structure theorem for finite abelian groups. First, note it is true for all cyclic groups. Second, note that if it is true for two groups $G$ and $H$, it is true for $G \times H$, because
%
\[ \Gamma(G \times H) \cong \Gamma(G) \times \Gamma(H) \]
%
since a finite abelian group is a finite product of cyclic groups, this proves the theorem. This seems almost like sweeping the algebra of the situation under the rug, however, so we will prove the statement only using elementary linear algebra. What's more, these linear algebraic techniques generalize to the theory of unitary representations in harmonic analysis over infinite groups.

\begin{theorem}
    Let $\{ T_1, \dots, T_n \}$ be a family of commuting unitary matrices. Then there is a basis $v_1, \dots, v_m \in \mathbf{C}^m$ which are eigenvectors for each $T_i$.
\end{theorem}
\begin{proof}
    For $n = 1$, the theorem is the standard spectral theorem. For induction, suppose that the $T_1, \dots, T_{k-1}$ are simultaneously diagonalizable. Write
    %
    \[ \mathbf{C}^m = V_{\lambda_1} \oplus \dots \oplus V_{\lambda_l} \]
    %
    where $\lambda_i$ are the eigenvalues of $T_k$, and $V_{\lambda_i}$ are the corresponding eigenspaces. Then if $v \in V_{\lambda_i}$, and $j < k$,
    %
    \[ T_k T_j v = T_j T_k v = \lambda_i T_j v \]
    %
    so $T_j(V_{\lambda_i}) = V_{\lambda_i}$. Now on each $V_{\lambda_i}$, we may apply the induction hypotheis to diagonalize the $T_1, \dots, T_{k-1}$. Putting this together, we simultaneously diagonalize $T_1, \dots, T_k$.
\end{proof}

This theorem enables us to prove the character theory in a much simpler manner. Let $V$ be the space of complex valued functions on $G$, and define, for $a \in G$, the map $(T_a f)(b) = f(ab)$. $V$ has an orthonormal basic consisting of the $\chi_a(b) = N [a = b]$, for $a \in G$. In this basis, we comcpute $T_a \chi_b = \chi_{ba^{-1}}$, hence $T_a$ is a permutation matrix with respect to this basis, hence unitary. The operators $T_a$ commute, since $T_aT_b = T_{ab} = T_{ba} = T_b T_a$. Hence these operators can be simultaneously diagonalized. That is, there is a family $e_1, \dots, e_n \in V$ and $\lambda_{an} \in \mathbf{T}$ such that for each $a \in G$, $T_a e_n = \lambda_{an} f_n$. We may assume $e_n(1) = 1$ for each $n$ by normalizing. Then, for any $a \in G$, we have $f_n(a) = f_n(a \cdot 1) = \lambda_{an} f_n(1) = \lambda_{an}$, so for any $b \in G$, $f_n(ab) = \lambda_{an} f_n(b) = f_n(a) f_n(b)$. This shows each $f_n$ is a character, completing the proof. We summarize our discussion in the following theorem.

\begin{theorem}
    Let $G$ be a finite abelian group. Then $\Gamma(G) \cong G$, and forms an orthonormal basis for the space of complex valued functions on $G$. For any function $f: G \to \mathbf{C}$,
    %
    \[ f(a) = \sum_{e \in \Gamma(G)} \langle f, e \rangle\ e(a) = \sum_{e \in \Gamma(G)} \hat{f}(e) e(a)\ \ \ \ \ \langle f, g \rangle = \frac{1}{|G|} \sum_{a \in G} f(a) \overline{g(a)} \]
    %
    In this context, we also have Parseval's theorem
    %
    \[ \| f(a) \|^2 = \sum_{e \in \hat{G}} |\widehat{f}(e)|^2\ \ \ \ \ \langle f, g \rangle = \sum_{e \in \hat{G}} \widehat{f}(e) \overline{\widehat{g}(e)} \]
\end{theorem}

\section{Convolutions}

There is a version of convolutions for finite functions, which is analogous to the convolutions on $\RR$. Given two functions $f,g$ on $G$, we define a function $f * g$ on $G$ by setting
%
\[ (f * g)(a) = \frac{1}{|G|} \sum_{b \in G} f(b) g(b^{-1} a) \]
%
The mapping $b \mapsto ab^{-1}$ is a bijection of $G$, and so we also have
%
\[ (f * g)(a) = \frac{1}{|G|} \sum_{b \in G} f(ab^{-1}) g(b) = (g * f)(a) \]
%
For $e \in \Gamma(G)$,
%
\begin{align*}
    \widehat{f * g}(e) &= \frac{1}{|G|} \sum_{a \in G} (f*g)(a) \overline{e(a)}\\
    &= \frac{1}{|G|^2} \sum_{a,b \in G} f(ab) g(b^{-1}) \overline{e(a)}
\end{align*}
%
The bijection $a \mapsto ab^{-1}$ shows that
%
\begin{align*}
    \widehat{f*g}(e) &= \frac{1}{|G|^2} \sum_{a,b} f(a) g(b^{-1}) \overline{e(a)} \overline{e(b^{-1})}\\
    &= \frac{1}{|G|} \left( \sum_a f(a) \overline{e(a)} \right) \frac{1}{|G|} \left( \sum_b g(b) \overline{e(b)} \right)\\
    &= \widehat{f}(e) \widehat{g}(e)
\end{align*}
%
In the finite case we do not need approximations to the identity, for we have an identity for convolution. Define $D: G \to \mathbf{C}$ by
%
\[ D(a) = \sum_{e \in \Gamma(G)} e(a) \]
%
We claim that $D(a) = |G|$ if $a = 1$, and $D(a) = 0$ otherwise. Note that since $|G| = |\Gamma(G)|$, the character space of $\Gamma(G)$ is isomorphic to $G$. Indeed, for each $a \in G$, we have the maps $\widehat{a}: e \mapsto e(a)$, which is a character of $\Gamma(G)$. Suppose $e(a) = 1$ for all characters $e$. Then $e(a) = e(1)$ for all characters $e$, and for any function $f: G \to \mathbf{C}$, we have $f(a) = f(1)$, implying $a = 1$. Thus we obtain $|G|$ distinct maps $\widehat{a}$, which therefore form the space of all characters. It therefore follows from a previous argument that if $a \neq 1$, then
%
\[ \sum_{e \in \Gamma(G)} e(a) = 0 \]
%
Now $f * D = f$, because
%
\[ \widehat{D}(e) = \frac{1}{|G|} \sum_{a \in G} D(a) \overline{e(a)} = \overline{e}(1) = 1 \]
%
$D$ is essentially the finite dimensional version of the Dirac delta function, since it has unit mass, and acts as the identity in convolution.

\section{The Fast Fourier Transform}

The main use of the fourier series on $\mu_n$ in applied mathematics is to approximate the Fourier transform on $\mathbf{T}$, where we need to compute integrals explicitly. If we have a function $f \in L^1(\mathbf{T})$, then $f$ may be approximated in $L^1(\mathbf{T})$ by step functions of the form
%
\[ f_n(t) = \sum_{k = 1}^{n} a_k \mathbf{I}(x \in (2 \pi (k-1) / n, 2 \pi k / n)) \]
%
And then $\widehat{f_n} \to \widehat{f}$ uniformly. The Fourier transform of $f_n$ is the same as the Fourier transform of the corresponding function $k \mapsto a_k$ on $\mathbf{Z}_n$, and thus we can approximate the Fourier transform on $\mathbf{T}$ by a discrete computation on $\mathbf{Z}_n$. Looking at the formula in the definition of the discrete transform, we find that we can compute the Fourier coefficients of a function $f: \mathbf{Z}_n \to \mathbf{C}$ in $O(n^2)$ addition and multiplication operations. It turns out that there is a much better method of computation which employs a divide and conquer approach, which works when $n$ is a power of 2, reducing the calculation to $O(n \log n)$ multiplications. Before this process was discovered, calculation of Fourier transforms was seen as a computation to avoid wherever possible.

To see this, consider a particular division in the group $\mathbf{Z}_{2n}$. Given $f: \mathbf{Z}_{2n} \to \mathbf{C}$, define two functions $g,h: \mathbf{Z}_n \to \mathbf{C}$, defined by $g(k) = f(2k)$, and $h(k) = f(2k + 1)$. Then $g$ and $h$ encode all the information in $f$, and if $\nu = e(\pi/n)$ is the canonical generator of $\mathbf{Z}_{2n}$, we have
%
\[ \hat{f}(m) = \frac{\hat{g}(m) + \hat{h}(m) \nu^m}{2} \]
%
Because
%
\begin{align*}
    \frac{1}{2n} \sum_{k = 1}^{n} \left( g(k) \omega^{-km} + h(m) \omega^{-km} \nu^m \right) &= \frac{1}{2n} \sum_{k = 1}^n f(2k) \nu^{-2km} + f(2k + 1) \nu^{-(2k+1)m}\\
    &= \frac{1}{2n} \sum_{k = 1}^{2n} f(k) \nu^{-km}
\end{align*}
%
This is essentially a discrete analogue of the Poission summation formula, which we will generalize later when we study the harmonic analysis of abelian groups. If $H(m)$ is the number of operations needed to calculate the Fourier transform of a function on $\mu_{2^n}$ using the above recursive formula, then the above relation tells us $H(2m) = 2H(m) + 3 (2m)$. If $G(n) = H(2^n)$, then $G(n) = 2G(n-1) + 3 2^n$, and $G(0) = 1$, and it follows that
%
\[ G(n) = 2^n + 3 \sum_{k = 1}^n 2^{k} 2^{n-k} = 2^n(1 + 3n) \]
%
Hence for $m = 2^n$, we have $H(m) = m(1 + 3 \log (m)) = O(m \log m)$. Similar techniques show that one can compute the inverse Fourier transform in $O(m \log m)$ operations (essentially by swapping the root $\nu$ with $\nu^{-1}$).

\section{Dirichlet's Theorem}

We now apply the theory of Fourier series on finite abelian groups to prove Dirichlet's theorem.

\begin{theorem}
    If $m$ and $n$ are relatively prime, then the set
    %
    \[ \{ m + kn : k \in \mathbf{N} \} \]
    %
    contains infinitely many prime numbers.
\end{theorem}

An exploration of this requries the Riemann-Zeta function, defined by
%
\[ \zeta(s) = \sum_{n = 1}^\infty \frac{1}{n^s} \]
%
The function is defined on $(1,\infty)$, since for $s > 1$ the map $t \mapsto 1/t^s$ is decreasing, and so
%
\[ \sum_{n = 1}^\infty \frac{1}{n^s} \leq 1 + \int_{1}^\infty \frac{1}{t^s} = 1 + \lim_{n \to \infty} \frac{1}{s-1} \left[1 - 1/n^{s-1} \right] = 1 + \frac{1}{s-1} \]
%
The series converges uniformly on $[1+\varepsilon, N]$ for any $\varepsilon > 0$, so $\zeta$ is continuous on $(1,\infty)$. As $t \to 1$, $\zeta(t) \to \infty$, because $n^s \to n$ for each $n$, and if for a fixed $M$ we make $s$ close enough to $1$ such that $|n/n^s - 1|<  1/2$ for $1 \leq n \leq M$, then
%
\[ \sum_{n = 1}^\infty \frac{1}{n^s} \geq \sum_{n = 1}^M \frac{1}{n^s} = \sum_{n = 1}^M \frac{1}{n} \frac{n}{n^s} \geq \frac{1}{2} \sum_{n = 1}^M \frac{1}{n} \]
%
Letting $M \to \infty$, we obtain that $\sum_{n = 1}^\infty \frac{1}{n^s} \to \infty$ as $s \to 1$.

The Riemann-Zeta function is very good at giving us information about the prime integers, because it encodes much of the information about the prime numbers.

\begin{theorem}
    For any $s > 1$,
    %
    \[ \zeta(s) = \prod_{p\ \text{prime}} \frac{1}{1 - p^s} \]
\end{theorem}
\begin{proof}
    The general idea is this -- we may write
    %
    \[ \prod_{p\ \text{prime}} \frac{1}{1 - p^s} = \prod_{p\ \text{prime}} (1 + 1/p^{s} + 1/p^{2s} + \dots) \]
    %
    If we expand this product out formally, enumating the primes to be $p_1, p_2, \dots$, we find
    %
    \[ \prod_{p \leq n} (1 + 1/p^s + 1/p^{2s} + \dots) = \sum_{n_1, n_2, \dots = 0}^\infty \frac{1}{p_1^{n_1}} \]
\end{proof}
















\chapter{Applications}

\section{The Wirtinger Inequality on an Interval}

\begin{theorem}
    Given $f \in C^1[-\pi,\pi]$ with $\int_{-\pi}^\pi f(t) dt = 0$,
    %
    \[ \int_{-\pi}^\pi |f(t)|^2 \leq \int_{-\pi}^\pi |f'(t)|^2 \]
\end{theorem}
\begin{proof}
    Consider the fourier series
    %
    \[ f(t) \sim \sum a_n e_n(t)\ \ \ \ \ f'(t) \sim \sum in a_n e_n(t) \]
    %
    Then $a_0 = 0$, and so
    %
    \[ \int_{-\pi}^\pi |f(t)|^2\ dt = 2 \pi \sum |a_n|^2 \leq 2 \pi \sum n^2 |a_n|^2 = \int_{-\pi}^\pi |f'(t)|^2\ dt \]
    %
    equality holds here if and only if $a_i = 0$ for $i > 1$, in which case we find
    %
    \[ f(t) = A e_n(t) + \overline{A} e_n(-t) = B \cos(t) + C \sin(t) \]
    %
    for some constants $A \in \mathbf{C}$, $B,C \in \RR$.
\end{proof}

\begin{corollary}
    Given $f \in C^1[a,b]$ with $\int_a^b f(t)\ dt = 0$,
    %
    \[ \int_a^b |f(t)|^2 dt \leq \left(\frac{b-a}{\pi}\right)^2 \int_a^b |f'(t)|^2\ dt \]
\end{corollary}

\section{Energy Preservation in the String equation}

Solutions to the string equation are

If $u(t,x)$

\section{Harmonic Functions} 

The study of a function $f$ defined on the real line can often be understood by extending it's definition holomorphically to the complex plane. Here we will extend this tool, establishing that a large family of functions $f$ defined on $\RR^n$ can be understood by looking at a {\it harmonic} function on the upper half plane $\mathbf{H}^{n+1}$, which approximates $f$ at it's boundary. This is a form of the Dirichlet problem, which asks, given a domain and a function on the domain's boundary, to find a function harmonic on the interior of the domain which `agrees' with the function on the boundary, in one of several senses. As we saw in our study of harmonic functions on the disk in the study of Fourier series, we can study such harmonic functions by convolving $f$ with an appropriate approximation to the identity which makes the function harmonic in the plane. In this case, we shall use the Poisson kernel for the upper half plane.

\begin{theorem}
	If $f \in L^p(\RR^n)$, for $1 \leq p \leq \infty$, and $u(x,y) = (f * P_y)(x)$, where
	%
	\[ P_y(x) = \frac{\Gamma((n+1)/2)}{\pi^{(n+1)/2}} \frac{1}{(1 + |x|^2)^{(n+1)/2}} \]
	%
	then $u$ is harmonic in the upper half plane, $u(x,y) \to f(x)$ for almost every $x$, and $u(\cdot,y)$ converges to $f$ in $L^p$ as $y \to 0$, with $\| u(\cdot,y) \|_{L^p(\RR^n)} \leq \| f \|_{L^p(\RR^n)}$. If, instead, $f$ is a continuous and bounded function, then $u(\cdot,y)$ converges to $f$ locally uniformly as $y \to 0$.
\end{theorem}
\begin{proof}
	The almost everywhere convergence and convergence in norm follow from the fact that $P_y$ is an approximation to the identity. The fact that $u$ is harmonic follows because
	%
	\[ u_{xx}(x,y) = (f * P_y'')(x)\ \ \ \ \ u_{yy} = (f * ) \]
\end{proof}


















\part{Euclidean Harmonic Analysis}

Here we employ the more modern techniques of functional analysis to understand the more advanced and technical portions of Fourier analysis, and related problems. Rather than focusing on the qualities of particular functions, we employ key tools from functional analysis. But different from basic functional analysis, where soft analysis is key, in harmonic analysis we are most interested in hard estimates. Thus we are interested in quantitative estimates on the properties of operators on function spaces. Key to this is the employment of certain operator norms which quantify a control on the qualitative properties of functions, be they their height, their width, their derivative, and many other more quantifiable properties.








\chapter{Monotone Rearrangement Invariant Norms}

Often in analysis, a problem occurs where one must understand how a quantitative control on the properties of a function, e.g. it's oscillation or growth at $\infty$, implies a control on the properties of a related object, i.e. the decay of it's derivative. The most analytically sound way to understand these controls is with respect to a {\it norm}, a quantitative measure of some property of a function which behaves well under the operations of addition and multiplication. Here we discuss the {\it rearrangement invariant} norms, those norms such that if $\Phi: Y \to X$ is a measure preserving bijection of the measure spaces $X$ and $Y$, then $f$ and $f \circ \Phi$ should have the same norm. Furthermore, we study {\it monotone} norms, so if $|f| \leq |g|$, the norm of $f$ should be smaller than the norm of $g$. Really, the only properties such a norm can reflect are the functions typical amplitude, or \emph{height}, and it's \emph{width}, i.e. the measure of the set where the majority of the amplitude is distributed. These two properties are not precisely defined, and so the rearrangement invariant norms quantify them in various different ways. In a particular problem, one picks the norm best emphasizing the features useful in a problem, often chosen by optimizing over a large family of norms.

Aside from decreasing functions, there are also two very useful classes of functions useful for testing the behaviour of an operator pointwise:
%
\begin{itemize}
    \item The \emph{indicator functions} $\mathbf{I}_E(x) = \mathbf{I}(x \in E)$, for a measurable set $E$.
    \item The \emph{simple functions} $f = \sum_{i = 1}^n a_i \mathbf{I}_{E_i}$, for disjoint sets $E_i$.
\end{itemize}
%
With respect to any of the norms we encounter in this chapter, the vector space of step functions will be dense, and we will often use these functions to test the behaviour of certain operators.

\section{The $L^p$ norms}

The most important family of measurable function are those which are integrable, i.e. such that
%
\[ \int |f(x)|\; dx < \infty. \]
%
This condition already places a control over the height and width of $f$; the function cannot be too large, except on a small set, and also must have the large majority of it's mass on a small set. The condition
%
\[ \int |f(x)|^2\; dx < \infty \]
%
also places a certain amount of control over the height and width of a function $f$, but now the height is controlled more tightly than the width, since the portions of the domain where $f$ is large are magnified in $|f(x)|^2$, and the portions of the domain where $f$ is small are made more negligible. More generally, for any $p > 0$, the condition
%
\begin{equation} \label{LpIntegrabilityCondition}
  \int |f(x)|^p\; dx < \infty
\end{equation}
%
controls the height and width of a function, and we define the space $L^p(X)$ as the family of measurable functions $f: X \to \mathbf{C}$ satisfying \eqref{LpIntegrabilityCondition}. The norm
%
\[ \| f \|_p = \left( \int |f|^p \right)^{1/p} \]
%
quantifies the width and height of $f$. The importance of taking the $p$'th root is useful for the stability of the norm, so $\| \lambda f \|_p = |\lambda| \| f \|_p$.

\begin{example}
  If $f(x) = |x|^{-\alpha}$ for $x \in \mathbf{R}^d$, then integration by radial coordinates shows that
  %
  \[ \int_{\varepsilon \leq |x| \leq M} |f(x)|^p\; dx \sim_d \int_\varepsilon^M r^{d-1 - p\alpha}\; dr = \frac{M^{d - p \alpha} - \varepsilon^{d - p \alpha}}{d - p \alpha}. \]
  %
  This quantity remains finite as $\varepsilon \to 0$ if and only if $d > p \alpha$, and finite as we let $M \to \infty$ if and only if $d < p \alpha$. Thus if $p < d/\alpha$, $f$ is \emph{locally} in $L^p$, or in $L^p(B)$ for every bounded $B \subset \mathbf{R}^d$. Conversely, if $p > d/\alpha$, then for every domain $B$ with $d(B,0) > 0$, $f \in L^p(B)$.
\end{example}

The last example shows that, roughly speaking, control on the $L^p$ norm of a function for large values of $p$ prevents the formation of large singularities of the function, and control of the norm for small values of $p$ ensures that functions have large decay at infinity.

\begin{example}
  If $f = A \chi_E$, and we set $H = |A|$ and $W = |E|$, then $\| f \|_p = W^{1/p} H$. As $p \to \infty$, the value of $\| f \|_p$ depends more and more on $H$, and less on $W$, and in fact $\lim_{p \to \infty} \| f \|_p = H$. If $f = \sum A_n \chi_{E_n}$, and $|A_m|$ is the largest constant from all other values $A_n$, then as $p$ becomes large, $|A_m|^p$ overwhelms all other terms. We calculate that as $p \to \infty$,
  %
  \[ \| f \|_p = \left( \sum |E_n| |A_n|^p \right)^{1/p} = |A_m|^p (|E_m| + o(1))^{1/p} = |A_m| (1 + o(1)). \]
  %
  This implies $\| f \|_p \to |A_m|$ as $p \to \infty$. But as $p \to 0$, the power of $1/p$ works against us, so that $\| f \|_p$ rarely converges to any universal quantity. We can conclude that $\lim_{p \to 0} \| f \|_p^p = \sum |E_n|$, so the width of the function becomes more and more emphasized.
\end{example}

As $p \to \infty$, the width of a function is disregarded completely by the $L^p$ norm, motivating the definition of \emph{the $L^\infty$ norm}; Given a measurable $f$, we define $\| f \|_\infty$ to be the smallest number such that $|f| \leq \| f \|_\infty$ almost surely. We then define $L^\infty(X)$ to be the space of measurable functions $f$ for which $\| f \|_\infty < \infty$. We have already shown $\| f \|_p \to \| f \|_\infty$ if $s$ is a simple function, and the density of such functions, combined with some functional analysis, shows that if $f \in L^p(X) \cap L^\infty(X)$ for any $p > 0$, $\| f \|_q \to \| f \|_\infty$ as $q \to \infty$.

Sometimes, authors also define $\| f \|_0 = | \text{supp} f | = | \{ x: f(x) \neq 0 \} |$, but this is really a `zeroeth power' of the $L^0$ norm. Because of this, most of the nice norm properties of the $L^p$ spaces are broken. For instance, $\| \cdot \|_0$ is no longer homogenous, i.e. if $\lambda \neq 0$, $\| \lambda f \|_0 = \| f \|_0$. It does satisfy the triangle inequality though; $\| f + g \|_0 \leq \| f \|_0 + \| g \|_0$, which follows from elementary considerations, or because $\| f + g \|_p^p \leq \| f \|_p^p + \| g \|_p^p$ when $p < 1$.

\begin{example}
  Let $p < q$, and suppose $f \in L^p(X) \cap L^q(X)$. For any $r \in (p,q)$, the $L^r$ norm emphasizes the height of $f$ less than the $L^q$ norm, and emphasizes the width of $f$ less than the $L^p$ norm. In particular, we find that for any $\lambda \geq 0$,
  %
  \begin{align*}
    \| f \|_r^r = \int_{\mathbf{R}} |f(x)|^r\; dx &= \int_{|f(x)| \leq 1} |f(x)|^r\; dx + \int_{|f(x)| > 1} |f(x)|^r\; dx\\
    &\leq \int_{|f(x)| \leq 1} |f(x)|^p\; dx + \int_{|f(x)| > 1} |f(x)|^q\; dx\\
    &\leq \| f \|_p^p + \| f \|_q^q < \infty.
  \end{align*}
  %
  In particular, this shows $f \in L^r(X)$.
\end{example}

\begin{remark}
    The bound obtained in the last example can be improved by using scaling symmetries. For any $A > 0$,
    %
    \[ \| f \|_r^r = \frac{\| Af \|_r^r}{A^r} \leq \frac{\| Af \|_p^p + \| Af \|_q^q}{A^r} \leq \frac{A^p \| f \|_p^p + A^q \| f \|_q^q}{A^r}. \]
    %
    If $1/r = \theta/p + (1 - \theta)/q$, and we set $A = \| f \|_q^{q/(p-q)} / \| f \|_p^{p/(p-q)}$, then the above inequality implies $\| f \|_r \leq 2 \| f \|_p^\theta \| f \|_q^{1 - \theta}$, which is a homogenous equality. The constant 2 can be removed in the equation using the {\it tensor power trick}. If we consider the function on $(\mathbf{R}^d)^n$ defined by $f^{\otimes n}(x_1, \dots, x_n) = f(x_1) \dots f(x_n)$, then $\| f^{\otimes n} \|_r = \| f \|_r^n$, and so
    %
    \[ \| f \|_r = \| f^{\otimes n} \|_r^{1/n} \leq \left( 2 \| f^{\otimes n} \|_p \| f^{\otimes n} \|_q \right)^{1/n} = 2^{1/n} \| f \|_p \| g \|_q. \]
    %
    We can then take $n \to \infty$ to conclude that $\| f \|_r \leq \| f \|_p \| f \|_q$.
\end{remark}

The argument in the last remark is an instance of \emph{real interpolation}; In order to conclude some fact about a function which lies `between' two other functions we know how to deal with, we split the function up into two parts lying in the other spaces, deal with them separately, and then put them back together to get some equality. One can then apply various symmetry considerations (homogeneity and the tensor power trick being two examples) to eliminate extraneous constants. We now also show how to prove this inequality using convexity, which illustrates another core technique of the field. In the next theorem, $1/\infty = 0$.

\begin{theorem}[H\"{o}lder]
  If $0 < p,q \leq \infty$ and $1/p + 1/q = 1/r$, $\| f g \|_r \leq \| f \|_p \| g \|_q$.
\end{theorem}
\begin{proof}
  The case where $p$ or $q$ is $\infty$ is left as an exercise to the reader. In the other case, by moving around exponents, we may simplify to the case where $r = 1$. The theorem depends on the log convexity inequality, such that for $A,B \geq 0$ and $0 \leq \theta \leq 1$, $A^\theta B^{1 - \theta} \leq \theta A + (1 - \theta) B$. But since the logarithm is concave, we calculate
  %
  \[ \log(A^\theta B^{1 - \theta}) = \theta \log A + (1 - \theta) \log B \leq \log(\theta A + (1 - \theta) B), \]
  %
  and we can then exponentiate. To prove H\"{o}lder's inequality, by scaling $f$ and $g$, which is fine by homogeneity, we may assume that $\| f \|_p = \| g \|_q = 1$. Then we calculate
  %
  \begin{align*}
    \| f g \|_1 &= \int |f(x)| |g(x)| = \int |f(x)|^{p/p} |g(x)|^{q/q}\\
    &\leq \int \frac{|f(x)|^p}{p} + \frac{|g(x)|^q}{q} = \frac{1}{p} + \frac{1}{q} = 1 = \| f \|_p \| g \|_q.
  \end{align*}
  %
  If $p = \infty$, $q = 1$, then the inequality is trivial, since we have the pointwise inequality $|f(x) g(x)| \leq \| f \|_\infty |g(x)|$ almost everywhere, which we can then integrate.
\end{proof}

\begin{remark}
  Note that $A^\theta B^{1-\theta} \leq \theta A + (1 - \theta) B$ is an \emph{equality} if and only if $A = B$, or $\theta \in \{ 0, 1 \}$. In particular, following through the proof above shows that if $\| f \|_p = \| g \|_q = 1$, we must have $|f(x)|^{1/p} = |g(x)|^{1/q}$ almost everywhere. In general, this means H\"{o}lder's inequality is sharp if and only if $|f(x)|^{1/p}$ is a constant multiple of $|g(x)|^{1/q}$.
\end{remark}

The next inequality is known as the \emph{triangle inequality}.

\begin{corollary}
  Given $f$,$g$, and $p \geq 1$, $\| f + g \|_p \leq \| f \|_p + \| g \|_p$.
\end{corollary}
\begin{proof}
  The inequality when $p = 1$ is obtained by integrating the inequality $|f(x) + g(x)| \leq |f(x)| + |g(x)|$, and the case $p = \infty$ is equally trivial. When $1 < p < \infty$, by scaling we can assume that $\| f \|_p + \| g \|_p = 1$. Then we can apply H\"{o}lder's inequality combined with the $p = 1$ case to conclude
  %
  \begin{align*}
    \int |f(x) + g(x)|^p &\leq \int |f(x)| |f(x) + g(x)|^{p-1} + |g(x)| |f(x) + g(x)|^{p-1}\\
    &\leq \| f \|_p \| (f + g)^{p-1} \|_q + \| g \|_p \| (f + g)^{p-1} \|_q = \| f + g \|_{p}^{p-1}
  \end{align*}
  %
  Thus $\| f + g \|_p^p \leq \| f + g \|_p^{p-1}$, and simplifying gives $\| f + g \|_p \leq 1$.
\end{proof}

\begin{remark}
  Suppose $\| f + g \|_p = \| f \| + \| g \|_p$. Following through the proof given above shows that both applications of H\"{o}lder's inequality must be sharp. And this is true if and only if $|f(x)|^p$ and $|g(x)|^p$ are scalar multiples of $|f(x) + g(x)|^p$ almost everywhere. But this means $|f(x)|$ and $|g(x)|$ are scalar multiples of $|f(x) + g(x)|$. If $|f(x)| = A|f(x) + g(x)|$ and $|g(x)| = B|f(x) + g(x)|$. If $g \neq 0$, this implies there is $C$ such that $|f(x)| = C |g(x)|$ for some $C > 0$. Thus we can write $f(x) = C e^{i \theta(x)} g(x)$, and we must have
  %
  \[ \| f + g \|_p^p = \int |1 + C e^{i \theta(x)}|^p |g(x)|^p = (1 + C)^p \int |g(x)|^p \]
  %
  so $|1 + Ce^{i \theta(x)}| = |1 + C|$ almost everywhere but this can only be true if $e^{i \theta(x)} = 1$ almost everywhere, so $f = C g$. Thus the triangle inequality is only sharp is $f$ and $g$ are positive scalar multiples of one another.
\end{remark}

This discussion leads to a useful heuristic: Unless $f$ and $g$ are `aligned' in a certain way, the triangle inequality is rarely sharp. For instance, if $f$ and $g$ have disjoint support, we calculate that
%
\[ \| f + g \|_p = \left( \| f \|_p^p + \| g \|_p^p \right)^{1/p} \]
%
For $p > 1$, this is always sharper than the triangle inequality.

\begin{remark}
  If $p < 1$, then the proof above no longer works, and in fact, is no longer true. In fact, if $f$ and $g$ are non-negative functions, then we actually have the \emph{anti} triangle inequality
  %
  \[ \| f + g \|_p \geq \| f \|_p + \| g \|_p. \]
\end{remark}

\begin{theorem}
    If $p \geq 1$, then for any positive functions $f_1, \dots, f_N$,
    %
    \begin{equation} \label{triangleInequality} ( \| f_1 \|_p^p + \dots + \| f_N \|_p^p )^{1/p} \leq \| f_1 + \dots + f_N \|_p \leq \| f_1 \|_p + \dots + \| f_N \|_p. \end{equation}
    %
    If $p \leq 1$, then the inequality reverses, i.e. for any positive functions $f_1, \dots, f_N$,
    %
    \begin{equation} \label{antiTriangleInequality} \| f_1 \|_p + \dots + \| f_N \|_p \leq \| f_1 + \dots + f_N \|_p \leq (\| f_1 \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \end{equation}
\end{theorem}
\begin{proof}
    The upper bound in \ref{triangleInequality} is just obtained by applying the triangle inequality iteratively. To obtain the lower bound, we note that for $A_1, \dots, A_N \geq 0$,
    %
    \[ (A_1 + \dots + A_N)^p \geq A_1^p + \dots + A_N^p, \]
    %
    One can prove this from induction from the inequality $(A_1 + A_2)^p \geq A_1^p + A_2^p$, which holds when $A_2 = 0$, and the derivative of the left hand side is greater than the right hand side for all $A_2 \geq 0$. But then setting $A_k = f_k$ and then integrating gives
    %
    \[ \| f_1 + \dots + f_N \|_p^p \geq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \]
    %
    Now assume $0 < p < 1$. We begin by proving the lower bound in \ref{antiTriangleInequality}. We can assume $N = 2$, and $\| f_1 \|_p + \| f_2 \|_p = 1$, and then it suffices to show $\| f_1 + f_2 \|_p \geq 1$. For any $\theta \in (0,1)$, and $A,B \geq 0$, concavity implies
    %
    \[ (A + B)^p = (\theta (A/\theta) + (1 - \theta) (B/(1-\theta)))^p \geq \theta^{1-p} A^p + (1 - \theta)^{1-p} B^p. \]
    %
    Thus setting $A = f_1(x)$, $B = f_2(x)$, and $\theta = \| f_1 \|_p$, so that $1 - \theta = \| f_2 \|_p$, and then integrating, we find
    %
    \[ \| f_1 + f_2 \|_p^p \geq \theta + (1 - \theta) = 1. \]
    %
    On the other hand, the inequality $(A_1 + \dots + A_N)^p \leq A_1^p + \dots + A_N^p$, which holds for $A_1, \dots, A_N \geq 0$, can be applied with $f_k = A_k$ and integrated to yield
    %
    \[ \| f_1 + \dots + f_N \|_p^p \leq \| f_1 \|_p^p + \dots + \| f_N \|_p^p. \qedhere \]
\end{proof}

Thus the triangle inequality is not satisfied for the $L^p$ norms when $p < 1$. This is one of the deficiencies which leads the $L^p$ theories for $0 < p < 1$ to be rather deficient when compared to the case with $p \geq 1$. This can be fixed in many ways, most notably to harmonic analysts, using the theory of Hardy spaces. On the other hand, we do have a \emph{quasi} triangle inequality.

\begin{theorem}
    For $f_1, \dots, f_N \in L^p(X)$, with $0 < p < 1$,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \]
\end{theorem}
\begin{proof}
    By H\"{o}lder's inequality applied to sums,
    %
    \[ \| f_1 + \dots + f_N \|_p \leq (\| f \|_p^p + \dots + \| f_N \|_p^p)^{1/p} \leq N^{1/p - 1} (\| f_1 \|_p + \dots + \| f_N \|_p). \]
    %
    Thus $L^p(X)$ is a quasinorm space.
\end{proof}

\begin{remark}
    When $p < 1$, the space $L^p(X)$ is \emph{not} normable. To see why, we look at the topological features of $L^p(X)$. Fix $\varepsilon > 0$, and let $C$ be a convex set containing all functions $f$ with $\| f \|_p < \varepsilon$. Thus, in particular, $C$ contains all step functions $H \mathbf{I}_E$ where $H |E|^{1/p} < \varepsilon$. But if we now find a countable sequence of disjoint sets $\{ E_k \}$, each with positive measure, and for each $k$, define $H_k = (\varepsilon/2) |E_k|^{-1/p}$, then for any $N$, the function
    %
    \[ f_N = (H_1/N) \mathbf{I}_{E_1} + \dots + (H_N/N) \mathbf{I}_{E_N} \]
    %
    lies in $C$, and
    %
    \[ \| f_N \|_p = (1/N) (H_1^p |E_1| + \dots + H_N^p |E_N|)^{1/p} = (\varepsilon/2) N^{1/p - 1} \]
    %
    as $N \to \infty$, the $L^p$ norm of $f_N$ becomes unbounded. In particular, this means that we have proven that every bounded convex subset of $L^p(X)$ has empty interior, and a norm space certainly does not have this property.
\end{remark}

As we have mentioned, as $p \to \infty$, the $L^p$ norm excludes functions with large peaks, or large height, and as $p \to 0$, the $L^p$ norm excludes functions with large tails, or large width. They form a continuously changing family of functions as $p$ ranges over the positive numbers. In general, there is no inclusion of $L^p(X)$ in $L^q(X)$ for any $p,q$, except in two circumstances which occur often enough to be mentioned.

\begin{example}
  If $X$ is a finite measure space, and $0 < p \leq q \leq \infty$, $L^p(X) \subset L^q(X)$. H\"{o}lder's inequality implies $\| f \|_p = \| f \chi_X \|_p \leq \| f \|_q |X|^{1/p-1/q}$. Taking $q \to \infty$, we conclude $\| f \|_p \leq | X |^{1/p} \| f \|_\infty$. One can best remember the constants here by the formula
  %
  \[ \left( \fint |f(x)|^p \right)^{1/p} \leq \left( \fint |f(x)|^q \right)^{1/q}. \]
  %
  In particular, when $X$ is a probability space, the $L^p$ norms are increasing.
\end{example}

\begin{example}
  On the other hand, suppose the measure space is {\it granular}, in the sense that there is $\varepsilon > 0$ such that either $|E| = 0$ or $|E| \geq \varepsilon$ for any measurable set $E$. Then $L^q(X) \subset L^p(X)$ for $0 < p \leq q \leq \infty$. First we check the $q = \infty$ case, which follows by the trivial estimate
  %
  \[ \int |f(x)|^p \geq \varepsilon \| f \|_\infty, \]
  %
  so $\| f \|_\infty \leq \| f \|_p \varepsilon^{-1/p}$. But then applying log convexity, if $p \leq q < \infty$, we can write $1/q = \theta/p$ for $0 < \theta \leq 1$, and then log convexity shows
  %
  \[ \| f \|_q = \| f \|_p^\theta \| f \|_\infty^{1-\theta} \leq \varepsilon^{-(1 - \theta)/p} \| f \|_p = \varepsilon^{-1/p - 1/q} \| f \|_p. \]
  %
  If $\varepsilon = 1$, which occurs if $X = \mathbf{Z}$, then the $L^p$ norms are decreasing in $p$. This gives the best way to remember the constants involved, since the measure $\mu(E) = |E|/\varepsilon$ is one granular, and so
  %
  \[ \left( \frac{1}{\varepsilon} \int |f(x)|^q\; dx \right)^{1/q} \leq \left( \frac{1}{\varepsilon} \int |f(x)|^p\; dx \right)^{1/p}. \]
\end{example}

%\begin{example}
%  Controlling additional properties of the function offers similar properties as for control on the measure space. If $|f(x)| \leq M$ for almost all $x$, then for $p \leq q$,
  %
%  \[ \| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}. \]
  %
%  Conversely, if $|f(x)| \geq M$ whenever $f(x) \neq 0$, then
  %
%  \[ \| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}. \]
  %
  
%\end{example}

\begin{remark}
  We can often use such results in spaces which are not granular by coarsening the sigma algebra. For instance, the Lebesgue measure is $\varepsilon^d$ granular over the sigma algebra generated by the length $\varepsilon$ cubes whose corner's lie on the lattice $(\mathbf{Z}/\varepsilon)^d$, and if a function is measurable with respect to such a $\sigma$ algebra we call the function $\varepsilon$ granular.
\end{remark}

\begin{remark}
  If we let $X = \{ 1, \dots, N \}$, then $X$ is both finite and granular, so all $L^p$ norms are comparable. In particular, if $p \leq q$,
  %
  \[ \| f \|_q \leq \| f \|_p \leq N^{1/p - 1/q} \| f \|_q. \]
  %
  The left hand side of this inequality becomes sharp when $f$ is concentrated at a single point, i.e. $f(n) = \mathbf{I}(n = 1)$. On the other hand, the left hand side becomes sharp when $f$ is constant, i.e. $f(n) = 1$ for all $n$.
\end{remark}

\begin{example}
    We can obtain similar $L^p$ bounds by controlling the functions $f$ involved, rather than the measure space. For instance, if $|f(x)| \leq M$, and $p \leq q$, then then $\| f \|_q \leq \| f \|_p^{p/q} M^{1 - p/q}$, which follows by log convexity. On the other hand, if $|f(x)| \geq M$ on the support of $f$, then $\| f \|_p \leq \| f \|_q^{q/p} M^{1-q/p}$.
\end{example}

\begin{theorem}
  If $p_\theta$ lies between $p_0$ and $p_1$, then
  %
  \[ L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X) \subset L^{p_0}(X) + L^{p_1}(X) \]
\end{theorem}
\begin{proof}
  If $\| f \|_{p_0}, \| f \|_{p_1} < \infty$, then for any $p_\theta$ between $p_0$ and $p_1$,
  %
  \[ \| f \chi_{|f| \leq 1} \|_{p_\theta}^{p_\theta} = \int_{|f| \leq 1} |f|^{p_\theta} \leq \int_{|f| \leq 1} |f|^{p_0} < \infty \]
  \[ \| f \chi_{|f| > 1} \|_{p_\theta}^{p_\theta} = \int_{|f| > 1} |f|^{p_\theta} \leq \int_{|f| > 1} |f|^{p_1} < \infty \]
  %
  Applying the triangle inequality, we conclude that $\| f \|_{p_\theta} < \infty$. In the case where $p_1 = \infty$, then $f \chi_{|f| > 1}$ is bounded, and must have finite support if $p_0 < \infty$, which shows this integral is bounded. Note the inequalities above show that we can split any function with finite $L^{p_\theta}$ norm into the sum of a function with finite $L^{p_0}$ norm and another with finite $L^{p_1}$ norm.
\end{proof}

This theorem is important in the study of interpolation theory, because if we have two linear operators $T_{p_0}$ defined on $L^{p_0}(X)$ and $T_{p_1}$ on $L^{p_1}(X)$, and they agree on $L^{p_0}(X) \cap L^{p_1}(X)$, then there is a unique linear operator $T_{p_\theta}$ on $L^{p_\theta}(X)$ which agrees with these two functions, and we can consider the boundedness of such a function with respect to the $L^{p_\theta}$ norms.

Finally, we note the duality property for the $L^p$ spaces. Given any values of $p$ and $q$ with $1/p + 1/q = 1$, H\"{o}lder's inequality implies that if $\| f \|_p < \infty$ and $\| g \|_q < \infty$, then $fg$ is integrable. In particular, the map $\lambda: f \mapsto \int fg$ is a linear functional on $L^p$. H\"{o}lder's inequality implies that $\| \lambda \| \leq \| g \|_q$. But this is actually an \emph{equality}.

\begin{theorem}
    For any function $f$ with $1 \leq p < \infty$,
    %
    \[ \| f \|_p = \sup \left\{ \int f(x)g(x) : \| g \|_q = 1 \right\}. \]
    %
    If the underlying measure space is $\sigma$ finite, then this claim also holds for $p = \infty$.
\end{theorem}
\begin{proof}
    Suppose that $1 < p < \infty$. Given $f$, we define
    %
    \[ g(x) = \frac{1}{\| f \|_p^{p-1}} \text{sgn}(f(x)) |f(x)|^{p-1}. \]
    %
    If $\| f \|_p < \infty$, then
    %
    \[ \| g \|_q^q = \frac{1}{\| f \|_p^{pq - q}} \int |f(x)|^{pq-q} = \frac{1}{\| f \|_p^p} \| f \|_p^p = 1, \]
    %
    and
    %
    \[ \int f(x) g(x) = \frac{1}{\| f \|_p^{p-1}} \int |f(x)|^p = \| f \|_p. \]
    %
    On the other hand, suppose $\| f \|_p = \infty$. Then there exists a sequence of step functions $s_1 \leq s_2 \leq \dots \to |f|$, and so $\| s_k \|_p \to \infty$. For each $k$, find a function $g_k \geq 0$ with $\| g_k \|_q = 1$, and $\int g_k(x) s_k(x) \geq \| s_k \|_p / 2$. Then
    %
    \[ \int g_k(x) \text{sgn}(f(x)) f(x) = \int g_k(x) |f(x)| \geq \int g_k(x) s_k(x) \geq \| s_k \|_p / 2 \to \infty, \]
    %
    which completes the proof. 

    Now suppose $p = 1$. Then, given any $f$, we can define
    %
    \[ g(x) = \text{sgn}(f(x)). \]
    %
    Then $\| g \|_\infty = 1$, and
    %
    \[ \int f(x) g(x) = \int |f(x)| = \| f \|_1. \]
    %
    Note this holds even if $\| f \|_1 = \infty$.

    Finally, suppose $p = \infty$. Given any $f$, fix $\varepsilon > 0$. Then we can find a set $E$ with $0 < |E| < \infty$ such that $|f(x)| \geq \| f \|_\infty - \varepsilon$ for $x \in E$. If $g(x) = \text{sgn}(f(x)) \mathbf{I}_E / |E|$, then $\| g \|_1 = 1$, and
    %
    \[ \int f(x) g(x) = \frac{1}{|E|} \int_E |f(x)| \geq \| f \|_\infty - \varepsilon. \]
    %
    Taking $\varepsilon \to 0$ completes the claim.
\end{proof}

\section{Distributions and Decreasing Rearrangements}

 The properties of a functions distribution are best reflected quite simply in the \emph{distribution function} of the function $f$, i.e. the function $F: [0,\infty) \to [0,\infty)$ given by $F(t) = |\{ x : |f(x)| > t \}|$, and any rearrangement invariant norm on $f$ should be a function of $F$. The function $F$ is right-continuous and decreasing, but has a jump discontinuity whenever $\{ x : |f(x)| = t \}$ is a set of positive measure. We denote distributions of functions $g$ and $h$ by $G$ and $H$.

\begin{lemma}
  Given a function $f$ and $g$, $\alpha \in \mathbf{C}$, and $t,s > 0$, then
  %
  \begin{itemize}
    \item If $|g| \leq |f|$, then $G \leq F$.
    \item If $g = \alpha f$, then $G(t) = F(t/|\alpha|)$.
    \item If $h = f + g$, then $H(t+s) \leq F(t) + G(s)$.
    \item If $h = fg$, then $H(ts) \leq F(t) + G(s)$.
  \end{itemize}
\end{lemma}
\begin{proof}
    The first point follows because $\{ x : |g(x)| > t \} \subset \{ x : |f(x)| > t \}$, and the second because $\{ x : |\alpha f(x)| > t \} = \{ x : |f(x)| > t/|\alpha| \}$. The third point follows because if $|f(x) + g(x)| \geq t + s$, then either $|f(x)| \geq t$ or $|g(x)| \geq s$. Finally, if $|f(x) g(x)| \geq ts$, then $|f(x)| \geq t$ or $|g(x)| \geq s$.
\end{proof}

We can simplify the study of the distribution of $f$ even more by defining the \emph{decreasing rearrangement} of $f$, a decreasing function $f^*: [0,\infty) \to [0,\infty)$ such that $f^*(s)$ is the \emph{smallest} number $t$ such that $F(t) \leq s$. Effectively, $f^*(s)$ is the inverse of $F$:
%
\begin{itemize}
    \item If there is a unique $t$ with $F(t) = s$, then $f^*(s) = t$.
    \item If there are multiple values $t$ with $F(t) = s$, let $f^*(s)$ be the \emph{smallest} such value.
    \item If there are no values $t$ with $F(t) = s$, then we pick the first value $t$ with $F(t) < s$.
\end{itemize}
%
We find
%
\[ \{ s : f^*(s) > t \} = \{ s : s < F(t) \} = [0,F(t)), \]
%
which has measure $F(t)$. This is the most important property of $f^*$; it is a decreasing function on the line which has the same distribution as the function $|f|$. It is also the unique such function which is right continuous. Thus our intuition when analyzing monotone, rearrangement invariant norms is not harmed if we focus on right continuous decreasing functions.

\begin{theorem}
    The function $f^*$ is right continuous.
\end{theorem}
\begin{proof}
    We note that $F(t) > s$ if and only if $t < f^*(s)$. Since $f^*$ is decreasing, for any $s \geq 0$, we automatically have $f^*(s^+) \leq f^*(s)$. If $f^*(s^+) < f^*(s)$, then
    %
    \[ s < F \left( f^*(s^+) \right) \leq F(f^*(s)) \leq s, \]
    %
    which gives a contradiction, so $f^*(s) = f^*(s^+)$.
\end{proof}

\begin{remark}
    We have a jump discontinuity at a point $s$ wherever $F$ is flat, and $f^*$ is flat wherever $F$ has a jump discontinuity.
\end{remark}

\section{Weak and Lorentz Norms}

The weak $L^p$ norms are obtained as a slight `refinement' of the $L^p$ norms.

\begin{theorem}
  If $\phi$ is an increasing, differentiable function on the real line with $\phi(0) = 0$, then
  %
  \[ \int_X \phi(|f(x)|) = \int_0^\infty \phi'(t) F(t)\; dt \]
\end{theorem}
\begin{proof}
  An application of Fubini's theorem is all that is needed to show
  %
  \begin{align*}
    \int_X \phi(|f(x)|)\; dx &= \int_X \int_0^{|f(x)|} \phi'(t)\; dt\; dx\\
    &= \int_0^\infty \phi'(t) \int_{|f(x)| > t}\; dx\; du\\
    &= \int_0^\infty \phi'(t) F(t)\; dt. \qedhere
  \end{align*}
\end{proof}

As a special case we find
%
\[ \| f \|_p = \left( p \int_0^\infty F(t) t^p \frac{dt}{t} \right)^{1/p}. \]
%
Thus in order for $\| f \|_p$ to be finite, we need $F(t) t^p$ to be integrable with respect to the Haar measure on $\mathbf{R}^+$. For this to be true, $F(t)$ must tend to zero slightly faster than $1/t^p$. Indeed, we find
%
\[ F(t) = |\{ |f|^p > t^p \}| \leq \frac{1}{t^p} \int |f|^p = \frac{\| f \|_p^p}{t^p}, \]
%
a fact known as \emph{Chebyshev's inequality}. But if we change the integrality condition to the condition that $F(t) t^p \in L^q(\mathbf{R}^+)$ for some $0 < q \leq \infty$, we obtain a different condition leading to the definition of the \emph{Lorentz norms}.

The most basic Lorentz norm is the \emph{weak $L^p$ norm}, denoted by $\| f \|_{p,\infty}$, which is the smallest value $A$ such that $F(t) \leq (A/t)^p$. We let $L^{p,\infty}(X)$ denote the space of all functions $f$ for which $\| f \|_{p,\infty} < \infty$. By Chebyshev's inequality, $L^p(X) \subset L^{p,\infty}(X)$. The reason that the value $A$ occurs within the brackets is so that the norm is homogenous; if $g = \alpha f$, and $\| f \|_{p,\infty} = A$, then
%
\[ G(t) = F(t/|\alpha|) \leq \left( \frac{A |\alpha|}{t} \right)^p, \]
%
so $\| \alpha f \|_{p,\infty} = |\alpha| \| f \|_p$. The weak norms do not satisfy a triangle inequality, but they do satisfy a quasitriangle inequality. If $g = f_1 + \dots + f_N$, with $\| f_k \|_{p,\infty} = A_k$, then
%
\begin{align*}
    G(t) &\leq F_1(t/N) + \dots + F_N(t/N)\\
    &\leq (NA_1/t)^p + \dots + (NA_N/t)^p = \frac{N^p(A_1^p + \dots + A_N^p)}{t^p}.
\end{align*}
%
Thus $\| G \|_{p,\infty} \leq N(A_1^p + \dots + A_N^p)^{1/p}$. If $p \geq 1$, then this is upper bounded by $N(A_1 + \dots + A_N)$, so
%
\[ \| G \|_{p,\infty} \leq N \left( \| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty} \right). \]
%
If $p \leq 1$, we instead bound $(A_1^p + \dots + A_N^p)^{1/p}$ by $N^{1/p}(A_1 + \dots + A_N)$, so that
%
\[ \| G \|_{p,\infty} \leq N^{1 + 1/p} \left( \| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty} \right). \]
%
The weak norm provides another monotone translation invariant measure, and it oftens comes up when finer tuning is needed in certain interpolation arguments, especially when dealing with maximal functions.

\begin{example}
  If $f = H \mathbf{I}_E$, with $|E| = W$, then
  %
  \[ F(t) = W \cdot \mathbf{I}_{[0,H)}. \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \sup_{0 \leq t < H} W t^p \right)^{1/p} = W^{1/p} H^p = \| f \|_p. \]
  %
  If $f = H_1 \mathbf{I}_{E_1} + H_2 \mathbf{I}_{E_2}$, with $|E_1| = W_1$ and $|E_2| = W_2$, with $H_1 \leq H_2$, then
  %
  \[ F(t) = \begin{cases} W_1 + W_2 &: t < H_1, \\ W_2 &: t < H_2, \\ 0 &: \text{otherwise.} \end{cases} \]
  %
  Thus
  %
  \[ \| f \|_{p,\infty} = \left( \max((W_1 + W_2) H_1^p, W_2 H_2^p) \right)^{1/p} = \max((W_1 + W_2)^{1/p} H_1, W_2^{1/p} H_2). \]
\end{example}

\begin{example}
    The function $f(x) = 1/|x|^\alpha$ does not lie in any $L^p(\mathbf{R}^d)$, but lies in $L^{p,\infty}$ precisely when $p = d/\alpha$, since
    %
    \[ \left| \{ 1/|x|^{p\alpha} > t \} \right| = \left| \left\{ |x| \leq \frac{1}{t^{1/p\alpha}} \right\} \right|\ \propto_d\ \frac{1}{t^{d/p\alpha}}. \]
    %
    Thus the weak $L^p$ norms are able to more precisely determine the distribution of certain functions.
\end{example}

In general, we define the \emph{Lorentz spaces} $L^{p,q}(X)$ as the space of functions such that
%
\[ \left( \int (t F^{1/p}(t))^q \frac{dt}{t} \right)^{1/q} < \infty. \]
%
For such functions, we can define the Lorentz norm
%
\[ \| f \|_{p,q} = \| p t F^{1/p} \|_{L^q(\mathbf{R}^+)} = \| s^{1/p} f^* \|_{L^q(\mathbf{R}^+)}. \]
%
The equivalence of these two definitions is verified for simple functions, from which the general case follows from the monotone convergence theorems. As a special case, $\| \cdot \|_{p,\infty}$ is the weak $L^p$ norm, and $\| \cdot \|_{p,p}$ is the standard $L^p$ norm. The Lorentz norm often occurs with other constants attached, but this only scales the Lorentz norm, and is rarely relevant to the problem at hand, since we normally only desire bounds of the form $\| f \|_{p,q} \lesssim_{p,q} A$. The main case are interested in which we haven't already encountered is when $q = 1$, for which
%
\[ \| f \|_{p,1} = \int_0^\infty s^{1/p} f^*(s)\; \frac{ds}{s}. \]
%
As $q \to 0$, the norm $\| \cdot \|_{p,q}$ becomes a stronger measurement.

\begin{theorem}
    For $q < r$, $\| f \|_{p,r} \lesssim_{p,q_1,q_2} \| f \|_{p,q}$.
\end{theorem}
\begin{proof}
    First we treat the case $r = \infty$. We have
    %
    \begin{align*}
        s_0^{1/p} f^*(s_0) &= \left( \frac{q}{p} \int_0^{s_0} [s^{1/p} f^*(s_0)]^q \frac{dt}{t} \right)^{1/q}\\
        &\leq \left( \frac{q}{p} \int_0^{s_0} [s^{1/p} f^*(s)]^q \frac{dt}{t} \right)\\
        &\leq (q/p)^{1/q} \| f \|_{p,q}.
    \end{align*}
    %
    When $r < \infty$, we can interpolate, calculating
    %
    \[ \| f \|_{p,r} = \left( \int_0^\infty [s^{1/p} f^*(s)]^r \frac{ds}{s} \right)^{1/r} \leq \| f \|_{p,\infty}^{1 - q/r} \| f \|_{p,q}^{q/r} \leq (q/p)^{1/q - 1/r} \| f \|_{p,q}. \qedhere \]
\end{proof}

The fact that multiplying a function by a constant dilates the distribution implies that the Lorentz norm is homogenous. We do not have a triangle inequality for the Lorentz norms, but we have a quasi triangle inequality.

\begin{theorem}
    All the Lorentz spaces satisfy a quasi triangle inequality. More precisely, if $p,q \geq 1$, then
    %
    \[ \| f_1 + \dots + f_N \|_{p,q} \leq N^{1 + [p \leq 1](1/p - 1) + [q \leq 1](1/q - 1)} \left( \| f_1 \|_{p,q} + \dots + \| f_N \|_{p,q} \right). \]
\end{theorem}
\begin{proof}
    We calculate that if $g = f_1 + \dots + f_N$,
    %
    \begin{align*}
    \| g \|_{p,q} &= \left( q \int_0^\infty \left[t G(t)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\leq \left( q \int_0^\infty \left[ t (F_1(t/N) + \dots + F_N(t/N))^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}\\
    &\leq N \left( q \int \left[ t \left( F_1(t) + \dots + F_N(t) \right)^{1/p} \right]^q \frac{dt}{t} \right)^{1/q}.
  \end{align*}
  %
  If $p \geq 1$, then
  %
  \[ \left( F_1(t) + \dots + F_N(t) \right)^{1/p} \leq F_1(t)^{1/p} + \dots + F_N(t)^{1/p}, \]
  %
  whereas if $p \leq 1$, H\"{o}lder's inequality shows
  %
  \[ \left( F_1(t) + \dots + F_N(t) \right)^{1/p} \leq N^{1/p - 1} \left( F_1(t)^{1/p} + \dots + F_N(t)^{1/p} \right), \]
  %
  If $q \geq 1$, the two inequalities above, combined with the triangle inequality in $L^q(\mathbf{R}^+)$, yield the required bound. If $q \leq 1$, then we apply the quasitriangle inequality.
\end{proof}

\section{Dyadic Layer Cake Decompositions}

An important trick to utilizing Lorentz norms is by utilizing a dyadic layer cake decomposition. The dyadic layer cake decompositions enable us to understand a function by breaking it up into parts upon which we can control the height or width of a function. We say $f$ is a \emph{sub step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \leq W$, and $|f(x)| \leq H$. A \emph{quasi step function} with height $H$ and width $W$ if $f$ is supported on a set $E$ with $|E| \sim W$ and on $E$, $|f(x)| \sim H$.

We start by discussing the \emph{vertical dyadic layer cake decomposition}. We define, for each $k \in \mathbf{Z}$, and set
%
\[ f_k(x) = f(x) \mathbf{I}(2^{k-1} < |f(x)| \leq 2^k) \]
%
Then $f = \sum f_k$, and $f_k$ is a quasi step function with height $2^k$ and width $F(2^{k-1}) - F(2^k)$. On the other hand, we can also perform a \emph{horizontal layer cake decomposition}. If we define $H_k = f^*(2^k)$, and set
%
\[ f_k(x) = f(x) \mathbf{I}(H_{k-1} < |f(x)| \leq H_k), \]
%
then $f_k$ is a substep function with height $H_k$ and width $2^k$. These decompositions are best visualized with respect to the representation $f^*$ of $f$, in which case the decomposition occurs over particular intervals.

\begin{theorem}
    The following values $A_1, \dots, A_5$ are all comparable up to a constant depending on $p$ and $q$:
    %
    \begin{enumerate}
        \item \label{onebound} $\| f \|_{p,q} \leq A_1$.

        \item \label{twobound} We can write $f = \sum_{k \in \mathbf{Z}} f_k$, where $f_k$ is a quasi-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \mathbf{Z}} \left[ 2^k W_k^{1/p} \right]^q \right)^{1/q} \leq A_2. \]

        \item \label{threebound} We can write $f = \sum_{k \in \mathbf{Z}} f_k$, where $f_k$ is a sub-step function with height $2^k$ and width $W_k$, and
        %
        \[ \left( \sum_{k \in \mathbf{Z}} \left[2^{k} W_k^{1/p} \right]^q \right)^{1/q} \leq A_3. \]

        \item \label{fourbound} We can write $f(x) = \sum_{k \in \mathbf{Z}} f_k$, where $f_k$ is a sub-step function with width $2^k$ and height $H_k$, where $\{ H_k \}$ is a decreasing family of functions, and
        %
        \[ \left( \sum_{k \in \mathbf{Z}} \left[H_k 2^{k/p} \right]^q \right)^{1/q} \leq A_4. \]
    \end{enumerate}
\end{theorem}
\begin{proof}
    It is obvious that we can always select $A_3 \leq A_2$ and $A_5 \leq A_4$. Next, we bound $A_2$ in terms of $A_1$ by performing a vertical layer cake decomposition on $f$. If we write $f = \sum_{k \in \mathbf{Z}} f_k$, then $f_k$ is supported on a set with measure $W_k = F(2^{k-1}) - F(2^k) \leq F(2^{k-1})$, and so
    %
    \begin{align*}
        \sum_{k \in \mathbf{Z}} [2^k W_k^{1/p}]^q &\leq \sum_{k \in \mathbf{Z}} [2^k F(2^{k-1})^{1/p}]^q\\
        &\lesssim_q \sum_{k \in \mathbf{Z}} [2^{k-1} F(2^k)^{1/p}]^q\\
        &\lesssim \sum_{k \in \mathbf{Z}} \int_{2^{k-1}}^{2^k} [tF(t)^{1/p}]^q\; \frac{dt}{t} \lesssim_q \| f \|_{p,q}^q \leq A_1^q.
    \end{align*}
    %
    Thus $A_2 \lesssim_q A_1$. Next, we bound $A_4$ interms of $A_1$. Perform a horizontal layer cake decomposition, writing $f = \sum f_k$, where $f_k$ is supported on a set with measure $W_k \leq 2^k$, and $H_{k+1} \leq |f_k(x)| \leq H_k$. Then a telescoping sum shows
    %
    \begin{align*}
        H_k 2^{k/p} &= \left( \sum_{m = 0}^\infty (H_{k+m}^q - H_{k+m+1}^q) 2^{kq /p} \right)^{1/q}\\
        &\lesssim_q \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t 2^{k/p}]^q \frac{dt}{t} \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \int_{H_{k+m+1}}^{H_{k+m}} [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q}
    \end{align*}
    %
    Thus
    %
    \[ \left( \sum_{k \in \mathbf{Z}} [H_k 2^{k/p}]^q \right)^{1/q} \leq \left( \int_0^\infty [t F(t)^{1/p}]^q \frac{dt}{t} \right)^{1/q} \lesssim_q A_1. \]
    %
    Thus $A_4 \lesssim_q A_1$. It remains to bound $A_1$ by $A_5$ and $A_3$. Given $A_3$, we can write $|f(x)| \leq \sum 2^k \mathbf{I}_{E_k}$, where $|E_k| \leq W_k$. We then find
    %
    \[ F(2^k) \leq \sum_{m = 1}^\infty W_{k+m}. \]
    %
    Thus
    %
    \[ \int_{2^{k-1}}^{2^k} [t F(t)^{1/p}]^q \frac{dt}{t} \lesssim \left[ 2^k \left(\sum_{m = 0}^\infty W_k \right)^{1/p} \right]^q. \]
    %
    Thus if $q \leq p$,
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \mathbf{Z}} \left[2^k \left( \sum_{m = 0}^\infty W_{k+m} \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{k \in \mathbf{Z}} \sum_{m = 0}^\infty \left[ 2^k W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty 2^{-qm} \sum_{k \in \mathbf{Z}} \left[ 2^{k+m} W_{k+m}^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( A_3^q \sum_{m = 0}^\infty 2^{-mq} \right)^{1/q} \lesssim_q A_3.
    \end{align*}
    %
    If $q \geq p$, we can employ the triangle inequality for $l^{q/p}$ to write
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_q \left( \sum_{k \in \mathbf{Z}} \left[2^k \left( \sum_{m = 0}^\infty W_{k + m}  \right)^{1/p} \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m = 0}^\infty \left( \sum_{k \in \mathbf{Z}} 2^{kq} W_{k+m}^{q/p} \right)^{p/q} \right)^{1/p}\\
        &\leq \left( A_3^p \sum_{m = 0}^\infty 2^{-mq} \right)^{1/p} \lesssim_{p,q} A_3.
    \end{align*}
    %
    The bound of $A_1$ in terms of $A_4$ involves the same `shifting' technique, and is left to the reader.
\end{proof}

\begin{remark}
    Heuristically, the theorem above says that if $f = \sum_{k \in \mathbf{Z}} f_k$, where $f_k$ is a quasi-step function with width $H_k$ and width $W_k$, and if either $\{ H_k \}$ and $\{ W_k \}$ grow faster than powers of two, then
    %
    \[ \| f \|_{p,q} \sim_{p,q} \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}. \]
    %
    Thus the $L^{p,q}$ norm has little interaction between elements of the sum when the sum occurs over dyadically different heights or width, which is another reason why we view the $q$ parameter as a `logarithmic' correction of the $L^p$ norm. In particular, if $f = f_1 + \dots + f_N$, and $q_1 < q_2$, then the last equation, combined with a $l^{q_1}$ to $l^{q_2}$ norm bound, gives
    %
    \[ \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p} \right]^{q_1} \right)^{1/q_1} \leq N^{1/q_1 - 1/q_2} \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p} \right]^{q_2} \right)^{1/q_2} \]
    %
    This implies
    %
    \[ \| f \|_{p,q_2} \lesssim_{p,q_1,q_2} \| f \|_{p,q_1} \lesssim_{p,q_1,q_2} N^{1/q_1 - 1/q_2} \| f \|_{p,q_2}. \]
    %
    On the other hand, if we vary the $p$ parameter, and the widths change dyadically, we find that for $p_1 < p_2$,
    %
    \[ \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} \leq \max(W_k)^{1/p_1 - 1/p_2} \left( \sum_{k \in \mathbf{Z}} \left[H_k W_k^{1/p_2} \right]^q \right)^{1/q}, \]
    \[ \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} \leq \left( \frac{1}{\min(W_k)} \right)^{1/p_1 - 1/p_2} \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q}. \]
    %
    which gives
    %
    \[ \min(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q} \lesssim_{p_1,p_2,q} \| f \|_{p_1,q} \lesssim_{p_1,p_2,q} \max(W_k)^{1/p_1 - 1/p_2} \| f \|_{p_2,q}. \]
    %
    Both of these inequalities can be tight. Because of the dyadic decomposition of $f$, we find $\max(W_k) \geq 2^N \min(W_k)$, so these two norms can differ by at least $2^{N(1/p_1 - 1/p_2)}$, and at \emph{most} if the $f_k$ occur over consecutive dyadic values, which is \emph{exponential} in $N$. Conversely, if the heights change dyadically, we find that
    % q = q'p_2/p-1
    \begin{align*}
        \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p_2} \right]^q \right)^{1/q} &\leq \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p_2} \right]^{qp_2/p_1} \right)^{(p_1/p_2)/q}\\
        &\leq \max(H_k)^{1 - p_1/p_2} \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p_1} \right]^q \right)^{(p_1/p_2)/q}
    \end{align*}
    %
    \begin{align*}
        \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p_1} \right]^q \right)^{1/q} &\lessapprox \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p_1} \right]^{qp_1/p_2} \right)^{(p_2/p_1)/q}\\
        &\leq \left( \frac{1}{\min(H_k)} \right)^{p_2/p_1 - 1} \left( \sum_{k \in \mathbf{Z}} \left[ H_k W_k^{1/p_2} \right]^q \right)^{(p_2/p_1)/q}
    \end{align*}
    %
    where $\lessapprox$ denotes a factor ignoring polynomial powers of $N$ occuring from the estimate. Thus
    %
    \[ \min(H_k)^{p_2 - p_1} \| f \|_{p_1,q}^{p_1} \lessapprox_{p_1,p_2,q} \| f \|_{p_2,q}^{p_2} \lesssim_{p_1,p_2,q} \max(H_k)^{p_2-p_1} \| f \|_{p_1,q}^{p_1} \]
    %
    again, these inequalities can be both tight, and $\max(H_k) \geq 2^N \min(H_k)$, with equality if the quasi step functions from which $f$ is composed occur consecutively dyadically.
\end{remark}

A simple consequence is H\"{o}lder's inequality for Lorentz spaces.

\begin{theorem}
    If $0 < p_1,p_2,p < \infty$ and $0 < q_1,q_2,q < \infty$ with
    %
    \[ 1/p = 1/p_1 + 1/p_2 \quad \text{and} \quad 1/q = 1/q_1 + 1/q_2, \]
    %
    then
    %
    \[ \| f g \|_{p,q} \lesssim_{p_1,p_2,q_1,q_2} \| f \|_{p_1,q_1} \| g \|_{p_2,q_2}. \]
\end{theorem}
\begin{proof}
    Without loss of generality, assume $\| f \|_{p_1,q_1} = \| g \|_{p_2, q_2} = 1$. Perform horizontal layer cake decompositions of $f$ and $g$, writing $|f| \leq \sum_{k \in \mathbf{Z}} H_k \mathbf{I}_{E_k}$ and $|g| \leq \sum_{k \in \mathbf{Z}} H_k' \mathbf{I}_{F_k}$, where $|E_k|, |F_k| \leq 2^k$. Then
    %
    \[ |fg| \leq \sum_{k,k' \in \mathbf{Z}} H_k H_k' \mathbf{I}_{E_k \cap F_{k'}} \]
    %
    For each fixed $k$, $|E_{k + m} \cap F_m| \leq 2^m$, and so
    %
    \begin{align*}
        \left\| \sum_{m \in \mathbf{Z}} H_{k + m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q} &\lesssim_{p,q} \left( \sum_{m \in \mathbf{Z}} [H_{k+m} H_m' 2^{m/p}]^q \right)^{1/q}\\
        &= \left( \sum_{m \in \mathbf{Z}} \left[ (H_{k+m} 2^{m/p_1}) (H_m 2^{m/p_2}) \right]^q \right)^{1/q}\\
        &\leq \left( \sum_{m \in \mathbf{Z}} [H_{k+m} 2^{m/p_1} ]^{q_1} \right)^{1/q_1} \left( \sum_{m \in \mathbf{Z}} [H_m' 2^{m/p_2}]^{q_2} \right)^{1/q_2} \lesssim_{p,q,p_1,q_1,p_2,q_2} 2^{-k/p_1}\\
    \end{align*}
    %
    Summing over $k > 0$ gives that
    %
    \[ \left\| \sum_{k \geq 0} \sum_{m \in \mathbf{Z}} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\| \lesssim_{p,q,p_1,q_1,p_2,q_2} 1 \]
    %
    By the quasitriangle inequality, it now suffices to obtain a bound
    %
    \[ \left\| \sum_{k < 0} \sum_{m \in \mathbf{Z}} H_{k+m} H_m' \mathbf{I}_{E_{k+m} \cap F_m} \right\|_{p,q}. \]
    %
    This is done similarily, but instead using the bound $|E_{k+m} \cap F_m| \leq 2^{k+m}$.
\end{proof}

\begin{corollary}
    If $p > 1$ and $q > 0$, $L^{p,q}(X) \subset L^{1,\text{loc}}(X)$.
\end{corollary}
\begin{proof}
    Let $E$ have finite measure and let $f \in L^{p,q}(X)$. Then the H\"{o}lder's inequality for Lorentz spaces shows
    % 1 = 1/p + 1/p_2 = 1/q + 1/q_2
    %
    \[ \| f \|_{L^1(E)} = \| \mathbf{I}_E f \|_1 \lesssim_{p,q} |E|^{1 - 1/p} \| f \|_{p,q} < \infty. \qedhere \]
\end{proof}

Finally, we consider the duality of the $L^{p,q}$ norms.

\begin{theorem}
    Let $1 < p < \infty$ and $1 \leq q \leq \infty$. Then if $f \in L^{p,q}(X)$,
    %
    \[ \| f \|_{p,q} \sim \sup \left\{ \int fg : \| g \|_{p',q'} \leq 1 \right\}. \]
\end{theorem}
\begin{proof}
    The upper bound is an easy consequence of H\"{o}lder's inequality. For the case $q = \infty$, we actually prove
    %
    \[ \| f \|_{p,\infty} \gtrsim_p \sup \left\{ |E|^{-1/p'} \left| \int_E f \right| : |E| < \infty \right\}, \]
    %
    If $F(t_0) \geq (A/t_0)^p$ for some $t_0$, then setting $E_\theta = \{ x : |f(x)| = re^{i\theta}, r > t_0 \}$, we find
    %
    \[ \int_0^{2\pi} |E_\theta| \geq (A/t_0)^p. \]
    %
    In particular, if $\varepsilon > 0$ is fixed, pidgeonholing shows we can find a set
    %
    \[ E = \bigcup_{\eta = \theta}^{\theta + \pi/4} E_\theta \]
    %
    such that $|E| \geq (A/t_0)^p/8$. Thus
    %
    \begin{align*}
        |E|^{-1/p'} \left| \int_E f(x)\; dx \right| &\geq |E|^{-1/p'} \text{Re} \left( \int_Ee^{-i\theta} f(x)\; dx \right)\\
        &\gtrsim |E|^{-1/p'} \int_E |f(x)|\; dx \gtrsim_p t_0 \cdot |E|^{1/p} \gtrsim A.
    \end{align*}
    %
    Now we consider the case with $q < \infty$. Without loss of generality, we may assume $\| f \|_{p,q} = 1$. We may perform a vertical layer cake decomposition, writing $f = \sum_{k \in \mathbf{Z}} f_k$, where $2^{k-1} \leq |f_k(x)| \leq 2^k$, is supported on a set with width $W_k$, and
    %
    \[ \left( (2^k W_k^{1/p})^q \right) \sim_{p,q} 1. \]
    %
    Define $a_k = 2^k W_k^{1/p}$, and set $g = \sum_{k \in \mathbf{Z}} g_k$, where $g_k(x) = a_k^{q-p} \text{sgn}(f_k(x)) |f_k(x)|^{p-1}$. Then
    %
    \begin{align*}
        \int f(x) g(x) &= \sum_{k \in \mathbf{Z}} \int f_k(x) g_k(x) = \sum_{k \in \mathbf{Z}} a_k^{q-p} \int |f_k(x)|^p\\
        &\gtrsim_p \sum_{k \in \mathbf{Z}} a_k^{q-p} W_k 2^{kp} = \sum_{k \in \mathbf{Z}} a_k^q \gtrsim_{p,q} 1.
    \end{align*}
    %
    We therefore need to show that $\| g \|_{p',q'} \lesssim 1$. We note $|g_k(x)| \lesssim a_k^{q-p} 2^{kp}$, and has width $W_k$. The gives a decomposition of $g$, but neither the height nor the widths necessarily in powers of two. Still, we can fix this since the heights increase exponentially; define
    %
    \[ H_k = \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2}. \]
    %
    Then $|g_k(x)| \lesssim_{p,q} H_k$, and $H_{k+1} \geq 2^{p/2} H_k$. In particular, if we pick $m$ such that $2^{mp/2} \geq 1$, then for any $l \leq m$, the sequence $H_{km + l}$, as $k$ ranges over values, increases dyadically, and so by the quasitriangle inequality for the $L^{p',q'}$ norm, and then the triangle inequality in $l^q$, we find
    % W_k = a_k^p/ 2^{kp}
    \begin{align*}
        \| g \|_{p',q'} &\lesssim_{m,p,q} \left( \sum [H_k W_k^{1/p'}]^{q'} \right)^{1/q'}\\
        &\lesssim \left( \sum_{k \in \mathbf{Z}} \left[ \left( \sup_{l \geq 0} a_{k-l}^{q-p} 2^{kp} 2^{-lp/2} \right) (a_k 2^{-k})^{p-1} \right]^{q'} \right)^{1/q'}\\
        &\lesssim_p \left( \sum_{k \in \mathbf{Z}} \left[ a_k^{p-1} \sum_{l = 0}^\infty a_{k-l}^{q-p} 2^{-lp/2} \right]^{q'} \right)^{1/q'}\\
        &\lesssim \sum_{l = 0}^\infty 2^{-lp/2} \left( \sum_{k \in \mathbf{Z}} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'}.
    \end{align*}
    %
    Applying's H\"{o}lder's inequality shows
    %
    \begin{align*}
        \left( \sum_{k \in \mathbf{Z}} \left[ a_k^{p-1} a_{k-l}^{q-p} \right]^{q'} \right)^{1/q'} &\leq  \left( \sum_{k \in \mathbf{Z}} a_k^q \right)^{(p-1)/q} \left( \sum_{k \in \mathbf{Z}} a_{k-l}^q \right)^{(q-p)/q}\\
        &\lesssim_{p,q} \| f \|_{p,q}^{q-1} \lesssim_{p,q} 1. \qedhere
    \end{align*}
\end{proof}

\begin{remark}
    This technique shows that if $f = \sum f_k$, where $f_k$ is a quasi-step function with measure $W_k$ and height $2^{ck}$, then we can find $m$ such that $cm > 1$, and then consider the $m$ functions $f^1, \dots, f^m$, where $f_i = \sum f_{km + i}$. Then the functions $f_{km + i}$ have heights which are separated by powers of two, and so the quasi-triangle inequality implies
    %
    \begin{align*}
        \| f \|_{p,q} &\lesssim_m \sum_{i = 1}^m \| f^i \|_{p,q}\\
        &\lesssim_{p,q} \sum_{i = 1}^m \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\lesssim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}
    \end{align*}
    %
    On the other hand,
    %
    \begin{align*}
        \| f \|_{p,q} &\gtrsim \max_{1 \leq i \leq m} \| f^i \|_{p,q}\\
        &\sim \max_{1 \leq i \leq m} \left( \sum \left[ H_{km + i} W_{km + i}^{1/p} \right]^q \right)^{1/q}\\
        &\gtrsim_m \left( \sum \left[ H_k W_k^{1/p} \right]^q \right)^{1/q}.
    \end{align*}
    %
    Thus the dyadic layer cake decomposition still works in this setting.
\end{remark}

\section{Normability of the Lorentz Spaces}

Though the Lorentz norms do not satisfy the triangle inequality, the space $L^{p,q}(X)$ is still a `Banach-able' space when $p > 1$, and $q \geq 1$. First off, the standard proof shows the norm gives a complete quasimetric, since a Cauchy sequence in the $L^{p,q}$ norm converges to a function almost everywhere, which is easily verified to have finite $L^{p,q}$ norm. The easiest way to define a norm is to through the decreasing rearrangement.

\begin{lemma}
    For any measurable set $E$,
    %
    \[ \int_E |f(x)|\; dx \leq \int_0^{|E|} f^*(t)\; dt. \]
    %
    and
    %
    \[ \int_{\{ |f(x)| > t \}} |f(x)|\; dx = \int_0^{F(t)} f^*(t)\; dt. \]
\end{lemma}
\begin{proof}
    If $g \leq f$, $g^* \leq f^*$. Thus $(\chi_E f)^* \leq f^*$, so
    %
    \[ \int_E |f(x)|\; dx = \int \chi_E |f(x)| = \int_0^\infty (\chi_E f)^*(t)\; dt = \int_0^{|E|} (\chi_E f)^*(t)\; dt \leq \int_0^{|E|} f^*(t)\; dt. \]
    %
    On the other hand, $(\chi_E f)^* = f^*$ when $E = \{ |f(x)| > t \}$, which gives the second equality.
\end{proof}

For a function $f$ and $t > 0$, we define a family of averages
%
\[ m(t) = \frac{1}{t} \int_0^t f^*(t)\; dt. \]
%
For any fixed $t > 0$, the map $f \mapsto m(t)$ is a norm. Provided our measure space is non-atomic, we have
%
\[ m(t) = \sup_{|E| \leq t} \int_E |f(x)|\; d\mu. \]
%
We define
%
\[ \vvvert f \vvvert_{p,q} = \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} \]
and
%
\[ \vvvert f \vvvert_{p,\infty} = \sup t^{1/p} m(t). \]
%
For $q \geq 1$, each of these functions is a norm, simply because the function $m$ is a norm. On the other hand, since $f^*$ is decreasing, $f^*(t) \leq m(t)$ for all $t$, which shows $\vvvert f \vvvert_{p,q} \geq \| f \|_{p,q}$. If $p = 1$ and $q < \infty$, if $\vvvert f \vvvert_{1,q} < \infty$, then $f = 0$, so these norms are effectively useless. If $q = \infty$, then
%
\[ \vvvert f \vvvert_{1,\infty} = \| f^* \|_{L^1[0,\infty)} = \| f \|_1, \]
%
and therefore doesn't measure the correct norm. But in all other cases, i.e. for $p > 1$ and $q \geq 1$, the norm is comparable to the $L^{p,q}$ norm.

\begin{theorem}
    If $p > 1$,
    %
    \[ \vvvert f \vvvert_{p,q} \leq \frac{p}{p-1} \| f \|_{p,q}. \]
\end{theorem}
\begin{proof}
    We utilize a \emph{Hardy's inequality} technique, which shows that the $L^p$ norm of the averages of a function are comparable to the $L^p$ norm of the function. Applying Minkowski's integral inequality, we conclude that
    %
    \begin{align*}
        \left( \frac{q}{p} \int_0^\infty [t^{1/p} m(t)]^q \frac{dt}{t} \right)^{1/q} &= \left( \frac{q}{p} \int_0^\infty \left( \int_0^1 t^{1/p} f^*(ts)\; ds \right)^q\; \frac{dt}{t} \right)^{1/q}\\
        &\leq \int_0^1 \left( \int_0^\infty \frac{q}{p} (t^{1/p} f^*(ts))^q\; \frac{dt}{t} \right)^{1/q}\; ds\\
        &\leq \left( \int_0^1 s^{- 1/p}\; ds \right) \left( \frac{q}{p} \int_0^\infty (t^{1/p} f^*(t))^q\; \frac{dt}{t} \right)^{1/q}\\
        &\leq \frac{1}{1 - 1/p} \| f \|_{p,q} = \frac{p}{p - 1} \| f \|_{p,q}.
    \end{align*}
    %
    For $q = \infty$, and $t > 0$, we have
    %
    \begin{align*}
        t^{1/p} m(t) &= t^{1/p - 1} \int_0^t f^*(t)\\
        &\leq (\sup_{s > 0} s^{1/p} f^*(s)) t^{1/p - 1} \int_0^t t^{-1/p}\\
        &= \frac{1}{1 - 1/p} \| f \|_{p,\infty} = \frac{p}{p-1} \| f \|_{p,\infty}.
    \end{align*}
    %
    since $t$ was arbitrary, this gives the required bound.
\end{proof}

\begin{remark}
    When $p = 1$, $q > 1$, the space $L^{p,q}(X)$ is not normable. We prove this when $X = \mathbf{R}$. Indeed, for each $k$, let
    %
    \[ f_k(x) = \frac{1}{|x - k|}. \]
    %
    Then $\| f_k \|_{1,\infty} \lesssim 1$ is bounded independently of $k$. If $\| \cdot \|$ was a norm giving the same topology as $L^{p,q}(X)$, then if $f = \sum_{k = 0}^{2N} f_k$, the triangle inequality would imply $\| f \| \lesssim N$. But if $|x| \leq N$, there are integers $k_1, \dots, k_N > 0$ such that $|x - k_i| \leq 2i$, so
    %
    \[ f(x) \geq \sum_{i = 1}^N \frac{1}{|x - k_i|} \geq \sum_{i = 1}^N \frac{1}{2i} \gtrsim \log(N) \]
    %
    so $\| f \|_{1,\infty} \geq N \log N$.
\end{remark}

\section{Metric Structure of Norms}

The geometric interest of these quantitative norms are that we can define a `distance' between two functions $f$ and $g$ by the magnitude of a norm of the function $f - g$. Thus, for instance, the $L^1(X)$ can be given a geometric structure by defining the distance between two functions $f$ and $g$ as $\| f - g \|_p$. The fact that we can treat functions as points in an `infinite dimensional geometry' is the fundamental foundation of the field of functional analysis. For $p \geq 1$, these norms do actually satisfy the triangle inequality, giving rise to a metric. For $0 < p < 1$, the norms give rise to a quasimetric.

One reason to discuss norms in the context of measure theory is that it enlightens us on the sense that the Lebesgue integral is that it is a `completion' of the Riemann integral. We have already seen this principle in the discussion of the metric $d(E,F) = |E \bigtriangleup F|$, for which the family of Lebesgue measurable sets `complete' the metric on Jordan measurable sets or elementary sets. Norms enable us to see this principle in a deeper context, for a norm gives rise to a metric on the family of measurable functions, and the Riemann integrable functions in this metric are dense in this space, so that the Lebesgue functions `fill the holes' with respect to any of the given norms. The triangle inequality for the norms says that the norm works like a metric on space.

The triangle inequality is only ever sharp if $f$ and $g$ are correlated in some manner. For instance, if the supports of $f$ and $g$ are disjoint, then we find
%
\[ \| f + g \|_p^p = \int (f + g)^p = \int f^p + g^p = \| f \|_p^p + \| g \|_p^p \]
%
so $\| f + g \|_p = (\| f \|_p^p + \| g \|_p^p)^{1/p}$, for any $0 < p < \infty$, with the natural infinite extension being $\| f + g \|_\infty = \max(\| f \|_\infty, \| g \|_\infty)$. In fact, the only time where $\| f + g \|_p = \| f \|_p + \| g \|_p$ is when $f$ and $g$ are positive scalar multiples of one another (up to a set of measure zero). To see this, note that if equality held, then we would have, except on a set of measure zero,
$|f + g|^p = \theta^{1-p} |f|^p + (1 - \theta)^{1 -p} |g|^p$. We claim that this forces $g = (1 - \theta)/\theta f$ (TODO).

If $0 < p < 1$, the triangle inequality isn't satisfied, which can be seen in the case of the $l_p$ norm on $\mathbf{R}^n$, which isn't convex. However, the discrete sum implies we have a pointwise estimate $|A + B|^p \leq |A|^p + |B|^p$, so that we have $\| f + g \|_p^p \leq \| f \|_p^p + \| g \|_p^p$. In fact, for $p < 1$ we have
%
\[ \frac{1}{N^{1/p}} \left\| \sum_{n = 1}^N f_n \right\|_p \leq \left\| \frac{1}{N} \sum_{n = 1}^N |f_n| \right\|_p \leq \frac{1}{N} \sum_{n = 1}^N \| f_n \|_p \]
%
To prove this, since $1/p \geq 1$, we can apply convexity to conclude
%
\[ \left( \frac{1}{N} \int \left( \sum_{n = 1}^N |f_n| \right)^p \right)^{1/p} \leq \left( \frac{1}{N} \int \sum_{n = 1}^N |f_n|^p \right)^{1/p} \leq \frac{1}{N} \sum_{n = 1}^N \left( \int |f_n|^p \right)^{1/p} \]
%
This is `almost' as good as a triangle inequality for the purposes of defining a geometric space. We call such a quantity a quasinorm.

The next most important inequality in the analysis of measurable functions is H\"{o}lder's inequality, which enables us to quantify the norm of the product of two functions in terms of the norm of the original two functions.

\begin{theorem}
  If $0 < p,q,r \leq \infty$, and $1/p + 1/q = 1/r$, then $\| fg \|_r \leq \| f \|_p \| g \|_q$.
\end{theorem}
\begin{proof}
  We may assume $p,q$, and $r$ are finite, for the other cases are trivial. By normalization, we may assume $\| f \|_p = \| g \|_q = 1$. If $\theta = r/q$, $1 - \theta = r/p$, then we must show
  %
  \[ \int |f|^{p(1 - \theta)} |g|^{q\theta} \leq 1 \]
  %
  But this follows by convexity of the map $\theta \mapsto A^{1 - \theta} B^\theta$, for any $A,B$, we can apply a pointwise estimate, and integrate.
\end{proof}

\begin{remark}
  The symmetry of the inequality under the homogenities of functions explains why the two must occur the same number of times on both sides of the equation. The homogeneity under the scaling of the underlying measure is the reason why $1/p + 1/q = 1/r$.
\end{remark}







\chapter{Schwartz Space and Tempered Distributions}

We have already encountered the fact that Fourier transforms are well behaved under differentiation and multiplication by polynomials. If we let $\mathcal{S}(\RR^d)$ denote a class of functions under which to study this phenomenon, it must be contained in $L^1(\RR^d)$ and $C^\infty(\RR^d)$, and also be closed under multiplication by polynomials. The differentiability and polynomial closure imply that the elements of $\mathcal{S}(\RR^d)$ must have rapid decay properties: For any non-negative integer $m$ and multi-index $\alpha$, there exists a constant $C_{\alpha,\beta}$ such that
%
\[ |f_\alpha(x)| \leq \frac{C_{\alpha,m}}{1 + |x|^m}. \]
%
We take this as a \emph{definition} of the space $\mathcal{S}(\RR^d)$. That is, for each non-negative integer $n$ and $m$, we consider the seminorm
%
\[ \| f \|_{n,m} = \sup_{|\beta| \leq n} \| (1 + |x|)^m f_\beta \|_{L^\infty(\RR^d)}. \]
%
We then consider
%
\[ \mathcal{S}(\RR^d) = \left\{ f: \RR^d \to \RR: \text{for all}\ n,m, \| f \|_{n,m} < \infty \right\}. \]
%
Elements of $\mathcal{S}(\RR^d)$ are known as \emph{Schwartz functions}, and $\mathcal{S}(\RR^d)$ is known as the \emph{Schwartz space}. The seminorms naturally give $\mathcal{S}(\RR^d)$ the structure of a Fr\'{e}chet space. Sometimes, it is more convenient to use the equivalent family of seminorms $\| f \|_{\alpha, \beta} = \| x^\alpha f_\beta \|_{L^\infty(\RR^n)}$, because $x^\alpha$ often behaves more nicely under various operations. It is obvious that $\mathcal{S}(\RR^d)$ is separated by the seminorms defined on it, because $\| \cdot \|_{L^\infty(\RR^d)} = \| \cdot \|_{0,0}$ is a norm used to define the space. We now show the choice of seminorms make the space complete.

\begin{theorem}
	$\mathcal{S}(\RR^d)$ is a complete metric space.
\end{theorem}
\begin{proof}
	Let $\{ f_1,f_2, \dots \}$ be a Cauchy sequence with respect to the seminorms. This implies that for each integer $m$, and multi-index $\alpha$, the sequence of functions $(1 + |x|)^m (f_k)_\alpha$ is Cauchy in $L^\infty(\RR^d)$. Since $L^\infty(\RR^d)$ is complete, there are functions $g_{m,\alpha}$ such that $(1 + |x|)^m (f_k)_\alpha$ converges uniformly to $g_{m,\alpha}$. If we set $f = g_{0,0}$, then it is easy to see using the basic real analysis of uniform continuity that $f$ is infinitely differentiable, and $(1 + |x|)^m f_\alpha = g_{m,\alpha}$. This shows that $f \in C^\infty(\RR^d)$. The sequence $\{ f_k \}$ is bounded in $\mathcal{S}(\RR^d)$, since it is Cauchy. And since $\| f_k - f \|_{n,m} \to 0$ for each $n$ and $m$, this implies that $\| f \|_{n,m} < \infty$ for each $n$ and $m$. Thus $f \in \mathcal{S}(\RR^d)$, and $f_k \to f \in \mathcal{S}(\RR^d)$.
\end{proof}

\begin{example}
	The Gaussian function $\phi: \RR^d \to \RR$ defined by $\phi(x) = e^{-|x|^2}$ is Schwartz. For any multi-index $\alpha$, there is a polynomial $P_\alpha$ of degree at most $|\alpha|$ such that $\phi_\alpha = P_\alpha \phi$; this can be established by a simple induction. But this means that for each fixed $\alpha$, $|P_\alpha(x)| \lesssim 1 + |x|^{|\alpha|}$. Since $e^{-|x|^2} \lesssim 1/(1 + |x|)^{m + |\alpha|}$ for any fixed $m$ and $\alpha$, we find
	%
	\[ | (1 + |x|)^m \phi_\alpha| \leq (1 + |x|)^m |P_\alpha \phi| \lesssim \frac{1 + |x|^{|\alpha| + m}}{1 + |x|^{|\alpha| + m}} = 1. \]
	%
	Since $m$ and $\alpha$ were arbitrary, this shows $\phi$ is Schwartz.
\end{example}

\begin{example}
	The space $C^\infty_c(\RR^d)$ consists of all compactly supported $C^\infty$ functions. If $f \in C^\infty_c(\RR^d)$, then $f$ is Schwartz. This is because for each $\alpha$ and $m$, $(1 + |x|)^m f_\alpha$ is a continuous function vanishing outside a compact set, and is therefore bounded.
\end{example} 

Because of the sharp control we have over functions in $\mathcal{S}(\RR^d)$, almost every analytic operation we want to perform on $\mathcal{S}(\RR^d)$ is continuous. To show that an operator $T$ on $\mathcal{S}(\RR^d)$ is bounded, it suffices to show that for each $n$ and $m$, there is $n'$, $m'$ such that $\| Tf \|_{n,m} \lesssim_{n,m} \| f \|_{n',m'}$. For a functional $\Lambda: \mathcal{S}(\RR^d) \to \RR$, it suffices to show that there exists $n$ and $m$ such that $|\Lambda f| \lesssim \| f \|_{n,m}$. The minimal such choice of $n$ is known as the {\bf order} of $\Lambda$. We normally do not care about the constant behind the operators for these norms, since the norms are not translation invariant and therefore highly sensitive to the positions of various operations. We really just care about proving the existence of such a constant.

\begin{lemma}
	If $g$ is a function, with $g$ and all it's derivatives subpolynomial, then the map $f \mapsto gf$ is a bounded operator on $\mathcal{S}(\RR^d)$.
\end{lemma}
\begin{proof}
	Fix $n$, and find values $A$ and $M$, depending only on $n$ and $g$, such that for any $|\beta| \leq n$,
	%
	\[ |g_\beta(x)| \leq A \cdot (1 + |x|)^M. \]
	%
	Consider $|\alpha| \leq n$. Then the Leibnitz formula implies that
	%
	\begin{align*}
		(1 + |x|)^m |(gf)_\alpha| &\leq 2^{|\alpha|} \sum_{\beta \leq \alpha} (1 + |x|)^m |g_\beta f_{\alpha-\beta}|\\
		&\leq A \cdot 2^n \sum_{\beta \leq \alpha} (1 + |x|)^{m+M} |f_{\alpha-\beta}|\\
		&\leq A \cdot 4^n \| f \|_{n,m+M}.
	\end{align*}
	%
	Thus $\| gf \|_{n,m} \lesssim_{n,m} \| f \|_{n,m+M}$, which implies the operator is bounded.
\end{proof}

If $f$ and $g$ are Schwartz functions, and $|\alpha| \leq n$, then the Leibnitz formula again implies that if $k + k' = m$, then
%
\begin{align*}
	(1 + |x|)^m (gf)_\alpha &\lesssim_n \sum_{\beta \leq \alpha} (1 + |x|)^m g_\beta f_{\alpha - \beta} \lesssim_n \| f \|_{n,k} \| g \|_{n,k'}
\end{align*}
%
Thus $\| gf \|_{n,m} \lesssim_{n,m} \| f \|_{n,k} \| g \|_{n,k'}$, so $(f,g) \mapsto fg$ is a continuous bilinear operator on $\mathcal{S}(\RR^d) \times \mathcal{S}(\RR^d)$. Most importantly, we have shown the product of two Schwartz functions is Schwartz.

\begin{theorem}
	The following sublinear operators are all bounded on $\mathcal{S}(\RR^n)$.
	%
	\begin{itemize}
		\item For each $h \in \RR^n$, the translation operator $(T_h f)(x) = f(x - h)$.

		\item For each $\xi \in \RR^n$, the modulation operator $(M_\xi f)(x) = e(\xi \cdot x) f(x)$.

		\item The $L^p$ norms $\| f \|_{L^p(\RR^n)}$, for $1 \leq p \leq \infty$.

		\item The Fourier transform.
	\end{itemize}
	%
	Furthermore, the Fourier transform is an isomorphism of $\mathcal{S}(\RR^n)$.
\end{theorem}
\begin{proof}
%	Let $(T_h f)(x) = f(x - h)$. We calculate that if $|\alpha| \leq n$, then
	%
%	\begin{align*}
%		(1 + |x|^m) (T_h f)_\alpha &= T_h((1 + |x + h|^m) f_\beta)\\
%		&\leq 2^m T_h((1 + |x|^m + |h|^m) f_\alpha)\\
%		&\leq 2^m |h|^m \| f_\alpha \|_{n,0} + 2^m \| f \|_{n,m}.
%	\end{align*}
	%
%	Thus $\| T_h f \|_{n,m} \leq 2^m(1 + |h|^m) \| f \|_{n,m}$, so $T_h$ is continuous.

%	Similarily, we calculate using the Leibnitz formula and the formula for the derivatives of $e(\xi \cdot x)$ that if $|\alpha| \leq n$, then
	%
%	\[ (1 + |x|^m) |(e(\xi \cdot x) f)_\alpha| \leq 4^n (2\pi)^n (1 + |\xi|^n) \| f \|_{n,m} \]
	%
%	Thus $\| M_\xi f \|_{n,m} \leq (8 \pi)^n (1 + |\xi|^n) \| f \|_{n,m}$.

%	For any Schwartz function $f$, and $|\alpha| \leq n$,
	%
%	\[ f(x) \leq \frac{\| f \|_{0,d+1}}{1 + |x|^{d+1}} \]
	%
%	Integrating this equation gives
	%
%	\[ \| f_\alpha \|_{L^1(\RR^d)} \leq 2^d \| f \|_{0,d+1}. \]
	%
%	Thus $\| \cdot \|_1$ is a bounded norm on the space. Interpolation then shows that for any $1 < p < \infty$,
	%
%	\[ \| f \|_{L^p(\RR^d)} \leq \| f \|_{L^1(\RR^d)}^{1 - 1/p} \| f \|_{L^\infty(\RR^d)}^{1/p} \leq \| f \|_{L^1(\RR^d)} + \| f \|_{L^\infty(\RR^d)} \leq 2 \| f \|_{0,d+1}. \]
	%
%	This implies $\| \cdot \|_{L^p(\RR^d)}$ is bounded.

%	A simple calculation using the Leibnitz formula shows that if $|\alpha| \leq n$,
	%
%	\begin{align*}
%		(1 + |x|^m) |\mathcal{F}(f)_\alpha| &\leq |\mathcal{F}(f)_\alpha| + \sum_{k = 1}^d |x_k^m \mathcal{F}(f)_\alpha|\\
%		&\leq (2 \pi)^n \left( \| \mathcal{F} f \|_{L^\infty(\RR^d)} + \sum_{k = 1}^d |\mathcal{F}((x^\alpha f)_{me_k})| \right)\\
%		&\leq n! (2 \pi)^n 2^m (n+1) \max_{0 \leq k \leq d} \max_{1 \leq l \leq m} \left( \| \mathcal{F} f \|_{L^\infty(\RR^d)} + \sum_{k = 1}^n \max_{1 \leq l \leq m} \| \mathcal{F}(f_{le_k}) \|_{L^\infty(\RR^d)} \right)\\
%		&\leq n! (2 \pi)^n 2^m \left( \| f \|_{L^1(\RR^d)} + \sum_{k = 1}^n \max_{1 \leq l \leq m} \| f_{le_k} \|_{L^1(\RR^d)} \right)\\
%		&\leq n! (2 \pi)^n 2^m 2^d (n+1) \| f \|_{n,d+1}.
%	\end{align*}

%	there are constants $c_{\alpha \beta \gamma}$ for each $\gamma \leq \alpha \wedge \beta$ such that
	%
%	\begin{align*}
%		|x^\alpha \mathcal{F}(f)_\beta| &= (2 \pi)^{|\beta|} |x^\alpha \cdot \mathcal{F}(x^\beta f)|\\
%		&= (2\pi)^{|\beta| - |\alpha|} \mathcal{F}((x^\beta f)_\alpha)\\
%		&\leq (2\pi)^{|\beta| - |\alpha|} \sum_{\gamma \leq \alpha \wedge \beta} c_{\alpha \beta \gamma} |\mathcal{F}(x^{\beta - \gamma} f_{\alpha - \gamma})|.
%	\end{align*}
	%
%	This calculation shows
	%
%	\begin{align*}
%		\| \mathcal{F} f \|_{\alpha,\beta} &\lesssim_{\alpha,\beta} \sum \| \mathcal{F}(x^{\beta - \gamma} f_{\alpha - \gamma}) \|_{L^\infty(\RR^n)}\\
%		&\leq \sum \| x^{\beta - \gamma} f_{\alpha - \gamma} \|_{L^1(\RR^n)}.
%	\end{align*}
	%
%	The right hand side is a continuous function of $f$, so the Fourier transform is bounded. The smoothness of the Schwartz space implies that $\mathcal{F}$ is a bijective map. But then the open mapping theorem implies that $\mathcal{F}^{-1}$ is a bounded operation, and therefore $\mathcal{F}$ is a homeomorphism.

	We leave all but the last point as exercises. Here it will be convenient to use the norms $\| \cdot \|_{\alpha,\beta}$ as well as the norms $\| \cdot \|_{n,m}$. If $|\alpha| \leq m$, $|\beta| \leq n$, then we can use the Leibnitz formula to conclude that
	%
	\begin{align*}
		|\xi^\alpha \mathcal{F}(f)_\beta| &\lesssim_{\alpha,\beta} \mathcal{F}((x^\beta f)_\alpha)\\
		&\lesssim_{\alpha,\beta} \max_{\gamma \leq \alpha \wedge \beta} |\mathcal{F}(x^{\beta - \gamma} f_{\alpha - \gamma})|\\
		&\lesssim_{\alpha,\beta} \max_{\gamma \leq \alpha \wedge \beta} \| x^{\beta - \gamma} f_\gamma \|_{L^1(\RR^d)}\\
		&\leq \max_{\gamma \leq \alpha \wedge \beta} \| (1 + |x|)^{|\beta|} f_\gamma \|_{L^1(\RR^d)} \lesssim \| f \|_{|\alpha|,|\beta|+d+1}.
	\end{align*}
	%
	Thus $\mathcal{F}$ is a bounded linear operator on $\mathcal{S}(\RR^d)$. Since all Schwartz functions are arbitrarily smooth, the Fourier inversion formula applies to all Schwartz functions, and so $\mathcal{F}$ is a bijective bounded linear operator with inverse $\mathcal{F}^{-1}$. The open mapping theorem then immediately implies that $\mathcal{F}^{-1}$ is bounded.
\end{proof}

\begin{corollary}
	If $f$ and $g$ are Schwartz, then $f * g$ is Schwartz.
\end{corollary}
\begin{proof}
	Since $f * g = \mathcal{F}^{-1}(\mathcal{F}(f) \mathcal{F}(g))$, this fact follows from the fact that the product of two Schwartz functions is Schwartz.
\end{proof}

Now we get to the interesting part of the theory. We have defined a homeomorphic linear transform from $\mathcal{S}(\RR^d)$ to itself. The theory of functional analysis then says that we can define a dual map, which is a homeomorphism from the dual space $\mathcal{S}(\RR^d)^*$ to itself. Note the inclusion map $C_c^\infty(\RR^d) \to \mathcal{S}(\RR^d)$ is continuous, and $C_c^\infty(\RR^d)$ is dense in $\mathcal{S}(\RR^d)$. This implies that we have an injective, continuous map from $\mathcal{S}^*(\RR^d)$ to $(C_c^\infty)^*(\RR^d)$, so every functional on the Schwarz space can be identified with a distribution. We call such distributions {\bf tempered}. They are precisely the linear functionals on $C_c^\infty(\RR^d)$ which have a continuous extension to $\mathcal{S}(\RR^d)$. Intuitively, this corresponds to an asymptotic decay condition.

\begin{example}
	For any $f \in L^1_{\text{loc}}(\RR^d)$, we define $f^*$ to be the distribution
	%
	\[ f^*(\phi) = \int f(x) \phi(x)\; dx \]
	%
	But this distribution is not always tempered. If $f \in L^p(\RR^d)$ for some $p$, then, applying H\"{o}lder's inequality, we obtain that
	%
	\[ |f^*(\phi)| \leq \| f \|_{L^p(\RR^d)} \| \phi \|_{L^q(\RR^d)}. \]
	%
	Since $\| \cdot \|_{L^q(\RR^d)}$ is a continuous norm on $\mathcal{S}(\RR^d)$, this shows $f^*$ is bounded. More generally, if $f \in L^1_{\text{loc}}(\RR^d)$, and $f(x) (1 + |x|)^{-m}$ is in $L^p(\RR^d)$ for some $m$, then $f^*$ is a tempered distribution. If $p = \infty$, such a function is known as {\bf slowly increasing}.
\end{example}

\begin{example}
	For any Radon measure, $\mu$, we can define a distribution
	%
	\[ \mu^*(\phi) = \int \phi(x) d\mu(x) \]
	%
	But this distribution is not always tempered. If $|\mu|$ is finite, the inequality $\| \mu^*(\phi) \| \leq \| \mu \| \| \phi \|_{L^\infty(\RR^d)}$ gives boundedness. More generally, if $\mu$ is a measure such that $|\mu(x)|/(1 + |x|^\alpha)$ is finite for some $k$, then $\mu$ is known as a {\bf tempered measure}, and also acts as a tempered distribution, since
	%
	\[ |\mu^*(\phi)| \leq \| \mu(x)/(1 + |x|^\alpha) \| \| \phi \|_{L^\infty(\RR^d, 1 + |x|^\alpha)}. \]
\end{example}

\begin{example}
	Suppose $\Lambda$ is a distribution support on a compact set $K$. Then $\Lambda$ is tempered, since if $\psi$ is a compactly supported bump function on $K$, then for any Schwarz function $\phi$ we can define $\Lambda(\phi) = \Lambda(\psi \phi)$, which is continuous.
\end{example}

\begin{example}
	The function $1/x$ is not locally integrable on $\RR$, since it is not defined near the origin. However, we can associate the value with a distribution. If $\phi$ is a Schwartz function, we define the {\bf principal value}
	%
	\[ \text{p.v.} \int_{-\infty}^\infty \frac{\phi(x)}{x}\; dx = \lim_{\varepsilon \to 0} \int_{|x| \geq \varepsilon} \frac{\phi(x)}{x}\; dx \]
	%
	Since $\int_{\varepsilon \leq |x| \leq 1} dx/x = 0$ for any $\varepsilon \leq 1$, we can write
	%
	\[ \int_{|x| \geq \varepsilon} \frac{\phi(x)}{x} = \int_{|x| \geq 1} \frac{\phi(x)}{x} + \int_{\varepsilon \leq |x| \leq 1} \frac{\phi(x) - \phi(0)}{x} \]
	%
	Since $\phi$ has rapid decay, the first integral is well defined. Since $\phi$ is differentiable at the origin, the second integral is bounded for all $\varepsilon \geq 0$. But this means that
	%
	\[ \lim_{\varepsilon \to 0} \frac{\phi(x)}{x} = \int_{|x| \geq 1} \frac{\phi(x)}{x} + \int_{|x| \leq 1} \frac{\phi(x) - \phi(0)}{x} \]
	%
	Thus it is evident that the principal value exists, and
	%
	\[ \left| \text{p.v.} \int_{-\infty}^\infty \frac{\phi(x)}{x}\; dx \right| \lesssim \| \phi \|_{L^1(\RR)} + \| \phi' \|_{L^\infty(\RR)} \]
	%
	so this functional is a tempered distribution of order 1, and is denoted by $\text{p.v.}(1/x)$. It is intimately connected to the theory of the Hilbert transform. 
\end{example}

Using the same techniques as for distributions, the derivative $\Lambda_\alpha$ of a tempered distribution $\Lambda$ is tempered, as is $\phi \Lambda$, whenever $\phi$ is a Schwartz function, or $f \Lambda$, where $f$ is a polynomial.

To remind the reader, we think of a distribution $\Lambda$ as corresponding to arbitrarily regular function $f$ such that
%
\[ \Lambda(\phi) = \int f(x) \phi(x)\; dx \]
%
If we can justify an identity with respect to this operation which removes the reliance of regularity on $f$, we can normally swap $f$ with a general distribution, and use it to define the operation on all distributions.

We now apply this process to define the Fourier transform of a tempered distribution. The multiplication formula
%
\[ \int \widehat{f}(x) g(x) = \int f(x) \widehat{g}(x) \]
%
provides the perfect situation. It says that for $f \in L^1(\RR^d)$, $\Lambda_{\mathcal{F}(f)}(g) = \Lambda_f(\mathcal{F}(g))$. If we want to generalize the Fourier transform to be defined on distributions, we better have $\mathcal{F}(\Lambda_f) = \Lambda_{\mathcal{F}(f)}$ for all integrable $f$. In particular, this motivates us to define the general Fourier transform of a tempered distribution $\Lambda$ as $\mathcal{F}(\Lambda)(\phi) = \Lambda \left( \mathcal{F}(\phi) \right)$. Similarily, we can define the inverse Fourier transform, which are the dual maps of the Fourier transforms and it's inverse, so they are obviously homeomorphisms of the space of tempered distributions.

\begin{theorem}
	If $\Lambda$ is tempered,
	%
	\[ \mathcal{F}(\Lambda_\alpha) = (-2 \pi i \xi)^\alpha \mathcal{F}(\Lambda)\quad\text{and}\quad \mathcal{F}((-2\pi i \xi)^\alpha \Lambda)) = \mathcal{F}(\Lambda)_\alpha. \]
\end{theorem}

\begin{example}
	Consider the constant function $1$. Then
	%
	\[ 1(\phi) = \int \phi(x)\; dx \]
	%
	and so
	%
	\[ \widehat{1}(\phi) = \int \widehat{\phi}(\xi)\; d\xi = \phi(0) = \delta(\phi) \]
	%
	so $\widehat{1}$ is the Dirac delta distribution $\delta$. Similarily,
	%
	\[ \widehat{\delta}(\phi) = \widehat{\phi}(0) = \int \phi(x)\; dx = 1(\phi) \]
	%
	so the Fourier transform of the Dirac delta function is the constant 1 function.
\end{example}

\begin{example}
	We know $((-2 \pi i x)^\alpha)^\ft = ((- 2 \pi i x)^\alpha \cdot 1)^\ft = \delta_\alpha$, which essentially provides us a way to compute the Fourier transform of any polynomial.
\end{example}

\begin{theorem}
	If $\mu$ is a finite measure, $\widehat{\mu}$ is a uniformly continuous bounded function with $\| \widehat{\mu} \|_{L^\infty(\RR^d)} \leq \| \mu \|$, and
	%
	\[ \widehat{\mu}(\xi) = \int e(- x \cdot \xi) d\mu(x) \]
	%
	The function $\widehat{\mu}$ is also smooth if $\mu$ has moments of all orders, i.e. $\int |x|^k d\mu(x) < \infty$ for all $k > 0$.
\end{theorem}
\begin{proof}
	Let $\phi \in \mathcal{S}(\RR^d)$. We then calculate that
	%
	\[ \widehat{\mu} \cdot \phi \]

	If $f$ is integrable, we can apply Fubini's theorem to conclude
	%
	\begin{align*}
		\int \widehat{f}(x) d\mu(x) &= \int \int f(\xi) e(- \xi \cdot x) d\xi\; d\mu(x)\\
		&= \int f(\xi) \int e(- \xi \cdot x) d\mu(x)\; d\xi\\
		&= \int f(\xi) \widehat{\mu}(\xi)\; d\xi
	\end{align*}
	%
	This gives that the distribution $\widehat{\mu}$ is given by integration with respect the required function. It is easy to check that $\| \widehat{\mu} \|_{L^\infty(\RR^d)} \leq \| \mu \|$. Moreover, $\widehat{\mu}$ is continuous, since by the dominated convergence theorem,
	%
	\[ \widehat{\mu}(\xi + \eta) - \widehat{\mu}(\xi) = \int e(-\xi \cdot x) (e(- \eta \cdot x) - 1) d\mu(x) \]
	%
	as $h \to 0$, the values of the function in the integral converge pointwise to $0$, and so the uniform continuity follows by the dominated convergence theorem. 

	To show $\widehat{\mu}$ is smooth if it has all moments, we calculate that if $|\eta| = 1$, and $t \in \RR$, then
	%
	\[ \frac{\widehat{\mu}(\xi + t \eta) - \widehat{\mu}(\xi)}{t} = \int e(- \xi \cdot x)(e(-t \eta \cdot x) - 1)\; d\mu(x). \]
\end{proof}

Not being compactly supported, we cannot compute the convolution of tempered distributions with all $C^\infty$ functions. Nonetheless, if $\phi$ is Schwartz, and $\Lambda$ is tempered, then the definition $(\Lambda * \phi)(x) = \Lambda(T_x \phi^*)$ certainly makes sense, and gives a $C^\infty$ function satisfying $D^\alpha(\Lambda * \phi) = (D^\alpha \Lambda) * \phi = \Lambda * (D^\alpha \phi)$. This function is slowly increasing, since it has polynomial growth. We know for some $N > 0$, for any Schwartz $\phi$,
%
\[ |\Lambda(\phi)| \lesssim \sup \{ |x^\alpha| |D^\beta \phi| : |\alpha|, |\beta| \leq N, k > 0 \} \]
%
TODO: FINSIH THIS. Because $\Lambda * \phi$ is tempered, this means that we can consider the Fourier transform $\smash{\widehat{\Lambda * \phi}}$. If $\psi$ is compactly supported, then
%
\[ (\Lambda * \phi)^\ft \left(\widehat{\psi} \right) = s \]
%
TODO: FINISH, which proves $\widehat{\Lambda * \phi} = \widehat{\Lambda} \widehat{\phi}$.

\begin{example}
	It is often useful to know the Fourier transform of the radial functions $f(x) = 1/|x|^\alpha$ on $\RR^d$, for $\alpha < d$, so that the function is locally integrable. Since $f$ satisfies a multiplicative symmetry $f(tx) = t^{-\alpha} f(x)$, the multiplicative Haar measure $dt/t$ become very useful in the analysis of this function. We calculate that the multiplicative convolution of this character against a Gaussian gives, for $\alpha > 0$, by a change of variables,
    %
    \[ \int_0^\infty t^\alpha e^{- \pi t^2 |x|^2}\; \frac{dt}{t} = \frac{1}{2\pi^{\alpha/2} |x|^\alpha} \int_0^\infty s^{\alpha/2} e^{-s} \frac{ds}{s} = \frac{\Gamma(\alpha/2)}{2 \pi^{\alpha/2} |x|^\alpha} \]
    %
    Let $g(x)$ denote the left hand side of the equation. Then if $\phi$ is an arbitrary Schwarz function, for $\alpha < d$, using Fubini's theorem,
    %
    \begin{align*}
    	\int g(x) \phi^\vee(x)\; dx &= \int \int \int_0^\infty t^\alpha e^{- \pi t^2 |x|^2}\; \phi(\xi) e(\xi \cdot x)\; \frac{dt}{t}\; d\xi\; dx\\
    	&= \int \phi(\xi) \int_0^\infty t^\alpha \int e^{- \pi t^2 |x|^2} e(\xi \cdot x)\; dx\; \frac{dt}{t}\; d\xi\\
    	&= \int \phi(\xi) \int_0^\infty t^{\alpha - d} e^{- \pi |\xi|^2/t^2}\; \frac{dt}{t}\; d\xi\\
    	&= \int \frac{\Gamma((d-\alpha)/2)}{2\pi^{(d-\alpha)/2} |\xi|^{d - \alpha}} \phi(\xi)\; d\xi
    \end{align*}
    %
    Thus, putting these two calculations together, we conclude
    %
    \[ \frac{\Gamma(\alpha/2)}{2 \pi^{\alpha/2}} (1/|x|^\alpha)^\ft = \frac{\Gamma((d-\alpha)/2)}{2 \pi^{(d-\alpha)/2} |\xi|^{d-\alpha}} \]
    %
    which can be simplified to
    %
    \[ (1/|x|^\alpha)^\ft = \frac{\Gamma((d-\alpha)/2)}{\Gamma(\alpha/2)} \pi^{\alpha-d/2} \frac{1}{|\xi|^{d-\alpha}} \]
    %
    Thus the Fourier transforms $|x|^{-\alpha}$ for $\alpha \in (0,d)$ map into themselves. For $\alpha \geq d$, we need to work with principal values TODO:
\end{example}

\section{Convolution Operators}

It is know that if $T: D(\RR^d) \to C^\infty(\RR^d)$ is any continuous linear functional commuting with translations, it is given by convolution from some distribution. If this convolution is with respect to some tempered distribution, then the transformation extends from a map from $\mathcal{S}(\RR^d)$ to $C^\infty(\RR^d)$. Studying the class of operators which commute with translations is very important because these operators occur again and again in Harmonic analysis. To begin with, with rely on a regularity result on the differentiation of functions in $L^p$ spaces.

\begin{lemma}
	If $f \in L^p(\RR^d)$, has derivatives in the $L^p$ norm of all orders $\leq d+1$, then $f$ is almost everywhere equal to a continuous function $g$ such that
	%
	\[ |g(0)| \lesssim \sum_{|\alpha| \leq n + 1} \| D^\alpha f \|_p \]
	%
	where the hidden constant depends only on $n$ and $p$.
\end{lemma}
\begin{proof}
	s
\end{proof}

\begin{theorem}
	If $T: L^p(\RR^d) \to L^q(\RR^d)$ is bounded, linear, and commutes with translations, then there exists a unique tempered distribution $\Lambda$ such that $T(\phi) = \Lambda * \phi$ for all $\phi \in \mathcal{S}(\RR^d)$
\end{theorem}
\begin{proof}
	If $T$ commutes with translations, then for any Schwartz function $\phi$, $T\phi$ has derivatives in the $L^q$ norm of all orders, since $\Delta_{h,e}(T \phi) = T(\Delta_{h,e} \phi)$, and $\Delta_{h,e} \phi$ converges to $D_e \phi$ in the $L^q$ norm, since the $L^q$ norm is continuous in Schwartz space. In particular, we find $D^\alpha (T\phi) = T(D^\alpha \phi)$. Thus $T\phi$ is equal to a continuous function $g_\phi$ with
	%
	\[ |g_\phi(0)| \lesssim \sum_{|\alpha| \leq n+1} \| D^\alpha(T\phi) \|_q = \sum_{|\alpha| \leq n+1} \| T(D^\alpha \phi) \|_q \leq \| T \| \sum_{|\alpha| \leq n+1} \| D^\alpha \phi \|_q \]
	%
	The map $\phi \mapsto g_\phi(0)$ is therefore continuous on $\mathcal{S}(\RR^d)$, and therefore defines a tempered distribution $\Lambda$, and the fact that $T(\phi) = \Lambda * \phi$ then holds by the translation invariance of $T$.
\end{proof}

\begin{remark}
	It therefore follows that if $T: L^p(\RR^d) \to L^q(\RR^d)$ is bounded, linear, and commutes with translations, then for any Schwartz function $\phi$, $T\phi$ is $C^\infty$, and is slowly increasing, as is all of it's derivatives.
\end{remark}

For each $p$ and $q$, we will let $(L^p,L^q)$ denote the space of tempered distributions which define a continuous linear map from $L^p(\RR^d)$ to $L^q(\RR^d)$, in the sense that the map $\phi \mapsto \Lambda * \phi$ is continuous as a map from $\mathcal{S}(\RR^d)$ to $L^q(\RR^d)$, and, by the Hahn-Banach theorem, extends uniquely to a linear map on the whole space. In general, a characterization of such distributions is unknown except in a few situations.

\begin{example}
	The distributions in $(L^2, L^2)$ are Fourier transforms of elements of $L^\infty(\RR^d)$. The $L^\infty$ norm of the element corresponds to the norm of the convolution operator. To see this, if $\Lambda$ is a distribution, and $\Phi$ is the Gaussian distribution, $\Phi(x) = e^{-\pi|x|^2}$, then $\Lambda * \Phi$ is an $L^2$ function, since $\Phi$ is in $L^2$, and as such we conclude by the Plancherel theorem that $(\Lambda * \Phi)^\ft = \Phi \Lambda^\ft$ is an element of $L^2(\RR^d)$. Thus we can think of $\widehat{\Lambda} = e^{\pi |x|^2} (\Lambda * \Phi)^\ft$ as a function $f$. Plancherel's theorem implies that for any Schwarz function $\phi$,
	%
	\[ \| f \widehat{\phi} \|_2 = \| \Lambda * \phi \|_2 \lesssim \| \phi \|_2 = \| \widehat{\phi} \|_2 \]
	%
	But this means that $f \in L^\infty(\RR^d)$, for if there is a set $E$ of positive measure where $|f| \geq M$, we can find $\widehat{\phi}$ with $\widehat{\phi} = 1$ on $E$ and with $\| \widehat{\phi} \|_2 = |E| + \varepsilon$, and then $\| f \widehat{\phi} \|_2 \geq M \| \widehat{\phi} \|_2$. Note that over $L^2(\mathbf{T})$, the only convolution operators are given by the distributions given by a Fourier series with bounded coefficients.
\end{example}

\begin{example}
	The distributions in $(L^1, L^1)$ are precisely the finite Borel measures. The total variation of the measure corresponds to the norm of the convolution operator. It is clear that if $\mu$ is a Borel measure, then $\| \mu * \phi \|_1 \leq \| \mu \|_1 \| \phi \|_1$. Conversely, if $\Lambda \in (L^1, L^1)$, and $\Phi_\delta$ is the Gauss kernel, then we set $\Lambda_\delta = \Lambda * \Phi_\delta$. By assumption, $\Lambda_\delta$ is an $L^1$ function, and so $\Lambda$, $\| \Lambda_\delta \|_1 \lesssim \| \Phi_\delta \|_1 = 1$. This implies that the $\Lambda_\delta$ are uniformly bounded in $L^1$, so by the Banach Alaoglu theorem, since $L^1(\RR^d)$ embeds itself in $M(\RR^d)$, which is the dual of $C_0(\RR^d)$, some subsequence of the $\Lambda_\delta$ converge weakly to some measure $\mu$. We claim $\Lambda = \Lambda_\mu$. To prove this, fix some Schwartz function $\phi$. If we let $\phi_\delta = \phi * \Phi_\delta$, then $D^\alpha \phi_\delta = (D^\alpha \phi) * \Phi_\delta$ converges uniformly to $D^\alpha \phi$, so $\phi_\delta$ converges to $\phi$ in $\mathcal{S}(\RR^d)$, and so $\Lambda(\phi)$ is the limit of $\Lambda(\phi_\delta)$. But
	%
	\begin{align*}
		\Lambda(\phi_\delta) &= \Lambda(\Phi_\delta * \phi) = (\Lambda * (\Phi_\delta * \phi)^*)(0)\\
		&= ((\Lambda * \Phi_\delta) * \phi^*)(0)\\
		&= \Lambda_\delta(\phi)
	\end{align*}
	%
	and we know some subsequence converges to $\int \phi(x) d\mu(x)$. But we know that overall the values converge to $\Lambda(\phi)$, which implies
	%
	\[ \Lambda(\phi) = \int \phi(x) d\mu(x) \]
	%
	Since $\phi$ was an arbitrary Schwartz function, we can now apply the density of $\mathcal{S}(\RR^d)$ in $L^1(\RR^d)$ to conclude that for any integrable function $f$,
	%
	\[ \Lambda(f) = \int f(x) d\mu(x) \]
	%
	This classifies the $(L^1, L^1)$ distributions.
\end{example}

We also have a duality theorem.

\begin{theorem}
	For any two $(p,q)$, $(L^p,L^q) = (L^{q^*}, L^{p^*})$.
\end{theorem}












\chapter{Riemann Theory of Trigonometric Series}

Using the techniques of measure theory, we can actually prove that the Fourier series is essentially the unique way of representing a function on any part of its domain as a trigonometric series.

\begin{lemma}
  For any sequence $u_n$ and set $E$ of finite measure,
  %
  \[ \lim_{n \to \infty} \int_E \cos^2(nx + u_n)\; dx = |E|/2 \]
\end{lemma}
\begin{proof}
  We have
  %
  \[ \cos^2(nx + u_n) = \frac{1 + \cos(2nx + 2u_n)}{2} = \frac{1}{2} + \frac{\cos(2nx) \cos(2u_n) - \sin(2nx) \sin(2u_n)}{2} \]
  %
  Since $\cos(2u_n)$ and $\sin(2u_n)$ are bounded, we have $\int \chi_E(x) \cos(2nx)$ and $\int \chi_E(x) \sin(2nx) \to 0$ as $n \to \infty$, and the same is true for the latter component of the sum since $\cos(2u_n)$ and $\sin(2u_n)$ are bounded, we conclude that
  %
  \[ \int_E \cos^2(nx + u_n) = \int \chi_E(x) \cos^2(nx + u_n) = |E|/2 \]
  %
  completing the proof.
\end{proof}

\begin{theorem}[Cantor-Lebesgue Theorem]
  If, for some pair of sequences $a_0, a_1, \dots$ and $b_0, b_1, \dots$ are chosen such that
  %
  \[ \sum_{n = 0}^\infty a_n \cos(2 \pi nx) + b_n \sin(2 \pi nx) \]
  %
  converges on a set of positive measure in $[0,1]$, then $a_n, b_n \to 0$.
\end{theorem}
\begin{proof}
  Let $E$ be the set of points upon which the trigonometric series converges. We write $a_n \cos(2 \pi n x) + b_n \sin(2 \pi n x) = r_n \cos(nx + c_n)$. The result of the theorem is then precisely that $r_n \to 0$. If this is not true, then we must have $\cos(nx + c_n) \to 0$ for every $x \in E$. In particular, the dominated convergence theorem implies that
  %
  \[ \lim_{n \to \infty} \int_E \cos(nx + c_n)^2\; dx = 0 \]
  %
  Yet we know this tends to $|E|/2$ as $n \to \infty$, which is a contradiction.
\end{proof}

TODO: EXPAND ON THIS FACT.






\section{Convergence in $L^p$ and the Hilbert Transform}

We now move onto a more 20th century viewpoint on Fourier series, namely, those to do with operator theory. Under this viewpoint, the properties of convergence are captured under the boundedness of certain operators on function spaces, allowing us to use the modern theory of functional analysis to it's full extent on our problems. However, unlike in most of basic functional analysis, where we assume all operators we encounter are bounded to begin with, in harmonic analysis we more often than not are given an operator defined only on a subset of spaces, and must prove the continuity of such an operator to show it is well defined on all of space. We will illustrate this concept through the theory of the circular Hilbert transform, and its relation to the norm convergence of Fourier series.

A {\bf Fourier multiplier} is a linear transform $T$ associated with a given sequence of scalars $\lambda_n$, for $n \in \mathbf{Z}$. It is defined for any trigonometric polynomial $f = \sum_{|n| \leq N} c_n e_n$ as $Tf = \sum_{|n| \leq N} \lambda_n c_n e_n$. The trigonometric polynomials are dense in $L^p(\mathbf{T})$, for each $p < \infty$. An important problem is determining whether $T$ is therefore figuring out whether the operator can be extended to a {\it continuous operator} on the entirety of $L^p$. Because the trigonometric polynomials are dense in $L^p$, in the light of the Hahn Banach theorem it suffices to prove an inequality of the form $\| Tf \| \lesssim \| f \|$. Here are some examples of Fourier operators we have already seen.

\begin{example}
	The truncation operator $S_N$ is the transform associated with the scalars $\lambda_n = [|n| \leq N]$. The truncation is continuous, since for any integrable function $f$, the Fourier coefficients are uniformly bounded by $\| f \|_1$, so $\| S_N f \|_1 \leq N \| f \|_1$. Similarily, the F\'{e}jer truncation $\sigma_N$ associated to the multipliers $\lambda_N = [|n| \leq N](1 - |n|/N)$ is continuous on all integrable functions. These operators are easy to extend precisely because the nonzero multipliers have finite support.
\end{example}

\begin{example}
	In the case of the Abel sum, $A_r$, associated with $\lambda_n = r^{|n|}$, $A_r$ extends in a continuous way to all integrable functions, since
	%
	\[ |A_r f| = \left| \sum r^{|n|} \widehat{f}(n) e_n(t) \right| \leq \| f \|_1 \sum r^{|n|} = \| f \|_1 \left( 1 + \frac{2}{1 - r} \right) \]
	%
	Thus the map is bounded.
\end{example}

To understand whether the truncations $S_N f$ of $f$ converge to $f$ in the $L^p$ norms, rather than pointwise, we turn to the analysis of an operator which is the core of the divergence issue, known as the {\bf Hilbert transform}. It is a Fourier multiplier operator $H$ associated with the coeficients
%
\[ \lambda_n = \frac{\text{sgn}(n)}{i} = \begin{cases} +1/i & n > 0 \\ 0 & n = 0 \\ -1/i & n < 0 \end{cases} \]
%
Because
%
\[ [|n| \leq N] = \frac{\text{sgn}(n + N) - \text{sgn}(n-N)}{2} + \frac{[n = N] + [n = -N]}{2} \]
%
we conclude
%
\[ S_n f = \frac{i \left( e_{-n} H(e_n f) - e_n H(e_{-n} f) \right)}{2} + \frac{\widehat{f}(n) e_n + \widehat{f}(-n) e_{-n}}{2} \]
%
Since the operators $f \mapsto \widehat{f}(n) e_n$ are bounded in all the $L^p$ spaces since they are continuous in $L^1(\mathbf{T})$, we conclude that the operators $S_n$ are uniformly bounded as endomorphisms on $L^p(\mathbf{T})$ provided that $H$ is bounded as an operator from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$. Since $S_n f$ converges to $f$ in $L^p$ whenever $f$ is a trigonometric polynomial, this would establish that $S_n f$ converges to $f$ in the $L^p$ norm for any function $f$ in $L^p(\mathbf{T})$. Later on, as a special case of the Hilbert transform on the real line, we will be able to prove that $H$ is a bounded operator on $L^p(\mathbf{T})$ for all $1 < p < \infty$, and as a result, we find that $S_N f \to f$ in $L^p$ for all such $p$. Unfortunately, $H$ is not bounded from $L^1(\mathbf{T})$ to itself, and correspondingly, $S_N f$ does not necessarily converge to $f$ in the $L^1$ norm for all integrable $f$.

For now, we explore some more ideas in how we can analyze the Hilbert transform via convolution, the dual of Fourier multipliers. The fact that $\smash{\widehat{f * g} = \widehat{f} \widehat{g}}$ implies that if their is an integrable function $g$ whose Fourier coefficients corresponds to the multipliers of an operator $T$, then $f * g = Tf$ for any trigonometric polynomial $f$, and by the continuity of convolution, this is the unique extension of the Fourier multiplier operator. In the theory of distributions, one generalizes the family of objects one can take the Fourier series from integrable functions to a more general family of objects, such that every sequence of Fourier coefficients is the Fourier series of some {\it distribution}. One can take the convolution of any such distribution $\Lambda$ with a $C^\infty$ function $f$, and so one finds that $\Lambda * f = Tf$ for any trigonometric polynomial $f$. There is a theorem saying that {\it all} continuous translation invariant operators from $L^p(\mathbf{T})$ to $L^q(\mathbf{T})$ are given by convolution with a Fourier multiplier operator. In practice, we just compute the convolution kernel which defines the Fourier multiplier, but it is certainly a satisfying reason to justify the study of Fourier multipliers. For instance, a natural question is to ask which Fourier multipliers result in bounded operations in space.

\begin{theorem}
	A Fourier multiplier is bounded from $L^2(\mathbf{T})$ to itself if and only if the coefficients are bounded.
\end{theorem}
\begin{proof}
	If a Fourier multiplier is given by $\lambda_n$, then for some trigonometric polynomial $f$,
	%
	\[ \| Tf \|_2^2 = \sum \left|\widehat{Tf}(n) \right|^2 = \sum |\lambda_n|^2 \left| \widehat{f}(n) \right|^2 \]
	%
	If the $\lambda_n$ are bounded, then we can obtain from this formula the bound
	%
	\[ \| Tf \|_2^2 \leq \max |\lambda_n| \| f \|_2^2 \]
	%
	Conversely, if $Tf$ is bounded, then
	%
	\[ |\lambda_n^2| = \| T(e_n) \|_2^2 \leq \| T \|^2 \]
	%
	so the $\lambda_n$ are bounded.
\end{proof}

\begin{corollary}
	The Hilbert transform is a bounded endomorphism on $L^2(\mathbf{T})$. Note that we already know that $S_N f \to f$ in the $L^2$ norm.
\end{corollary}

The terms of the Hilbert transform cannot be considered the Fourier coefficients of any integrable function. Indeed, they don't vanish as $n \to \infty$. Nonetheless, we can use Abel summation to treat the Hilbert transform as convolution with an appropriate operator. For $0 < r < 1$, consider, for $z = e^{it}$,
%
\[ K_r(z) = \sum_{n \in \mathbf{Z}} \frac{\text{sgn}(n)}{i} r^{|n|} z^n = K * P_r \]
%
Since we know the Hilbert transform is continuous in $L^2(\mathbf{T})$, we can conclude that, in particular, for any $C^\infty$ function $f$,
%
\[ H f = \lim_{r \to 1} K * (P_r * f) = \lim_{r \to 1} (K * P_r) * f = \lim_{r \to 1} K_r * f \]
%
So it suffices to determine the limit of the $K_r$. We find that
%
\begin{align*}
	\sum_{n = 1}^\infty \frac{(rz)^n - (r \overline{z})^n}{i} &= \frac{r}{i} \left( \frac{1}{\overline{z} - r} - \frac{1}{z - r} \right) = \frac{r}{i} \frac{z - \overline{z}}{|z|^2 - 2r \text{Re}(z) + r^2}\\
	&= \frac{2r \sin(t)}{1 - 2r \cos(t) + r^2} = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r \sin^2(t/2)}\\
	&= \cot(t/2) + O \left( \frac{(1 - r)^2}{t^3} \right)
\end{align*}
%
Thus $K_r(t)$ tends to $\cot(t/2)$ locally uniformly away from the origin. But
%
\[ K_r(t) = \frac{4r \sin(t/2) \cos(t/2)}{(1 - r)^2 + 4r\sin^2(t/2)} = O \left( \frac{t}{(1 - r)^2} \right) \]
%
If $f$ is any $C^\infty$ function on $\mathbf{T}$, then
%
\[ \left| \int_{|t| \geq \varepsilon} [K_r(t) - \cot(t/2)] f(t) \right| \lesssim (1 - r)^2 \| f \|_\infty \int_{|t| \geq \varepsilon} \frac{dt}{|t|^3} \lesssim \frac{(1 - r)^2 \| f \|_\infty}{\varepsilon^2} \]
%
\begin{align*}
	\left| \int_{|t| < \varepsilon} K_r(t) f(t)\; dt \right| &\leq \int_0^\varepsilon |K_r(t)||f(t) - f(-t)|\\
	&\lesssim \int_0^\varepsilon |tK_r(t)||f'(0)| \lesssim \frac{|f'(0)|}{(1 - r)^2} \int_0^\varepsilon t^2 \lesssim \| f' \|_\infty \frac{\varepsilon^3}{(1 - r)^2}
\end{align*}
%
\[ \left| \int_{|t| < \varepsilon} \cot(t/2) f(t)\; dt \right| \lesssim \int_0^\varepsilon \frac{|f(t) - f(-t)|}{t} \lesssim \varepsilon f'(0) \]
%
Thus
%
\[ \left| \int K_r(t) f(t)\; dt - \int \cot(t/2) f(t)\; dt \right| \lesssim \frac{(1 - r)^2}{\varepsilon^2} \| f \|_\infty + \left( \frac{\varepsilon^3}{(1 - r)^2} + \varepsilon \right) \| f' \|_\infty \]
%
Choosing $\varepsilon = (1 - r)^\alpha$ for some $2/3 < \alpha < 1$ shows that for sufficiently smooth $f$,
%
\[ (Hf)(x) = \lim_{r \to 1} \int \cot(t/2) f(x - t)\; dt \]


\section{A Divergent Fourier Series}

Analysis was built to analyze continuous functions, so we would hope the method of fourier expansion would work for all continuous functions. Unfortunately, this is not so. The behaviour of the Dirichlet kernel away from the origin already tells us that the convergence of Fourier series is subtle. We shall take advantage of this to construct a continuous function with divergent fourier series at a point.

To start with, we shall consider the series
%
\[ f(t) \sim \sum_{n \neq 0} \frac{e_n(t)}{n} \]
%
where $f$ is an odd function equaling $i(\pi - t)$ for $t \in (0,\pi]$. Such a function is nice to use, because its Fourier representation is simple, yet very close to diverging. Indeed, if we break the series into the pair
%
\[ \sum_{n = 1}^\infty  \frac{e_n(t)}{n}\ \ \ \ \ \ \ \ \ \ \sum_{n = -\infty}^{-1} \frac{e_n(t)}{n} \]
%
Then these series no longer are the Fourier representations of a Riemann integrable function. For instance, if $g(t) \sim \sum_{n = 1}^\infty \frac{e_n(t)}{n}$, then the Abel means

$A_r(f)(t) = $

\section{Conjugate Fourier Series}

When $f$ is a real-valued integrable function, then $\overline{\widehat{f}(-n)} = \widehat{f}(n)$. Thus we formally calculate that
%
\[ \sum_{n = -\infty}^\infty \widehat{f}(n) e_n(t) = \text{Re} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) \]
%
This series defines an analytic function in the interior of the unit circle since the coefficients are bounded. Thus the sum is a harmonic function in the interior of the unit circle. The imaginary part of this sum is
%
\[ \text{Im} \left( \widehat{f}(0) + 2\sum_{n = 1}^\infty \widehat{f}(n) e_n(t) \right) = \Re \left( -i \sum_{n = -\infty}^\infty \text{sgn}(n) \widehat{f}(n) e_n(t) \right) \]
%
The right hand side is known as the conjugate series to the Fourier series $\widehat{f}(n)$. It is closely related to the study of a function $\tilde{f}$ known as the {\it conjugate function}.





\chapter{Interpolation Theory}

One of the most fundamental tools in the `hard style' of mathematical analysis, involving explicit quantitative estimates on quantities that arises in basic methods of mathematics, is the theory of interpolation. The main goal of interpolation is to take two estimates, and blend them together to form a family of intermediate estimates. Often each estimate will focus on one component of the problem at hand (an estimate in terms of the decay of the function at $\infty$, an estimate involving the growth of the derivative, or the low frequency the function is, etc). By interpolating, we can optimize and obtain an estimate which simultaneously takes into account multiple features of the function.

\section{Convex Interpolation}

The most basic way to interpolate is using the notion of convexity. Given two inequalities $A_0 \leq B_0$ and $A_1 \leq B_1$, for any parameter $0 \leq \theta \leq 1$, if we define the additive weighted averages $A_\theta = (1 - \theta) A_0 + \theta A_1$ and $B_\theta = (1 - \theta) B_0 + \theta B_1$, then we conclude $A_\theta \leq B_\theta$ for all $\theta$. Similarily, we can consider the weighted multiplicative averages $A_\theta = A_0^{1 - \theta} A_1^\theta$ and $B_\theta = B_0^{1 - \theta}B_1^\theta$, in which case we still have $A_\theta \leq B_\theta$. Note that the additive averages are obtained by taking the unique linear function between two values, and the multiplicative averages are obtained by taking the unique log-linear function between two values. In particular, if $A_\theta$ is defined to be any convex function, then $A_\theta \leq (1 - \theta) A_0 + \theta A_1$, and if $B_\theta$ is logarithmically convex, so that $\log B_\theta$ is convex, then $B_\theta \leq B_0^{1 - \theta} B_1^\theta$. Thus convexity provides us with a more general way of interpolating estimates, which is what makes this property so useful in analysis, enabling us to simplify estimates.

\begin{example}
	For a fixed, measurable function $f$, the map $p \mapsto \| f \|_p$ is a log convex function. This statement is precisely H\"{o}lder's inequality, since the inequality
	%
	\[ \| f \|_{\theta p + (1 - \theta) q} \leq \| f \|_p^\theta \| f \|_{q}^{1-\theta} \]
	%
	says
	%
	\[ \| |f|^{\theta p} |f|^{(1 - \theta) q} \|_1^{1/(\theta p + (1 - \theta) q)} \leq \| f^{\theta p} \|_{1/\theta}^{\theta} \| f^{(1-\theta)q} \|_{1/(1-\theta)}^{1-\theta} \]
	%
	which is precisely H\"{o}lder's inequality. Note this implies that if $p_0 < p_\theta < p_1$, then $L^{p_0}(X) \cap L^{p_1}(X) \subset L^{p_\theta}(X)$.
\end{example}

\begin{example}
	For a fixed $p$, the {\bf weak $L^p$ space $L^{p,\infty}(X)$} is the family of functions $f$ for which the quantity
	%
	\[ \| f \|_{p,\infty} = \sup t F(t)^{1/p} \]
	%
	is finite, where $F(t) = ||f| \geq t|$. This weak $L^p$ norm is log convex, because if $F(t) \leq A_0^{p_0}/t^{p_0}$, and $F(t) \leq A_1^{p_1}/t^{p_1}$, then we can apply scalar interpolation to conclude that if $p_\theta = (1 - \alpha) p_0 + \alpha p_1$,
	%
	\[ F(t) \leq \frac{A_0^{(1 - \alpha) p_0}A_1^{\alpha p_1}}{t^{(1 - \alpha)p_0 + \alpha p_1}} = \frac{A_\theta^{p_\theta}}{t^{p_\theta}} \]
	%
	where $p_\theta$ is the harmonic weighted average between $p_0$ and $p_1$, and $A_\theta$ the geometric weighted average. Using this argument, interpolating slightly to the left and right of $p_\theta$, we can conclude that if $p_0 < p_\theta < p_1$, then $L^{p_0,\infty}(X) \cap L^{p_1,\infty}(X) \subset L^{p_\theta}(X)$.
\end{example}

\section{Complex Interpolation}

Another major technique to perform an interpolation is to utilize the theory of complex analytic functions to obtain estimates. The core idea of this technique is to exploit the maximum principle, which says that bounding an analytic function at its boundary enables one to obtain bounds everywhere in the domain of the function. The next result, known as Lindel\"{o}f's theorem, is one of the fundamental examples of the application of complex analysis.

\begin{theorem}[The Three Lines Lemma]
	If $f$ is a holomorphic function on the strip $S = \{ s : \sigma \in [0,1] \}$ with the growth condition $\smash{|f(s)| \lesssim e^{e^{(\pi - \delta)|t|}}}$, for some $\delta > 0$, then the function $\sigma \mapsto \sup f(\sigma + it)$ is log convex on $[0,1]$. In other words, if we have a bound $|f(it)| \leq B_0$ and $|f(1 + it)| \leq B_1$, then we have a general estimate $|f(s)| \leq B_0^{1-\theta}B_1^\theta$.
\end{theorem}
\begin{proof}
	We can divide $f$ by the holomorphic function $B_0^{1-s}B_1^s$, and since this new function satisfies the constraints of the theorem, it suffices to prove that if $|f(it)|, |f(1+it)| \leq 1$, then $|f(s)| \leq 1$ for all $s \in S$. If we assume first that $|f(s)| \to 0$ as $|t| \to \infty$, then, applying the maximum principle, we conclude that the maximum value on $\{ s: |t| \leq T \}$ occurs for $\sigma \in \{ 0, 1 \}$, which gives us the bound for $|t| \leq T$. Taking $T \to \infty$ completes the proof. In general, if we define the function $g_\varepsilon(s) = \exp(\varepsilon i \exp(i[(\pi - \delta/2)s + \delta/4]))$, then the function $f(s)g_\varepsilon(s)g_\varepsilon(1-s) \to 0$ as $|t| \to \infty$, since
	%
	\begin{align*}
		|g_\varepsilon(s)| &= \exp(-\varepsilon \text{Im}(\exp(i[(\pi - \delta/2)s + \delta/4])))\\
		&= \exp(-\varepsilon e^{-(\pi - \delta/2) t} \sin(\delta/4 + (\pi - \delta/2)\sigma ))\\
		&\leq \min \left( 1, e^{-\varepsilon \sin(\delta/4) e^{- (\pi - \delta/2)t}} \right)
	\end{align*}
	%
	Thus $g_\varepsilon$ causes sharp decay for large values of $t$. $g_\varepsilon(1-s)$ then causes sharp decay for small values of $t$, so
	%
	\[ |g_\varepsilon(s)g_\varepsilon(1-s)| \leq e^{-\varepsilon \sin(\delta/4) e^{- (\pi - \delta/2)|t|}} \]
	%
	We can thus apply the previous case to this function to conclude that $|f(s)g_\varepsilon(s)g_\varepsilon(1-s)| \leq 1$, and then taking $\varepsilon \to 0$ completes the claim.
\end{proof}

\begin{remark}
	The function $e^{-ie^{\pi i s}}$ shows that this theorem cannot be proven for all holomorphic functions. In particular, this means there is no family of holomorphic functions $g_\varepsilon$ which decays faster than the functions constructed above as $|t| \to \infty$ and pointwise approximates the identity as $\varepsilon \to 0$.
\end{remark}

\begin{remark}
	Similar variants can be used to show that if $f$ is a function on the upper half strip satisfying a growth condition, then the supremum over lines on the upper half strip is log convex. If $f$ is a function on the annulus, we do not need to even restrict ourselves to a growth condition to conclude that the supremum over circles centred at the origin is log convex (a result known as the three circles lemma).
\end{remark}

\begin{example}
	Here we show how we can use the three lines lemma to prove that the $L^p$ norms are log convex. If $f = \sum a_n \chi_{E_n}$ is a simple function, then the function
	%
	\[ g(s) = \int |f|^s = \sum |a_n|^s |E_n| \]
	%
	is analytic in $s$, and satisfies the growth condition of the three lines lemma because each term of the sum is exponential in growth. Since $|g(s)| \leq |g(\sigma)|$, the three lines lemma implies that $g$ is log convex on the real line. By normalizing the function $f$ and the underlying measure, given $p_0$, $p_1$, we may assume $\| f \|_{p_0} = \| f \|_{p_1} = 1$, and it suffices to prove that $\| f \|_{p_\theta} \leq 1$ for all $p_\theta \in [p_0, p_1]$. But the log convexity of $g$ guarantees this is true, since $|g(p)| = \| f \|_p^p$. A standard limiting argument then gives the inequality for all functions $f$.
\end{example}

\section{Real Interpolation}

The idea of real interpolation is to break functions into various parts, and then applying estimates we have obtained from endpoints to obtain an estimate on the original function. The decomposition normally depends on parameters which can be optimized to give a good result for an estimate of the function in question. Real interpolation is much more flexible than complex interpolation, but complex interpolation obtains cleaner bounds. The classic example of real interpolation is the Marcinkiewiz interpolation theorem.

\begin{theorem}
	Let $T$ be a sublinear operator defined on $L^{p_0}(X) + L^{p_1}(X)$, and suppose.
\end{theorem}
\begin{proof}
	Let $f \in L^{p_\theta}(X)$ be given. If we fix a $\lambda$, then we can write $f = f \chi_E + f \chi_{E^c}$, where $E = \{ x: |f(x)| \geq \lambda \}$. Then $|E| < \infty$, and so
	%
	\[ \| f \chi_E \|_{p_0} \leq |E|^{1/p-1/p_0} \| f \|_p \]
\end{proof}

\section{Interpolation of Operators}

In the theory of operator interpolation, we address the following situation. We are given a norm space $X$, which can be written as the sum of two other norm spaces $Y + Z$, which perhaps have a different norm to $X$. We are given a (not necessarily bounded operator) $T: X + Y \to Z$. Given that $\| T \|_Y$ and $\| T \|_Z$ are finite, what tools enable us to conclude that $\| T \|_X$ is finite? In other cases, we are given a norm space $X$ with a family of norms $\| \cdot \|_\alpha$, and given the boundedness of $T: X \to Y$ in $\| \cdot \|_{p_0}$ and $\| \cdot \|_{p_1}$, we want to obtain boundedness in $\| \cdot \|_{p_\theta}$ for all $p_\theta$ inbetween $p_0$ and $p_1$.

\begin{theorem}[Riesz-Thorin]
	Let $p_0,p_1 \in (0,\infty]$ and $q_0,q_1 \in [1,\infty]$. Consider a linear operator $T$ mapping elements of $L^{p_0}(X)$ to $L^{q_0}(Y)$, and elements of $L^{p_1}(X)$ to $L^{q_1}(Y)$. Then for any $f \in L^{p_\theta}(X)$, where $p_\theta$ is the weighted harmonic average $1/p_\theta = (1 - \theta)/p_0 + \theta/p_1$, $Tf \in L^{q_\theta}(Y)$, where $q$ is a weighted harmonic average, and
	%
	\[ \| T \|_{p_\theta \to q_\theta} \leq \| T \|_{p_0 \to q_0}^{1-\theta} \| T \|_{p_1 \to q_1}^\theta \]
\end{theorem}
\begin{proof}
	If $p_0 = p_1$, the proof follows by the log convexity of the $L^p$ norms of a function. Thus we may assume $p_0 \neq p_1$, so $p_\theta$ is finite in any case of interest. By normalizing the measures on both spaces, we may assume $\| T \|_{p_0,q_0} = \| T \|_{p_1,q_1} = 1$, so it suffices to prove $\| T \|_{p_\theta,q_\theta} \leq 1$. H\"{o}lder's inequality implies
	%
	\[ \left| \int_Y (Tf) g \right| \leq \| f \|_{p_0} \| g \|_{q_0'}, \| f \|_{p_1} \| g \|_{q_1'} \]
	%
	We now employ some complex interpolation to conclude that whenever $f$ and $g$ are simple functions,
	%
	\[ \left| \int_Y (Tf) g \right| \leq \| f \|_{p_\theta} \| g \|_{q_\theta'} \]
	%
	To see this, we can normalize so $\| f \|_{p_\theta} = \| g \|_{q_\theta'} = 1$, and write $f = |f| \text{sgn}(f)$. But if we now define
	%
	\[ F(s) = \int_Y T(|f|^{(1-s)p_\theta/p_0 + sp_\theta/p_1} \text{sgn}(f)) |g|^{(1-s)q_\theta'/q_0' + sq_\theta'/q_1'} \text{sgn}(g) \]
	%
	Then an application of Lindel\"{o}f's theorem implies the result. Since $g$ and $f$ can be taken to approximate all elements of $L^{p_\theta}(X)$ and $L^{q_\theta'}(Y)$, we conclude that the theorem is true for all not-necessarily simple elements of these function spaces. But applying duality, this now implies thath $\| Tf \|_{q_\theta} \leq \| f \|_{p_\theta}$, which was what was required to be proven.
\end{proof}

Given a linear operator $T$ mapping simple functions on $X$ to measurable functions on $Y$, we say $T$ has {\it strong type} $(p,q)$ if $\| T f \|_q \leq \| f \|_p$ for any simple function $f$. The Hahn-Banach theorem then says $T$ has an extension to a continuous operator from $L^p(X)$ to $L^q(Y)$, and, provided $p$ is finite, or $X$ has finite measure, this extension will be unique. If we consider the {\it strong type} diagram to be all points $(p,q)$ where $T$ is of strong type $(1/p,1/q)$, then the Riesz-Thorin interpolation theorem implies that the intersection of the strong type diagram with $[0,\infty) \times [0,1]$ is convex, and the operator norm $\| T \|_{p,q}$ is a log convex function of $(1/p,1/q)$.

\begin{example}
	If $T$ is the identity map on functions on $[0,1]$, then because of the fact that $\| f \|_p \leq \| f \|_q$ for $p < q$,
\end{example}

\begin{example}
	We know that if $f$ and $g$ are integrable functions, then $f * g$ is an integrable function, and $\| f * g \|_1 \leq \| f \|_1 \| g \|_1$. If we apply Minkowski's integral inequality, then we find that if $f \in L^1(\RR^n)$ and $g \in L^q(\RR^n)$, then
	%
	\begin{align*}
		\| f * g \|_q &= \left( \int |(f * g)(x)|^q\; dx \right)^{1/q} \leq \int \left( \int |f(y)g(x-y)|^q dx\; \right)^{1/q} dy\\
		&= \int |f(y)| \| g \|_q = \| f \|_1 \| g \|_q
	\end{align*}
	%
	This means $f * g \in L^q(\RR^n)$, and so is, in particular, defined everywhere. H\"{older}'s inequality implies that if $f \in L^q(\RR^n)$ and $g \in L^{q^*}(\RR^n)$, then
	%
	\[ \left| \int f(y) g(x-y)\; dy \right| \leq \int |f(y-x)| |g(x)| \leq \int |f(y)|\; dy \int |g(y)|^{q^*}\; dy = \| f \|_q \| g \|_{q^*} \]
	%
	Thus $\| f * g \|_\infty \leq \| f \|_q \| g \|_{q^*}$. But this means that the convolution operator $T_g: f \mapsto f * g$ is $(1,q)$, as well as $(q^*,\infty)$ continuous. But now, connecting these two points, and applying the Riesz-Thorin theorem, we conclude that if $f \in L^p(\RR^n)$, with $1/p = \theta/q^* + (1 - \theta) = 1/q^* + (1-\theta)/q = 1 - 1/q + 1/r$, $(f * g) \in L^r(\RR^n)$, and
	%
	\[ \| f * g \|_r \leq \| f \|_p \| g \|_q \]
	%
	Note that we never used anything about $\RR^n$ here other than it's translational structure, and as such Young's inequality continues to apply in the theory of any modular locally compact group. Indeed, this means if we swap $\mu$ with $\lambda \mu$, then we obtain that
	%
	\[ \| f * g \|_r = \lambda^{1 + 1/r} = \lambda^{1/p + 1/q} \| f \|_p \| g \|_p \]
	%
	which is a good way of remembering that we must have $1 + 1/r = 1/p + 1/q$.	
\end{example}

Elias Stein noticed that the Riesz-Thorin theorem can be easily extended to allow bounds over an `analytic family' of operators $T_s$, where $s \in S$, in the sense that for any two test functions $f$ and $g$, $\langle T_s f, g \rangle$ is analytic in $s$, growing slower than doubly exponentially, and we have estimates
%
\[ \| T_{it} f \|_{q_0} \leq B_t \| f \|_{p_0}\ \ \ \ \ \| T_{1+it} f \|_{q_1} \leq B_t \| f \|_{p_1} \]
%
where $B_t = O(e^{e^{(\pi - \delta)t}})$, then $\| T_\theta f \|_{q_\theta} \leq B_\theta \| f \|_{p_\theta}$.

\chapter{Oscillatory Integrals}

The study of oscillatory integrals provides tools enabling one to obtain asymptotics for integrals of the form
%
\[ I(\lambda) = \int e(\lambda \Phi(x)) \psi(x)\; dx \]
%
where $\Phi$ is the {\bf phase}, and $\psi$ is the amplitude, which are both fixed parameters, and $\lambda$ is allowed to vary. Determining the asymptotics of these integrals as $\lambda \to \infty$ requires control over the cancelling properties of the integral, so certain decomposition techniques often employed, i.e. in the theory of singular integrals, fail completely here.

\begin{example}
	The most basic example, and most important, example of an oscillatory integral is the Fourier transform
	%
	\[ \widehat{f}(\xi) = \int e(-\xi \cdot x) f(x)\; dx \]
	%
	More generally, we can obtain another example by taking a finite measure $\mu$, and considering it's Fourier transform
	%
	\[ \widehat{\mu}(\xi) = \int e(- \xi \cdot x) d\mu(x)\; dx \]
	%
	One of the main applications of the theory of oscillatory integrals is to show that the Fourier transforms of certain measures have fast decay properties.
\end{example}

\section{The Principle of Stationary Phase}

\subsection{Localization}

The basic principle of the theory of stationary phase is that the asymptotics of the integral are determined by where $\nabla \Phi$ vanishes. One of the principles of oscillatory integrals is that the asymptotics of the theory depend only on the local properties of the function $\Phi$.

\begin{theorem}
	If $\Phi$ and $\psi$ are smooth, compactly supported functions with $\nabla \Phi(x) \neq 0$ for all $x$ in the support of $\psi$, then $I(\lambda) \lesssim 1/\lambda^N$.
\end{theorem}
\begin{proof}
	Set $a = (\nabla \Phi)/|\nabla \Phi|^2$. Then for any smooth functions $f$ and $g$, integrating by parts, we obtain that
	%
	\[ \int \frac{a \cdot \nabla f(x)}{i \lambda} g(x)\; dx = - \int f(x) \frac{(\nabla \cdot (ag))(x)}{i \lambda}\; dx \]
	%
	Set
	%
	\[ D(f) = (i \lambda)^{-1} (a \cdot \nabla f)\ \ \ \ \ D^*(f) = - (i\lambda)^{-1} (\nabla \cdot (af)) \]
	%
	Note that $D(e(\lambda \Phi)) = e(\lambda \Phi)$, so $D^N(e(\lambda \Phi)) = e(\lambda \Phi)$ for all integers $N$, and so
	%
	\[ I(\lambda) = \int D^N(e(\lambda \Phi)) \phi = \int e(\lambda \Phi) (D^*)^N(\psi) \]
	%
	Taking absolute values in the last integral gives that
	%
	\[ |I(\lambda)| \leq \int |(D^*)^N(\psi)| \lesssim \frac{1}{\lambda^N} \]
	%
	which gives the required bounds.
\end{proof}

Of course, if $\Phi$ changes suitably rapidly around a point $x$, in the sense that $\nabla \Phi$ is nonsingular, then as we increase $\lambda$, the oscillatory factor in the integral is allowed to oscillate at a fast enough rate that $\psi$ is effectively constant, and so the integral has so much cancellation that we get rapid decay. Note, however, that this depends on $\psi$ being effectively constant, i.e. smooth. If $\psi$ and $\Phi$ are only $C^N$ functions, then we can only get a $|\lambda|^{-N}$ decay rate. A particularly revealing example is where we take the Fourier transform of the characteristic function of an interval $[a,b]$ (smooth, albeit at the two endpoints where we get a sharp jump), where
%
\[ \int_a^b e(- \lambda x)\; dx = \frac{e(\lambda b) - e(\lambda a)}{2 \pi i \lambda} \]
%
which has only a rate $1/|\lambda|$ decay. Note, however, if we are taking an oscillatory integral `on an interval' $[a,b]$, where $\psi$ and $\Phi$ are both $C^N$, and for all $n \leq N$, $\Phi^{(n)}(a) = \Phi^{(n)}(b)$ and $\psi^{(n)}(a) = \psi^{(n)}(b)$, then we can still get $1/|\lambda|^N$ decay using the same proof as above, except now the integration by parts must take into account the endpoints of the integral, which now cancel to a suitably high degree.

\section{Scaling}

To hint at the multidimensional theory, we now focus solely on the single-variable theory. This simplifies the situation considerably, and we shall find there is an essentially complete theory of such oscillatory integrals in one dimension. Note that we now have
%
\[ D(f) = (i\lambda \phi')^{-1} f'\ \ \ \ \ D^*(f) = -(i \lambda)^{-1} (f/\phi)' \]
%
In particular, we attempt to guess the asymptotic development of the oscillatory integral
%
\[ \int e(\lambda \phi(x)) \psi(x) \]
%
where the derivatives of $\phi$ may vanish at suitable points, yet for a suitably high $n$, $\phi^{(n)}$ does not vanish on the support of $\psi$. In particular, suppose that we want to find the best constant $\alpha$, such that there exists a constant $C_n$ such that for any $\phi$ and interval $[a,b]$ such that $|\phi^{(n)}(x)| \geq 1$ on $(a,b)$, then
%
\[ \left| \int_a^b e(\lambda \phi(x))\; dx \right| \leq C_n/|\lambda|^\alpha \]
%
If $\phi(x) = x^n$, then the change of variables $y = \beta x$ implies that if we have a best constant $\alpha$ which works for all $\phi$, then we must have $\alpha = 1/k$. Indeed, this estimate, known to Van der Corput, says this result is true.

\begin{theorem}
	There exists a constant $C_n$ such that if $\phi$ is smooth in $(a,b)$ with $|\phi^{(n)} \geq 1|$ for all $x \in (a,b)$, then
	%
	\[ \left| \int_a^b e(\lambda \phi(x)) \right| \leq C_n \lambda^{-1/n} \]
	%
	where $n \geq 2$, or $n = 1$, under the extra assumptions that $\phi'$ is monotonic.
\end{theorem}
\begin{proof}
	Consider first $n = 1$. Then, using the operator $D$, we have
	%
	\begin{align*}
		\int_a^b e(\lambda \phi)\; dx &= \int_a^b D(e(i \lambda \phi))\; dx = \int_a^b e(\lambda \phi) D^*(1)\; dx + \frac{e(\lambda b)/\phi'(b) - e(\lambda a)/\phi'(a)}{i \lambda}
	\end{align*}
	%
	The boundary terms are collectively bounded by $2/|\lambda|$, and we can bound the integration term, using the monotonicity of $\phi'$, by
	%
	\begin{align*}
		\left| \int_a^b e(\lambda \phi) D^*(1)\; dx \right| &\leq |\lambda|^{-1} \int_a^b |(1/\phi')'|\; dx \leq |\lambda|^{-1} \left| \int_a^b (1/\phi')'\; dx \right|\\
		&= |\lambda|^{-1} \left| \frac{1}{\phi'(b)} - \frac{1}{\phi'(a)} \right| \leq |\lambda|^{-1}
	\end{align*}
	%
	so we can set $C_1 = 3$. We now prove the remaining inequalities by induction, using an integration by parts. Suppose that (by replacing $\phi$ with its negation if necessary) $\phi^{(n+1)}(x) \geq 1$ on $[a,b]$. Let $x_0$ be the point at which $|\phi^{(n)}(x)|$ is minimized. Without loss of generality, we may assume that $|\phi^{(n)}(x)$ TODO: FINISH THIS ARGUMENT, GIVES $C_n = 5 \cdot 2^{n-1} - 2$.
\end{proof}

\begin{remark}
	If $|\phi^{(n)}(x)| \geq \mu$, then $|\phi^{(n)}(x)/\mu| \geq 1$, and so substituting into the previous result establishes that $|I(\lambda)| \leq C_m / |\mu \lambda|^{1/n}$.
\end{remark}

\begin{remark}
	If $n = 1$, and $\phi'$ is not monotonic, we can choose $\phi$ to grow suitably slowly on intervals of the form $[0,\pi] + 2 \pi n$, and $\phi$ to grow much faster on intervals of the form $[\pi, 2\pi] + 2 \pi n$. It then follows that $\int_0^{2 \pi N} \sin(\phi(x))$ is unbounded as we let $N \to \infty$, which prevents us from extending the result completely to the one dimensional case.
\end{remark}

Continuing in the simpler, one dimensional case, we now consider a {\it nondegenerate} critical point $x$, where $\Phi'(x) = 0$, but $\Phi''(x) \neq 0$. A good instance of this occurs where $\Phi(x) = x^2$, where we find
%
\[ \int e(\lambda x^2) \psi(x)\; dx = \sum_{k = 0}^N C_k \lambda^{-1/2-k} + O(|\lambda|^{-3/2-N}) \]
%
This is obtained by noting that the Fourier transform of the Gaussian implies
%
\[ \int e^{- sx^2} \psi(x)\; dx = (\pi/s)^{1/2} \int e^{- \pi^2 \xi^2/ s} \widehat{\psi}(\xi)\; d\xi \]
%
Since both sides are analytic, and they make sense for $\Re(s) > 0$, we can take $s \to -i\lambda$ to conclude that
%
\[ \int e(\lambda x^2) \psi(x)\; dx = \left( \frac{\pi}{i \lambda} \right)^{1/2} \int e(-\pi^2 \xi^2/\lambda) \widehat{\psi}(x)\; dx \]
%
Expanding the exponential $e(u^2)$ gives the required bounds. Thus we can expect a critical, nondegenerate point to give a $O(\lambda^{-1/2})$ error bound.

\begin{corollary}
	If an amplitude $\psi$ is present, then
	%
	\[ \left| \int_a^b e(\lambda \Phi(x)) \psi(x)\; dx \right| \leq 8 \left( \int_a^b |\psi'(x)|\; dx + |\psi(b)| \right) \lambda^{-1/2} \]
\end{corollary}
\begin{proof}
	Integrating by parts, if $J(x) = \int_a^x e(\lambda \Phi(u))\; du$, then
	%
	\[ \int_a^b e(\lambda \Phi(x)) \psi(x)\; dx = J(b)\psi(b) - \int_a^b J(x) \psi'(x)\; dx \]
	%
	and then since $|J(x)| \leq 8\lambda^{-1/2}$, the proposition follows. TODO: ADDRESS MULTIDIMENSIONAL CASE.
\end{proof}

\begin{example}
	The Bessel functions
	%
	\[ J_m(r) = \frac{1}{2\pi} \int_0^{2\pi} e(r \sin(x)) e_m(-x)\; dx \]
	%
	occur naturally in many areas of analysis. The definition of the functions can be seen as an oscillatory integral, with $\lambda = r$, $\Phi(x) = \sin(x)$, and $\psi(x) = e_m(-x)/2\pi$. Split $[0,2\pi]$ into two intervals, the first upon which $\cos(x) \geq 1/\sqrt{2}$, the second where $\sin(x) \geq 1/\sqrt{2}$. On the first part, we may apply the corollary above to obtain a $O(r^{-1/2})$ bound, and on the second, we can apply the first to obtain a $O(r^{-1})$ bound. Summing these two bounds up gives the theorem.
\end{example}

\section{Surface Carried Measures}

\begin{theorem}
	If a hypersurface $\Sigma$ has non-vanishing Gauss curvature at each point in the support of a surface carried measure $\mu$, then
	%
	\[ |\widehat{\mu}(\xi)| = O(|\xi|^{-(d-1)/2}) \]
	%
	s
\end{theorem}





\section{Restriction Theorems}

If $f \in L^p(\RR^n)$, then the Hausdorff Young theorem says that $\widehat{f}$ is a function in $L^q(\RR^n)$, where $q$ is the dual of $p$. If $f \in L^1(\RR^n)$, then $\smash{\widehat{f}}$ is actually continuous, so you can meaningfully discuss the behaviour of the Fourier transform when restricted to low dimensional hypersurfaces, for instance, on a sphere of a fixed radius. However, in general $\widehat{f}$ will only be defined almost everywhere, and so it is unclear whether one can form a well defined restriction of the Fourier transform.

The general situation is as follows. If $\mu$ is a measure carried on a compact surface $M$, for a fixed $p$, does there exist an estimate 
%
\[ \| \widehat{f} \|_{L^q(M,\mu)} \lesssim \| f \|_{L^p(\RR^n)} \]
%
for Schwartz functions $f$. If this is true, we can apply a density argument to show that the restriction operator $\smash{R(f) = \widehat{f}|_M}$ uniquely extends to a well defined continuous linear operator from $L^p(\RR^n)$ to $L^q(M,\mu)$.

We begin by determining a duality result to the restriction calculation. Assuming our functions are suitably regular, we calculate
%
\begin{align*}
	\int_M (Rf)(\xi) \overline{g(\xi)}\; d\mu(\xi) &= \int_M \left( \int_{\RR^n} f(x) e(- \xi \cdot x)\; dx \right) \overline{g(\xi)}\; d\mu(\xi)\\
	&= \int_{\RR^n} f(x) \overline{\int_M g(\xi) e(\xi \cdot x)\; d\mu(\xi)}\; dx 
\end{align*}
%
which implies the formal adjoint of the map $R$ is the {\bf extension operator}
%
\[ (R^* f)(x) = \int_M e(\xi \cdot x) f(\xi) d\mu(\xi) \]
%
which extends a function in frequency space supported on $M$ to a function on the entirety of phase space. By duality properties, $R$ is continuous as an operator from $L^p(\RR^n)$ to $L^q(M,\mu)$ if and only if $R^*$ is continuous as an operator from $L^{q^*}(M,\mu)$ to $L^{p^*}(\RR^n)$. We also calculate
%
\[ ((R^* R)f)(x) = \int_{\RR^n} \left( \int_M e(\xi \cdot (x-y))\; d\mu(\xi) \right) f(y)\; dy = \left( f * \widecheck{\mu} \right)(x) \]
%
So if $R$ is $(p,2)$ continuous, $R^*$ is $(2,p^*)$ continuous, and so $R^*R$ is $(p,p^*)$ continuous. Conversely, if we know that $R^*R$ is $(p,p^*)$ continuous, then we find that for $f \in L^p(\RR^n)$, H\"{o}lder's inequality implies
%
\[ \| Rf \|_{L^2(M,\mu)}^2 = (Rf,Rf)_M = ((R^* R)f, f)_{\RR^d} \leq \| R^*R \|_{p \to p^*} \| f \|_p^2 \]
%
and so we conclude that $\| R \|_{p \to 2} \leq \sqrt{\| R^* R\|_{p \to p^*}}$.

We now prove that $R$ is $(2n+2/n+3, 2)$ continuous, assuming that $M$ has non-zero Gaussian curvature at each point. The previous paragram implies that it suffices to show that it is enough to show that $R^*R$ is $(p,p^*)$ continuous, where $p = (2n+2)/(n+3)$ and $p^* = (2n+2)/(n-1)$. Since
%
\[ (R^*R)(f) = f * \widecheck{\mu} \]
%
We shall verify this using Stein's interpolation theorem. Consider the family of kernels $k_s$, where $\smash{k_s = \widecheck{K_s}}$, and $K_s = \gamma_s |x_n - \varphi(x')|^{s-1}_+ \varphi_0(x)$, where $\gamma_s = s(s+1) \dots (s + N) e^{s^2}$



\part{Abstract Harmonic Analysis}

The main property of spaces where Fourier analysis applies is symmetry -- for a function $\RR$, we can translate and negate. On $\RR^n$ we have not only translational symmetry but also rotational symmetry. It turns out that we can apply Fourier analysis to any `space with symmetry'. That is, functions on an Abelian group. We shall begin with the study of finite abelian groups, where convergence questions disappear, and with it much of the analytical questions involved in the theory. We then proceed to generalize to a study of infinite abelian groups with topological structure.







\chapter{Topological Groups}

In abstract harmonic analysis, the main subject matter is the {\bf topological group}, a group $G$ equipped with a topology which makes the operation of multiplication and inversion continuous. In the mid 20th century, it was realized that basic Fourier analysis could be generalized to a large class of groups. The nicest generalization occurs over the locally compact groups, which simplifies the theory considerably.

\begin{example}
    There are a few groups we should keep in mind for intuition in the general topological group.
    %
    \begin{itemize}
        \item The classical groups $\RR^n$ and $\mathbf{T}^n$, from which Fourier analysis originated.
        \item The group $\mu$ of roots of unity, rational numbers $\mathbf{Q}$, and cyclic groups $\mathbf{Z}_n$.
        \item The matrix subgroups of the general linear group $GL(n)$.
        \item The product $\mathbf{T}^\omega$ of Torii, occurring in the study of Dirichlet series.
        \item The product $\mathbf{Z}_2^\omega$, which occurs in probability theory, and other contexts.
        \item The field of $p$-adic numbers $\mathbf{Q}_p$, which are the completion of $\mathbf{Q}$ with respect to the absolute value $|p^{-m} q|_p = p^m$.
    \end{itemize}
\end{example}

\section{Basic Results}

The topological structure of a topological group naturally possesses large amounts of symmetry, simplifying the spatial structure. For any topological group, the maps
%
\[ x \mapsto gx\ \ \ \ \ \ \ \ \ \ x \mapsto xg\ \ \ \ \ \ \ \ \ \ x \mapsto x^{-1} \]
%
are homeomorphisms. Thus if $U$ is a neighbourhood of $x$, then $gU$ is a neighbourhood of $gx$, $Ug$ a neighbourhood of $xg$, and $U^{-1}$ a neighbourhood of $x^{-1}$, and as we vary $U$ through all neighbourhoods of $x$, we obtain all neighbourhoods of the other points. Understanding the topological structure at any point reduces to studying the neighbourhoods of the identity element of the group.

In topological group theory it is even more important than in basic group theory to discuss set multiplication. If $U$ and $V$ are subsets of a group, then we define
%
\[ U^{-1} = \{ x^{-1} : x \in U \}\ \ \ \ \ \ \ \ UV = \{ xy: x \in U, y \in V \} \]
%
We let $V^2 = VV$, $V^3 = VVV$, and so on.

\begin{theorem}
    Let $U$ and $V$ be subsets of a topological group.
    %
    \begin{enumerate}
        \item[(i)] If $U$ is open, then $UV$ is open.
        \item[(ii)] If $U$ is compact, and $V$ closed, then $UV$ is closed.
        \item[(iii)] If $U$ and $V$ are connected, $UV$ is connected.
        \item[(iv)] If $U$ and $V$ are compact, then $UV$ is compact.
    \end{enumerate}
\end{theorem}
\begin{proof}
    To see that (i) holds, we see that
    %
    \[ UV = \bigcup_{x \in V} Ux \]
    %
    and each $Ux$ is open. To see (ii), suppose $u_i v_i \to x$. Since $U$ is compact, there is a subnet $u_{i_k}$ converging to $y$. Then $y \in U$, and we find
    %
    \[ v_{i_k} = u_{i_k}^{-1} ( u_{i_k} v_{i_k} ) \to y^{-1} x \]
    %
    Thus $y^{-1} x \in V$, and so $x = y y^{-1} x \in UV$. (iii) follows immediately from the continuity of multiplication, and the fact that $U \times V$ is connected, and (iv) follows from similar reasoning.
\end{proof}

\begin{example}
    If $U$ is merely closed, then (ii) need not hold. For instance, in $\RR$, take $U = \alpha \mathbf{Z}$, and $V = \mathbf{Z}$, where $\alpha$ is an irrational number. Then $U + V = \alpha \mathbf{Z} + \mathbf{Z}$ is dense in $\RR$, and is hence not closed.
\end{example}

There are useful ways we can construct neighbourhoods under the group operations, which we list below.

\begin{lemma}
    Let $U$ be a neighbourhood of the identity. Then
    %
    \begin{itemize}
        \item[(1)] There is an open $V$ such that $V^2 \subset U$.
        \item[(2)] There is an open $V$ such that $V^{-1} \subset U$.
        \item[(3)] For any $x \in U$, there is an open $V$ such that $xV \subset U$.
        \item[(4)] For any $x$, there is an open $V$ such that $xVx^{-1} \subset U$.
    \end{itemize}
\end{lemma}
\begin{proof}
    (1) follows simply from the continuity of multiplication, and (2) from the continuity of inversion. (3) is verified because $x^{-1}U$ is a neighbourhood of the origin, so if $V = x^{-1}U$, then $xV = U \subset U$. Finally (4) follows in a manner analogously to (3) because $x^{-1}Ux$ contains the origin.
\end{proof}

If $\mathcal{U}$ is an open basis at the origin, then it is only a slight generalization to show that for any of the above situations, we can always select $V \in \mathcal{U}$. Conversely, suppose that $\mathcal{V}$ is a family of subsets of a (not yet topological) group $G$ containing $e$ such that (1), (2), (3), and (4) hold. Then the family $\mathcal{V}' = \{ xV : V \in \mathcal{V}, x \in G \}$ forms a subbasis for a topology on $G$ which forms a topological group. If $\mathcal{V}$ also has the base property, then $\mathcal{V}'$ is a basis.

\begin{theorem}
    If $K$ and $C$ are disjoint, $K$ is compact, and $C$ is closed, then there is a neighbourhood $V$ of the origin for which $KV$ and $CV$ is disjoint. If $G$ is locally compact, then we can select $V$ such that $KV$ is precompact.
\end{theorem}
\begin{proof}
    For each $x \in K$, $C^c$ is an open neighbourhood containing $x$, so by applying the last lemma recursively we find that there is a symmetric neighbourhood $V_x$ such that $x V_x^4 \subset C^c$. Since $K$ is compact, finitely many of the $xV_x$ cover $K$. If we then let $V$ be the open set obtained by intersecting the finite subfamily of the $V_x$, then $KV$ is disjoint from $CV$.
\end{proof}

Taking $K$ to be a point, we find that any open neighbourhood of a point contains a closed neighbourhood. Provided points are closed, we can set $C$ to be a point as well.

\begin{corollary}
    Every Kolmogorov topological group is Hausdorff.
\end{corollary}

\begin{theorem}
    For any set $A \subset G$,
    %
    \[ \overline{A} = \bigcap_V AV \]
    %
    Where $V$ ranges over the set of neighbourhoods of the origin.
\end{theorem}
\begin{proof}
    If $x \not \in \overline{A}$, then the last theorem guarantees that there is $V$ for which $\overline{A}V$ and $Ax$ are disjoint. We conclude $\bigcap AV \subset \overline{A}$. Conversely, any neighbourhood contains a closed neighbourhood, so that $\overline{A} \subset AV$ for a fixed $V$, and hence $\overline{A} \subset \bigcap AV$.
\end{proof}

\begin{theorem}
    Every open subgroup of $G$ is closed.
\end{theorem}
\begin{proof}
    Let $H$ be an open subgroup of $G$. Then $\overline{H} = \bigcap_V HV$. If $W$ is a neighbourhood of the origin contained in $H$, then we find $\overline{H} \subset HW \subset H$, so $H$ is closed.
\end{proof}

We see that open subgroups of a group therefore correspond to connected components of the group, so that connected groups have no proper open subgroups. This also tells us that a locally compact group is $\sigma$-compact on each of its components, for if $V$ is a pre-compact neighbourhood of the origin, then $V^2, V^3, \dots$ are all precompact, and $\bigcup_{k = 1}^\infty V^k$ is an open subgroup of $G$, which therefore contains the component of $e$, and is $\sigma$-compact. Since the topology of a topological group is homogenous, we can conclude that all components of the group are $\sigma$ compact.

\section{Quotient Groups}

If $G$ is a topological group, and $H$ is a subgroup, then $G/H$ can be given a topological structure in the obvious way. The quotient map is open, because $VH$ is open in $G$ for any open set $V$, and if $H$ is normal, $G/H$ is also a topological group, because multiplication is just induced from the quotient map of $G \times G$ to $G/H \times G/H$, and inversion from $G$ to $G/H$. We should think the quotient structure is pleasant, but if no conditions on $H$ are given, then $G/H$ can have pathological structure. One particular example is the quotient $\mathbf{T}/\mu_\infty$ of the torus modulo the roots of unity, where the quotient is lumpy.

\begin{theorem}
    If $H$ is closed, $G/H$ is Hausdorff.
\end{theorem}
\begin{proof}
    If $x \neq y \in G/H$, then $xHy^{-1}$ is a closed set in $G$, not containing $e$, so we may conclude there is a neighbourhood $V$ for which $V$ and $VxHy^{-1}$ are disjoint, so $VyH$ and $VxH$ are disjoint. This implies that the open sets $V(xH)$ and $V(yH)$ are disjoint in $G/H$.
\end{proof}

\begin{theorem}
    If $G$ is locally compact, $G/H$ is also.
\end{theorem}
\begin{proof}
    If $\{ U_i \}$ is a basis of precompact neighbourhoods at the origin, then $U_iH$ is a family of precompact neighbourhoods of the origin in $G/H$, and is in fact a basis, for if $V$ is any neighbourhood of the origin, there is $U_i \subset \pi^{-1}(V)$, and so $U_iH \subset V$.
\end{proof}

If $G$ is a non-Hausdorff group, then $\overline{\{e\}} \neq \{ e \}$, and $G/\overline{\{e\}}$ is Hausdorff. Thus we can get away with assuming all our topological groups are Hausdorff, because a slight modification in the algebraic structure of the topological group gives us this property.

\section{Uniform Continuity}

An advantage of the real line $\RR$ is that continuity can be explained in a {\it uniform sense}, because we can transport any topological questions about a certain point $x$ to questions about topological structure near the origin via the map $g \mapsto x^{-1}g$. We can then define a uniformly continuous function $f: \RR \to \RR$ to be a function possessing, for every $\varepsilon > 0$, a $\delta > 0$ such that if $|y| < \delta$, $|f(x+y) - f(x)|<\varepsilon$. Instead of having to specify a $\delta$ for every point on the domain, the $\delta$ works uniformly everywhere. The group structure is all we need to talk about these questions.

We say a function $f: G \to H$ between topological groups is (left) uniformly continuous if, for any open neighbourhood $U$ of the origin in $H$, there is a neighbourhood $V$ of the origin in $G$ such that for each $x$, $f(xV) \subset f(x) U$. Right continuity requires $f(Vx) \subset U f(x)$. The requirement of distinguishing between left and right uniformity is important when we study non-commutative groups, for there are certainly left uniform maps which are not right uniform in these groups. If $f: G \to \mathbf{C}$, then left uniform continuity is equivalent to the fact that $\| L_x f - f \|_\infty \to 0$ as $x \to 1$, where $(L_x f)(y) = f(xy)$. Right uniform continuity requires $\| R_x f - f \|_\infty \to 0$, where $(R_x f)(y) = f(yx)$. $R_x$ is a homomorphism, but $L_x$ is what is called an antihomomorphism.

\begin{example}
    Let $G$ be any Hausdorff non-commutative topological group, with sequences $x_i$ and $y_i$ for which $x_i y_i \to e$, $y_i x_i \to z \neq e$. Then the uniform structures on $G$ are not equivalent.
\end{example}

It is hopeless to express uniform continuity in terms of a new topology on $G$, because the topology only gives a local description of continuity, which prevents us from describing things uniformly across the whole group. However, we can express uniform continuity in terms of a new topology on $G \times G$. If $U \subset G$ is an open neighbourhood of the origin, let
%
\[ L_U = \{ (x,y): yx^{-1} \in U \}\ \ \ \ \ R_U = \{ (x,y): x^{-1}y \in U \} \]
%
The family of all $L_U$ (resp. $R_U$) is known as the left (right) uniform structure on $G$, denoted $LU(G)$ and $RU(G)$. Fix a map $f: G \to H$, and consider the map
%
\[ g(x,y) = (f(x), f(y)) \]
%
from $G^2$ to $H^2$. Then $f$ is left (right) uniformly continuous if and only if $g$ is continuous with respect to $LU(G)$ and $LU(H)$ ($RU(G)$ and $RU(H)$). $LU(G)$ and $RU(G)$ are weaker than the product topologies on $G$ and $H$, which reflects the fact that uniform continuity is a strong condition than normal continuity. We can also consider uniform maps with respect to $LU(G)$ and $RU(H)$, and so on and so forth. We can also consider uniform continuity on functions defined on an open subset of a group.

\begin{example}
    Here are a few examples of easily verified continuous maps.
    \begin{itemize}
        \item If the identity map on $G$ is left-right uniformly continuous, then $LU(G) = RU(G)$, and so uniform continuity is invariant of the uniform structure chosen.
        \item Translation maps $x \mapsto axb$, for $a,b \in G$, are left and right uniform.
        \item Inversion is uniformly continuous.
    \end{itemize}
\end{example}

\begin{theorem}
    All continuous maps on compact subsets of topological groups are uniformly continuous.
\end{theorem}
\begin{proof}
    Let $K$ be a compact subset of a group $G$, and let $f:K \to H$ be a continuous map into a topological group. We claim that $f$ is then uniformly continuous. Fix an open neighbourhood $V$ of the origin, and let $V'$ be a symmetric neighbourhood such that $V'^2 \subset V$. For any $x$, there is $U_x$ such that
    %
    \[ f(x)^{-1} f(xU_x) \subset V' \]
    %
    Choose $U'_x$ such that $U'^2_x \subset U_x$. The $xU'_x$ cover $K$, so there is a finite subcover corresponding to sets $U'_{x_1}, \dots, U'_{x_n}$. Let $U = U'_{x_1} \cap \dots \cap U'_{x_n}$. Fix $y \in G$, and suppose $y \in x_k U'_{x_k}$. Then
    %
    \begin{align*}
        f(y)^{-1} f(yU) &= f(y)^{-1} f(x_k) f(x_k)^{-1} f(yU)\\
        &\subset f(y)^{-1} f(x_k) f(x_k)^{-1} f(x_k Ux_k)\\
        &\subset f(y)^{-1} f(x_k) V'\\
        &\subset V'^2 \subset V
    \end{align*}
    %
    So that $f$ is left uniformly continuous. Right uniform continuity is proven in the exact same way.
\end{proof}

\begin{corollary}
    All maps with compact support are uniformly continuous.
\end{corollary}

\begin{corollary}
    Uniform continuity on compact groups is invariant of the uniform structure chosen.
\end{corollary}

\section{Ordered Groups}

In this section we describe a general class of groups which contain both interesting and pathological examples. Let $G$ be a group with an ordering $<$ preserved by the group operations, so that $a < b$ implies both $ag < bg$ and $ga < gb$. We now prove that the order topology gives $G$ the structure of a normal topological group (the normality follows because of general properties of order topologies).

First note, that $a < b$ implies $a^{-1} < b^{-1}$. This results from a simple algebraic trick, because
%
\[  a^{-1} = a^{-1} b b^{-1} > a^{-1} a b^{-1} = b^{-1} \]
%
This implies that the inverse image of an interval $(a,b)$ under inversion is $(b^{-1}, a^{-1})$, hence inversion is continuous.

Now let $e < b < a$. We claim that there is then $e < c$ such that $c^2 < a$. This follows because if $b^2 \geq a$, then $b \geq ab^{-1}$ and so
%
\[ (ab^{-1})^2 = ab^{-1}ab^{-1} \leq ab^{-1}b = a \]
%
Now suppose $a < e < b$. If $\inf \{ y : y > e \} = x > e$, then $(x^{-1}, x) = \{ e \}$, and the topology on $G$ is discrete, hence the continuity of operations is obvious. Otherwise, we may always find $c$ such that $c^2 < b$, $a < c^{-2}$, and then if $c^{-1} < g,h < c$, then
%
\[ a < c^{-2} < gh < c^2 < b \]
%
so multiplication is continuous at every pair $(x,x^{-1})$. In the general case, if $a < gh < b$, then $g^{-1}ah^{-1} < e < g^{-1}bh^{-1}$, so there is $c$ such that if $c^{-1} < g',h' < c$, then $g^{-1}ah^{-1} < g'h' < g^{-1}bh^{-1}$, so $a < gg'h'h < b$. The set of $gg'$, where $c^{-1} < g' < c$, is really just the set of $gc^{-1} < x < gc$, and the set of $h'h$ is really just the set of $c^{-1}h < x < ch$. Thus multiplication is continuous everywhere.

\begin{example}[Dieudonne]
    For any well ordered set $S$, the dictionary ordering on $\RR^S$ induces a linear ordering inducing a topological group structure on the set of maps from $S$ to $\RR$.
\end{example}

Let us study Dieudonne's topological group in more detail. If $S$ is a finite set, or more generally possesses a maximal element $w$, then the topology on $\RR^S$ can be defined such that $f_i \to f$ if eventually $f_i(s) = f(s)$ for all $s < w$ simultaneously, and $f_i(w) \to f(w)$. Thus $\RR^S$ is isomorphic (topologically) to a discrete union of a certain number of copies of $\RR$, one for each tuple in $S - \{ w \}$.

If $S$ has a countable cofinal subset $\{ s_i \}$, the topology is no longer so simple, but $\RR^S$ is still first countable, because the sets
%
\[ U_i = \{ f : (\forall w < s_i: f(w) = 0) \} \]
%
provide a countable neighbourhood basis of the origin.

The strangest properties of $\RR^S$ occur when $S$ has no countable cofinal set. Suppose that $f_i \to f$. We claim that it follows that $f_i = f$ eventually. To prove by contradiction, we assume without loss of generality (by thinning the sequence) that no $f_i$ is equal to $f$. For each $f_i$, find the largest $w_i \in S$ such that for $s < w_i$, $f_i(s) = f(s)$ (since $S$ is well ordered, the set of elements for which $f_i(s) \neq f(s)$ has a minimal element). Then the $w_i$ form a countable cofinal set, because if $v \in S$ is arbitrary, the $f_i$ eventually satisfy $f_i(s) = f(s)$ for $s < v$, hence the corresponding $w_i$ is greater than $v_i$. Hence, if $f_i \to f$ in $\RR^S$, where $S$ does not have a countable cofinal subset, then eventually $f_i = f$. We conclude all countable sets in $\RR^S$ are closed, and this proof easily generalises to show that if $S$ does not have a cofinal set of cardinality $\mathfrak{a}$, then every set of cardinality $\leq \mathfrak{a}$ is closed.

The simple corollary to this proof is that compact subsets are finite. Let $X = f_1, f_2, \dots$ be a denumerable, compact set. Since all subsets of $X$ are compact, we may assume $f_1 < f_2 < \dots$ (or $f_1 > f_2 > \dots$, which does not change the proof in any interesting way). There is certainly $g \in \RR^S$ such that $g < f_1$, and then the sets $(g,f_2), (f_1, f_3), (f_2,f_4), \dots$ form an open cover of $X$ with no finite subcover, hence $X$ cannot be compact. We conclude that the only compact subsets of $\RR^S$ are finite.

Furthermore, the class of open sets is closed under countable intersections. Consider a series of functions
%
\[ f_1 \leq f_2 \leq \dots < h < \dots \leq g_2 \leq g_1 \]
%
Suppose that $f_i \leq k < h < k' \leq g_j$. Then the intersection of the $(f_i, g_i)$ contains an interval $(k,k')$ around $h$, so that the intersection is open near $h$. The only other possiblity is that $f_i \to h$ or $g_i \to h$, which can only occur if $f_i = h$ or $g_i = h$ eventually, in which case we cannot have $f_i < h$, $h < g_i$. We conclude the intersection of countably many intervals is open, because we can always adjust any intersection to an intersection of this form without changing the resulting intersecting set (except if the set is empty, in which case the claim is trivial). The general case results from noting that any open set in an ordered group is a union of intervals.

\section{Topological Groups arising from Normal subgroups}

Let $G$ be a group, and $\mathcal{N}$ a family of normal subgroups closed under intersection. If we interpret $\mathcal{N}$ as a neighbourhood base at the origin, the resulting topology gives $G$ the structure of a totally disconnected topological group, which is Hausdorff if and only if $\bigcap \mathcal{N} = \{ e \}$. First note that $g_i \to g$ if $g_i$ is eventually in $gN$, for every $N \in \mathcal{N}$, which implies $g_i^{-1} \in Ng^{-1} = g^{-1}N$, hence inversion is continuous. Furthermore, if $h_i$ is eventually in $hN$, then $g_ih_i \in gNhN = ghN$, so multiplication is continuous. Finally note that $N^c = \bigcup_{g \neq e} gN$ is open, so that every open set is closed.

\begin{example}
    Consider $\mathcal{N} = \{ \mathbf{Z}, 2\mathbf{Z}, 3\mathbf{Z}, \dots \}$. Then $\mathcal{N}$ induces a Hausdorff topology on $\mathbf{Z}$, such that $g_i \to g$, if and only if $g_i$ is eventually in $g + n \mathbf{Z}$ for all $n$. In this topology, the series $1,2,3,\dots$ converges to zero!
\end{example}

This example gives us a novel proof, due to Furstenburg, that there are infinitely many primes. Suppose that there were only finitely many, $\{ p_1, p_2, \dots, p_n \}$. By the fundamental theorem of arithmetic,
%
\[ \{ -1, 1 \} = (\mathbf{Z} p_1)^c \cap \dots \cap (\mathbf{Z} p_n)^c \]
%
and is therefore an open set. But this is clearly not the case as open sets must contain infinite sequences.

\chapter{The Haar Measure}

One of the reasons that we isolate locally compact groups to study is that they possess an incredibly useful object allowing us to understand functions on the group, and thus the group itself. A {\bf left (right) Haar measure} for a group $G$ is a Radon measure $\mu$ for which $\mu(xE) = \mu(E)$ for any $x \in G$ and measurable $E$ ($\mu(Ex) = \mu(E)$ for all $x$ and $E$). For commutative groups, all left Haar measures are right Haar measures, but in non-commutative groups this need not hold. However, if $\mu$ is a right Haar measure, then $\nu(E) = \mu(E^{-1})$ is a left Haar measure, so there is no loss of generality in focusing our study on left Haar measures.

\begin{example}
    The example of a Haar measure that everyone knows is the Lebesgue measure on $\RR$ (or $\RR^n$). It commutes with translations because it is the measure induced by the linear functional corresponding to Riemann integration on $C_c^+(\RR^n)$. A similar theory of Darboux integration can be applied to linearly ordered groups, leading to the construction of a Haar measure on such a group.
\end{example}

\begin{example}
    If $G$ is a Lie group, consider a $2$-tensor $g_e \in T^2_e(G)$ inducing an inner product at the origin. Then the diffeomorphism $f: a \mapsto b^{-1}a$ allows us to consider $g_b = f^* \lambda \in T^2_b(G)$, and this is easily verified to be an inner product, hence we have a Riemannian metric. The associated Riemannian volume element can be integrated, producing a Haar measure on $G$.
\end{example}

\begin{example}
    If $G$ and $H$ have Haar measures $\mu$ and $\nu$, then $G \times H$ has a Haar measure $\mu \times \nu$, so that the class of topological groups with Haar measures is closed under the product operation. We can even allow infinite products, provided that the groups involved are compact, and the Haar measures are normalized to probability measures. This gives us measures on $F_2^\omega$ and $\mathbf{T}^\omega$, which models the probability of an infinite sequence of coin flips.
\end{example}

\begin{example}
    $dx/x$ is a Haar measure for the multiplicative group of positive real numbers, since
    %
    \[ \int_a^b \frac{1}{x} = \log(b) - \log(a) = \log(cb) - \log(ca) = \int_{ca}^{cb} \frac{1}{x} \]
    %
    If we take the multiplicative group of all non-negative real numbers, the Haar measure becomes $dx/|x|$.
\end{example}

\begin{example}
    $dx dy/(x^2 + y^2)$ is a Haar measure for the multiplicative group of complex numbers, since we have a basis of `arcs' around the origin, and by a change of variables to polar coordinates, we verify the integral is changed by multiplication. Another way to obtain this measure is by noticing that $\mathbf{C}^\times$ is topologically isomorphic to the product of the circle group and the multiplicative group of real numbers, and hence the measure obtained should be the product of these measures. Since
    %
    \[ \frac{dx dy}{x^2 + y^2} = \frac{dr d\theta}{r} \]
    %
    We see that this is just the product of the Haar measure on $\RR^+$, $dr/r$, and the Haar measure on $\mathbf{T}$, $d \theta$.
\end{example}

\begin{example}
    The space $M_n(\RR)$ of all $n$ by $n$ real matrices under addition has a Haar measure $dM$, which is essentially the Lebesgue measure on $\RR^{n^2}$. If we consider the measure on $GL_n(\RR)$, defined by
    %
    \[ \frac{dM}{\text{det}(M)^n} \]
    %
    To see this, note the determinant of the map $M \mapsto NM$ on $M_n(\RR)$ is $\text{det}(N)^n$, because we can view $M_n(\RR)$ as the product of $\RR^n$ $n$ times, multiplication operates on the space componentwise, and the volume of the image of the unit paralelliped in each $\RR^n$ is $\text{det}(N)$. Since the multiplicative group of complex numbers $z = x + iy$ can be identified with the group of matrices of the form
    %
    \[ \begin{pmatrix} x & -y \\ y & x \end{pmatrix} \]
    %
    and the measure on $\mathbf{C} - \{ 0 \}$ then takes the form $dM/\text{det}(M)$. More generally, if $G$ is an open subset of $\RR^n$, and left multiplication acts affinely, $xy = A(x)y + b(x)$, then $dx/|\text{det}(A(x))|$ is a left Haar measure on $G$, where $dx$ is Lebesgue measure.
\end{example}

It turns out that there is a Haar measure on any locally compact group, and what's more, it is unique up to scaling. The construction of the measure involves constructing a positive linear functional $\phi: C_c(G) \to \RR$ such that $\phi(L_x f) = \phi(f)$ for all $x$. The Riesz representation theorem then guarantees the existence of a Radon measure $\mu$ which represents this linear functional, and one then immediately verifies that this measure is a Haar measure.

\begin{theorem}
    Every locally compact group $G$ has a Haar measure.
\end{theorem}
\begin{proof}
    The idea of the proof is fairly simple. If $\mu$ was a Haar measure, $f \in C_c^+(G)$ was fixed, and $\phi \in C_c^+(G)$ was a function supported on a small set, and behaving like a step function, then we could approximate $f$ well by translates of $\phi$,
    %
    \[ f(x) \approx \sum c_i (L_{x_i} \phi) \]
    %
    Hence
    %
    \[ \int f(x) d \mu \approx \sum c_i \int L_{x_i} \phi = \sum c_i \int \phi \]
    %
    If $\int \phi = 1$, then we could approximate $\int f(x) d \mu$ as literal sums of coefficients $c_i$. Since $\mu$ is outer regular, and $\phi$ is supported on neighbourhoods, one can show $\int f(x) d\mu$ is the infinum of $\sum c_i$, over all choices of $c_i > 0$ and $\int \phi \geq 1$, for which $f \leq \sum c_i L_{x_i} \phi$. Without the integral, we cannot measure the size of the functions $\phi$, so we have to normalize by a different factor. We define $(f: \phi)$ to be the infinum of the sums $\sum c_i$, where $f \leq \sum c_i L_{x_i} \phi$ for some $x_i \in G$. We would then have
    %
    \[ \int f d \mu \leq (f: \phi) \int \phi d\mu \]
    %
    If $k$ is fixed with $\int k = 1$, then we would have
    %
    \[ \int f d\mu \leq (f: \phi) (\phi: k) \]
    %
    We cannot change $k$ if we wish to provide a limiting result in $\phi$, so we notice that $(f: g) (g: h) \leq (f:h)$, which allows us to write
    %
    \[ \int f d\mu \leq \frac{(f: \phi)}{(k : \phi)} \]
    %
    Taking the support of $\phi$ to be smaller and smaller, this value should approximate the integral perfectly accurately.

    Define the linear functional
    %
    \[ I_\phi(f) = \frac{(f: \phi)}{(k: \phi)} \]
    %
    Then $I_\phi$ is a sublinear, monotone, function with a functional bound
    %
    \[ (k: f)^{-1} \leq I_\phi(f) \leq (f: k) \]
    %
    Which effectively says that, regardless of how badly we choose $\phi$, the approximation factor $(f:\phi)$ is normalized by the approximation factor $(k:\phi)$ so that the integral is bounded. Now we need only prove that $I_\phi$ approximates a linear functional well enough that we can perform a limiting process to obtain a Haar integral. If $\varepsilon > 0$, and $g \in C_c^+(G)$ with $g = 1$ on $\text{supp}(f_1 + f_2)$, then the functions
    %
    \[ h = f_1 + f_2 + \varepsilon g \]
    %
    \[ h_1 = f_1/h \ \ \ \ \ h_2 = f_2/h \]
    %
    are in $C^+_0(G)$, if we define $h_i(x) = 0$ if $f_i(x) = 0$. This implies that there is a neighbourhood $V$ of $e$ such that if $x \in V$, and $y$ is arbitrary, then
    %
    \[ | h_1(xy) - h_1(y) | \leq \varepsilon\ \ \ \ \ | h_2(xy) - h_2(y) | < \varepsilon \]
    %
    If $\text{supp}(\phi) \subset V$, and $h \leq \sum c_i L_{x_i} \phi$, then
    %
    \[ f_j(x) = h(x) h_j(x) \leq \sum c_i \phi(x_i x) h_j(x) \leq \sum c_i \phi(x_i x) \left[ h_j(x_i^{-1}) + \varepsilon \right] \]
    %
    since we may assume that $x_i x \in \text{supp}(\phi) \subset V$. Then, because $h_1 + h_2 \leq 1$,
    %
    \[ (f_1: \phi) + (f_2 : \phi) \leq \sum c_j [h_1(x_j^{-1}) + \varepsilon] + \sum c_j [h_2(x_j^{-1}) + \varepsilon] \leq \sum c_j [1 + 2 \varepsilon] \]
    %
    Now we find, by taking infinums, that
    %
    \[ I_\phi(f_1) + I_\phi(f_2) \leq I_\phi(h) (1 + 2 \varepsilon) \leq [I_\phi(f_1 + f_2) + \varepsilon I_\phi(g)] [1 + 2 \varepsilon] \]
    %
    Since $g$ is fixed, and we have a bound $I_\phi(g) \leq (g: k)$, we may always find a neighbourhood $V$ (dependant on $f_1$, $f_2$) for any $\varepsilon > 0$ such that
    %
    \[ I_\phi(f_1) + I_\phi(f_2) \leq I_\phi(f_1 + f_2) + \varepsilon \]
    %
    if $\text{supp}(\phi) \subset V$.

    Now we have estimates on how well $I_\phi$ approximates a linear function, so we can apply a limiting process. Consider the product
    %
    \[ X = \prod_{f \in C^+_0(G)} [(k : f)^{-1}, (k: f_0)] \]
    %
    a compact space, by Tychonoff's theorem, consisting of $F: C_c^+(G) \to \RR$ such that $(k : f)^{-1} \leq F(f) \leq (f: k)$. For each neighbourhood $V$ of the identity, let $K(V)$ be the closure of the set of $I_\phi$ such that $\text{supp}(\phi) \subset V$. Then the set of all $K(V)$ has the finite intersection property, so we conclude there is some $I: C_c^+(G) \to \RR$ contained in $\bigcap K(V)$. This means that every neighbourhood of $I$ contains $I_\phi$ with $\text{supp}(\phi) \subset V$, for all $\phi$. This means that if $f_1, f_2 \in C_c^+(G)$, $\varepsilon > 0$, and $V$ is arbitrary, there is $\phi$ with $\text{supp}(\phi) \subset V$, and
    %
    \[ |I(f_1) - I_\phi(f_1)| < \varepsilon\ \ \ |I(f_2) - I_\phi(f_2)| < \varepsilon \]
    \[ |I(f_1 + f_2) - I_\phi(f_1 + f_2)| < \varepsilon \]
    %
    this implies that if $V$ is chosen small enough, then
    %
    \[ |I(f_1 + f_2) - (I(f_1) - I(f_2))| \leq 2 \varepsilon + |I_\phi(f_1 + f_2) - (I_\phi(f_1) + I_\phi(f_2))| < 3 \varepsilon \]
    %
    Taking $\varepsilon \to 0$, we conclude $I$ is linear. Similar limiting arguments show that $I$ is homogenous of degree 1, and commutes with all left translations. We conclude the extension of $I$ to a linear functional on $C_0(G)$ is well defined, and the Radon measure obtained by the Riesz representation theorem is a Haar measure.
\end{proof}

We shall prove that the Haar measure is unique, but first we show an incredibly useful regularity property.

\begin{prop}
    If $U$ is open, and $\mu$ is a Haar measure, then $\mu(U) > 0$. It follows that if $f$ is in $C_c^+(G)$, then $\int f d \mu > 0$.
\end{prop}
\begin{proof}
    If $\mu(U) = 0$, then for any $x_1, \dots, x_n \in G$,
    %
    \[ \mu \left( \bigcup_{i = 1}^n x_i U \right) \leq \sum_{i = 1}^n \mu(x_i U) = 0 \]
    %
    If $K$ is compact, then $K$ can be covered by finitely many translates of $U$, so $\mu(K) = 0$. But then $\mu = 0$ by regularity, a contradiction.
\end{proof}

\begin{theorem}
    Haar measures are unique up to a multiplicative constant.
\end{theorem}
\begin{proof}
    Let $\mu$ and $\nu$ be Haar measures. Fix a compact neighbourhood $V$ of the identity. If $f,g \in C_c^+(G)$, consider the compact sets
    %
    \[ A = \text{supp}(f) V \cup V \text{supp}(f)\ \ \ \ \ B = \text{supp}(g) V \cup V \text{supp}(g) \]
    %
    Then the functions $F_y(x) = f(xy) - f(yx)$ and $G_y(x) = g(xy) - g(yx)$ are supported on $A$ and $B$. There is a neighbourhood $W \subset V$ of the identity such that $\| F_y \|_\infty, \| G_y \|_\infty < \varepsilon$ if $y \in W$. Now find $h \in C_c^+(G)$ with $h(x) = h(x^{-1})$ and $\text{supp}(h) \subset W$ (take $h(x) = k(x) k(x^{-1})$ for some function $k \in C^+_c(G)$ with $\text{supp}(k) \subset W$, and $k = 1$ on a symmetric neighbourhood of the origin). Then
    %
    \begin{align*}
        \left( \int h d\mu \right) \left( \int f d\lambda \right) &= \int h(y) f(x) d\mu(y) d\lambda(x)\\
        &= \int h(y) f(yx) d\mu(y) d\lambda(x)
    \end{align*}
    %
    and
    %
    \begin{align*}
        \left( \int h d\lambda \right) \left( \int f d\mu \right) &= \int h(x) f(y) d\mu(y) d\lambda(x)\\
        &= \int h(y^{-1}x) f(y) d\mu(y) d\lambda(x)\\
        &= \int h(x^{-1}y) f(y) d\mu(y) d\lambda(x)\\
        &= \int h(y) f(xy) d\mu(y) d\lambda(x)
    \end{align*}
    %
    Hence, applying Fubini's theorem,
    %
    \begin{align*}
        \left| \int h d\mu \int f d\lambda - \int h d\lambda \int f d\mu \right| &\leq \int h(y) |F_y(x)| d\mu(y) d\lambda(x)\\
        &\leq \varepsilon \lambda(A) \int h d\mu
    \end{align*}
    %
    In the same way, we find this is also true when $f$ is swapped with $g$, and $A$ with $B$. Dividing this inequalities by $\int h d\mu \int f d\mu$, we find
    %
    \[  \left| \frac{\int f d\lambda}{\int f d\mu} - \frac{\int h d\lambda}{\int h d\mu} \right| \leq \frac{\varepsilon \lambda(A)}{\int f d\mu} \]
    %
    and this inequality holds with $f$ swapped out with $g$, $A$ with $B$. We then combine these inequalities to conclude
    %
    \[ \left| \frac{\int f d\lambda}{\int f d\mu} - \frac{\int g d\lambda}{\int g d\mu} \right| \leq \varepsilon \left[ \frac{\lambda(A)}{\int f d\mu} + \frac{\lambda(B)}{\int g d\mu} \right] \]
    %
    Taking $\varepsilon$ to zero, we find $\lambda(A), \lambda(B)$ remain bounded, and hence
    %
    \[ \frac{\int f d\lambda}{\int f d\mu} = \frac{\int g d\lambda}{\int g d\mu} \]
    %
    Thus there is a cosntant $c > 0$ such that $\int f d\lambda = c \int f d\mu$ for any function $f \in C_c^+(G)$, and we conclude that $\lambda = c \mu$.
\end{proof}

The theorem can also be proven by looking at the translation invariant properties of the derivative $f = d\mu/d\nu$, where $\nu = \mu + \lambda$ (We assume our group is $\sigma$ compact for now). Consider the function $g(x) = f(yx)$. Then
%
\[ \int_A g(x) d\nu = \int_{yA} f(x) d\nu = \mu(yA) = \mu(A) \]
%
so $g$ is derivative, and thus $f = g$ almost everywhere. Our interpretation is that for a fixed $y$, $f(yx) = f(x)$ almost everywhere with respect to $\nu$. Then (applying a discrete version of Fubini's theorem), we find that for almost all $x$ with respect to $\nu$, $f(yx) = f(x)$ holds for almost all $y$. But this implies that there exists an $x$ for which $f(yx) = f(x)$ holds almost everywhere. Thus for any measurable $A$,
%
\[ \mu(A) = \int_A f(y) d\nu(y) = f(x) \nu(A) = f(x) \mu(A) + f(x) \nu(A) \]
%
Now $(1 - f(x)) \mu(A) = f(x) \nu(A)$ for all $A$, implying (since $\mu, \nu \neq 0$), that $f(x) \neq 0,1$, and so
%
\[ \frac{1-f(x)}{f(x)} \mu(A) = \nu(A) \]
%
for all $A$. This shows the uniqueness property for all $\sigma$ compact groups. If $G$ is an arbitrary group with two measures $\mu$ and $\nu$, then there is $c$ such that $\mu = c \nu$ on every component of $G$, and thus on the union of countably many components. If $A$ intersects uncountably many components, then either $\mu(A) = \nu(A) = \infty$, or the intersection of $A$ on each set has positive measure on only countably many components, and in either case we have $\mu(A) = \nu(A)$.

\section{Fubini, Radon Nikodym, and Duality}

Before we continue, we briefly mention that integration theory is particularly nice over locally compact groups, even if we do not have $\sigma$ finiteness. This essentially follows because the component of the identity in $G$ is $\sigma$ compact (take a compact neighbourhood and its iterated multiples), hence all components in $G$ are $\sigma$ compact. The three theorems that break down outside of the $\sigma$ compact domain are Fubini's theorem, the Radon Nikodym theory, and the duality between $L^1(X)$ and $L^\infty(X)$. We show here that all three hold if $X$ is a locally compact topological group.

First, suppose that $f \in L^1(G \times G)$. Then the essential support of $f$ is contained within countably many components of $G \times G$ (which are simply products of components in $G$). Thus $f$ is supported on a $\sigma$ compact subset of $G \times G$ (as a locally compact topological group, each component of $G \times G$ is $\sigma$ compact), and we may apply Fubini's theorem on the countably many components (the countable union of $\sigma$ compact sets is $\sigma$ compact). The functions in $L^p(G)$, for $1 \leq p < \infty$, also vanish outside of a $\sigma$ compact subset (for if $f \in L^p(G)$, $|f|^p \in L^1(G)$ and thus vanishes outside of a $\sigma$ compact set). What's more, all finite sums and products of functions from these sets (in either variable) vanish outside of $\sigma$ compact subsets, so we almost never need to explicitly check the conditions for satisfying Fubini's theorem, and from now on we apply it wantonly.s

Now suppose $\mu$ and $\nu$ are both Radon measures, with $\nu \ll \mu$, and $\nu$ is $\sigma$-finite. By inner regularity, the support of $\nu$ is a $\sigma$ compact set $E$. By inner regularity, $\mu$ restricted to $E$ is $\sigma$ finite, and so we may find a Radon Nikodym derivative on $E$. This derivative can be extended to all of $G$ because $\nu$ vanishes on $G$.

Finally, we note that $L^\infty(X) = L^1(X)^*$ can be made to hold if $X$ is not $\sigma$ finite, but locally compact and Hausdorff, provided we are integrating with respect to a Radon measure $\mu$, and we modify $L^\infty(G)$ slightly. Call a set $E \subset X$ {\bf locally Borel} if $E \cap F$ is Borel whenever $F$ is Borel and $\mu(F) < \infty$. A locally Borel set is {\bf locally null} if $\mu(E \cap F) = 0$ whenever $\mu(F) < \infty$ and $F$ is Borel. We say a property holds {\bf locally almost everywhere} if it is true except on a locally null set. $f: X \to \mathbf{C}$ is {\bf locally measurable} if $f^{-1}(U)$ is locally Borel for every borel set $U \subset \mathbf{C}$. We now define $L^\infty(X)$ to be the space of all functions bounded except on a locally null set, modulo functions that are locally zero. That is, we define a norm
%
\[ \| f \|_\infty = \inf \{ c : |f(x)| \leq c\ \text{locally almost everywhere} \} \]
%
and then $L^\infty(X)$ consists of the functions that have finite norm. It then follows that if $f \in L^\infty(X)$ and $g \in L^1(X)$, then $g$ vanishes outside of a $\sigma$-finite set $Y$, so $fg \in L^1(X)$, and if we let $Y_1 \subset Y_2 \subset \dots \to Y$ be an increasing subsequence such that $\mu(Y_i) < \infty$, then $|f(x)| \leq \| f \|_\infty$ almost everywhere for $x \in Y_i$, and so by the monotone convergence theorem
%
\[ \int |fg| d\mu = \lim_{Y_i \to \infty} \int_{Y_i} |fg| d\mu \leq \| f \|_\infty \int_{Y_i} |g| d\mu \leq \| f \|_\infty \| g \|_1 \]
%
Thus the map $g \mapsto \int fg d\mu$ is a well defined, continuous linear functional with norm $\| f \|_\infty$. That $L^1(X)^* = L^\infty(X)$ follows from the decomposibility of the Carath\'{e}odory extension of $\mu$, a fact we leave to the general measure theorists.

\section{Unimodularity}

We have thus defined a left invariant measure, but make sure to note that such a function is not right invariant. We call a group who's left Haar measure is also right invariant {\bf unimodular}. Obviously all abelian groups are unimodular.

Given a fixed $y$, the measure $\mu_y(A) = \mu(Ay)$ is a new Haar measure on the space, hence there is a constant $\Delta(y) > 0$ depending only on $y$ such that $\mu(Ay) = \Delta(y) \mu(A)$ for all measurable $A$. Since $\mu(Axy) = \Delta(y) \mu(Ay) = \Delta(x) \Delta(y) \mu(A)$, we find that $\Delta(xy) = \Delta(x) \Delta(y)$, so $\Delta$ is a homomorphism from $G$ to the multiplicative group of real numbers. For any $f \in L^1(\mu)$, we have
%
\[ \int f(xy) d\mu(x) = \Delta(y^{-1}) \int f(x) d\mu(x)  \]
%
If $y_i \to e$, and $f \in C_c(G)$, then $\| R_{y_i} f - f \|_\infty \to 0$, so
%
\[ \Delta(y_i^{-1}) \int f(x) d\mu = \int f(xy_i) d\mu \to \int f(x) d\mu \]
%
Hence $\Delta(y_i^{-1}) \to 1$. This implies $\Delta$, known as the unimodular function, is a continuous homomorphism from $G$ to the real numbers. Note that $\Delta$ is trivial if and only if $G$ is unimodular.

\begin{theorem}
    Any compact group is unimodular.
\end{theorem}
\begin{proof}
    $\Delta: G \to \RR^*$ is a continuous homomorphism, hence $\Delta(G)$ is compact. But the only compact subgroup of $\RR$ is trivial, hence $\Delta$ is trivial.
\end{proof}

Let $G^c$ be the smallest closed subgroup of $G$ containing the commutators $[x,y] = xyx^{-1}y^{-1}$. It is verified to be a normal subgroup of $G$ by simple algebras.

\begin{theorem}
    If $G/G^c$ is compact, then $G$ is unimodular.
\end{theorem}
\begin{proof}
    $\Delta$ factors through $G/G^c$ since it is abelian. But if $\Delta$ is trivial on $G/G^c$, it must also be trivial on $G$.
\end{proof}

The modular function relates right multiplication to left multiplcation in the group. In particular, if $d \mu$ is a Left Haar measure, then $\Delta^{-1} d\mu$ is a right Haar measure. Hence any right Haar measure is a constant multiple of $\Delta^{-1} d\mu$. Hence the measure $\nu(A) = \mu(A^{-1})$ has a value $c$ such that for any function $f$,
%
\[ \int \frac{f(x)}{\Delta(x)} d\mu(x) = c \int f(x) d\nu(x) = c \int f(x^{-1}) d\mu \]
%
If $c \neq 1$, pick a symmetric neighbourhood $U$ such that for $x \in U$, $|\Delta(x) - 1| \leq \varepsilon |c - 1|$. Then if $f > 0$
%
\[ |c-1|\mu(U) = |c\mu(U^{-1}) - \mu(U)| = \left| \int_U [\Delta(x^{-1}) - 1] d\mu(x) \right| \leq \varepsilon \mu(U) |c-1| \]
%
A contradiction if $\varepsilon < 1$. Thus we have
%
\[ \int f(x^{-1}) d\mu(x) = \int \frac{f(x)}{\Delta(x)} d\mu(x) \]
%
A useful integration trick. When $\Delta$ is unbounded, then it follows that $L^p(\mu)$ and $L^p(\nu)$ do not consist of the same functions. There are two ways of mapping the sets isomorphically onto one another -- the map $f(x) \mapsto f(x^{-1})$, and the map $f(x) \mapsto \Delta(x)^{1/p} f(x)$.

From now on, we assume a left invariant Haar measure is fixed over an entire group. Since a Haar measure is uniquely determined up to a constant, this is no loss of generality, and we might as well denote our integration factors $d\mu(x)$ and $d\mu(y)$ as $dx$ and $dy$, where it is assumed that this integration is over the Lebesgue measure.

\section{Convolution}

If $G$ is a topological group, then $C(G)$ does not contain enough algebraic structure to identify $G$ -- for instance, if $G$ is a discrete group, then $C(G)$ is defined solely by the cardinality of $G$. The algebras we wish to study over $G$ is the space $M(G)$ of all complex valued Radon measures over $G$ and the space $L^1(G)$ of integrable functions with respect to the Haar measure, because here we can place a Banach algebra structure with an involution. We note that $L^1(G)$ can be isometrically identified as the space of all measures $\mu \in M(G)$ which are absolutely continuous with respect to the Haar measure. Given $\mu, \nu \in M(G)$, we define the convolution measure
%
\[ \int \phi d(\mu * \nu) = \int \phi(xy) d\mu(x) d\nu(y) \]
%
The measure is well defined, for if $\phi \in C_c^+(X)$ is supported on a compact set $K$, then
%
\begin{align*}
    \left| \int \phi(xy) d\mu(x) d\nu(y) \right| &\leq \int_G \int_G \phi(xy) d|\mu|(x) d|\nu|(y)\\
    &\leq \| \mu \| \| \nu \| \| \phi \|_\infty
\end{align*}
%
This defines an operation on $M(G)$ which is associative, since, by applying the associativity of $G$ and Fubini's theorem.
%
\begin{align*}
    \int \phi d((\mu * \nu) * \lambda) &= \int \int \phi(xz) d(\mu * \nu)(x) d\lambda(z)\\
    &= \int \int \int \phi((xy)z) d\mu(x) d\nu(y) d\lambda(z)\\
    &= \int \int \int \phi(x(yz)) d\mu(x) d\nu(y) d\lambda(z)\\
    &= \int \int \phi(xz) d\mu(x) d(\nu * \lambda)(z)\\
    &= \int \phi d(\mu * (\nu * \lambda))
\end{align*}
%
Thus we begin to see how the structure of $G$ gives us structure on $M(G)$. Another example is that convolution is commutative if and only if $G$ is commutative. We have the estimate $\| \mu * \nu \| \leq \| \mu \| \| \nu \|$, because of the bound we placed on the integrals above. $M(G)$ is therefore an involutive Banach algebra, which has a unit, the dirac delta measure at the identity.

As a remark, we note that involutive Banach algebras have nowhere as near a nice of a theory than that of $C^*$ algebras. $M(G)$ cannot be renormed to be a $C^*$ algebra, since every weakly convergent Cauchy sequence converges, which is impossible in a $C^*$ algebra, except in the finite dimensional case.

A {\bf discrete measure} on $G$ is a measure in $M(G)$ which vanishes outside a countable set of points, and the set of all such measures is denoted $M_d(G)$. A {\bf continuous measure} on $G$ is a measure $\mu$ such that $\mu(\{x\}) = 0$ for all $x \in G$. We then have a decomposition $M(G) = M_d(G) \oplus M_c(G)$, for if $\mu$ is any measure, then $\mu(\{x\}) \neq 0$ for at most countably many points $x$, for
%
\[ \| \mu \| \geq \sum_{x \in G} |\mu|(x) \]
%
This gives rise to a discrete measure $\nu$, and $\mu - \nu$ is continuous. If we had another decomposition, $\mu = \psi + \phi$, then $\mu(\{x\}) = \psi(\{x\}) = \nu(\{x\})$, so $\psi = \nu$ by discreteness, and we then conclude $\phi = \mu - \nu$. $M_c(G)$ is actually a closed subspace of $M(G)$, since if $\mu_i \to \mu$, and $\mu_i \in M_c(G)$, and $\| \mu_i - \mu \| < \varepsilon$, then for any $x \in G$,
%
\[ \varepsilon > \| \mu - \mu_i \| \geq |(\mu_i - \mu)(\{x\})| = |\mu(\{ x \})| \]
%
Letting $\varepsilon \to 0$ shows continuity.

The convolution on $M(G)$ gives rise to a convolution on $L^1(G)$, where
%
\[ (f*g)(x) = \int f(y) g(y^{-1}x) dy \]
%
which satisfies $\| f*g \|_1 \leq \| f \|_1 \| g \|_1$. This is induced by the identification of $f$ with $f(x) dx$, because then
%
\begin{align*}
    \int \phi (f(x) dx * g(x) dx) &= \int \int \phi(yx) f(y) g(x) dy dx\\
    &= \int \phi(y) \left( \int f(y) g(y^{-1}x) dx \right) dy
\end{align*}
%
Hence $f d\mu * g d\mu = (f * g) d\mu$. What's more,
%
\[ \| f \|_1 = \| f d\mu \| \]
%
If $\nu \in M(G)$, then we can still define $\nu * f \in L^1(G)$
%
\[ (\nu * f)(x) = \int f(y^{-1}x) d\mu(y) \]
%
which holds since
%
\[ \int \phi d(\nu * f \mu) = \int \phi(yx) f(x) d\nu(y) d\mu(x) = \int \phi(x) f(y^{-1}x) d\nu(y) d\mu(x) \]
%
If $G$ is unimodular, then we also find
%
\[ \int \phi d(f \mu * \nu) = \int \phi(yx) f(y) d\mu(y) d\nu(x) = \int \phi(x) f(y) d\mu(y) d\nu(y^{-1}x) \]
%
So we let $f * \mu(x) = \int f(y) d\mu(y^{-1}x)$.

\begin{theorem}
    $L^1(G)$ and $M_c(G)$ are closed ideals in $M(G)$, and $M_d(G)$ is a closed subalgebra.
\end{theorem}
\begin{proof}
    If $\mu_i \to \mu$, and each $\mu_i$ is discrete, the $\mu$ is discrete, because there is a countable set $K$ such that all $\mu_i$ are equal to zero outside of $K$, so $\mu$ must also vanish outside of $K$ (here we have used the fact that $M(G)$ is a Banach space, so that we need only consider sequences). Thus $M_d(G)$ is closed, and is easily verified to be subalgebra, essentially because $\delta_x * \delta_y = \delta_{xy}$. If $\mu_i \to \mu$, then $\mu_i(\{x\}) \to \mu(\{x\})$, so that $M_c(G)$ is closed in $M(G)$. If $\nu$ is an arbitrary measure, and $\mu$ is continuous, then
    %
    \[ (\mu * \nu)(\{ x \}) = \int_G \mu(\{ y \}) d\nu(y^{-1}x) = 0 \]
    \[ (\nu * \mu)(\{ x \}) = \int_G \mu(\{ y \}) d\nu(xy^{-1}) = 0 \]
    %
    so $M_c(G)$ is an ideal. Finally, we verify $L^1(G)$ is closed, because it is complete, and if $\nu \in M(G)$ is arbitrary, and if $U$ has null Haar measure, then
    %
    \[ (f dx * \nu)(U) = \int \chi_{U}(xy) f(x) dx\ d\nu(y) = \int_G \int_{y^{-1}U} f(x) dx d\nu(y) = 0 \]
    \[ (\nu * f dx)(U) = \int \chi_U(xy) d\nu(x) f(y) dy = \int_G \int_{Ux^{-1}} f(y) dy d\nu(x) = 0 \]
    %
    So $L^1(G)$ is a two-sided ideal.
\end{proof}

If we wish to integrate by right multiplication instead of left multiplication, we find by the substitution $y \mapsto xy$ that
%
\begin{align*}
    (f*g)(x) &= \int f(y) g(y^{-1}x) dy\\
    &= \int \int f(xy) g(y^{-1}) dy\\
    &= \int \int \frac{f(xy^{-1}) g(y)}{\Delta(y)} dy
\end{align*}
%
Observe that
%
\[ f*g = \int f(y) L_{y^{-1}} g\ dy \]
%
which can be interpreted as a vector valued integral, since for $\phi \in L^\infty(\mu)$,
%
\[ \int (f*g)(x) \phi(x) dx = \int f(y) g(y^{-1}x) \phi(x) dx dy \]
%
so we can see convolution as a generalized `averaging' of translate of $g$ with respect to the values of $f$. If $G$ is commutative, this is the same as the averaging of translates of $f$, but not in the noncommutative case. It then easily follows from operator computations $L_z (f*g) = (L_z f) * g$, and $R_z (f*g) = f * (R_zg)$, or from the fact that
%
\[ (f*g)(zx) = \int f(y) g(y^{-1}zx) dy = \int f(zy) g(y^{-1}x) dy = [(L_z f) * g](x) \]
\[ (f*g)(xz) = \int f(y) g(y^{-1}xz) dy = [f * (R_z g)](x) \]
%
Convolution can also be applied to the other $L^p$ spaces, but we have to be a bit more careful with our integration.

\begin{theorem}
    If $f \in L^1(G)$ and $g \in L^p(G)$, then $f*g$ is defined for almost all $x$, $f*g \in L^p(G)$, and $\| f*g\|_p \leq \|f \| \| g \|_p$. If $G$ is unimodular, then the same results hold for $g*f$, or if $G$ is not unimodular and $f$ has compact support.
\end{theorem}
\begin{proof}
    We use Minkowski's inequality to find
    %
    \begin{align*}
        \| f*g \|_p &= \left( \int \left| \int f(y) |g(y^{-1}x) dy \right|^{p} dx \right)^{1/p}\\
        &\leq \int |f(y)| \left( \int |g(y^{-1}x)|^p dx \right)^{1/p} dy\\
        &= \| f \|_1 \| g \|_p
    \end{align*}

    If $G$ is unimodular, then
    %
    \[ \| g*f \|_p = \left( \int \left| \int g(xy^{-1}) f(y) dy \right|^{p} dx \right)^{1/p} \]
    %
    and we may apply the same trick as used before.

    If $f$ has compact support $K$, then $1/\Delta$ is bounded above by $M > 0$ on $K$ and
    %
    \begin{align*}
        \| g * f \|_p &= \left( \int \left| \int \frac{ g(xy^{-1}) f(y)}{\Delta(y)} dy \right|^{p} dx \right)^{1/p}\\
        &\leq \int \left( \int \left| \frac{g(xy^{-1}) f(y)}{\Delta(y)} \right|^p dx \right)^{1/p} dy\\
        &= \| g \|_p \int_K \frac{|f(y)|}{\Delta(y)} d \mu(y)\\
        &\leq M \| g \|_p \| f \|_1
    \end{align*}
    %
    which shows that $g*f$ is defined almost everywhere.
\end{proof}

\begin{theorem}
    If $G$ is unimodular, $f \in L^p(G)$, $g \in L^q(G)$, and $p = q^*$, then $f*g \in C_0(G)$ and $\| f * g \|_\infty \leq \| f \|_p \| g \|_q$.
\end{theorem}
\begin{proof}
    First, note that
    %
    \begin{align*}
        |(f*g)(x)| &\leq \int |f(y)| |g(y^{-1}x)| dy\\
        &\leq \| f \|_p \left( \int |g(y^{-1}x)|^q dy \right)^{1/q}\\
        &= \| f \|_p \| g \|_q
    \end{align*}
    %
    For each $x$ and $y$, applying H\"{o}lder's inequality, we find
    %
    \begin{align*}
        |(f*g)(x) - (f*g)(y)| &\leq \int |f(z)| |g(z^{-1}x) - g(z^{-1}y)| dz\\
        &\leq \| f \|_p \left( \int |g(z^{-1}x) - g(z^{-1}y)|^q dz \right)^{1/q}\\
        &= \| f \|_p \left( \int |g(z) - g(zx^{-1}y)|^q dz \right)^{1/q}\\
        &= \| f \|_p \| g - R_{x^{-1}y} g \|_q
    \end{align*}
    %
    Thus to prove continuity (and in fact uniform continuity), we need only prove that $\| g - R_x g \|_q \to 0$ for $q \neq \infty$ as $x \to \infty$ or $x \to 0$. This is the content of the next lemma.
\end{proof}

We now show that the map $x \mapsto L_x$ is a continuous operation from $G$ to the weak $*$ topology on the $L_p$ spaces, for $p \neq \infty$. It is easily verified that translation is not continuous on $L_\infty$, by taking a suitable bumpy function.

\begin{theorem}
    If $p \neq \infty$, then $\| g - R_x g \|_p \to 0$ and $\| g - L_x g \|_p \to 0$ as $x \to 0$.
\end{theorem}
\begin{proof}
    If $g \in C_c(G)$, then one verifies the theorem by using left and right uniform continuity. In general, we let $g_i \in C_c(G)$ be a sequence of functions converging to $g$ in the $L_p$ norm, and we then find
    %
    \[ \| g - L_x g \|_p \leq \| g - g_i \|_p + \| g_i - L_x g_i \|_p + \| L_x (g_i - g) \|_p = 2 \| g - g_i \|_p + \| g_i - L_x g_i \|_p \]
    %
    Taking $i$ large enough, $x$ small enough, we find $\| g - L_x g \|_p \to 0$. The only problem for right translation is the appearance of the modular function
    %
    \begin{align*}
        \| R_x (g - g_i) \|_p = \frac{\| g - g_i \|_p}{\Delta(x)^{1/p}}
    \end{align*}
    %
    If we assume our $x$ values range only over a compact neighbourhood $K$ of the origin, we find that $\Delta(x)$ is bounded below, and hence $\| R_x (g - g_i) \|_p \to 0$, which effectively removes the problems in the proof.
\end{proof}

Since the map is linear, we have verified that the map $x \mapsto L_x f$ is uniformly continuous in $L^p$ for each $f \in L^p$. In the case where $p = \infty$, the same theorem cannot hold, but we have even better conditions that do not even require unimodularity.

\begin{theorem}
    If $f \in L^1(G)$ and $g \in L^\infty(G)$, then $f*g$ is left uniformly continuous, and $g*f$ is right uniformly continuous.
\end{theorem}
\begin{proof}
    We have
    %
    \[ \| L_z (f*g) - (f*g) \|_\infty = \| (L_z f - f) * g \|_\infty \leq \| L_z f - f \|_1 \| g \|_\infty \]
    %
    \[ \| R_z (g*f) - (g*f) \|_\infty = \| g * (R_z f - f) \|_\infty \leq \| g \|_\infty \| R_z f - f \|_1 \]
    %
    and both integrals converge to zero as $z \to 1$.
\end{proof}

The passage from $M(G)$ to $L^1(G)$ removes an identity from the Banach algebra in question (except if $G$ is discrete), but there is always a way to approximate an identity.

\begin{theorem}
    For each neighbourhood $U$ of the origin, pick a function $f_U \in (L^1)^+(G)$, with $\int \phi_U = 1$, $\text{supp}(f_U) \subset U$. Then if $g$ is any function in $L^p(G)$,
    %
    \[ \| f_U * g - g \|_p \to 0 \]
    %
    where we assume $g$ is left uniformly continuous if $p = \infty$, and if $f_U$ is viewed as a net with neighbourhoods ordered by inclusion. If in addition $f_U(x) = f_U(x^{-1})$, then $\| g * f_U - g \|_p \to 0$, where $g$ is right uniformly continuous for $p = \infty$.
\end{theorem}
\begin{proof}
    Let us first prove the theorem for $p \neq \infty$. If $g \in C_c(G)$ is supported on a compact $K$, and if $U$ is small enough that $|g(y^{-1}x) - g(x)| < \varepsilon$ for $y \in U$, then because $\int_U f_U(y) = 1$, and by applying Minkowski's inequality, we find
    %
    \begin{align*}
        \| f_U * g - g \|_p &= \left( \int \left| \int f_U(y) [g(y^{-1}x) - g(x)] dy \right|^p dx \right)^{1/p} \\
        &\leq \int f_U(y) \left( \int |g(y^{-1}x) - g(x)|^p dx \right)^{1/p} dy\\
        &\leq 2 \mu(K)\varepsilon \int f_U(y) dy \leq 2 \mu(K)\varepsilon
    \end{align*}
    %
    Results are then found for all of $L^p$ by taking limits. If $g$ is left uniformly continuous, then we may find $U$ such that $|g(y^{-1}x) - g(x)| < \varepsilon$ for $y \in U$ then
    %
    \[ |(f_U * g - g)(x)| = \left| \int f_U(y) [g(y^{-1}x) - g(x)] \right| \leq \varepsilon \]
    %
    For right convolution, we find that for $g \in C_c(G)$, where $|g(xy) - g(x)| < \varepsilon$ for $y \in U$, then
    %
    \begin{align*}
        \| g * f_U - g \|_p &= \left( \int \left| \int g(y) f_U(y^{-1}x) - g(x) dy \right|^p dx \right)^{1/p}\\
        &= \left( \int \left| \int [g(xy) - g(x)] f_U(y) dy \right|^p dx \right)^{1/p}\\
        &\leq \int \left( \int |g(xy) - g(x)|^p dx \right)^{1/p} f_U(y) dy\\
        &\leq \mu(K) \varepsilon \int f_U(y) (1 + \Delta(y)) dy\\
        &= \mu(K) \varepsilon + \mu(K) \varepsilon \int f_U(y) \Delta(y) dy
    \end{align*}
    %
    We may always choose $U$ small enough that $\Delta(y) < \varepsilon$ for $y \in U$, so we obtain a complete estimate $\mu(K) (\varepsilon + \varepsilon^2)$. If $g$ is right uniformly continuous, then choosing $U$ for which $|g(xy) - g(x)| < \varepsilon$, then
    %
    \[ |(g * f_U - g)(x)| = \left| \int [g(xy) - g(x)] f_U(y) dy \right| \leq \varepsilon \]
    %
    We will always assume from hereon out that the approximate identities in $L^1(G)$ are of this form.
\end{proof}

We have already obtained enough information to characterize the closed ideals of $L^1(G)$.

\begin{theorem}
    If $V$ is a closed subspace of $L^1(G)$, then $V$ is a left ideal if and only if it is closed under left translations, and a right ideal if and only if it is closed under right translations.
\end{theorem}
\begin{proof}
    If $V$ is a closed left ideal, and $f_U$ is an approximate identity at the origin, then for any $g$,
    %
    \[ \| (L_z f_U) * g - L_z g \|_1 = \| L_z (f_U * g - g) \|_1 = \| f_U * g - g \| \to 0 \]
    %
    so $L_z g \in V$. Conversely, if $V$ is closed under left translations, $g \in L^1(G)$, and $f \in V$, then
    %
    \[ g * f = \int g(y) L_{y^{-1}} f dy \]
    %
    which is in the closed linear space of the translates of $f$. Right translation is verified very similarily.
\end{proof}

\section{The Riesz Thorin Theorem}

We finalize our basic discussion by looking at convolutions of functions in $L^p * L^q$. Certainly $L^p * L^1 \subset L^p$, and $L^p * L^q \subset L^\infty$ for $q = p^*$. To prove general results, we require a foundational interpolation result.
%
\begin{theorem}
    For any $0 < \theta < 1$, and $0 < p,q \leq \infty$. If we define
    %
    \[ 1/r_\theta = (1-\theta)/p + \theta/q \]
    %
    to be the inverse interpolation of the two numbers. Then
    %
    \[ \| f \|_{r_\theta} \leq \| f \|_p^{1-\theta} \| f \|_q^\theta \]
\end{theorem}
\begin{proof}
    We apply H\"{o}lder's inequality to find
    %
    \[ \| f \|_{r_\theta} \leq \| f \|_{p/(1 - \theta)} \| f \|_{q/\theta} = \left( \int |f|^{p/(1 - \theta)} \right)^{(1-  \theta)/p} \left( \int |f|^{q/\theta} \right)^{\theta/q} \]
    %
    so it suffices to prove $\| f \|_{p/(1-\theta)} \leq \| f \|_p^{1-\theta}$, $\| f \|_{q/\theta} \leq \| f \|_q^\theta$.

    The map $x \mapsto x^p$ is concave for $0 < p < 1$, so we may apply Jensen's inequality in reverse to conclude
    %
    \[ \left( \int |f|^{p/(1 - \theta)} \right)^{(1-  \theta)/p} \leq \left( \int |f|^p \right)^{1/p} \]
\end{proof}

The Riesz Thorin interpolation theorem then implies $L^p * L^q \subset L^r$, for $p^{-1} + q^{-1} = 1 + r^{-1}$. However, these estimates only guarantee $L^1(G)$ is closed under convolution. If $G$ is compact, then $L_p(G)$ is closed under convolution for all $p$ (TODO). The $L_p$ conjecture says that this is true if and only if $G$ is compact. This was only resolved in 1990.

\section{Homogenous Spaces and Haar Measures}

The natural way for a locally compact topological group $G$ to act on a locally compact Hausdorff space $X$ is via a representation of $G$ in the homeomorphisms of $X$. We assume the action is transitive on $X$. The standard example are the action of $G$ on $G/H$, where $H$ is a closed subspace. These are effectively all examples, because if we fix $x \in X$, then the map $y \mapsto yx$ induces a continuous bijection from $G/H$ to $X$, where $H$ is the set of all $y$ for which $yx = x$. If $G$ is a $\sigma$ compact space, then this map is a homeomorphism.

\begin{theorem}
    If a $\sigma$ compact topological group $G$ has a transitive topological action on $X$, and $x \in X$, then the continuous bijection from $G/G_x$ to $X$ is a homeomorphism.
\end{theorem}
\begin{proof}
    It suffices to show that the map $\phi: G \to X$ is open, and we need only verify this for the neighbourhood basis of compact neighbourhoods $V$ of the origin by properties of the action. $G$ is covered by countably many translates $y_1V, y_2V, \dots$, and since each $\phi(y_kV) = y_k \phi(V)$ is closed (compactness), we conclude that $y_k \phi(V)$ has non-empty interior for some $y_k$, and hence $\phi(V)$ has a non-empty interior point $\phi(y_0)$. But then for any $y \in V$, $y$ is in the interior of $\phi(y V y_0^{-1}) \subset \phi(VV y_0^{-1})$, so if we fix a compact $U$, and find $V$ with $V^3 \subset U$, we have shown $\phi(U)$ is open in $X$.
\end{proof}

We shall say a space $X$ is homogenous if it is homeomorphic to $G/H$ for some group action of $G$ over $X$. The $H$ depends on our choice of basepoint $x$, but only up to conjugation, for if if we switch to a new basepoint $y$, and $c$ maps $x$ to $y$, then $ax = x$ holds if and only if $cac^{-1}y = y$. The question here is to determine whether we have a $G$-invariant measure on $X$. This is certainly not always possible. If we had a measure on $\RR$ invariant under the affine maps $ax + b$, then it would be equal to the Haar measure by uniqueness, but the Haar measure is not invariant under dilation $x \mapsto ax$.

Let $G$ and $H$ have left Haar measures $\mu$ and $\nu$ respectively, denote the projection of $G$ onto $G/H$ as $\pi: G \to G/H$, and let $\Delta_G$ and $\Delta_H$ be the respective modular functions. Define a map $P: C_c(G) \to C_c(G/H)$ by
%
\[ (Pf)(Hx) = \int_H f(xy) d\nu(y) = \int_H  \]
%
this is well defined by the invariance properties of $\nu$. $Pf$ is obviously continuous, and $\text{supp}(Pf) \subset \pi(\text{supp}(f))$. Moreover, if $\phi \in C(G/H)$ we have
%
\[ P((\phi \circ \pi) \cdot f)(Hx) = \phi(xH) \int_H f(xy) d\nu(y) \]
%
so $P((\phi \circ \pi) \cdot f) = \phi P(f)$.

\begin{lemma}
    If $E$ is a compact subset of $G/H$, there is a compact $K \subset G$ with $\pi(K) = E$.
\end{lemma}
\begin{proof}
    Let $V$ be a compact neighbourhood of the origin, and cover $E$ by finitely many translates of $\pi(V)$. We conclude that $\pi^{-1}(E)$ is covered by finitely many of the translates, and taking the intersections of these translates with $\pi^{-1}(E)$ gives us the desired $K$.
\end{proof}

\begin{lemma}
    A compact $F \subset G/H$ gives rise to a function $f \geq 0$ in $C_c(G)$ such that $Pf = 1$ on $E$.
\end{lemma}
\begin{proof}
    Let $E$ be a compact neighbourhood containing $F$, and if $\pi(K) = E$, there is a function $g \in C_c(G)$ with $g > 0$ on $K$, and $\phi \in C_c(G/H)$ is supported on $E$ and $\phi(x) = 1$ for $x \in F$, let
    %
    \[ f = \frac{\phi \circ \pi}{P g \circ \pi} g \]
    %
    Hence
    %
    \[ Pf = \frac{\phi}{Pg} Pg = \phi \]
\end{proof}

\begin{lemma}
    If $\phi \in C_c(G/H)$, there is $f \in C_c(G)$ with $Pf = \phi$, and $\pi(\text{supp} f) = \text{supp}(\phi)$, and also $f \geq 0$ if $\phi \geq 0$.
\end{lemma}
\begin{proof}
    There exists $g \geq 0$ in $C_c(G/H)$ with $Pg = 1$ on $\text{supp}(\phi)$, and then $f = (\phi \circ \pi) g$ satisfies the properties of the theorem.
\end{proof}

We can now provide conditions on the existence of a measure on $G/H$.

\begin{theorem}
    There is a $G$ invariant measure $\psi$ on $G/H$ if and only if $\Delta_G = \Delta_H$ when restricted to $H$. In this case, the measure is unique up to a common factor, and if the factor is chosen, we have
    %
    \[ \int_G f d\mu = \int_{G/H} Pf d\psi = \int_{G/H} \int_H f(xy) d\nu(y) d\psi(xH) \]
\end{theorem}
\begin{proof}
    Suppose $\psi$ existed. Then $f \mapsto \int Pf d \psi$ is a non-zero left invariant positive linear functional on $G/H$, so $\int Pf d\psi = c \int f d\mu$ for some $c > 0$. Since $P(C_c(G)) = C_c(G/H)$, we find that $\psi$ is determined up to a constant factor. We then compute, for $y \in H$,
    %
    \begin{align*}
        \Delta_G(y) \int f(x) d\mu(x) &= \int f(xy^{-1}) d\mu(x)\\
        &= \int_{G/H} \int_H f(xzy^{-1}) d\nu(z) d\psi(xH)\\
        &= \Delta_H(y) \int_{G/H} \int_H f(xz) d\nu(z) d\psi(xH)\\
        &= \Delta_H(y) \int f(x) d\mu(x)
    \end{align*}
    %
    Hence $\Delta_G = \Delta_H$. Conversely, suppose $\Delta_G = \Delta_H$. First, we claim if $f \in C_c(G)$ and $Pf = 0$, then $\int f d\mu = 0$. Indeed if $P\phi = 1$ on $\pi(\text{supp} f)$ then
    %
    \[ 0 = Pf(xH) = \int_H f(xy) d\nu(y) = \Delta_G(y^{-1}) \int_H f(xy^{-1}) d\nu(y) \]
    %
    so
    %
    \begin{align*}
        0 &= \int_G \int_H \Delta_G(y^{-1}) \phi(x) f(xy^{-1}) d\nu(y) d\mu(x)\\
        &= \int_H \int_G \phi(xy) f(x) d\mu(x) d\nu(y)\\
        &= \int_G P\phi(xH) f(x) d\mu(x)\\
        &= \int_G f(x) d\mu(x)
    \end{align*}
    %
    This implies that if $Pf = Pg$, then $\int_G f = \int_G g$. Thus the map $Pf \mapsto \int_G f$ is a well defined $G$ invariant positive linear functional on $C_c(G/H)$, and we obtain a Radon measure from the Riesz representation theorem.
\end{proof}

If $H$ is compact, then $\Delta_G$ and $\Delta_H$ are both continuous homomorphisms from $H$ to $\RR^+$, so $\Delta_G$ and $\Delta_H$ are both trivial, and we conclude a $G$ invariant measure exists on $G/H$.

\section{Function Spaces In Harmonic Analysis}

There are a couple other function spaces that are interesting in Harmonic analysis. We define $\text{AP}(G)$ to be the set of all almost periodic functions, functions $f \in L^\infty(G)$ such that $\{ L_x f : x \in G \}$ is relatively compact in $L^\infty(G)$. If this is true, then $\{ R_x f : x \in G \}$ is also relatively compact, a rather deep theorem. If we define $\text{WAP}(G)$ to be the space of weakly almost periodic functions (the translates are relatively compact in the weak topology). It is a deep fact that $\text{WAP}(G)$ contains $C_0(G)$, but $\text{AP}(G)$ can be quite small. The reason these function spaces are almost periodic is that in the real dimensional case, $\text{AP}(\RR)$ is just the closure of the set of all trigonometric polynomials.

\chapter{The Character Space}

Let $G$ be a locally compact group. A character on $G$ is a {\it continuous} homomorphism from $G$ to $\mathbf{T}$. The space of all characters of a group will be denoted $\Gamma(G)$.

\begin{example}
    Determining the characters of $\mathbf{T}$ involves much of classical Fourier analysis. Let $f: \mathbf{T} \to \mathbf{T}$ be an arbitrary continuous character. For each $w \in \mathbf{T}$, consider the function $g(z) = f(zw) = f(z)f(w)$. We know the Fourier series acts nicely under translation, telling us that
    %
    \[ \hat{g}(n) = w^n \hat{f}(n) \]
    %
    Conversely, since $g(z) = f(z)f(w)$,
    %
    \[ \hat{g}(n) = f(w) \hat{f}(n) \]
    %
    Thus $(w^n - f(w)) \hat{f}(n) = 0$ for all $w \in \mathbf{T}$, $n \in \mathbf{Z}$. Fixing $n$, we either have $f(w) = w^n$ for all $w$, or $\hat{f}(n) = 0$. This implies that if $f \neq 0$, then $f$ is just a power map for some $n \in \mathbf{Z}$.
\end{example}

\begin{example}
    The characters of $\RR$ are of the form $t \mapsto e(t\xi)$, for $\xi \in \RR$. To see this, let $e: \RR \to \mathbf{T}$ be an arbitrary character. Define
    %
    \[ F(x) = \int_0^x e(t) dt \]
    %
    Then $F'(x) = e(x)$. Since $e(0) = 1$, for suitably small $\delta$ we have
    %
    \[ F(\delta) = \int_0^\delta e(t) dt = c > 0 \]
    %
    and then it follows that
    %
    \[ F(x + \delta) - F(x) = \int_x^{x + \delta} e(t) dt = \int_0^\delta e(x + t) dt = c e(x) \]
    %
    As a function of $x$, $F$ is differentiable, and by the fundamental theorem of calculus,
    %
    \[ \frac{dF(x + \delta) - F(x)}{dt} = F'(x + \delta) - F'(x) = e(x + \delta) - e(x) \]
    %
    This implies the right side of the above equation is differentiable, and so
    %
    \[ ce'(x) = e(x + \delta) - e(x) = e(x) [e(\delta) - 1] \]
    %
    Implying $e'(x) = A e(x)$ for some $A \in \mathbf{C}$, so $e(x) = e^{Ax}$. We require that $e(x) \in \mathbf{T}$ for all $x$, so $A = \xi i$ for some $\xi \in \RR$.
\end{example}

\begin{example}
    Consider the group $\RR^+$ of positive real numbers under multiplication. The map $x \mapsto \log x$ is an isomorphism from $\RR^+$ and $\RR$, so that every character on $\RR^+$ is of the form $e(s \log x) = x^{is}$, for some $s \in \RR$. The character group is then $\RR$, since $x^{is} x^{is'} = x^{i(s + s')}$.
\end{example}

There is a connection between characters on $G$ and characters on $L^1(G)$ that is invaluable to the generalization of Fourier analysis to arbitrary groups.

\begin{theorem}
    For any character $\phi: G \to \mathbf{C}$, the map
    %
    \[ \varphi(f) = \int \frac{f(x)}{\phi(x)} dx \]
    %
    is a non-zero character on the convolution algebra $L^1(G)$, and all characters arise this way.
\end{theorem}
\begin{proof}
    The induced map is certainly linear, and
    %
    \begin{align*}
        \varphi(f * g) &= \int \int \frac{f(y) g(y^{-1}x)}{\phi(x)} dy dx\\
        &= \int \int \frac{f(y) g(x)}{\phi(y) \phi(x)} dy dx\\
        &= \int \frac{f(y)}{\phi(y)} dy \int \frac{g(x)}{\phi(x)} dx
    \end{align*}
    %
    Since $\phi$ is continuous, there is a compact subset $K$ of $G$ where $\phi > \varepsilon$ for some $\varepsilon > 0$, and we may then choose a positive $f$ supported on $K$ in such a way that $\varphi(f)$ is non-zero.

    The converse results from applying the duality theory of the $L^p$ spaces. Any character on $L^1(G)$ is a linear functional, hence is of the form
    %
    \[ f \mapsto \int f(x) \phi(x) dx \]
    %
    for some $\phi \in L^\infty(G)$. Now
    %
    \begin{align*}
        \int \int f(y) g(x) \phi(yx) dy dx &= \int \int f(y) g(y^{-1}x) \phi(x) dy dx\\
        &= \int f(x) \phi(x) dx \int g(y) \phi(y) dy\\
        &= \int f(x) g(y) \phi(x) \phi(y) dx dy
    \end{align*}
    %
    Since this holds for all functions $f$ and $g$ in $L^1(G)$, we must have $\phi(yx) = \phi(x) \phi(y)$ almost everywhere. Also
    %
    \begin{align*}
        \int \varphi(f) g(y) \phi(y) dy &= \varphi(f * g)\\
        &= \int \int g(y) f(y^{-1}x) \phi(x) dy dx\\
        &= \int \int (L_{y^{-1}} f)(x) g(y) \phi(x) dy dx\\
        &= \int \varphi(L_{y^{-1}} f) g(y) dy
    \end{align*}
    %
    which implies $\varphi(f) \phi(y) = \varphi(L_{y^{-1}} f)$ almost everywhere. Since the map $\varphi(L_{y^{-1}} f)/\varphi(f)$ is a uniformly continuous function of $y$, $\phi$ is continuous almost everywhere, and we might as well assume $\phi$ is continuous. We then conclude $\phi(xy) = \phi(x) \phi(y)$. Since $\| \phi \|_\infty = 1$ (this is the norm of any character operator on $L^1(G)$), we find $\phi$ maps into $\mathbf{T}$, for if $\| \phi(x) \| < 1$ for any particular $x$, $\| \phi(x^{-1}) \| > 1$.
\end{proof}

Thus there is a one-to-one correspondence with $\Gamma(G)$ and $\Gamma(L^1(G))$, which implies a connection with the Gelfand theory and the character theory of locally compact groups. This also gives us a locally compact topological structure on $\Gamma(G)$, induced by the Gelfand representation on $\Gamma(L^1(G))$. A sequence $\phi_i \to \phi$ if and only if
%
\[ \int \frac{f(x)}{\phi_i(x)} dx \to \int \frac{f(x)}{\phi(x)} dx \]
%
for all functions $f \in L^1(G)$. This actually makes the map
%
\[ (f,\phi) \mapsto \int \frac{f(x)}{\phi(x)} dx \]
%
a jointly continuous map, because as we verified in the proof above,
%
\[ \widehat{f}(\phi) \phi(y) = \widehat{L_y f}(\phi) \]
%
And the map $y \mapsto L_y f$ is a continuous map into $L^1(G)$. If $K \subset G$ and $C \subset \Gamma(G)$ are compact, this allows us to find open sets in $G$ and $\Gamma(G)$ of the form
%
\[ \{ \gamma : \| 1 - \gamma(x) \| < \varepsilon\ \text{for all}\ x \in K \}\ \ \ \ \ \{ x : \| 1 - \gamma(x) \| < \varepsilon\ \text{for all}\ \gamma \in C \} \]
%
And these sets actually form a base for the topology on $\Gamma(G)$.

\begin{theorem}
    If $G$ is discrete, $\Gamma(G)$ is compact, and if $G$ is compact, $\Gamma(G)$ is discrete.
\end{theorem}
\begin{proof}
    If $G$ is discrete, then $L^1(G)$ contains an identity, so $\Gamma(G) = \Gamma(L^1(G))$ is compact. Conversely, if $G$ is compact, then it contains the constant $1$ function, and
    %
    \[ \widehat{1}(\phi) = \int \frac{dx}{\phi(x)} \]
    %
    And
    %
    \[ \frac{1}{\phi(y)} \widehat{1}(\phi) = \int \frac{dx}{\phi(yx)} = \int \frac{dx}{\phi(x)} = \hat{1}(\phi) \]
    %
    So either $\phi(y) = 1$ for all $y$, and it is then verified by calculation that $\widehat{1}(\phi) = 1$, or $\widehat{1}(\phi) = 0$. Since $\widehat{1}$ is continuous, the trivial character must be an open set by itself, and hence $\Gamma(G)$ is discrete.
\end{proof}

Given a function $f \in L^1(G)$, we may take the Gelfand transform, obtaining a function on $C_0(\Gamma(L^1(G)))$. The identification then gives us a function on $C_0(\Gamma(G))$, if we give $\Gamma(G)$ the topology induced by the correspondence (which also makes $\Gamma(G)$ into a topological group). The formula is
%
\[ \widehat{f}(\phi) = \phi(f) = \int \frac{f(x)}{\phi(x)} \]
%
This gives us the classical correspondence between $L^1(\mathbf{T})$ and $C_0(\mathbf{Z})$, and $L^1(\RR)$ and $C_0(\RR)$, which is just the Fourier transform. Thus we see the Gelfand representation as a natural generalization of the Fourier transform. We shall also denote the Fourier transform by $\mathcal{F}$, especially when we try and understand it's properties as an operator. Gelfand's theory (and some basic computation) tells us instantly that

\begin{itemize}
    \item $\widehat{f * g} = \widehat{f} \widehat{g}$ (The transform is a homomorphism).
    \item $\mathcal{F}$ is norm decreasing and therefore continuous: $\| \widehat{f} \|_\infty \leq \| f \|_1$.
    \item If $G$ is unimodular, and $\gamma \in \Gamma(G)$, then $(f * \gamma)(x) = \gamma(x) \widehat{f}(\gamma)$.
\end{itemize}

Whenever we integrate a function with respect to the Haar measure, there is a natural generalization of the concept to the space of all measures on $G$. Thus, for $\mu \in M(G)$, we define
%
\[ \widehat{\mu}(\phi) = \int \frac{dx}{\phi(x)} \]
%
which we call the {\bf Fourier-Stieltjes transform} on $G$. It is essentially an extension of the Gelfand representation on $L^1(G)$ to $M(G)$. Each $\widehat{\mu}$ is a bounded, uniformly continuous function on $\Gamma(G)$, because the transform is still contracting, i.e.
%
\[ \left| \int \frac{d\mu(x)}{\phi(x)} dx \right| \leq \| \mu \| \]
%
It is uniformly continuous, because
%
\[ (L_{\nu} \widehat{\mu} - \widehat{\mu})(\phi) = \int \frac{1 - \nu(x)}{\nu(x) \phi(x)} d\mu(x)  \]
%
The regularity of $\mu$ implies that there is a compact set $K$ such that $|\mu|(K^c) < \varepsilon$. If $\nu_i \to 0$, then eventually we must have $|\nu_i(x) - 1| < \varepsilon$ for all $x \in K$, and then
%
\[ |(L_{\nu} \widehat{\mu} - \widehat{\mu})(\phi)| \leq 2|\mu|(K^c) + \varepsilon \| \mu \| \leq \varepsilon(2 + \|\mu\|) \]
%
Which implies uniform continuity.

Let us consider why it is natural to generalize operators on $L^1(G)$ to $M(G)$. The first reason is due to the intuition of physicists; most of classical Fourier analysis emerged from physical considerations, and it is in this field that $L^1(G)$ is often confused with $M(G)$. Take, for instance, the determination of the electric charge at a point in space. To determine this experimentally, we take the ratio of the charge over some region in space to the volume of the region, and then we limit the size of the region to zero. This is the historical way to obtain the density of a measure with respect to the Lebesgue measure, so that the function we obtain can be integrated to find the charge over a region. However, it is more natural to avoid taking limits, and to just think of charge as an element of $M(\RR^3)$. If we consider a finite number of discrete charges, then we obtain a discrete measure, whose density with respect to the Lebesgue measure does not exist. This doesn't prevent physicists from trying, so they think of the density obtained as shooting off to infinity at points. Essentially, we obtain the Dirac Delta function as a `generalized function'. This is fine for intuition, but things seem to get less intuitive when we consider the charge on a subsurface of $\RR^3$, where the `density' is `dirac'-esque near the function, where as measure theoretically we just obtain a density with respect to the two-dimensional Hausdorff measure on the surface. Thus, when physicists discuss quantities as functions, they are really thinking of measures, and trying to take densities, where really they may not exist.

There is a more austere explanation, which results from the fact that, with respect to integration, $L^1(G)$ is essentially equivalent to $M(G)$. Notice that if $\mu_i \to \mu$ in the weak-$*$ topology, then $\widehat{\mu_i} \to \widehat{\mu}$ pointwise, because
%
\[ \int \frac{d\mu_i(x)}{\phi(x)} \to \int \frac{d\mu(x)}{\phi(x)} \]
%
(This makes sense, because weak-$*$ convergence is essentially pointwise convergence in $M(G)$). Thus the Fourier-Stietjes transform is continuous with respect to these topologies. It is the unique continuous extension of the Fourier transform, because

\begin{theorem}
    $L^1(G)$ is weak-$*$ dense in $M(G)$.
\end{theorem}
\begin{proof}
    First, note that the Dirac delta function can be weak-$*$ approximated by elements of $L^1(G)$, since we have an approximate identity in the space.

    First, note that if $\mu_i \to \mu$, then $\mu_i * \nu \to \mu * \nu$, because
    %
    \[ \int f d(\mu_i * \nu) = \int \int f(xy) d\mu_i(x) d\nu(y) \]
    %
    The functions $y \mapsto \int f(xy) d\mu_i(x)$ converge pointwise to $\int f(xy) d\mu(y)$. Since
    %
    \[ \left| \int f(xy) d\mu_i(x) \right| \leq \| f \|_1 \| \mu_i \| \]

    If $i$ is taken large enough that
\end{proof}

If $\phi_\alpha \to \phi$, in the sense that $\phi_\alpha(x) \to \phi(x)$ for all $x \in G$, then, because $\| \phi_\alpha(x) \| = 1$ for all $x$, we can apply the dominated convergence theorem on any compact subset $K$ of $G$ to conclude
%
\[ \int_K \frac{d\mu(x)}{\phi_\alpha(x)} \to \int_K \frac{d\mu(x)}{\phi(x)} \]

It is immediately verified to be a map into $L^1(\Gamma(G))$, because
%
\[ \int \left| \int \frac{d\mu(x)}{\phi(x)} \right| d\phi \leq \int \int \| \mu \| \]

The formula above immediately suggests a generalization to a transform on $M(G)$. For $\nu \in M(G)$, we define
%
\[ \mathcal{F}(\nu)(\phi) = \int \frac{d \nu}{\phi} \]
%
If $\mathcal{G}: L^1(G) \to C_0(\Gamma(G))$ is the Gelfand transform, then the transform induces a map $\mathcal{G}^* : M(\Gamma(G)) \to L^\infty(G)$.

The duality in class-ical Fourier analysis is shown through the inversion formulas. That is, we have inversion functions
%-00
\[ \mathcal{F}^{-1}(\{ a_k \}) = \sum a_k e_k(t)\ \ \ \ \ \mathcal{F}^{-1}(f)(x) = \int f(t) e(x t) \]
%
which reverses the fourier transform on $\mathbf{T}$ and $\RR$ respectively, on a certain subclass of $L^1$. One of the challenges of Harmonic analysis is trying to find where this holds for the general class of measurable functions.

The first problem is to determine surjectivity. We denote by $A(G)$ the space of all continuous functions which can be represented as the fourier transform of some function in $L^1(G)$. It is to even determine $A(\mathbf{T})$, the most basic example. $A(G)$ always separates the points of $\Gamma(G)$, by Gelfand theory, and if $G$ is unimdoular, then it is closed under conjugation. If we let $g(x) = \overline{f(x^{-1})}$, we find
%
\[ \mathcal{F}(g)(\phi) = \int \frac{g(x)}{\phi(x)} dx = \overline{ \int \frac{f(x^{-1})}{\phi(x^{-1})} dx } = \int \frac{f(x)}{\phi(x)} dx = \overline{\mathcal{F}(f)(\phi)} \]
%
so that by the Stone Weirstrass theorem $A(G)$ is dense in $C_0(\Gamma(L^1(G)))$.

\chapter{Banach Algebra Techniques}

In the mid 20th century, it was realized that much of the analytic information about a topological group can be captured in various $C^*$ algebras related to the group. For instance, consider the Gelfand space of $L^1(\mathbf{Z})$ is $\mathbf{T}$, which represents the fact that one can represent functions over $\mathbf{T}$ as sequences of numbers. Similarily, we find the characters of $L^1(\RR)$ are the maps $f \mapsto \widehat{f}(x)$, so that the Gelfand space of $\RR$ is $\RR$, and the Gelfand transform is the Fourier transform on this space. For a general $G$, we may hope to find a generalized Fourier transform by understanding the Gelfand transform on $L^1(G)$. We can also generalize results by extending our understanding to the class $M(G)$ of regular, Borel measures on $G$.

\chapter{Vector Spaces}

If $\mathbf{K}$ is a closed, multiplicative subgroup of the complex numbers, then $\mathbf{K}$ is also a locally compact abelian group, and we can therefore understand $\mathbf{K}$ by looking at its dual group $\mathbf{K}^*$. The map $\langle x,y \rangle = xy$ is bilinear, in the set that it is a homomorphism in the variable $y$ for each fixed $x$, and a homomorphism in the variable $x$ for each $y$.

If $\mathbf{K}$ is a subfield of the complex numbers, then $\mathbf{K}$ is also an abelian group under addition, and we can consider the dual group $\mathbf{K}^*$. The inner product $\langle x, y \rangle = xy$ gives a continuous bilinear map $\mathbf{K} \times \mathbf{K} \to \mathbf{C}$, and therefore we can define $x^* \in \mathbf{K}^*$ by $x^*(y) = \langle x,y \rangle$. If $x^*(y) = xy = 0$ for all $y$, then in particular $x^*(1) = x$, so $x = 0$. This means that the homomorphism $\mathbf{K} \to \mathbf{K}^*$ is injective.

\chapter{Interpolation of Besov and Sobolev spaces}

An important class of operators arise as singular integrals, that is, they arise as convolution operators $T$ given by $T(f) = f * K$, where $K$ is an appropriate distribution. Taking Fourier transforms, these operators can also be defined by $\widehat{T(f)} = \widehat{f} \widehat{K}$. The function $\widehat{K}$ is known as a {\bf Fourier multiplier}, because it operates by multiplication on the frequencies of the function $f$. We say $\widehat{K}$ is a {\bf Fourier multiplier on $L^p(\RR^n)$} if $T$ is a bounded map from $S(\RR^n)$ to $L^p(\RR^n)$, under the $L^p$ norms. Such maps clearly extend uniquely to maps from $L^p(\RR^n)$ to $L^p(\RR^n)$, and so we can think of $T$ as operating by convolution on the space of $L^p$ functions. We will denote the space of all Fourier multipliers on $L^p$ by $M_p$. We define the $L^p$ norm on these distributions $K$, denoted $\| K \|_p$, to be the operator norm of the associated operator $T$.

\begin{example}
	Consider the space $M_\infty$. If $K$ is a distribution in $M_\infty$, then $\| K \|_\infty < \infty$, and since convolution commutes with translations, in the sense that $f_h * K = (f * K)_h$, then
	%
	\[ \| K \|_\infty = \sup_{f \in L^\infty(\RR^n)} \frac{|(f * K)(0)|}{\| f \|_\infty} \]
	%
	But then the map $f \mapsto (f * K)(0)$ is a bounded operator on the space of bounded continuous functions, and so the Riesz representation says there is a bounded Radon measure $\mu$ such that
	%
	\[ (f * K)(0) = \int f(-y)\; d\mu(y) \]
	%
	But now we know
	%
	\[ (f * K)(x) = (f_{-x} * K)(0) = \int f(x - y) d\mu(y) = (f * \mu)(x) \]
	%
	Thus $M_\infty$ is really just the space of all bounded Radon measures, and
	%
	\[ \| K \|_\infty = \sup_{f \in L^\infty(\RR^n)} \frac{\left| \int f(y)\; d\mu(y) \right|}{\| f \|_\infty} = \| \mu \|_1 \]
	%
	so $M_\infty$ even has the same norm as the space of all bounded Radon measures. Note that it becomes a Banach algebra under convolution of distributions, since the convolution of two bounded Radon measures is a bounded Radon measure.
\end{example}

\begin{theorem}
	For any $1 \leq p \leq \infty$, and $q = p^*$, then $M_p = M_q$.
\end{theorem}
\begin{proof}
	Let $f \in L^p$, and $g \in L^q$, then H\"{o}lder's inequality gives
	%
	\[ |(K * f * g)(0)| \leq \| K * f \|_p \| g \|_q \leq \| K \|_p \| f \|_p \| g \|_p \]
	%
	Thus $K * g \in L_q$, and that $K \in M_q$ with $\| K \|_q \leq \| K \|_p$. By symmetry, we find $\| K \|_p = \| K \|_q$.
\end{proof}

\begin{example}
	Consider $M_2$. If $K$ is a distribution with $\| f * K \|_2 \leq A \| f \|_2$, then Parsevel's inequality implies that
	%
	\[ \| \widehat{f} \widehat{K} \|_2 = \| f * K \|_2 \leq A \| f \|_2 = A \| \widehat{f} \|_2 \]
	%
	so for each $\widehat{f}$, TODO: PROVE THAT THIS IS REALLY JUST THE SPACE $L^\infty(\RR^n)$, with the supremum norm. Note that this is also a Banach algebra under pointwise multiplication.
\end{example}

Using the Riesz-Thorin interpolation theorem, we find that if $1/p = (1 - \theta)/p_0 + \theta/p_1$, then $\| K \|_p \leq \| K \|_{p_0}^{1 - \theta} \| K \|_{p_1}^\theta$, when $K$ lies in the three spaces. In particular, $\| K \|_p$ is a decreasing function of $p$ for $1 \leq p \leq 2$, so we find $M_1 \subset M_p \subset M_q \subset M_2$ for $1 \leq p < q \leq 2$. In particular, all Fourier multipliers can be viewed as Fourier multipliers with respect to bounded, measurable functions on $L^\infty$. Riesz interpolation shows that each $M_p$ is a Banach algebra under multiplication in the frequency domain, or convolution in the spatial domain.

\begin{theorem}
	Let $T: \RR^n \to \RR^m$ be a surjective affine transformation. Then the endomorphism $T^*$ on $M_p(\RR^n)$ defined by $(T^* f)(\xi) = f(T(\xi))$ is an isometry, and if $T$ is a bijection, so too is $T^*$.
\end{theorem}
\begin{proof}
	TODO
\end{proof}

The next theorem is the main tool to prove results about Sobolev and Besov space. Note that it assumes $1 < p < \infty$, and cannot be applied for $p = 1$ or $p = \infty$. The proof relies on two lemmas, the first of which is used frequently later, and the second is used universally in modern harmonic analysis.

\begin{lemma}
	There exists a Schwartz function $\varphi$ on $\RR^n$ which is supported on the annulus
	%
	\[ \{ \xi: 1/2 \leq |\xi| \leq 2 \} \]
	%
	is positive for $1/2 < |\xi| < 2$, and satisfies
	%
	\[ \sum_{k = -\infty}^\infty \varphi(2^{-k} \xi) = 1 \]
	%
	for all $\xi \neq 0$.
\end{lemma}

\begin{lemma}[Calderon-Zygmund Decomposition]
	Let $f \in L^1(\RR^n)$, and $\sigma > 0$. Then there are pairwise almost disjoint cubes $I_1, I_2, \dots$ with edges parallel to the coordinate axis and
	%
	\[ \sigma < \frac{1}{|I_n|} \int_{I_n} |f(x)|\; dx \leq 2^n \sigma \]
	%
	and with $|f(x)| \leq \sigma$ for almost all $x$ outside these cubes.
\end{lemma}

\begin{theorem}[The Mihlin Multiplier Theorem]
	Let $m$ be a bounded function on $\RR^n$ which is smooth except possibly at the origin, such that
	%
	\[ \sup_{\substack{\xi \in \RR^n\\|\alpha| \leq L}} |\xi|^{|\alpha|} |(D^\alpha m)(x)| < \infty \]
	%
	Then $m$ is an $L^p$ Fourier multiplier for $1 < p < \infty$.
\end{theorem}

\section{Besov Spaces}

Recall the Schwarz function $\varphi$ used to prove the Mihlin multiplier theorem. We now define functions $\varphi_k$ such that
%
\[ \widehat{\varphi_n}(\xi) = \varphi(2^{-n} \xi)\ \ \ \ \ \ \ \ \widehat{\psi}(\xi) = 1 - \sum_{n = 1}^\infty \varphi(2^{-n} \xi) \]
%
Thus $\varphi_n$ essentially covers the annulus $2^{n-1} \leq |\xi| \leq 2^{n+1}$, and the function $\psi$ covers the remaining low frequency parts covered in the frequency ball of radius 2. We have
%
\[ \varphi_n(\xi) = \widecheck{\varphi_{2^{-n}}}(\xi) = 2^{dn} \widecheck{\varphi}(2^n \xi) \]
%
Given $s \in \RR$, and $1 \leq p, q \leq \infty$, we write
%
\[ \| f \|_{pq}^s = \| \psi * f \|_p + \left( \sum_{n = 1}^\infty (2^{sn} \| \varphi_k * f \|_p)^q \right)^{1/q} \]
%
The convolution $\varphi_n * f$ essentially captures the portion of $f$ whose frequencies lie in the annulus $2^{n-1} \leq |\xi| \leq 2^{n+1}$

\section{Proof of The Projection Result}

As with Marstrand's projection theorem, we require an energy integral variant. Rather than considering the Riesz kernel on $\RR^n$, we consider the kernel on balls
%
\[ K_\alpha(x) = \frac{\chi_{B(0,R)}(x)}{|x|^\alpha} \]
%
where $R$ is a fixed radius. If $\alpha < \beta$, and $\mu$ is measure supported on a $\beta$ dimensional subset of $\RR^n$, then $\mu * K_\alpha \in L^\infty(\RR^d)$ because $\mu$ cancels out the singular part of $K_\alpha$. Assuming $\beta < d$, we conclude $\mu * K_\alpha \in L^1(\RR^d)$. Applying interpolation (TODO: Which interpolation), we conclude that $\nu * K_\rho$ 

\chapter{The Cap Set Problem}

The cap set problem comes out of additive combinatorics, whose goal is to understand additive structure in some abelian group, typically the integers. For instance, we can think of a set $A$  as being roughly closed under addition if $|A+A| = O(|A|)$. Over rings, we can study the interplay between additive and multiplicative structure. For instance, one conjecture of Erd\"{o}s and Szemer\'{e}di says that if $A$ is a finite subset of real numbers, then $\text{max}(|A+A|,|A \cdot A|) \gtrsim |A|^{1+c}$ for some positive $c \in (0,1)$. The best known $c$ so far is $c \sim 1/3$, though it is conjectured that we can take $c$ arbitrarily close to $1$. This can be seen as a discrete version of the results of Bourgain and Edgar-Miller on the Hausdorff dimensions of Borel subrings.

\begin{theorem}[Van Der Waerden - 1927]
	For any positive integes $r$ and $k$, there is $N$ such that if the integers in $[1,N]$ are given an $r$ coloring, then there is a monochromatic $k$ term arithmetic progression.
\end{theorem}

The coloring itself is not so important, more just the partitioning. We just pidgeonhole, using the density of $k$ term arithmetic progressions. This problem suggests the Ramsey type problem of determining the largest set $A$ of the integers $[1,N]$ which does not contain $k$ term arithmetic progressions. Behrend's theorem says we can choose $A$ to be on the order of $N\exp(-c \sqrt{\log N})$.

\begin{theorem}[Roth - 1956] If $A$ is a set of integers in $[1,N]$ which is free of three term arithmetic progressions, then $|A| = O(N/\log \log N)$.
\end{theorem}

Szemer\'{e}di proved that if $A$ is free of $k$ term arithmetic progressions, $|A| = o(N)$. If Erd\"{o}s Turan, if $\sum_{x \in X} 1/x$ diverges, then $X$ contains arbitrarily long arithmetic progressions. For now, we'll restrict our attention to three term arithmetic progressions. Heath and Brown showed that three term arithmetic progresisons are $O(N/(\log N)^c)$ for some constant $c$. In 2016, the best known bound was given by Bloom, given $O(N(\log \log N)^4/\log N)$.

One way we can simplify our problem is to note that avoiding three term arithmetic progressions is a local issue, so we can embed $[1,N]$ in $\mathbf{Z}/M\mathbf{Z}$ for suitably large $M$, and we lose none of the problems we had over the integers. A heuristic is that it is easier to solve these kind of problems in $\mathbf{F}_p^n$, where $p$ is small and $n$ is large, which should behave like $\{ 1, \dots, p^n \}$. This leads naturally to the cap set problem.

\begin{theorem}[Cap Set Problem]
	What is the largest subset of $\mathbf{F}_3^n$ containing no three term arithmetic progressions?
\end{theorem}

We look at $\mathbf{F}_3$ because it is the smallest case where three term arithmetic progressions become important.

\begin{theorem}[Meschulam - 1995]
	Let $A \subset \mathbf{F}_3^n$ be a cap set. Then $|A| = O(3^n/n)$. This is analogous to a $N/\log N$ case over the integers, giving evidence that the finite field case is easier.
\end{theorem}

In 2012, Bateman and Katz showed $|A| = O(3^n/n^{1 + \varepsilon})$ for some $c > 0$. This was a difficult proof. In 2016, there was a more significant breakthrough, which gave an easy proof using the polynomial method of an exponentially small bound of $c^n$, where $c < 4$, over $\mathbf{Z}/4\mathbf{Z}$, and a week later Ellenberg-Gijswijt used this argument in the $\mathbf{F}_3$ case to prove that if $A$ is a capset in $\mathbf{F}_3$,then $|A| = O(c^n)$, for $c = 2.7551\dots$.

The idea of the polynomial method is to take combinatorial information about some set, encode it as some algebraic structura information, and then apply the theory of polynomials to encode this algebraic information and use it to limit and enable certain properties to occur.

If $V$ is the space of polynomials of degree $d$ vanishing on a set $A$, then we know $\dim V \geq \dim \mathcal{P}_d - |A|$. This gives a lower bound on the size of $A$, whereas we want a lower bound. To get an upper bound, we take $|A|^c$ instead, which shows
%
\[ \dim V \geq \dim \mathcal{P}_d + |A| - 3^n \]
%
whichs gives $|A| \leq 3^n + \dim V - \dim \mathcal{P}_d$. Now using linear algebra, we can find a polynomial $P$ vanishing on $A^c$ with support of cardinality greater than or equal to $\dim V$, hence
%
\[ |A| \leq 3^n - \dim \mathcal{P}_d + \max |\text{supp}(P)| \]
%
It follows that $A$ is a cap set if and only if $x + y = 2z$, or $x + y + z = 0$ holds if and only if $x = y = z$. This is an algebraic property which says directly that $A$ has no nontrivial three term arithmetic progressions. Thus for any $a_1, \dots, a_m \in A$, $P(-a_i-a_j) = 0$ when $i \neq j$. Equivalently, this means $P(-a_i-a_j) \neq 0$ when $i = j$. This suggests we consider the $|A|$ by $|A|$ matrix $M$ with $M_{ij} = P(-a_i-a_j)$. This is a diagonal matrix, with $M_{ii} = P(a_i)$. Thus the rank of this matrix is the dimension of the support of $P$, so it suffices to upper bound the rank of $M$. The key observation, where we now explicitly employ the fact that $P$ is a polynomial, is that $P(-x-y)$ is a polynomial in $2n$ variables $x,y \in \mathbf{F}_3^n$,









\chapter{Appendix: Interpolation Theory}













\end{document}






\section{Homogenous Banach Spaces}

We finish our basic discussion of Fourier summation with a theorem employing the more abstract parts of functional analysis to generalize the convergence properties of good kernels. We saw a Banach space $X$ is a {\bf Homogenous Banach space} if it is a translation invariant subset of $L^1(\mathbf{T})$, with $\| \cdot \|_X \gtrsim \| \cdot \|_1$, and $\| T_t f \|_X = \| f \|_X$ for all $f$ and $T_t$. Finally, we require that $t \mapsto T_t f$ is continuous for each fixed $f \in X$.

\begin{theorem}
	For any good kernel $K_N \in C(\mathbf{T})$, and $f \in X$, $f * K_N \to f$ in $X$.
\end{theorem}
\begin{proof}
	Basic analysis shows that if a map $\phi: [0,2\pi] \to X$ is continuous, then
%
\[ \lim_{N \to \infty} \frac{1}{N} \sum_{m = 1}^N \phi(2\pi m/N) \]
%
exists in the $X$ norm, ala the Riemann integral. We define this to be the `Riemann integral' of $\phi$, i.e.
%
\[ \int_0^{2\pi} \phi(x)\; dx \]
%
This definition obeys all the finite additivity properties of the origin Riemann integral. Further basic approximations prove that if $K_N$ is a good kernel, then
%
\[ \lim \int K_N(x) \phi(x)\; dx = \phi(0) \]
%
If the map $x \mapsto f_x$ is continuous in the $X$ norm, then
%
\[ \lim \int K_N(x) f_x\; dx = f \]
%
But since the $X$ norm upper bounds the $L^1$ norm, $x \mapsto f_x$ is continuous in the $L^1$ norm, and it is easy to see that the $L^1$ value of $\int f_x K_N(x)\; dx$ is $f * K_N$, so we conclude that $f * K_N$ converges to $f$ in the $X$ norm.
\end{proof}

\begin{corollary}
	The trigonometric polynomials contained in $X$ are dense, and for any closed, translation invariant subspace $Y$ of $X$, $f \in Y$ if and only if for every $n$ for which $\widehat{f}(n) \neq 0$, there is $g \in Y$ such that $\widehat{g}(n) \neq 0$.
\end{corollary}
\begin{proof}
	The techniques of the proof above show that if $f \in C(\mathbf{T})$, and $g \in X$, then $f * g \in X$. In particular, this means that the convolutions of any $g \in X$ with an exponential function is contained in $X$. In particular, the trigonometric polynomials spanned by these exponentials must be dense in $X$. The fact about $Y$ is then obvious.
\end{proof}

Examples of homogenous spaces include $C(\mathbf{T})$, with uniform convergence, $C^n(\mathbf{T})$, with uniform convergence of the first $n$ derivatives, and $L^p(\mathbf{T})$, for $p < \infty$. Unfortunately, however, the space $L^\infty(\mathbf{T})$ fails to satisfy the fact that $t \mapsto f_t$ is uniformly continuous, with a counterexample provided by letting $f$ be the characteristic function of an interval. Similarily, the space of $\alpha$ Lipschitz continuous functions for $0 < \alpha < 1$ also does not satisfy this continuity property.

However, if $X$ is any space satisfying the properties of a homogenous Banach space except for the continuity of translation, the space of functions for which translation {\it is} continuous form a closed subspace which is a homogenous Banach space. In the case of $L^\infty(\mathbf{T})$, this subspace is precisely $C(\mathbf{T})$. For the $\alpha$ continuous functions, these functions are precisely those $f$ for which
%
\[ \limsup_{h \to 0} \frac{|f(t+h) - f(t)|}{|h|^\alpha} = 0 \]
%
For $\alpha = 1$, this space is again $C(\mathbf{T})$.

